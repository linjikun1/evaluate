{
    "source_code": "\nstatic void *\nxpalloc (void *pa, ptrdiff_t *nitems, ptrdiff_t nitems_incr_min,\n\t ptrdiff_t nitems_max, ptrdiff_t item_size)\n{\n  ptrdiff_t n0 = *nitems;\n\n  /* The approximate size to use for initial small allocation\n     requests.  This is the largest \"small\" request for the GNU C\n     library malloc.  */\n  enum { DEFAULT_MXFAST = 64 * sizeof (size_t) / 4 };\n\n  /* If the array is tiny, grow it to about (but no greater than)\n     DEFAULT_MXFAST bytes.  Otherwise, grow it by about 50%.\n     Adjust the growth according to three constraints: NITEMS_INCR_MIN,\n     NITEMS_MAX, and what the C language can represent safely.  */\n\n  ptrdiff_t n, nbytes;\n  if (INT_ADD_WRAPV (n0, n0 >> 1, &n))\n    n = PTRDIFF_MAX;\n  if (0 <= nitems_max && nitems_max < n)\n    n = nitems_max;\n\n  ptrdiff_t adjusted_nbytes\n    = ((INT_MULTIPLY_WRAPV (n, item_size, &nbytes) || SIZE_MAX < nbytes)\n       ? MIN (PTRDIFF_MAX, SIZE_MAX)\n       : nbytes < DEFAULT_MXFAST ? DEFAULT_MXFAST : 0);\n  if (adjusted_nbytes)\n    {\n      n = adjusted_nbytes / item_size;\n      nbytes = adjusted_nbytes - adjusted_nbytes % item_size;\n    }\n\n  if (! pa)\n    *nitems = 0;\n  if (n - n0 < nitems_incr_min\n      && (INT_ADD_WRAPV (n0, nitems_incr_min, &n)\n\t  || (0 <= nitems_max && nitems_max < n)\n\t  || INT_MULTIPLY_WRAPV (n, item_size, &nbytes)))\n    xalloc_die ();\n  pa = xrealloc (pa, nbytes);\n  *nitems = n;\n  return pa;\n}",
    "comment": "Allocates or reallocates memory for an array based on its current size, growth constraints, and item size, ensuring safe memory usage.",
    "prorec_sum": "Resizes a buffer allocation size with overflow and limit checks, adjusting to minimum capacity and invoking allocation routines as needed.",
    "filter_prorec_sum": "Dynamically expands a buffer size with overflow and limit checks, adjusting allocation and invoking helper routines to safely increase available storage space.",
    "prorec_aug_sum": "Dynamically increases an allocation size with overflow and limit checks, adjusts element count, and reallocates memory as needed.",
    "filter_prorec_aug_sum": "Resizes a memory buffer, increasing capacity with overflow and limit checks, and reallocates if necessary before updating the tracked size.",
    "work_score": {
        "prorec": {
            "summary": "Resizes a buffer allocation size with overflow and limit checks, adjusting to minimum capacity and invoking allocation routines as needed.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function resizes a buffer and includes overflow and limit checks, adjusts to a minimum capacity, and calls allocation routines. All these details are explicitly present in the source code: overflow/limit checks using INT_ADD_WRAPV, INT_MULTIPLY_WRAPV, constraints on nitems_max and nitems_incr_min, and memory allocation via xrealloc. There are no unverified assumptions or hallucinations, indicating the description is fully accurate.",
                "The summary accurately reflects the core action of resizing a buffer with overflow and limit checks, adjusting to a minimum capacity, and calling allocation routines. This aligns with the source code\u2019s use of INT_ADD_WRAPV, INT_MULTIPLY_WRAPV, NITEMS constraints, and calls to xrealloc and xalloc_die. However, it omits important details such as the initial small allocation logic using DEFAULT_MXFAST, and specific adjustments based on item size, meaning the coverage of edge case handling is incomplete.",
                "The summary correctly notes that the function resizes a buffer with overflow and limit checks, adjusts to a minimum capacity, and uses allocation routines, which are all explicitly evidenced in the code through calls to INT_ADD_WRAPV, INT_MULTIPLY_WRAPV, capacity adjustments, and use of xrealloc/xalloc_die. However, the description is generic and omits specific domain-rich details present in the source, such as DEFAULT_MXFAST logic and handling of pointer initialization, making the accurate details modestly useful rather than richly insightful."
            ]
        },
        "filter_prorec": {
            "summary": "Dynamically expands a buffer size with overflow and limit checks, adjusting allocation and invoking helper routines to safely increase available storage space.",
            "score": [
                0.9666666666666667,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function dynamically expands the buffer with overflow and limit checks and uses helper routines to adjust allocation, all of which are explicitly present in the source code through logic involving INT_ADD_WRAPV, INT_MULTIPLY_WRAPV, nitems_max checks, and xrealloc. The reference to safely increasing available storage aligns with the safe allocation logic seen in the code. No unverifiable or hallucinated claims are present.",
                "The summary accurately captures the main action of the function\u2014dynamic buffer expansion with overflow and limit checks, and use of helper routines for safe allocation\u2014as seen in the code via INT_ADD_WRAPV, INT_MULTIPLY_WRAPV, size limits, and xrealloc/xalloc_die. However, it omits several critical semantic details found in the source, such as DEFAULT_MXFAST handling, precise growth strategy (50% increase or DEFAULT_MXFAST for small arrays), and setting nitems to 0 when pa is NULL, meaning it misses important parts of the logic flow.",
                "The summary correctly captures the dynamic buffer expansion and mentions overflow and limit checks, which are explicitly implemented via INT_ADD_WRAPV, INT_MULTIPLY_WRAPV, and constraints on nitems_max. It also accurately notes the use of helper routines for safe allocation, as seen with xrealloc and xalloc_die. However, it omits specific domain-rich details such as the DEFAULT_MXFAST threshold logic, item_size-based adjustments, and handling of initial null pointer allocations. The accurate points are generic but not highly domain-specific."
            ]
        }
    }
}
{
    "source_code": "\nint\nmu_get_host_name (char **host)\n{\n  char *hostname = NULL;\n  size_t size = 0;\n  char *p;\n\n  while (1)\n    {\n      if (size == 0)\n\t{\n\t  size = MAXHOSTNAMELEN;\n\t  p = malloc (size);\n\t}\n      else\n\t{\n\t  size_t ns = size * 2;\n\t  if (ns < size)\n\t    {\n\t      free (hostname);\n\t      return ENOMEM;\n\t    }\n\t  size = ns;\n\t  p = realloc (hostname, size);\n\t}\n      if (!p)\n\t{\n\t  free (hostname);\n\t  return ENOMEM;\n\t}\n      hostname = p;\n      hostname[size - 1] = 0;\n      if (gethostname (hostname, size - 1) == 0)\n\t{\n\t  if (!hostname[size - 1])\n\t    break;\n\t}\n      else if (errno != 0 && errno != ENAMETOOLONG && errno != EINVAL\n\t       && errno != ENOMEM)\n\t{\n\t  int rc = errno;\n\t  free (hostname);\n\t  return rc;\n\t}\n    }\n\n  /* Try to return fully qualified host name */\n  if (!strchr (hostname, '.'))\n    {\n      struct hostent *hp = gethostbyname (hostname);\n      if (hp)\n\t{\n\t  size_t len = strlen (hp->h_name);\n\t  if (size < len + 1)\n\t    {\n\t      p = realloc (hostname, len + 1);\n\t      if (!p)\n\t\t{\n\t\t  free (hostname);\n\t\t  return ENOMEM;\n\t\t}\n\t      hostname = p;\n\t    }\n\t  strcpy (hostname, hp->h_name);\n\t}\n    }\n  \n  *host = hostname;\n  return 0;\n}",
    "comment": "Retrieves the host name of the machine, expanding the buffer as needed, and attempts to return the fully qualified host name if not present.",
    "prorec_sum": "Retrieves the local host name into allocated memory, expanding buffer as needed and resolving full name via DNS if missing a domain.",
    "filter_prorec_sum": "Allocates and resizes a buffer to retrieve the system\u2019s hostname, optionally resolving it to a fully qualified domain name, and returns it to the caller.",
    "prorec_aug_sum": "Retrieves the local host name, expanding buffer as needed, and resolves it to a fully qualified name if no domain is present.",
    "filter_prorec_aug_sum": "Retrieves the local host name, expanding buffer as needed, and resolves it via DNS if no domain component is present.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves the local host name into allocated memory, expanding buffer as needed and resolving full name via DNS if missing a domain.",
            "score": [
                1.0,
                0.8000000000000002,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function retrieves the local host name, allocates memory, expands the buffer as needed, and resolves the full name via DNS if the hostname lacks a domain. All these details are explicitly supported by the source code via calls to gethostname, malloc/realloc logic, and gethostbyname when no dot is present. No unverified or hallucinated details are present.",
                "The summary accurately describes that the function retrieves the local host name, dynamically expanding the buffer using malloc/realloc until it fits, and attempts to resolve a fully qualified domain name via DNS (gethostbyname) if a '.' is missing. These details match explicit logic in the source code, covering allocation, resizing, hostname retrieval, and DNS resolution. While the summary omits some error handling specifics, it captures the main flow and core logic accurately.",
                "The summary accurately states that the function retrieves the local host name, allocates memory, expands the buffer as needed, and resolves the full name via DNS when missing a domain. All these details are directly supported by the source code: buffer allocation/expansion logic is present, gethostname is used to retrieve the name, and gethostbyname is called if the domain is missing. No inaccuracies are found, and the details are domain-specific and informative."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and resizes a buffer to retrieve the system\u2019s hostname, optionally resolving it to a fully qualified domain name, and returns it to the caller.",
            "score": [
                1.0,
                0.6999999999999998,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function allocates and resizes a buffer to get the system's hostname and may resolve it to a fully qualified domain name before returning it to the caller. Both allocation/resizing via malloc/realloc and optional resolution using gethostbyname are explicitly present in the source code, making all details accurate with no unverified assumptions.",
                "The summary accurately describes the allocation and resizing of a buffer to obtain the system hostname, the optional resolution to a fully qualified domain name via gethostbyname, and returning it to the caller. These elements are explicitly present in the source code, covering the primary logic, though the summary omits specific error handling paths and edge-case handling found in the code.",
                "The summary accurately states that the function allocates and resizes a buffer to retrieve the system\u2019s hostname and may resolve it to a fully qualified domain name before returning it. These steps are explicitly reflected in the source code through allocation with malloc/realloc, repeated calls to gethostname, and the conditional logic using gethostbyname to obtain a fully qualified name. No details are inaccurate, and the accurate details are domain-specific and directly tied to the code\u2019s logic."
            ]
        }
    }
}
{
    "source_code": "static int do_sysinfo(struct sysinfo *info)\n{\n\tunsigned long mem_total, sav_total;\n\tunsigned int mem_unit, bitcount;\n\tstruct timespec tp;\n\n\tmemset(info, 0, sizeof(struct sysinfo));\n\n\tktime_get_ts(&tp);\n\tmonotonic_to_bootbased(&tp);\n\tinfo->uptime = tp.tv_sec + (tp.tv_nsec ? 1 : 0);\n\n\tget_avenrun(info->loads, 0, SI_LOAD_SHIFT - FSHIFT);\n\n\tinfo->procs = nr_threads;\n\n\tsi_meminfo(info);\n\tsi_swapinfo(info);\n\n\t/*\n\t * If the sum of all the available memory (i.e. ram + swap)\n\t * is less than can be stored in a 32 bit unsigned long then\n\t * we can be binary compatible with 2.2.x kernels.  If not,\n\t * well, in that case 2.2.x was broken anyways...\n\t *\n\t *  -Erik Andersen <andersee@debian.org>\n\t */\n\n\tmem_total = info->totalram + info->totalswap;\n\tif (mem_total < info->totalram || mem_total < info->totalswap)\n\t\tgoto out;\n\tbitcount = 0;\n\tmem_unit = info->mem_unit;\n\twhile (mem_unit > 1) {\n\t\tbitcount++;\n\t\tmem_unit >>= 1;\n\t\tsav_total = mem_total;\n\t\tmem_total <<= 1;\n\t\tif (mem_total < sav_total)\n\t\t\tgoto out;\n\t}\n\n\t/*\n\t * If mem_total did not overflow, multiply all memory values by\n\t * info->mem_unit and set it to 1.  This leaves things compatible\n\t * with 2.2.x, and also retains compatibility with earlier 2.4.x\n\t * kernels...\n\t */\n\n\tinfo->mem_unit = 1;\n\tinfo->totalram <<= bitcount;\n\tinfo->freeram <<= bitcount;\n\tinfo->sharedram <<= bitcount;\n\tinfo->bufferram <<= bitcount;\n\tinfo->totalswap <<= bitcount;\n\tinfo->freeswap <<= bitcount;\n\tinfo->totalhigh <<= bitcount;\n\tinfo->freehigh <<= bitcount;\n\nout:\n\treturn 0;\n}",
    "comment": "Populates the `sysinfo` structure with system uptime, load averages, process count, and adjusted memory and swap information, ensuring compatibility with older kernels.",
    "prorec_sum": "Initializes a 0x70-byte structure, populates fields via helper calls, and scales multiple numeric members based on computed size constraints.",
    "filter_prorec_sum": "Initializes a 0x70-byte structure with computed size parameters and scales multiple fields based on capacity and power-of-two alignment requirements.",
    "prorec_aug_sum": "Initializes and scales multiple 64-bit fields in a 0x70-byte structure based on computed sums and shift factors from temporary values.",
    "filter_prorec_aug_sum": "Initializes and zeroes a 0x70-byte structure, computes and adjusts multiple 64-bit fields via scaling shifts based on combined size constraints and stored parameters.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a 0x70-byte structure, populates fields via helper calls, and scales multiple numeric members based on computed size constraints.",
            "score": [
                0.7666666666666666,
                0.6333333333333333,
                0.7333333333333334
            ],
            "reason": [
                "The summary correctly notes that a structure is initialized and populated via helper calls, and that multiple numeric members are scaled based on computed constraints, which matches the memset call, various si_* helper functions, and bit-shifting logic in the source code. However, the claim of a '0x70-byte structure' is unverified, as neither size nor exact byte length is specified in the code; sizeof(struct sysinfo) is present but without byte value evidence. This introduces a hallucination, reducing overall accuracy.",
                "The summary accurately captures that the function initializes a structure (via memset), populates fields using helper calls (ktime_get_ts, get_avenrun, si_meminfo, si_swapinfo) and scales multiple numeric members based on computed size constraints (bitcount loop and <<= operations). However, it omits key specifics such as the conditional overflow checks and the mem_unit recalculation logic, so while the main actions are present, some critical control flow and edge case handling are missing.",
                "The summary claims a 0x70-byte structure initialization, but the source code uses sizeof(struct sysinfo) with no evidence of an explicit 0x70 size, making that detail inaccurate. It accurately notes that fields are populated via helper calls (e.g., ktime_get_ts, get_avenrun, si_meminfo, si_swapinfo) and describes scaling numeric members based on computed constraints, which matches the bitcount logic and shifts in the code. Only one of three main details is inaccurate, so the proportion of inaccuracies is below the kill switch threshold. The accurate details are domain-relevant and describe meaningful control and scaling logic."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a 0x70-byte structure with computed size parameters and scales multiple fields based on capacity and power-of-two alignment requirements.",
            "score": [
                0.2333333333333333,
                0.39999999999999997,
                0.0
            ],
            "reason": [
                "The summary claims the structure is 0x70 bytes and refers to computed size parameters and power-of-two alignment requirements, but the source code only shows initialization using sizeof(struct sysinfo) and scaling memory fields based on mem_unit and bit shifts. There is no explicit evidence of the 0x70-byte size or capacity-based alignment logic beyond bitcount calculation for mem_unit. Only the scaling of multiple memory-related fields is accurate; most other details are unverified or hallucinated.",
                "The summary claims initialization of a 0x70-byte structure and scaling based on capacity and power-of-two alignment requirements. The source code does initialize a struct sysinfo with memset and scales multiple memory-related fields after determining a bitcount via a power-of-two loop over mem_unit. However, there is no explicit evidence in the source code that the structure is 0x70 bytes or that scaling is based on capacity; the scaling is conditional on overflow checks and mem_unit shifting, not total capacity thresholds. The 0x70-byte claim is unsupported, making part of the summary inaccurate. The remaining accurate detail\u2014that multiple fields are scaled after specific loop logic\u2014is partial and misses other core logic like uptime calculation, load averages retrieval, and swap/memory info collection.",
                "The summary claims a 0x70-byte structure size and references capacity and power-of-two alignment requirements, but the source code does not provide explicit evidence of the structure's byte size or any general capacity/power-of-two alignment constraint beyond the specific mem_unit shifting loop. While it does initialize the struct and scale memory fields, most details are either absent or loosely inferred, with more than half being inaccurate."
            ]
        }
    }
}
{
    "source_code": "int drm_markbufs(struct drm_device *dev, void *data,\n\t\t struct drm_file *file_priv)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf_desc *request = data;\n\tint order;\n\tstruct drm_buf_entry *entry;\n\n\tif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\n\t\treturn -EINVAL;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tDRM_DEBUG(\"%d, %d, %d\\n\",\n\t\t  request->size, request->low_mark, request->high_mark);\n\torder = drm_order(request->size);\n\tif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\n\t\treturn -EINVAL;\n\tentry = &dma->bufs[order];\n\n\tif (request->low_mark < 0 || request->low_mark > entry->buf_count)\n\t\treturn -EINVAL;\n\tif (request->high_mark < 0 || request->high_mark > entry->buf_count)\n\t\treturn -EINVAL;\n\n\tentry->freelist.low_mark = request->low_mark;\n\tentry->freelist.high_mark = request->high_mark;\n\n\treturn 0;\n}",
    "comment": "Configures buffer management parameters, including size and free list thresholds, for a Direct Rendering Manager (DRM) device's DMA buffers.",
    "prorec_sum": "Validates DRM buffer parameters and updates buffer metadata entries after ensuring power-of-two size constraints and index bounds are satisfied.",
    "filter_prorec_sum": "Validates DRM buffer parameters and updates buffer metadata entries with provided indices after extensive bounds and configuration checks.",
    "prorec_aug_sum": "Validates DRM buffer parameters and updates two buffer-related fields within a device-specific structure if all checks pass.",
    "filter_prorec_aug_sum": "Validates DRM buffer parameters and updates corresponding buffer record fields with provided values if all alignment, size, and range checks pass.",
    "work_score": {
        "prorec": {
            "summary": "Validates DRM buffer parameters and updates buffer metadata entries after ensuring power-of-two size constraints and index bounds are satisfied.",
            "score": [
                0.7666666666666666,
                0.6,
                0.6
            ],
            "reason": [
                "The summary accurately reflects that the function validates DRM buffer parameters and updates metadata entries. It captures checks on size and index bounds, and setting low/high marks. However, the mention of 'power-of-two size constraints' is inaccurate, as the code validates size using drm_order and order range checks rather than explicitly enforcing a power-of-two requirement. This adds an unverified assumption, reducing accuracy.",
                "The summary correctly notes validation of DRM buffer parameters and updating buffer metadata entries with index bounds checks, which matches the code's checks of low_mark and high_mark against buf_count and subsequent assignment to freelist. However, the mention of 'power-of-two size constraints' is inaccurate, as the code does not explicitly enforce a power-of-two size, only checking that the order derived from size is within min/max bounds. This omission of specific feature checks (DRIVER_HAVE_DMA, dma existence) means the coverage of logic is partial.",
                "The summary accurately notes that the function validates DRM buffer parameters and updates buffer metadata entries, as seen in the checks for low_mark and high_mark bounds and the updates to freelist. However, the mention of 'power-of-two size constraints' is inaccurate since the code verifies size order against DRM_MIN_ORDER and DRM_MAX_ORDER, not explicitly for power-of-two. With one out of three semantic details inaccurate, the proportion of inaccuracies is under 50%, and the accurate details are specific to DRM buffer logic but not deeply domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Validates DRM buffer parameters and updates buffer metadata entries with provided indices after extensive bounds and configuration checks.",
            "score": [
                1.0,
                0.7666666666666666,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly states that the function validates DRM buffer parameters and updates buffer metadata entries after performing bounds and configuration checks. This is explicitly supported by the source code, which checks driver capabilities, DMA availability, and bounds on size, low_mark, and high_mark before updating freelist metadata. All semantic details match the code without introducing unverified assumptions, showing strong alignment.",
                "The summary accurately describes validation of DRM buffer parameters and updating metadata entries after bounds and configuration checks. This matches the code\u2019s checks for DRIVER_HAVE_DMA, dma existence, valid order range, and low/high marks within buffer counts before assigning them to the freelist. While the summary omits explicit mention of order calculation and buffer count constraints, it covers the main action and critical control flow for parameter validation and updates.",
                "The summary correctly notes validation of DRM buffer parameters and updating of metadata entries, which is explicitly shown by the bounds checks against buf_count and the assignment to freelist.low_mark/high_mark in the source code. However, the claim of 'extensive bounds and configuration checks' is slightly overstated but still grounded in visible conditions such as feature flags, DMA existence, size order limits, and mark bounds. All details are accurate, and though they are somewhat generic rather than deeply domain-rich, they reflect the actual logic present."
            ]
        }
    }
}
{
    "source_code": "\nstatic const char* findlocal(lua_State* L, CallInfo* ci, int n, StkId* pos) {\n  const char* name = NULL;\n  StkId base;\n  if (isLua(ci)) {\n    if (n < 0) /* access to vararg values? */\n      return findvararg(ci, -n, pos);\n    else {\n      base = ci->u.l.base;\n      name = luaF_getlocalname(ci_func(ci)->p, n, currentpc(ci));\n    }\n  } else\n    base = ci->func + 1;\n  if (name == NULL) { /* no 'standard' name? */\n    StkId limit = (ci == L->ci) ? L->top : ci->next->func;\n    if (limit - base >= n && n > 0) /* is 'n' inside 'ci' stack? */\n      name = \"(*temporary)\"; /* generic name for any valid slot */\n    else\n      return NULL; /* no name */\n  }\n  *pos = base + (n - 1);\n  return name;\n}",
    "comment": "Retrieves the local variable name from a Lua function's call frame or returns a generic name for temporary slots if no name exists.",
    "prorec_sum": "Retrieves a pointer to a specified argument slot and returns a descriptor string for vararg or temporary arguments based on index bounds.",
    "filter_prorec_sum": "Retrieves a parameter or temporary value address from a parser data structure, returning descriptive labels for vararg or temporary entries when valid.",
    "prorec_aug_sum": "Resolves an argument position within a variadic or temporary sequence, setting a pointer to its data and returning an identifying descriptor string.",
    "filter_prorec_aug_sum": "Retrieves a specific argument or temporary variable pointer from a data structure, returning descriptor strings for varargs or temporaries when within valid bounds.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves a pointer to a specified argument slot and returns a descriptor string for vararg or temporary arguments based on index bounds.",
            "score": [
                0.9666666666666667,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly states that the function returns a descriptor string for vararg arguments when the index is negative and a temporary name when appropriate based on bounds checks. It also accurately notes that the function calculates a pointer to the argument slot. All these details are explicitly supported by the source code logic (vararg handling, temporary name assignment, and pointer calculation via *pos). No unverified assumptions are present.",
                "The summary correctly identifies that the function retrieves a pointer to a stack slot and returns descriptor strings for vararg or temporary arguments depending on index bounds, which is directly evidenced by the vararg handling when 'n < 0', the generic name assignment \"(*temporary)\" when within stack bounds, and calculation of '*pos'. However, it omits details such as the retrieval of local variable names via 'luaF_getlocalname', control flow for non-Lua functions, and the NULL return case when bounds fail, making the depiction incomplete.",
                "The summary correctly notes that the function returns a descriptor string for vararg or temporary arguments based on index bounds, which matches the explicit logic for handling 'n < 0' via findvararg and returning '(*temporary)'. However, it inaccurately claims retrieval of a pointer to a specified argument slot in general terms without specifying that it is placed in '*pos' and depends on the base pointer logic, making this partial misrepresentation. The proportion of inaccurate details is below 50%, and the accurate details are domain-relevant but somewhat generic without full explanation of Lua-specific internals."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves a parameter or temporary value address from a parser data structure, returning descriptive labels for vararg or temporary entries when valid.",
            "score": [
                0.6,
                0.6,
                0.19999999999999998
            ],
            "reason": [
                "The summary claims interaction with a 'parser data structure', which is inaccurate because the source code operates on Lua interpreter structures (`lua_State`, `CallInfo`, `StkId`) rather than a parser. The mention of returning descriptive labels for vararg entries aligns with the branch returning `findvararg` results, and for temporary entries matches the code assigning \"(*temporary)\" when conditions are met. However, the reference to retrieving a parameter or temporary value address is only partially accurate, as the function returns names and sets `*pos` rather than the address itself. Overall, there is a mix of accurate description of vararg/temporary handling and inaccurate assumptions about parser context, yielding a moderate accuracy ratio.",
                "The summary correctly notes retrieval of a value address and returning labels for vararg or temporary entries when valid, which is explicitly shown in the source code via checks for varargs (n < 0) and assignment of '(*temporary)'. However, it inaccurately describes the source as a parser data structure\u2014there is no evidence of parsing, as the code deals with Lua call frames and stack positions\u2014so part of the context is hallucinated. The accurate portion captures the core branching and label assignment but omits specifics such as handling NULL names, base calculation for non-Lua functions, and limit checks, leaving some important logic unmentioned.",
                "The summary claims the function retrieves a parameter or temporary value address from a parser data structure and returns descriptive labels for vararg or temporary entries when valid. While it is accurate that the function can return labels for vararg (via findvararg) and temporary entries (\"(*temporary)\"), and calculates positions via *pos, the mention of a 'parser data structure' is inaccurate\u2014this code operates on Lua runtime call frames, not a parser. Therefore, over 50% of the details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "  \nvoid\nmu_ident_stat (mu_stream_t str)\n{\n  size_t count, i;\n  mu_iterator_t itr;\n  \n  mu_stream_printf (str, \"BEGIN IDENT STAT\\n\");\n\n  mu_assoc_count (nametab, &count);\n  mu_stream_printf (str, \"N=%zu\\n\", count);\n\n  if (count > 0)\n    {\n      int rc = mu_assoc_get_iterator (nametab, &itr);\n      if (rc)\n\tmu_stream_printf (str, \"mu_assoc_get_iterator: %s\\n\",\n\t\t\t  mu_strerror (rc));\n      else\n\t{\n\t  i = 0;\n\t  for (mu_iterator_first (itr); !mu_iterator_is_done (itr);\n\t       mu_iterator_next (itr), i++)\n\t    {\n\t      const char *key;\n\t      struct mu_ident_ref *ref;\n\t      \n\t      mu_iterator_current_kv (itr,\n\t\t\t\t      (const void **)&key, (void **)&ref);  \n\t      mu_stream_printf (str, \"%04zu: %s: %zu\\n\", i, key, ref->count);\n\t    }\n\t}\n      mu_iterator_destroy (&itr);\n    }\n  mu_stream_printf (str, \"END IDENT STAT\\n\");\n}",
    "comment": "Outputs the count and details of identifiers from a name table to a specified stream, including key-value pairs and their associated counts.",
    "prorec_sum": "Outputs the contents and size of the global `qword_2DFC80` association to a stream, iterating and printing each key\u2013value pair with formatted statistics.",
    "filter_prorec_sum": "Outputs identification statistics by counting entries in an association, iterating over key\u2011value pairs, and printing formatted results to the given stream.",
    "prorec_aug_sum": "Outputs identification statistics by counting entries in an association, iterating through key-value pairs, and printing formatted results to the given stream.",
    "filter_prorec_aug_sum": "Outputs identification statistics by counting entries in a global association, iterating through key-value pairs, and printing formatted results to a provided stream.",
    "work_score": {
        "prorec": {
            "summary": "Outputs the contents and size of the global `qword_2DFC80` association to a stream, iterating and printing each key\u2013value pair with formatted statistics.",
            "score": [
                0.3666666666666667,
                0.2333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims the function outputs the contents and size of a global `qword_2DFC80` association, but the source code references `nametab` as the data source, with no evidence of `qword_2DFC80`. While it is correct that the function iterates over key\u2013value pairs and prints formatted statistics, the identification of the global variable is inaccurate. This makes only part of the summary accurate, with a key detail being a hallucination.",
                "The summary references a global `qword_2DFC80` association, which is not present in the source code; the source code uses `nametab` instead. It correctly describes iteration and formatted output of each key\u2013value pair, but the inaccurate identifier means the main subject is misrepresented. After discarding the incorrect detail, the remaining accurate parts only partially capture the logic, missing error handling and the 'BEGIN'/'END' markers.",
                "The summary claims the function outputs the contents and size of a global `qword_2DFC80` association, but the source code shows it operates on `nametab` via `mu_assoc_count` and `mu_assoc_get_iterator`. There is no mention or evidence of `qword_2DFC80`. The accurate part is that it iterates over key\u2013value pairs and prints them with formatting, but the main association name detail is inaccurate. Since over 50% of the semantic details are incorrect, the evaluation stops with the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Outputs identification statistics by counting entries in an association, iterating over key\u2011value pairs, and printing formatted results to the given stream.",
            "score": [
                1.0,
                0.6333333333333333,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly states that the function counts entries in an association, iterates over key\u2011value pairs, and prints formatted results to the given stream. All these points are explicitly supported by the source code via functions like mu_assoc_count, mu_assoc_get_iterator, mu_iterator_current_kv, and mu_stream_printf. There are no unverified assumptions or extraneous claims, meaning all identified semantic details align with the code.",
                "The summary accurately states that the function counts entries in an association, iterates over key-value pairs, and prints formatted results to the provided stream. These details are all explicitly present in the code via mu_assoc_count, mu_assoc_get_iterator, the iteration loop over mu_iterator functions, and mu_stream_printf calls. However, the summary omits notable elements such as the printing of BEGIN/END markers, handling of the iterator creation error, and the output of N= count. While correct on the core logic, it lacks completeness regarding edge cases and specific output details.",
                "The summary accurately reflects the source code\u2019s logic: it counts entries using mu_assoc_count, iterates over key-value pairs with an iterator, and prints formatted results to the provided stream. All these details have explicit evidence in function calls and parameters. The details are domain\u2011specific and provide a clear understanding of the function\u2019s purpose and flow."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\nnfs3_proc_link(struct inode *inode, struct inode *dir, struct qstr *name)\n{\n\tstruct nfs3_linkargs\targ = {\n\t\t.fromfh\t\t= NFS_FH(inode),\n\t\t.tofh\t\t= NFS_FH(dir),\n\t\t.toname\t\t= name->name,\n\t\t.tolen\t\t= name->len\n\t};\n\tstruct nfs3_linkres\tres;\n\tstruct rpc_message msg = {\n\t\t.rpc_proc\t= &nfs3_procedures[NFS3PROC_LINK],\n\t\t.rpc_argp\t= &arg,\n\t\t.rpc_resp\t= &res,\n\t};\n\tint status = -ENOMEM;\n\n\tdprintk(\"NFS call  link %s\\n\", name->name);\n\tres.fattr = nfs_alloc_fattr();\n\tres.dir_attr = nfs_alloc_fattr();\n\tif (res.fattr == NULL || res.dir_attr == NULL)\n\t\tgoto out;\n\n\tstatus = rpc_call_sync(NFS_CLIENT(inode), &msg, 0);\n\tnfs_post_op_update_inode(dir, res.dir_attr);\n\tnfs_post_op_update_inode(inode, res.fattr);\nout:\n\tnfs_free_fattr(res.dir_attr);\n\tnfs_free_fattr(res.fattr);\n\tdprintk(\"NFS reply link: %d\\n\", status);\n\treturn status;\n}",
    "comment": "Links a source inode to a target directory inode with a specified name using an NFS procedure and updates their attributes.",
    "prorec_sum": "Generates two data structures from provided doubles, processes them with helper routines, and returns a status from a subsequent structured operation.",
    "filter_prorec_sum": "Generates two data objects from input parameters, processes them with helper routines, and returns a status code indicating success or resource error.",
    "prorec_aug_sum": "Allocates two data structures from provided parameters, processes them through helper calls, and returns a status code while performing related cleanup.",
    "filter_prorec_aug_sum": "Allocates two data structures from provided parameters, processes them through helper routines, and returns the resulting status code.",
    "work_score": {
        "prorec": {
            "summary": "Generates two data structures from provided doubles, processes them with helper routines, and returns a status from a subsequent structured operation.",
            "score": [
                0.06666666666666667,
                0.06666666666666667,
                0.0
            ],
            "reason": [
                "The summary claims the function generates two data structures from provided doubles and processes them with helper routines, but the source code shows it creates link argument and result structures from inode and name values, not doubles. The operations involve RPC calls and attribute updates, which are not described accurately in the summary. None of the specific details in the summary are supported by explicit evidence from the source code, indicating complete inaccuracy.",
                "The summary claims generation of data structures from doubles, which is inaccurate since the source code constructs 'nfs3_linkargs' and 'nfs3_linkres' from inode and name parameters, not doubles. It also references processing with unspecified helper routines, which doesn't match the explicit function calls like 'nfs_alloc_fattr', 'rpc_call_sync', and 'nfs_post_op_update_inode' in the code. None of the specific details in the summary are directly supported by the source code, leaving no accurate content to map to critical logic.",
                "The summary claims the function generates two data structures from provided doubles, but the source code shows creation of NFS-related structs from inode and name parameters, with no use of doubles. It also omits specific accurate details like the rpc_call_sync invocation, use of nfs_alloc_fattr, and post-operation inode updates. All semantic details in the summary are inaccurate, exceeding the kill switch threshold."
            ]
        },
        "filter_prorec": {
            "summary": "Generates two data objects from input parameters, processes them with helper routines, and returns a status code indicating success or resource error.",
            "score": [
                0.7333333333333334,
                0.6333333333333333,
                0.5666666666666667
            ],
            "reason": [
                "The summary contains vague semantic details but misses explicit evidence from the source code. While it correctly notes generating data objects from input parameters and returning a status code, it fails to reflect specifics such as 'nfs3_linkargs', 'nfs3_linkres', use of 'rpc_call_sync', and allocation of fattr structures. The claim of processing with helper routines is partially accurate but is too generalized and omits key verified function names. Overall, less than half of the summary\u2019s details are explicitly supported by the source code.",
                "The summary\u2019s claims about generating two data objects from input parameters and processing them with helper routines are supported by the code: the function constructs `nfs3_linkargs` from inode and name inputs, creates `nfs3_linkres`, uses allocation helpers (`nfs_alloc_fattr`), and processes these with RPC and update routines. It also returns a status code that can indicate success or a resource allocation failure (`-ENOMEM`). However, the summary omits mention of control flow elements like conditional checks, error handling via `goto`, and cleanup (`nfs_free_fattr`), so it does not fully capture all critical logic.",
                "The summary omits critical specifics from the source code, such as the use of 'nfs3_linkargs', 'nfs3_linkres', and 'rpc_message' structures, and helper functions like 'nfs_alloc_fattr', 'rpc_call_sync', and 'nfs_post_op_update_inode'. While it correctly notes that data objects are created from input and a status code is returned, it generalizes the process too much, failing to capture domain-rich details evident in the code. The few accurate points are generic and lack specificity, making them of low value."
            ]
        }
    }
}
{
    "source_code": "static void tsc_refine_calibration_work(struct work_struct *work)\n{\n\tstatic u64 tsc_start = -1, ref_start;\n\tstatic int hpet;\n\tu64 tsc_stop, ref_stop, delta;\n\tunsigned long freq;\n\n\t/* Don't bother refining TSC on unstable systems */\n\tif (check_tsc_unstable())\n\t\tgoto out;\n\n\t/*\n\t * Since the work is started early in boot, we may be\n\t * delayed the first time we expire. So set the workqueue\n\t * again once we know timers are working.\n\t */\n\tif (tsc_start == -1) {\n\t\t/*\n\t\t * Only set hpet once, to avoid mixing hardware\n\t\t * if the hpet becomes enabled later.\n\t\t */\n\t\thpet = is_hpet_enabled();\n\t\tschedule_delayed_work(&tsc_irqwork, HZ);\n\t\ttsc_start = tsc_read_refs(&ref_start, hpet);\n\t\treturn;\n\t}\n\n\ttsc_stop = tsc_read_refs(&ref_stop, hpet);\n\n\t/* hpet or pmtimer available ? */\n\tif (ref_start == ref_stop)\n\t\tgoto out;\n\n\t/* Check, whether the sampling was disturbed by an SMI */\n\tif (tsc_start == ULLONG_MAX || tsc_stop == ULLONG_MAX)\n\t\tgoto out;\n\n\tdelta = tsc_stop - tsc_start;\n\tdelta *= 1000000LL;\n\tif (hpet)\n\t\tfreq = calc_hpet_ref(delta, ref_start, ref_stop);\n\telse\n\t\tfreq = calc_pmtimer_ref(delta, ref_start, ref_stop);\n\n\t/* Make sure we're within 1% */\n\tif (abs(tsc_khz - freq) > tsc_khz/100)\n\t\tgoto out;\n\n\ttsc_khz = freq;\n\tpr_info(\"Refined TSC clocksource calibration: %lu.%03lu MHz\\n\",\n\t\t(unsigned long)tsc_khz / 1000,\n\t\t(unsigned long)tsc_khz % 1000);\n\nout:\n\tclocksource_register_khz(&clocksource_tsc, tsc_khz);\n}",
    "comment": "Refines TSC clocksource calibration by measuring timer frequencies and adjusting the TSC frequency if within 1% accuracy after initial readings.",
    "prorec_sum": "Calculates elapsed time between hardware counter readings to derive a clock rate or interval, updates stored timing values, and returns the computed result.",
    "filter_prorec_sum": "Computes the elapsed time since a stored timestamp using hardware counters, updates cached timing values, and returns the current computed clock interval.",
    "prorec_aug_sum": "Calculates timing ratio from recent clock readings, updates a stored value, and invokes a handler with the derived timing metrics.",
    "filter_prorec_aug_sum": "Calculates time elapsed from hardware counters to update and return a scaled clock value, initializing reference timestamps if not yet set.",
    "work_score": {
        "prorec": {
            "summary": "Calculates elapsed time between hardware counter readings to derive a clock rate or interval, updates stored timing values, and returns the computed result.",
            "score": [
                0.6,
                0.5333333333333333,
                0.16666666666666666
            ],
            "reason": [
                "The summary correctly notes that the function calculates elapsed time between hardware counter readings to derive a frequency and updates a stored timing value, which matches the delta computation and tsc_khz update in the source. However, it inaccurately claims the function returns the computed result, whereas in the code there is no return value; instead, it registers the updated frequency with clocksource_register_khz. The omission of conditional checks, hardware selection logic, and absence of explicit return reduces accuracy.",
                "The summary correctly notes that the code calculates elapsed time between hardware counter readings to derive a clock rate and updates stored timing values, which is explicitly shown through the use of tsc_start, tsc_stop, delta calculation, and updating tsc_khz. However, it omits key control flow and edge case handling present in the source, such as early exits for unstable TSC, equal ref_start/ref_stop checks, SMI disturbance conditions, and branching between HPET and PMTIMER calculations. These omissions mean the coverage of the main logic is partial and misses critical steps.",
                "The summary omits key logic such as checks for unstable TSC, handling HPET vs PMTimer, scheduling delayed work, and verifying consistency within 1%. It inaccurately claims that the function 'returns the computed result', whereas the source code does not return a value but updates a global variable and registers the clocksource. While timing values are updated and frequency derived using delta calculations, most described details are either generic or partially incorrect, with over half being inaccurate."
            ]
        },
        "filter_prorec": {
            "summary": "Computes the elapsed time since a stored timestamp using hardware counters, updates cached timing values, and returns the current computed clock interval.",
            "score": [
                0.3666666666666667,
                0.5,
                0.0
            ],
            "reason": [
                "The summary incorrectly states that the function computes elapsed time since a stored timestamp and returns the current computed clock interval. While the source code does use hardware counters (TSC and either HPET or PMTimer) to calculate frequency and update tsc_khz, it does not explicitly return a clock interval. The function primarily refines calibration, checks stability, schedules work, and registers the clocksource. The reference to returning a computed interval is a hallucination, reducing accuracy to less than half of the details.",
                "The summary claims computation of elapsed time since a stored timestamp using hardware counters and returning a current clock interval. While the source code does compute a delta between two hardware-based readings (tsc_start and tsc_stop) and updates a cached frequency (tsc_khz), it does not explicitly return a computed clock interval. The summary omits important control flow, such as multiple early exits (goto out), handling of unstable TSC conditions, and selection between HPET and PMTimer calculations. These omissions mean the accurate portion covers only part of the main logic, missing significant edge handling and registration steps.",
                "The summary claims that the function computes elapsed time since a stored timestamp using hardware counters, updates cached timing values, and returns the current computed clock interval. While the source code does calculate a delta between tsc_stop and tsc_start using hardware references (hpet/pmtimer) and updates tsc_khz (a cached timing value), there is no return value at all, making the 'returns the current computed clock interval' claim inaccurate. The accurate parts\u2014hardware counter use, cached timing update\u2014are present but described generically, lacking specifics about the conditional checks and calibration refinement logic. Only one of the three major claims is fully correct, one is partially correct, and one is false, so inaccurate details exceed 50%."
            ]
        }
    }
}
{
    "source_code": "\nstatic int pci_pm_poweroff(struct device *dev)\n{\n\tstruct pci_dev *pci_dev = to_pci_dev(dev);\n\tconst struct dev_pm_ops *pm = dev->driver ? dev->driver->pm : NULL;\n\n\tif (pci_has_legacy_pm_support(pci_dev))\n\t\treturn pci_legacy_suspend(dev, PMSG_HIBERNATE);\n\n\tif (!pm) {\n\t\tpci_pm_default_suspend(pci_dev);\n\t\tgoto Fixup;\n\t}\n\n\tpci_dev->state_saved = false;\n\tif (pm->poweroff) {\n\t\tint error;\n\n\t\terror = pm->poweroff(dev);\n\t\tsuspend_report_result(pm->poweroff, error);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n Fixup:\n\tpci_fixup_device(pci_fixup_suspend, pci_dev);\n\n\treturn 0;\n}",
    "comment": "Handles the power-off process for PCI devices, utilizing legacy support or device-specific power management operations, and fixes up device state afterward.",
    "prorec_sum": "Handles PCI device power management by checking conditions and invoking callbacks, performing power-off sequences when necessary.",
    "filter_prorec_sum": "Handles PCI device power management by checking link conditions, invoking callbacks, and powering off the device when specific criteria are met.",
    "prorec_aug_sum": "Checks PCI device state, attempts hardware initialization or power-off, and invokes recovery or shutdown procedures based on evaluation results.",
    "filter_prorec_aug_sum": "Handles PCI device power management, invoking initialization or poweroff routines based on hardware checks and driver-provided callbacks.",
    "work_score": {
        "prorec": {
            "summary": "Handles PCI device power management by checking conditions and invoking callbacks, performing power-off sequences when necessary.",
            "score": [
                0.7333333333333334,
                0.6,
                0.5333333333333333
            ],
            "reason": [
                "The summary captures the general purpose of the function as handling PCI device power management and invoking callbacks for power-off sequences, which is accurate given that the code checks for legacy PM support, calls `pm->poweroff` if present, and applies fixups. However, the description is high-level and omits specific logic details such as the call to `pci_legacy_suspend`, handling of `pm` being NULL, the setting of `state_saved` to false, and execution of `pci_fixup_device`. Since it accurately reflects only a portion of the function\u2019s concrete behavior without introducing false specifics, the proportion of accurate details is moderate.",
                "The summary correctly notes that the function handles PCI device power management and performs power-off sequences using callbacks when certain conditions are met. These details are supported by the source code, which checks legacy PM support, invokes pm->poweroff if available, and uses pci_pm_default_suspend otherwise. However, the summary omits significant specifics such as the legacy suspend path, state_saved reset, error handling, and fixup logic. This missing detail means the coverage of the core logic is incomplete.",
                "The summary correctly notes that the function manages PCI device power by checking conditions and invoking callbacks, which is directly supported by evidence in the code through checks like pci_has_legacy_pm_support, pm presence, and calls to poweroff sequences and fixup functions. However, the details are generic and omit specific domain-rich elements such as legacy PM handling, the use of pci_pm_default_suspend, and the final pci_fixup_device call. All stated details are accurate but lack granular technical insight, making the value moderate rather than high."
            ]
        },
        "filter_prorec": {
            "summary": "Handles PCI device power management by checking link conditions, invoking callbacks, and powering off the device when specific criteria are met.",
            "score": [
                0.39999999999999997,
                0.43333333333333335,
                0.0
            ],
            "reason": [
                "The summary claims that the code checks link conditions, but there is no evidence of link-related logic in the source code. While the code does handle PCI device power management and invokes driver callbacks when available, it does not explicitly mention powering off based on link conditions. This introduces an unverified assumption, making only part of the summary accurate.",
                "The summary vaguely describes PCI power management but introduces an inaccurate detail about 'checking link conditions,' which is not supported by the source code. The code checks for legacy PM support, handles the absence of driver PM ops, invokes a 'poweroff' callback if present, and performs fixups. After discarding the inaccurate link condition, the remaining details do not fully capture the control flow, error handling, or specific function calls, so coverage of the core logic is incomplete.",
                "The summary claims that the code checks link conditions, but there is no evidence in the source code of any link-related checks. The code focuses on PCI device power management using legacy PM support checks, driver PM callbacks, and fixup routines. While 'invoking callbacks' and 'powering off the device when criteria are met' are accurate, the inclusion of the incorrect 'link conditions' detail pushes the proportion of inaccurate details over 50%, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "static void drm_cleanup_buf_error(struct drm_device * dev,\n\t\t\t\t  struct drm_buf_entry * entry)\n{\n\tint i;\n\n\tif (entry->seg_count) {\n\t\tfor (i = 0; i < entry->seg_count; i++) {\n\t\t\tif (entry->seglist[i]) {\n\t\t\t\tdrm_pci_free(dev, entry->seglist[i]);\n\t\t\t}\n\t\t}\n\t\tkfree(entry->seglist);\n\n\t\tentry->seg_count = 0;\n\t}\n\n\tif (entry->buf_count) {\n\t\tfor (i = 0; i < entry->buf_count; i++) {\n\t\t\tkfree(entry->buflist[i].dev_private);\n\t\t}\n\t\tkfree(entry->buflist);\n\n\t\tentry->buf_count = 0;\n\t}\n}",
    "comment": "Cleans up allocated buffer memory and frees associated resources in a DRM device's buffer entry structure.",
    "prorec_sum": "Traverses and processes two indexed lists from the structure at `a2` using `sub_FFFFFFFF8112DCD0`, resets their counters, and optionally invokes `sub_FFFFFFFF8137CAD0` on non-null elements.",
    "filter_prorec_sum": "Processes and clears two indexed lists from the given structure, invoking a callback on each referenced element with provided parameters.",
    "prorec_aug_sum": "Processes and resets queued and secondary items for a given structure by invoking a callback on each entry with provided parameters.",
    "filter_prorec_aug_sum": "Processes and resets queued and active items in a structure by invoking a handler on each entry with provided parameters.",
    "work_score": {
        "prorec": {
            "summary": "Traverses and processes two indexed lists from the structure at `a2` using `sub_FFFFFFFF8112DCD0`, resets their counters, and optionally invokes `sub_FFFFFFFF8137CAD0` on non-null elements.",
            "score": [
                0.39999999999999997,
                0.0,
                0.0
            ],
            "reason": [
                "The summary's mention of `a2` instead of the actual parameters `dev` and `entry` is inaccurate, and both functions `sub_FFFFFFFF8112DCD0` and `sub_FFFFFFFF8137CAD0` are absent from the source code, indicating hallucination. While it correctly notes traversal of two indexed lists and resetting counters, it misrepresents function names and fails to match the actual calls (`drm_pci_free`, `kfree`). Only a small portion of the described logic is explicitly supported by the source code.",
                "The summary's claims about structure at `a2`, functions `sub_FFFFFFFF8112DCD0` and `sub_FFFFFFFF8137CAD0` are not supported by the source code. The code operates on `entry->seglist` and `entry->buflist` within `drm_cleanup_buf_error`, calling `drm_pci_free` and `kfree`, not the functions mentioned in the summary. After filtering out these inaccuracies, no accurate details remain that reflect the actual control flow and memory cleanup present in the source.",
                "The summary mentions processing lists from structure `a2` with functions `sub_FFFFFFFF8112DCD0` and `sub_FFFFFFFF8137CAD0`, but these function names do not appear in the source code, which instead calls `drm_pci_free` and `kfree`. It also uses `dev` and `entry` parameters, not `a2`. While the summary notes traversing two indexed lists and resetting counters \u2014 which matches the loops over `seglist` and `buflist` and setting `seg_count` and `buf_count` to 0 \u2014 the majority of details (function names, parameter names, optional invocation specifics) are inaccurate. Inaccurate details exceed 50%, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Processes and clears two indexed lists from the given structure, invoking a callback on each referenced element with provided parameters.",
            "score": [
                0.3666666666666667,
                0.43333333333333335,
                0.0
            ],
            "reason": [
                "The summary claims that the function invokes a callback on each referenced element with provided parameters, which is inaccurate; the source code explicitly shows memory deallocation via drm_pci_free and kfree rather than any callback invocation. While it correctly notes that two indexed lists from the structure are processed and cleared, the callback detail is a hallucination. With only one accurate detail out of two, the accuracy ratio is 50%, placing it in the low-mixed accuracy range.",
                "The summary incorrectly describes invoking a callback on each element with provided parameters, which is not evidenced in the source code. The code instead frees memory for each element in two lists (seglist and buflist) using drm_pci_free or kfree, and resets the associated counts. After discarding inaccuracies, the remaining accurate detail is simply that the function processes and clears two indexed lists, but this alone misses critical specifics such as the memory freeing logic and conditional checks, leading to an incomplete picture.",
                "The summary incorrectly claims that a callback is invoked on each element with provided parameters, but the source code shows direct calls to `drm_pci_free` and `kfree` rather than any generic callback mechanism. While it is true that two indexed lists are processed and cleared (`seglist` and `buflist`), the main functional description in the summary is inaccurate. Given that more than half of the semantic details are incorrect, the evaluation stops at the kill switch."
            ]
        }
    }
}
{
    "source_code": "int Xorriso_register_node_target(struct XorrisO *xorriso, int node_idx,\n                                 char *disk_path, int flag)\n{\n int l;\n\n if(xorriso->node_targets_availmem == 0)\n   return(2);\n if(xorriso->hln_targets == NULL || node_idx < 0 ||\n    node_idx >= xorriso->hln_count)\n   return(0);\n if(xorriso->hln_targets[node_idx] != NULL) {\n   xorriso->node_targets_availmem+= strlen(xorriso->hln_targets[node_idx]) +1;\n   free(xorriso->hln_targets[node_idx]);\n }\n l= strlen(disk_path);\n if(xorriso->node_targets_availmem <= l + 1) {\n   sprintf(xorriso->info_text,\n \"Hardlink target buffer exceeds -temp_mem_limit. Hardlinks may get divided.\");\n   Xorriso_msgs_submit(xorriso, 0, xorriso->info_text, 0, \"FAILURE\", 0);\n   xorriso->node_targets_availmem= 0;\n   return(0);\n }\n xorriso->hln_targets[node_idx]= strdup(disk_path);\n if(xorriso->hln_targets[node_idx] == NULL) {\n   Xorriso_no_malloc_memory(xorriso, NULL, 0);\n   return(-1);\n }\n xorriso->node_targets_availmem-= (l + 1);\n return(1);\n}",
    "comment": "Registers a hardlink target for a specified node index in the Xorriso structure, managing memory and error handling accordingly.",
    "prorec_sum": "Updates a specified path component in an ISO9660 file structure, adjusting available space, duplicating the new string, and handling overflow or allocation failures.",
    "filter_prorec_sum": "Updates a specific path component string in an ISO9660 file structure, freeing the old value, checking size limits, and handling errors if allocation fails.",
    "prorec_aug_sum": "Replaces an indexed string in an internal array with a new value, enforcing length limits, freeing old memory, and updating remaining capacity.",
    "filter_prorec_aug_sum": "Updates a string entry in an indexed array, adjusting available buffer space and reporting failure if the new string exceeds the remaining capacity.",
    "work_score": {
        "prorec": {
            "summary": "Updates a specified path component in an ISO9660 file structure, adjusting available space, duplicating the new string, and handling overflow or allocation failures.",
            "score": [
                0.5333333333333333,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims the function updates a path component in an ISO9660 file structure, but there is no explicit mention of ISO9660 in the source code, making this a hallucination. While it correctly notes adjusting available space, duplicating a string, and handling overflow or allocation failures\u2014details all supported by logic in the function\u2014it misattributes the context to ISO9660 rather than the actual hardlink target management. Out of roughly four semantic details, three are accurate and one is inaccurate, resulting in a mixed accuracy ratio.",
                "The summary is inaccurate because it claims the function updates a path component in an ISO9660 file structure, which is not explicitly supported by the source code. The code instead registers a hardlink target in `xorriso->hln_targets`, manages `node_targets_availmem`, duplicates the given disk path, and handles memory overflow or allocation failures. While overflow and allocation error handling are correctly mentioned, the ISO9660 and path component update details are hallucinated, leaving only partial alignment with the actual logic.",
                "The summary inaccurately claims modification of an ISO9660 file structure and updating a path component, which is not evidenced in the source code. The function deals with registering hardlink targets by managing available memory, duplicating strings, and handling overflow or allocation failures; while the space adjustment, duplication, and failure handling parts are accurate, the ISO9660 reference and path component update are unsupported. Since more than half of the details are inaccurate, this triggers the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Updates a specific path component string in an ISO9660 file structure, freeing the old value, checking size limits, and handling errors if allocation fails.",
            "score": [
                0.39999999999999997,
                0.5,
                0.0
            ],
            "reason": [
                "The summary incorrectly claims that the function updates a path component string in an ISO9660 file structure, which is not explicitly supported by the source code. The code operates on 'hln_targets' in a 'XorrisO' struct, managing hardlink target strings and memory limits, but there is no mention of ISO9660 or path components in an ISO9660 file structure. While it accurately notes freeing old values, checking size limits, and handling allocation failures, most of the described context about ISO9660 is a hallucination. This results in less than half of the details being accurate.",
                "The summary inaccurately describes the function as operating on an ISO9660 file structure, which is not supported by explicit evidence in the source code. While it correctly notes freeing the old value, checking size limits, and handling allocation errors, these details are generalized and omit specific elements such as the node_targets_availmem updates, specific return values for different conditions, and the logging of failure messages. The retained accurate details only partially cover the main logic, missing critical control flow and data handling steps.",
                "The summary claims the function updates a path component in an ISO9660 file structure, but there is no evidence in the source code of ISO9660-specific handling or file structure manipulation; the function manages hardlink target strings within the xorriso context. While freeing the old value, checking a memory limit, and handling allocation errors are accurately described, the central claim about ISO9660 path components is inaccurate. Over 50% of the semantic details are incorrect, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic const char *\nget_symbol_index_type (Filedata * filedata, unsigned int type)\n{\n  static char buff[32];\n\n  switch (type)\n    {\n    case SHN_UNDEF:\treturn \"UND\";\n    case SHN_ABS:\treturn \"ABS\";\n    case SHN_COMMON:\treturn \"COM\";\n    default:\n      if (type == SHN_IA_64_ANSI_COMMON\n\t  && filedata->file_header.e_machine == EM_IA_64\n\t  && filedata->file_header.e_ident[EI_OSABI] == ELFOSABI_HPUX)\n\treturn \"ANSI_COM\";\n      else if ((filedata->file_header.e_machine == EM_X86_64\n\t\t|| filedata->file_header.e_machine == EM_L1OM\n\t\t|| filedata->file_header.e_machine == EM_K1OM)\n\t       && type == SHN_X86_64_LCOMMON)\n\treturn \"LARGE_COM\";\n      else if ((type == SHN_MIPS_SCOMMON\n\t\t&& filedata->file_header.e_machine == EM_MIPS)\n\t       || (type == SHN_TIC6X_SCOMMON\n\t\t   && filedata->file_header.e_machine == EM_TI_C6000))\n\treturn \"SCOM\";\n      else if (type == SHN_MIPS_SUNDEFINED\n\t       && filedata->file_header.e_machine == EM_MIPS)\n\treturn \"SUND\";\n      else if (type >= SHN_LOPROC && type <= SHN_HIPROC)\n\tsprintf (buff, \"PRC[0x%04x]\", type & 0xffff);\n      else if (type >= SHN_LOOS && type <= SHN_HIOS)\n\tsprintf (buff, \"OS [0x%04x]\", type & 0xffff);\n      else if (type >= SHN_LORESERVE)\n\tsprintf (buff, \"RSV[0x%04x]\", type & 0xffff);\n      else if (type >= filedata->file_header.e_shnum)\n\tsprintf (buff, _(\"bad section index[%3d]\"), type);\n      else\n\tsprintf (buff, \"%3d\", type);\n      break;\n    }\n\n  return buff;\n}",
    "comment": "Returns a string representation of a symbol index type based on the provided type and file header information.",
    "prorec_sum": "Maps special numeric codes and object attributes to descriptive section type strings or formatted labels for display.",
    "filter_prorec_sum": "Maps a numeric section type code and related header fields to a corresponding descriptive string or formatted code representation for display.",
    "prorec_aug_sum": "Converts a section index and related header fields into a descriptive string label or formatted code based on predefined type mappings and value ranges.",
    "filter_prorec_aug_sum": "Maps special negative and small section index values to descriptive strings or formats them into labeled codes for display.",
    "work_score": {
        "prorec": {
            "summary": "Maps special numeric codes and object attributes to descriptive section type strings or formatted labels for display.",
            "score": [
                0.7333333333333334,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly captures the general behavior of mapping numeric codes and object attributes to descriptive strings, which aligns with the source code's switch cases and conditional logic that format section type labels. However, it lacks specific details about constants, machine types, and explicit string outputs found in the code, so while the essence is correct, the detail accuracy is low due to omission. The accurate portion is the generic mapping logic, but missing explicit references reduces completeness.",
                "The summary accurately captures the general purpose of the function\u2014mapping numeric codes and object attributes to human-readable strings or formatted labels for display\u2014based on the source code. However, it lacks specific details present in the code, such as handling of special constants (e.g., SHN_UNDEF, SHN_ABS), machine-type checks, and various sprintf formats, meaning it does not present a complete picture of the logic or edge cases.",
                "The summary accurately notes that the function maps numeric codes and object attributes to descriptive strings or formatted labels, which is evident in the switch cases and conditional checks returning predefined strings like 'UND', 'ABS', and formatted values using sprintf. However, it omits specific domain-rich details such as the handling of certain constants (SHN_IA_64_ANSI_COMMON, SHN_X86_64_LCOMMON, SHN_MIPS_SCOMMON, etc.) and OS/machine type checks, making the description generic rather than highly detailed."
            ]
        },
        "filter_prorec": {
            "summary": "Maps a numeric section type code and related header fields to a corresponding descriptive string or formatted code representation for display.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary accurately captures the main functionality of the function: it takes a numeric section type code along with header fields and maps them to descriptive or formatted strings for output. This is directly evidenced by the switch cases and conditional checks against the section type and file header fields in the source code. No unverified assumptions or hallucinations are present.",
                "The summary accurately identifies that the function converts a numeric section type code and some header information into a corresponding string or formatted representation for display. This aligns with the switch cases and conditional checks that map various 'type' values and 'file_header' fields to specific strings or formatted output. However, it omits mention of specific mappings, detailed conditions, and edge cases handled in the code, such as special architecture-specific codes, numeric bounds, and formatted output for out-of-range values, meaning the coverage is incomplete.",
                "The summary correctly describes the general purpose of mapping a numeric section type and related header fields to a descriptive string or formatted code, which matches the switch cases in the source code. However, it does not mention any specific constants, machine types, or conditional logic from the function, making the accurate details generic rather than domain-rich."
            ]
        }
    }
}
{
    "source_code": "\nvoid *\nFcompile (char *pattern, idx_t size, reg_syntax_t ignored, bool exact)\n{\n  kwset_t kwset;\n  char *buf = NULL;\n  idx_t bufalloc = 0;\n\n  kwset = kwsinit (true);\n\n  char const *p = pattern;\n  do\n    {\n      char const *sep = rawmemchr (p, '\\n');\n      idx_t len = sep - p;\n\n      if (match_lines)\n        {\n          if (eolbyte == '\\n' && pattern < p)\n            p--;\n          else\n            {\n              if (bufalloc < len + 2)\n                {\n                  free (buf);\n                  bufalloc = len;\n                  buf = xpalloc (NULL, &bufalloc, 2, -1, 1);\n                  buf[0] = eolbyte;\n                }\n              memcpy (buf + 1, p, len);\n              buf[len + 1] = eolbyte;\n              p = buf;\n            }\n          len += 2;\n        }\n      kwsincr (kwset, p, len);\n\n      p = sep + 1;\n    }\n  while (p <= pattern + size);\n\n  free (buf);\n\n  idx_t words = kwswords (kwset);\n  kwsprep (kwset);\n\n  struct kwsearch *kwsearch = xmalloc (sizeof *kwsearch);\n  kwsearch->kwset = kwset;\n  kwsearch->words = words;\n  kwsearch->pattern = pattern;\n  kwsearch->size = size;\n  kwsearch->re = NULL;\n  return kwsearch;\n}",
    "comment": "Processes a pattern string, initializes a keyword set, and returns a structure containing the keyword set and its associated properties.",
    "prorec_sum": "Processes input data line-by-line, conditionally transforms line endings, stores chunks in an obstack, and returns a structured collection of accumulated results.",
    "filter_prorec_sum": "Processes newline-delimited data from two obstack buffers, optionally inserting a delimiter byte, and returns a composite structure containing processed and original buffers.",
    "prorec_aug_sum": "Processes a memory block line-by-line, optionally inserting a configured byte after each line, and assembles the processed data into a new obstack structure.",
    "filter_prorec_aug_sum": "Processes a memory block line-by-line, conditionally modifies line endings, accumulates lines in an obstack, and returns a structured result with processing metadata.",
    "work_score": {
        "prorec": {
            "summary": "Processes input data line-by-line, conditionally transforms line endings, stores chunks in an obstack, and returns a structured collection of accumulated results.",
            "score": [
                0.26666666666666666,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary misrepresents important aspects of the code. While it correctly notes line-by-line processing and conditional transformation of line endings, it inaccurately states that chunks are stored in an obstack\u2014there is no use of obstack in the source code, only dynamic allocation via xpalloc and xmalloc. It also incorrectly describes the return value as a 'structured collection of accumulated results'; the function returns a struct kwsearch containing compiled keyword set data rather than a generic accumulated collection. With more than half of the details unsupported by explicit evidence, accuracy is low.",
                "The summary contains multiple inaccurate details: it mentions storing chunks in an obstack and returning a structured collection of accumulated results, which are not present in the source code. The code instead uses dynamic allocation with xpalloc, processes the pattern string line-by-line, conditionally modifies line endings based on match_lines and eolbyte, and stores data in a kwset_t structure before wrapping it in a kwsearch struct. After removing inaccuracies, only the general line-by-line processing and conditional line-ending transformation remain, which omits key details such as kwset initialization, memory management, and preparation steps.",
                "The summary contains multiple inaccuracies: it claims storage in an obstack, which is not present in the source code (the code uses dynamic allocation via xpalloc and xmalloc). It also describes returning a structured collection of accumulated results, but the return value is a kwsearch struct with specific fields, not a generic collection. While the code does process input line-by-line and conditionally transform line endings (accurate), more than half of the described details are hallucinated, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Processes newline-delimited data from two obstack buffers, optionally inserting a delimiter byte, and returns a composite structure containing processed and original buffers.",
            "score": [
                0.10000000000000002,
                0.10000000000000002,
                0.0
            ],
            "reason": [
                "The summary claims the function processes newline-delimited data from two obstack buffers and returns a composite structure with processed and original buffers. The source code shows no use of obstack buffers\u2014only a single char pointer `pattern`, dynamic allocation via `xpalloc` and `xmalloc`, and a kwsearch structure containing pointers to the pattern and size. There is no explicit evidence of two buffers or obstack usage, and the return is not described as containing both processed and original buffers. The only partially accurate detail is processing newline-delimited data, which occurs via `rawmemchr` and loop logic, but most claims are hallucinations.",
                "The summary mentions processing data from two obstack buffers and returning a composite structure containing processed and original buffers, but there is no evidence in the source code of any obstack usage or composite structures containing buffers. The code processes a single pattern string, splits by newline, optionally inserts an eolbyte, and builds a kwset structure. These core logic elements are absent from the summary, leaving no accurate details after filtering.",
                "The summary claims the function processes data from two obstack buffers, inserts a delimiter byte, and returns a composite structure with processed and original buffers. However, the source code shows it processes a single char* pattern, uses kwset functions, allocates a temporary buffer with xpalloc under certain conditions, and returns a kwsearch struct. There is no explicit evidence of obstack buffers, nor composite structures containing both processed and original buffers. Over 50% of the details, including the obstack usage and composite structure claim, are inaccurate."
            ]
        }
    }
}
{
    "source_code": "bool pm_wakeup_pending(void)\n{\n\tunsigned long flags;\n\tbool ret = false;\n\n\tspin_lock_irqsave(&events_lock, flags);\n\tif (events_check_enabled) {\n\t\tunsigned int cnt, inpr;\n\n\t\tsplit_counters(&cnt, &inpr);\n\t\tret = (cnt != saved_count || inpr > 0);\n\t\tevents_check_enabled = !ret;\n\t}\n\tspin_unlock_irqrestore(&events_lock, flags);\n\n\tif (ret)\n\t\tprint_active_wakeup_sources();\n\n\treturn ret;\n}",
    "comment": "Checks if a wakeup event is pending by comparing counters and prints active wakeup sources if there is a pending event.",
    "prorec_sum": "Checks a global unlock state, updates it, and triggers specific handler calls based on flagged entries in a linked list of device structures.",
    "filter_prorec_sum": "Checks a global state flag, updates it, iterates device list, and triggers specific handler calls for matching or highest-priority non-matching device.",
    "prorec_aug_sum": "Checks a condition flag, iterates over registered objects to trigger actions on active ones, and selects the newest inactive object for fallback handling.",
    "filter_prorec_aug_sum": "Checks a global condition and, if state changes, iterates CPU-related structures to trigger specific handling for active or most recently active entries.",
    "work_score": {
        "prorec": {
            "summary": "Checks a global unlock state, updates it, and triggers specific handler calls based on flagged entries in a linked list of device structures.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary's claims about checking a global unlock state, handling flagged entries in a linked list of device structures, and triggering specific device-related handlers are not supported by the source code. The actual code locks `events_lock`, checks `events_check_enabled`, manipulates counters, and optionally calls `print_active_wakeup_sources()`. There is no evidence of a global unlock state variable, linked list traversal, or device structure handling. All details in the summary are hallucinations, resulting in no accurate matches.",
                "The summary claims the function checks a global unlock state, updates it, and works with a linked list of device structures, but the source code shows it locks with spin_lock_irqsave, checks a global flag (events_check_enabled), compares counter values, updates the flag, conditionally prints active wakeup sources, and returns a boolean. There is no evidence of a linked list or device structures, and the 'unlock state' mentioned in the summary is misleading. None of the specific claims match the actual code, so all details are inaccurate and no valid logic remains for evaluation.",
                "The summary claims checking a global unlock state, use of a linked list of device structures, and triggering handler calls based on flagged entries. None of these elements (linked lists, device structures, handler calls, global unlock state) are present in the source code. The source instead locks with spin_lock_irqsave, checks events_check_enabled, compares counters from split_counters, updates events_check_enabled, optionally calls print_active_wakeup_sources, and returns a boolean. All summary details are inaccurate, exceeding the inaccuracy threshold."
            ]
        },
        "filter_prorec": {
            "summary": "Checks a global state flag, updates it, iterates device list, and triggers specific handler calls for matching or highest-priority non-matching device.",
            "score": [
                0.20000000000000004,
                0.06666666666666667,
                0.0
            ],
            "reason": [
                "The summary includes several details not supported by the source code. The source code checks a global flag (`events_check_enabled`), updates it, uses spin locks, and calls `print_active_wakeup_sources()` if a condition is met. However, there is no iteration over a device list or triggering of handlers for matching or highest-priority devices in the code. Only the global flag check and update are accurate, while the majority of the described logic is hallucinated.",
                "The summary describes iterating over a device list and triggering specific handlers for devices, which is not present in the source code. The actual code checks a global flag, locks, runs split_counters, updates the flag, optionally prints active wakeup sources, and returns a boolean. None of the device list iteration or handler logic exists, leaving no accurate details after filtering.",
                "The summary claims iteration over a device list and triggering of specific handler calls based on matching or priority, none of which are present in the source code. The actual code checks a global flag, reads counters, updates the flag, and prints wakeup sources \u2014 there is no device list iteration or handler invocation logic. All major details in the summary are inaccurate, exceeding the threshold for termination."
            ]
        }
    }
}
{
    "source_code": "\nstruct local_symbol *\nlocal_symbol_make (const char *name, segT section, valueT val, fragS *frag)\n{\n  const char *name_copy;\n  struct local_symbol *ret;\n\n  ++local_symbol_count;\n\n  name_copy = save_symbol_name (name);\n\n  ret = (struct local_symbol *) obstack_alloc (&notes, sizeof *ret);\n  ret->lsy_flags.sy_local_symbol = 1;\n  ret->lsy_flags.sy_resolved = 0;\n  ret->lsy_name = name_copy;\n  ret->lsy_section = section;\n  local_symbol_set_frag (ret, frag);\n  ret->lsy_value = val;\n\n  hash_jam (local_hash, name_copy, (void *) ret);\n\n  return ret;\n}",
    "comment": "Creates and initializes a local symbol structure, copying its name, setting properties, and storing it in a hash table.",
    "prorec_sum": "Allocates space in a global obstack for a new object, sets its fields from the arguments, and registers it via a callback.",
    "filter_prorec_sum": "Allocates a 40-byte object in a global obstack, stores provided parameters and a string pointer into it, and registers it via sub_411620.",
    "prorec_aug_sum": "Allocates a 40-byte aligned object in an obstack, stores provided parameters into its fields, and registers it with a handler function.",
    "filter_prorec_aug_sum": "Allocates a 40\u2011byte aligned object in an obstack, stores provided parameters into its fields, and registers it via sub_411620.",
    "work_score": {
        "prorec": {
            "summary": "Allocates space in a global obstack for a new object, sets its fields from the arguments, and registers it via a callback.",
            "score": [
                0.6999999999999998,
                0.6,
                0.3333333333333333
            ],
            "reason": [
                "The summary correctly notes that the function allocates space in a global obstack and sets object fields from the arguments, both of which are explicitly present in the code via `obstack_alloc(&notes, ...)` and field assignments. However, the claim about registering via a callback is inaccurate: the code uses `hash_jam` to insert into a hash table, not a callback mechanism. This results in a mixed accuracy with at least one unverified assumption.",
                "The summary correctly notes allocation in a global obstack, assignment of fields from arguments, and registration via a function call, all of which are explicitly present in the source code through `obstack_alloc`, direct field assignments, and `hash_jam`. However, it omits mention of `save_symbol_name` for name handling, flag initializations, and the increment of `local_symbol_count`, which are significant parts of the function's logic, including setup and metadata handling. This means the accurate details cover the main actions but miss some important logic steps.",
                "The summary claims space is allocated in a global obstack, fields are set from arguments, and registration occurs via a callback. The source code shows allocation via obstack_alloc on 'notes' (global), and fields being populated from arguments (Accurate). However, there is no evidence of a 'callback' mechanism; registration is done via 'hash_jam', which is a direct function call, so this part is Inaccurate. With only 1 of 3 details inaccurate (<50%), the remaining accurate details are somewhat generic, describing allocation and field assignment without domain-rich specifics."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates a 40-byte object in a global obstack, stores provided parameters and a string pointer into it, and registers it via sub_411620.",
            "score": [
                0.3,
                0.30000000000000004,
                0.0
            ],
            "reason": [
                "The summary's claims about allocating a 40-byte object, using a global obstack, and registering via sub_411620 cannot be verified from the source code. The code allocates memory using obstack_alloc with sizeof *ret, but the size is not specified as 40 bytes in the source. The obstack variable &notes is present, but its global scope is not confirmed. The registration is done via hash_jam, not sub_411620. Overall, most details are unsupported, with only generic allocation in an obstack being accurate.",
                "The summary's claims about allocating a fixed 40-byte object, use of a global obstack, and registering via 'sub_411620' lack explicit support in the source code. The code shows allocation using 'obstack_alloc', use of 'notes' obstack, but no evidence of a fixed size of 40 bytes or the function 'sub_411620'. The only accurate detail is that parameters and a string pointer are stored in the allocated structure, but overall important actions like flag initialization, hash insertion, and specific allocation steps are missing from the summary.",
                "The summary claims a 40-byte allocation, use of a global obstack, and registration via sub_411620. The source code shows allocation using obstack_alloc on &notes, consistent with a global obstack, and storing provided parameters and a string pointer, so those details are accurate. However, the 40-byte size is not specified in the code, and sub_411620 does not appear anywhere, making these claims inaccurate. With 2 out of 4 details inaccurate, the proportion of inaccuracies exceeds 50%, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\ngss_pipe_release(struct inode *inode)\n{\n\tstruct net *net = inode->i_sb->s_fs_info;\n\tstruct rpc_pipe *pipe = RPC_I(inode)->pipe;\n\tstruct gss_upcall_msg *gss_msg;\n\nrestart:\n\tspin_lock(&pipe->lock);\n\tlist_for_each_entry(gss_msg, &pipe->in_downcall, list) {\n\n\t\tif (!list_empty(&gss_msg->msg.list))\n\t\t\tcontinue;\n\t\tgss_msg->msg.errno = -EPIPE;\n\t\tatomic_inc(&gss_msg->count);\n\t\t__gss_unhash_msg(gss_msg);\n\t\tspin_unlock(&pipe->lock);\n\t\tgss_release_msg(gss_msg);\n\t\tgoto restart;\n\t}\n\tspin_unlock(&pipe->lock);\n\n\tput_pipe_version(net);\n}",
    "comment": "Releases GSS upcall messages in a pipe by unhashing and incrementing the error count for empty message lists before freeing resources.",
    "prorec_sum": "Iterates over linked structures from a context pointer, updates fields, invokes two processing callbacks with provided doubles, then finalizes through another function call.",
    "filter_prorec_sum": "Iterates over and updates queue entries, invoking two processing callbacks for each, then finalizes by calling a completion routine.",
    "prorec_aug_sum": "Iterates over and updates queue entries with provided parameters, invoking two processing callbacks before returning a final service-related result.",
    "filter_prorec_aug_sum": "Iterates over and updates linked objects from a1, invoking two processing callbacks with given double parameters, then finalizes by calling a completion routine.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over linked structures from a context pointer, updates fields, invokes two processing callbacks with provided doubles, then finalizes through another function call.",
            "score": [
                0.3,
                0.16666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims iteration over linked structures from a context pointer, updates fields, invokes two processing callbacks with provided doubles, and finalizes through another function call. While the source code does iterate through a linked list and update a field, there is no evidence of processing callbacks being invoked with doubles\u2014the functions called are __gss_unhash_msg, gss_release_msg, and put_pipe_version, none of which involve double-typed arguments. The 'context pointer' description is vague compared to explicit structures in code, and much of the claimed logic is absent, making most details inaccurate.",
                "The summary's claims about processing callbacks with doubles and finalizing through another function do not match any explicit evidence in the source code. The code instead locks a pipe structure, iterates over a list of gss_upcall_msg objects, updates an errno field, increments an atomic counter, unhashes and releases messages, and calls put_pipe_version. No double data types or generic processing callbacks are present, so all summary details are inaccurate and no core logic is captured.",
                "The summary's claims about iterating over linked structures are partially aligned with the source code, which loops through a linked list via list_for_each_entry. However, it inaccurately describes updating fields with provided doubles and invoking two processing callbacks, which are not present. The code updates an integer errno with -EPIPE, increments a counter, and calls __gss_unhash_msg and gss_release_msg, but none of these match the summary\u2019s stated callbacks or data type usage. More than half of the described details are hallucinations, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates over and updates queue entries, invoking two processing callbacks for each, then finalizes by calling a completion routine.",
            "score": [
                0.3,
                0.2333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims two processing callbacks are invoked for each queue entry and that a completion routine is called at the end. In the source code, only certain entries without a non-empty msg.list are processed, and only two specific functions (__gss_unhash_msg and gss_release_msg) are called\u2014these are not clearly described as 'two processing callbacks for each'. The 'completion routine' mention is inaccurate because the final call is put_pipe_version, which is not described in the summary. Overall, most details in the summary are either inaccurate or unverified against the code.",
                "The summary claims two processing callbacks invoked for each queue entry and a final completion routine, but the source code shows a loop over in_downcall entries with specific conditions, modifying errno, incrementing a counter, unhashing, unlocking and releasing messages, then calling put_pipe_version once. There is no explicit evidence of two distinct callbacks per entry or a generic completion routine as described; thus most details are inaccurate and the core logic is missed.",
                "The summary claims two processing callbacks and a completion routine are invoked for each queue entry, but the source code explicitly shows only specific calls to '__gss_unhash_msg' and 'gss_release_msg' in certain conditions, not a generic per-entry double callback pattern. The iteration is conditional and restarts, and 'put_pipe_version' is called once after loop completion, not per entry. These mismatches result in most details being inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "void FAST_FUNC add_to_ino_dev_hashtable(const struct stat *statbuf, const char *name)\n{\n\tint i;\n\tino_dev_hashtable_bucket_t *bucket;\n\n\tif (!name)\n\t\tname = \"\";\n\tbucket = xmalloc(sizeof(ino_dev_hashtable_bucket_t) + strlen(name));\n\tbucket->ino = statbuf->st_ino;\n\tbucket->dev = statbuf->st_dev;\n\tbucket->isdir = !!S_ISDIR(statbuf->st_mode);\n\tstrcpy(bucket->name, name);\n\n\tif (!ino_dev_hashtable)\n\t\tino_dev_hashtable = xzalloc(HASH_SIZE * sizeof(*ino_dev_hashtable));\n\n\ti = hash_inode(statbuf->st_ino);\n\tbucket->next = ino_dev_hashtable[i];\n\tino_dev_hashtable[i] = bucket;\n}",
    "comment": "Adds a new entry to the inode-device hashtable using the provided stat structure and name, allocating memory for the bucket dynamically.",
    "prorec_sum": "Creates and links a new entry structure for the given path, handling defaults and inserting it into a hash table keyed by its identifier.",
    "filter_prorec_sum": "Links a newly created entry into a hash-based structure, assigning metadata and copying identifier data from the provided parameters.",
    "prorec_aug_sum": "Initializes a new structure from provided parameters, links it into a hash table keyed by an identifier, and copies metadata from the source object.",
    "filter_prorec_aug_sum": "Creates and links a new structure for the given identifier, initializing fields from input parameters and inserting it into a global hash table.",
    "work_score": {
        "prorec": {
            "summary": "Creates and links a new entry structure for the given path, handling defaults and inserting it into a hash table keyed by its identifier.",
            "score": [
                0.8000000000000002,
                0.6,
                0.5
            ],
            "reason": [
                "The summary correctly identifies that a new entry structure is created and inserted into a hash table, which is supported by the allocation of 'bucket', assignment of its fields, and linking into 'ino_dev_hashtable'. However, the summary mentions 'given path' and 'keyed by its identifier' without specifying actual evidence from the code\u2014'name' is used, not a path, and the hash key is based on the inode number, not a generic identifier. This adds minor inaccuracy but the core description aligns with the implementation.",
                "The summary correctly captures that the code creates a new structure, sets its fields based on the given parameters, applies a default for a missing name, and inserts it into a hash table keyed by an identifier. These align with the source code\u2019s allocation of a bucket, field assignments, default empty string for null names, and insertion logic using a hash of the inode. However, the summary omits specific details such as the exact fields set (inode, device, isdir), the hash computation function used, and the initialization of the hash table when null, which means some critical logic is missing.",
                "The summary omits key explicit details from the source code such as use of `struct stat` fields (`st_ino`, `st_dev`, `st_mode`), bucket allocation with extra space for `name`, and initialization of `ino_dev_hashtable` via `xzalloc`. While it correctly conveys that a new entry is created and inserted into a hash table, it inaccurately generalizes 'keyed by its identifier' without specifying inode hashing and ignores directory detection logic. The accurate part is generic and lacks domain-rich specificity."
            ]
        },
        "filter_prorec": {
            "summary": "Links a newly created entry into a hash-based structure, assigning metadata and copying identifier data from the provided parameters.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly describes linking a newly created entry into a hash-based structure and assigning metadata from provided parameters, which is evidenced by the allocation of 'bucket', setting inode, device, and directory flag, copying the name, and inserting into 'ino_dev_hashtable'. These points match the source code with no apparent hallucinations, making the description accurate.",
                "The summary accurately describes the main logic of inserting a newly allocated bucket into a hash table, including assigning metadata from parameters and copying identifier data. These details are explicitly supported by the source code through field assignments from statbuf, copying the name, and linking into the hash table. However, it omits notable aspects such as defaulting to an empty string when name is NULL, allocation of the hash table if not already present, and calculation of the bucket index via hash_inode, meaning it does not fully cover all core logic and edge cases.",
                "The summary correctly describes that a new entry is linked into a hash-based structure and initialized with metadata from parameters, matching the code's behavior of creating a bucket, setting fields from 'statbuf', copying the name, and linking into 'ino_dev_hashtable'. While accurate, the description is generic and omits specific details such as the use of 'st_ino', 'st_dev', the directory flag logic, and allocation functions, reducing domain richness."
            ]
        }
    }
}
{
    "source_code": "int loadkmap_main(int argc UNUSED_PARAM, char **argv)\n{\n\tstruct kbentry ke;\n\tint i, j, fd;\n\tuint16_t ibuff[NR_KEYS];\n/*\tconst char *tty_name = CURRENT_TTY; */\n\tRESERVE_CONFIG_BUFFER(flags, MAX_NR_KEYMAPS);\n\n\t/* When user accidentally runs \"loadkmap FILE\"\n\t * instead of \"loadkmap <FILE\", we end up waiting for input from tty.\n\t * Let's prevent it: */\n\tif (argv[1])\n\t\tbb_show_usage();\n/* bb_warn_ignoring_args(argv[1]); */\n\n\tfd = get_console_fd_or_die();\n/* or maybe:\n\topt = getopt32(argv, \"C:\", &tty_name);\n\tfd = xopen_nonblocking(tty_name);\n*/\n\n\txread(STDIN_FILENO, flags, 7);\n\tif (!is_prefixed_with(flags, BINARY_KEYMAP_MAGIC))\n\t\tbb_error_msg_and_die(\"not a valid binary keymap\");\n\n\txread(STDIN_FILENO, flags, MAX_NR_KEYMAPS);\n\n\tfor (i = 0; i < MAX_NR_KEYMAPS; i++) {\n\t\tif (flags[i] != 1)\n\t\t\tcontinue;\n\t\txread(STDIN_FILENO, ibuff, NR_KEYS * sizeof(uint16_t));\n\t\tfor (j = 0; j < NR_KEYS; j++) {\n\t\t\tke.kb_index = j;\n\t\t\tke.kb_table = i;\n\t\t\tke.kb_value = ibuff[j];\n\t\t\t/*\n\t\t\t * Note: table[idx:0] can contain special value\n\t\t\t * K_ALLOCATED (marks allocated tables in kernel).\n\t\t\t * dumpkmap saves the value as-is; but attempts\n\t\t\t * to load it here fail, since it isn't a valid\n\t\t\t * key value: it is K(KT_SPEC,126) == 2<<8 + 126,\n\t\t\t * whereas last valid KT_SPEC is\n\t\t\t * K_BARENUMLOCK == K(KT_SPEC,19).\n\t\t\t * So far we just ignore these errors:\n\t\t\t */\n\t\t\tioctl(fd, KDSKBENT, &ke);\n\t\t}\n\t}\n\n\tif (ENABLE_FEATURE_CLEAN_UP) {\n\t\tclose(fd);\n\t\tRELEASE_CONFIG_BUFFER(flags);\n\t}\n\treturn EXIT_SUCCESS;\n}",
    "comment": "Loads a binary keymap from standard input and updates the keyboard mapping using ioctl calls for each valid keymap.",
    "prorec_sum": "Processes a binary keymap file, validates its header, and registers keycode mappings for all active keys across 256 possible entries.",
    "filter_prorec_sum": "Processes and validates a binary keymap file, then registers each mapped key code pair using a specific device command identifier.",
    "prorec_aug_sum": "Parses and validates a binary keymap file, then iterates entries to send keycode mappings using the provided identifier.",
    "filter_prorec_aug_sum": "Processes a binary keymap file, validates its header, and dispatches keycode mappings for each defined entry to the appropriate handler.",
    "work_score": {
        "prorec": {
            "summary": "Processes a binary keymap file, validates its header, and registers keycode mappings for all active keys across 256 possible entries.",
            "score": [
                0.7666666666666666,
                0.6999999999999998,
                0.7666666666666666
            ],
            "reason": [
                "The summary correctly notes that the code processes a binary keymap file, validates its header, and registers key mappings for active keys. However, it inaccurately specifies '256 possible entries'\u2014the source code uses MAX_NR_KEYMAPS, whose value is not shown, so this number is unverified. While most details are supported by function calls like xread, is_prefixed_with, and ioctl, the explicit numeric claim is a hallucination, lowering accuracy.",
                "The summary correctly identifies that the code processes a binary keymap, validates its header using a magic prefix check, and registers keycode mappings via ioctl for active entries marked in the flags array. However, the claim of '256 possible entries' is inaccurate as the actual number is determined by MAX_NR_KEYMAPS from the source, not explicitly given as 256. Despite this minor inaccuracy, the remaining accurate details cover the main steps of the code, including reading from STDIN, validation, iterating over active entries, and setting keycodes.",
                "The summary accurately captures that the code processes a binary keymap file, validates its header, and registers key mappings for active keys. However, it claims there are 256 possible entries, which is not explicitly supported by the source code\u2014`MAX_NR_KEYMAPS` is used but its value is not shown. Most details such as validation of header and loop over active keymaps match the code, with the single numeric claim about 256 being inaccurate. Since inaccurate details are under half and the accurate portions describe meaningful domain-specific logic, the content is moderately valuable."
            ]
        },
        "filter_prorec": {
            "summary": "Processes and validates a binary keymap file, then registers each mapped key code pair using a specific device command identifier.",
            "score": [
                0.9666666666666667,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly identifies that the code processes and validates a binary keymap file, supported by the use of `xread`, `is_prefixed_with` with `BINARY_KEYMAP_MAGIC`, and looping through keymaps. It also accurately describes that each mapped key is registered using a device command identifier, evidenced by the `ioctl(fd, KDSKBENT, &ke)` call. Both core details are explicitly present in the source code, with no unverified assumptions or hallucinations detected.",
                "The summary accurately captures that the code processes a binary keymap file, validates it using a magic prefix, and then registers each key via an ioctl call. This corresponds to validating with 'is_prefixed_with' and iterating over keys and tables to set them using 'ioctl' with KDSKBENT. However, it omits important logic such as checking command-line arguments to prevent incorrect usage, reading flags in two stages, skipping unused tables, handling special K_ALLOCATED values, and cleanup operations. The coverage is partial and misses key control flow details.",
                "The summary correctly notes that the code processes a binary keymap file and uses a device command identifier to register key mappings, which matches the use of xread to load data and ioctl with KDSKBENT to set entries. However, it omits key details such as the magic prefix validation with BINARY_KEYMAP_MAGIC and conditional logic to skip certain tables, making the accurate content somewhat generic rather than richly detailed."
            ]
        }
    }
}
{
    "source_code": "\nstatic int i915_ring_freq_table(struct seq_file *m, void *unused)\n{\n\tstruct drm_info_node *node = (struct drm_info_node *) m->private;\n\tstruct drm_device *dev = node->minor->dev;\n\tdrm_i915_private_t *dev_priv = dev->dev_private;\n\tint ret;\n\tint gpu_freq, ia_freq;\n\n\tif (!(IS_GEN6(dev) || IS_GEN7(dev))) {\n\t\tseq_printf(m, \"unsupported on this chipset\\n\");\n\t\treturn 0;\n\t}\n\n\tret = mutex_lock_interruptible(&dev_priv->rps.hw_lock);\n\tif (ret)\n\t\treturn ret;\n\n\tseq_printf(m, \"GPU freq (MHz)\\tEffective CPU freq (MHz)\\tEffective Ring freq (MHz)\\n\");\n\n\tfor (gpu_freq = dev_priv->rps.min_delay;\n\t     gpu_freq <= dev_priv->rps.max_delay;\n\t     gpu_freq++) {\n\t\tia_freq = gpu_freq;\n\t\tsandybridge_pcode_read(dev_priv,\n\t\t\t\t       GEN6_PCODE_READ_MIN_FREQ_TABLE,\n\t\t\t\t       &ia_freq);\n\t\tseq_printf(m, \"%d\\t\\t%d\\t\\t\\t\\t%d\\n\",\n\t\t\t   gpu_freq * GT_FREQUENCY_MULTIPLIER,\n\t\t\t   ((ia_freq >> 0) & 0xff) * 100,\n\t\t\t   ((ia_freq >> 8) & 0xff) * 100);\n\t}\n\n\tmutex_unlock(&dev_priv->rps.hw_lock);\n\n\treturn 0;\n}",
    "comment": "Retrieves and prints GPU, effective CPU, and effective Ring frequencies for Intel Gen6 and Gen7 chipsets, while protecting access with a mutex lock.",
    "prorec_sum": "Displays GPU, CPU, and Ring frequency information in a table, or prints an unsupported message if the chipset does not support it.",
    "filter_prorec_sum": "Displays a formatted table of GPU, CPU, and ring frequencies for supported chipsets, retrieving values from hardware and outputting via seq_file.",
    "prorec_aug_sum": "Outputs GPU, CPU, and ring frequencies in MHz for supported chipsets, iterating through frequency steps and formatting results into a tabular display.",
    "filter_prorec_aug_sum": "Prints GPU, CPU, and Ring frequencies in MHz for supported chipsets, iterating over frequency steps and outputting tabulated values.",
    "work_score": {
        "prorec": {
            "summary": "Displays GPU, CPU, and Ring frequency information in a table, or prints an unsupported message if the chipset does not support it.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function displays GPU, CPU, and Ring frequency information in a table and outputs an unsupported message if the chipset is not supported. These details are explicitly verified in the source code through seq_printf statements and the IS_GEN6/IS_GEN7 conditional check. All semantic details in the summary have direct evidence in the source code, with no unverified assumptions.",
                "The summary accurately captures the main logic of the function: printing GPU, CPU, and Ring frequency values in a table, and showing a message for unsupported chipsets when neither GEN6 nor GEN7 is detected. These details align directly with the source code's conditional check, loop, and output formatting. However, it omits some specifics such as the lock/unlock mechanism and exact calculation steps for frequencies, meaning it covers the main action but misses significant implementation details.",
                "The summary accurately captures that the function displays GPU, CPU, and Ring frequency information in a table and prints an unsupported message for unsupported chipsets, as evidenced by the seq_printf calls and IS_GEN6/IS_GEN7 check in the source code. There are no inaccurate details, but the description is generic and omits specifics such as the use of device private data, frequency multipliers, and the loop structure for frequency ranges, limiting domain-rich insight."
            ]
        },
        "filter_prorec": {
            "summary": "Displays a formatted table of GPU, CPU, and ring frequencies for supported chipsets, retrieving values from hardware and outputting via seq_file.",
            "score": [
                1.0,
                0.6333333333333333,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function outputs a formatted table of GPU, CPU, and ring frequencies, which is evidenced by the seq_printf calls in the code printing these values. It also accurately notes that the data is output via seq_file, as the function takes a seq_file pointer and uses seq_printf. The mention of retrieving values from hardware is supported by the sandybridge_pcode_read call interacting with hardware-related registers. Additionally, the reference to 'supported chipsets' matches the conditional check for IS_GEN6 or IS_GEN7. All semantic details in the summary are explicitly supported by the source code.",
                "The summary correctly identifies that the function outputs a table of GPU, CPU, and ring frequencies for supported chipsets and uses seq_file for output. These points are explicitly evident: the code prints a header and iterates over frequencies, checks chipset generation, reads values from hardware via sandybridge_pcode_read, and formats them into a table. While accurate, the summary omits key logic details such as the specific generation check (IS_GEN6 or IS_GEN7), the use of mutex_lock_interruptible for synchronization, and the exact computation of frequencies. Therefore, it captures the main action but misses important implementation details.",
                "The summary claims the code displays a formatted table of GPU, CPU, and ring frequencies for supported chipsets, retrieves values from hardware, and outputs via seq_file. These details are supported: the code prints a header and table columns for GPU, CPU, and ring frequencies, uses `seq_printf` on an `m` parameter of type `struct seq_file`, and calls `sandybridge_pcode_read` to read frequency data from hardware for GEN6/GEN7 chipsets. All semantic elements are accurate and domain-specific, providing clear insight into the function's output and data source."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nlisting_page (list_info_type *list)\n{\n  /* Grope around, see if we can see a title or subtitle edict coming up\n     soon.  (we look down 10 lines of the page and see if it's there)  */\n  if ((eject || (on_page >= (unsigned int) paper_height))\n      && paper_height != 0)\n    {\n      unsigned int c = 10;\n      int had_title = 0;\n      int had_subtitle = 0;\n\n      page++;\n\n      while (c != 0 && list)\n\t{\n\t  if (list->edict == EDICT_SBTTL && !had_subtitle)\n\t    {\n\t      had_subtitle = 1;\n\t      subtitle = list->edict_arg;\n\t    }\n\t  if (list->edict == EDICT_TITLE && !had_title)\n\t    {\n\t      had_title = 1;\n\t      title = list->edict_arg;\n\t    }\n\t  list = list->next;\n\t  c--;\n\t}\n\n      if (page > 1)\n\t{\n\t  fprintf (list_file, \"\\f\");\n\t}\n\n      fprintf (list_file, \"%s %s \\t\\t\\tpage %d\\n\", LISTING_HEADER, fn, page);\n      fprintf (list_file, \"%s\\n\", title);\n      fprintf (list_file, \"%s\\n\", subtitle);\n      on_page = 3;\n      eject = 0;\n    }\n}",
    "comment": "The function checks for titles and subtitles in a list before printing the current page header, title, and subtitle to a file.",
    "prorec_sum": "Generates a new \u201cGAS LISTING\u201d page header and prints stored location strings to the output file, updating related global tracking variables.",
    "filter_prorec_sum": "Generates a new \u201cGAS LISTING\u201d page header and prints stored title and location lines to the listing output file.",
    "prorec_aug_sum": "Generates a new \u201cGAS LISTING\u201d page header and prints stored title and subtitle strings to the listing output file.",
    "filter_prorec_aug_sum": "Generates a \"GAS LISTING\" page header and outputs stored section strings to the listing file, updating pagination and related global state.",
    "work_score": {
        "prorec": {
            "summary": "Generates a new \u201cGAS LISTING\u201d page header and prints stored location strings to the output file, updating related global tracking variables.",
            "score": [
                0.5333333333333333,
                0.6,
                0.0
            ],
            "reason": [
                "The summary claims generation of a 'GAS LISTING' page header, but the source code only formats the header using LISTING_HEADER without explicit evidence that it contains 'GAS LISTING'. It also mentions 'stored location strings', which is vague and not clearly supported; the code prints title and subtitle from edict_arg but does not indicate they are location strings. The code does update global variables like page, on_page, and eject, which matches part of the summary. Overall, there are more unverified assumptions than confirmed details.",
                "The summary claims a 'GAS LISTING' page header is generated and stored location strings are printed, but the source code simply prints LISTING_HEADER, file name, page number, title, and subtitle. There is no explicit evidence of the label 'GAS LISTING' or stored location strings. It does accurately note that global tracking variables like page, on_page, and eject are updated, but key claimed details about the header content are unsupported, resulting in only partial coverage of the actual logic.",
                "The summary claims that the function generates a new 'GAS LISTING' page header and prints stored location strings, but the source code shows it printing a header composed of LISTING_HEADER, fn, title, and subtitle, without explicit evidence that 'GAS LISTING' or location strings are involved. There is evidence of updating global variables such as page, title, subtitle, on_page, and eject. Since the key claim about 'GAS LISTING' and location strings is inaccurate, and more than half of the limited details are not supported by the code, the summary fails the kill switch criteria."
            ]
        },
        "filter_prorec": {
            "summary": "Generates a new \u201cGAS LISTING\u201d page header and prints stored title and location lines to the listing output file.",
            "score": [
                0.5,
                0.5,
                0.16666666666666666
            ],
            "reason": [
                "The summary claims the code generates a 'GAS LISTING' header and prints title and location lines, but the source code does not indicate any 'GAS LISTING' string, nor a 'location' line; instead it prints a header using LISTING_HEADER, the filename 'fn', and page number, plus the title and subtitle found in the list structure. The specific 'GAS LISTING' and 'location' details are hallucinations, with only the title printing being accurate, resulting in mostly inaccurate details.",
                "The summary claims generation of a 'GAS LISTING' page header and printing of stored title and location lines. The source code confirms printing of a header using LISTING_HEADER and variables 'title' and 'subtitle', but there is no explicit evidence of a 'GAS LISTING' string nor any 'location lines' printing. Thus, only part of the description is accurate, with the 'location lines' detail being unsupported. The accurate portion covers main header and title/subtitle printing, but omits surrounding control flow and conditional logic, leading to partial coverage.",
                "The summary claims the function generates a 'GAS LISTING' page header and prints stored title and location lines. The source code confirms printing a page header using LISTING_HEADER, as well as printing title and subtitle variables, so those parts are accurate. However, there is no mention or evidence of 'location lines' in the code\u2014only titles and subtitles\u2014making that detail inaccurate. With only one of two claims incorrect, the proportion of inaccurate details is under 50%, but the accurate details are fairly generic, providing limited domain-specific insight."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_multifit_fdfsolver_test (const gsl_multifit_fdfsolver * s,\n                             const double xtol, const double gtol,\n                             const double ftol, int *info)\n{\n  int status;\n  double gnorm, fnorm, phi;\n\n  *info = 0;\n\n  status = gsl_multifit_test_delta(s->dx, s->x, xtol*xtol, xtol);\n  if (status == GSL_SUCCESS)\n    {\n      *info = 1;\n      return GSL_SUCCESS;\n    }\n\n  /* compute gradient g = J^T f */\n  (s->type->gradient) (s->state, s->g);\n\n  /* compute gnorm = max_i( g_i * max(x_i, 1) ) */\n  gnorm = scaled_infnorm(s->x, s->g);\n\n  /* compute fnorm = ||f|| */\n  fnorm = gsl_blas_dnrm2(s->f);\n  phi = 0.5 * fnorm * fnorm;\n\n  if (gnorm <= gtol * GSL_MAX(phi, 1.0))\n    {\n      *info = 2;\n      return GSL_SUCCESS;\n    }\n\n#if 0\n  if (dfnorm <= ftol * GSL_MAX(fnorm, 1.0))\n    {\n      *info = 3;\n      return GSL_SUCCESS;\n    }\n#endif\n\n  return GSL_CONTINUE;\n}",
    "comment": "Evaluates the convergence of a multifit solver by checking parameter changes, gradient norms, and function norms against specified tolerances.",
    "prorec_sum": "Checks convergence of a multifit solver using delta and residual norms, updating status codes based on scaled step size and gradient magnitude.",
    "filter_prorec_sum": "Tests a GSL multifit solver\u2019s convergence using delta and residual norms, updating status codes based on step size and solution tolerance.",
    "prorec_aug_sum": "Checks convergence of a GSL multifit solver using delta and residual norms, updating status codes based on scaled step and gradient magnitude.",
    "filter_prorec_aug_sum": "Tests convergence of a GSL multifit solver using parameter deltas and residual norms, updating status codes and applying scaling criteria for termination.",
    "work_score": {
        "prorec": {
            "summary": "Checks convergence of a multifit solver using delta and residual norms, updating status codes based on scaled step size and gradient magnitude.",
            "score": [
                0.9,
                0.6333333333333333,
                0.8666666666666667
            ],
            "reason": [
                "The summary correctly notes that the function checks convergence for a multifit solver. It accurately identifies the use of a delta test (`gsl_multifit_test_delta`) and gradient magnitude checks (`scaled_infnorm` and `gtol` thresholds). It also correctly mentions status code updates (`*info` values). However, the reference to 'residual norms' is partially imprecise: while `fnorm` from `gsl_blas_dnrm2` of `s->f` is computed, it is used in conjunction with gradient tolerance, not as a standalone residual norm test. Overall, most details are supported by the code, with only minor overgeneralization.",
                "The summary accurately captures that the function checks convergence for a multifit solver and uses step size (via gsl_multifit_test_delta) and gradient magnitude (via scaled_infnorm) to update status codes. It omits other explicit details in the code, such as the residual norm computation (fnorm), its squared half value (phi), and the specific gtol scaling condition, meaning the coverage of the full logic is incomplete.",
                "The summary correctly identifies the function\u2019s purpose as checking convergence of a multifit solver using delta and residual norms, which is supported by calls to gsl_multifit_test_delta, scaled_infnorm, and gsl_blas_dnrm2. It also accurately notes status updates based on gradient magnitude and scaled step size. There are no inaccurate details, and the accurate ones are specific to the solver\u2019s logic and domain, providing meaningful insight."
            ]
        },
        "filter_prorec": {
            "summary": "Tests a GSL multifit solver\u2019s convergence using delta and residual norms, updating status codes based on step size and solution tolerance.",
            "score": [
                0.9666666666666667,
                0.6,
                0.8333333333333334
            ],
            "reason": [
                "The summary correctly identifies that the function tests a GSL multifit solver's convergence and uses delta and residual norms. The source code explicitly calls gsl_multifit_test_delta for step size (delta) check, and computes fnorm from residuals. It also updates *info with status codes based on tolerance checks, which matches the described behavior. All semantic details in the summary are directly supported by the code, with no unverified assumptions.",
                "The summary is partially accurate: it correctly notes that the function tests convergence of a GSL multifit solver using a delta comparison, and sets status codes accordingly. However, while it mentions residual norms, the source code explicitly uses a gradient norm and a function norm, with logic for step size (xtol) and gradient tolerance (gtol), not residual norms per se. It omits key control flow details such as separate handling for gradient tolerance and the unused ftol block. Therefore, the accurate content covers the primary action but misses important parts of the logic.",
                "The summary correctly identifies that the function tests convergence of a GSL multifit solver using delta and residual norms and updates status codes based on tolerance checks. These details are explicitly reflected in the code through the use of gsl_multifit_test_delta, gradient and norm calculations, and info/status assignments. Although it does not mention all tolerance types individually (xtol, gtol, ftol), the provided accurate details are domain-specific and relevant."
            ]
        }
    }
}
{
    "source_code": "\nZSTD_CStream* ZSTD_createCStream_advanced(ZSTD_customMem customMem)\n{\n    ZSTD_CStream* zcs;\n\n    if (!customMem.customAlloc && !customMem.customFree) customMem = defaultCustomMem;\n    if (!customMem.customAlloc || !customMem.customFree) return NULL;\n\n    zcs = (ZSTD_CStream*)ZSTD_malloc(sizeof(ZSTD_CStream), customMem);\n    if (zcs==NULL) return NULL;\n    memset(zcs, 0, sizeof(ZSTD_CStream));\n    memcpy(&zcs->customMem, &customMem, sizeof(ZSTD_customMem));\n    zcs->cctx = ZSTD_createCCtx_advanced(customMem);\n    if (zcs->cctx == NULL) { ZSTD_freeCStream(zcs); return NULL; }\n    return zcs;\n}",
    "comment": "Creates and initializes a ZSTD_CStream object with custom memory allocation, returning NULL on failure or invalid parameters.",
    "prorec_sum": "Allocates and initializes a 200-byte structure with function pointers and parameters, then invokes a setup routine, returning the structure on success.",
    "filter_prorec_sum": "Allocates and initializes a 200-byte structure with provided function pointers and parameters, invoking helper routines to set up internal data before returning it.",
    "prorec_aug_sum": "Allocates and initializes a 200-byte structure with provided callback pointers and parameters, invoking a secondary setup routine and cleaning up on failure.",
    "filter_prorec_aug_sum": "Initializes a 200-byte structure with provided callbacks and parameters, zeroes its data, and invokes a secondary setup function to finalize initialization.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a 200-byte structure with function pointers and parameters, then invokes a setup routine, returning the structure on success.",
            "score": [
                0.2333333333333333,
                0.16666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims the function allocates a 200-byte structure with function pointers and parameters and invokes a setup routine. The source code does not specify a 200-byte size\u2014it uses sizeof(ZSTD_CStream) dynamically\u2014and there is no evidence of function pointers being stored. While the code does allocate and initialize a structure and call ZSTD_createCCtx_advanced, most details in the summary (byte size, function pointers, parameter setup) are unsupported by the source. Only the general allocation, initialization, and setup call are accurate, resulting in less than half of the details being correct.",
                "The summary's claim of a 200-byte structure and inclusion of function pointers and parameters is unsupported by the source code, which explicitly allocates sizeof(ZSTD_CStream) without specifying its size in bytes and deals with a custom memory struct, not generalized function pointers. The invocation of a setup routine loosely corresponds to ZSTD_createCCtx_advanced, but the rest of the described details are inaccurate, leaving little accurate content about the actual allocation checks, initialization with memset/memcpy, error handling, and cleanup.",
                "The summary claims a fixed 200-byte allocation and the presence of function pointers and parameters, none of which are evidenced in the source code. The actual code allocates using sizeof(ZSTD_CStream), initializes memory to zero, sets customMem, and creates a compression context. Most details in the summary are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a 200-byte structure with provided function pointers and parameters, invoking helper routines to set up internal data before returning it.",
            "score": [
                0.3,
                0.2333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims a fixed 200-byte allocation, which is not present in the source code; the allocation size is based on sizeof(ZSTD_CStream). It references 'provided function pointers and parameters' generally matching customAlloc/customFree checks, but omits details about defaultCustomMem or null handling. The mention of invoking helper routines is partially accurate with calls to ZSTD_createCCtx_advanced, but the summary does not reflect the specific initialization logic (memset, memcpy) and misstates size allocation. Overall, most details lack explicit evidence, yielding low accuracy.",
                "The summary contains inaccuracies: it claims a fixed 200-byte allocation and mentions function pointers and parameters without matching evidence in the source. The source explicitly allocates sizeof(ZSTD_CStream), checks customAlloc/customFree, uses defaultCustomMem if both are NULL, copies customMem, and initializes cctx with ZSTD_createCCtx_advanced. These accurate details are absent in the summary, so the core logic is largely missed after filtering hallucinations.",
                "The summary's claim of allocating a 200-byte structure is inaccurate, as the code allocates sizeof(ZSTD_CStream) without specifying or suggesting a fixed size. The mention of 'function pointers and parameters' is partially accurate in that customAlloc and customFree function pointers are used via ZSTD_customMem, but there is no explicit evidence of arbitrary parameters beyond that. The reference to invoking helper routines is accurate for calls to ZSTD_createCCtx_advanced and possible cleanup via ZSTD_freeCStream. Since more than half of the details (notably the fixed size and generic parameter handling) are inaccurate, the evaluation stops per the kill switch."
            ]
        }
    }
}
{
    "source_code": "static enum mu_filter_result\n_crlfdot_decoder (void *xd,\n\t\t  enum mu_filter_command cmd,\n\t\t  struct mu_filter_io *iobuf)\n{\n  int *pstate = xd;\n  size_t i, j;\n  const unsigned char *iptr;\n  size_t isize;\n  char *optr;\n  size_t osize;\n\n  switch (cmd)\n    {\n    case mu_filter_init:\n      *pstate = crlfdot_decode_init;\n      return mu_filter_ok;\n      \n    case mu_filter_done:\n      return mu_filter_ok;\n      \n    default:\n      break;\n    }\n  \n  iptr = (const unsigned char *) iobuf->input;\n  isize = iobuf->isize;\n  optr = iobuf->output;\n  osize = iobuf->osize;\n\n  for (i = j = 0; *pstate != crlfdot_decode_end && i < isize && j < osize; i++)\n    {\n      unsigned char c = *iptr++;\n\n      if (c == '\\r')\n\t{\n\t  if (i + 1 == isize)\n\t    break;\n\t  *pstate = new_decode_state (*pstate, c);\n\t  if (*iptr == '\\n')\n\t    continue;\n\t}\n      else if (c == '.' &&\n\t       (*pstate == crlfdot_decode_init ||\n\t\t*pstate == crlfdot_decode_crlf))\n\t{\n\t  /* Make sure we have two more characters in the buffer */\n\t  if (i + 2 == isize)\n\t    break;\n\t  *pstate = new_decode_state (*pstate, c);\n\t  if (*iptr != '\\r')\n\t    continue;\n\t}\n      else\n\t*pstate = new_decode_state (*pstate, c);\n      optr[j++] = c;\n    }\n  \n  if (*pstate == crlfdot_decode_end)\n    {\n      j -= 2; /* remove the trailing .\\n */\n      iobuf->eof = 1;\n    }\n  iobuf->isize = i;\n  iobuf->osize = j;\n  return mu_filter_ok;\n}",
    "comment": "Decodes input data by processing CRLF sequences and dots, modifying the state and output buffer accordingly, until reaching the end condition.",
    "prorec_sum": "Processes an input byte stream into a buffer, updating a parsing state machine and handling special cases for carriage return, line feed, and period characters.",
    "filter_prorec_sum": "Processes an input byte stream, updating a state machine and writing valid bytes to a buffer until termination conditions or maximum lengths are reached.",
    "prorec_aug_sum": "Processes an input byte stream into a destination buffer, updating a parser state and handling carriage return, line feed, and period character transitions.",
    "filter_prorec_aug_sum": "Processes an input byte stream, updating a parsing state and output buffer while handling carriage return, line feed, and period characters with special rules.",
    "work_score": {
        "prorec": {
            "summary": "Processes an input byte stream into a buffer, updating a parsing state machine and handling special cases for carriage return, line feed, and period characters.",
            "score": [
                1.0,
                0.7333333333333334,
                0.7999999999999999
            ],
            "reason": [
                "The summary accurately captures the core functionality: the code processes an input byte stream into an output buffer, updates a parsing state machine via `new_decode_state`, and handles special cases for carriage return (`\\r`), line feed (`\\n`), and period (`.`) characters. These aspects are explicitly evidenced in the source code. No unsupported claims or hallucinations are present, so all details are accurate.",
                "The summary correctly identifies that the function processes an input byte stream into an output buffer, maintains a parsing state machine, and implements special handling for carriage return, line feed, and period characters. These elements are explicitly evidenced in the source code via variables for input/output buffers, calls to new_decode_state, and conditional blocks for '\\r', '\\n', and '.'. However, it omits explicit mention of init/done command handling, buffer size checks to avoid overruns, and EOF marking when the end state is reached, which are critical parts of the logic.",
                "The summary's details about processing an input byte stream, maintaining a parsing state machine, and handling carriage return, line feed, and period characters are explicitly supported in the source code via variables like iptr/optr, the pstate state updates, and conditionals for '\\r', '\\n', and '.'. All extracted details are accurate and domain-specific, reflecting the control flow and special character handling in the function."
            ]
        },
        "filter_prorec": {
            "summary": "Processes an input byte stream, updating a state machine and writing valid bytes to a buffer until termination conditions or maximum lengths are reached.",
            "score": [
                1.0,
                0.6,
                0.5666666666666668
            ],
            "reason": [
                "The summary correctly captures that the function processes an input byte stream, updates a state machine, and writes to an output buffer until certain conditions are met, which corresponds to the loop over input bytes, state updates via new_decode_state, and writing to optr until end state or buffer limits. However, it omits specific details visible in the code such as handling of CRLF and '.' sequences, and the explicit termination logic involving crlfdot_decode_end and eof setting. All stated claims are supported by the source code, resulting in no hallucinations but a lack of completeness.",
                "The summary accurately captures the broad logic of processing an input byte stream, updating a state machine, and writing valid bytes to an output buffer until certain stopping conditions are met. These points are explicitly supported in the source code via the loop processing `iptr` and `optr`, state updates via `new_decode_state`, and termination when `*pstate == crlfdot_decode_end` or buffer sizes are reached. However, the summary omits important details like handling specific characters (`\\r`, `.`), skipping conditions, and the EOF flag setting, so it does not fully cover the code's logic.",
                "The summary is accurate in describing that the function processes an input byte stream, updates a state machine, and writes bytes to an output buffer until certain conditions are met. These behaviors are explicitly reflected in the source code through the use of pointers to input/output buffers, the state updates via `new_decode_state`, and loop termination conditions based on buffer sizes and state checks. However, the description is quite generic and lacks mention of more domain-specific aspects like CRLF sequences, dot handling, or EOF signaling, which would give deeper insights."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\ntry_load_plugin (const char *pname, bfd *abfd, int *has_plugin_p)\n{\n  void *plugin_handle;\n  struct ld_plugin_tv tv[4];\n  int i;\n  ld_plugin_onload onload;\n  enum ld_plugin_status status;\n\n  *has_plugin_p = 0;\n\n  plugin_handle = dlopen (pname, RTLD_NOW);\n  if (!plugin_handle)\n    {\n      _bfd_error_handler (\"%s\\n\", dlerror ());\n      return 0;\n    }\n\n  onload = dlsym (plugin_handle, \"onload\");\n  if (!onload)\n    goto err;\n\n  i = 0;\n  tv[i].tv_tag = LDPT_MESSAGE;\n  tv[i].tv_u.tv_message = message;\n\n  ++i;\n  tv[i].tv_tag = LDPT_REGISTER_CLAIM_FILE_HOOK;\n  tv[i].tv_u.tv_register_claim_file = register_claim_file;\n\n  ++i;\n  tv[i].tv_tag = LDPT_ADD_SYMBOLS;\n  tv[i].tv_u.tv_add_symbols = add_symbols;\n\n  ++i;\n  tv[i].tv_tag = LDPT_NULL;\n  tv[i].tv_u.tv_val = 0;\n\n  status = (*onload)(tv);\n\n  if (status != LDPS_OK)\n    goto err;\n\n  *has_plugin_p = 1;\n\n  abfd->plugin_format = bfd_plugin_no;\n\n  if (!claim_file)\n    goto err;\n\n  if (!try_claim (abfd))\n    goto err;\n\n  abfd->plugin_format = bfd_plugin_yes;\n\n  return 1;\n\n err:\n  return 0;\n}",
    "comment": "Loads a plugin from a specified path, initializes it, and claims a file if successful, returning the status of the operation.",
    "prorec_sum": "Loads a shared library, invokes its `onload` function with callbacks, and conditionally updates flags and processes data via registered handler functions.",
    "filter_prorec_sum": "Dynamically loads a shared library, invokes its `onload` entry with callbacks, and updates flags based on an optional file descriptor processing routine\u2019s result.",
    "prorec_aug_sum": "Loads a shared library, calls its `onload` function with callbacks, and updates flags and state based on optional `qword_714B10` processing results.",
    "filter_prorec_aug_sum": "Loads a shared library, calls its `onload` entry with callbacks, and updates flags based on optional file descriptor processing results.",
    "work_score": {
        "prorec": {
            "summary": "Loads a shared library, invokes its `onload` function with callbacks, and conditionally updates flags and processes data via registered handler functions.",
            "score": [
                0.9333333333333332,
                0.6333333333333333,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly states that the code loads a shared library using dlopen, invokes its `onload` function with callback structures, and updates flags based on plugin status. These details are explicitly supported by the source code. However, the phrase 'processes data via registered handler functions' is vague and not fully evidenced; while functions are registered as callbacks, actual data processing is not shown in the provided code. Overall, most details are accurate with minor ambiguity in the last claim.",
                "The summary accurately captures that the code loads a shared library via dlopen, invokes its onload function, and updates flags based on conditional checks. It correctly notes that callbacks are passed to onload. However, it omits explicit details about error handling, specific tv_tag assignments (LDPT_MESSAGE, LDPT_REGISTER_CLAIM_FILE_HOOK, LDPT_ADD_SYMBOLS), and the two plugin_format states. It also generalizes 'processes data via registered handler functions' without directly referencing the claim_file and try_claim logic, resulting in incomplete coverage of the code's critical control flow.",
                "The summary correctly notes loading a shared library, invoking the `onload` function with callbacks, and updating flags based on conditions, all of which are explicitly shown in the source code through `dlopen`, `dlsym`, setting callback tags in `tv`, and conditional assignments to `has_plugin_p` and `plugin_format`. However, the description of 'processes data via registered handler functions' is generic and does not point to specific handlers like `register_claim_file` or `add_symbols`, reducing the domain-rich value of the accurate details."
            ]
        },
        "filter_prorec": {
            "summary": "Dynamically loads a shared library, invokes its `onload` entry with callbacks, and updates flags based on an optional file descriptor processing routine\u2019s result.",
            "score": [
                0.7666666666666666,
                0.6666666666666666,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly identifies that the function dynamically loads a shared library using `dlopen`, retrieves the `onload` symbol, and passes callbacks via a struct array, which is supported in the source code. It also notes that flags are updated based on subsequent processing. However, the summary inaccurately specifies 'optional file descriptor processing routine', which is not explicitly present; the code uses `try_claim(abfd)` rather than handling a file descriptor. Overall, most details are accurate except for that mischaracterization.",
                "The summary accurately notes that the function dynamically loads a shared library using dlopen, calls its 'onload' function with a set of callbacks, and updates flags based on further processing. However, the mention of an 'optional file descriptor processing routine' is inaccurate, as the source code deals with claim_file and try_claim on a bfd structure, not file descriptors. The accurate elements capture the main logic but omit error handling specifics and the conditional checks for plugin presence, leading to partial coverage.",
                "The summary correctly states that the function dynamically loads a shared library using `dlopen` and invokes its `onload` entry point with callbacks, which matches the setup of the `tv` array and the `(*onload)(tv)` call. However, it inaccurately describes updating flags based on an optional file descriptor processing routine; the code instead checks `claim_file` and calls `try_claim(abfd)` to set `plugin_format`, with no use of any file descriptor routine. Because 1 of the 3 key details is inaccurate, the proportion of inaccuracies is 33%, allowing scoring to proceed. The accurate details are specific and domain-relevant, involving dynamic linking mechanisms and plugin initialization, but not deeply rich in broader context, yielding a moderate value."
            ]
        }
    }
}
{
    "source_code": "static int\nxmlDOMWrapNSNormGatherInScopeNs(xmlNsMapPtr *map,\n\t\t\t\txmlNodePtr node)\n{\n    xmlNodePtr cur;\n    xmlNsPtr ns;\n    xmlNsMapItemPtr mi;\n    int shadowed;\n\n    if ((map == NULL) || (*map != NULL))\n\treturn (-1);\n    if ((node == NULL) || (node->type == XML_NAMESPACE_DECL))\n        return (-1);\n    /*\n    * Get in-scope ns-decls of @parent.\n    */\n    cur = node;\n    while ((cur != NULL) && (cur != (xmlNodePtr) cur->doc)) {\n\tif (cur->type == XML_ELEMENT_NODE) {\n\t    if (cur->nsDef != NULL) {\n\t\tns = cur->nsDef;\n\t\tdo {\n\t\t    shadowed = 0;\n\t\t    if (XML_NSMAP_NOTEMPTY(*map)) {\n\t\t\t/*\n\t\t\t* Skip shadowed prefixes.\n\t\t\t*/\n\t\t\tXML_NSMAP_FOREACH(*map, mi) {\n\t\t\t    if ((ns->prefix == mi->newNs->prefix) ||\n\t\t\t\txmlStrEqual(ns->prefix, mi->newNs->prefix)) {\n\t\t\t\tshadowed = 1;\n\t\t\t\tbreak;\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\t\t    /*\n\t\t    * Insert mapping.\n\t\t    */\n\t\t    mi = xmlDOMWrapNsMapAddItem(map, 0, NULL,\n\t\t\tns, XML_TREE_NSMAP_PARENT);\n\t\t    if (mi == NULL)\n\t\t\treturn (-1);\n\t\t    if (shadowed)\n\t\t\tmi->shadowDepth = 0;\n\t\t    ns = ns->next;\n\t\t} while (ns != NULL);\n\t    }\n\t}\n\tcur = cur->parent;\n    }\n    return (0);\n}",
    "comment": "Gathers in-scope namespace declarations from the given node's ancestors and updates the namespace mapping, avoiding shadowed prefixes.",
    "prorec_sum": "Traverses XML namespace nodes from a starting node, matching names against a list, and adds each match to the destination collection.",
    "filter_prorec_sum": "Traverses linked XML nodes, compares namespace names, and adds matching namespaces to a provided list using xmlStrEqual and sub_51530.",
    "prorec_aug_sum": "Traverses linked XML nodes, matching names with an existing list, and adds new matching entries using sub_51530, returning errors when insertion fails.",
    "filter_prorec_aug_sum": "Traverses related XML nodes, finds matches by name, and adds them via `sub_51530`, returning an error code on failure.",
    "work_score": {
        "prorec": {
            "summary": "Traverses XML namespace nodes from a starting node, matching names against a list, and adds each match to the destination collection.",
            "score": [
                0.19999999999999998,
                0.13333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims that the function matches names against a list and adds each match to a destination collection, but the source code shows it specifically gathers in-scope XML namespace declarations from ancestor nodes, checks for shadowed prefixes, and adds namespace mappings to an xmlNsMap. There is no evidence of a generic 'matching names' process, nor of a 'destination collection' in the abstract sense described; the code is focused on namespace mapping structures. All key details in the summary are inaccurate based on the given function.",
                "The summary incorrectly states that the function matches names against a list and adds each match to a destination collection. In reality, the code traverses ancestor XML element nodes, checks for namespace definitions, skips shadowed prefixes based on existing map entries, and adds all namespace entries into the map without filtering by name matches. Since the only partially correct detail is that namespaces are added to a collection, most core logic is missing or misstated, making the coverage inadequate.",
                "The summary claims the function matches names against a list and adds each match to a destination collection. In reality, the code iterates through XML element nodes from the starting node, gathers in-scope namespace declarations, checks for shadowed prefixes, and adds namespace items to a map. The 'matching names against a list' detail is inaccurate because it specifically deals with namespace prefixes, not generic names, and the 'destination collection' is a namespace map with specific shadow handling logic. Most details are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Traverses linked XML nodes, compares namespace names, and adds matching namespaces to a provided list using xmlStrEqual and sub_51530.",
            "score": [
                0.5666666666666668,
                0.5,
                0.0
            ],
            "reason": [
                "The summary correctly notes that the code traverses linked XML nodes and uses xmlStrEqual to compare namespace names, which is supported by the presence of the while loop over nodes and the xmlStrEqual function call. However, it inaccurately claims that matching namespaces are added using 'sub_51530'; in reality, the code uses xmlDOMWrapNsMapAddItem, and it does not limit additions to only matching namespaces per se but adds in-scope namespaces while checking for shadowed prefixes. This results in a mix of accurate and hallucinated details.",
                "The summary correctly notes traversal of linked XML nodes and namespace comparison using xmlStrEqual, which is evident in the loop over 'cur' and the use of xmlStrEqual in the source code. However, it inaccurately claims namespaces are added only when names match; the real code adds each namespace via xmlDOMWrapNsMapAddItem regardless of match, skipping only shadowed prefixes. The mention of 'sub_51530' is a hallucination since the actual function called is xmlDOMWrapNsMapAddItem. This omission and misstatement fail to capture critical details such as shadow prefix handling, shadowDepth assignment, and error returns, leaving the accurate content incomplete.",
                "The summary contains multiple inaccuracies: it claims use of a function named sub_51530, which is not present in the source code, and states that only matching namespaces are added, whereas the code adds all in-scope namespaces unless shadowed. While 'traverses linked XML nodes' and 'compares namespace names using xmlStrEqual' are accurate, the majority of the details are incorrect, exceeding the 50% inaccuracy threshold and triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nssize_t led_trigger_show(struct device *dev, struct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct led_classdev *led_cdev = dev_get_drvdata(dev);\n\tstruct led_trigger *trig;\n\tint len = 0;\n\n\tdown_read(&triggers_list_lock);\n\tdown_read(&led_cdev->trigger_lock);\n\n\tif (!led_cdev->trigger)\n\t\tlen += sprintf(buf+len, \"[none] \");\n\telse\n\t\tlen += sprintf(buf+len, \"none \");\n\n\tlist_for_each_entry(trig, &trigger_list, next_trig) {\n\t\tif (led_cdev->trigger && !strcmp(led_cdev->trigger->name,\n\t\t\t\t\t\t\ttrig->name))\n\t\t\tlen += sprintf(buf+len, \"[%s] \", trig->name);\n\t\telse\n\t\t\tlen += sprintf(buf+len, \"%s \", trig->name);\n\t}\n\tup_read(&led_cdev->trigger_lock);\n\tup_read(&triggers_list_lock);\n\n\tlen += sprintf(len+buf, \"\\n\");\n\treturn len;\n}",
    "comment": "Retrieves the current LED trigger state and lists available triggers, marking the active trigger with brackets in the output buffer.",
    "prorec_sum": "Formats and writes a device\u2019s option list into the provided buffer, starting with \u201cnone\u201d if no options are present.",
    "filter_prorec_sum": "Builds a textual status string combining a default label and formatted entries from a global list, then appends a newline and returns its length.",
    "prorec_aug_sum": "Formats and writes a status string into the provided buffer, starting with \u201cnone\u201d if no entries, then appending formatted data for each registered item.",
    "filter_prorec_aug_sum": "Builds a textual list of entries into the provided buffer, starting with \u201cnone\u201d if no data, then appending formatted names for each available item.",
    "work_score": {
        "prorec": {
            "summary": "Formats and writes a device\u2019s option list into the provided buffer, starting with \u201cnone\u201d if no options are present.",
            "score": [
                0.3,
                0.20000000000000004,
                0.0
            ],
            "reason": [
                "The summary claims the function starts with 'none' if no options are present, but the source code explicitly writes '[none]' in that case. It also generalizes 'device\u2019s option list' without specifying it is the LED trigger list, which is clear from the code. This shows at least one key detail is inaccurate, lowering the proportion of accurate details below half.",
                "The summary misstates the code\u2019s behavior: in the source, it writes \"[none]\" if no trigger is set, and \"none\" otherwise, not simply starting with \"none\" when no options exist. It also omits the loop over trigger_list, the logic for marking the active trigger with brackets, and the newline append at the end. The only partly accurate element is that it writes to a provided buffer, but most semantic details are inaccurate or missing, resulting in very limited coverage of the actual logic.",
                "The summary claims the function starts with 'none' if no options are present, but the code actually prints '[none]' when there is no trigger and 'none' otherwise, and it always enumerates triggers from the trigger_list. The summary omits important specifics such as the use of locks, the differentiation between '[none]' and 'none', and the iteration over actual trigger names. The main detail given is misleading, making the majority of its content inaccurate."
            ]
        },
        "filter_prorec": {
            "summary": "Builds a textual status string combining a default label and formatted entries from a global list, then appends a newline and returns its length.",
            "score": [
                0.9666666666666667,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly describes that the function builds a textual status string, combines a default label, iterates through a global list, appends a newline, and returns the length. All these elements are explicitly supported by the source code: use of sprintf to write either '[none]' or 'none' as a default label, iteration over trigger_list, formatting entries, appending a newline, and returning len. No unverified or hallucinated details are present, indicating full alignment with the evaluation steps.",
                "The summary is mostly accurate in describing that the function constructs a status string from entries in a global list, adds a newline, and returns the length. It correctly notes the concatenation of formatted entries and return value. However, it omits key details evident in the source code, such as the conditional handling of the 'none' label, use of brackets around the active trigger, and reading locks around list iteration. These missing elements mean the summary does not fully capture the function's logic.",
                "The summary's claims about building a status string and appending a newline match the source code's logic, where the function uses sprintf to write default labels (\"[none]\" or \"none\"), iterates over a global trigger_list, formats each entry, then appends a newline and returns the total length. All semantic details have explicit evidence in the code, and they convey clear, domain-relevant behavior rather than vague statements."
            ]
        }
    }
}
{
    "source_code": "\nvoid ping_rcv(struct sk_buff *skb)\n{\n\tstruct sock *sk;\n\tstruct net *net = dev_net(skb->dev);\n\tstruct iphdr *iph = ip_hdr(skb);\n\tstruct icmphdr *icmph = icmp_hdr(skb);\n\t__be32 saddr = iph->saddr;\n\t__be32 daddr = iph->daddr;\n\n\t/* We assume the packet has already been checked by icmp_rcv */\n\n\tpr_debug(\"ping_rcv(skb=%p,id=%04x,seq=%04x)\\n\",\n\t\t skb, ntohs(icmph->un.echo.id), ntohs(icmph->un.echo.sequence));\n\n\t/* Push ICMP header back */\n\tskb_push(skb, skb->data - (u8 *)icmph);\n\n\tsk = ping_v4_lookup(net, saddr, daddr, ntohs(icmph->un.echo.id),\n\t\t\t    skb->dev->ifindex);\n\tif (sk != NULL) {\n\t\tpr_debug(\"rcv on socket %p\\n\", sk);\n\t\tping_queue_rcv_skb(sk, skb_get(skb));\n\t\tsock_put(sk);\n\t\treturn;\n\t}\n\tpr_debug(\"no socket, dropping\\n\");\n\n\t/* We're called from icmp_rcv(). kfree_skb() is done there. */\n}",
    "comment": "Processes received ICMP packets, checks for an associated socket, and queues the packet for delivery if a corresponding socket is found.",
    "prorec_sum": "Processes network buffer metadata, prepares associated resources, and performs operations before releasing references when conditions on retrieved descriptors are satisfied.",
    "filter_prorec_sum": "Processes packet-related structures, performing lookups and data copying into buffers, then updates reference counts and triggers cleanup when no longer referenced.",
    "prorec_aug_sum": "Obtains routing-related data from cached structures, processes it with helper routines, and conditionally releases references when usage count reaches zero.",
    "filter_prorec_aug_sum": "Retrieves routing entry data, processes it with helper functions, and manages reference counts, invoking cleanup when the last reference to the entry is released.",
    "work_score": {
        "prorec": {
            "summary": "Processes network buffer metadata, prepares associated resources, and performs operations before releasing references when conditions on retrieved descriptors are satisfied.",
            "score": [
                0.30000000000000004,
                0.26666666666666666,
                0.0
            ],
            "reason": [
                "The summary is overly generic and fails to capture explicit details present in the source code, such as use of specific structures (`sk_buff`, `sock`, `iphdr`, `icmphdr`), functions (`ping_v4_lookup`, `ping_queue_rcv_skb`, `sock_put`), and debugging output. While it loosely references processing and conditional resource release, these elements are not directly verified against the code in a specific manner, making most semantic details vague or unverifiable.",
                "The summary is overly generic and does not explicitly mention concrete code elements such as 'ping_v4_lookup', 'skb_push', or the handling of ICMP and socket lookup logic present in the source. While it vaguely refers to processing metadata and releasing references, these are broad notions without direct evidence mapping to the actual control flow or data structures, resulting in significant missing details about the main logic.",
                "The summary is overly generic and fails to capture explicit details from the source code, such as the use of specific structs (sock, net, iphdr, icmphdr), the call to ping_v4_lookup, or the condition on the socket before queuing and releasing it. It does not mention the ICMP-specific processing or pr_debug messages, and its vague references to 'descriptors' and 'preparing resources' lack direct evidence in the code. Most details are inaccurate due to insufficient grounding in the actual logic, exceeding the 50% threshold for inaccuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Processes packet-related structures, performing lookups and data copying into buffers, then updates reference counts and triggers cleanup when no longer referenced.",
            "score": [
                0.5,
                0.5333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims that the code performs data copying into buffers, updates reference counts, and triggers cleanup when no longer referenced. While the source code does perform a lookup (ping_v4_lookup) and updates reference counts via sock_put, there is no explicit evidence of generic data copying into arbitrary buffers\u2014only skb_push, which adjusts the buffer pointer, not a data copy. It also does not explicitly trigger cleanup based on reference counts; cleanup is mentioned only indirectly via kfree_skb in a comment, handled elsewhere. Thus, several details are inaccurate or unverified, making the accuracy ratio below 50%.",
                "The summary claims lookup and data copying into buffers, reference count updates, and cleanup when no longer referenced. The source code confirms packet structure processing via struct iphdr and icmphdr, and a lookup with ping_v4_lookup. However, there is no explicit evidence of copying data into buffers; instead, skb_push manipulates pointers, and skb_get increments reference counts. Cleanup is not performed here, as kfree_skb is handled elsewhere. After filtering, only partial logic remains, missing details on control flow handling when sk is NULL and data manipulations, so the picture of logic is incomplete.",
                "The summary contains multiple inaccuracies: it mentions 'data copying into buffers' and 'updates reference counts' which are not explicitly shown in the source code. While the code does perform lookups (ping_v4_lookup) and triggers cleanup indirectly through sock_put/skb handling, the majority of the described actions, such as explicit data copying and manual reference count updates, are not evidenced. More than half of the details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "static int snd_seq_device_free(struct snd_seq_device *dev)\n{\n\tstruct ops_list *ops;\n\n\tif (snd_BUG_ON(!dev))\n\t\treturn -EINVAL;\n\n\tops = find_driver(dev->id, 0);\n\tif (ops == NULL)\n\t\treturn -ENXIO;\n\n\t/* remove the device from the list */\n\tmutex_lock(&ops->reg_mutex);\n\tlist_del(&dev->list);\n\tops->num_devices--;\n\tmutex_unlock(&ops->reg_mutex);\n\n\tfree_device(dev, ops);\n\tif (dev->private_free)\n\t\tdev->private_free(dev);\n\tkfree(dev);\n\n\tunlock_driver(ops);\n\n\treturn 0;\n}",
    "comment": "Frees a sequencer device by removing it from the list, releasing resources, and invoking the device's private cleanup function if defined.",
    "prorec_sum": "Frees and detaches an HDA codec\u2019s associated resources, updates power state, and performs final cleanup based on provided parameters.",
    "filter_prorec_sum": "Releases and cleans up an HDA codec's associated resources, updates linked structures, invokes optional callbacks, and resets hardware-related state fields.",
    "prorec_aug_sum": "Removes an allocated object from internal linked lists, updates related counters, invokes cleanup routines, and calls a registered callback if present.",
    "filter_prorec_aug_sum": "Removes an object from linked lists, decrements its reference counters, invokes a callback, and performs associated cleanup operations for the given context.",
    "work_score": {
        "prorec": {
            "summary": "Frees and detaches an HDA codec\u2019s associated resources, updates power state, and performs final cleanup based on provided parameters.",
            "score": [
                0.06666666666666667,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims the function frees and detaches an HDA codec, updates power state, and performs cleanup based on parameters. The source code shows freeing a generic snd_seq_device, removing it from a list, decrementing a device count, invoking optional private cleanup, and unlocking the driver. There is no mention of HDA codecs or power state updates, making all specific claims about codec handling and power management inaccurate. Only the generic cleanup part aligns with the code. This results in less than half of the details being accurate.",
                "The summary describes freeing and detaching an HDA codec, updating the power state, and performing cleanup based on parameters, but none of these details are present in the source code. The code instead frees a generic snd_seq_device, removes it from a driver\u2019s list, decrements a count, calls free routines, and unlocks the driver. All summary claims are inaccurate, leaving no valid details to map to the code\u2019s logic.",
                "The summary claims the function frees and detaches an HDA codec, updates power state, and performs final cleanup based on parameters. In the source code, the function actually frees a generic snd_seq_device by removing it from a driver-managed list, decrementing the device count, freeing associated resources, and unlocking the driver. There is no mention of HDA codecs, power state changes, or parameters controlling the cleanup. All specific claims about HDA and power state are unsupported, making the majority of details inaccurate."
            ]
        },
        "filter_prorec": {
            "summary": "Releases and cleans up an HDA codec's associated resources, updates linked structures, invokes optional callbacks, and resets hardware-related state fields.",
            "score": [
                0.20000000000000004,
                0.10000000000000002,
                0.0
            ],
            "reason": [
                "The summary inaccurately describes the function as handling an HDA codec and hardware state resets, which are not supported by the source code. The code deals with freeing a sequencer device: it locks a mutex, removes the device from a list, decrements a device count, frees the device, calls an optional private_free callback, and unlocks the driver. No evidence of HDA codec handling or hardware state manipulation exists. Accurate elements are minimal, leading to a low accuracy ratio.",
                "The summary claims actions involving an HDA codec, linked structures, and resetting hardware state fields, none of which are evidenced in the provided code. The source code handles freeing an snd_seq_device, locating its driver, removing it from a list, decrementing device count, invoking an optional private_free callback, freeing memory, and unlocking the driver. All codec-related and hardware-reset details are hallucinated, leaving no accurate overlap with the actual code logic.",
                "The summary claims the function handles an HDA codec, resets hardware state fields, and updates codec-linked structures. The source code instead operates on a generic 'snd_seq_device', frees device resources, updates a driver device list, and calls an optional private_free callback. References to HDA codecs and hardware state resets are unsupported, making most details inaccurate. More than half of the summary's statements have no explicit evidence in the code, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "static void\nmixed_string_buffer_flush_curr (struct mixed_string_buffer *bp)\n{\n  if (bp->curr_type == utf8_encoded)\n    mixed_string_buffer_flush_utf16_surr (bp);\n  if (bp->curr_type != -1)\n    {\n      if (bp->curr_buflen > 0)\n        {\n          struct mixed_string_segment *segment =\n            segment_alloc (bp->curr_type, bp->curr_buffer, bp->curr_buflen);\n          mixed_string_buffer_add_segment (bp, segment);\n        }\n      bp->curr_buflen = 0;\n    }\n}",
    "comment": "Flushes the current buffer to segments based on its type, handling UTF-8 encoding and resetting the buffer length after addition.",
    "prorec_sum": "Buffers the current state and associated data from the provided structure into a dynamically managed list, reallocating storage as necessary.",
    "filter_prorec_sum": "Stores the current item\u2019s state and associated data into a dynamically resized list, clearing temporary buffers and handling specific status codes before insertion.",
    "prorec_aug_sum": "Appends a newly allocated, state-tagged data block from the current buffer into a dynamically resized list and resets the buffer pointer.",
    "filter_prorec_aug_sum": "Flushes the buffered data from the specified structure into a dynamically resized array, allocating and copying its contents along with an associated state byte.",
    "work_score": {
        "prorec": {
            "summary": "Buffers the current state and associated data from the provided structure into a dynamically managed list, reallocating storage as necessary.",
            "score": [
                0.3,
                0.13333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims dynamic reallocation of storage, which is not evidenced in the source code. The code flushes the current buffer into segments, calls specific functions like mixed_string_buffer_flush_utf16_surr, segment_alloc, and mixed_string_buffer_add_segment, but there is no indication of dynamic memory reallocation logic as described. Therefore, the only partially accurate notion is storing buffered data, while the main claim about reallocation is unsupported.",
                "The summary claims buffering of state into a dynamically managed list with reallocation, but the source code explicitly flushes the current buffer if conditions match, creates a segment via segment_alloc, and adds it to the buffer without mentioning any dynamic storage reallocation. The dynamic list concept is only loosely implied and not evidenced in the code, so the described storage management is inaccurate. This leaves almost no accurate details from the summary, missing the explicit control flow and type checks present in the function.",
                "The summary claims dynamic list management and reallocation of storage, but the source code only shows flushing logic with conditional calls to specific functions, structure allocation via segment_alloc, and adding segments. There is no explicit evidence of dynamic reallocation or list management in the form described. The only accurate detail is that data from the structure is processed and stored, meaning the majority of the summary's semantic claims are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Stores the current item\u2019s state and associated data into a dynamically resized list, clearing temporary buffers and handling specific status codes before insertion.",
            "score": [
                0.3,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims handling of a dynamically resized list and specific status codes, neither of which are evidenced in the source code. The source code shows flushing a buffer, optionally processing UTF-16 surrogate pairs, allocating a segment, and adding it to the buffer's segments, with no mention of dynamic resizing or explicit status codes. Only the clearing of temporary buffers and insertion into a collection align somewhat, making most details inaccurate.",
                "The summary's claim about storing state into a dynamically resized list and handling specific status codes is not explicitly evidenced in the source code. The code instead checks the current type, flushes UTF-16 surrogate data if needed, allocates a segment from the current buffer, adds it to the mixed string buffer, and resets the buffer length. There is no mention of dynamic resizing or status codes, making most details inaccurate. Only the concepts of adding a segment and clearing the buffer are accurate, which cover part of the core logic but omit key flow control elements.",
                "The summary claims dynamic resizing, state storage, and handling of specific status codes, none of which are explicitly evident in the source code. The code flushes buffered string segments by checking types, allocating a segment, adding it to a buffer, and resetting the length. As over 50% of the details are inaccurate relative to the source, this triggers the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstruct sequence *\nnew_C_string_sequence (const char * delimitor)\n{\n  struct sequence * res = XMALLOC (struct sequence, 1);\n  res->open = rule_new (xustrdup (delimitor), NULL,\n\t\t\trhs_new_single (NULL, 0, Plain_fface),\n\t\t\t__FILE__, __LINE__);\n  res->face = String_fface;\n  res->exceptions = new_C_exceptions ();\n  res->close = words_new (\"C Close: strings\", \"C Close: regex\", 5, 5);\n  words_add_string (res->close,\n\t\t    rule_new (xustrdup (delimitor), NULL,\n\t\t\t      rhs_new_single (NULL, 0, Plain_fface),\n\t\t\t      __FILE__, __LINE__));\n  words_finalize (res->close);\n  return res;\n}",
    "comment": "Creates and initializes a new string sequence structure with a specified delimiter and associated rules for processing strings.",
    "prorec_sum": "Constructs and returns a structure containing regex patterns for C string handling, including exceptions for escaped quotes, backslashes, and a closing pattern.",
    "filter_prorec_sum": "Builds and returns a structure containing C string handling rules, including escape sequence exceptions and closing patterns, based on the provided delimiter string.",
    "prorec_aug_sum": "Constructs and returns a structure containing C language string and regex exception patterns plus closing rules based on the provided source string.",
    "filter_prorec_aug_sum": "Builds and returns a structure describing C string token handling, adding usual escape sequence exceptions and closing patterns based on the given source string.",
    "work_score": {
        "prorec": {
            "summary": "Constructs and returns a structure containing regex patterns for C string handling, including exceptions for escaped quotes, backslashes, and a closing pattern.",
            "score": [
                0.3,
                0.2333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims explicit regex patterns and exceptions for escaped quotes and backslashes, but the source code only shows creation of `rule_new` and `words_new` structures using the given delimiter, with no direct evidence of regex usage or explicit handling of quotes/backslashes. The closing pattern mentioned in the summary is partially supported by 'C Close: strings' and 'C Close: regex', but the rest are unverifiable. Most details are hallucinations, with only the existence of a closing pattern supported.",
                "The summary claims the function builds regex patterns for C string handling with exceptions for escaped quotes and backslashes, but the source code shows no evidence of regex construction or handling of escaped characters. The code allocates a 'struct sequence', sets fields using provided functions, and adds closing rules, but the specific exceptions mentioned in the summary are not present. After filtering out these inaccurate details, the remaining content only indicates structure initialization and basic rule setup, missing most of the actual stated logic.",
                "The summary claims the function deals with regex patterns for C string handling and includes specific exceptions for escaped quotes and backslashes, but the source code only shows creation of a 'struct sequence' with rules based on the given delimiter, setting faces, creating exceptions via 'new_C_exceptions()', and adding a closing pattern. There is no explicit evidence in the source code that escaped quotes or backslashes are specifically handled, nor that regex patterns are used beyond simple string rules. More than half of the details in the summary are unsupported, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Builds and returns a structure containing C string handling rules, including escape sequence exceptions and closing patterns, based on the provided delimiter string.",
            "score": [
                0.6333333333333334,
                0.6333333333333333,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly notes that the function builds and returns a structure and that it uses the provided delimiter to define rules and closing patterns, which is explicitly shown in `rule_new` and `words_new` calls. However, the claim about 'escape sequence exceptions' is inaccurate; the code calls `new_C_exceptions()` but there is no evidence in the snippet that these are specifically escape sequences\u2014it\u2019s an unverified assumption. Overall, most details are accurate but there is at least one hallucination.",
                "The summary accurately notes that the function builds and returns a structure based on a provided delimiter and implements closing patterns, which match the code\u2019s creation of a struct with open and close rules. However, the mention of 'C string handling rules' and 'escape sequence exceptions' is only partially supported \u2014 while the code sets res->face to String_fface and creates exceptions via new_C_exceptions, it does not explicitly show handling of escape sequences. The accurate elements capture the main construction and purpose of the struct, but omit details like specific function calls and initialization flow beyond high-level features.",
                "The summary mentions C string handling rules and closing patterns, which are supported by the code via 'String_fface', 'words_new', and adding rules based on the provided delimiter. However, it also claims inclusion of escape sequence exceptions, which is inaccurate\u2014the code creates 'new_C_exceptions()' but does not explicitly indicate they are escape sequences. Since only one clear inaccuracy exists and most other details are supported, the proportion of inaccurate details is below the threshold. The accurate portions provide moderately specific domain insights about how the structure is populated."
            ]
        }
    }
}
{
    "source_code": "int mmc_get_phys_format_info(struct burn_drive *d, int *disk_category,\n\t\t\tchar **book_name, int *part_version, int *num_layers,\n\t\t\tint *num_blocks, int flag)\n{\n\tint ret, reply_len, prf;\n\tchar *reply = NULL;\n\tstatic char book_names[][16] = {\n\t\t\"DVD-ROM\", \"DVD-RAM\", \"DVD-R\", \"DVD-RW\",\n\t\t\"HD DVD-ROM\", \"HD DVD-RAM\", \"HD DVD-R\", \"unknown\",\n\t\t\"unknown\", \"DVD+RW\", \"DVD+R\", \"unknown\", \"unknown\",\n\t\t\"unknown\", \"DVD+RW DL\", \"DVD+R DL\", \"unknown\"\n\t};\n\n\tprf = d->current_profile;\n\tif (!(prf == 0x11 || prf == 0x13 || prf == 0x14 || prf == 0x15 ||\n\t      prf == 0x51))\n\t\treturn 0; /* Not a [HD] DVD-R[W] loaded */\n\tret = mmc_read_disc_structure(d, 0, 0, 0x10, 12, &reply,\n\t\t\t\t\t\t\t &reply_len, 0);\n\tif (ret <= 0)\n\t\tgoto ex;\n\tif(reply_len < 12) {\n\t\tlibdax_msgs_submit(libdax_messenger, -1, 0x00000002,\n\t\t\tLIBDAX_MSGS_SEV_DEBUG, LIBDAX_MSGS_PRIO_ZERO,\n\t\t\t\"READ DISC STRUCTURE format 10h: Less than 12 bytes\",\n\t\t\t0, 0);\n\t\t{ret = 0; goto ex;}\n\t}\n\t*disk_category = (reply[0] >> 4) & 0xf;\n\t*book_name = book_names[*disk_category];\n\t*part_version = reply[0] & 0xf;\n\t*num_layers = ((reply[2] >> 5) & 0x3) + 1;\n\t*num_blocks = ((reply[9] << 16) | (reply[10] << 8) | reply[11]) -\n\t              ((reply[5] << 16) | (reply[6] << 8) | reply[7]) + 1;\n\tret = 1;\nex:;\n\tif (reply != NULL)\n\t\tfree(reply);\n\treturn ret;\n}",
    "comment": "Retrieves physical format information of a disc in the drive, including disk category, book name, version, layer count, and block count.",
    "prorec_sum": "Reads a disc structure in format 0x10, extracts header fields, computes sector range, and returns parsed values to caller-provided pointers.",
    "filter_prorec_sum": "Parses the \u201cREAD DISC STRUCTURE\u201d format 0x10h response to extract disc metadata fields and stores them into provided output parameters.",
    "prorec_aug_sum": "Extracts and returns disc structure format 0x10h fields from a device, computing address, layer info, and sector span, then frees allocated buffer.",
    "filter_prorec_aug_sum": "Extracts and returns disc structure format 0x10 details, including layer, address, track, and sector count, freeing allocated buffer after processing.",
    "work_score": {
        "prorec": {
            "summary": "Reads a disc structure in format 0x10, extracts header fields, computes sector range, and returns parsed values to caller-provided pointers.",
            "score": [
                1.0,
                0.6666666666666666,
                0.8333333333333334
            ],
            "reason": [
                "The summary accurately states that the function reads disc structure format 0x10, extracts header fields, computes a value based on sector range, and returns parsed results through caller-provided pointers. All these actions are explicitly evidenced in the source code via the call to mmc_read_disc_structure, bit manipulations on reply data for header fields, arithmetic on indices for num_blocks, and assignment to output pointers. There are no unverified or hallucinated claims beyond what the code shows.",
                "The summary accurately states that the disc structure is read in format 0x10 and that values are parsed into caller-provided pointers, as seen from the mmc_read_disc_structure call and the subsequent assignments to disk_category, book_name, part_version, num_layers, and num_blocks. It correctly notes the extraction of header fields and computation of the sector range via arithmetic on reply bytes. However, the summary omits important control flow details such as profile checks, error handling for invalid reply lengths, and memory cleanup, which are critical parts of the code's logic.",
                "The summary\u2019s claims are mostly accurate: the code calls mmc_read_disc_structure with format 0x10, reads fields from the reply buffer corresponding to header bits, calculates disk_category, book_name, part_version, num_layers, and num_blocks (sector range), and stores them in caller-provided pointers. All these actions are explicitly supported by the source. There are no hallucinated details, but the summary is somewhat generic and does not mention specifics such as the profile checks, the reply length validation, or the exact computations performed, limiting domain-rich insight."
            ]
        },
        "filter_prorec": {
            "summary": "Parses the \u201cREAD DISC STRUCTURE\u201d format 0x10h response to extract disc metadata fields and stores them into provided output parameters.",
            "score": [
                1.0,
                0.6333333333333333,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function processes a 'READ DISC STRUCTURE' format 0x10h response and extracts metadata into output parameters, which is explicitly shown in the code through the call to mmc_read_disc_structure with 0x10, parsing of reply buffer fields, and assignment to disk_category, book_name, part_version, num_layers, and num_blocks. No unverified or hallucinated details are present.",
                "The summary correctly identifies that the function processes the READ DISC STRUCTURE format 0x10h response and extracts disc metadata into the provided output parameters. This is explicitly supported by the call to mmc_read_disc_structure with format 0x10, the subsequent parsing of the reply buffer to set disk_category, book_name, part_version, num_layers, and num_blocks. However, the summary omits important control flow such as profile checks, error handling for short replies, and memory cleanup, which are critical semantic units in the code.",
                "The summary correctly states that the function processes a READ DISC STRUCTURE format 0x10h response to extract disc metadata and store it in output parameters. This is directly evidenced by the call to mmc_read_disc_structure with 0x10, and subsequent parsing of reply bytes into disk_category, book_name, part_version, num_layers, and num_blocks. No inaccuracies are present, and the details are domain-specific and informative."
            ]
        }
    }
}
{
    "source_code": "int aaip_add_acl_st_mode(char *acl_text, mode_t st_mode, int flag)\n{\n char *wpt;\n int tag_types= 0;\n\n tag_types = aaip_cleanout_st_mode(acl_text, &st_mode, 1);\n if(!(tag_types & (4 | 32))) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"user::%c%c%c\\n\",\n           st_mode & S_IRUSR ? 'r' : '-',\n           st_mode & S_IWUSR ? 'w' : '-',\n           st_mode & S_IXUSR ? 'x' : '-');\n }\n if(!(tag_types & (2 | 16 | 1024))) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"group::%c%c%c\\n\",\n         st_mode & S_IRGRP ? 'r' : '-',\n         st_mode & S_IWGRP ? 'w' : '-',\n         st_mode & S_IXGRP ? 'x' : '-');\n }\n if(!(tag_types & (1 | 8))) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"other::%c%c%c\\n\",\n         st_mode & S_IROTH ? 'r' : '-',\n         st_mode & S_IWOTH ? 'w' : '-',\n         st_mode & S_IXOTH ? 'x' : '-');\n }\n if((tag_types & (128 | 256)) && !(tag_types & 512)) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"mask::%c%c%c\\n\",\n         st_mode & S_IRGRP ? 'r' : '-',\n         st_mode & S_IWGRP ? 'w' : '-',\n         st_mode & S_IXGRP ? 'x' : '-');\n }\n return(1); \n}",
    "comment": "Adds entries for user, group, other, and mask permissions to an ACL string based on the provided `mode_t` and existing ACL tags.",
    "prorec_sum": "Formats and appends user, group, other, and mask permission strings to the buffer based on access control bits from the provided flags.",
    "filter_prorec_sum": "Formats and appends user, group, other, and mask permission strings with rwx indicators to the provided buffer based on given access flags.",
    "prorec_aug_sum": "Formats and appends user, group, other, and mask permission strings to the buffer based on specific bits in the provided mode value.",
    "filter_prorec_aug_sum": "Formats and appends user, group, other, and mask POSIX-style rwx permission strings to the provided buffer based on the given mode bits.",
    "work_score": {
        "prorec": {
            "summary": "Formats and appends user, group, other, and mask permission strings to the buffer based on access control bits from the provided flags.",
            "score": [
                1.0,
                0.6999999999999998,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function formats and appends user, group, other, and mask permission strings to a buffer, as evidenced by the multiple sprintf calls for each category conditional on specific tag_types bits. It also accurately notes that these are based on access control bits derived from st_mode and flags, which matches the bitwise checks using S_IRUSR, S_IWUSR, etc. No significant details are inaccurate or missing, so accuracy is very high.",
                "The summary accurately states that the function formats and appends user, group, other, and mask permission strings to the buffer based on st_mode bits, and this is explicitly supported by the source code, which uses sprintf with permission checks and conditional blocks for each of these categories. However, the summary omits details about the conditional logic based on tag_types flags and the prior call to aaip_cleanout_st_mode, which are important parts of the code\u2019s control flow and edge case handling.",
                "The summary correctly identifies that the function appends user, group, other, and mask permission strings to the buffer based on access control bits from st_mode and tag_types. This is explicitly shown in the source code via conditional checks on tag_types and sprintf calls for each permission category. However, the summary inaccurately states that permissions are based on 'provided flags' without specifying st_mode or tag_types as the actual sources. The majority of details are accurate and domain-specific, describing the logic structure and data handling clearly."
            ]
        },
        "filter_prorec": {
            "summary": "Formats and appends user, group, other, and mask permission strings with rwx indicators to the provided buffer based on given access flags.",
            "score": [
                1.0,
                0.6999999999999998,
                0.7999999999999999
            ],
            "reason": [
                "The summary accurately describes the function\u2019s purpose: it appends user, group, other, and mask permission strings with rwx indicators to the provided buffer based on conditions from tag_types and st_mode. All mentioned entities (user, group, other, mask, rwx indicators, buffer appending logic) are explicitly present in the source code, and no unverified assumptions were made.",
                "The summary accurately reflects that the function appends formatted permission strings for user, group, other, and mask with rwx indicators to the buffer, and that this behavior depends on certain bitwise checks against tag_types, which are derived from st_mode and flags. These details match the source code's control flow and string formatting logic. It does not mention edge conditions like the specific bit masks used for deciding whether to append each section, which means some completeness is lacking.",
                "The summary accurately reflects the main function behavior: it formats and appends permission strings for user, group, other, and mask using rwx indicators based on st_mode and certain tag_type flags, which matches the conditional logic and sprintf calls in the source code. All described elements (entities, rwx formatting, buffer modification) have explicit evidence in the source code, with no inaccurate details. While correct, the description is somewhat generic and omits specifics such as the bitmask values checked or the use of aaip_cleanout_st_mode, reducing its domain-rich depth."
            ]
        }
    }
}
{
    "source_code": "int get_counters(struct thread_data *t, struct core_data *c, struct pkg_data *p)\n{\n\tint cpu = t->cpu_id;\n\tunsigned long long msr;\n\n\tif (cpu_migrate(cpu)) {\n\t\tfprintf(stderr, \"Could not migrate to CPU %d\\n\", cpu);\n\t\treturn -1;\n\t}\n\n\tt->tsc = rdtsc();\t/* we are running on local CPU of interest */\n\n\tif (has_aperf) {\n\t\tif (get_msr(cpu, MSR_IA32_APERF, &t->aperf))\n\t\t\treturn -3;\n\t\tif (get_msr(cpu, MSR_IA32_MPERF, &t->mperf))\n\t\t\treturn -4;\n\t}\n\n\tif (do_smi) {\n\t\tif (get_msr(cpu, MSR_SMI_COUNT, &msr))\n\t\t\treturn -5;\n\t\tt->smi_count = msr & 0xFFFFFFFF;\n\t}\n\tif (extra_delta_offset32) {\n\t\tif (get_msr(cpu, extra_delta_offset32, &msr))\n\t\t\treturn -5;\n\t\tt->extra_delta32 = msr & 0xFFFFFFFF;\n\t}\n\n\tif (extra_delta_offset64)\n\t\tif (get_msr(cpu, extra_delta_offset64, &t->extra_delta64))\n\t\t\treturn -5;\n\n\tif (extra_msr_offset32) {\n\t\tif (get_msr(cpu, extra_msr_offset32, &msr))\n\t\t\treturn -5;\n\t\tt->extra_msr32 = msr & 0xFFFFFFFF;\n\t}\n\n\tif (extra_msr_offset64)\n\t\tif (get_msr(cpu, extra_msr_offset64, &t->extra_msr64))\n\t\t\treturn -5;\n\n\t/* collect core counters only for 1st thread in core */\n\tif (!(t->flags & CPU_IS_FIRST_THREAD_IN_CORE))\n\t\treturn 0;\n\n\tif (do_nhm_cstates) {\n\t\tif (get_msr(cpu, MSR_CORE_C3_RESIDENCY, &c->c3))\n\t\t\treturn -6;\n\t\tif (get_msr(cpu, MSR_CORE_C6_RESIDENCY, &c->c6))\n\t\t\treturn -7;\n\t}\n\n\tif (do_snb_cstates)\n\t\tif (get_msr(cpu, MSR_CORE_C7_RESIDENCY, &c->c7))\n\t\t\treturn -8;\n\n\tif (do_dts) {\n\t\tif (get_msr(cpu, MSR_IA32_THERM_STATUS, &msr))\n\t\t\treturn -9;\n\t\tc->core_temp_c = tcc_activation_temp - ((msr >> 16) & 0x7F);\n\t}\n\n\n\t/* collect package counters only for 1st core in package */\n\tif (!(t->flags & CPU_IS_FIRST_CORE_IN_PACKAGE))\n\t\treturn 0;\n\n\tif (do_nhm_cstates) {\n\t\tif (get_msr(cpu, MSR_PKG_C3_RESIDENCY, &p->pc3))\n\t\t\treturn -9;\n\t\tif (get_msr(cpu, MSR_PKG_C6_RESIDENCY, &p->pc6))\n\t\t\treturn -10;\n\t}\n\tif (do_snb_cstates) {\n\t\tif (get_msr(cpu, MSR_PKG_C2_RESIDENCY, &p->pc2))\n\t\t\treturn -11;\n\t\tif (get_msr(cpu, MSR_PKG_C7_RESIDENCY, &p->pc7))\n\t\t\treturn -12;\n\t}\n\tif (do_c8_c9_c10) {\n\t\tif (get_msr(cpu, MSR_PKG_C8_RESIDENCY, &p->pc8))\n\t\t\treturn -13;\n\t\tif (get_msr(cpu, MSR_PKG_C9_RESIDENCY, &p->pc9))\n\t\t\treturn -13;\n\t\tif (get_msr(cpu, MSR_PKG_C10_RESIDENCY, &p->pc10))\n\t\t\treturn -13;\n\t}\n\tif (do_rapl & RAPL_PKG) {\n\t\tif (get_msr(cpu, MSR_PKG_ENERGY_STATUS, &msr))\n\t\t\treturn -13;\n\t\tp->energy_pkg = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_CORES) {\n\t\tif (get_msr(cpu, MSR_PP0_ENERGY_STATUS, &msr))\n\t\t\treturn -14;\n\t\tp->energy_cores = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_DRAM) {\n\t\tif (get_msr(cpu, MSR_DRAM_ENERGY_STATUS, &msr))\n\t\t\treturn -15;\n\t\tp->energy_dram = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_GFX) {\n\t\tif (get_msr(cpu, MSR_PP1_ENERGY_STATUS, &msr))\n\t\t\treturn -16;\n\t\tp->energy_gfx = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_PKG_PERF_STATUS) {\n\t\tif (get_msr(cpu, MSR_PKG_PERF_STATUS, &msr))\n\t\t\treturn -16;\n\t\tp->rapl_pkg_perf_status = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_DRAM_PERF_STATUS) {\n\t\tif (get_msr(cpu, MSR_DRAM_PERF_STATUS, &msr))\n\t\t\treturn -16;\n\t\tp->rapl_dram_perf_status = msr & 0xFFFFFFFF;\n\t}\n\tif (do_ptm) {\n\t\tif (get_msr(cpu, MSR_IA32_PACKAGE_THERM_STATUS, &msr))\n\t\t\treturn -17;\n\t\tp->pkg_temp_c = tcc_activation_temp - ((msr >> 16) & 0x7F);\n\t}\n\treturn 0;\n}",
    "comment": "Aggregates packet and byte counters from multiple CPU entries into a single counter array based on the provided old counters.",
    "prorec_sum": "Iterates over indexed data structures, waiting on lock flags and aggregating 64\u2011bit values into an output buffer until all entries are processed.",
    "filter_prorec_sum": "Iterates through indexed data blocks, aggregating two 64\u2011bit fields into an output array while handling concurrent access through version and lock checks.",
    "prorec_aug_sum": "Iterates over table entries, accumulating two 64\u2011bit counter values into an output array while synchronizing with a lock variable to avoid concurrent modifications.",
    "filter_prorec_aug_sum": "Iterates over indexed data blocks, summing two 64-bit fields into an output array while synchronizing access using version checks and spin-waiting on a lock flag.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over indexed data structures, waiting on lock flags and aggregating 64\u2011bit values into an output buffer until all entries are processed.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes iteration over indexed data structures, lock handling, and aggregation of 64-bit values into an output buffer, but none of these details are supported by the source code. The code reads MSR registers for various CPU and package counters, applies conditional logic based on flags, and stores results into struct fields; there is no evidence of locks, explicit iteration over indexed structures, or output buffer aggregation. All details in the summary are inaccurate.",
                "The summary's claims about iterating over indexed data structures, waiting on lock flags, and aggregating 64-bit values into an output buffer are unsupported by the source code. The function get_counters primarily retrieves MSR values for specific CPU, core, and package counters with conditional checks and error handling, without any loops over data structures or lock mechanisms. After discarding these inaccurate details, no accurate content remains to map to critical semantic units.",
                "The summary describes iteration over indexed data structures, lock handling, and aggregation into an output buffer, none of which are present in the source code. The actual code reads MSR registers for various counters and conditionally populates struct fields based on feature flags, with no evidence of locks, indexed data structures, or aggregation loops. All details in the summary are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates through indexed data blocks, aggregating two 64\u2011bit fields into an output array while handling concurrent access through version and lock checks.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes iteration over indexed data blocks, aggregation of 64\u2011bit fields, and concurrency management via version and lock checks. None of these details are supported by the source code, which instead retrieves MSR values for various CPU and package counters without any indexed block iteration, aggregation logic, or explicit concurrency mechanisms. All details in the summary are hallucinated, resulting in no alignment with the source.",
                "The summary claims iteration over data blocks, aggregation of 64\u2011bit fields, and concurrency control with locks and version checks, none of which are supported by the code. The source code collects CPU, core, and package MSR counters, performs error handling via conditional returns, and manages flags for specific counter reads, but no array aggregation or locking logic exists. Therefore, all described details are inaccurate and the summary fails to capture any real aspects of the implementation.",
                "The summary claims iteration through indexed data blocks, aggregation of two 64-bit fields, and concurrent access handling via version and lock checks. None of these elements are present in the source code. The code instead retrieves MSR register values for various CPU, core, and package counters, with no evidence of indexed data blocks, aggregation logic, or concurrency mechanisms. All stated details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic R_xlen_t\ncompact_intseq_Get_region(SEXP sx, R_xlen_t i, R_xlen_t n, int *buf)\n{\n    /* should not get here if x is already expanded */\n    CHECK_NOT_EXPANDED(sx);\n\n    SEXP info = COMPACT_SEQ_INFO(sx);\n    R_xlen_t size = COMPACT_INTSEQ_INFO_LENGTH(info);\n    R_xlen_t n1 = COMPACT_INTSEQ_INFO_FIRST(info);\n    int inc = COMPACT_INTSEQ_INFO_INCR(info);\n\n    R_xlen_t ncopy = size - i > n ? n : size - i;\n    if (inc == 1) {\n\tfor (R_xlen_t k = 0; k < ncopy; k++)\n\t    buf[k] = (int) (n1 + k + i);\n\treturn ncopy;\n    }\n    else if (inc == -1) {\n\tfor (R_xlen_t k = 0; k < ncopy; k++)\n\t    buf[k] = (int) (n1 - k - i);\n\treturn ncopy;\n    }\n    else\n\terror(\"compact sequences with increment %d not supported yet\", inc);\n}",
    "comment": "Extracts a specified region from a compact integer sequence into a buffer, handling both increasing and decreasing increments.",
    "prorec_sum": "Generates a sequence of integer indices from vector metadata, supporting increments of 1 or -1, and raises errors for unsupported increments or expanded vectors.",
    "filter_prorec_sum": "Generates a sequence of integer indices from vector metadata, erroring on unsupported increments, and stores them in the provided output array.",
    "prorec_aug_sum": "Generates a sequence of integer indices from compact vector metadata, supporting increments of 1 or -1, and reports unsupported increments via error.",
    "filter_prorec_aug_sum": "Generates a sequence of integer indices from vector metadata, supporting only increments of 1 or -1, and throws errors for unsupported cases.",
    "work_score": {
        "prorec": {
            "summary": "Generates a sequence of integer indices from vector metadata, supporting increments of 1 or -1, and raises errors for unsupported increments or expanded vectors.",
            "score": [
                0.9333333333333332,
                0.8666666666666667,
                0.9
            ],
            "reason": [
                "The summary correctly identifies that the function generates integer values based on vector metadata, supports increments of 1 and -1, and raises errors for unsupported increments. This is explicitly reflected in the source code via the increment checks and error call. However, the claim about raising errors for expanded vectors is inaccurate\u2014expanded vectors are prevented from reaching this code using CHECK_NOT_EXPANDED, but no error is raised for them here. Overall, most details are accurate with only one unverified assumption.",
                "The summary accurately mentions generating an integer sequence from vector metadata, supporting increments of 1 and -1, and raising errors for unsupported increments. It also correctly notes error handling for expanded vectors via CHECK_NOT_EXPANDED. These details match explicit logic in the source such as variable initialization from COMPACT_SEQ_INFO and conditional loops for inc == 1 or inc == -1. The coverage includes core logic and edge cases, forming a complete picture of the code's behavior.",
                "The summary claims the function generates integer indices from vector metadata, supports increments of 1 or -1, and raises errors for unsupported increments or expanded vectors. All of these details are explicitly supported in the source code: COMPACT_SEQ_INFO and related macros extract metadata, loops handle inc == 1 and inc == -1, and error calls cover unsupported increments, while CHECK_NOT_EXPANDED enforces the expanded vector check. These accurate, domain-specific details directly match the code\u2019s logic and data handling."
            ]
        },
        "filter_prorec": {
            "summary": "Generates a sequence of integer indices from vector metadata, erroring on unsupported increments, and stores them in the provided output array.",
            "score": [
                1.0,
                0.7999999999999999,
                0.7000000000000001
            ],
            "reason": [
                "The summary accurately states that the function generates a sequence of integer indices derived from vector metadata (`COMPACT_INTSEQ_INFO_FIRST`, `INCR`, and `LENGTH`), stores them in the provided buffer, and raises an error for unsupported increments. All of these details are explicitly present in the source code. There are no unverified or hallucinated claims, resulting in a high accuracy ratio.",
                "The summary accurately captures that the function generates integer sequences based on metadata, writes them to the output buffer, and raises an error for unsupported increments. These details are explicitly present in the source code through the extraction of `size`, `n1`, `inc`, the conditional handling of `inc` values 1 and -1, and the `error` call for unsupported increments. However, the summary omits the edge-case logic involving bounds calculation (`ncopy`) and the two specific increment directions, so it does not fully represent the complete control flow.",
                "The summary accurately reflects the function's behavior: it uses vector metadata (via COMPACT_INTSEQ_INFO_* calls) to generate integer values based on an increment, writes them to the provided buffer, and raises an error for unsupported increments. All details are explicitly supported by the source code, with no hallucinations. However, the description is somewhat generic and lacks deeper detail about the bidirectional increment handling or exact conditions, so its domain richness is moderate."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\nxmlIsDocNameStartChar(xmlDocPtr doc, int c) {\n    if ((doc == NULL) || (doc->properties & XML_DOC_OLD10) == 0) {\n        /*\n\t * Use the new checks of production [4] [4a] amd [5] of the\n\t * Update 5 of XML-1.0\n\t */\n\tif (((c >= 'a') && (c <= 'z')) ||\n\t    ((c >= 'A') && (c <= 'Z')) ||\n\t    (c == '_') || (c == ':') ||\n\t    ((c >= 0xC0) && (c <= 0xD6)) ||\n\t    ((c >= 0xD8) && (c <= 0xF6)) ||\n\t    ((c >= 0xF8) && (c <= 0x2FF)) ||\n\t    ((c >= 0x370) && (c <= 0x37D)) ||\n\t    ((c >= 0x37F) && (c <= 0x1FFF)) ||\n\t    ((c >= 0x200C) && (c <= 0x200D)) ||\n\t    ((c >= 0x2070) && (c <= 0x218F)) ||\n\t    ((c >= 0x2C00) && (c <= 0x2FEF)) ||\n\t    ((c >= 0x3001) && (c <= 0xD7FF)) ||\n\t    ((c >= 0xF900) && (c <= 0xFDCF)) ||\n\t    ((c >= 0xFDF0) && (c <= 0xFFFD)) ||\n\t    ((c >= 0x10000) && (c <= 0xEFFFF)))\n\t    return(1);\n    } else {\n        if (IS_LETTER(c) || (c == '_') || (c == ':'))\n\t    return(1);\n    }\n    return(0);\n}",
    "comment": "Determines if a character is a valid starting character for an XML document name based on XML-1.0 specifications or old document properties.",
    "prorec_sum": "Checks whether a given Unicode codepoint is an allowed XML name character, considering specific ranges and a flag in the input structure.",
    "filter_prorec_sum": "Determines if a given Unicode codepoint is allowed as part of an XML name, considering configuration flags and XML character classification rules.",
    "prorec_aug_sum": "Checks whether a given Unicode code point is an accepted name character based on XML naming rules and an optional parsing context flag.",
    "filter_prorec_aug_sum": "Determines if a given Unicode code point is an allowed XML name character, considering parser state and specific character range rules.",
    "work_score": {
        "prorec": {
            "summary": "Checks whether a given Unicode codepoint is an allowed XML name character, considering specific ranges and a flag in the input structure.",
            "score": [
                1.0,
                0.7000000000000001,
                0.7666666666666666
            ],
            "reason": [
                "The summary correctly identifies the function as checking whether a given Unicode codepoint is an allowed XML name character, and notes consideration of specific ranges and a flag in the input structure. These are explicitly supported by the source code: it inspects numeric ranges, certain characters, and a property flag in the doc struct. No elements in the summary appear to be hallucinated, indicating full alignment with the code.",
                "The summary correctly states that the function checks whether a Unicode codepoint is an allowed XML name character and that it considers specific ranges and a flag in the input structure. These are explicitly present in the code: multiple range checks on 'c' and a conditional based on 'doc->properties' and XML_DOC_OLD10. However, the summary omits important details such as the distinction between 'start characters' and general name characters, the use of IS_LETTER macro in the old-XML path, and the exact control flow for the flag check, resulting in a partial but not complete picture of the logic.",
                "The summary correctly captures the core logic of the function: it checks whether a Unicode codepoint is an allowed XML name start character and considers specific numeric ranges along with a property flag from the input `xmlDocPtr`. All elements are supported by the source code, including the conditional on `doc->properties & XML_DOC_OLD10` and the explicit Unicode ranges. These details are accurate and domain-specific, providing meaningful insight into the implementation."
            ]
        },
        "filter_prorec": {
            "summary": "Determines if a given Unicode codepoint is allowed as part of an XML name, considering configuration flags and XML character classification rules.",
            "score": [
                0.9333333333333332,
                0.6666666666666666,
                0.7000000000000001
            ],
            "reason": [
                "The summary states that the function checks if a Unicode codepoint is allowed in an XML name based on configuration flags and XML character classification. This is accurate: the source code evaluates character ranges and specific symbols allowed at the start of an XML name, and it branches based on the 'doc->properties' flag (specifically XML_DOC_OLD10). All semantic details in the summary are explicitly supported by the code, with no extraneous or unverifiable claims.",
                "The summary accurately states that the function checks whether a given Unicode codepoint is valid for XML names, taking into account configuration flags (`doc->properties & XML_DOC_OLD10`) and character classification rules. These elements are explicitly present in the source code, which includes conditional logic to apply different sets of character ranges or `IS_LETTER` checks depending on the flag. However, the summary slightly generalizes the character classification as 'XML character classification rules' without detailing the specific ranges, which omits a key part of the logic, such as the numerous Unicode ranges handled. This results in an incomplete picture.",
                "The summary correctly captures that the function checks a Unicode codepoint against XML naming rules and considers a configuration flag (doc->properties & XML_DOC_OLD10). These details are supported by the source code, which uses conditional logic to apply different character range checks based on the flag. However, the summary is generic and omits the explicit character ranges and branching logic present, providing limited domain-specific insight."
            ]
        }
    }
}
{
    "source_code": "\nstatic void uncore_pci_remove(struct pci_dev *pdev)\n{\n\tstruct intel_uncore_box *box = pci_get_drvdata(pdev);\n\tstruct intel_uncore_pmu *pmu = box->pmu;\n\tint cpu, phys_id = pcibus_to_physid[pdev->bus->number];\n\n\tif (WARN_ON_ONCE(phys_id != box->phys_id))\n\t\treturn;\n\n\tpci_set_drvdata(pdev, NULL);\n\n\traw_spin_lock(&uncore_box_lock);\n\tlist_del(&box->list);\n\traw_spin_unlock(&uncore_box_lock);\n\n\tfor_each_possible_cpu(cpu) {\n\t\tif (*per_cpu_ptr(pmu->box, cpu) == box) {\n\t\t\t*per_cpu_ptr(pmu->box, cpu) = NULL;\n\t\t\tatomic_dec(&box->refcnt);\n\t\t}\n\t}\n\n\tWARN_ON_ONCE(atomic_read(&box->refcnt) != 1);\n\tkfree(box);\n}",
    "comment": "Removes an uncore PCI device, updates reference counts, and frees associated resources while ensuring proper synchronization in a multi-CPU environment.",
    "prorec_sum": "Unregisters an Intel uncore performance event, clears associated links, updates reference counts, and logs diagnostic messages on unexpected states.",
    "filter_prorec_sum": "Removes and unlinks an Intel uncore performance event object from related structures, updates counters, and logs anomalies during the cleanup process.",
    "prorec_aug_sum": "Unregisters and cleans up an Intel uncore performance event, removing references, updating counters, and logging state inconsistencies.",
    "filter_prorec_aug_sum": "Removes and cleans up an Intel uncore performance monitoring unit, unlinking references, updating counters, and logging inconsistencies during the teardown process.",
    "work_score": {
        "prorec": {
            "summary": "Unregisters an Intel uncore performance event, clears associated links, updates reference counts, and logs diagnostic messages on unexpected states.",
            "score": [
                0.6,
                0.5666666666666668,
                0.6666666666666666
            ],
            "reason": [
                "The summary contains multiple semantic claims: unregistering an Intel uncore performance event, clearing associated links, updating reference counts, and logging diagnostic messages on unexpected states. 'Clears associated links' is accurate as evidenced by list_del and pci_set_drvdata. 'Updates reference counts' is accurate with atomic_dec and atomic_read. 'Logs diagnostic messages on unexpected states' is accurate via WARN_ON_ONCE. However, 'unregisters an Intel uncore performance event' is inaccurate, as the code removes a PCI device instance and associated box/PMU references rather than unregistering a performance event. With two accurate and one inaccurate claim, accuracy ratio is about 75%, indicating mixed correctness.",
                "The summary correctly notes clearing associated links and updating reference counts, as evidenced by `list_del`, `pci_set_drvdata` and `atomic_dec` in the source code. However, it inaccurately claims unregistration of a performance event, which is not explicitly shown, and mentions logging diagnostic messages, while the code only uses `WARN_ON_ONCE` macros, not explicit logging. These inaccuracies mean the accurate portion covers some of the main operations but omits details about control flow, error handling, and freeing memory, resulting in partial coverage.",
                "The summary claims that the function unregisters an Intel uncore performance event and logs diagnostic messages. The source code does use WARN_ON_ONCE, which aligns with logging diagnostics on unexpected states, and it updates reference counts via atomic_dec and clears associated links through list_del and pci_set_drvdata. However, there is no explicit evidence of 'unregistering' a performance event\u2014only removal of data structures\u2014and the description of 'unregisters an Intel uncore performance event' is not directly supported. With one major detail inaccurate and the rest accurate, the proportion of inaccurate details is below the kill switch threshold, but the accurate details are somewhat generic."
            ]
        },
        "filter_prorec": {
            "summary": "Removes and unlinks an Intel uncore performance event object from related structures, updates counters, and logs anomalies during the cleanup process.",
            "score": [
                1.0,
                0.7666666666666666,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function removes and unlinks an Intel uncore performance event object (the 'box') from related structures (e.g., list_del, pci_set_drvdata) and updates counters (atomic_dec on refcnt). It also mentions logging anomalies, which aligns with WARN_ON_ONCE calls in the code. All stated details are explicitly supported by the source code, with no unverifiable or hallucinated claims.",
                "The summary accurately reflects the function's behavior: it removes the Intel uncore performance event object (via kfree(box)), unlinks it from internal lists (list_del under spinlock), updates counters (atomic_dec on refcnt), and logs anomalies (WARN_ON_ONCE checks) during cleanup. All these details are explicitly present in the source code, and the description covers the main control flow and cleanup logic without introducing inaccuracies.",
                "The summary accurately reflects the source code's logic: it removes an Intel uncore performance object (via kfree) from related structures (list_del on box->list), updates counters (atomic_dec on refcnt), and logs anomalies (WARN_ON_ONCE checks). All these actions are explicitly present in the code, with no fabricated details. The accurate details are specific to kernel-level PCI driver cleanup processes, showing domain-rich insights."
            ]
        }
    }
}
{
    "source_code": "\nstatic void sig_child_handler(int sig_no UNUSED_PARAM)\n{\n\tpid_t pid;\n\tint l;\n\n\tif (verbose)\n\t\tbb_error_msg(INFO\"sig%s received\", \"child\");\n\twhile ((pid = wait_any_nohang(&wstat)) > 0) {\n\t\tfor (l = 0; l < dirn; ++l) {\n\t\t\tif (dir[l].ppid == pid) {\n\t\t\t\tdir[l].ppid = 0;\n\t\t\t\tprocessorstop(&dir[l]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}",
    "comment": "Handles SIGCHLD signals by cleaning up and processing terminated child processes that match entries in the directory.",
    "prorec_sum": "Processes incoming event codes, logs an \u201cend\u201d message with type and signal info, and conditionally invokes a follow\u2011up handler based on global state.",
    "filter_prorec_sum": "Processes incoming events from `sub_518073`, logs their type as \"signal\" or \"exit\", and triggers follow-up handling when the global flag is set.",
    "prorec_aug_sum": "Processes input events in a loop, logging termination or signal details for each, and invokes a final handler if an active session flag is set.",
    "filter_prorec_aug_sum": "Processes input event codes, logs an \"end\" message with type and details, and conditionally triggers a follow\u2011up routine based on global state.",
    "work_score": {
        "prorec": {
            "summary": "Processes incoming event codes, logs an \u201cend\u201d message with type and signal info, and conditionally invokes a follow\u2011up handler based on global state.",
            "score": [
                0.26666666666666666,
                0.16666666666666666,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccurate details. The source code handles the SIGCHLD signal, logs a message containing \"sig\" and signal info when verbose mode is enabled, and iterates over a global array to stop a processor if its ppid matches. However, there is no explicit handling of 'event codes', no logging of an 'end' message, and no reference to a 'type' in the log. The follow\u2011up handler mentioned is processorstop, but it is not conditionally invoked based on arbitrary global state beyond pid matching. Most claims are unsupported, resulting in a low accuracy ratio.",
                "The summary claims the code processes event codes, logs an 'end' message with type and signal info, and invokes a follow-up handler based on global state. In the source, the function handles SIGCHLD signals, logs a 'sigchild received' message when verbose is set, waits for child processes, updates a process table, and calls 'processorstop'. No 'end' message, event codes, or type-specific logging is present; these are hallucinations. The only accurate detail is the conditional handler invocation based on global state ('verbose'), but this is a small fraction of the overall logic, leaving much of the code's core behavior unrepresented.",
                "The summary claims that the function processes event codes, logs an 'end' message with type and signal info, and conditionally invokes a follow-up handler based on global state. The source code shows a signal handler for SIGCHLD that logs a message when verbose is enabled, waits for child processes without hanging, and updates 'dir' entries before calling 'processorstop'. There is no indication of 'event codes', an 'end' message, or generic 'type and signal info' beyond the hardcoded 'child' string. At least two of the three claims are unsupported, exceeding the 50% inaccuracy threshold."
            ]
        },
        "filter_prorec": {
            "summary": "Processes incoming events from `sub_518073`, logs their type as \"signal\" or \"exit\", and triggers follow-up handling when the global flag is set.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims handling of incoming events from `sub_518073`, logging their type as \"signal\" or \"exit\", and conditional follow-up based on a global flag. None of these elements are present in the source code. The code defines `sig_child_handler`, uses `wait_any_nohang`, iterates through `dir` array, sets `ppid` to 0, and calls `processorstop`. There is no function named `sub_518073`, no explicit logging of event type as \"signal\" or \"exit\", and no logic contingent on a global flag beyond the `verbose` condition. All listed details in the summary are unsupported, resulting in all being marked as inaccurate.",
                "The summary describes handling events from a function named `sub_518073`, logging their type as 'signal' or 'exit', and conditional follow-up when a global flag is set. None of these details have explicit evidence in the source code: there is no mention of `sub_518073`, no logging of 'signal' or 'exit', and no conditional behavior based on a global flag. The source code instead shows a signal handler for `SIGCHLD`, logging a message with 'sigchild received', iterating over an array to match `ppid`, resetting it, and calling `processorstop`. As all summary points are inaccurate per Step 1, no valid details remain, meaning the core logic is entirely missed.",
                "The summary mentions processing events from `sub_518073`, logging their type as 'signal' or 'exit', and triggering handling when a global flag is set. None of these specifics are present in the source code. The code defines `sig_child_handler`, uses `wait_any_nohang` to process child process terminations, matches them against `dir[l].ppid`, and calls `processorstop`, but there is no reference to `sub_518073`, event type logging as 'signal' or 'exit', or a global flag condition. All stated details are inaccurate, exceeding the 50% threshold."
            ]
        }
    }
}
{
    "source_code": "\nint\nrl_arrow_keys (int count, int key)\n{\n  int ch;\n\n  RL_SETSTATE(RL_STATE_MOREINPUT);\n  ch = rl_read_key ();\n  RL_UNSETSTATE(RL_STATE_MOREINPUT);\n  if (ch < 0)\n    return (1);\n\n  switch (_rl_to_upper (ch))\n    {\n    case 'A':\n      rl_get_previous_history (count, ch);\n      break;\n\n    case 'B':\n      rl_get_next_history (count, ch);\n      break;\n\n    case 'C':\n      if (MB_CUR_MAX > 1 && rl_byte_oriented == 0)\n\trl_forward_char (count, ch);\n      else\n\trl_forward_byte (count, ch);\n      break;\n\n    case 'D':\n      if (MB_CUR_MAX > 1 && rl_byte_oriented == 0)\n\trl_backward_char (count, ch);\n      else\n\trl_backward_byte (count, ch);\n      break;\n\n    default:\n      rl_ding ();\n    }\n\n  return 0;\n}",
    "comment": "Handles arrow key inputs to navigate command history or move the cursor forward/backward, depending on the key pressed and character encoding.",
    "prorec_sum": "Handles arrow key input by mapping specific key codes to history navigation or cursor movement, including multibyte character awareness and fallback to alert.",
    "filter_prorec_sum": "Handles arrow key input in readline, performing history navigation or cursor movement based on the detected key and character encoding settings.",
    "prorec_aug_sum": "Handles arrow key input in readline, executing history navigation or cursor movement based on the key pressed and character encoding settings.",
    "filter_prorec_aug_sum": "Processes arrow key inputs to navigate command history or move the cursor within the readline interface, handling both byte-oriented and multibyte character modes.",
    "work_score": {
        "prorec": {
            "summary": "Handles arrow key input by mapping specific key codes to history navigation or cursor movement, including multibyte character awareness and fallback to alert.",
            "score": [
                1.0,
                0.9,
                0.9
            ],
            "reason": [
                "The summary accurately reflects the function's handling of arrow key input, mapping 'A' and 'B' codes to previous/next history calls, 'C' and 'D' codes to forward/backward movement, with conditional checks for multibyte character handling and a fallback to an alert via rl_ding(). All described details are explicitly supported by the source code, showing no unverified assumptions.",
                "The summary's details align with the source code: specific key codes map to functions for navigating history ('A' for previous, 'B' for next) or cursor movement ('C' and 'D' with multibyte-aware checks using MB_CUR_MAX and rl_byte_oriented). The fallback to rl_ding() matches the 'alert' description. All key elements in the summary are explicitly present in the code, showing completeness of the logic, including multibyte handling and default case behavior.",
                "The summary accurately captures key behaviors from the source code: mapping specific arrow key codes to history navigation (cases 'A' and 'B'), cursor movement (cases 'C' and 'D'), handling multibyte characters via MB_CUR_MAX checks and rl_byte_oriented, and using a fallback alert through rl_ding(). All stated details are explicitly supported by function calls and conditions in the code, and they provide domain-relevant insight into input handling."
            ]
        },
        "filter_prorec": {
            "summary": "Handles arrow key input in readline, performing history navigation or cursor movement based on the detected key and character encoding settings.",
            "score": [
                1.0,
                0.7666666666666666,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function handles arrow key input, uses readline, and performs history navigation or cursor movement depending on the detected key and character encoding settings. All these details are explicitly evidenced in the source code through the switch cases for 'A'/'B' (history navigation) and 'C'/'D' (cursor movement) with conditional checks using MB_CUR_MAX and rl_byte_oriented. No unverified or hallucinated details are present, so accuracy is very high.",
                "The summary accurately reflects the code\u2019s handling of arrow keys, mapping them to history navigation (up/down arrows) and cursor movement (left/right arrows) with conditional logic based on character encoding settings (MB_CUR_MAX and rl_byte_oriented). It omits mention of the rl_ding fallback for unrecognized keys and the early return when ch < 0, which are important edge cases in the control flow.",
                "The summary is fully accurate: it describes arrow key handling within readline, including history navigation for up/down keys and cursor movement for left/right keys, with logic dependent on character encoding settings (MB_CUR_MAX and rl_byte_oriented). All these details are explicitly supported by function calls and conditional checks in the source code. The accurate details are domain-rich and convey clear, specific behavior from the code."
            ]
        }
    }
}
{
    "source_code": "\nint rtc_update_irq_enable(struct rtc_device *rtc, unsigned int enabled)\n{\n\tint err = mutex_lock_interruptible(&rtc->ops_lock);\n\tif (err)\n\t\treturn err;\n\n#ifdef CONFIG_RTC_INTF_DEV_UIE_EMUL\n\tif (enabled == 0 && rtc->uie_irq_active) {\n\t\tmutex_unlock(&rtc->ops_lock);\n\t\treturn rtc_dev_update_irq_enable_emul(rtc, 0);\n\t}\n#endif\n\t/* make sure we're changing state */\n\tif (rtc->uie_rtctimer.enabled == enabled)\n\t\tgoto out;\n\n\tif (rtc->uie_unsupported) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (enabled) {\n\t\tstruct rtc_time tm;\n\t\tktime_t now, onesec;\n\n\t\t__rtc_read_time(rtc, &tm);\n\t\tonesec = ktime_set(1, 0);\n\t\tnow = rtc_tm_to_ktime(tm);\n\t\trtc->uie_rtctimer.node.expires = ktime_add(now, onesec);\n\t\trtc->uie_rtctimer.period = ktime_set(1, 0);\n\t\terr = rtc_timer_enqueue(rtc, &rtc->uie_rtctimer);\n\t} else\n\t\trtc_timer_remove(rtc, &rtc->uie_rtctimer);\n\nout:\n\tmutex_unlock(&rtc->ops_lock);\n#ifdef CONFIG_RTC_INTF_DEV_UIE_EMUL\n\t/*\n\t * Enable emulation if the driver did not provide\n\t * the update_irq_enable function pointer or if returned\n\t * -EINVAL to signal that it has been configured without\n\t * interrupts or that are not available at the moment.\n\t */\n\tif (err == -EINVAL)\n\t\terr = rtc_dev_update_irq_enable_emul(rtc, enabled);\n#endif\n\treturn err;\n\n}",
    "comment": "Updates the RTC interrupt state, enabling or disabling the timer based on the provided flag, while handling potential emulation requirements.",
    "prorec_sum": "Manages device power state transitions, initializing timing parameters when enabling and invoking appropriate handlers for both activation and deactivation scenarios.",
    "filter_prorec_sum": "Changes a device\u2019s power state based on requested mode, updating related timing fields and invoking appropriate initialization or shutdown routines.",
    "prorec_aug_sum": "Handles switching a device state based on `a2`, updating timing fields, invoking setup or shutdown routines, and managing synchronization via a1+480 lock.",
    "filter_prorec_aug_sum": "Manages a state change for a device context, updating timing fields and invoking appropriate subroutines based on the new mode value.",
    "work_score": {
        "prorec": {
            "summary": "Manages device power state transitions, initializing timing parameters when enabling and invoking appropriate handlers for both activation and deactivation scenarios.",
            "score": [
                0.3,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims the function manages device power state transitions, which is inaccurate as there is no evidence in the source code of power management functionality; the code handles enabling/disabling RTC update interrupts and setting timing parameters. While the summary correctly notes timing parameter initialization when enabling and handling activation/deactivation scenarios, the core claim about power state transitions is a hallucination. This results in less than half of the details being accurate.",
                "The summary claims management of device power state transitions, which is unsupported by the source code. The function solely enables or disables RTC update interrupts, handles conditional emulation, and sets up one-second timer parameters when enabled, or removes them when disabled. Since the summary's core description about power state transitions is inaccurate, only the generic activation/deactivation notion loosely aligns with the code. This leaves nearly all semantic content as hallucinated, missing the core mutex locking, error handling, and timer scheduling logic present in the source.",
                "The summary claims the function manages device power state transitions, which is inaccurate as the source code deals with enabling or disabling RTC update interrupts and related timers, not power state changes. It omits specific references to mutex locking, conditional emulation handling, timer parameter initialization, and removal logic, instead offering a vague and incorrect description. Since the primary claim is inaccurate and constitutes more than 50% of the details, the evaluation halts at the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Changes a device\u2019s power state based on requested mode, updating related timing fields and invoking appropriate initialization or shutdown routines.",
            "score": [
                0.06666666666666667,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims the function changes a device\u2019s power state and handles initialization/shutdown routines, but the source code shows it controlling RTC update interrupts, manipulating timing fields, and managing timers. No evidence of power state changes or general initialization/shutdown routines exists. The only partially accurate element is updating timing fields for the RTC when enabling interrupts. Most details are inaccurate given the actual logic, resulting in very low accuracy.",
                "The summary is inaccurate because it claims to change a device\u2019s power state and perform initialization or shutdown routines, which is not supported by the source code. The actual function manages enabling or disabling RTC update interrupts, modifies timer fields, handles emulation and error cases, and updates expiration and period timing for the RTC timer. None of the details in the summary match explicit evidence in the code, leaving no accurate content to map to the source code\u2019s logic.",
                "The summary claims the function changes a device's power state and handles initialization/shutdown routines, but the source code instead enables or disables RTC update interrupts, manipulates timer structures, and uses RTC-specific functions. All asserted details about power state changes and generic mode handling are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic ngx_int_t\nngx_http_variable_tcpinfo(ngx_http_request_t *r, ngx_http_variable_value_t *v,\n    uintptr_t data)\n{\n    struct tcp_info  ti;\n    socklen_t        len;\n    uint32_t         value;\n\n    len = sizeof(struct tcp_info);\n    if (getsockopt(r->connection->fd, IPPROTO_TCP, TCP_INFO, &ti, &len) == -1) {\n        v->not_found = 1;\n        return NGX_OK;\n    }\n\n    v->data = ngx_pnalloc(r->pool, NGX_INT32_LEN);\n    if (v->data == NULL) {\n        return NGX_ERROR;\n    }\n\n    switch (data) {\n    case 0:\n        value = ti.tcpi_rtt;\n        break;\n\n    case 1:\n        value = ti.tcpi_rttvar;\n        break;\n\n    case 2:\n        value = ti.tcpi_snd_cwnd;\n        break;\n\n    case 3:\n        value = ti.tcpi_rcv_space;\n        break;\n\n    /* suppress warning */\n    default:\n        value = 0;\n        break;\n    }\n\n    v->len = ngx_sprintf(v->data, \"%uD\", value) - v->data;\n    v->valid = 1;\n    v->no_cacheable = 0;\n    v->not_found = 0;\n\n    return NGX_OK;\n}",
    "comment": "Retrieves TCP connection statistics like RTT, RTT variance, send window size, or receive space and stores the result in an HTTP variable.",
    "prorec_sum": "Retrieves TCP_INFO from a socket, formats a selected statistic as a string, and stores it in the provided structure with status flags.",
    "filter_prorec_sum": "Retrieves TCP connection info via `getsockopt` and stores a selected numeric metric as a formatted string into the provided output structure.",
    "prorec_aug_sum": "Retrieves TCP connection info via getsockopt, selects a metric based on input, formats it as a string, and updates the provided structure.",
    "filter_prorec_aug_sum": "Retrieves TCP connection info via getsockopt and stores a selected metric as a decimal string into a provided structure.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves TCP_INFO from a socket, formats a selected statistic as a string, and stores it in the provided structure with status flags.",
            "score": [
                1.0,
                0.7666666666666666,
                0.7999999999999999
            ],
            "reason": [
                "The summary accurately mentions retrieving TCP_INFO via getsockopt, selecting a statistic, formatting it as a string, and storing it in the provided structure with status flags. All these elements are explicitly reflected in the source code through the use of TCP_INFO, switch cases for statistics, ngx_sprintf for formatting, and setting structure flags. No details appear hallucinated, meeting full alignment with the source.",
                "The summary accurately reflects the core logic: it retrieves TCP_INFO from a socket using getsockopt, selects a specific statistic based on the 'data' parameter, formats it as a string, and stores it in the provided structure while setting appropriate status flags. All described actions are explicitly present in the source code, including data retrieval, formatting, and flag assignments. However, it omits mention of error handling paths, allocation checks, and the specific statistics handled by the switch statement, which are significant parts of the logic.",
                "The summary accurately reflects the core behavior in the source code: it retrieves TCP_INFO via getsockopt, selects a specific metric based on the 'data' parameter, formats the value as a string, and stores it in the structure with status flags set accordingly. All these details are explicitly present in the source. The accurate details are domain-specific and relevant to networking and Nginx variable handling, providing clear insights into the function\u2019s purpose."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves TCP connection info via `getsockopt` and stores a selected numeric metric as a formatted string into the provided output structure.",
            "score": [
                1.0,
                0.6,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly identifies that the code retrieves TCP connection information using `getsockopt` and formats a selected numeric metric into the output structure, which is explicitly shown in the source code through the `getsockopt` call with `TCP_INFO`, the `switch` selection of metrics, and `ngx_sprintf` formatting. No inaccurate or unverifiable details were introduced.",
                "The summary accurately states that the function retrieves TCP connection info via `getsockopt` and formats a selected numeric metric into the output structure. These details are explicitly supported by the source code through the use of `getsockopt` with `TCP_INFO`, the switch over `data` to select specific `tcp_info` fields, and the formatting with `ngx_sprintf`. However, the summary omits key aspects such as error handling when `getsockopt` fails, memory allocation steps, and handling of multiple possible metrics, meaning it covers the main action but not the complete logic.",
                "The summary correctly identifies the use of `getsockopt` to retrieve TCP connection info and the storage of a selected numeric metric as a formatted string in the output structure. These are explicitly shown in the code through the call to `getsockopt` with `TCP_INFO`, the selection of `value` from fields like `tcpi_rtt`, and formatting via `ngx_sprintf`. No inaccurate details are present, and the accurate details are specific to the domain and helpful for understanding the code's purpose."
            ]
        }
    }
}
{
    "source_code": "\nint libjte_write_header(struct libjte_env *o)\n{\n    int ret;\n\n    if (o->jtemplate_out == NULL || o->jjigdo_out == NULL ||\n        o->outfile == NULL || o->jmd5_list == NULL) {\n        sprintf(o->message_buffer,\n               \"Undefined: template_path, jigdo_path, md5_paths, or outfile.\");\n        libjte_add_msg_entry(o, o->message_buffer, 0);\n        return 0;\n    }\n    \n    o->jttemplate = fopen(o->jtemplate_out, \"wb\");\n    if (o->jttemplate == NULL) {\n        sprintf(o->message_buffer,\n                \"Cannot open template file '%1.1024s' for writing. errno=%d\",\n                o->jtemplate_out, errno);\n        libjte_add_msg_entry(o, o->message_buffer, 0);\n        return 0;\n    }\n    o->jtjigdo = fopen(o->jjigdo_out, \"wb\");\n    if (o->jtjigdo == NULL) {\n        sprintf(o->message_buffer,\n                \"Cannot open jigdo file '%1.1024s' for writing. errno=%d\",\n                o->jjigdo_out, errno);\n        libjte_add_msg_entry(o, o->message_buffer, 0);\n        return 0;\n    }\n\n    ret = write_jt_header(o, o->jttemplate, o->jtjigdo);\n    if (ret <= 0)\n        return ret;\n    return 1;\n}",
    "comment": "Initializes output files for a template and jigdo, checks for errors, and writes the header using the provided environment structure.",
    "prorec_sum": "Opens specified template and jigdo output files for writing, reporting detailed errors if creation fails, then processes them via sub_4D0600.",
    "filter_prorec_sum": "Opens two specified output files for writing, reports detailed errors if opening fails, and invokes a processing routine on their file handles.",
    "prorec_aug_sum": "Opens specified template and jigdo output files for writing, reports descriptive errors if opening fails, and processes them via sub_4D0600.",
    "filter_prorec_aug_sum": "Opens specified template and jigdo output files for writing, reports detailed errors if opening fails, and processes them via sub_4D0600.",
    "work_score": {
        "prorec": {
            "summary": "Opens specified template and jigdo output files for writing, reporting detailed errors if creation fails, then processes them via sub_4D0600.",
            "score": [
                0.6,
                0.6,
                0.3666666666666667
            ],
            "reason": [
                "The summary correctly describes opening template and jigdo files for writing and detailed error reporting when file creation fails, which is explicitly shown in the source code via fopen calls and error messages. However, it inaccurately names the processing function as sub_4D0600; the source code calls write_jt_header instead. This is a clear hallucination, reducing accuracy.",
                "The summary accurately describes opening template and jigdo files for writing and reporting detailed errors if creation fails, which is explicitly shown in the code via fopen calls and error messages. However, the summary incorrectly names the final processing function as sub_4D0600 instead of the actual write_jt_header, making this detail inaccurate. The remaining accurate details cover the main file handling and basic logic but omit the initial null-parameter checks and message logging, so the overall picture of the code is incomplete.",
                "The summary correctly notes opening template and jigdo output files for writing and reporting detailed errors if creation fails, which is explicitly shown in the source code via fopen calls and error messages. However, the claim that they are processed via 'sub_4D0600' is inaccurate; the code calls 'write_jt_header' instead. With one of two main details being inaccurate, the proportion of inaccurate details exceeds 50%, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Opens two specified output files for writing, reports detailed errors if opening fails, and invokes a processing routine on their file handles.",
            "score": [
                1.0,
                0.6999999999999998,
                0.7999999999999999
            ],
            "reason": [
                "The summary accurately identifies that the code opens two output files for writing, reports errors if either fails, and calls a processing routine (`write_jt_header`) with their file handles. These behaviors are explicitly present in the source code, and there are no unsupported claims or omissions of significant details relevant to the described actions.",
                "The summary accurately states that the function opens two specified output files for writing, reports detailed errors when opening fails, and calls a processing routine using their file handles. These details are explicitly supported by the code through fopen calls for jtemplate_out and jjigdo_out, error reporting via sprintf and libjte_add_msg_entry, and the invocation of write_jt_header. However, the summary omits the initial null-check on input pointers and corresponding error handling, which is a significant part of the function's logic.",
                "The summary accurately reflects the source code's logic: it opens two output files (`jtemplate_out` and `jjigdo_out`) for writing, reports detailed error messages with `errno` if either fails, and calls a processing routine (`write_jt_header`) with their file handles. No inaccurate details are present, and the description is specific and matches the domain operations in the code."
            ]
        }
    }
}
{
    "source_code": "\nint __ipv6_addr_type(const struct in6_addr *addr)\n{\n\t__be32 st;\n\n\tst = addr->s6_addr32[0];\n\n\t/* Consider all addresses with the first three bits different of\n\t   000 and 111 as unicasts.\n\t */\n\tif ((st & htonl(0xE0000000)) != htonl(0x00000000) &&\n\t    (st & htonl(0xE0000000)) != htonl(0xE0000000))\n\t\treturn (IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\n\n\tif ((st & htonl(0xFF000000)) == htonl(0xFF000000)) {\n\t\t/* multicast */\n\t\t/* addr-select 3.1 */\n\t\treturn (IPV6_ADDR_MULTICAST |\n\t\t\tipv6_addr_scope2type(IPV6_ADDR_MC_SCOPE(addr)));\n\t}\n\n\tif ((st & htonl(0xFFC00000)) == htonl(0xFE800000))\n\t\treturn (IPV6_ADDR_LINKLOCAL | IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_LINKLOCAL));\t\t/* addr-select 3.1 */\n\tif ((st & htonl(0xFFC00000)) == htonl(0xFEC00000))\n\t\treturn (IPV6_ADDR_SITELOCAL | IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_SITELOCAL));\t\t/* addr-select 3.1 */\n\tif ((st & htonl(0xFE000000)) == htonl(0xFC000000))\n\t\treturn (IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t\t\t/* RFC 4193 */\n\n\tif ((addr->s6_addr32[0] | addr->s6_addr32[1]) == 0) {\n\t\tif (addr->s6_addr32[2] == 0) {\n\t\t\tif (addr->s6_addr32[3] == 0)\n\t\t\t\treturn IPV6_ADDR_ANY;\n\n\t\t\tif (addr->s6_addr32[3] == htonl(0x00000001))\n\t\t\t\treturn (IPV6_ADDR_LOOPBACK | IPV6_ADDR_UNICAST |\n\t\t\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_LINKLOCAL));\t/* addr-select 3.4 */\n\n\t\t\treturn (IPV6_ADDR_COMPATv4 | IPV6_ADDR_UNICAST |\n\t\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t/* addr-select 3.3 */\n\t\t}\n\n\t\tif (addr->s6_addr32[2] == htonl(0x0000ffff))\n\t\t\treturn (IPV6_ADDR_MAPPED |\n\t\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t/* addr-select 3.3 */\n\t}\n\n\treturn (IPV6_ADDR_UNICAST |\n\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t/* addr-select 3.4 */\n}",
    "comment": "Determines the IPv6 address type (unicast, multicast, link-local, site-local, loopback, or any) based on the address structure and specific bit patterns.",
    "prorec_sum": "Classifies packet header data from the given memory address into predefined constant codes based on specific byte and bit pattern checks.",
    "filter_prorec_sum": "Determines and returns a constant code based on specific bit patterns and byte values found at and after the provided memory address.",
    "prorec_aug_sum": "Evaluates specific bit patterns in the first bytes of a memory block and returns corresponding constant codes based on matched conditions.",
    "filter_prorec_aug_sum": "Evaluates specific bit patterns and field values in a data structure to return predefined codes representing recognized input formats or special cases.",
    "work_score": {
        "prorec": {
            "summary": "Classifies packet header data from the given memory address into predefined constant codes based on specific byte and bit pattern checks.",
            "score": [
                0.6666666666666666,
                0.6,
                0.3666666666666667
            ],
            "reason": [
                "The summary correctly identifies that the function classifies data based on specific bit pattern checks into predefined constants, which is evident from multiple bitmask operations and returns of defined IPV6_ADDR_* constants in the source code. However, it inaccurately describes the subject as 'packet header data from a given memory address' rather than IPv6 address structures, and omits context-specific details such as the explicit handling of multicast, link-local, site-local, loopback, and mapped IPv4 addresses. The core classification mechanism is accurate, but key semantic specifics are missing, leading to partial alignment.",
                "The summary correctly captures the core logic that the function classifies data into predefined constant codes based on specific bit pattern checks in the IPv6 address. This aligns with evidence from the code, which tests various bit masks on the address's first 32-bit segment and other segments to determine types like unicast, multicast, link-local, loopback, etc. However, the summary is incomplete, as it omits critical details such as the specific IPv6 categories handled, scope determination, and handling of special cases like any, mapped, and compat IPv4 addresses.",
                "The summary claims classification of packet header data from a given memory address, but the source code actually inspects IPv6 address structures (`struct in6_addr`) and applies bitmask checks to determine the address type. There is no evidence of packet headers or memory address manipulation as described; instead, it focuses strictly on address type constants. This makes the main claim inaccurate, and since it is the only substantive detail, the proportion of inaccurate details exceeds the threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Determines and returns a constant code based on specific bit patterns and byte values found at and after the provided memory address.",
            "score": [
                0.6,
                0.5,
                0.09999999999999999
            ],
            "reason": [
                "The summary omits key semantic details from the source code, such as explicit checks for IPv6 address types (unicast, multicast, link-local, site-local, loopback, mapped) and use of constants like IPV6_ADDR_UNICAST or IPV6_ADDR_MULTICAST. It vaguely describes bit pattern checks but inaccurately states 'provided memory address' without confirming pointer dereferencing specifics and ignores network byte order functions (htonl) and multiple scope type determinations. Most explicit logic steps and constants are missing, leading to less than half of the actual details being represented accurately.",
                "The summary correctly states that the function returns a constant code based on specific bit patterns and byte values, which matches the source code's conditional checks using bit masks and comparisons on the address fields. However, it omits critical details such as the identification of address types (unicast, multicast, link-local, site-local, etc.), scope type determination, and special cases for unspecified, loopback, mapped, and IPv4-compatible addresses. This missing coverage means the accurate content only captures the most general logic without the completeness of all key branches and edge cases.",
                "The summary is inaccurate because it describes inspecting memory at and after a provided address, which is not supported by the source code. The function operates on a struct in6_addr, specifically checking predefined elements of the s6_addr32 array and applying bitmask comparisons to identify IPv6 address types and scopes. More than half of the details are false, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "static void\nnlmsvc_insert_block_locked(struct nlm_block *block, unsigned long when)\n{\n\tstruct nlm_block *b;\n\tstruct list_head *pos;\n\n\tdprintk(\"lockd: nlmsvc_insert_block(%p, %ld)\\n\", block, when);\n\tif (list_empty(&block->b_list)) {\n\t\tkref_get(&block->b_count);\n\t} else {\n\t\tlist_del_init(&block->b_list);\n\t}\n\n\tpos = &nlm_blocked;\n\tif (when != NLM_NEVER) {\n\t\tif ((when += jiffies) == NLM_NEVER)\n\t\t\twhen ++;\n\t\tlist_for_each(pos, &nlm_blocked) {\n\t\t\tb = list_entry(pos, struct nlm_block, b_list);\n\t\t\tif (time_after(b->b_when,when) || b->b_when == NLM_NEVER)\n\t\t\t\tbreak;\n\t\t}\n\t\t/* On normal exit from the loop, pos == &nlm_blocked,\n\t\t * so we will be adding to the end of the list - good\n\t\t */\n\t}\n\n\tlist_add_tail(&block->b_list, pos);\n\tblock->b_when = when;\n}",
    "comment": "Inserts a network lock block into a sorted list based on its scheduled time, managing its reference count and handling the list initialization.",
    "prorec_sum": "Manages a doubly linked list of objects, adjusting references and associated data while handling special conditions and incrementing a kernel reference count.",
    "filter_prorec_sum": "Manages linked list node removal and reinsertion while updating reference counts and associated metadata value.",
    "prorec_aug_sum": "Removes an entry from its current doubly linked list and reinserts it into another list position based on a calculated offset value.",
    "filter_prorec_aug_sum": "Manages removal and reinsertion of a list entry, updating links and associated value, with a one-time debug call on initial empty state.",
    "work_score": {
        "prorec": {
            "summary": "Manages a doubly linked list of objects, adjusting references and associated data while handling special conditions and incrementing a kernel reference count.",
            "score": [
                0.7666666666666666,
                0.6,
                0.6
            ],
            "reason": [
                "The summary\u2019s mention of managing a doubly linked list is accurate, as the code uses `list_head` and functions like `list_add_tail`, `list_del_init`, and `list_for_each`. The handling of special conditions is also accurate, evidenced by the `when != NLM_NEVER` logic and adjustments involving `jiffies`. The incrementing of a kernel reference count is confirmed by the `kref_get(&block->b_count)` call. However, the phrase \u2018adjusting references and associated data\u2019 is vague and partly unverified; while reference counts are adjusted, there is no explicit handling of arbitrary associated data beyond fields in `struct nlm_block`. Overall, nearly all stated details match explicit code evidence, with minor vagueness in one part.",
                "The summary correctly notes management of a doubly linked list and incrementing a kernel reference count, which is evidenced by usage of list_* functions and kref_get in the source code. However, it omits key details such as handling of the 'when' parameter, checks for NLM_NEVER, conditional repositioning within the list based on time comparison, and removal/init of existing list entries. This missing logic means the accurate details only partially capture the core behavior.",
                "The summary accurately notes handling of a doubly linked list, special conditions, and incrementing a kernel reference count, all of which are explicitly evidenced by the use of list manipulation functions, conditional checks, and kref_get in the source. However, the summary omits specific logic such as ordering based on 'when' and use of 'nlm_blocked', making the description generic rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Manages linked list node removal and reinsertion while updating reference counts and associated metadata value.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly notes that the function handles linked list node removal and reinsertion (via `list_del_init` and `list_add_tail`) and updates a metadata value (`block->b_when`). It also accurately mentions updating a reference count (`kref_get` when the list is empty). All these elements are explicitly present in the source code, with no unsupported or hallucinated details.",
                "The summary accurately notes removal and reinsertion of linked list nodes and updating of a reference count (via kref_get) and a metadata-like value (b_when), which are explicit in the source code. However, it omits details about conditional checks, handling of NLM_NEVER, time calculations using jiffies, and loop logic for insertion positioning, leaving significant parts of the function\u2019s logic unmentioned.",
                "The summary's claim about linked list node removal and reinsertion is accurate, as the code uses `list_del_init()`, `list_add_tail()`, and iterates through `nlm_blocked`. The mention of updating reference counts aligns with the `kref_get(&block->b_count)` call. However, 'associated metadata value' is vague and only partially accurate since the code specifically updates `block->b_when`, which is a timestamp rather than generic metadata. Overall, the details are correct but presented in a generic way rather than providing specific, domain-rich insights from the source code."
            ]
        }
    }
}
{
    "source_code": "void mm_drop_all_locks(struct mm_struct *mm)\n{\n\tstruct vm_area_struct *vma;\n\tstruct anon_vma_chain *avc;\n\n\tBUG_ON(down_read_trylock(&mm->mmap_sem));\n\tBUG_ON(!mutex_is_locked(&mm_all_locks_mutex));\n\n\tfor (vma = mm->mmap; vma; vma = vma->vm_next) {\n\t\tif (vma->anon_vma)\n\t\t\tlist_for_each_entry(avc, &vma->anon_vma_chain, same_vma)\n\t\t\t\tvm_unlock_anon_vma(avc->anon_vma);\n\t\tif (vma->vm_file && vma->vm_file->f_mapping)\n\t\t\tvm_unlock_mapping(vma->vm_file->f_mapping);\n\t}\n\n\tmutex_unlock(&mm_all_locks_mutex);\n}",
    "comment": "Releases all locks on virtual memory areas and their associated anonymous virtual memory structures in the specified memory management structure.",
    "prorec_sum": "Traverses and cleans up linked DRM-related structures, clearing flags, releasing associated resources, and finalizing with a global state reset.",
    "filter_prorec_sum": "Cleans up DRM file-private resources by releasing associated DMA fences and signaling objects, ensuring proper state reset before final global synchronization.",
    "prorec_aug_sum": "Traverses and cleans up linked work structures, clearing specific status bits and invoking release routines before finalizing with a global flag reset.",
    "filter_prorec_aug_sum": "Cleans up linked work queue structures, clears specific status bits, and releases associated resources before finalizing with a global state reset.",
    "work_score": {
        "prorec": {
            "summary": "Traverses and cleans up linked DRM-related structures, clearing flags, releasing associated resources, and finalizing with a global state reset.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims traversal of DRM-related structures, clearing flags, and global state reset, but the source code does not reference DRM, flags, or global state resets. The actual code iterates over vm_area_struct linked list in an mm_struct, unlocking anon_vma and file mappings, and releases a mutex. None of the summary's semantic claims are supported, resulting in all details being hallucinations.",
                "The summary describes traversal and cleanup of DRM-related structures, clearing flags, and global state reset, but the source code deals with memory management structures (`mm_struct`, `vm_area_struct`, anonymous VMA chains) and unlocking associated locks. There is no mention of DRM, flags, or a global state reset, so all details are inaccurate, leaving no valid content from the summary.",
                "The summary's claims about DRM-related structures, clearing flags, and a global state reset are unsupported by the source code. The code operates on memory management structures (`mm_struct`, `vm_area_struct`, and related lists), unlocking associated resources such as `anon_vma` and file mappings, not DRM. All semantic details in the summary are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Cleans up DRM file-private resources by releasing associated DMA fences and signaling objects, ensuring proper state reset before final global synchronization.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes DRM file-private resources, DMA fences, signaling objects, and global synchronization, none of which appear in the source code. The actual function in the source code is concerned with dropping all locks in a memory management context, involving vm_area_struct, anon_vma_chain, and mutex handling. There is no evidence of DRM, DMA, or signaling, making all details in the summary inaccurate.",
                "The summary describes DRM-specific resource cleanup involving DMA fences and signaling objects, which has no explicit evidence in the provided source code. The actual code operates on memory management structures (`mm_struct`, `vm_area_struct`) and unlocks associated anon_vma and file mappings under mutex protection, with no DRM or DMA fence logic present. All details in the summary are inaccurate, leaving no valid content to map to the source's critical semantic units.",
                "The summary describes cleanup of DRM file-private resources, DMA fences, and signaling objects, but the source code instead deals with releasing locks on memory structures such as anon_vma and file mappings in a mm_struct. None of the claimed DRM-related details are present, making all semantic details inaccurate and triggering the kill switch due to an inaccuracy rate above 50%."
            ]
        }
    }
}
{
    "source_code": "int\ngnet_stats_finish_copy(struct gnet_dump *d)\n{\n\tif (d->tail)\n\t\td->tail->nla_len = skb_tail_pointer(d->skb) - (u8 *)d->tail;\n\n\tif (d->compat_tc_stats)\n\t\tif (gnet_stats_copy(d, d->compat_tc_stats, &d->tc_stats,\n\t\t\tsizeof(d->tc_stats)) < 0)\n\t\t\treturn -1;\n\n\tif (d->compat_xstats && d->xstats) {\n\t\tif (gnet_stats_copy(d, d->compat_xstats, d->xstats,\n\t\t\td->xstats_len) < 0)\n\t\t\treturn -1;\n\t}\n\n\tspin_unlock_bh(d->lock);\n\treturn 0;\n}",
    "comment": "Finalizes the statistics copy process by updating lengths and copying compatible statistics into the provided structures before unlocking the spinlock.",
    "prorec_sum": "Frees and resets a PCM substream\u2019s allocated buffers after processing, invoking cleanup routines based on buffer state and validation results.",
    "filter_prorec_sum": "Frees a PCM substream\u2019s allocated resources after invoking a processing routine, based on validation of stream parameters and buffer state.",
    "prorec_aug_sum": "Processes a1-related buffer state, performs conditional sub_FFFFFFFF812C91D0 checks, executes sub_FFFFFFFF8112DCD0, resets fields, and invokes cleanup via sub_FFFFFFFF81792870.",
    "filter_prorec_aug_sum": "Validates parameters and either processes or discards a network-related work queue entry, invoking cleanup and resource release on failure or after execution.",
    "work_score": {
        "prorec": {
            "summary": "Frees and resets a PCM substream\u2019s allocated buffers after processing, invoking cleanup routines based on buffer state and validation results.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes PCM substream buffer management and cleanup routines, which are unrelated to the source code. The actual function operates on gnet statistics structures, performing length adjustments, conditional copy operations, and unlocking a spinlock. None of the summary\u2019s claims about PCM buffers, validation results, or cleanup routines are evidenced in the source code, resulting in all details being inaccurate.",
                "The summary describes freeing and resetting PCM substream buffers and cleanup routines, but the source code deals with copying network statistics, adjusting length fields, handling compatibility stats, and releasing a spinlock. None of the summary\u2019s details are evidenced in the provided code, so all points are inaccurate, leaving no valid content to map to the actual logic.",
                "The summary claims behavior related to PCM substream buffer management and cleanup routines, which is entirely unrelated to the source code. The source code specifically handles network statistics copying and locking mechanisms in gnet_stats_finish_copy, with no mention of PCM, audio buffers, or buffer validation. All semantic details are inaccurate, exceeding the threshold for the kill switch, making the summary misleading."
            ]
        },
        "filter_prorec": {
            "summary": "Frees a PCM substream\u2019s allocated resources after invoking a processing routine, based on validation of stream parameters and buffer state.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary mentions freeing a PCM substream's allocated resources, invoking a processing routine, validating stream parameters, and checking buffer state. None of these concepts appear in the source code, which instead deals with copying network statistics structures, adjusting lengths, and unlocking a spinlock. All details in the summary are hallucinations with no explicit evidence in the source code.",
                "The summary's claims about PCM substream resource freeing, processing routines, and stream/buffer validation are entirely unrelated to the source code, which deals with copying and finalizing network statistics in a gnet_dump structure. No details in the summary match any functions, variables, or logic present in the source code, leaving no accurate content to map to critical semantic units.",
                "The summary claims the code frees a PCM substream\u2019s resources after processing based on stream parameters and buffer state, which is entirely unrelated to the source code. The source function deals with finalizing statistics copy operations for networking, handling compatibility structures, adjusting lengths, and unlocking a spinlock. None of the summary\u2019s semantic details are reflected in the source logic, making all details inaccurate and triggering the kill switch due to over 50% inaccuracy."
            ]
        }
    }
}
{
    "source_code": "\nstatic int checkscript(void)\n{\n\tchar *prog[2];\n\tstruct stat s;\n\tint pid, w;\n\n\tif (stat(\"check\", &s) == -1) {\n\t\tif (errno == ENOENT) return 1;\n\t\tbb_perror_msg(WARN\"can't stat %s/check\", *service);\n\t\treturn 0;\n\t}\n\t/* if (!(s.st_mode & S_IXUSR)) return 1; */\n\tprog[0] = (char*)\"./check\";\n\tprog[1] = NULL;\n\tpid = spawn(prog);\n\tif (pid <= 0) {\n\t\tbb_perror_msg(WARN\"can't %s child %s/check\", \"run\", *service);\n\t\treturn 0;\n\t}\n\twhile (safe_waitpid(pid, &w, 0) == -1) {\n\t\tbb_perror_msg(WARN\"can't %s child %s/check\", \"wait for\", *service);\n\t\treturn 0;\n\t}\n\treturn WEXITSTATUS(w) == 0;\n}",
    "comment": "Checks for the existence of the \"check\" script, executes it, and returns true if it exits successfully.",
    "prorec_sum": "Checks for the './check' file, executes it if present, waits for its completion, and returns success status or logs warnings on failure.",
    "filter_prorec_sum": "Checks for the existence of a \"check\" file, runs it as a child process, waits for completion, and returns success status or warns on failure.",
    "prorec_aug_sum": "Checks for the existence of a \"./check\" executable, runs it, waits for completion, and returns success status while issuing warnings on failure.",
    "filter_prorec_aug_sum": "Checks for the presence of a \"./check\" file, executes it if found, waits for its completion, and returns success status or warnings.",
    "work_score": {
        "prorec": {
            "summary": "Checks for the './check' file, executes it if present, waits for its completion, and returns success status or logs warnings on failure.",
            "score": [
                1.0,
                0.7999999999999999,
                0.9
            ],
            "reason": [
                "The summary correctly identifies all key steps in the function: checking for the './check' file via stat, executing it if present, waiting for completion, returning a success status based on exit code, and logging warnings on failure. All these details are explicitly supported by the source code, indicating full accuracy with no hallucinations.",
                "The summary correctly identifies that the function checks for the './check' file, executes it if found, waits for completion, and returns a success status, while logging warnings on failure. All these points are explicitly supported by the source code: use of stat to check existence, preparation of prog with './check', spawn call, safe_waitpid loop, WEXITSTATUS check, and bb_perror_msg for errors. The summary covers the core logic, including error handling, without introducing inaccurate or missing details.",
                "The summary accurately reflects the core flow of the source code: it checks for the './check' file using stat, runs it via spawn when present, waits for its completion, and handles errors via logging. All details are explicitly supported by the code, including the return of a success status based on WEXITSTATUS. The accurate details are specific and domain-relevant, capturing key logic steps rather than being generic."
            ]
        },
        "filter_prorec": {
            "summary": "Checks for the existence of a \"check\" file, runs it as a child process, waits for completion, and returns success status or warns on failure.",
            "score": [
                1.0,
                0.8333333333333334,
                0.9
            ],
            "reason": [
                "The summary accurately captures the key logic: it verifies existence of the 'check' file, attempts to execute it via a child process, waits for it to complete, and returns a success status or logs warnings on failure. All these elements are explicitly evidenced in the source code through 'stat', 'spawn', 'safe_waitpid', and 'WEXITSTATUS' checks. No details in the summary are unsupported or fabricated, resulting in complete alignment with the source.",
                "The summary accurately notes the existence check for the \"check\" file via stat(), execution as a child process through spawn(), waiting for completion using safe_waitpid(), and returning a success status if the exit code is zero. It also correctly mentions warning on failures. These points are all explicitly present in the source code and cover the main control flow, though minor details such as errno checking for ENOENT and specific warning contexts are omitted.",
                "The summary accurately captures key semantics from the source code: it checks for the 'check' file using stat(), runs it as a child process via spawn(), waits for completion with safe_waitpid(), and returns a success status based on WEXITSTATUS, issuing warnings on failure. All details are explicitly evidenced in the source code, with no inaccuracies. The accurate details are specific to process management and error handling, providing clear domain-relevant insights."
            ]
        }
    }
}
{
    "source_code": "\nstatic int ieee80211_scan(struct wiphy *wiphy,\n\t\t\t  struct cfg80211_scan_request *req)\n{\n\tstruct ieee80211_sub_if_data *sdata;\n\n\tsdata = IEEE80211_WDEV_TO_SUB_IF(req->wdev);\n\n\tswitch (ieee80211_vif_type_p2p(&sdata->vif)) {\n\tcase NL80211_IFTYPE_STATION:\n\tcase NL80211_IFTYPE_ADHOC:\n\tcase NL80211_IFTYPE_MESH_POINT:\n\tcase NL80211_IFTYPE_P2P_CLIENT:\n\tcase NL80211_IFTYPE_P2P_DEVICE:\n\t\tbreak;\n\tcase NL80211_IFTYPE_P2P_GO:\n\t\tif (sdata->local->ops->hw_scan)\n\t\t\tbreak;\n\t\t/*\n\t\t * FIXME: implement NoA while scanning in software,\n\t\t * for now fall through to allow scanning only when\n\t\t * beaconing hasn't been configured yet\n\t\t */\n\tcase NL80211_IFTYPE_AP:\n\t\t/*\n\t\t * If the scan has been forced (and the driver supports\n\t\t * forcing), don't care about being beaconing already.\n\t\t * This will create problems to the attached stations (e.g. all\n\t\t * the  frames sent while scanning on other channel will be\n\t\t * lost)\n\t\t */\n\t\tif (sdata->u.ap.beacon &&\n\t\t    (!(wiphy->features & NL80211_FEATURE_AP_SCAN) ||\n\t\t     !(req->flags & NL80211_SCAN_FLAG_AP)))\n\t\t\treturn -EOPNOTSUPP;\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn ieee80211_request_scan(sdata, req);\n}",
    "comment": "Handles scanning requests for various Wi-Fi interface types, ensuring appropriate conditions are met before initiating a scan.",
    "prorec_sum": "Determines whether to process a network route entry by invoking a handler based on route type and flag checks, otherwise returns an error code.",
    "filter_prorec_sum": "Determines packet handling based on route type and flags, delegating to sub_FFFFFFFF81738B20 or returning an error code when conditions are unmet.",
    "prorec_aug_sum": "Conditionally dispatches to sub_FFFFFFFF81738B20 based on control field values and flags in a2\u2019s associated structure, otherwise returns error code 4294967201.",
    "filter_prorec_aug_sum": "Checks object state and type flags, then conditionally dispatches to sub_FFFFFFFF81738B20 or returns an error code 4294967201 based on multiple field conditions.",
    "work_score": {
        "prorec": {
            "summary": "Determines whether to process a network route entry by invoking a handler based on route type and flag checks, otherwise returns an error code.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary incorrectly describes the function as processing a network route entry, referencing route type and flag checks, while the source code actually handles Wi-Fi scan requests with interface type checks and beaconing conditions. None of the semantic details in the summary match explicit evidence in the source code, indicating a complete mismatch.",
                "The summary describes processing of a network route entry with a handler based on route type and flags, but the source code actually processes a wireless scan request with interface type checks, beacon conditions, and hardware scan support, returning errors in unsupported cases. None of the summary's details match the code's actual logic, so all are inaccurate and the core logic is entirely missed.",
                "The summary claims the code processes a network route entry via a handler based on route type and flag checks, but the source code is about initiating an IEEE 802.11 scan request with checks on interface types and beaconing flags. All semantic details about 'network route entry', 'route type', and 'route flags' are inaccurate, with no explicit evidence in the code. Since all details are inaccurate, this triggers the kill switch for misleading content."
            ]
        },
        "filter_prorec": {
            "summary": "Determines packet handling based on route type and flags, delegating to sub_FFFFFFFF81738B20 or returning an error code when conditions are unmet.",
            "score": [
                0.06666666666666667,
                0.0,
                0.0
            ],
            "reason": [
                "The summary introduces concepts like packet handling, route type, and a function named sub_FFFFFFFF81738B20, none of which are present in the source code. The actual code handles scan requests based on interface type and flags, using functions such as ieee80211_request_scan and macros like IEEE80211_WDEV_TO_SUB_IF. No accurate details from the summary match the code logic, making all claims hallucinations.",
                "The summary claims the function determines packet handling based on route type and flags and delegates to a function named sub_FFFFFFFF81738B20, which is not present in the source code. The actual code controls scanning behavior based on interface type and scan flags, returning -EOPNOTSUPP when unsupported, and calls ieee80211_request_scan, not the mentioned function. No details from the summary are explicitly supported by the source code, leaving no accurate content after filtering.",
                "The summary claims the function determines packet handling based on route type and flags, but the source code focuses on handling scan requests based on interface types and beaconing conditions. There is no indication of packet handling or routing logic, nor any reference to a function named sub_FFFFFFFF81738B20. All details in the summary are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "void dnotify_flush(struct file *filp, fl_owner_t id)\n{\n\tstruct fsnotify_mark *fsn_mark;\n\tstruct dnotify_mark *dn_mark;\n\tstruct dnotify_struct *dn;\n\tstruct dnotify_struct **prev;\n\tstruct inode *inode;\n\n\tinode = file_inode(filp);\n\tif (!S_ISDIR(inode->i_mode))\n\t\treturn;\n\n\tfsn_mark = fsnotify_find_inode_mark(dnotify_group, inode);\n\tif (!fsn_mark)\n\t\treturn;\n\tdn_mark = container_of(fsn_mark, struct dnotify_mark, fsn_mark);\n\n\tmutex_lock(&dnotify_mark_mutex);\n\n\tspin_lock(&fsn_mark->lock);\n\tprev = &dn_mark->dn;\n\twhile ((dn = *prev) != NULL) {\n\t\tif ((dn->dn_owner == id) && (dn->dn_filp == filp)) {\n\t\t\t*prev = dn->dn_next;\n\t\t\tkmem_cache_free(dnotify_struct_cache, dn);\n\t\t\tdnotify_recalc_inode_mask(fsn_mark);\n\t\t\tbreak;\n\t\t}\n\t\tprev = &dn->dn_next;\n\t}\n\n\tspin_unlock(&fsn_mark->lock);\n\n\t/* nothing else could have found us thanks to the dnotify_mark_mutex */\n\tif (dn_mark->dn == NULL)\n\t\tfsnotify_destroy_mark(fsn_mark, dnotify_group);\n\n\tmutex_unlock(&dnotify_mark_mutex);\n\n\tfsnotify_put_mark(fsn_mark);\n}",
    "comment": "Removes a dnotify structure associated with a file if the owner ID matches, and cleans up the corresponding fsnotify mark if no more notifications exist.",
    "prorec_sum": "Removes a matching entry from an inode-associated list, updates related references, and triggers cleanup and finalization routines for the affected structure.",
    "filter_prorec_sum": "Removes a matching entry from a linked list, updates related structures, and invokes cleanup routines when a specific object identifier is found.",
    "prorec_aug_sum": "Removes a matching entry from a linked list, processes it with provided parameters, updates counters, and performs final cleanup and state update operations.",
    "filter_prorec_aug_sum": "Removes a matching entry from a block device\u2019s linked list, updates counters, and triggers cleanup and follow\u2011up processing.",
    "work_score": {
        "prorec": {
            "summary": "Removes a matching entry from an inode-associated list, updates related references, and triggers cleanup and finalization routines for the affected structure.",
            "score": [
                1.0,
                0.6333333333333333,
                0.7999999999999999
            ],
            "reason": [
                "The summary accurately describes the main logic in the source code: it searches for a matching entry in an inode-associated list (matching dn_owner and dn_filp), removes it, updates related references (prev pointer), and triggers cleanup routines such as kmem_cache_free, dnotify_recalc_inode_mask, and fsnotify_destroy_mark. All these details are explicitly evidenced in the code, with no unverified assumptions or hallucinations present.",
                "The summary is accurate in describing removal of a matching entry from a list associated with an inode, as shown by the while-loop checking dn_owner and dn_filp, updating the 'prev' pointer, and freeing the structure. It also correctly notes updating references via dnotify_recalc_inode_mask and triggering cleanup routines such as fsnotify_destroy_mark and fsnotify_put_mark. However, the summary omits explicit mention of critical control flow conditions (directory check, null mark return) and locking mechanisms used, which are important to the code's logic.",
                "The summary accurately captures the core logic of removing a matching entry from an inode-associated list and performing cleanup and finalization routines, which corresponds to the loop that finds and removes the matching dnotify_struct, calls kmem_cache_free, updates the mask, and potentially destroys the mark. However, it omits specific technical elements such as the checks for directory type, use of mutex and spinlocks, and precise function calls, making the accurate details somewhat generic rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Removes a matching entry from a linked list, updates related structures, and invokes cleanup routines when a specific object identifier is found.",
            "score": [
                1.0,
                0.7333333333333333,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly describes removing a matching entry from a linked list when certain conditions are met, updating related structures, and performing cleanup. This aligns with the code, which searches through dn_mark->dn for entries matching the given owner and file, removes them, frees memory, recalculates inode masks, and destroys marks if the list is empty. All details are explicitly supported by the source code, with no unverified claims.",
                "The summary is accurate in noting that the function searches a linked list for a matching entry based on a specific identifier and file pointer, removes it, updates related structures (via dnotify_recalc_inode_mask), and triggers cleanup routines (kmem_cache_free, fsnotify_destroy_mark, fsnotify_put_mark). These actions are clearly present in the source code, covering the primary control flow and key operations without introducing unfounded details. The description captures the core logic, including condition-based removal and subsequent cleanup, aligning well with the code.",
                "The summary accurately describes the core logic: the function iterates over a linked list to find and remove a matching entry based on an object identifier, updates related structures, and performs cleanup routines. All these steps are explicitly visible in the code through the linked list traversal, matching conditions, `kmem_cache_free`, mask recalculation, mark destruction, and mark release. The details are domain-rich, referencing actual data structure operations and cleanup mechanics rather than being vague."
            ]
        }
    }
}
{
    "source_code": "\nint x86_pmu_handle_irq(struct pt_regs *regs)\n{\n\tstruct perf_sample_data data;\n\tstruct cpu_hw_events *cpuc;\n\tstruct perf_event *event;\n\tint idx, handled = 0;\n\tu64 val;\n\n\tcpuc = &__get_cpu_var(cpu_hw_events);\n\n\t/*\n\t * Some chipsets need to unmask the LVTPC in a particular spot\n\t * inside the nmi handler.  As a result, the unmasking was pushed\n\t * into all the nmi handlers.\n\t *\n\t * This generic handler doesn't seem to have any issues where the\n\t * unmasking occurs so it was left at the top.\n\t */\n\tapic_write(APIC_LVTPC, APIC_DM_NMI);\n\n\tfor (idx = 0; idx < x86_pmu.num_counters; idx++) {\n\t\tif (!test_bit(idx, cpuc->active_mask)) {\n\t\t\t/*\n\t\t\t * Though we deactivated the counter some cpus\n\t\t\t * might still deliver spurious interrupts still\n\t\t\t * in flight. Catch them:\n\t\t\t */\n\t\t\tif (__test_and_clear_bit(idx, cpuc->running))\n\t\t\t\thandled++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tevent = cpuc->events[idx];\n\n\t\tval = x86_perf_event_update(event);\n\t\tif (val & (1ULL << (x86_pmu.cntval_bits - 1)))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * event overflow\n\t\t */\n\t\thandled++;\n\t\tperf_sample_data_init(&data, 0, event->hw.last_period);\n\n\t\tif (!x86_perf_event_set_period(event))\n\t\t\tcontinue;\n\n\t\tif (perf_event_overflow(event, &data, regs))\n\t\t\tx86_pmu_stop(event, 0);\n\t}\n\n\tif (handled)\n\t\tinc_irq_stat(apic_perf_irqs);\n\n\treturn handled;\n}",
    "comment": "Handles performance monitoring unit interrupts by checking active counters, updating event values, and managing event overflows, while ensuring proper NMI handling.",
    "prorec_sum": "Iterates over a per\u2011CPU list of active entries, checks conditions, and triggers processing or resets state, returning the count of successfully processed entries.",
    "filter_prorec_sum": "Iterates over per-CPU memory cgroup entries, checking bitmasks, processing eligible entries, and incrementing a counter for successfully handled memory charge operations.",
    "prorec_aug_sum": "Iterates over active entities, checks specific state bits, conditionally processes them via helper functions, and returns the count of successfully handled entries.",
    "filter_prorec_aug_sum": "Iterates over active CPU entries, checks scheduling and runtime conditions, and performs task-specific operations while counting and updating active CPU statistics.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over a per\u2011CPU list of active entries, checks conditions, and triggers processing or resets state, returning the count of successfully processed entries.",
            "score": [
                0.5,
                0.6,
                0.5
            ],
            "reason": [
                "The summary correctly notes iteration over a per\u2011CPU list, condition checks, and returning a count, which aligns with the loop over cpuc->active_mask and 'handled' variable updates. However, it inaccurately generalizes the processing as 'resets state'\u2014the source code specifically handles performance events, updates periods, and possibly stops events, not generic state resets. It also omits key explicit details such as the APIC unmasking, handling spurious interrupts, and overflow handling, thus failing to capture all semantic specifics required for full accuracy.",
                "The summary accurately notes that the function iterates over a per\u2011CPU collection and processes entries based on conditions, and that it returns a count of processed entries, which aligns with the loop over counters, conditional checks, and incrementing 'handled'. However, it omits critical details such as handling inactive counters, detecting spurious interrupts, the specific overflow detection and reset logic, and the conditional stopping of events. These omissions mean it covers the main iteration and return behavior but misses significant parts of the code's control flow and edge case handling.",
                "The summary omits specific, domain-rich elements from the source code such as the handling of spurious interrupts via __test_and_clear_bit, event overflow processing with perf_sample_data_init, and conditional stopping of events. While it is partially accurate in describing iteration over a set of entries and returning a count, it generalizes away the clear references to performance monitoring data structures, hardware interrupt handling, and counter logic. The accurate portion is too generic to provide meaningful technical insight."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates over per-CPU memory cgroup entries, checking bitmasks, processing eligible entries, and incrementing a counter for successfully handled memory charge operations.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes operations on per-CPU memory cgroup entries, memory charge handling, and related concepts, none of which are present in the source code. The actual function handles performance monitoring unit interrupts, iterates over hardware event counters, checks active and running bitmasks, updates event values, and manages overflow and stopping events. Every detail in the summary is inaccurate as it relates to an unrelated domain and functions not found in the code.",
                "The summary's claims about iterating over per-CPU memory cgroup entries and handling memory charge operations are inaccurate, as the source code deals with performance monitoring interrupt handling, checking active mask bits for hardware counters, updating events, and managing overflow cases. There is no reference to memory cgroups or memory charge logic, so no accurate details remain after filtering, leaving the core logic entirely unrepresented.",
                "The summary describes iterating over per-CPU memory cgroup entries and handling memory charge operations, but the source code actually iterates over performance monitoring counters, checks active bitmasks, processes hardware events, and updates interrupt statistics. All semantic details in the summary, including references to memory cgroups and charge operations, are inaccurate compared to the code's PMU interrupt handling logic. Since over 50% of the details are incorrect, the evaluation stops with a score of 0."
            ]
        }
    }
}
{
    "source_code": "int Findjob_set_name_expr(struct FindjoB *o, char *name_expr, int flag)\n{\n char *regexpr= NULL;\n regex_t *name_re;\n struct ExprtesT *t;\n int ret;\n\n regexpr= TSOB_FELD(char, 2*SfileadrL+2);\n if(regexpr == NULL)\n   {ret= -1; goto ex;}\n if(strlen(name_expr)>=SfileadrL)\n   {ret= 0; goto ex;};\n\n ret= Findjob_default_and(o, 0);\n if(ret <= 0)\n   goto ex;\n t= o->cursor->test;\n t->test_type= 1;\n if ((flag & 3) == 1)\n   t->test_type= 13;\n else if((flag & 3) == 2)\n   t->test_type= 16;\n else if((flag & 3) == 3)\n   t->test_type= 20;\n t->arg1= strdup(name_expr);\n if(t->arg1 == NULL)\n   {ret= -1; goto ex;};\n\n if((flag & 3) == 3)\n   {ret= 1; goto ex;}\n\n name_re= (regex_t *) calloc(1, sizeof(regex_t));\n if(name_re == NULL)\n   {ret= -1; goto ex;};\n Xorriso__bourne_to_reg(name_expr, regexpr, 0);\n if(regcomp(name_re, regexpr, 0) != 0) {\n   free((char *) name_re);\n   {ret= 0; goto ex;};\n }\n t->arg2= name_re;\n ret= 1;\nex:;\n Xorriso_free_meM(regexpr);\n return(ret);\n}",
    "comment": "Constructs a regex from a given name expression and updates a job's testing criteria based on a specified flag, returning success status.",
    "prorec_sum": "Compiles a given pattern string into a `regex_t` structure, stores it with type flags in a context structure, and reports success or failure.",
    "filter_prorec_sum": "Compiles a regex from the given pattern string, stores it and related mode settings into a target structure, and returns success or failure.",
    "prorec_aug_sum": "Compiles a regex from the given pattern string, stores it with type metadata in a structure, and returns success or error status.",
    "filter_prorec_aug_sum": "Allocates resources, stores the input pattern and type code, compiles it into a regex, and saves the compiled regex in the target structure.",
    "work_score": {
        "prorec": {
            "summary": "Compiles a given pattern string into a `regex_t` structure, stores it with type flags in a context structure, and reports success or failure.",
            "score": [
                0.9333333333333332,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly notes that the function compiles a pattern into a `regex_t` structure, stores it in the context (`t->arg2`), and returns a success/failure code. However, it omits details about type flag handling and storage of the original string (`t->arg1`), and generalizes the context as a single structure without referencing `struct ExprtesT` or the specific flag-based test_type logic present in the code. Despite these omissions, the central operations described are accurate based on the source.",
                "The summary correctly identifies that a pattern string is compiled into a `regex_t` and stored alongside type flags in a context structure, and that success or failure is reported. These aspects are explicitly evidenced in the code: allocation of `regex_t`, use of `regcomp`, assignment to `t->arg2`, manipulation of `t->test_type` based on flags, and returning via `ret`. However, the summary omits several critical steps such as the initial allocation and length check of `regexpr`, the specific flag-based branching that can skip regex compilation, and error handling for null allocations or failed compilations. These omissions mean the description does not fully capture the complete logic and edge cases.",
                "The summary correctly notes that the function compiles a pattern into a `regex_t`, assigns a type flag, and returns success or failure, which is explicitly shown in the code through `regcomp`, `t->test_type` assignments, and return values. However, it omits other key details like memory allocation for `regexpr`, handling of edge cases (`strlen` check, null checks), and conditional early exits, making the accurate details somewhat generic rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Compiles a regex from the given pattern string, stores it and related mode settings into a target structure, and returns success or failure.",
            "score": [
                0.9666666666666667,
                0.6,
                0.6333333333333333
            ],
            "reason": [
                "The summary correctly notes that the function compiles a regex from the input pattern and stores it in a structure, as evidenced by the use of regcomp and assigning to t->arg2. It also accurately indicates that related mode settings are stored, supported by the flag-based assignment to t->test_type. The return of success or failure aligns with the conditional return values (ret). All core details in the summary are explicitly present in the source code, with no hallucinations detected.",
                "The summary captures the main idea of compiling a regex from the given string, storing it in a target structure, and returning success or failure, which is explicitly present in the source code. It correctly reflects the regex compilation via regcomp, storing into t->arg2, and return codes. However, it omits important logic such as allocation of regexpr, strlen check, setting test_type based on flag values, handling special case when flag & 3 equals 3 to skip regex compilation, and memory cleanup. These omissions mean the accurate details do not give a complete picture of the code's flow and edge case handling.",
                "The summary correctly states that the function compiles a regex from the provided pattern string and stores it into a structure, as seen with `regcomp` and assignment to `t->arg2`. It also accurately notes the setting of mode values (`t->test_type`) based on the `flag` and returns a status via `ret`. However, it omits specific implementation details such as memory allocation checks, early exits for certain flags, and use of helper functions that provide richer domain-specific context. The accurate details are generic and lack deeper insight into the code's logic."
            ]
        }
    }
}
{
    "source_code": "\nstatic void tg3_phy_toggle_apd(struct tg3 *tp, bool enable)\n{\n\tu32 reg;\n\n\tif (!tg3_flag(tp, 5705_PLUS) ||\n\t    (tg3_flag(tp, 5717_PLUS) &&\n\t     (tp->phy_flags & TG3_PHYFLG_MII_SERDES)))\n\t\treturn;\n\n\tif (tp->phy_flags & TG3_PHYFLG_IS_FET) {\n\t\ttg3_phy_fet_toggle_apd(tp, enable);\n\t\treturn;\n\t}\n\n\treg = MII_TG3_MISC_SHDW_WREN |\n\t      MII_TG3_MISC_SHDW_SCR5_SEL |\n\t      MII_TG3_MISC_SHDW_SCR5_LPED |\n\t      MII_TG3_MISC_SHDW_SCR5_DLPTLM |\n\t      MII_TG3_MISC_SHDW_SCR5_SDTL |\n\t      MII_TG3_MISC_SHDW_SCR5_C125OE;\n\tif (tg3_asic_rev(tp) != ASIC_REV_5784 || !enable)\n\t\treg |= MII_TG3_MISC_SHDW_SCR5_DLLAPD;\n\n\ttg3_writephy(tp, MII_TG3_MISC_SHDW, reg);\n\n\n\treg = MII_TG3_MISC_SHDW_WREN |\n\t      MII_TG3_MISC_SHDW_APD_SEL |\n\t      MII_TG3_MISC_SHDW_APD_WKTM_84MS;\n\tif (enable)\n\t\treg |= MII_TG3_MISC_SHDW_APD_ENABLE;\n\n\ttg3_writephy(tp, MII_TG3_MISC_SHDW, reg);\n}",
    "comment": "Toggles the APD feature of a PHY interface based on device flags and configurations, writing appropriate values to the hardware registers.",
    "prorec_sum": "Updates specific ATA port register fields to modify control flags and mode settings based on device status and the provided enable/disable parameter.",
    "filter_prorec_sum": "Updates specific AHCI/SATA port registers to configure PHY parameters and control flags based on current status bits and the provided enable/disable flag.",
    "prorec_aug_sum": "Updates specific PHY register bits on a network adapter based on link status flags and the provided control parameter.",
    "filter_prorec_aug_sum": "Updates specific PHY register values based on flag conditions and input parameter to control link settings or operational modes for the hardware.",
    "work_score": {
        "prorec": {
            "summary": "Updates specific ATA port register fields to modify control flags and mode settings based on device status and the provided enable/disable parameter.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims operations on ATA port registers, control flags, and mode settings, which are unrelated to the source code. The code manipulates PHY-related registers for a tg3 network driver, not ATA ports, and specifically uses tg3_writephy with MII_TG3_MISC_SHDW constants. None of the summary's details are supported by the provided source; all are hallucinations.",
                "The summary claims the function updates ATA port register fields and modifies control flags and mode settings based on device status, but the source code deals with toggling PHY settings for tg3 network devices via specific MII register writes. No ATA-related operations or references exist, making all details in the summary inaccurate and leaving no valid content after filtering.",
                "The summary claims to update ATA port register fields and modify control flags based on device status, but the source code is for toggling PHY APD settings in a tg3 network driver, using tg3_writephy and PHY-related flags, with no ATA references. All key details in the summary are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Updates specific AHCI/SATA port registers to configure PHY parameters and control flags based on current status bits and the provided enable/disable flag.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims AHCI/SATA port register updates and PHY parameter configuration based on status bits, but the source code works with tg3 Ethernet PHY control, using tg3_writephy and specific MII_TG3_MISC_SHDW register flags. There is no evidence of AHCI/SATA or status bits in the code, indicating the details are hallucinated and not grounded in the provided source.",
                "The summary claims the function updates AHCI/SATA port registers for PHY configuration, but the source code clearly operates on tg3 network PHY registers via tg3_writephy with MII_TG3 constants. The described AHCI/SATA context is inaccurate, and no accurate details remain after filtering, meaning the core logic is entirely missed.",
                "The summary claims AHCI/SATA port register updates and related PHY parameter configuration, but the source code is specific to Broadcom tg3 Ethernet PHY handling, toggling APD and writing to MII_TG3_MISC_SHDW registers. No AHCI or SATA context exists in the code. All semantic details in the summary are inaccurate, triggering the kill switch due to >50% hallucinations."
            ]
        }
    }
}
{
    "source_code": "\nstatic void calc_mode_timings(int xres, int yres, int refresh,\n\t\t\t      struct fb_videomode *mode)\n{\n\tstruct fb_var_screeninfo *var;\n\n\tvar = kzalloc(sizeof(struct fb_var_screeninfo), GFP_KERNEL);\n\n\tif (var) {\n\t\tvar->xres = xres;\n\t\tvar->yres = yres;\n\t\tfb_get_mode(FB_VSYNCTIMINGS | FB_IGNOREMON,\n\t\t\t    refresh, var, NULL);\n\t\tmode->xres = xres;\n\t\tmode->yres = yres;\n\t\tmode->pixclock = var->pixclock;\n\t\tmode->refresh = refresh;\n\t\tmode->left_margin = var->left_margin;\n\t\tmode->right_margin = var->right_margin;\n\t\tmode->upper_margin = var->upper_margin;\n\t\tmode->lower_margin = var->lower_margin;\n\t\tmode->hsync_len = var->hsync_len;\n\t\tmode->vsync_len = var->vsync_len;\n\t\tmode->vmode = 0;\n\t\tmode->sync = 0;\n\t\tkfree(var);\n\t}\n}",
    "comment": "Calculates video mode timings based on resolution and refresh rate, populating the provided fb_videomode structure with these settings.",
    "prorec_sum": "Allocates a 160\u2011byte structure, initializes it with given parameters, copies selected fields into another structure, and then releases the allocated memory.",
    "filter_prorec_sum": "Allocates and initializes a 160-byte structure with given parameters, invokes a setup routine, copies specific fields into an output buffer, and then releases the structure.",
    "prorec_aug_sum": "Allocates a 160-byte structure, populates it with input parameters, updates fields at a4, invokes processing, and releases the allocated structure.",
    "filter_prorec_aug_sum": "Allocates and initializes a 160\u2011byte structure with input fields, invokes a setup routine, copies specific elements into an output buffer, and then releases the structure.",
    "work_score": {
        "prorec": {
            "summary": "Allocates a 160\u2011byte structure, initializes it with given parameters, copies selected fields into another structure, and then releases the allocated memory.",
            "score": [
                0.7333333333333334,
                0.6666666666666666,
                0.7000000000000001
            ],
            "reason": [
                "The summary mentions allocation of a 160-byte structure, but the source code uses kzalloc(sizeof(struct fb_var_screeninfo)), and the exact size (160 bytes) is not confirmed in the code, making that detail inaccurate. It accurately describes initialization of fields from parameters, copying selected fields to another structure, and freeing the allocated memory, which are explicitly shown in the source. Overall, there is at least one key unverified assumption, lowering the accuracy ratio.",
                "The summary correctly notes allocation of a structure, initialization from parameters, copying selected fields to another structure, and freeing memory, which all have explicit evidence in the code. However, it inaccurately claims the structure is 160 bytes \u2014 the source code only uses sizeof(struct fb_var_screeninfo) and does not specify or imply the size. After discarding this hallucinated detail, the remaining accurate points cover the main logic flow, though without mentioning function calls like fb_get_mode or the specific set of fields handled, making the coverage incomplete.",
                "The summary claims allocation of a 160-byte structure, but the source code only shows allocation via kzalloc for sizeof(struct fb_var_screeninfo) without any evidence of its size being 160 bytes, making that detail inaccurate. It correctly notes that the structure is initialized with given parameters, selected fields are copied to another structure, and memory is freed. With one of four key details inaccurate (>25% but not exceeding half), the kill switch does not trigger. The accurate parts are generic procedural descriptions and lack domain-rich specifics."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a 160-byte structure with given parameters, invokes a setup routine, copies specific fields into an output buffer, and then releases the structure.",
            "score": [
                0.6333333333333334,
                0.6666666666666666,
                0.26666666666666666
            ],
            "reason": [
                "The summary correctly notes allocation of a structure, initialization with given parameters, copying specific fields to an output structure, and freeing it, all of which are explicitly supported by the code. However, it inaccurately specifies a '160-byte' size; the code uses sizeof(struct fb_var_screeninfo) without defining its exact byte size in the snippet, making that detail unverifiable. This single hallucination lowers the accuracy ratio but most of the summary is supported by the source code.",
                "The summary's claim about allocating a 160-byte structure is inaccurate, as the code allocates sizeof(struct fb_var_screeninfo) without indicating the exact byte size. The accurate details are: allocation of a structure, initialization with given parameters (xres, yres), invocation of fb_get_mode, copying several fields from the allocated structure to the output struct fb_videomode, and freeing the allocated memory. While these correct points capture the main logic of the function, the mention of 'output buffer' could be misleading since it is a struct, and the allocation size detail is incorrect.",
                "The summary contains multiple inaccuracies: it specifies a 160-byte structure with given parameters, but the source code allocates memory using sizeof(struct fb_var_screeninfo) without confirming its size; it describes invoking a 'setup routine' without explicitly naming fb_get_mode or its flags; it refers to copying fields into an 'output buffer', which is misleading since fields are copied into a struct fb_videomode. These inaccuracies make up more than half of the details, triggering the kill switch due to misleading description."
            ]
        }
    }
}
{
    "source_code": "int img_collect_inos(IsoImage *image, IsoDir *dir, int flag)\n{\n    int ret, register_dir = 1;\n    IsoDirIter *iter = NULL;\n    IsoNode *node;\n    IsoDir *subdir;\n\n    if (dir == NULL)\n        dir = image->root;\n    if (image->used_inodes == NULL) {\n        image->used_inodes = calloc(ISO_USED_INODE_RANGE / 8, 1);\n        if (image->used_inodes == NULL)\n            return ISO_OUT_OF_MEM;\n    } else if(!(flag & 1)) {\n        memset(image->used_inodes, 0, ISO_USED_INODE_RANGE / 8);\n    } else {\n        register_dir = 0;\n    }\n    if (register_dir) {\n        node = (IsoNode *) dir;\n        ret = img_register_ino(image, node, 0);\n        if (ret < 0)\n            return ret;\n    }\n\n    ret = iso_dir_get_children(dir, &iter);\n    if (ret < 0)\n        return ret;\n    while (iso_dir_iter_next(iter, &node) == 1 ) {\n        ret = img_register_ino(image, node, 0);\n        if (ret < 0)\n            goto ex;\n        if (iso_node_get_type(node) == LIBISO_DIR) {\n            subdir = (IsoDir *) node;\n            ret = img_collect_inos(image, subdir, flag | 1);\n            if (ret < 0)\n                goto ex;\n        }\n    }\n    ret = 1;\nex:;\n    if (iter != NULL)\n        iso_dir_iter_free(iter);\n    return ret;\n}",
    "comment": "Registers inodes for an ISO image and its subdirectories, initializing used inode tracking if necessary.",
    "prorec_sum": "Recursively processes ISO9660 directory records, allocating and clearing buffers, and invoking helper functions to read, iterate, and handle subdirectory entries.",
    "filter_prorec_sum": "Recursively processes ISO9660 directory entries, allocating and clearing buffers, and invoking helper functions to read, handle, and release directory resources.",
    "prorec_aug_sum": "Recursively processes and stores data blocks in a buffer, traversing linked records via helper calls until no further entries remain.",
    "filter_prorec_aug_sum": "Recursively processes and writes directory or file entries into a 32KB buffer, reinitializing it as needed and traversing subentries via helper callbacks.",
    "work_score": {
        "prorec": {
            "summary": "Recursively processes ISO9660 directory records, allocating and clearing buffers, and invoking helper functions to read, iterate, and handle subdirectory entries.",
            "score": [
                0.8000000000000002,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function processes directory entries recursively, allocates buffers with calloc, clears them with memset, and calls helper functions to iterate and handle subdirectories. However, it inaccurately claims handling of ISO9660-specific directory records without explicit evidence in the code, as the source only shows generic functions like iso_dir_get_children and iso_node_get_type without mention of ISO9660. Most core points are accurate except for this unverified assumption.",
                "The summary accurately notes recursive processing of directories and handling of subdirectory entries, as well as buffer allocation and clearing, all of which are explicitly present in the code through `img_collect_inos` calls, `calloc`, `memset`, and iteration over children. However, it introduces the term 'ISO9660 directory records' and 'invoking helper functions to read' without explicit evidence in the source code; the code deals with `IsoDir` structures and iteration, but does not show reading ISO9660 records per se. No mention is made of important error handling steps and flag-checking logic, which are key parts of the function, so the accurate details cover main actions but miss significant logic.",
                "The summary correctly notes the recursive processing of directory entries and the buffer allocation/clearing, which are explicitly present via the recursion into subdirectories and calloc/memset calls. However, it inaccurately claims the code processes ISO9660 directory records explicitly; the source code operates on generic IsoDir/IsoNode structures without clear evidence that these are ISO9660 records. The reference to 'helper functions to read' is also inaccurate, as the functions used (e.g., iso_dir_get_children, img_register_ino) handle iteration and registration rather than reading per se. More than half of the semantic details are accurate and domain-relevant, but their depth is moderate rather than highly specialized."
            ]
        },
        "filter_prorec": {
            "summary": "Recursively processes ISO9660 directory entries, allocating and clearing buffers, and invoking helper functions to read, handle, and release directory resources.",
            "score": [
                0.6333333333333333,
                0.6,
                0.5333333333333333
            ],
            "reason": [
                "The summary correctly notes recursive processing of directory entries and buffer allocation/clearing, both explicitly supported by the calloc/memset logic and the recursive img_collect_inos calls on subdirectories. However, it inaccurately claims reading and handling directory resources and releasing them in a generic sense; while helper functions are invoked, there is no evidence of actual data reading beyond iterating children, and the only release seen is freeing the iterator, not broader resource management. This makes the description partially accurate but containing unverified assumptions.",
                "The summary captures the recursive processing of directory entries and the allocation/clearing of buffers, which are explicitly shown via the recursive call to img_collect_inos and use of calloc/memset. It also notes invoking helper functions to handle directory resources, matching calls to img_register_ino, iso_dir_get_children, and iso_dir_iter_free. However, the summary omits key details such as conditional inode registration based on flags, error handling through return values and goto, and specific type checks (LIBISO_DIR). This missing information means the accurate details cover the main action but do not form a complete picture of the logic.",
                "The summary correctly notes that the function recursively processes directory entries and allocates/clears buffers, which matches the calloc/memset calls and the recursive call to img_collect_inos for subdirectories. However, it inaccurately claims the use of helper functions to 'read' and 'handle' directory resources broadly; the source only shows registering inodes and iterating children, not general reading logic, and 'release' is only partially accurate (iter free). Since fewer than half of the details are inaccurate and the accurate details are generic, the value is modest."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nxmlFARegExecSaveInputString(xmlRegExecCtxtPtr exec, const xmlChar *value,\n\t                    void *data) {\n#ifdef DEBUG_PUSH\n    printf(\"saving value: %d:%s\\n\", exec->inputStackNr, value);\n#endif\n    if (exec->inputStackMax == 0) {\n\texec->inputStackMax = 4;\n\texec->inputStack = (xmlRegInputTokenPtr)\n\t    xmlMalloc(exec->inputStackMax * sizeof(xmlRegInputToken));\n\tif (exec->inputStack == NULL) {\n\t    xmlRegexpErrMemory(NULL, \"pushing input string\");\n\t    exec->inputStackMax = 0;\n\t    return;\n\t}\n    } else if (exec->inputStackNr + 1 >= exec->inputStackMax) {\n\txmlRegInputTokenPtr tmp;\n\n\texec->inputStackMax *= 2;\n\ttmp = (xmlRegInputTokenPtr) xmlRealloc(exec->inputStack,\n\t\t\texec->inputStackMax * sizeof(xmlRegInputToken));\n\tif (tmp == NULL) {\n\t    xmlRegexpErrMemory(NULL, \"pushing input string\");\n\t    exec->inputStackMax /= 2;\n\t    return;\n\t}\n\texec->inputStack = tmp;\n    }\n    exec->inputStack[exec->inputStackNr].value = xmlStrdup(value);\n    exec->inputStack[exec->inputStackNr].data = data;\n    exec->inputStackNr++;\n    exec->inputStack[exec->inputStackNr].value = NULL;\n    exec->inputStack[exec->inputStackNr].data = NULL;\n}",
    "comment": "Stores an input string and associated data in a dynamically expanding stack within the xmlRegExecCtxt structure.",
    "prorec_sum": "Adds a duplicated XML string and associated data into a dynamically resized array within the given context structure.",
    "filter_prorec_sum": "Adds a duplicated input string and associated data into a dynamically resized array within the given context structure.",
    "prorec_aug_sum": "Adds a duplicated XML string and associated data to a dynamically resized array within a parser context structure.",
    "filter_prorec_aug_sum": "Adds a duplicated XML string and associated data to a dynamically resized array within the given parser context structure.",
    "work_score": {
        "prorec": {
            "summary": "Adds a duplicated XML string and associated data into a dynamically resized array within the given context structure.",
            "score": [
                1.0,
                0.7666666666666666,
                0.9
            ],
            "reason": [
                "The summary correctly describes that the function duplicates an XML string and stores it with associated data in a dynamically resized array within the context structure. This is explicitly evidenced by the use of `xmlStrdup(value)` to duplicate the string, assignments to `exec->inputStack[...].data`, and the resizing logic with `xmlMalloc`/`xmlRealloc`. No unverified assumptions or inaccuracies are present, making all details accurate.",
                "The summary accurately reflects the core functionality: the function duplicates an XML string, associates provided data, and stores them in a dynamically resized array within the context structure. This matches the explicit code evidence showing use of xmlStrdup for duplication, data assignment, and resizing via xmlMalloc/xmlRealloc. However, it omits mention of initial allocation checks, error handling, and null-terminating of array entries, so while the core action is covered, edge case handling is missing.",
                "The summary correctly describes that the function duplicates an XML string (via xmlStrdup) and stores it along with associated data into a dynamically resized array within the exec context structure. Each element's value and data are set, and resizing is handled with xmlMalloc and xmlRealloc when needed. The details are accurate, specific to the code, and domain-relevant, making the description aligned with the source logic."
            ]
        },
        "filter_prorec": {
            "summary": "Adds a duplicated input string and associated data into a dynamically resized array within the given context structure.",
            "score": [
                1.0,
                0.6999999999999998,
                0.9
            ],
            "reason": [
                "The summary accurately captures the core functionality of the function: duplicating the input string, associating it with provided data, and storing it in a dynamically resized array within the context structure. The source code shows xmlStrdup(value) for duplication, assignments to value and data fields, and logic for reallocating the inputStack array as needed. No extraneous or unverified claims are present.",
                "The summary accurately describes the core logic: the function duplicates the input string, associates it with given data, and places it into a dynamically resized array within the context structure. This aligns with the source code, which uses xmlStrdup for duplication, sets data, and handles resizing via xmlMalloc and xmlRealloc. While concise, it captures the main action, including dynamic array growth and insertion, but omits explicit mention of memory error handling, which means some edge-case logic is not fully covered.",
                "The summary accurately captures the core logic: the function duplicates the input string, associates it with provided data, and stores it in a dynamically resized array within the context. The source code shows dynamic allocation/reallocation of `exec->inputStack`, use of `xmlStrdup` for duplication, and storing both `value` and `data`. There are no inaccurate details, and the accurate detail provides specific insight into the memory management and data handling process."
            ]
        }
    }
}
{
    "source_code": "static void statPush(\n  sqlite3_context *context,\n  int argc,\n  sqlite3_value **argv\n){\n  int i;\n\n  /* The three function arguments */\n  Stat4Accum *p = (Stat4Accum*)sqlite3_value_blob(argv[0]);\n  int iChng = sqlite3_value_int(argv[1]);\n\n  UNUSED_PARAMETER( argc );\n  UNUSED_PARAMETER( context );\n  assert( p->nCol>0 );\n  assert( iChng<p->nCol );\n\n  if( p->nRow==0 ){\n    /* This is the first call to this function. Do initialization. */\n    for(i=0; i<p->nCol; i++) p->current.anEq[i] = 1;\n  }else{\n    /* Second and subsequent calls get processed here */\n    samplePushPrevious(p, iChng);\n\n    /* Update anDLt[], anLt[] and anEq[] to reflect the values that apply\n    ** to the current row of the index. */\n    for(i=0; i<iChng; i++){\n      p->current.anEq[i]++;\n    }\n    for(i=iChng; i<p->nCol; i++){\n      p->current.anDLt[i]++;\n#ifdef SQLITE_ENABLE_STAT3_OR_STAT4\n      p->current.anLt[i] += p->current.anEq[i];\n#endif\n      p->current.anEq[i] = 1;\n    }\n  }\n  p->nRow++;\n#ifdef SQLITE_ENABLE_STAT3_OR_STAT4\n  if( sqlite3_value_type(argv[2])==SQLITE_INTEGER ){\n    sampleSetRowidInt64(p->db, &p->current, sqlite3_value_int64(argv[2]));\n  }else{\n    sampleSetRowid(p->db, &p->current, sqlite3_value_bytes(argv[2]),\n                                       sqlite3_value_blob(argv[2]));\n  }\n  p->current.iHash = p->iPrn = p->iPrn*1103515245 + 12345;\n#endif\n\n#ifdef SQLITE_ENABLE_STAT4\n  {\n    tRowcnt nLt = p->current.anLt[p->nCol-1];\n\n    /* Check if this is to be a periodic sample. If so, add it. */\n    if( (nLt/p->nPSample)!=(nLt+1)/p->nPSample ){\n      p->current.isPSample = 1;\n      p->current.iCol = 0;\n      sampleInsert(p, &p->current, p->nCol-1);\n      p->current.isPSample = 0;\n    }\n\n    /* Update the aBest[] array. */\n    for(i=0; i<(p->nCol-1); i++){\n      p->current.iCol = i;\n      if( i>=iChng || sampleIsBetterPost(p, &p->current, &p->aBest[i]) ){\n        sampleCopy(p, &p->aBest[i], &p->current);\n      }\n    }\n  }\n#endif\n}",
    "comment": "Processes statistical data by updating counts and tracking samples based on input changes and row identifiers within a given dataset structure.",
    "prorec_sum": "Updates internal counters and flags in a cache entry structure based on an index value obtained from the provided input parameters.",
    "filter_prorec_sum": "Updates counters and flags in a cache entry structure based on an index value, incrementing relevant ranges and marking entries as active.",
    "prorec_aug_sum": "Increments counters and updates flag arrays within a retrieved structure based on the given index and total count, then increments the structure\u2019s primary counter.",
    "filter_prorec_aug_sum": "Updates counters and flags in a data structure based on an index value, then increments the structure\u2019s primary operation count.",
    "work_score": {
        "prorec": {
            "summary": "Updates internal counters and flags in a cache entry structure based on an index value obtained from the provided input parameters.",
            "score": [
                0.3666666666666667,
                0.3,
                0.09999999999999999
            ],
            "reason": [
                "The summary mentions updating internal counters and flags in a cache entry structure based on an index from input parameters, which loosely aligns with the code's behavior of modifying fields like anEq, anDLt, anLt in the Stat4Accum structure using iChng from argv[1]. However, the description of a 'cache entry structure' is inaccurate, as the structure is specific to statistical accumulation, not a generic cache. The mention of flags is vague and not clearly supported by explicit identifiers in the code, making some details unverified. Overall, the summary captures part of the high-level action but omits precise and accurate references to the actual logic and data types seen in the source.",
                "The summary's claim about updating internal counters and flags is partially accurate, as the code indeed updates arrays like anEq[], anDLt[], and conditionally flags such as isPSample based on iChng and other logic. However, the mention of a 'cache entry structure' is inaccurate \u2014 the code manipulates a Stat4Accum structure, not a cache entry. Important details from the source, such as initialization on first call, handling of rowid types, and periodic sampling logic, are missing, leaving the description incomplete regarding the core control flow and edge cases.",
                "The summary is highly generic and omits key domain-specific details present in the source code, such as initialization of anEq[], updates to anDLt[] and anLt[] arrays, conditional logic with SQLITE_ENABLE_STAT3_OR_STAT4 and SQLITE_ENABLE_STAT4, rowid handling, periodic sampling, and best sample updates. While it vaguely mentions updating counters and flags, it does not accurately reflect the explicit structures (Stat4Accum, current) or the specific operations in the code, resulting in most semantic details being absent or incorrectly generalized. The lack of accurate, explicit references means the proportion of inaccurate details exceeds the threshold."
            ]
        },
        "filter_prorec": {
            "summary": "Updates counters and flags in a cache entry structure based on an index value, incrementing relevant ranges and marking entries as active.",
            "score": [
                0.26666666666666666,
                0.16666666666666666,
                0.0
            ],
            "reason": [
                "The summary is overly generic and fails to capture verified details from the code. While it vaguely reflects that counters are updated based on an index value, it omits explicit structures such as 'p->current.anEq', 'p->current.anDLt', and 'p->current.anLt', and the function's sampling logic. It introduces unverified notions like 'cache entry structure' and 'marking entries as active', which are not present in the source code. Most semantic elements are either inaccurate or unverifiable, leading to a low accuracy ratio.",
                "The summary broadly states that counters and flags are updated based on an index and entries are marked active, but it omits specific, verifiable details from the source such as initialization on first call, distinct handling for anEq, anDLt, and anLt arrays, conditional compilation blocks for STAT3/STAT4, and logic for periodic sampling and aBest[] updates. The provided statement is overly generic and lacks the key explicit evidence from the code, resulting in minimal alignment with the actual control flow and data manipulation.",
                "The summary claims the function updates counters and flags in a cache entry structure, increments ranges, and marks entries as active, but the source code shows it operates on a Stat4Accum structure, updating arrays like anEq, anDLt, anLt, handling periodic samples, and modifying sample data for SQLite statistics\u2014there is no explicit 'cache entry' or 'marking entries as active' logic. These details are inaccurate and constitute more than half of the summary."
            ]
        }
    }
}
{
    "source_code": "\nstatic u32\nacpi_ex_convert_to_ascii(u64 integer, u16 base, u8 *string, u8 data_width)\n{\n\tu64 digit;\n\tu32 i;\n\tu32 j;\n\tu32 k = 0;\n\tu32 hex_length;\n\tu32 decimal_length;\n\tu32 remainder;\n\tu8 supress_zeros;\n\n\tACPI_FUNCTION_ENTRY();\n\n\tswitch (base) {\n\tcase 10:\n\n\t\t/* Setup max length for the decimal number */\n\n\t\tswitch (data_width) {\n\t\tcase 1:\n\t\t\tdecimal_length = ACPI_MAX8_DECIMAL_DIGITS;\n\t\t\tbreak;\n\n\t\tcase 4:\n\t\t\tdecimal_length = ACPI_MAX32_DECIMAL_DIGITS;\n\t\t\tbreak;\n\n\t\tcase 8:\n\t\tdefault:\n\t\t\tdecimal_length = ACPI_MAX64_DECIMAL_DIGITS;\n\t\t\tbreak;\n\t\t}\n\n\t\tsupress_zeros = TRUE;\t/* No leading zeros */\n\t\tremainder = 0;\n\n\t\tfor (i = decimal_length; i > 0; i--) {\n\n\t\t\t/* Divide by nth factor of 10 */\n\n\t\t\tdigit = integer;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t(void)acpi_ut_short_divide(digit, 10, &digit,\n\t\t\t\t\t\t\t   &remainder);\n\t\t\t}\n\n\t\t\t/* Handle leading zeros */\n\n\t\t\tif (remainder != 0) {\n\t\t\t\tsupress_zeros = FALSE;\n\t\t\t}\n\n\t\t\tif (!supress_zeros) {\n\t\t\t\tstring[k] = (u8) (ACPI_ASCII_ZERO + remainder);\n\t\t\t\tk++;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase 16:\n\n\t\t/* hex_length: 2 ascii hex chars per data byte */\n\n\t\thex_length = ACPI_MUL_2(data_width);\n\t\tfor (i = 0, j = (hex_length - 1); i < hex_length; i++, j--) {\n\n\t\t\t/* Get one hex digit, most significant digits first */\n\n\t\t\tstring[k] =\n\t\t\t    (u8) acpi_ut_hex_to_ascii_char(integer,\n\t\t\t\t\t\t\t   ACPI_MUL_4(j));\n\t\t\tk++;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn (0);\n\t}\n\n\t/*\n\t * Since leading zeros are suppressed, we must check for the case where\n\t * the integer equals 0\n\t *\n\t * Finally, null terminate the string and return the length\n\t */\n\tif (!k) {\n\t\tstring[0] = ACPI_ASCII_ZERO;\n\t\tk = 1;\n\t}\n\n\tstring[k] = 0;\n\treturn ((u32) k);\n}",
    "comment": "Converts a given integer to its ASCII representation in either decimal or hexadecimal format based on specified parameters and returns the string length.",
    "prorec_sum": "Generates a numeric string representation from input data in either decimal or hexadecimal format based on the specified type and length parameters.",
    "filter_prorec_sum": "Formats numeric data from the given source into a decimal or hexadecimal string based on parameters and writes it to the provided buffer.",
    "prorec_aug_sum": "Formats data from the given source into either decimal or hexadecimal string representation based on the specified type and writes it to the output buffer.",
    "filter_prorec_aug_sum": "Formats data from the given source into a decimal or hexadecimal string representation based on the specified type and output length.",
    "work_score": {
        "prorec": {
            "summary": "Generates a numeric string representation from input data in either decimal or hexadecimal format based on the specified type and length parameters.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function produces a numeric string from input data in decimal or hexadecimal format, which matches the switch cases for base 10 and base 16 in the code. It also accurately notes that formatting depends on specified type and length parameters, reflected in the 'data_width' handling. No unsupported or unverifiable claims are present, making all details accurate.",
                "The summary accurately captures the core function of the code: converting an integer to either decimal or hexadecimal string form based on given parameters for type (base) and data width. It omits important details such as suppression of leading zeros in decimal mode, handling of zero values explicitly, and the specific looping/division logic. These omissions mean it covers the main action but misses significant parts of the logic.",
                "The summary correctly states that the function generates a numeric string in decimal or hexadecimal based on input parameters. These details match the source code's switch cases for base 10 and base 16, handling length via data_width and applying specific logic for each format. However, the summary is generic and omits important specifics such as suppression of leading zeros, handling of integer==0 cases, and the precise digit extraction methods used, which are present in the source. While accurate, the value of the accurate details is low due to lack of domain-rich insights."
            ]
        },
        "filter_prorec": {
            "summary": "Formats numeric data from the given source into a decimal or hexadecimal string based on parameters and writes it to the provided buffer.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function formats numeric data into either decimal or hexadecimal based on the 'base' parameter and writes the result into the provided 'string' buffer. These details are explicitly supported in the source code by the switch statement handling base 10 and base 16 cases and the assignment to 'string'. No unsupported claims or hallucinations are present, making all extracted details accurate.",
                "The summary accurately states that the function formats numeric data into decimal or hexadecimal strings based on parameters and writes the result into a provided buffer. This aligns with the source code, which converts a u64 integer to ASCII in either base 10 or base 16, manages suppression of leading zeros, and writes to the string buffer before returning the length. However, the summary omits key details such as how leading zeros are suppressed, the role of data_width in determining decimal or hex length, and edge case handling when the value is zero, meaning the coverage is incomplete.",
                "The summary correctly identifies that the function formats numeric data into either decimal or hexadecimal based on the 'base' parameter and writes the result into the provided buffer, which is evidenced by the switch-case handling of base 10 and base 16 and use of string[k]. However, it omits specific implementation details such as suppression of leading zeros for decimal, handling of zero values, use of data_width to determine length, and the actual conversion logic via helper functions. The details present are accurate but generic, lacking domain-rich insights from the source code."
            ]
        }
    }
}
{
    "source_code": "static void renameTriggerFunc(\n  sqlite3_context *context,\n  int NotUsed,\n  sqlite3_value **argv\n){\n  unsigned char const *zSql = sqlite3_value_text(argv[0]);\n  unsigned char const *zTableName = sqlite3_value_text(argv[1]);\n\n  int token;\n  Token tname;\n  int dist = 3;\n  unsigned char const *zCsr = zSql;\n  int len = 0;\n  char *zRet;\n  sqlite3 *db = sqlite3_context_db_handle(context);\n\n  UNUSED_PARAMETER(NotUsed);\n\n  /* The principle used to locate the table name in the CREATE TRIGGER \n  ** statement is that the table name is the first token that is immediately\n  ** preceded by either TK_ON or TK_DOT and immediately followed by one\n  ** of TK_WHEN, TK_BEGIN or TK_FOR.\n  */\n  if( zSql ){\n    do {\n\n      if( !*zCsr ){\n        /* Ran out of input before finding the table name. Return NULL. */\n        return;\n      }\n\n      /* Store the token that zCsr points to in tname. */\n      tname.z = (char*)zCsr;\n      tname.n = len;\n\n      /* Advance zCsr to the next token. Store that token type in 'token',\n      ** and its length in 'len' (to be used next iteration of this loop).\n      */\n      do {\n        zCsr += len;\n        len = sqlite3GetToken(zCsr, &token);\n      }while( token==TK_SPACE );\n      assert( len>0 );\n\n      /* Variable 'dist' stores the number of tokens read since the most\n      ** recent TK_DOT or TK_ON. This means that when a WHEN, FOR or BEGIN \n      ** token is read and 'dist' equals 2, the condition stated above\n      ** to be met.\n      **\n      ** Note that ON cannot be a database, table or column name, so\n      ** there is no need to worry about syntax like \n      ** \"CREATE TRIGGER ... ON ON.ON BEGIN ...\" etc.\n      */\n      dist++;\n      if( token==TK_DOT || token==TK_ON ){\n        dist = 0;\n      }\n    } while( dist!=2 || (token!=TK_WHEN && token!=TK_FOR && token!=TK_BEGIN) );\n\n    /* Variable tname now contains the token that is the old table-name\n    ** in the CREATE TRIGGER statement.\n    */\n    zRet = sqlite3MPrintf(db, \"%.*s\\\"%w\\\"%s\", (int)(((u8*)tname.z) - zSql),\n       zSql, zTableName, tname.z+tname.n);\n    sqlite3_result_text(context, zRet, -1, SQLITE_DYNAMIC);\n  }\n}",
    "comment": "Replaces the old table name in a CREATE TRIGGER SQL statement with a new table name provided as an argument.",
    "prorec_sum": "Scans a byte buffer for specific marker values and, upon matching conditions, formats a composite string and dispatches it via a handler.",
    "filter_prorec_sum": "Parses byte sequences from provided buffers, detects specific opcode patterns, and formats a string for further processing through a callback function.",
    "prorec_aug_sum": "Parses a byte sequence from input buffers, detects specific marker codes, and formats matched fragments into a string for further processing.",
    "filter_prorec_aug_sum": "Parses byte sequences from two inputs, detecting specific marker values, and formats matched fragments into a string for further processing.",
    "work_score": {
        "prorec": {
            "summary": "Scans a byte buffer for specific marker values and, upon matching conditions, formats a composite string and dispatches it via a handler.",
            "score": [
                0.3,
                0.16666666666666666,
                0.0
            ],
            "reason": [
                "The summary omits key semantic details from the source code, such as the use of SQLite-specific functions (sqlite3_value_text, sqlite3GetToken, sqlite3MPrintf, sqlite3_result_text), the identification of a table name within a CREATE TRIGGER statement based on preceding and following tokens (TK_ON, TK_DOT, TK_WHEN, TK_FOR, TK_BEGIN), and the handling of token distances. The mention of scanning a byte buffer for marker values and dispatching via a handler is a vague reinterpretation without explicit grounding in the source code's actual logic, making most details unverified or inaccurate.",
                "The summary is inaccurate \u2014 the source code parses SQL text to locate and replace a table name in a CREATE TRIGGER statement, using token scanning and formatting with sqlite3 functions. The described 'byte buffer' scanning for 'marker values' and dispatching via a 'handler' omits critical semantic units like token identification (TK_ON, TK_DOT, TK_WHEN, etc.), condition logic for locating the table name, and use of sqlite3_result_text for returning the modified SQL. No accurate details were present to map to the actual control flow or data manipulations in the source.",
                "The summary omits key details from the source code, such as its purpose of locating and replacing the table name in a CREATE TRIGGER SQL statement based on specific token patterns (TK_ON, TK_DOT, followed by TK_WHEN, TK_FOR, or TK_BEGIN). While 'scans a byte buffer' loosely reflects iterating over zSql via tokens, there is no mention of the critical token-based logic, SQLite functions used (sqlite3_value_text, sqlite3GetToken, sqlite3MPrintf), or that the output is a modified SQL string. Most semantic details in the summary are too generic, and at least half are inaccurate or under-specified, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Parses byte sequences from provided buffers, detects specific opcode patterns, and formats a string for further processing through a callback function.",
            "score": [
                0.13333333333333333,
                0.06666666666666667,
                0.0
            ],
            "reason": [
                "The summary\u2019s claims about parsing byte sequences, detecting opcode patterns, and using a callback function are not supported by the source code. The code works with token parsing in SQL statements, specifically locating and replacing a table name in a CREATE TRIGGER statement, using SQLite API functions like sqlite3GetToken and sqlite3MPrintf. No evidence exists for opcode pattern detection or callbacks, making the only partial alignment the fact that it formats a string, while most details are hallucinations.",
                "The summary claims the code parses byte sequences, detects opcode patterns, and formats a string for a callback function. The source code does not explicitly handle opcodes; it parses SQL text tokens to locate and replace a table name in a CREATE TRIGGER statement, using sqlite3 functions, and returns the result via sqlite3_result_text. The 'byte sequences' and 'opcode patterns' references are unsupported by the code, leaving little accurate detail from the summary.",
                "The summary claims parsing byte sequences, detecting opcode patterns, and using a callback function. In reality, the code parses SQL trigger statements to locate a table name using token logic, and formats the string with sqlite3MPrintf before returning it via sqlite3_result_text. There is no explicit evidence of opcode pattern detection or a callback mechanism beyond standard SQLite function calls. More than half of the described details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "int blk_bio_map_sg(struct request_queue *q, struct bio *bio,\n\t\t   struct scatterlist *sglist)\n{\n\tstruct bio_vec *bvec, *bvprv;\n\tstruct scatterlist *sg;\n\tint nsegs, cluster;\n\tunsigned long i;\n\n\tnsegs = 0;\n\tcluster = blk_queue_cluster(q);\n\n\tbvprv = NULL;\n\tsg = NULL;\n\tbio_for_each_segment(bvec, bio, i) {\n\t\t__blk_segment_map_sg(q, bvec, sglist, &bvprv, &sg,\n\t\t\t\t     &nsegs, &cluster);\n\t} /* segments in bio */\n\n\tif (sg)\n\t\tsg_mark_end(sg);\n\n\tBUG_ON(bio->bi_phys_segments && nsegs > bio->bi_phys_segments);\n\treturn nsegs;\n}",
    "comment": "Maps segments of a block I/O bio to a scatter-gather list, updating the number of segments and handling physical segment constraints.",
    "prorec_sum": "Iterates over consecutive block entries from a starting index, processes each via a helper, updates metadata flags, and verifies block count constraints.",
    "filter_prorec_sum": "Processes consecutive table entries from the given index, invoking a helper on each, updates a status flag, and enforces a maximum allowed count limit.",
    "prorec_aug_sum": "Iterates over consecutive 16\u2011byte entries from a starting index, processes each with sub_FFFFFFFF8129B260, updates state, and enforces a maximum count constraint.",
    "filter_prorec_aug_sum": "Iterates over consecutive 16\u2011byte entries from a given index, processes them via sub_FFFFFFFF8129B260, updates flags, and returns the processed count.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over consecutive block entries from a starting index, processes each via a helper, updates metadata flags, and verifies block count constraints.",
            "score": [
                0.3666666666666667,
                0.6,
                0.16666666666666666
            ],
            "reason": [
                "The summary contains multiple inaccuracies: it claims iteration over 'consecutive block entries from a starting index', but the code iterates over bio segments using bio_for_each_segment without an explicit starting index concept; 'updates metadata flags' is vague and unsupported\u2014code only calls sg_mark_end, which marks the end of the scatter-gather list element, not generic metadata flags; 'processes each via a helper' is accurate since __blk_segment_map_sg is called for each segment; 'verifies block count constraints' partly matches the BUG_ON check comparing nsegs to bio->bi_phys_segments. Overall, only about half of the details are clearly evidenced in the source.",
                "The summary correctly identifies iteration over entries (bio_for_each_segment) and invoking a helper function (__blk_segment_map_sg), as well as enforcing a block count constraint (BUG_ON comparing nsegs to bi_phys_segments). However, details like 'consecutive block entries from a starting index' and 'updates metadata flags' are not explicitly evidenced in the source code \u2014 there is no visible index management beyond the loop macro and no clear metadata flag updates. The accurate parts cover the main flow but omit specific elements like sg_mark_end's role and initial variable setup, so the overall picture is incomplete.",
                "The summary claims iteration over consecutive block entries from a starting index, which loosely matches the bio_for_each_segment loop. It also mentions processing each via a helper, which aligns with the __blk_segment_map_sg call. However, 'updates metadata flags' is inaccurate since the source only marks the end of the scatterlist (sg_mark_end) and does not update actual metadata flags. The verification of block count constraints is accurate due to the BUG_ON logic checking nsegs against bi_phys_segments. With 1 out of 3 claims inaccurate (~33%), the proportion is under the kill switch threshold, but most accurate details are general rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Processes consecutive table entries from the given index, invoking a helper on each, updates a status flag, and enforces a maximum allowed count limit.",
            "score": [
                0.2333333333333333,
                0.10000000000000002,
                0.0
            ],
            "reason": [
                "The summary contains multiple unverified or incorrect details. The source code iterates over bio segments with a helper function (__blk_segment_map_sg), but there is no evidence of processing 'consecutive table entries' or a specific 'given index'. The code does not explicitly update a 'status flag', and the 'maximum allowed count limit' is enforced via BUG_ON with bi_phys_segments, which is domain-specific but not clearly matching the summary's phrasing. Only the iteration with helper invocation is accurate; most other details are unsupported, resulting in less than half of the summary being correct.",
                "The summary's claims about processing consecutive table entries from a given index, updating a status flag, and enforcing a maximum allowed count do not match explicit details in the source code. The function iterates over bio segments using bio_for_each_segment, calls a helper to map each segment to a scatterlist, marks the end scatterlist entry, and checks segment count against bio->bi_phys_segments, but there is no concept of table entries or a generic status flag. After filtering out inaccuracies, no accurate details remain, leaving the core logic unrepresented.",
                "The summary claims processing of consecutive table entries from a given index, updating a status flag, and enforcing a maximum allowed count limit. In the source code, there is iteration over bio segments via bio_for_each_segment, which could loosely match 'consecutive entries', and invocation of a helper (__blk_segment_map_sg). However, there is no explicit notion of a 'given index' controlling the sequence beyond the macro's iteration variable, no status flag being updated, and no explicit maximum limit beyond a BUG_ON check comparing nsegs to bi_phys_segments. More than half of the stated details (status flag update, table entries, given index concept) are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\ncleanup (void)\n{\n  if (close (STDIN_FILENO) < 0)\n    die (EXIT_FAILURE, errno, _(\"closing input file %s\"), quoteaf (input_file));\n\n  /* Don't remove this call to close, even though close_stdout\n     closes standard output.  This close is necessary when cleanup\n     is called as part of a signal handler.  */\n  if (close (STDOUT_FILENO) < 0)\n    die (EXIT_FAILURE, errno,\n         _(\"closing output file %s\"), quoteaf (output_file));\n}",
    "comment": "Cleans up temporary nodes by unlinking their associated names and resets the temporary head pointer to NULL.",
    "prorec_sum": "Handles process termination by sending designated signals to a target PID, logging actions, and performing follow-up kills for specific signal types.",
    "filter_prorec_sum": "Handles signals by optionally logging, resetting timers, and sending them to a target process and process group, including follow-up stop signals when appropriate.",
    "prorec_aug_sum": "Handles delivering the specified signal to a target process, optionally logging the action, and managing related termination or continuation signals.",
    "filter_prorec_aug_sum": "Handles sending specified signals to a process or group, with optional messaging, cleanup, and additional stop signal delivery when appropriate.",
    "work_score": {
        "prorec": {
            "summary": "Handles process termination by sending designated signals to a target PID, logging actions, and performing follow-up kills for specific signal types.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes process termination via signals, logging, and follow-up kills, but the source code only performs file descriptor closures for stdin and stdout and reports errors. There is no evidence of signal handling, PID targeting, or logging actions, making all details in the summary inaccurate.",
                "The summary claims signal sending to a target PID, action logging, and follow-up kills, none of which appear in the source code. The source code only contains a cleanup function that closes stdin and stdout, with error handling using die(), and no process termination or signal-related logic. Therefore, all details in the summary are inaccurate and do not reflect the code\u2019s actual functionality.",
                "The summary claims process termination, sending signals to a target PID, logging actions, and performing follow-up kills for specific signal types. None of these behaviors are present in the source code, which only defines a cleanup function that closes STDIN and STDOUT and handles potential errors. All details in the summary are inaccurate, triggering the kill switch due to more than 50% inaccuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Handles signals by optionally logging, resetting timers, and sending them to a target process and process group, including follow-up stop signals when appropriate.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes handling signals, logging, resetting timers, and sending signals to processes, but the source code only contains a cleanup function that closes standard input and output, with no evidence of signal handling, logging, timers, or process management. All details in the summary are unsupported, indicating complete inaccuracy.",
                "The summary describes complex signal handling logic including logging, timer resets, targeting processes, and sending follow-up stop signals, none of which are present in the source code. The code only contains a cleanup function that closes STDIN and STDOUT with error handling, and there is no evidence of any signal handling or messaging to process groups. All details in the summary are inaccurate, leaving no valid content to evaluate.",
                "The summary claims signal handling with logging, timer resets, and forwarding to target processes/groups, which is unsupported by the source code. The provided code only closes standard input/output and reports errors, without any logic for signals, timers, process groups, or follow-up stop signals. All details in the summary are inaccurate, triggering the kill switch due to >50% inaccuracies."
            ]
        }
    }
}
{
    "source_code": "int schedule_on_each_cpu(work_func_t func)\n{\n\tint cpu;\n\tstruct work_struct __percpu *works;\n\n\tworks = alloc_percpu(struct work_struct);\n\tif (!works)\n\t\treturn -ENOMEM;\n\n\tget_online_cpus();\n\n\tfor_each_online_cpu(cpu) {\n\t\tstruct work_struct *work = per_cpu_ptr(works, cpu);\n\n\t\tINIT_WORK(work, func);\n\t\tschedule_work_on(cpu, work);\n\t}\n\n\tfor_each_online_cpu(cpu)\n\t\tflush_work(per_cpu_ptr(works, cpu));\n\n\tput_online_cpus();\n\tfree_percpu(works);\n\treturn 0;\n}",
    "comment": "Schedules a specified work function on each online CPU and waits for their completion before freeing allocated resources.",
    "prorec_sum": "Allocates a control block, iterates over IRQ descriptors to initialize handler data with provided parameters, finalizes links, and releases allocated resources.",
    "filter_prorec_sum": "Initializes and links per\u2011CPU data structures, invokes setup routines with provided parameters for each CPU, then finalizes and frees allocated resources.",
    "prorec_aug_sum": "Allocates a 32-byte context, iterates over indexed entries to initialize and process them with provided parameters, then cleans up and releases the allocation.",
    "filter_prorec_aug_sum": "Initializes structures for each indexed entry, invokes a processing routine with provided parameters, then finalizes and frees allocated resources.",
    "work_score": {
        "prorec": {
            "summary": "Allocates a control block, iterates over IRQ descriptors to initialize handler data with provided parameters, finalizes links, and releases allocated resources.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes allocating a control block, iterating over IRQ descriptors, initializing handler data, and finalizing links, none of which are reflected in the source code. The actual code allocates per-CPU work structures, iterates over online CPUs, schedules work, flushes work, and frees resources. All details in the summary are hallucinations, with no explicit evidence in the code.",
                "The summary's details about allocating a control block, iterating over IRQ descriptors, initializing handler data, and finalizing links are not present in the source code. The source code deals with allocating per-CPU work structures, initializing them with a function, scheduling work on each CPU, flushing the work, and freeing resources. None of the summary's claims are explicitly evidenced, so all are inaccurate, leaving no valid details to map to the core logic.",
                "The summary claims the code allocates a control block for IRQ descriptors, initializes handler data, finalizes links, and releases resources. None of these details match the actual source code, which allocates per-CPU work_structs, schedules work on each CPU, flushes work, and frees the structures. All semantic details in the summary are inaccurate, exceeding the 50% threshold and triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes and links per\u2011CPU data structures, invokes setup routines with provided parameters for each CPU, then finalizes and frees allocated resources.",
            "score": [
                0.7666666666666666,
                0.6,
                0.6666666666666666
            ],
            "reason": [
                "The summary correctly notes initialization of per\u2011CPU data structures and freeing of resources, which are explicitly seen via alloc_percpu, INIT_WORK, and free_percpu in the source. However, it inaccurately describes 'links' and 'setup routines', which are not directly evidenced in the code. The use of 'finalizes' is vague and not clearly tied to any code function. Roughly half of the details are grounded in the source, while the rest are unverified assumptions.",
                "The summary accurately notes initialization of per\u2011CPU data structures, invoking routines for each CPU, and freeing resources, which matches alloc_percpu, looped INIT_WORK/schedule_work_on calls, and free_percpu in the code. However, it omits critical control flow such as error handling on allocation failure, the get_online_cpus/put_online_cpus calls that guard CPU iteration, and the flush_work calls to complete queued work. These omissions mean the accurate details do not fully capture the code\u2019s logic and edge cases.",
                "The summary correctly notes initialization of per-CPU data structures, executing logic for each CPU, and freeing resources, which are explicitly shown in the code via alloc_percpu, for_each_online_cpu loops, INIT_WORK, schedule_work_on, flush_work, and free_percpu. While these details are accurate, they are generic and do not reference specific functions or structures by name, limiting their domain-rich value."
            ]
        }
    }
}
{
    "source_code": "\nstatic int put_compat_statfs(struct compat_statfs __user *ubuf, struct kstatfs *kbuf)\n{\n\t\n\tif (sizeof ubuf->f_blocks == 4) {\n\t\tif ((kbuf->f_blocks | kbuf->f_bfree | kbuf->f_bavail |\n\t\t     kbuf->f_bsize | kbuf->f_frsize) & 0xffffffff00000000ULL)\n\t\t\treturn -EOVERFLOW;\n\t\t/* f_files and f_ffree may be -1; it's okay\n\t\t * to stuff that into 32 bits */\n\t\tif (kbuf->f_files != 0xffffffffffffffffULL\n\t\t && (kbuf->f_files & 0xffffffff00000000ULL))\n\t\t\treturn -EOVERFLOW;\n\t\tif (kbuf->f_ffree != 0xffffffffffffffffULL\n\t\t && (kbuf->f_ffree & 0xffffffff00000000ULL))\n\t\t\treturn -EOVERFLOW;\n\t}\n\tif (!access_ok(VERIFY_WRITE, ubuf, sizeof(*ubuf)) ||\n\t    __put_user(kbuf->f_type, &ubuf->f_type) ||\n\t    __put_user(kbuf->f_bsize, &ubuf->f_bsize) ||\n\t    __put_user(kbuf->f_blocks, &ubuf->f_blocks) ||\n\t    __put_user(kbuf->f_bfree, &ubuf->f_bfree) ||\n\t    __put_user(kbuf->f_bavail, &ubuf->f_bavail) ||\n\t    __put_user(kbuf->f_files, &ubuf->f_files) ||\n\t    __put_user(kbuf->f_ffree, &ubuf->f_ffree) ||\n\t    __put_user(kbuf->f_namelen, &ubuf->f_namelen) ||\n\t    __put_user(kbuf->f_fsid.val[0], &ubuf->f_fsid.val[0]) ||\n\t    __put_user(kbuf->f_fsid.val[1], &ubuf->f_fsid.val[1]) ||\n\t    __put_user(kbuf->f_frsize, &ubuf->f_frsize) ||\n\t    __put_user(kbuf->f_flags, &ubuf->f_flags) ||\n\t    __clear_user(ubuf->f_spare, sizeof(ubuf->f_spare)))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
    "comment": "Validates and transfers filesystem statistics from kernel to user space, ensuring no overflow occurs for 32-bit fields.",
    "prorec_sum": "Validates 64-bit fields for overflow, copies structured data from `a2` to `a1`, and initializes additional fields with a fixed-size subroutine call.",
    "filter_prorec_sum": "Validates 64-bit field widths and copies data from a source structure into a destination array, returning specific error codes on validation failures.",
    "prorec_aug_sum": "Validates multiple 64-bit fields from a source structure for 32-bit constraints, copies them into a destination buffer, and performs a final integrity check.",
    "filter_prorec_aug_sum": "Validates multiple 64\u2011bit fields for 32\u2011bit limits, copies them into a destination buffer, and performs a final 16\u2011byte data integrity check.",
    "work_score": {
        "prorec": {
            "summary": "Validates 64-bit fields for overflow, copies structured data from `a2` to `a1`, and initializes additional fields with a fixed-size subroutine call.",
            "score": [
                0.3,
                0.5,
                0.0
            ],
            "reason": [
                "The summary claims data is copied from `a2` to `a1`, but the source code uses `kbuf` and `ubuf` parameters, making this detail inaccurate. It also mentions a fixed-size subroutine call to initialize additional fields, which is not explicitly present; instead, fields are set via multiple `__put_user` calls and `__clear_user`. The overflow validation of 64-bit fields is accurate, as the code checks for values exceeding 32-bit limits before assignment. Overall, only one detail is accurate while the other two are unsupported, leading to a low accuracy ratio.",
                "The summary correctly notes overflow validation for 64-bit fields, which is explicitly shown in the code through bitmask checks against 0xffffffff00000000ULL. However, it inaccurately describes copying data from `a2` to `a1`\u2014the code actually copies from `kbuf` to `ubuf` using multiple `__put_user` calls. The mention of a fixed-size subroutine call is vague and does not clearly map to the actual `__clear_user` invocation that zeroes a spare field, resulting in partial coverage of the core logic and missing explicit details about access checks and error handling.",
                "The summary claims data is copied from 'a2' to 'a1', but the source code uses 'kbuf' and 'ubuf', making this detail inaccurate. The claim about initializing additional fields via a fixed-size subroutine call is vague and not explicitly supported, as the code uses __clear_user rather than a clearly named initialization routine. The accurate part is the validation of 64-bit fields for overflow, which matches the initial conditional checks. With 2 of the 3 claims being inaccurate, the proportion of inaccuracies exceeds 50%, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Validates 64-bit field widths and copies data from a source structure into a destination array, returning specific error codes on validation failures.",
            "score": [
                0.5333333333333333,
                0.6,
                0.19999999999999998
            ],
            "reason": [
                "The summary states that the function validates 64-bit field widths and copies data into a destination array, but the source code actually checks whether certain fields fit within 32 bits when the destination field size is 4 bytes, and it copies to a struct using __put_user rather than into an array. While it correctly notes validation and data copying with specific error codes, the type detail (64-bit) and 'array' claim are inaccurate, leading to mixed accuracy.",
                "The summary correctly identifies that the function validates field sizes related to 64-bit values and copies data from one structure to another, returning error codes (-EOVERFLOW/-EFAULT) when validation fails. However, it inaccurately describes the destination as an array rather than a struct, omitting critical details like specific 32-bit overflow checks for multiple fields and use of access_ok and __put_user calls. While the main action is conveyed, important aspects of control flow and edge case handling are missing.",
                "The summary states that the function validates 64-bit field widths, which is inaccurate because the code specifically checks if certain fields fit into 32-bit values (using masks like 0xffffffff00000000ULL). It also describes copying from a source structure into a destination array, but the destination is a struct (`ubuf`), not an array, making this detail inaccurate. Accurate details include the fact that data from one structure (`kbuf`) is written to another (`ubuf`) and that specific error codes like -EOVERFLOW and -EFAULT are returned based on validation or write failures. However, more than half of the details in the summary are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\n\nsize_t ZSTD_compressEnd (ZSTD_CCtx* cctx,\n                         void* dst, size_t dstCapacity,\n                   const void* src, size_t srcSize)\n{\n    size_t endResult;\n    size_t const cSize = ZSTD_compressContinue_internal(cctx, dst, dstCapacity, src, srcSize, 1, 1);\n    if (ZSTD_isError(cSize)) return cSize;\n    endResult = ZSTD_writeEpilogue(cctx, (char*)dst + cSize, dstCapacity-cSize);\n    if (ZSTD_isError(endResult)) return endResult;\n    return cSize + endResult;\n}",
    "comment": "Compresses data using a continuation method, writes an epilogue, and returns the total compressed size or an error code if the process fails.",
    "prorec_sum": "Processes data in a buffer based on state flags, inserting control values, and returns total bytes handled or specific error codes.",
    "filter_prorec_sum": "Processes a data buffer with staged operations based on state flags, writing marker and value bytes, and returning total bytes consumed or error codes.",
    "prorec_aug_sum": "Processes a data block with state-dependent transformations, writes optional marker and value fields, and returns total processed bytes or an error code.",
    "filter_prorec_aug_sum": "Processes a data block with state-dependent steps, inserting markers or values, and returns the total bytes written or an error code.",
    "work_score": {
        "prorec": {
            "summary": "Processes data in a buffer based on state flags, inserting control values, and returns total bytes handled or specific error codes.",
            "score": [
                0.3,
                0.26666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims processing based on state flags and inserting control values, but the source code shows function calls to compress data and write an epilogue without any explicit state flag handling or control value insertion. While returning total bytes handled or error codes is accurate, most of the described details lack direct evidence from the code, resulting in a majority of hallucinated content.",
                "The summary's claims about processing data based on state flags and inserting control values are not explicitly supported by the source code. The code clearly compresses data using ZSTD functions, checks for errors, and returns either the error code or the sum of compressed size and epilogue size. Since the described logic in the summary does not match the actual function calls or structures in the source code, the details are inaccurate, leaving no valid content to map to critical semantic units.",
                "The summary introduces concepts like 'state flags' and 'inserting control values' that are not explicitly present in the source code, making them inaccurate. The code shown involves calling specific functions (`ZSTD_compressContinue_internal` and `ZSTD_writeEpilogue`), checking for errors, and returning the sum of result sizes, which matches only the part about returning total bytes or error codes. Since more than half of the stated details are unsupported by the source, the kill switch applies."
            ]
        },
        "filter_prorec": {
            "summary": "Processes a data buffer with staged operations based on state flags, writing marker and value bytes, and returning total bytes consumed or error codes.",
            "score": [
                0.10000000000000002,
                0.10000000000000002,
                0.0
            ],
            "reason": [
                "The summary introduces unverified elements such as 'staged operations based on state flags', 'writing marker and value bytes', and 'total bytes consumed or error codes'. The source code only shows a compression process using ZSTD functions, checking for errors and returning a size value. There is no explicit evidence of marker bytes, state flags, or value bytes in the source. The only accurate detail is that it returns either a size result or an error code, but the majority of the claims are hallucinations.",
                "The summary's claims about staged operations, state flags, and writing marker/value bytes are not supported by any explicit evidence in the source code. The code performs compression by calling ZSTD_compressContinue_internal, checks for errors, writes an epilogue, and returns the sum of compressed data and epilogue size. None of the described marker or flag logic appears, so the main logic in the summary is inaccurate and no accurate details remain.",
                "The summary claims staged operations based on state flags and writing marker/value bytes, but the source code shows compression followed by an epilogue write, with no explicit flags or marker/value byte operations. These core details are inaccurate, exceeding the threshold for the kill switch. There is minimal overlap between the described process and the actual function\u2019s compression and error-checking logic."
            ]
        }
    }
}
{
    "source_code": "void nfs_init_timeout_values(struct rpc_timeout *to, int proto,\n\t\t\t\t    unsigned int timeo, unsigned int retrans)\n{\n\tto->to_initval = timeo * HZ / 10;\n\tto->to_retries = retrans;\n\n\tswitch (proto) {\n\tcase XPRT_TRANSPORT_TCP:\n\tcase XPRT_TRANSPORT_RDMA:\n\t\tif (to->to_retries == 0)\n\t\t\tto->to_retries = NFS_DEF_TCP_RETRANS;\n\t\tif (to->to_initval == 0)\n\t\t\tto->to_initval = NFS_DEF_TCP_TIMEO * HZ / 10;\n\t\tif (to->to_initval > NFS_MAX_TCP_TIMEOUT)\n\t\t\tto->to_initval = NFS_MAX_TCP_TIMEOUT;\n\t\tto->to_increment = to->to_initval;\n\t\tto->to_maxval = to->to_initval + (to->to_increment * to->to_retries);\n\t\tif (to->to_maxval > NFS_MAX_TCP_TIMEOUT)\n\t\t\tto->to_maxval = NFS_MAX_TCP_TIMEOUT;\n\t\tif (to->to_maxval < to->to_initval)\n\t\t\tto->to_maxval = to->to_initval;\n\t\tto->to_exponential = 0;\n\t\tbreak;\n\tcase XPRT_TRANSPORT_UDP:\n\t\tif (to->to_retries == 0)\n\t\t\tto->to_retries = NFS_DEF_UDP_RETRANS;\n\t\tif (!to->to_initval)\n\t\t\tto->to_initval = NFS_DEF_UDP_TIMEO * HZ / 10;\n\t\tif (to->to_initval > NFS_MAX_UDP_TIMEOUT)\n\t\t\tto->to_initval = NFS_MAX_UDP_TIMEOUT;\n\t\tto->to_maxval = NFS_MAX_UDP_TIMEOUT;\n\t\tto->to_exponential = 1;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n}",
    "comment": "Initializes timeout values for NFS RPC transport depending on the protocol type, setting retries, initial timeout, and limits accordingly.",
    "prorec_sum": "Calculates and sets timing parameters and state flags in a structure based on input codes, a rate value, and an auxiliary parameter.",
    "filter_prorec_sum": "Calculates and sets timeout and related fields in a structure based on provided parameters, enforcing limits and special cases for specific operation codes.",
    "prorec_aug_sum": "Configures timeout and related interval fields in a structure based on input parameters, with special handling for specific operation codes and bounds enforcement.",
    "filter_prorec_aug_sum": "Calculates and sets timeout and retry parameters in a connection-related structure based on input type, scale, and retry count constraints.",
    "work_score": {
        "prorec": {
            "summary": "Calculates and sets timing parameters and state flags in a structure based on input codes, a rate value, and an auxiliary parameter.",
            "score": [
                0.5333333333333333,
                0.5666666666666667,
                0.16666666666666666
            ],
            "reason": [
                "The summary is accurate only at a very high level, correctly noting that timing parameters and flags are set in a structure based on inputs. However, it omits nearly all specific semantic details present in the source code, such as protocol-specific logic for TCP, RDMA, and UDP, default values, conditional adjustments, and exact structure fields. Because the summary does not include or verify these explicit elements, the proportion of accurately detailed content is very low.",
                "The summary captures the general idea of setting timing parameters in a structure, but omits critical control flow details from the source code such as protocol-specific handling for TCP, RDMA, and UDP, default value assignments, clamping to maximums, setting of incremental values, and exponential flag assignment. The vague mention of 'state flags' is not explicitly supported by the source, making the coverage incomplete and lacking edge case logic.",
                "The summary is highly generic and omits nearly all specific, evidence-backed details from the source code, such as the handling of different transport protocols (TCP, RDMA, UDP), specific constants like NFS_DEF_TCP_RETRANS or NFS_MAX_UDP_TIMEOUT, calculation formulas using HZ, and conditional adjustments of retries and timeout values. While the summary vaguely mentions setting timing parameters and flags, it does not explicitly capture the domain-rich logic or constants present in the code. As a result, most critical semantic details are missing, making the accurate detail proportion well below half."
            ]
        },
        "filter_prorec": {
            "summary": "Calculates and sets timeout and related fields in a structure based on provided parameters, enforcing limits and special cases for specific operation codes.",
            "score": [
                0.6666666666666666,
                0.6333333333333333,
                0.5666666666666668
            ],
            "reason": [
                "The summary captures the general idea that the function calculates and sets timeout-related fields based on parameters and applies limits for certain cases, which is supported by the explicit assignments and conditional logic in the code. However, it inaccurately uses the term 'operation codes' instead of clearly specifying the transport protocol cases (TCP, RDMA, UDP) shown in the switch statement, making this detail unverified. Overall, the majority of the semantic content aligns with the source code, but one key detail is inaccurate.",
                "The summary correctly captures that the function computes and sets timeout-related fields in a structure based on parameters and applies limits and special handling for different transport types. These points are explicitly supported by the source code\u2019s assignments, conditional checks, and switch cases for TCP, RDMA, and UDP. However, it omits details about specific constants used, initial calculations, and handling of edge cases like retry defaults and BUG() in the default branch, so it lacks full coverage of the code\u2019s logic.",
                "The summary accurately captures that the function calculates and sets timeout-related fields in a structure based on parameters and applies limits depending on different transport protocol cases. However, it refers to 'specific operation codes', which is inaccurate since the code uses transport protocol constants (TCP, RDMA, UDP), not operation codes. The majority of details are accurate and domain-relevant, but the description is somewhat generic and omits specifics like exponential backoff for UDP or increment calculation for TCP."
            ]
        }
    }
}
{
    "source_code": "\nint\nfreadseek (FILE *fp, size_t offset)\n{\n  size_t total_buffered;\n  int fd;\n\n  if (offset == 0)\n    return 0;\n\n  /* Seek over the already read and buffered input as quickly as possible,\n     without doing any system calls.  */\n  total_buffered = freadahead (fp);\n  /* This loop is usually executed at most twice: once for ungetc buffer (if\n     present) and once for the main buffer.  */\n  while (total_buffered > 0)\n    {\n      size_t buffered;\n\n      if (freadptr (fp, &buffered) != NULL && buffered > 0)\n        {\n          size_t increment = (buffered < offset ? buffered : offset);\n\n          freadptrinc (fp, increment);\n          offset -= increment;\n          if (offset == 0)\n            return 0;\n          total_buffered -= increment;\n          if (total_buffered == 0)\n            break;\n        }\n      /* Read one byte.  If we were reading from the ungetc buffer, this\n         switches the stream back to the main buffer.  */\n      if (fgetc (fp) == EOF)\n        goto eof;\n      offset--;\n      if (offset == 0)\n        return 0;\n      total_buffered--;\n    }\n\n  /* Test whether the stream is seekable or not.  */\n  fd = fileno (fp);\n  if (fd >= 0 && lseek (fd, 0, SEEK_CUR) >= 0)\n    {\n      /* FP refers to a regular file.  fseek is most efficient in this case.  */\n      return fseeko (fp, offset, SEEK_CUR);\n    }\n  else\n    {\n      /* FP is a non-seekable stream, possibly not even referring to a file\n         descriptor.  Read OFFSET bytes explicitly and discard them.  */\n      char buf[4096];\n\n      do\n        {\n          size_t count = (sizeof (buf) < offset ? sizeof (buf) : offset);\n          if (fread (buf, 1, count, fp) < count)\n            goto eof;\n          offset -= count;\n        }\n      while (offset > 0);\n\n      return 0;\n   }\n\n eof:\n  /* EOF, or error before or while reading.  */\n  if (ferror (fp))\n    return EOF;\n  else\n    /* Encountered EOF.  */\n    return 0;\n}",
    "comment": "The function efficiently skips a specified number of bytes in a FILE stream, handling buffered input and seeking on regular files when possible.",
    "prorec_sum": "Skips ahead in a FILE stream by a specified number of bytes using buffer manipulation, reading, or seeking depending on stream capabilities.",
    "filter_prorec_sum": "Skips a specified number of bytes from a FILE stream using buffered reading, fgetc, or lseek, handling errors appropriately.",
    "prorec_aug_sum": "Reads and discards up to a specified number of bytes from a file stream using buffered reads, fgetc, or lseek depending on stream state.",
    "filter_prorec_aug_sum": "Skips a specified number of bytes from a file stream using buffered reads, fgetc, or lseek-based methods depending on stream capabilities.",
    "work_score": {
        "prorec": {
            "summary": "Skips ahead in a FILE stream by a specified number of bytes using buffer manipulation, reading, or seeking depending on stream capabilities.",
            "score": [
                1.0,
                0.6666666666666666,
                0.6333333333333333
            ],
            "reason": [
                "The summary correctly states that the function skips ahead in a FILE stream by a specified number of bytes and uses buffer manipulation, reading, or seeking depending on stream capabilities. All these details are explicitly evidenced in the source code: buffer manipulation via freadahead/freadptr/freadptrinc, reading via fgetc/fread, and seeking via fseeko when the stream is seekable. There are no unverified assumptions or hallucinations.",
                "The summary accurately reflects the core logic of the function: it skips ahead in a FILE stream by a given byte offset, using buffered data manipulation, reading bytes if necessary, or seeking when possible based on stream capabilities. This matches explicit evidence in the code through use of functions like freadptrinc, fgetc, fseeko, and fread for non-seekable streams. However, it omits mention of edge case handling such as offset==0 checks and EOF/error handling, so while accurate, it is not fully complete.",
                "The summary correctly identifies that the function moves ahead in a FILE stream by a specified byte offset and uses different strategies based on stream capabilities, including buffer manipulation, reading, and seeking. These details are explicitly supported by the source code through the use of functions like freadahead, freadptrinc, fgetc, fseeko, and fread. The description is accurate but remains generic, omitting specific implementation nuances present in the code such as handling of ungetc buffer, EOF logic, and use of fileno/lseek for capability checks."
            ]
        },
        "filter_prorec": {
            "summary": "Skips a specified number of bytes from a FILE stream using buffered reading, fgetc, or lseek, handling errors appropriately.",
            "score": [
                0.9666666666666667,
                0.6666666666666666,
                0.6
            ],
            "reason": [
                "The summary accurately states that the function skips a specified number of bytes from a FILE stream and that it uses buffered reading, fgetc, and lseek. It also correctly mentions error handling. All these details are explicitly evidenced in the source code through the use of freadahead, freadptr, fgetc, lseek, and EOF/error checks. No unverifiable or hallucinated details are present.",
                "The summary accurately states that the function skips a specified number of bytes from a FILE stream, uses buffered reading, fgetc, and lseek, and includes error handling. These points match explicit evidence in the source code: buffered skipping is done with freadahead/freadptr/freadptrinc, fgetc is used when switching buffers, lseek is attempted for seekable streams, and error handling is implemented via ferror and EOF checks. However, the summary omits important edge case details, such as using fseeko for seekable files, handling non-seekable streams via fread in chunks, and the special case when offset is zero.",
                "The summary correctly captures the function\u2019s purpose of skipping bytes from a FILE stream and mentions using buffered reading, fgetc, and lseek, which are all evidenced in the source code. It also notes error handling, which is present via checks for EOF and ferror. However, the summary omits important specifics shown in the source, such as the use of freadptr/freadptrinc or the explicit fallback to fread with a buffer for non-seekable streams, making the description somewhat generic despite being accurate."
            ]
        }
    }
}
{
    "source_code": "\nstatic Rconnection\nnewxzfile(const char *description, const char *mode, int type, int compress)\n{\n    Rconnection new;\n    new = (Rconnection) malloc(sizeof(struct Rconn));\n    if(!new) error(_(\"allocation of xzfile connection failed\"));\n    new->class = (char *) malloc(strlen(\"xzfile\") + 1);\n    if(!new->class) {\n\tfree(new);\n\terror(_(\"allocation of xzfile connection failed\"));\n\t/* for Solaris 12.5 */ new = NULL;\n    }\n    strcpy(new->class, \"xzfile\");\n    new->description = (char *) malloc(strlen(description) + 1);\n    if(!new->description) {\n\tfree(new->class); free(new);\n\terror(_(\"allocation of xzfile connection failed\"));\n\t/* for Solaris 12.5 */ new = NULL;\n    }\n    init_con(new, description, CE_NATIVE, mode);\n\n    new->canseek = FALSE;\n    new->open = &xzfile_open;\n    new->close = &xzfile_close;\n    new->vfprintf = &dummy_vfprintf;\n    new->fgetc_internal = &xzfile_fgetc_internal;\n    new->fgetc = &dummy_fgetc;\n    new->seek = &null_seek;\n    new->fflush = &null_fflush;\n    new->read = &xzfile_read;\n    new->write = &xzfile_write;\n    new->private = (void *) malloc(sizeof(struct xzfileconn));\n    memset(new->private, 0, sizeof(struct xzfileconn));\n    if(!new->private) {\n\tfree(new->description); free(new->class); free(new);\n\terror(_(\"allocation of xzfile connection failed\"));\n\t/* for Solaris 12.5 */ new = NULL;\n    }\n    ((Rxzfileconn) new->private)->type = type;\n    ((Rxzfileconn) new->private)->compress = compress;\n    return new;\n}",
    "comment": "Allocates and initializes a new xzfile connection, setting its properties and handling memory for class, description, and private data structures.",
    "prorec_sum": "Initializes and returns an xzfile connection structure, setting handlers, storing parameters, and allocating associated buffers for R\u2019s connection interface.",
    "filter_prorec_sum": "Allocates and initializes an xzfile connection structure with associated buffers, handlers, and parameters for use within the R interpreter environment.",
    "prorec_aug_sum": "Initializes and returns an xzfile connection structure, allocating buffers and assigning function pointers for handling compressed file operations.",
    "filter_prorec_aug_sum": "Allocates and initializes an xzfile connection structure, sets up related function pointers, and stores configuration values for compression handling.",
    "work_score": {
        "prorec": {
            "summary": "Initializes and returns an xzfile connection structure, setting handlers, storing parameters, and allocating associated buffers for R\u2019s connection interface.",
            "score": [
                1.0,
                0.7666666666666666,
                0.7333333333333334
            ],
            "reason": [
                "The summary correctly states that the function initializes and returns an xzfile connection structure, sets handlers, stores parameters, and allocates buffers for R\u2019s connection interface. All these details are explicitly supported by the code: it allocates memory for the Rconnection, sets the class to 'xzfile', assigns function pointers for various handlers, stores the type and compress parameters, and allocates/initializes a private buffer. There are no unsupported or hallucinated claims.",
                "The summary correctly identifies that the function initializes and returns an xzfile connection structure, assigns handlers, stores parameters, and allocates memory for use in R\u2019s connection interface. These details are explicitly supported by the source code: the function allocates memory for the connection struct and its fields, sets handler function pointers, stores type and compress parameters, and returns the initialized object. However, the summary omits explicit mention of the error handling logic and some specific initialization steps like setting canseek to FALSE and zeroing the private struct, which are part of the core logic.",
                "The summary accurately captures the core functionality in the source code: it initializes an xzfile connection structure, assigns handler function pointers, stores parameters (type, compress), and allocates memory for associated structures used in R's connection interface. All these elements are explicitly evidenced in the code. However, the description is somewhat generic and lacks mention of specific function names or error handling mechanisms, making the accurate details domain-relevant but not highly detailed."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes an xzfile connection structure with associated buffers, handlers, and parameters for use within the R interpreter environment.",
            "score": [
                0.6666666666666666,
                0.6666666666666666,
                0.3666666666666667
            ],
            "reason": [
                "The summary correctly states that the function allocates and initializes an xzfile connection structure with handlers and parameters, as evidenced by multiple malloc calls, string assignments for 'xzfile', and function pointer assignments. However, the mention of 'associated buffers' is not explicitly supported in the source code, and the claim of usage within the R interpreter environment is an unverified assumption without direct evidence. This mix of accurate points and unsupported details leads to moderate accuracy.",
                "The summary correctly states that the function allocates and initializes an xzfile connection structure with handlers and parameters, which is evidenced by multiple malloc calls, function pointer assignments, and parameter setting in the source code. However, it inaccurately adds 'associated buffers' without explicit evidence of buffer allocation beyond the private struct, and it assumes usage 'within the R interpreter environment' without direct confirmation from the given code. The accurate details capture the core allocation and initialization actions, but some contextual specifics are unsupported.",
                "The summary correctly states that the function allocates and initializes an xzfile connection structure with handlers and parameters, which matches the malloc calls, initialization of function pointers, and setting of type/compress values in the source code. However, it inaccurately mentions 'associated buffers,' which is not explicitly evidenced in the code, and the reference to 'use within the R interpreter environment' is not verifiable from the given snippet. With only one inaccuracy out of three details, the proportion of inaccuracies is under 50%, but the accurate details are generic and lack domain-specific richness."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_multifit_linear_applyW(const gsl_matrix * X,\n                           const gsl_vector * w,\n                           const gsl_vector * y,\n                           gsl_matrix * WX,\n                           gsl_vector * Wy)\n{\n  const size_t n = X->size1;\n  const size_t p = X->size2;\n\n  if (n != y->size)\n    {\n      GSL_ERROR(\"y vector does not match X\", GSL_EBADLEN);\n    }\n  else if (w != NULL && n != w->size)\n    {\n      GSL_ERROR(\"weight vector does not match X\", GSL_EBADLEN);\n    }\n  else if (n != WX->size1 || p != WX->size2)\n    {\n      GSL_ERROR(\"WX matrix dimensions do not match X\", GSL_EBADLEN);\n    }\n  else if (n != Wy->size)\n    {\n      GSL_ERROR(\"Wy vector must be length n\", GSL_EBADLEN);\n    }\n  else\n    {\n      size_t i;\n\n      /* copy WX = X; Wy = y if distinct pointers */\n      if (WX != X)\n        gsl_matrix_memcpy(WX, X);\n      if (Wy != y)\n        gsl_vector_memcpy(Wy, y);\n\n      if (w != NULL)\n        {\n          /* construct WX = sqrt(W) X and Wy = sqrt(W) y */\n          for (i = 0; i < n; ++i)\n            {\n              double wi = gsl_vector_get(w, i);\n              double swi;\n              gsl_vector_view row = gsl_matrix_row(WX, i);\n              double *yi = gsl_vector_ptr(Wy, i);\n\n              if (wi < 0.0)\n                wi = 0.0;\n\n              swi = sqrt(wi);\n              gsl_vector_scale(&row.vector, swi);\n              *yi *= swi;\n            }\n        }\n\n      return GSL_SUCCESS;\n    }\n}",
    "comment": "Applies weighted transformations to input matrix X and vector y, storing results in WX and Wy, respectively, while handling potential dimension mismatches.",
    "prorec_sum": "Validates dimension consistency of input matrices/vectors, then copies and applies square-root weights to X and y for weighted linear regression.",
    "filter_prorec_sum": "Validates dimension consistency between vectors/matrices and applies square-root weight scaling to rows of X and elements of y.",
    "prorec_aug_sum": "Validates dimension compatibility of input matrices/vectors and applies weight scaling to X and y, copying data as needed for weighted linear regression.",
    "filter_prorec_aug_sum": "Validates matching dimensions of X, y, and weight data, then copies and applies square-root weight scaling to matrix rows and vector elements.",
    "work_score": {
        "prorec": {
            "summary": "Validates dimension consistency of input matrices/vectors, then copies and applies square-root weights to X and y for weighted linear regression.",
            "score": [
                1.0,
                0.7666666666666666,
                0.9
            ],
            "reason": [
                "The summary correctly captures the dimension consistency checks, the copying of X and y into WX and Wy, and the application of square-root weights to both, all of which are explicitly present in the source code. No details in the summary are unsupported, so accuracy is very high.",
                "The summary correctly captures the main logic: dimension checks for input matrices/vectors, copying data, and applying square-root weights to X and y, which is fully evidenced by the source code's validation steps, memcpy calls, and weighted scaling loop. However, it omits edge cases and specific error conditions such as handling NULL weight vectors or skipping copy when pointers are the same. Despite these omissions, the core logic is well aligned with the code.",
                "The summary correctly captures two major details from the source code: the dimension consistency checks for matrices/vectors and the application of square-root weights to X and y. These are explicitly implemented via multiple GSL_ERROR checks and the sqrt(wi) scaling logic. The mention of weighting for 'weighted linear regression' is implied but not explicitly stated in the code, making it somewhat interpretive but still grounded. The accurate details are specific and domain-relevant, providing a clear understanding of the function's purpose."
            ]
        },
        "filter_prorec": {
            "summary": "Validates dimension consistency between vectors/matrices and applies square-root weight scaling to rows of X and elements of y.",
            "score": [
                1.0,
                0.6999999999999998,
                0.9
            ],
            "reason": [
                "The summary correctly identifies the validation of dimension consistency between input vectors and matrices, as well as the square-root weight scaling applied to rows of X and elements of y. Both details are explicitly present in the source code: multiple size checks confirm dimension consistency, and the loop applies sqrt(wi) scaling to X and y when weights are provided. No unverified or hallucinated details are present.",
                "The summary accurately captures the main logic of the source code: dimension checks between X, y, w, WX, and Wy, and the application of square-root weight scaling to rows of X and elements of y when w is provided. However, it omits some edge-case handling such as copying WX and Wy when they are distinct pointers and setting negative weights to zero before scaling. Despite these omissions, the core functionality is well represented.",
                "The summary correctly identifies both major functions of the source code: validation of dimension consistency between vectors/matrices and the application of square-root weight scaling to rows of X and elements of y. These details are explicitly supported in the code through checks on sizes of X, y, w, WX, and Wy, and a loop applying sqrt(w) scaling to both matrix rows and vector elements. The accurate details are domain-specific and directly describe the core logic implemented."
            ]
        }
    }
}
{
    "source_code": "\nstatic double InReal(R_inpstream_t stream)\n{\n    char word[128];\n    char buf[128];\n    double d;\n\n    switch (stream->type) {\n    case R_pstream_ascii_format:\n\tInWord(stream, word, sizeof(word));\n\tif(sscanf(word, \"%127s\", buf) != 1) error(_(\"read error\"));\n\tif (strcmp(buf, \"NA\") == 0)\n\t    return NA_REAL;\n\telse if (strcmp(buf, \"NaN\") == 0)\n\t    return R_NaN;\n\telse if (strcmp(buf, \"Inf\") == 0)\n\t    return R_PosInf;\n\telse if (strcmp(buf, \"-Inf\") == 0)\n\t    return R_NegInf;\n\telse\n\t    if(\n#ifdef Win32\n\t\ttrio_sscanf(buf, \"%lg\", &d)\n#else\n\t\tsscanf(buf, \"%lg\", &d)\n#endif\n\t\t!= 1) error(_(\"read error\"));\n\treturn d;\n    case R_pstream_binary_format:\n\tstream->InBytes(stream, &d, sizeof(double));\n\treturn d;\n    case R_pstream_xdr_format:\n\tstream->InBytes(stream, buf, R_XDR_DOUBLE_SIZE);\n\treturn R_XDRDecodeDouble(buf);\n    default:\n\treturn NA_REAL;\n    }\n}",
    "comment": "Reads a double value from a specified input stream format (ASCII, binary, or XDR) and handles special cases like NA, NaN, and infinity.",
    "prorec_sum": "Parses numeric or special string values from input, handling NA/NaN/Inf cases, and invokes type-specific processing callbacks based on a mode flag.",
    "filter_prorec_sum": "Parses numeric or special string values from input, handling cases like NA, NaN, Inf, and reports a read error on invalid formats.",
    "prorec_aug_sum": "Parses numeric or special string values from input based on type code, handling \"NA\"/\"NaN\"/\"Inf\" cases and reporting errors on invalid data.",
    "filter_prorec_aug_sum": "Parses numeric or special string values from input based on type code, handling NA/NaN/Inf cases and reporting errors on invalid formats.",
    "work_score": {
        "prorec": {
            "summary": "Parses numeric or special string values from input, handling NA/NaN/Inf cases, and invokes type-specific processing callbacks based on a mode flag.",
            "score": [
                0.5333333333333333,
                0.6,
                0.43333333333333335
            ],
            "reason": [
                "The summary correctly describes parsing numeric and special string values (NA, NaN, Inf) from input, which is explicitly handled in the ASCII case logic, making that detail accurate. However, the claim about invoking type-specific processing callbacks based on a mode flag is inaccurate; the source code uses a switch on `stream->type` to determine format-specific parsing, not callbacks. This introduces an unverified assumption. With one accurate detail and one hallucination, the ratio of accurate details is 50%, putting it in the lower range.",
                "The summary correctly notes parsing of numeric and special string values (NA, NaN, Inf) from input, which is explicitly present in the code through string comparisons and corresponding returns. However, it inaccurately claims 'type-specific processing callbacks', as the code uses a switch on stream->type to handle ASCII, binary, and XDR formats directly, not generic callbacks. This omission of specific reading functions and error handling means the accurate details cover the core parsing logic but miss key aspects like error checks and format-specific decoding.",
                "The summary correctly notes parsing of numeric and special string values (NA, NaN, Inf) and type-specific handling based on a mode flag, which aligns with the switch on stream->type in the source. However, it inaccurately describes 'invokes type-specific processing callbacks'\u2014the code uses direct function calls (InWord, InBytes, sscanf, etc.) rather than generic callbacks\u2014making this a misleading embellishment. With one of two main details inaccurate (>50%), the Kill Switch applies."
            ]
        },
        "filter_prorec": {
            "summary": "Parses numeric or special string values from input, handling cases like NA, NaN, Inf, and reports a read error on invalid formats.",
            "score": [
                0.9666666666666667,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly identifies the function's purpose of parsing numeric and special string values from input and explicitly mentions handling NA, NaN, Inf, and read errors, all of which are evidenced in the source code via conditional checks and error calls. There are no details in the summary that are unsupported or hallucinated, and every claim aligns directly with the logic and constants seen in the code.",
                "The summary correctly identifies that the function parses numeric and special string values (NA, NaN, Inf) and reports errors for invalid formats. These behaviors are explicitly present in the code for the ASCII format branch, including error handling via 'error' calls and checks for the special strings. However, the summary omits significant logic for other input types such as binary and XDR formats, which are also handled in the source code. As a result, it captures the main idea for one branch but not the complete logic of the function.",
                "The summary correctly identifies that the function parses numeric or special string values, handles NA, NaN, Inf, and triggers a read error for invalid formats, all of which are explicitly present in the source code logic. However, it omits details about multiple input formats (ASCII, binary, XDR) and platform-specific scanning behavior, making the accurate details somewhat generic rather than domain-rich."
            ]
        }
    }
}
{
    "source_code": "dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,\n\t\t\t    unsigned long offset, size_t size,\n\t\t\t    enum dma_data_direction dir,\n\t\t\t    struct dma_attrs *attrs)\n{\n\tphys_addr_t map, phys = page_to_phys(page) + offset;\n\tdma_addr_t dev_addr = phys_to_dma(dev, phys);\n\n\tBUG_ON(dir == DMA_NONE);\n\t/*\n\t * If the address happens to be in the device's DMA window,\n\t * we can safely return the device addr and not worry about bounce\n\t * buffering it.\n\t */\n\tif (dma_capable(dev, dev_addr, size) && !swiotlb_force)\n\t\treturn dev_addr;\n\n\t/* Oh well, have to allocate and map a bounce buffer. */\n\tmap = map_single(dev, phys, size, dir);\n\tif (map == SWIOTLB_MAP_ERROR) {\n\t\tswiotlb_full(dev, size, dir, 1);\n\t\treturn phys_to_dma(dev, io_tlb_overflow_buffer);\n\t}\n\n\tdev_addr = phys_to_dma(dev, map);\n\n\t/* Ensure that the address returned is DMA'ble */\n\tif (!dma_capable(dev, dev_addr, size)) {\n\t\tswiotlb_tbl_unmap_single(dev, map, size, dir);\n\t\treturn phys_to_dma(dev, io_tlb_overflow_buffer);\n\t}\n\n\treturn dev_addr;\n}",
    "comment": "Maps a page of memory for DMA access, handling bounce buffers if the device cannot directly access the address.",
    "prorec_sum": "Maps a physical address range for DMA access, validates bounds, handles failures with logging, and ensures proper address space visibility.",
    "filter_prorec_sum": "Maps a physical address range for DMA access, validates boundaries, and logs warnings for large transfers or invalid mappings before returning the mapped address.",
    "prorec_aug_sum": "Checks DMA access permissions for a memory range, logs warnings for unsafe access, and invokes allocation or fallback handling when checks fail.",
    "filter_prorec_aug_sum": "Validates and resolves a DMA memory range request, invoking error handling and logging when the range is invalid or access constraints are violated.",
    "work_score": {
        "prorec": {
            "summary": "Maps a physical address range for DMA access, validates bounds, handles failures with logging, and ensures proper address space visibility.",
            "score": [
                0.3,
                0.5,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies. While the source code does map a physical address for DMA and handles failures, it does not perform general 'bounds validation' or 'logging', nor does it explicitly ensure 'address space visibility' in the sense described; instead, it checks DMA capability and handles bounce buffering. These added claims are not evidenced in the code, resulting in less than half of the details being accurate.",
                "The summary's claim about mapping a physical address range for DMA access is accurate, as the code uses page_to_phys, phys_to_dma, and dma_capable checks to handle DMA mapping. However, references to 'validates bounds' are partially accurate since dma_capable checks device range, but statements about 'logging' and 'ensures proper address space visibility' are inaccurate\u2014no explicit logging or visibility enforcement is present. The missing mention of bounce buffer handling and error recovery logic means key parts of the control flow are not covered.",
                "The summary claims bounds validation, logging of failures, and ensuring proper address space visibility, but the source code only shows DMA capability checks, bounce buffer mapping, and handling errors via swiotlb_full and overflow buffer without explicit logging or visibility mechanisms. Most details in the summary are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Maps a physical address range for DMA access, validates boundaries, and logs warnings for large transfers or invalid mappings before returning the mapped address.",
            "score": [
                0.26666666666666666,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims that the function validates boundaries and logs warnings for large transfers or invalid mappings, but the source code does not contain any explicit logging behavior or checks specifically for large transfers. While the summary correctly mentions mapping a physical address for DMA access and returning the mapped address, the majority of details about boundary validation and warnings are unsupported by the code. This results in mostly inaccurate details compared to the source.",
                "The summary contains inaccuracies: it claims validation of boundaries and logging warnings for large transfers or invalid mappings, which is not present in the source code. The code performs DMA capability checks, bounce buffer allocation, error handling via fallback buffers, and ensures the mapped address is suitable for DMA, but there is no logging or explicit large transfer logic. After discarding the inaccurate details, only the general action of mapping a physical address for DMA remains, which misses most of the control flow and edge case handling.",
                "The summary claims the function validates boundaries and logs warnings for large transfers or invalid mappings, but the source code does not contain any explicit boundary validation steps or logging calls. The code only checks DMA capability, forces bounce buffering if needed, and handles mapping errors without logging. Since all main details in the summary lack explicit evidence in the source, the proportion of inaccurate details exceeds 50%, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nasmlinkage int sys_modify_ldt(int func, void __user *ptr,\n\t\t\t      unsigned long bytecount)\n{\n\tint ret = -ENOSYS;\n\n\tswitch (func) {\n\tcase 0:\n\t\tret = read_ldt(ptr, bytecount);\n\t\tbreak;\n\tcase 1:\n\t\tret = write_ldt(ptr, bytecount, 1);\n\t\tbreak;\n\tcase 2:\n\t\tret = read_default_ldt(ptr, bytecount);\n\t\tbreak;\n\tcase 0x11:\n\t\tret = write_ldt(ptr, bytecount, 0);\n\t\tbreak;\n\t}\n\treturn ret;\n}",
    "comment": "The function modifies the local descriptor table (LDT) by reading or writing its entries based on the specified operation code.",
    "prorec_sum": "Handles various data transfer operations based on command type, including reading, writing, and validating memory segments with specific size constraints.",
    "filter_prorec_sum": "Handles different command codes to transfer data between a buffer and target address, validating sizes and invoking appropriate low-level memory or storage routines.",
    "prorec_aug_sum": "Handles different command codes to transfer data chunks to or from a specified address, performing validation and fallback operations based on size limits.",
    "filter_prorec_aug_sum": "Handles commands for transferring data from a specified memory source, supporting immediate send, partial chunking, and conditional retries based on request type.",
    "work_score": {
        "prorec": {
            "summary": "Handles various data transfer operations based on command type, including reading, writing, and validating memory segments with specific size constraints.",
            "score": [
                0.5666666666666668,
                0.5666666666666667,
                0.0
            ],
            "reason": [
                "The summary correctly mentions reading and writing operations based on command type, which is supported by the switch cases calling read_ldt, write_ldt, and read_default_ldt. However, the claim about 'validating memory segments' and 'specific size constraints' is not evidenced in the source code, as no explicit validation logic or size constraint checks are present. This results in a mix of accurate and inaccurate details, lowering the overall alignment.",
                "The summary correctly notes reading and writing operations based on command type, which matches the switch cases calling read_ldt, write_ldt, and read_default_ldt. However, the claim about validating memory segments with specific size constraints is not supported by any explicit evidence in the source code. Significant details like handling specific func values and the absence of explicit validation logic are missing, so the accurate parts only partially represent the code\u2019s core logic.",
                "The summary claims validation of memory segments with specific size constraints, which is not evidenced in the source code. The accurate portions are the mentions of reading and writing operations based on a command type, reflected by the switch cases calling read_ldt and write_ldt functions. However, the additional claim about validation and size constraints is unsupported. Since half or more of the details in the summary are inaccurate, the representation is misleading and triggers the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Handles different command codes to transfer data between a buffer and target address, validating sizes and invoking appropriate low-level memory or storage routines.",
            "score": [
                0.3333333333333333,
                0.26666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims the code transfers data between a buffer and target address, validates sizes, and uses low-level memory/storage routines. While the source code does handle different function codes and calls `read_ldt`, `write_ldt`, and `read_default_ldt` based on those codes, there is no explicit evidence of size validation or generic buffer-to-address transfer logic. Additionally, 'low-level storage routines' is unverifiable; the routines are specific to LDT operations. Only the detail about handling command codes and invoking appropriate functions matches the source, resulting in more than half of the claims being unverified.",
                "The summary claims size validation and mentions data transfer between a buffer and target address, along with low-level memory or storage routines. The source code shows switching on 'func' to call read_ldt, write_ldt, or read_default_ldt, returning their outcomes, but does not explicitly validate sizes or reference a 'target address'. The only accurate detail is handling different command codes and invoking routines, missing significant parts of the actual logic. Therefore, the coverage is partial and omits key specifics.",
                "The summary claims validation of sizes and transferring data between a buffer and a target address, as well as invoking low-level memory or storage routines. The source code only shows branching on 'func' values to call read_ldt, write_ldt, or read_default_ldt without any explicit size validation or generalized buffer-target transfer logic. Most claims are inaccurate, with only the invocation of functions based on command codes being supported. Since inaccurate details exceed half of the total, the evaluation stops per the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic int usb_set_lpm_timeout(struct usb_device *udev,\n\t\tenum usb3_link_state state, int timeout)\n{\n\tint ret;\n\tint feature;\n\n\tswitch (state) {\n\tcase USB3_LPM_U1:\n\t\tfeature = USB_PORT_FEAT_U1_TIMEOUT;\n\t\tbreak;\n\tcase USB3_LPM_U2:\n\t\tfeature = USB_PORT_FEAT_U2_TIMEOUT;\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(&udev->dev, \"%s: Can't set timeout for non-U1 or U2 state.\\n\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (state == USB3_LPM_U1 && timeout > USB3_LPM_U1_MAX_TIMEOUT &&\n\t\t\ttimeout != USB3_LPM_DEVICE_INITIATED) {\n\t\tdev_warn(&udev->dev, \"Failed to set %s timeout to 0x%x, \"\n\t\t\t\t\"which is a reserved value.\\n\",\n\t\t\t\tusb3_lpm_names[state], timeout);\n\t\treturn -EINVAL;\n\t}\n\n\tret = set_port_feature(udev->parent,\n\t\t\tUSB_PORT_LPM_TIMEOUT(timeout) | udev->portnum,\n\t\t\tfeature);\n\tif (ret < 0) {\n\t\tdev_warn(&udev->dev, \"Failed to set %s timeout to 0x%x,\"\n\t\t\t\t\"error code %i\\n\", usb3_lpm_names[state],\n\t\t\t\ttimeout, ret);\n\t\treturn -EBUSY;\n\t}\n\tif (state == USB3_LPM_U1)\n\t\tudev->u1_params.timeout = timeout;\n\telse\n\t\tudev->u2_params.timeout = timeout;\n\treturn 0;\n}",
    "comment": "Sets the low power mode timeout for a USB device based on the specified USB 3.0 link state, validating the timeout value before applying it.",
    "prorec_sum": "Sets USB U1 or U2 link power management timeout values, validating input and reporting errors if unsupported state or reserved values are provided.",
    "filter_prorec_sum": "Sets USB U1 or U2 link power management timeout values, validating inputs and reporting errors if values are reserved or configuration fails.",
    "prorec_aug_sum": "Sets the USB device\u2019s U1 or U2 link power management timeout, validating values and reporting errors if the operation fails or state is invalid.",
    "filter_prorec_aug_sum": "Sets USB U1 or U2 link power management timeout, validating parameters and reporting errors if commands fail or values are reserved.",
    "work_score": {
        "prorec": {
            "summary": "Sets USB U1 or U2 link power management timeout values, validating input and reporting errors if unsupported state or reserved values are provided.",
            "score": [
                1.0,
                0.7666666666666666,
                0.9
            ],
            "reason": [
                "The summary correctly identifies that the function sets link power management timeout values for USB U1 or U2 states, validates inputs, and reports errors for unsupported states or reserved values, all of which are explicitly present in the source code (via state checks, reserved value handling, and dev_warn calls). No extraneous or unverifiable claims are made, so all details align with evidence from the source.",
                "The summary accurately conveys that the function sets USB U1 or U2 link power management timeouts, validates the input, and reports errors for unsupported states or reserved values. These details are explicitly supported by the source code: it uses a switch to handle U1/U2 states, warns and returns errors for unsupported states, checks for reserved timeout values in U1, and sets the timeout parameters accordingly. However, the summary omits other explicit error handling such as the specific condition for returning EBUSY on port feature setting failures, resulting in a slightly incomplete depiction of the logic.",
                "The summary correctly captures that the function sets USB U1 or U2 LPM timeout values, checks for unsupported states, and rejects reserved values, all of which are explicitly present in the code. These details are accurate, domain-specific, and supported by the function's switch case handling, reserved value check for U1, and error reporting. No inaccuracies were found, and the description offers clear, relevant insights."
            ]
        },
        "filter_prorec": {
            "summary": "Sets USB U1 or U2 link power management timeout values, validating inputs and reporting errors if values are reserved or configuration fails.",
            "score": [
                1.0,
                0.8000000000000002,
                0.9
            ],
            "reason": [
                "The summary accurately states that the function sets USB U1 or U2 link power management timeouts, validates the inputs, and reports errors when values are reserved or configuration fails. These details are explicitly supported by the source code, which includes logic for handling only U1/U2 states, checking U1 timeout constraints, using dev_warn for errors, and setting appropriate timeout fields. No unsupported claims or hallucinations are present.",
                "The summary correctly identifies that the function sets U1 or U2 link power management timeouts, includes validation checks for reserved values in the U1 case, and reports errors when configuration fails, all of which are explicitly implemented in the source code. It omits minor internal details such as feature selection via a switch, specific error codes returned, and assignment to udev parameters, but captures the core logic accurately.",
                "The summary correctly states that the function sets USB U1 or U2 link power management timeouts, performs validation of inputs, and reports errors for reserved values or configuration failures, all of which are explicitly present in the code via switch cases, timeout checks, and dev_warn error messages. These accurate details are domain-specific and grounded in the source's logic. No inaccuracies are present, and the details provide solid insight into the function's behavior."
            ]
        }
    }
}
{
    "source_code": "\nstatic struct rpc_cred *\nunx_create_cred(struct rpc_auth *auth, struct auth_cred *acred, int flags)\n{\n\tstruct unx_cred\t*cred;\n\tunsigned int groups = 0;\n\tunsigned int i;\n\n\tdprintk(\"RPC:       allocating UNIX cred for uid %d gid %d\\n\",\n\t\t\tfrom_kuid(&init_user_ns, acred->uid),\n\t\t\tfrom_kgid(&init_user_ns, acred->gid));\n\n\tif (!(cred = kmalloc(sizeof(*cred), GFP_NOFS)))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\trpcauth_init_cred(&cred->uc_base, acred, auth, &unix_credops);\n\tcred->uc_base.cr_flags = 1UL << RPCAUTH_CRED_UPTODATE;\n\n\tif (acred->group_info != NULL)\n\t\tgroups = acred->group_info->ngroups;\n\tif (groups > NFS_NGROUPS)\n\t\tgroups = NFS_NGROUPS;\n\n\tcred->uc_gid = acred->gid;\n\tfor (i = 0; i < groups; i++)\n\t\tcred->uc_gids[i] = GROUP_AT(acred->group_info, i);\n\tif (i < NFS_NGROUPS)\n\t\tcred->uc_gids[i] = INVALID_GID;\n\n\treturn &cred->uc_base;\n}",
    "comment": "Allocates and initializes a UNIX credential structure with user and group identifiers based on provided authentication credentials.",
    "prorec_sum": "Allocates and initializes a structure from given parameters, copies up to 16 integers from a2\u2019s substructure, and sets default values when absent.",
    "filter_prorec_sum": "Allocates and initializes a data structure from provided parameters, copies up to 16 configuration values from a2, and finalizes specific fields.",
    "prorec_aug_sum": "Allocates and initializes a 160-byte structure, copies fields from input pointers, and fills up to 16 integer entries with provided data.",
    "filter_prorec_aug_sum": "Allocates and initializes a 160-byte structure, sets fixed and copied fields from input data, and fills up to 16 integer entries from a secondary structure.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a structure from given parameters, copies up to 16 integers from a2\u2019s substructure, and sets default values when absent.",
            "score": [
                0.6999999999999998,
                0.6,
                0.5
            ],
            "reason": [
                "The summary correctly notes allocation and initialization of a structure from given parameters, consistent with the kmalloc call and rpcauth_init_cred usage in the source. It also accurately describes setting default values when absent, matching the INVALID_GID assignment. However, the claim of copying up to 16 integers is inaccurate: the source copies up to NFS_NGROUPS values, but there is no evidence that NFS_NGROUPS is 16 in the given code. This constitutes an unverifiable assumption, reducing the overall accuracy.",
                "The summary correctly notes that the function allocates and initializes a structure from given parameters and sets default values when absent, which aligns with the kmalloc call, rpcauth_init_cred initialization, and INVALID_GID fallback. However, it inaccurately specifies copying up to 16 integers from a2\u2019s substructure; while the code copies group IDs from acred->group_info up to NFS_NGROUPS, the summary\u2019s explicit '16 integers' claim is unsupported by evidence in the source code. This omission of the actual control flow for group count limiting and lack of mention of specific fields like uc_gid reduces completeness.",
                "The summary claims copying up to 16 integers from a2\u2019s substructure, but the source code never explicitly shows '16'\u2014it uses 'NFS_NGROUPS', whose value is not present. The summary vaguely refers to 'default values when absent', which loosely maps to setting INVALID_GID, but other parts like identifying a2 as a parameter name and specifying integer count are unsupported. While 'allocates and initializes a structure from given parameters' is accurate, most specific details are either unverified or inaccurate, resulting in more than half the details being unsupported."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a data structure from provided parameters, copies up to 16 configuration values from a2, and finalizes specific fields.",
            "score": [
                0.5,
                0.5,
                0.19999999999999998
            ],
            "reason": [
                "The summary correctly states that the function allocates and initializes a data structure using provided parameters, which is supported by kmalloc and rpcauth_init_cred calls. However, the claim about copying 'up to 16 configuration values from a2' is inaccurate: the code instead copies up to NFS_NGROUPS GIDs from acred->group_info, and NFS_NGROUPS is not explicitly confirmed as 16 here. 'Finalizes specific fields' is vague but could apply to setting uc_base.cr_flags and uc_gids; overall, about half of the claimed details are either inaccurate or unverifiable.",
                "The summary accurately notes allocation and initialization of a data structure from provided parameters, which is evident from kmalloc and rpcauth_init_cred usage. However, it inaccurately specifies 'copies up to 16 configuration values from a2', as the code instead copies group IDs from acred->group_info with a limit defined by NFS_NGROUPS, not an explicit constant like 16 or a variable named a2. The finalization of specific fields is partly accurate given the setting of uc_base.cr_flags and uc_gid. The main copying logic is misrepresented, so while the core initialization is included, significant specific logic (group count handling, INVALID_GID assignment) is missing.",
                "The summary claims that the function copies up to 16 configuration values from 'a2', but the source code shows it copies GID values from 'acred->group_info' up to NFS_NGROUPS without any mention of 'a2' or configuration values, making this detail inaccurate. It also omits specific identifiers such as 'unx_create_cred', data structures like 'struct unx_cred', and key logic such as setting 'uc_base.cr_flags'. The only accurate element is the generic statement about allocating and initializing a data structure, but more than half of the semantic details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nvoid\nstatcmd (void)\n{\n  struct sockaddr_storage *sin;\n  unsigned char *a, *p;\n\n  lreply (211, \"%s FTP server status:\", hostname);\n  if (!no_version)\n    printf (\"     ftpd (%s) %s\\r\\n\", PACKAGE_NAME, PACKAGE_VERSION);\n  printf (\"     Connected to %s\", cred.remotehost);\n  (void) getnameinfo ((struct sockaddr *) &his_addr, his_addrlen,\n\t\t      addrstr, sizeof (addrstr), NULL, 0, NI_NUMERICHOST);\n  if (!isdigit (cred.remotehost[0]))\n    printf (\" (%s)\", addrstr);\n  printf (\"\\r\\n\");\n  printf (\"     Session timeout is %d seconds\\r\\n\", timeout);\n  if (cred.logged_in)\n    {\n      if (cred.guest)\n\tprintf (\"     Logged in anonymously\\r\\n\");\n      else\n\tprintf (\"     Logged in as %s\\r\\n\", cred.name);\n    }\n  else if (askpasswd)\n    printf (\"     Waiting for password\\r\\n\");\n  else\n    printf (\"     Waiting for user name\\r\\n\");\n  printf (\"     TYPE: %s\", typenames[type]);\n  if (type == TYPE_A || type == TYPE_E)\n    printf (\", FORM: %s\", formnames[form]);\n  if (type == TYPE_L)\n#ifdef CHAR_BIT\n    printf (\" %d\", CHAR_BIT);\n#else\n# if NBBY == 8\n    printf (\" %d\", NBBY);\n# else\n    printf (\" %d\", bytesize);\t/* need definition! */\n# endif\n#endif\n  printf (\"; STRUcture: %s; transfer MODE: %s\\r\\n\",\n\t  strunames[stru], modenames[stru_mode]);\n  if (data != -1)\n    printf (\"     Data connection open\\r\\n\");\n  else if (pdata != -1)\n    {\n      printf (\"     in Passive mode\");\n      sin = &pasv_addr;\n      goto printaddr;\n    }\n  else if (usedefault == 0)\n    {\n      printf (\"     PORT\");\n      sin = &data_dest;\n    printaddr:\n      a = (unsigned char *) & ((struct sockaddr_in *) sin)->sin_addr;\n      p = (unsigned char *) & ((struct sockaddr_in *) sin)->sin_port;\n#define UC(b) (((int) b) & 0xff)\n      printf (\" (%d,%d,%d,%d,%d,%d)\\r\\n\", UC (a[0]),\n\t      UC (a[1]), UC (a[2]), UC (a[3]), UC (p[0]), UC (p[1]));\n#undef UC\n    }\n  else\n    printf (\"     No data connection\\r\\n\");\n  reply (211, \"End of status\");\n}",
    "comment": "Displays the current status of the FTP server, including connection details, session timeout, user login status, data connection status, and transfer settings.",
    "prorec_sum": "Outputs the current FTP server status, including connection details, session state, transfer settings, and data connection mode or address.",
    "filter_prorec_sum": "Displays detailed FTP server status, including software version, connection info, login state, transfer settings, and data connection parameters.",
    "prorec_aug_sum": "Reports the current FTP server and session status, including connection details, login state, transfer settings, and data connection mode.",
    "filter_prorec_aug_sum": "Outputs the current FTP server status, including connection details, login state, transfer settings, and data connection information.",
    "work_score": {
        "prorec": {
            "summary": "Outputs the current FTP server status, including connection details, session state, transfer settings, and data connection mode or address.",
            "score": [
                1.0,
                0.6666666666666666,
                0.6333333333333333
            ],
            "reason": [
                "The summary accurately reflects the function's purpose: it prints current FTP server status, including connection details (hostname, remotehost), session state (logged in, waiting for password/username), transfer settings (type, form, structure, mode), and data connection mode or address. All these elements are explicitly present in the source code's printf statements and conditional logic, with no unverified assumptions or hallucinations.",
                "The summary accurately reflects the core function's purpose: displaying FTP server status with connection details, session state, transfer settings, and data connection mode or address. All listed aspects are explicitly present in the source code through various printf calls and conditional logic. However, the summary omits some specific elements like displaying the server's version, handling of anonymous login vs named user, timeout value, and passive vs PORT mode distinctions. These omissions mean the accurate details cover the main action but miss several important parts of the logic.",
                "The summary captures accurate high-level details from the source code: it indeed outputs FTP server status, including connection details (remote host info), session state (logged in/user/password prompt), transfer settings (type, form, structure, mode), and data connection mode/address. All these elements are explicitly present in printed output logic. However, the details remain generic rather than offering domain-rich or nuanced specifics, limiting the insight value."
            ]
        },
        "filter_prorec": {
            "summary": "Displays detailed FTP server status, including software version, connection info, login state, transfer settings, and data connection parameters.",
            "score": [
                1.0,
                0.9,
                0.9333333333333332
            ],
            "reason": [
                "The summary captures multiple accurate details: the function outputs FTP server status including version information (PACKAGE_NAME, PACKAGE_VERSION), connection info (cred.remotehost, addrstr), login state (cred.logged_in, cred.guest), transfer settings (typenames[type], formnames[form], strunames[stru], modenames[stru_mode]), and data connection parameters (data, pdata, usedefault, pasv_addr, data_dest). All these elements are explicitly present in the source code, with no unverified assumptions or hallucinations detected.",
                "The summary\u2019s details about showing FTP server status, software version, connection info, login state, transfer settings, and data connection parameters are all explicitly supported by the source code, which prints each of these based on variables such as PACKAGE_NAME, PACKAGE_VERSION, cred fields, typenames, formnames, and data connection handling. These accurate details cover the main control flow and outputs of the function, forming a complete and truthful representation of the code\u2019s logic including conditional branches for login state and data connection modes.",
                "The summary's details about showing software version, connection info, login state, transfer settings, and data connection parameters are all explicitly supported by the source code. The function prints package name/version, remote host info, login status (anonymous or named), type/form/structure/mode settings, and data connection details including passive/PORT modes and address/port numbers. No inaccuracies are present, and the accurate details are specific and domain-rich."
            ]
        }
    }
}
{
    "source_code": "\nstatic ssize_t snd_pcm_oss_write2(struct snd_pcm_substream *substream, const char *buf, size_t bytes, int in_kernel)\n{\n\tstruct snd_pcm_runtime *runtime = substream->runtime;\n\tsnd_pcm_sframes_t frames, frames1;\n#ifdef CONFIG_SND_PCM_OSS_PLUGINS\n\tif (runtime->oss.plugin_first) {\n\t\tstruct snd_pcm_plugin_channel *channels;\n\t\tsize_t oss_frame_bytes = (runtime->oss.plugin_first->src_width * runtime->oss.plugin_first->src_format.channels) / 8;\n\t\tif (!in_kernel) {\n\t\t\tif (copy_from_user(runtime->oss.buffer, (const char __force __user *)buf, bytes))\n\t\t\t\treturn -EFAULT;\n\t\t\tbuf = runtime->oss.buffer;\n\t\t}\n\t\tframes = bytes / oss_frame_bytes;\n\t\tframes1 = snd_pcm_plug_client_channels_buf(substream, (char *)buf, frames, &channels);\n\t\tif (frames1 < 0)\n\t\t\treturn frames1;\n\t\tframes1 = snd_pcm_plug_write_transfer(substream, channels, frames1);\n\t\tif (frames1 <= 0)\n\t\t\treturn frames1;\n\t\tbytes = frames1 * oss_frame_bytes;\n\t} else\n#endif\n\t{\n\t\tframes = bytes_to_frames(runtime, bytes);\n\t\tframes1 = snd_pcm_oss_write3(substream, buf, frames, in_kernel);\n\t\tif (frames1 <= 0)\n\t\t\treturn frames1;\n\t\tbytes = frames_to_bytes(runtime, frames1);\n\t}\n\treturn bytes;\n}",
    "comment": "Writes audio data from a buffer to a PCM substream, handling potential OSS plugin processing and user-kernel memory copying.",
    "prorec_sum": "Handles audio playback data transfer, adjusting buffer offsets and sizes based on stream parameters, and delegating to appropriate low-level write or copy routines.",
    "filter_prorec_sum": "Reads audio frames from a PCM substream buffer, handling format-specific frame sizing and delegating to appropriate fallback when no hardware buffer is present.",
    "prorec_aug_sum": "Processes PCM substream buffer data, invoking alternate handling if specific runtime parameters exist, and returns the processed frame count scaled by frame or sample size.",
    "filter_prorec_aug_sum": "Processes PCM substream data transfer, using hardware-specific parameters when available or a fallback routine, and returns the transferred frame count in bytes.",
    "work_score": {
        "prorec": {
            "summary": "Handles audio playback data transfer, adjusting buffer offsets and sizes based on stream parameters, and delegating to appropriate low-level write or copy routines.",
            "score": [
                0.5,
                0.6,
                0.3333333333333333
            ],
            "reason": [
                "The summary vaguely describes audio playback data transfer and buffer adjustments, but the source code shows specific operations like calculating frame sizes, conditional plugin handling, `copy_from_user` usage, and delegating to `snd_pcm_plug_write_transfer` or `snd_pcm_oss_write3`. The summary omits these explicit details and instead makes generalized claims about buffer offsets and sizes without clear evidence from the code, making most semantic details unverifiable.",
                "The summary vaguely describes audio data transfer and delegation to routines, which aligns partially with the source code's logic in calling low-level functions for writing and handling user-space copying when necessary. However, it inaccurately mentions adjusting buffer offsets, which is not explicitly present in the source code, and omits key details such as conditional plugin handling, calculation of frame sizes, error checking on copy_from_user, and the specific flow for plugin versus non-plugin cases. This results in coverage of the main action but missing significant portions of the core logic.",
                "The summary claims the code adjusts buffer offsets, which is not explicitly supported by the source. While it correctly notes handling audio playback data transfer and delegating to lower-level write or copy routines (seen in calls to copy_from_user, snd_pcm_plug_write_transfer, and snd_pcm_oss_write3), the mention of buffer offsets is inaccurate. With one key inaccuracy out of three details, the proportion of inaccurate details is below the kill-switch threshold, but the accurate parts are generic and lack domain-specific richness beyond high-level data handling steps."
            ]
        },
        "filter_prorec": {
            "summary": "Reads audio frames from a PCM substream buffer, handling format-specific frame sizing and delegating to appropriate fallback when no hardware buffer is present.",
            "score": [
                0.5,
                0.39999999999999997,
                0.0
            ],
            "reason": [
                "The summary claims the function reads audio frames from a PCM substream buffer and uses a fallback when no hardware buffer is present. While the source code shows logic for calculating frame sizes and writing PCM data, there is no explicit mention of 'reading' audio frames or of a missing hardware buffer as a fallback condition; instead it writes data and delegates based on the presence of OSS plugins. Only the frame sizing and delegation aspects are accurate, meaning less than half of the details are supported by the code.",
                "The summary is largely inaccurate because the source code does not reference reading audio frames or a hardware buffer. Instead, it performs a write operation to a PCM substream, calculates frame sizes based on plugin parameters, handles user-kernel space data transfer via copy_from_user, and calls different write functions depending on plugin presence. These core details are missing from the summary, leaving almost no accurate content.",
                "The summary claims the function reads audio frames from a PCM substream buffer, but in the source code the function writes data to the substream, performing either plugin-based transfer or a fallback routine. The mention of a fallback when no hardware buffer is present is unsupported; the code\u2019s conditional is based on the presence of a plugin, not hardware buffer availability. Both key details are inaccurate, exceeding the 50% threshold, resulting in a misleading summary."
            ]
        }
    }
}
{
    "source_code": "static int\nbackward_move_node_structure (WINDOW *window, int behaviour)\n{\n  if (window->node->flags & (N_IsInternal | N_IsManPage))\n    return 1;\n\n  switch (behaviour)\n    {\n    case IS_PageOnly:\n      info_error (\"%s\", msg_at_node_top);\n      return 1;\n\n    case IS_NextOnly:\n      return !info_handle_pointer (\"Prev\", window);\n      break;\n\n    case IS_Continuous:\n      if (window->node->up)\n        {\n          /* If up is the dir node, we are at the top node.\n             Don't do anything. */\n          if (!strncasecmp (window->node->up, \"(dir)\", strlen (\"(dir)\")))\n            {\n              info_error (\"%s\", _(\"No 'Prev' or 'Up' for this node within this document\"));\n              return 1;\n            }\n          /* If 'Prev' and 'Up' are the same, we are at the first node\n             of the 'Up' node's menu. Go to up node. */\n          else if (window->node->prev\n              && !strcmp(window->node->prev, window->node->up))\n            {\n              if (!info_handle_pointer (\"Up\", window))\n                return 1;\n            }\n          /* Otherwise, go to 'Prev' node and go down the last entry\n             in the menus as far as possible. */\n          else if (window->node->prev)\n            {\n              int starting_hist_index = window->hist_index;\n              if (!info_handle_pointer (\"Prev\", window))\n                return 1;\n              if (!(window->node->flags & N_IsIndex))\n                {\n                  while (1)\n                    {\n                      REFERENCE *entry = select_menu_digit (window, '0');\n                      if (!entry)\n                        break;\n                      if (!info_select_reference (window, entry))\n                        break;\n                    }\n                  /* Don't include intermediate nodes in the window's\n                     history.  */\n                  cleanup_history (window, starting_hist_index,\n                                   window->hist_index - 1);\n                }\n            }\n          else /* 'Up' but no 'Prev' */\n            {\n              if (!info_handle_pointer (\"Up\", window))\n                return 1;\n            }\n        }\n      else if (window->node->prev) /* 'Prev' but no 'Up' */\n        {\n          if (!info_handle_pointer (\"Prev\", window))\n            return 1;\n        }\n      else\n        {\n          info_error (\"%s\", _(\"No 'Prev' or 'Up' for this node within this document\"));\n          return 1;\n        }\n\n      break; /* case IS_Continuous: */\n    }\n  return 0;\n}",
    "comment": "Handles backward navigation in a document's node structure based on specified behavior, managing transitions to previous or upward nodes as necessary.",
    "prorec_sum": "Determines and executes navigation to 'Prev' or 'Up' nodes, handling special cases and displaying errors when such navigation is unavailable.",
    "filter_prorec_sum": "Handles navigation commands by executing \u201cPrev\u201d or \u201cUp\u201d actions for document nodes and displaying messages when no relevant navigation target exists.",
    "prorec_aug_sum": "Determines navigation availability for 'Prev' or 'Up' nodes and executes related actions, displaying an error message if neither is accessible.",
    "filter_prorec_aug_sum": "Determines navigation availability for \"Prev\" or \"Up\" nodes in a document, handling directory markers and displaying an error when neither is accessible.",
    "work_score": {
        "prorec": {
            "summary": "Determines and executes navigation to 'Prev' or 'Up' nodes, handling special cases and displaying errors when such navigation is unavailable.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary accurately reflects the core functionality of the source code: navigating to 'Prev' or 'Up' nodes, managing special cases such as the absence of these links, and displaying relevant error messages. All stated details are explicitly supported by the code's logic, which includes multiple conditionals to select 'Prev' or 'Up' and error handling when neither is available.",
                "The summary accurately reflects the main logic of the source code \u2014 it describes navigation to 'Prev' or 'Up' nodes and mentions special case handling with error messages when navigation is unavailable. While it does not detail all edge cases (such as handling internal/manpage nodes or continuous navigation logic with menu traversal and history cleanup), the core navigation behavior and error handling are captured without hallucination.",
                "The summary accurately captures the core functionality shown in the source code, which involves navigating to 'Prev' or 'Up' nodes, handling special cases (such as when 'Prev' and 'Up' are the same, or when either is missing), and displaying appropriate error messages when navigation is not possible. All stated details are explicitly supported by the logic in the code, including multiple conditional branches and calls to info_error. While accurate, the summary provides only a high-level description without deeper specifics like handling IS_PageOnly, IS_NextOnly, or the looping through menu entries, making it somewhat generic rather than richly detailed."
            ]
        },
        "filter_prorec": {
            "summary": "Handles navigation commands by executing \u201cPrev\u201d or \u201cUp\u201d actions for document nodes and displaying messages when no relevant navigation target exists.",
            "score": [
                0.9666666666666667,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly captures the core navigation logic, specifically that the function executes 'Prev' or 'Up' actions for document nodes and shows an error message when no target exists. These details are directly evidenced by calls to info_handle_pointer with 'Prev' or 'Up' and info_error calls in the source code. However, the summary omits some nuanced behaviors, such as special handling for '(dir)' nodes, checking for identical 'Prev' and 'Up', and traversing menu entries. Despite these omissions, the given details are accurate with no hallucinations.",
                "The summary accurately captures the navigation logic in the source code, which includes executing 'Prev' or 'Up' actions depending on node relationships and returning error messages when neither is available. However, it omits important branching details such as handling specific behaviour cases (IS_PageOnly, IS_NextOnly, IS_Continuous), checks for '(dir)' nodes, conditions for traversing menu entries, and history cleanup. This means it conveys the main action but misses significant implementation logic.",
                "The summary correctly identifies that the function handles navigation using \"Prev\" or \"Up\" actions and displays error messages when no navigation target exists, which is explicitly supported by the function's conditional logic and calls to info_handle_pointer and info_error. However, it omits specific branching conditions for behaviours (IS_PageOnly, IS_NextOnly, IS_Continuous), as well as the detailed logic for handling top nodes, index nodes, and history cleanup, making the accurate details somewhat generic rather than domain-rich."
            ]
        }
    }
}
{
    "source_code": "\nstatic void *\ndogleg_alloc (const void * params, const size_t n, const size_t p)\n{\n  dogleg_state_t *state;\n  \n  state = calloc(1, sizeof(dogleg_state_t));\n  if (state == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate dogleg state\", GSL_ENOMEM);\n    }\n\n  state->dx_gn = gsl_vector_alloc(p);\n  if (state->dx_gn == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for dx_gn\", GSL_ENOMEM);\n    }\n\n  state->dx_sd = gsl_vector_alloc(p);\n  if (state->dx_sd == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for dx_sd\", GSL_ENOMEM);\n    }\n\n  state->workp1 = gsl_vector_alloc(p);\n  if (state->workp1 == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for workp1\", GSL_ENOMEM);\n    }\n\n  state->workp2 = gsl_vector_alloc(p);\n  if (state->workp2 == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for workp2\", GSL_ENOMEM);\n    }\n\n  state->workn = gsl_vector_alloc(n);\n  if (state->workn == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for workn\", GSL_ENOMEM);\n    }\n\n  state->n = n;\n  state->p = p;\n  state->params = *(const gsl_multilarge_nlinear_parameters *) params;\n\n  return state;\n}",
    "comment": "Allocates memory for a dogleg optimization state and its associated vectors, initializing parameters for nonlinear optimization.",
    "prorec_sum": "Allocates and initializes a dogleg solver state with multiple GSL vectors, copying parameters and data from the provided source structure.",
    "filter_prorec_sum": "Allocates and initializes a dogleg solver state structure with multiple GSL vectors, copying parameters and vector data from the provided source structure.",
    "prorec_aug_sum": "Allocates and initializes a dogleg solver state structure with multiple GSL vectors, copying initial parameters from the provided input structure.",
    "filter_prorec_aug_sum": "Allocates and initializes a dogleg algorithm state structure with multiple GSL vectors, copying initial parameters from the provided input structure.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a dogleg solver state with multiple GSL vectors, copying parameters and data from the provided source structure.",
            "score": [
                0.8666666666666667,
                0.6333333333333333,
                0.8000000000000002
            ],
            "reason": [
                "The summary correctly identifies that the function allocates and initializes a dogleg solver state and uses multiple GSL vectors. It also accurately states that parameters are copied from the provided structure (`params` cast to `gsl_multilarge_nlinear_parameters`). However, the phrase 'copying parameters and data' slightly overstates since the code only copies parameters, not separate 'data'. Overall, nearly all of the details are explicitly supported by the source code, with only a minor overreach in describing 'data'.",
                "The summary correctly states that the function allocates and initializes a dogleg solver state, and that it uses multiple GSL vectors and copies parameters from the provided input structure. These details are explicitly supported by the source code, which allocates gsl_vector objects for dx_gn, dx_sd, workp1, workp2, and workn, and assigns params after casting. However, the phrase 'copying parameters and data' is slightly misleading, as the code copies only a parameters structure and does not copy arbitrary data beyond size values for n and p. Despite that minor inaccuracy, the accurate details cover the main action but do not mention explicit error handling logic present in the source, meaning some key aspects are omitted.",
                "The summary correctly states that the function allocates and initializes a dogleg solver state and multiple GSL vectors, and that parameters from the provided structure are copied into the state. However, the claim of copying 'data' from the source structure is inaccurate \u2014 the code only copies parameter values, not additional data content. With only one inaccuracy out of several details, the accurate parts are specific to GSL vectors and parameter handling, offering meaningful domain insight."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a dogleg solver state structure with multiple GSL vectors, copying parameters and vector data from the provided source structure.",
            "score": [
                0.6333333333333333,
                0.6,
                0.4666666666666666
            ],
            "reason": [
                "The summary correctly notes allocation of a dogleg solver state structure with multiple GSL vectors and copying parameters, which is explicitly shown in the code. However, it inaccurately claims that vector data is copied from the provided source structure; the code only copies scalar parameters, not vector contents. This introduces an unverified detail, reducing overall accuracy.",
                "The summary accurately notes allocation and initialization of a dogleg solver state with multiple GSL vectors and copying parameters, which is evident from multiple gsl_vector_alloc calls and assignment of params. However, it inaccurately claims copying vector data from the provided source structure, which is not present in the code. This omission of the actual error handling and allocation steps for each vector means the correct logic is only partially covered.",
                "The summary claims that vector data is copied from the provided source structure, but the source code only copies the parameter struct and allocates new vectors using gsl_vector_alloc without copying any existing vector data. This makes the 'copying vector data' detail inaccurate. The other claims\u2014allocating and initializing a dogleg solver state, using multiple GSL vectors, and copying parameters\u2014are supported by the code. As only one of four details is inaccurate, the proportion of inaccuracies is below the threshold, but the accurate details are somewhat generic and lack deeper domain-specific insight."
            ]
        }
    }
}
{
    "source_code": "\n\nngx_int_t\nngx_os_init(ngx_log_t *log)\n{\n    ngx_time_t  *tp;\n    ngx_uint_t   n;\n#if (NGX_HAVE_LEVEL1_DCACHE_LINESIZE)\n    long         size;\n#endif\n\n#if (NGX_HAVE_OS_SPECIFIC_INIT)\n    if (ngx_os_specific_init(log) != NGX_OK) {\n        return NGX_ERROR;\n    }\n#endif\n\n    if (ngx_init_setproctitle(log) != NGX_OK) {\n        return NGX_ERROR;\n    }\n\n    ngx_pagesize = getpagesize();\n    ngx_cacheline_size = NGX_CPU_CACHE_LINE;\n\n    for (n = ngx_pagesize; n >>= 1; ngx_pagesize_shift++) { /* void */ }\n\n#if (NGX_HAVE_SC_NPROCESSORS_ONLN)\n    if (ngx_ncpu == 0) {\n        ngx_ncpu = sysconf(_SC_NPROCESSORS_ONLN);\n    }\n#endif\n\n    if (ngx_ncpu < 1) {\n        ngx_ncpu = 1;\n    }\n\n#if (NGX_HAVE_LEVEL1_DCACHE_LINESIZE)\n    size = sysconf(_SC_LEVEL1_DCACHE_LINESIZE);\n    if (size > 0) {\n        ngx_cacheline_size = size;\n    }\n#endif\n\n    ngx_cpuinfo();\n\n    if (getrlimit(RLIMIT_NOFILE, &rlmt) == -1) {\n        ngx_log_error(NGX_LOG_ALERT, log, errno,\n                      \"getrlimit(RLIMIT_NOFILE) failed\");\n        return NGX_ERROR;\n    }\n\n    ngx_max_sockets = (ngx_int_t) rlmt.rlim_cur;\n\n#if (NGX_HAVE_INHERITED_NONBLOCK || NGX_HAVE_ACCEPT4)\n    ngx_inherited_nonblocking = 1;\n#else\n    ngx_inherited_nonblocking = 0;\n#endif\n\n    tp = ngx_timeofday();\n    srandom(((unsigned) ngx_pid << 16) ^ tp->sec ^ tp->msec);\n\n    return NGX_OK;\n}",
    "comment": "Initializes operating system parameters, retrieves CPU information, sets process title, and configures resource limits for a server application.",
    "prorec_sum": "Initializes OS-specific settings, determines system page and cache parameters, retrieves limits, gathers CPU info, and seeds randomness for the Nginx runtime environment.",
    "filter_prorec_sum": "Initializes core OS-specific parameters for Nginx, including page and cache line sizes, CPU count, file limits, and random seed setup.",
    "prorec_aug_sum": "Initializes OS-specific settings for Nginx, determines system page and cache parameters, configures CPU info, file descriptor limits, and seeds the random number generator.",
    "filter_prorec_aug_sum": "Initializes OS-level settings for Nginx, including page size, CPU and cacheline parameters, resource limits, and process title, then seeds the random number generator.",
    "work_score": {
        "prorec": {
            "summary": "Initializes OS-specific settings, determines system page and cache parameters, retrieves limits, gathers CPU info, and seeds randomness for the Nginx runtime environment.",
            "score": [
                1.0,
                0.9,
                0.9
            ],
            "reason": [
                "The summary correctly notes initialization of OS-specific settings, determination of page size and cache line size, retrieval of resource limits, CPU information gathering, and seeding randomness, all of which are explicitly present in the source code. No details in the summary are unsupported, so it aligns closely with the actual implementation.",
                "The summary accurately reflects the main functionality of the source code: it correctly notes OS-specific initialization, retrieval of system page size and cache line size, fetching system resource limits, gathering CPU information, and seeding the random number generator. These steps are explicitly present in the code, and no major hallucinations are detected. However, the summary omits certain specific control flow details such as handling when `ngx_ncpu` is zero, conditional compilation flags, and the use of `getrlimit` error handling, meaning it is not a fully complete picture of the logic.",
                "The summary contains multiple accurate details: it correctly notes OS-specific initialization, determining page size and cache parameters, retrieving system limits, gathering CPU info, and seeding randomness, all of which are explicitly shown in the source code via functions like ngx_os_specific_init, getpagesize, sysconf, getrlimit, ngx_cpuinfo, and srandom. These details are domain-specific and reflect specific actions in the code, with no evident inaccuracies."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes core OS-specific parameters for Nginx, including page and cache line sizes, CPU count, file limits, and random seed setup.",
            "score": [
                1.0,
                0.7666666666666666,
                0.7333333333333334
            ],
            "reason": [
                "The summary correctly identifies all major operations in the source code: initialization of OS-specific parameters, setting page size and cache line size, determining CPU count, retrieving file descriptor limit, and seeding the random number generator. All these details are explicitly present in the function, with no unverified assumptions or hallucinations.",
                "The summary accurately reflects the source code's initialization steps for OS-specific parameters, including setting page size, cache line size, CPU count, file descriptor limits via getrlimit, and seeding the random number generator. These details are all explicitly present in the code, covering the main logic flow, though it omits some secondary details like conditional compilation flags and ngx_os_specific_init check.",
                "The summary's details about initializing page size, cache line size, CPU count, file limits, and random seed are all explicitly supported by the source code via functions like getpagesize(), sysconf(), getrlimit(), and srandom(). No inaccuracies are present, but the details are presented in a generic manner without deeper insight into the control flow or conditional compilation logic present in the code."
            ]
        }
    }
}
{
    "source_code": "static int tcp_match_skb_to_sack(struct sock *sk, struct sk_buff *skb,\n\t\t\t\t  u32 start_seq, u32 end_seq)\n{\n\tint err;\n\tbool in_sack;\n\tunsigned int pkt_len;\n\tunsigned int mss;\n\n\tin_sack = !after(start_seq, TCP_SKB_CB(skb)->seq) &&\n\t\t  !before(end_seq, TCP_SKB_CB(skb)->end_seq);\n\n\tif (tcp_skb_pcount(skb) > 1 && !in_sack &&\n\t    after(TCP_SKB_CB(skb)->end_seq, start_seq)) {\n\t\tmss = tcp_skb_mss(skb);\n\t\tin_sack = !after(start_seq, TCP_SKB_CB(skb)->seq);\n\n\t\tif (!in_sack) {\n\t\t\tpkt_len = start_seq - TCP_SKB_CB(skb)->seq;\n\t\t\tif (pkt_len < mss)\n\t\t\t\tpkt_len = mss;\n\t\t} else {\n\t\t\tpkt_len = end_seq - TCP_SKB_CB(skb)->seq;\n\t\t\tif (pkt_len < mss)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* Round if necessary so that SACKs cover only full MSSes\n\t\t * and/or the remaining small portion (if present)\n\t\t */\n\t\tif (pkt_len > mss) {\n\t\t\tunsigned int new_len = (pkt_len / mss) * mss;\n\t\t\tif (!in_sack && new_len < pkt_len) {\n\t\t\t\tnew_len += mss;\n\t\t\t\tif (new_len > skb->len)\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tpkt_len = new_len;\n\t\t}\n\t\terr = tcp_fragment(sk, skb, pkt_len, mss);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\treturn in_sack;\n}",
    "comment": "Determines if a TCP segment belongs to the SACK range and fragments it accordingly based on MSS and sequence numbers.",
    "prorec_sum": "Checks position offsets against stored bounds and segment sizes, invoking a helper to process within range and returning status or specific error codes.",
    "filter_prorec_sum": "Validates position parameters against struct bounds and block size, invoking a helper to process data when within the allowed range.",
    "prorec_aug_sum": "Checks size and position parameters against route-related limits and invokes a helper to process data when within allowed threshold boundaries.",
    "filter_prorec_aug_sum": "Checks packet size against route\u2019s path MTU and invokes handling logic when size exceeds limits, returning status or specific error codes accordingly.",
    "work_score": {
        "prorec": {
            "summary": "Checks position offsets against stored bounds and segment sizes, invoking a helper to process within range and returning status or specific error codes.",
            "score": [
                0.9666666666666667,
                0.6,
                0.5666666666666668
            ],
            "reason": [
                "The summary correctly notes that the function checks position offsets (via sequence comparisons) against stored bounds and segment sizes, and that it returns either a status or specific error codes (e.g., -EINVAL). It also mentions invoking a helper to process when within range, which matches the call to tcp_fragment after certain conditions are met. These details are all directly supported by the source code, with no unverified or hallucinated claims.",
                "The summary correctly captures that the function checks position-related values (\u2018position offsets against stored bounds\u2019 maps to comparing start_seq/end_seq to skb sequence numbers) and that it may return status or error codes (e.g., -EINVAL, propagated err). It also notes invocation of a helper when within certain conditions (tcp_fragment is called when criteria are met). However, it omits significant details such as the in_sack initial logic, multi-packet handling via tcp_skb_pcount, MSS rounding, and edge-case handling for pkt_len adjustments, so the description is incomplete regarding the control flow and data manipulation.",
                "The summary captures some accurate aspects such as checking positions against bounds and segment sizes, invoking a helper function, and returning either a status or an error code, all of which are evidenced by the use of 'after'/'before' checks, mss/pkt_len comparisons, tcp_fragment calls, and -EINVAL returns. However, it omits key specifics like SACK logic, multiple packet handling, and the detailed rounding behavior, making the accurate details somewhat generic rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Validates position parameters against struct bounds and block size, invoking a helper to process data when within the allowed range.",
            "score": [
                0.06666666666666667,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims validation of position parameters against struct bounds and block size, and invoking a helper to process data when in range. In the source, the function checks TCP sequence numbers and calculates packet length relative to MSS, not generic 'position parameters' or generic struct bounds. While a helper function `tcp_fragment` is invoked, the context is TCP SACK handling rather than general data processing. Most described details are inaccurate or overly generic, lacking explicit evidence in the code. Accurate elements are limited to the presence of a helper invocation.",
                "The summary claims the function validates position parameters against struct bounds and block size, and invokes a helper to process data if within the allowed range. In the source code, the function checks whether the skb sequence falls within the SACK range, handles packet fragmentation using MSS, and calls tcp_fragment based on computed lengths and conditions. There is no explicit concept of 'struct bounds' or generic 'block size'; instead, it deals specifically with sequence numbers, MSS rounding logic, and skb length checks. The summary omits key logic such as multiple-packet handling, error returns, and rounding behavior, and misrepresents the data semantics, leading to no accurate alignment with the code.",
                "The summary claims validation of position parameters against struct bounds and block size, and invocation of a helper to process data when within range. The source code instead checks sequence numbers against SACK ranges, handles packet fragmentation using MSS, and calls tcp_fragment under specific conditions. There is no explicit mention of position parameters, struct bounds, or block size in the code. All details in the summary are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "static int o_save_ptr_helper(o_string *o, int n)\n{\n\tchar **list = (char**)o->data;\n\tint string_start;\n\tint string_len;\n\n\tif (!o->has_empty_slot) {\n\t\tstring_start = ((n + 0xf) & ~0xf) * sizeof(list[0]);\n\t\tstring_len = o->length - string_start;\n\t\tif (!(n & 0xf)) { /* 0, 0x10, 0x20...? */\n\t\t\tdebug_printf_list(\"list[%d]=%d string_start=%d (growing)\\n\", n, string_len, string_start);\n\t\t\t/* list[n] points to string_start, make space for 16 more pointers */\n\t\t\to->maxlen += 0x10 * sizeof(list[0]);\n\t\t\to->data = xrealloc(o->data, o->maxlen + 1);\n\t\t\tlist = (char**)o->data;\n\t\t\tmemmove(list + n + 0x10, list + n, string_len);\n\t\t\to->length += 0x10 * sizeof(list[0]);\n\t\t} else {\n\t\t\tdebug_printf_list(\"list[%d]=%d string_start=%d\\n\",\n\t\t\t\t\tn, string_len, string_start);\n\t\t}\n\t} else {\n\t\t/* We have empty slot at list[n], reuse without growth */\n\t\tstring_start = ((n+1 + 0xf) & ~0xf) * sizeof(list[0]); /* NB: n+1! */\n\t\tstring_len = o->length - string_start;\n\t\tdebug_printf_list(\"list[%d]=%d string_start=%d (empty slot)\\n\",\n\t\t\t\tn, string_len, string_start);\n\t\to->has_empty_slot = 0;\n\t}\n\to->has_quoted_part = 0;\n\tlist[n] = (char*)(uintptr_t)string_len;\n\treturn n + 1;\n}",
    "comment": "Reallocates string storage for a list, handles empty slots, and updates the length and state of the string data structure.",
    "prorec_sum": "Updates an indexed entry in a state structure, reallocating and initializing when needed, then returns the incremented index.",
    "filter_prorec_sum": "Updates a data structure entry for index\u202f`a2`, optionally creating and initializing it when alignment conditions are met, and returns the next index value.",
    "prorec_aug_sum": "Updates an entry in a table at index\u202f`a2`, allocating and initializing new space when needed, then returns the next index value.",
    "filter_prorec_aug_sum": "Updates an entry in a table at index\u202f`a2`, allocating and initializing a new block if required, and returns the next index value.",
    "work_score": {
        "prorec": {
            "summary": "Updates an indexed entry in a state structure, reallocating and initializing when needed, then returns the incremented index.",
            "score": [
                0.6999999999999998,
                0.5666666666666668,
                0.16666666666666666
            ],
            "reason": [
                "The summary contains only one major claim: that the function updates an indexed entry, reallocates and initializes when needed, and returns the incremented index. The reallocating portion is accurate and well-supported by the `xrealloc` and `memmove` logic in the source, and the return value `n + 1` matches. However, the term 'initializing' is unsupported, as there is no explicit initialization of new memory beyond reallocation, making that a hallucination. Overall, most of the described behavior is accurate, with only a minor unverified assumption.",
                "The summary captures the high-level idea of updating an indexed entry and reallocating when needed, which matches part of the code's behavior involving list[n] updates and conditional xrealloc with memmove. However, it omits critical details such as the empty-slot reuse path, debug logging, specific alignment operations using bitwise logic, changes to maxlen/length, and resetting flags like has_empty_slot and has_quoted_part. These omissions mean the accurate content does not fully represent the code's complete logic flow.",
                "The summary omits most of the specific logic found in the source code, such as the conditional handling for empty slots, the calculation of string_start and string_len, the use of debug_printf_list for logging, and the specific growth logic involving xrealloc and memmove. Its claim about 'reallocating and initializing when needed' is only partially accurate, but 'initializing' is unsupported by the code. Since more than half of the details in the summary are either vague or inaccurate, it triggers the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Updates a data structure entry for index\u202f`a2`, optionally creating and initializing it when alignment conditions are met, and returns the next index value.",
            "score": [
                0.6,
                0.5,
                0.16666666666666666
            ],
            "reason": [
                "The summary claims the function works with index `a2`, but the source code uses parameter `n`. It correctly notes that the function updates a data structure entry and returns the next index value (matching the return of `n + 1`). However, the claim about 'optionally creating and initializing it when alignment conditions are met' is only partially accurate: while the code grows the list when `n & 0xf == 0`, it doesn't explicitly 'initialize' entries as described. These discrepancies mean only some key details are supported by explicit evidence from the code.",
                "The summary correctly captures that the function updates a data structure entry at a given index and returns the next index, aligning with the code's return of n+1 and assignment to list[n]. However, it omits key accurate details, such as conditional growth of the array when no empty slot exists, memory reallocation with xrealloc, memmove operations, handling of alignment with 16-element boundaries, and resetting flags like has_quoted_part and has_empty_slot. The mention of 'creating and initializing when alignment conditions are met' is partially accurate but lacks explicit reference to the 0x10 alignment and pointer slot expansion logic shown in the code.",
                "The summary claims the function updates a data structure entry for index `a2`, but the source code uses parameter `n` without any mention of `a2`, making this detail inaccurate. It also says it 'optionally creates and initializes it when alignment conditions are met', which partially aligns with the code\u2019s behavior of reallocating and shifting elements when `n & 0xf == 0` and no empty slot exists. However, the summary omits important specifics such as handling of `has_empty_slot`, calculations of `string_start` and `string_len`, and updating `has_quoted_part`. Accurate elements (returning the next index, conditional growth) are generic and do not convey the full domain-specific logic present in the code."
            ]
        }
    }
}
{
    "source_code": "\nvoid\ndatamash_ops_free ( struct datamash_ops* p )\n{\n  assert (p != NULL);                            /* LCOV_EXCL_LINE */\n  for (size_t i=0; i<p->num_grps; ++i)\n    free (p->grps[i].name);\n  free (p->grps);\n  p->grps = NULL;\n\n  #ifndef _STANDALONE_\n  for (size_t i=0; i<p->num_ops; ++i)\n    field_op_free (&p->ops[i]);\n  #endif\n\n  free (p->ops);\n  p->ops = NULL;\n\n  for  (size_t i=0; i<_fields_used; ++i) {\n    free (_fields[i].name);\n  }\n  free (_fields);\n  _fields = NULL;\n  _fields_alloc = 0;\n  _fields_used = 0;\n\n  free (_params);\n  _params_alloc = 0;\n  _params_used = 0;\n\n  free (p);\n}",
    "comment": "Frees allocated memory for operation groups, fields, parameters, and the datamash_ops structure while ensuring no memory leaks occur.",
    "prorec_sum": "Frees all dynamically allocated memory associated with the given datamash operations structure and related global data before releasing the structure itself.",
    "filter_prorec_sum": "Frees all dynamically allocated fields, arrays, and global buffers associated with an operation parser structure, then releases the structure itself.",
    "prorec_aug_sum": "Releases all dynamically allocated fields, nested structures, and global arrays associated with an operation parser, then frees the parser object itself.",
    "filter_prorec_aug_sum": "Frees all dynamically allocated memory associated with an operation parser structure, including its internal arrays, elements, and related global resources.",
    "work_score": {
        "prorec": {
            "summary": "Frees all dynamically allocated memory associated with the given datamash operations structure and related global data before releasing the structure itself.",
            "score": [
                1.0,
                0.8333333333333334,
                0.9
            ],
            "reason": [
                "The summary accurately states that the function releases all dynamically allocated memory linked to the datamash operations structure (`p`) and associated global data before freeing the structure itself. The source code confirms freeing group names, group array, operation arrays, field names, global fields array, parameters, and finally the structure itself. No hallucinated details are present, and all claims are explicitly supported by the code.",
                "The summary accurately states that the function frees dynamically allocated memory for the provided datamash operations structure and associated global data before releasing the structure itself. The source code confirms memory deallocation for multiple components of the struct (`grps`, `ops`) and global arrays (`_fields`, `_params`) followed by freeing the struct. No claims in the summary are unsupported or incorrect, but the summary omits details about control flow aspects like conditionally freeing `ops` elements when `_STANDALONE_` is not defined, and resetting allocation counters, which means it covers the main action but not all specifics.",
                "The summary accurately reflects that the function frees all dynamically allocated memory tied to both the given datamash_ops structure and related global data before freeing the structure itself. Every step mentioned is explicitly evident in the source code: freeing group names, groups array, ops data, fields names and array, params, resetting related counters, and ultimately freeing the structure pointer. No inaccurate details were found, and the accurate description conveys a clear, domain-specific understanding of the code\u2019s purpose."
            ]
        },
        "filter_prorec": {
            "summary": "Frees all dynamically allocated fields, arrays, and global buffers associated with an operation parser structure, then releases the structure itself.",
            "score": [
                1.0,
                0.7333333333333334,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly states that the function frees dynamically allocated fields, arrays, and global buffers related to the structure, and finally frees the structure itself. Each of these details is explicitly supported by the source code: it frees group names, group arrays, operation arrays, global _fields and _params buffers, and the struct pointer. No unverified assumptions are present, making all details accurate.",
                "The summary accurately states that the function frees dynamically allocated fields, arrays, and global buffers tied to a structure, and then frees the structure itself. The source code shows it freeing group names, group arrays, ops arrays, global _fields array and its elements, global _params buffer, and finally the struct itself. While correct, the summary is high-level and omits notable specific details such as conditional freeing of operations under _STANDALONE_, resetting allocation counters (_fields_alloc, _params_alloc), and zeroing usage counters (_fields_used, _params_used), which are part of the function's complete logic.",
                "The summary correctly states that the function frees all dynamically allocated fields, arrays, and global buffers tied to the structure, then frees the structure itself. The source confirms freeing group names, ops, global _fields, and _params, and finally the struct. All details are accurate and provide domain-specific insight into memory deallocation logic."
            ]
        }
    }
}
{
    "source_code": "\nbfd_boolean\n_bfd_elf_maybe_strip_eh_frame_hdr (struct bfd_link_info *info)\n{\n  struct elf_link_hash_table *htab;\n  struct eh_frame_hdr_info *hdr_info;\n  struct bfd_link_hash_entry *bh = NULL;\n  struct elf_link_hash_entry *h;\n\n  htab = elf_hash_table (info);\n  hdr_info = &htab->eh_info;\n  if (hdr_info->hdr_sec == NULL)\n    return TRUE;\n\n  if (bfd_is_abs_section (hdr_info->hdr_sec->output_section)\n      || info->eh_frame_hdr_type == 0\n      || (info->eh_frame_hdr_type == DWARF2_EH_HDR\n\t  && !_bfd_elf_eh_frame_present (info))\n      || (info->eh_frame_hdr_type == COMPACT_EH_HDR\n\t  && !_bfd_elf_eh_frame_entry_present (info)))\n    {\n      hdr_info->hdr_sec->flags |= SEC_EXCLUDE;\n      hdr_info->hdr_sec = NULL;\n      return TRUE;\n    }\n\n  /* Add a hidden symbol so that systems without access to PHDRs can\n     find the table.  */\n  if (! (_bfd_generic_link_add_one_symbol\n\t (info, info->output_bfd, \"__GNU_EH_FRAME_HDR\", BSF_LOCAL,\n\t  hdr_info->hdr_sec, 0, NULL, FALSE, FALSE, &bh)))\n    return FALSE;\n\n  h = (struct elf_link_hash_entry *) bh;\n  h->def_regular = 1;\n  h->other = STV_HIDDEN;\n  get_elf_backend_data\n    (info->output_bfd)->elf_backend_hide_symbol (info, h, TRUE);\n\n  if (!hdr_info->frame_hdr_is_compact)\n    hdr_info->u.dwarf.table = TRUE;\n  return TRUE;\n}",
    "comment": "Modifies the header section flags and adds a hidden symbol if specific conditions for EH frame header presence are not met.",
    "prorec_sum": "Handles GNU EH frame header processing based on status flags, updating related structures and clearing session data when conditions are not met.",
    "filter_prorec_sum": "Handles a session\u2019s GNU exception frame header, updating related flags and structures or clearing references based on specific status bits.",
    "prorec_aug_sum": "Processes ELF exception handling frame data for a given object, updating related flags and invoking a handler when specific header conditions are met.",
    "filter_prorec_aug_sum": "Handles GNU EH frame header processing for an ELF object, updating related flags and structures based on object state and validation results.",
    "work_score": {
        "prorec": {
            "summary": "Handles GNU EH frame header processing based on status flags, updating related structures and clearing session data when conditions are not met.",
            "score": [
                0.6,
                0.5333333333333333,
                0.26666666666666666
            ],
            "reason": [
                "The summary captures that the code processes the GNU EH frame header based on certain conditions and updates structures accordingly, which aligns with the source code's conditional checks and modifications to `hdr_info`. However, the mention of 'clearing session data' is inaccurate\u2014there is no evidence of session data being cleared; the code only nullifies `hdr_sec` and modifies flags. Overall, only part of the summary is directly supported by the source code, with at least one key detail being a hallucination.",
                "The summary correctly notes that the function handles EH frame header processing and updates related structures based on conditional checks. However, it inaccurately describes 'clearing session data', which is not present in the code. It also omits specific and critical logic like header section exclusion, symbol creation, hidden symbol handling, and compact vs. DWARF table configuration. While the gist of status flag checking is mentioned, the coverage is incomplete and lacking in key details present in the source.",
                "The summary makes vague claims about handling GNU EH frame header processing and clearing session data, but the source code does not reference or manipulate any 'session data'. While the summary generically matches the control flow based on flags and updates of related structures in the header info, it omits concrete details such as symbol addition, SEC_EXCLUDE flag setting, and specific function calls. The mention of session data is inaccurate, giving more than 50% inaccurate details, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Handles a session\u2019s GNU exception frame header, updating related flags and structures or clearing references based on specific status bits.",
            "score": [
                0.5333333333333333,
                0.5,
                0.16666666666666666
            ],
            "reason": [
                "The summary correctly identifies that the function manages GNU exception frame header structures and updates flags or clears references based on conditional checks. However, it inaccurately describes these conditions as 'specific status bits' without referencing the actual checks present in the code, which involve hdr_sec null checks, section type, eh_frame_hdr_type values, and helper function results. This vagueness omits key explicit logic and makes part of the claim unverified. The general high-level purpose is accurate, but detail alignment is partial.",
                "The summary vaguely mentions handling a GNU exception frame header and updating flags or clearing references, which loosely aligns with the code's manipulation of hdr_sec, flags, and structures based on conditions. However, it omits critical specifics from the source code, such as the multiple condition checks on section type and hdr_type, the addition of a hidden symbol, explicit use of functions like _bfd_generic_link_add_one_symbol, and setting particular symbol attributes. Without these details, the accurate content only covers a partial view of the logic.",
                "The summary vaguely mentions handling a GNU exception frame header and updating flags based on status bits, which aligns generally with the source code\u2019s operations of modifying `hdr_sec`, setting flags like `SEC_EXCLUDE`, and managing symbol visibility. However, it omits explicit details present in the code such as condition checks on `eh_frame_hdr_type`, use of specific functions (`_bfd_generic_link_add_one_symbol`, `get_elf_backend_data`), and handling of compact vs dwarf table headers. The description of 'status bits' is not backed by the source, making it overly generic. Accurate elements are present but lack domain-rich specificity."
            ]
        }
    }
}
{
    "source_code": "static int\ngmp_stronglucas (const mpz_t x, mpz_t Qk)\n{\n  mp_bitcnt_t b0;\n  mpz_t V, n;\n  mp_limb_t maxD, D; /* The absolute value is stored. */\n  long Q;\n  mp_limb_t tl;\n\n  /* Test on the absolute value. */\n  mpz_roinit_normal_n (n, x->_mp_d, GMP_ABS (x->_mp_size));\n\n  assert (mpz_odd_p (n));\n  /* assert (mpz_gcd_ui (NULL, n, 6) == 1); */\n  if (mpz_root (Qk, n, 2))\n    return 0; /* A square is composite. */\n\n  /* Check Ds up to square root (in case, n is prime)\n     or avoid overflows */\n  maxD = (Qk->_mp_size == 1) ? Qk->_mp_d [0] - 1 : GMP_LIMB_MAX;\n\n  D = 3;\n  /* Search a D such that (D/n) = -1 in the sequence 5,-7,9,-11,.. */\n  /* For those Ds we have (D/n) = (n/|D|) */\n  do\n    {\n      if (D >= maxD)\n\treturn 1 + (D != GMP_LIMB_MAX); /* (1 + ! ~ D) */\n      D += 2;\n      tl = mpz_tdiv_ui (n, D);\n      if (tl == 0)\n\treturn 0;\n    }\n  while (gmp_jacobi_coprime (tl, D) == 1);\n\n  mpz_init (V);\n\n  /* n-(D/n) = n+1 = d*2^{b0}, with d = (n>>b0) | 1 */\n  b0 = mpz_scan0 (n, 0);\n\n  /* D= P^2 - 4Q; P = 1; Q = (1-D)/4 */\n  Q = (D & 2) ? (long) (D >> 2) + 1 : -(long) (D >> 2);\n\n  if (! gmp_lucas_mod (V, Qk, Q, b0, n))\t/* If Ud != 0 */\n    while (V->_mp_size != 0 && --b0 != 0)\t/* while Vk != 0 */\n      /* V <- V ^ 2 - 2Q^k */\n      /* Q^{2k} = (Q^k)^2 */\n      gmp_lucas_step_k_2k (V, Qk, n);\n\n  mpz_clear (V);\n  return (b0 != 0);\n}",
    "comment": "Determines if an odd integer is prime using the Lucas-Lehmer test and computes the Lucas sequence value based on specific parameters.",
    "prorec_sum": "Performs a strong Lucas probable prime test on a given large integer using mini-GMP arbitrary-precision arithmetic functions.",
    "filter_prorec_sum": "Performs a strong Lucas primality test on the given big integer using mini-gmp functions and returns whether it is a probable prime.",
    "prorec_aug_sum": "Performs a strong Lucas probable prime test on the given number using mini-gmp routines and returns the primality result.",
    "filter_prorec_aug_sum": "Performs a strong Lucas primality test on the given large integer using GMP-style arbitrary-precision operations and returns the primality result.",
    "work_score": {
        "prorec": {
            "summary": "Performs a strong Lucas probable prime test on a given large integer using mini-GMP arbitrary-precision arithmetic functions.",
            "score": [
                0.9666666666666667,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function implements a strong Lucas probable prime test, as evidenced by the function name and Lucas sequence operations in the code. It also accurately notes use of arbitrary-precision arithmetic functions from GMP (e.g., mpz_init, mpz_clear, mpz_root), although 'mini-GMP' is not explicitly stated and thus is an unverified assumption. Overall, the core claim is supported by the source code, but there is a minor inaccuracy regarding 'mini-GMP' specifically.",
                "The summary correctly identifies that the function performs a strong Lucas probable prime test on a large integer and uses mini-GMP arbitrary-precision arithmetic functions, which is explicitly supported by the function name `gmp_stronglucas` and the use of GMP functions like `mpz_root`, `mpz_tdiv_ui`, `gmp_jacobi_coprime`, and `gmp_lucas_mod`. However, the summary omits significant parts of the code\u2019s logic such as the explicit handling of squares, computation of D values, Jacobi symbol checks, Lucas sequence steps, and specific return value conditions, resulting in incomplete coverage of critical control flow and data manipulations.",
                "The summary correctly states that the function performs a strong Lucas probable prime test, which is explicitly evidenced by the function name `gmp_stronglucas` and its use of Lucas sequence logic with GMP functions. It also accurately notes the use of arbitrary-precision arithmetic functions from mini-GMP, as shown by calls like `mpz_root`, `mpz_scan0`, and `mpz_tdiv_ui`. There are no additional semantic claims to verify, and all present claims are accurate. However, the detail level is quite generic, providing only a high-level description without mentioning specific GMP functions, parameters, or the Lucas sequence steps present in the source code, so the insight value is limited."
            ]
        },
        "filter_prorec": {
            "summary": "Performs a strong Lucas primality test on the given big integer using mini-gmp functions and returns whether it is a probable prime.",
            "score": [
                0.8333333333333334,
                0.6,
                0.6333333333333333
            ],
            "reason": [
                "The summary correctly identifies that the function implements a strong Lucas primality test and uses GMP/mini-GMP functions, both clearly supported by function names and operations such as gmp_lucas_mod, gmp_lucas_step_k_2k, and mpz_* utilities. However, the claim that it returns whether the number is a 'probable prime' is not fully supported: the return values are integers (0, 1, 2) with meanings tied to specific conditions, not an explicit probable-prime boolean, so this interpretation is partly inferential. Overall, most details are accurate with only minor overreach.",
                "The summary correctly identifies that the function implements a strong Lucas primality test using GMP-related functions and returns a probable prime indicator. This is supported by explicit evidence in the source code, such as calls to `gmp_lucas_mod`, `gmp_lucas_step_k_2k`, and Lucas sequence parameter calculations. However, it omits critical semantic details present in the code, including specific handling for squares, control flow for selecting D values, Jacobi symbol checks, and edge-case return logic. The lack of these details means the accurate content does not form a complete picture of the implementation.",
                "The summary correctly identifies that the function implements a strong Lucas primality test and operates on big integers via GMP-style functions (e.g., mpz_* functions), but it inaccurately claims the use of 'mini-gmp', which is not evidenced in the code. Since there is only one explicit inaccuracy out of a small set of details, the proportion of inaccurate information is below the kill switch threshold. However, the accurate parts are generic \u2014 identifying the algorithm type and purpose without deeper specifics from the code such as parameter handling, D search logic, or Lucas sequence steps \u2014 thus the detail value is moderate."
            ]
        }
    }
}
{
    "source_code": "\n\nint ec_GFp_simple_group_get_curve(const EC_GROUP *group, BIGNUM *p, BIGNUM *a, BIGNUM *b, BN_CTX *ctx)\n\t{\n\tint ret = 0;\n\tBN_CTX *new_ctx = NULL;\n\t\n\tif (p != NULL)\n\t\t{\n\t\tif (!BN_copy(p, &group->field)) return 0;\n\t\t}\n\n\tif (a != NULL || b != NULL)\n\t\t{\n\t\tif (group->meth->field_decode)\n\t\t\t{\n\t\t\tif (ctx == NULL)\n\t\t\t\t{\n\t\t\t\tctx = new_ctx = BN_CTX_new();\n\t\t\t\tif (ctx == NULL)\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\tif (a != NULL)\n\t\t\t\t{\n\t\t\t\tif (!group->meth->field_decode(group, a, &group->a, ctx)) goto err;\n\t\t\t\t}\n\t\t\tif (b != NULL)\n\t\t\t\t{\n\t\t\t\tif (!group->meth->field_decode(group, b, &group->b, ctx)) goto err;\n\t\t\t\t}\n\t\t\t}\n\t\telse\n\t\t\t{\n\t\t\tif (a != NULL)\n\t\t\t\t{\n\t\t\t\tif (!BN_copy(a, &group->a)) goto err;\n\t\t\t\t}\n\t\t\tif (b != NULL)\n\t\t\t\t{\n\t\t\t\tif (!BN_copy(b, &group->b)) goto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\n\tret = 1;\n\t\n err:\n\tif (new_ctx)\n\t\tBN_CTX_free(new_ctx);\n\treturn ret;\n\t}",
    "comment": "Retrieves the elliptic curve parameters (field, a, and b) from the specified EC_GROUP structure into provided BIGNUM variables.",
    "prorec_sum": "Retrieves the prime field curve parameters a, b from an EC group, using method callbacks or direct copies, optionally with a provided BN_CTX.",
    "filter_prorec_sum": "Retrieves the prime field curve parameters a and b from an EC_GROUP object, optionally using a BN_CTX for temporary big number operations.",
    "prorec_aug_sum": "Retrieves the elliptic curve group's parameters a, b, and p into provided BIGNUMs, using method callbacks or direct BN_copy with optional BN_CTX.",
    "filter_prorec_aug_sum": "Retrieves the elliptic curve group\u2019s field parameters a, b, and p into provided BIGNUMs using BN_copy, optionally via group-specific method with BN_CTX.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves the prime field curve parameters a, b from an EC group, using method callbacks or direct copies, optionally with a provided BN_CTX.",
            "score": [
                0.9666666666666667,
                0.6,
                0.6666666666666666
            ],
            "reason": [
                "The summary mentions retrieving prime field curve parameters a and b from an EC group, which is supported by the code where `BN_copy` or `field_decode` is used on `group->a` and `group->b`. It also correctly notes that method callbacks or direct copies are used, matching the conditional use of `group->meth->field_decode`. The mention of optionally using a provided BN_CTX is accurate as the code checks for `ctx` and allocates `new_ctx` if needed. However, the summary omits detail about retrieving 'p', which is present in the code, and it asserts 'prime field' without explicit confirmation in the snippet, making that part unverifiable. Overall, most details are accurate with only minor omissions/assumptions.",
                "The summary accurately states that the function retrieves the curve parameters 'a' and 'b' from an EC_GROUP structure, deciding between using method callbacks (via group->meth->field_decode) or direct BN_copy, and that it can optionally use a provided BN_CTX. However, it omits mention of retrieving the 'p' (field) parameter and the conditional BN_CTX allocation and cleanup logic, meaning it does not fully capture all core logic and edge cases from the source.",
                "The summary correctly states that the function retrieves curve parameters 'a' and 'b' from an EC group using either method callbacks or direct copies, and that it can use an optionally provided BN_CTX. However, it omits the retrieval of parameter 'p', which is clearly implemented in the code. This omission is one inaccurate detail among several accurate ones, resulting in less than 50% inaccuracy. The accurate parts are specific and describe domain-relevant logic such as method callbacks and BN_CTX usage, but are moderately detailed rather than deeply insightful."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves the prime field curve parameters a and b from an EC_GROUP object, optionally using a BN_CTX for temporary big number operations.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function retrieves curve parameters 'a' and 'b' from an EC_GROUP object and may use a BN_CTX for temporary big number operations, both of which are explicitly shown in the code through BN_copy and BN_CTX usage. However, it omits mentioning parameter 'p', which is also retrieved, and does not note the conditional use of group->meth->field_decode, which are explicit details in the source. Thus, while mostly accurate, it lacks completeness and misses some verified semantic elements.",
                "The summary correctly identifies that the function retrieves curve parameters a and b from an EC_GROUP and may use a BN_CTX for temporary big number operations. However, it omits key aspects of the code\u2019s logic, such as retrieval of the prime field parameter p, conditional use of BN_copy versus field_decode based on the group\u2019s method, creation of a new BN_CTX when none is provided, and error handling with cleanup. These missing details mean the coverage of core logic is incomplete.",
                "The summary correctly notes that the function retrieves curve parameters a and b from an EC_GROUP and may use a BN_CTX for temporary big number operations, which matches the presence of BN_copy, BN_CTX_new, and BN_CTX_free in the code. However, it omits the retrieval of parameter p and the conditional use of the field_decode method, making the description partially accurate but generic in detail."
            ]
        }
    }
}
{
    "source_code": "\nvoid FAST_FUNC bb_perror_msg(const char *s, ...)\n{\n\tva_list p;\n\n\tva_start(p, s);\n\t/* Guard against \"<error message>: Success\" */\n\tbb_verror_msg(s, p, errno ? strerror(errno) : NULL);\n\tva_end(p);\n}",
    "comment": "Logs an error message along with the string representation of the current errno value, using a variable argument list for additional context.",
    "prorec_sum": "Computes parameters from provided vectors and calls a secondary function with configuration data and an optional computed double result.",
    "filter_prorec_sum": "Computes transformation parameters from eight 128\u2011bit vectors and forwards them with control data to sub_5176F5 for further processing.",
    "prorec_aug_sum": "Constructs parameter arrays from provided arguments, conditionally processes vector data into a computed value, and forwards them to another function for final handling.",
    "filter_prorec_aug_sum": "Initializes vector and scalar parameters, optionally computes a derived value from them, and forwards all data to another processing function for execution.",
    "work_score": {
        "prorec": {
            "summary": "Computes parameters from provided vectors and calls a secondary function with configuration data and an optional computed double result.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims parameter computation from vectors, invocation of a secondary function with configuration data, and handling of a computed double result, none of which are present in the source code. The source code instead initializes a va_list, calls bb_verror_msg with a string, va_list, and an error string, and does not involve vectors, configuration data, or double computations. All details are hallucinated, resulting in no accurate matches.",
                "The summary describes computing parameters from vectors, passing configuration data, and an optional double result, none of which appear in the source code. The actual code processes variadic arguments, guards against a misleading 'Success' error message, and calls bb_verror_msg with an error string derived from errno. No accurate details remain after filtering, so the summary misses the core logic entirely.",
                "The summary claims vector-based parameter computation, passing configuration data, and handling an optional double result, none of which are present in the source code. The actual function initializes a va_list, forwards arguments along with an error string to bb_verror_msg, and cleans up. Since all described details in the summary are inaccurate, the proportion of inaccuracies is over 50%, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Computes transformation parameters from eight 128\u2011bit vectors and forwards them with control data to sub_5176F5 for further processing.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims processing of eight 128-bit vectors, computation of transformation parameters, and forwarding to a function named sub_5176F5, none of which match the source code. The actual code defines bb_perror_msg, which formats and outputs error messages using va_list, bb_verror_msg, and strerror. All details in the summary are hallucinated, resulting in 0% accurate details.",
                "The summary describes transformation parameters from eight 128\u2011bit vectors and forwarding to a function named sub_5176F5, but none of these elements exist in the provided source code. The source code instead defines bb_perror_msg, handling variadic arguments and error messages with bb_verror_msg. All details from the summary are hallucinations, so no accurate content remains after filtering.",
                "The summary claims the function computes transformation parameters from eight 128\u2011bit vectors and forwards them to another function, but the source code only shows bb_perror_msg, which handles variable arguments and error string formatting. None of the described operations (128\u2011bit vectors, transformation parameters, control data, sub_5176F5) appear in the code, making all details inaccurate. Since all details are hallucinated, the proportion of inaccuracies exceeds 50%, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "int mls_import_netlbl_cat(struct context *context,\n\t\t\t  struct netlbl_lsm_secattr *secattr)\n{\n\tint rc;\n\n\tif (!policydb.mls_enabled)\n\t\treturn 0;\n\n\trc = ebitmap_netlbl_import(&context->range.level[0].cat,\n\t\t\t\t   secattr->attr.mls.cat);\n\tif (rc != 0)\n\t\tgoto import_netlbl_cat_failure;\n\n\trc = ebitmap_cpy(&context->range.level[1].cat,\n\t\t\t &context->range.level[0].cat);\n\tif (rc != 0)\n\t\tgoto import_netlbl_cat_failure;\n\n\treturn 0;\n\nimport_netlbl_cat_failure:\n\tebitmap_destroy(&context->range.level[0].cat);\n\tebitmap_destroy(&context->range.level[1].cat);\n\treturn rc;\n}",
    "comment": "Imports and copies the MLS category attributes into the context structure if MLS is enabled, handling errors by destroying allocated resources.",
    "prorec_sum": "Checks global state and performs two attribute-related operations on objects at given offsets, returning success if either operation completes.",
    "filter_prorec_sum": "Checks a global flag and performs two related processing operations on structures from a1 and a2, returning success if either operation completes.",
    "prorec_aug_sum": "Checks a global flag and processes two related data structures with geometry parameters, invoking helper functions if matching or update conditions are met.",
    "filter_prorec_aug_sum": "Checks global initialization, performs two data matching operations, and updates both target structures if any match succeeds, returning the match status code.",
    "work_score": {
        "prorec": {
            "summary": "Checks global state and performs two attribute-related operations on objects at given offsets, returning success if either operation completes.",
            "score": [
                0.26666666666666666,
                0.4666666666666666,
                0.0
            ],
            "reason": [
                "The summary incorrectly states that the function returns success if either operation completes, while the source code explicitly returns success only if both operations succeed; failure in either leads to cleanup and return of the error code. It also generalizes 'attribute-related operations on objects at given offsets' without explicitly mentioning the actual functions used (ebitmap_netlbl_import, ebitmap_cpy) or the specific data structures involved. The only accurate detail is that it checks global state, making the majority of the claims inaccurate.",
                "The summary correctly notes checking a global state (`policydb.mls_enabled`) and performing two attribute-related operations (`ebitmap_netlbl_import` and `ebitmap_cpy`) on object fields. However, it inaccurately claims success if either operation completes, whereas the code returns success only if both operations succeed. Additionally, it omits detail about error handling, cleanup on failure, and the fact that the operations are sequential on two category levels. These omissions and inaccuracies mean the coverage is partial and slightly misleading.",
                "The summary claims success if either operation completes, but the source code requires both operations to succeed, making this a significant inaccuracy. It also misrepresents the nature of the operations as generic 'attribute-related' rather than the specific `ebitmap_netlbl_import` and `ebitmap_cpy` calls handling MLS category data. These inaccuracies exceed 50% of the summary\u2019s details, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Checks a global flag and performs two related processing operations on structures from a1 and a2, returning success if either operation completes.",
            "score": [
                0.26666666666666666,
                0.20000000000000004,
                0.0
            ],
            "reason": [
                "The summary claims the function processes structures from 'a1' and 'a2' and returns success if either operation completes, which is inaccurate. The source code instead uses 'context' and 'secattr' (not a1/a2), and requires both operations to succeed; otherwise, it performs cleanup and returns an error. The only accurate part is that it checks a global flag before processing. This results in less than half of the details being accurate.",
                "The summary inaccurately states that success is returned if either operation completes, while the source code actually returns success only if both operations succeed; any failure triggers cleanup and returns an error code. It also refers to 'structures from a1 and a2' which do not appear in the source, instead the function processes `context->range.level` and `secattr->attr.mls.cat`. The only accurate element is that it checks a global flag, meaning most critical logic is omitted or misrepresented.",
                "The summary claims success is returned if either operation completes, but in the source code success is only returned if both operations succeed; if either fails, it goes to the failure handler. It also describes using structures from 'a1' and 'a2', which are not present in the code. The only accurate element is checking a global flag before proceeding, making most of the details inaccurate and triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nvoid assert_pipe(struct drm_i915_private *dev_priv,\n\t\t enum pipe pipe, bool state)\n{\n\tint reg;\n\tu32 val;\n\tbool cur_state;\n\tenum transcoder cpu_transcoder = intel_pipe_to_cpu_transcoder(dev_priv,\n\t\t\t\t\t\t\t\t      pipe);\n\n\t/* if we need the pipe A quirk it must be always on */\n\tif (pipe == PIPE_A && dev_priv->quirks & QUIRK_PIPEA_FORCE)\n\t\tstate = true;\n\n\tif (!intel_using_power_well(dev_priv->dev) &&\n\t    cpu_transcoder != TRANSCODER_EDP) {\n\t\tcur_state = false;\n\t} else {\n\t\treg = PIPECONF(cpu_transcoder);\n\t\tval = I915_READ(reg);\n\t\tcur_state = !!(val & PIPECONF_ENABLE);\n\t}\n\n\tWARN(cur_state != state,\n\t     \"pipe %c assertion failure (expected %s, current %s)\\n\",\n\t     pipe_name(pipe), state_string(state), state_string(cur_state));\n}",
    "comment": "Asserts the state of a specified display pipe in the Intel graphics driver, ensuring it matches the expected enablement state.",
    "prorec_sum": "Checks an Intel GPU display pipe\u2019s expected on/off state against hardware status and logs an assertion failure if mismatched.",
    "filter_prorec_sum": "Checks the expected versus actual display pipe state in i915 and logs an assertion failure if they do not match.",
    "prorec_aug_sum": "Checks a GPU display pipe\u2019s expected versus actual state and logs an assertion failure with details when the states do not match.",
    "filter_prorec_aug_sum": "Checks a GPU display pipe\u2019s expected versus current state and logs an assertion failure with on/off status details for debugging.",
    "work_score": {
        "prorec": {
            "summary": "Checks an Intel GPU display pipe\u2019s expected on/off state against hardware status and logs an assertion failure if mismatched.",
            "score": [
                1.0,
                0.6333333333333333,
                0.7999999999999999
            ],
            "reason": [
                "The summary accurately describes the function\u2019s purpose: it determines the current on/off state of an Intel GPU display pipe by reading hardware registers, compares it to an expected state, and logs a warning if mismatched. All these details are directly supported by the source code, with no extraneous or unverified claims.",
                "The summary accurately reflects the core functionality: the function compares an expected Intel GPU display pipe state with the actual hardware state and logs a warning if they differ. This is explicitly shown in the code via reading PIPECONF, determining cur_state, and calling WARN with a mismatch condition. However, the summary omits notable implementation details such as handling the PIPE_A quirk, the power well check, and the special TRANSCODER_EDP case, which are important parts of the control flow.",
                "The summary accurately describes the core functionality: the function verifies an Intel GPU display pipe's expected on/off state against the actual hardware state and issues a warning if they differ. This is fully supported by the code, which reads hardware registers, applies a quirk override, and uses WARN to log mismatches. The detail is specific and domain-relevant, matching variable names and logic found in the source."
            ]
        },
        "filter_prorec": {
            "summary": "Checks the expected versus actual display pipe state in i915 and logs an assertion failure if they do not match.",
            "score": [
                1.0,
                0.6,
                0.6666666666666666
            ],
            "reason": [
                "The summary correctly describes that the function compares expected versus current display pipe state and logs an assertion failure if they differ. This is explicitly supported by the WARN call and state comparison logic in the code. No unverified or hallucinated details are present, and all elements in the summary are accurate based on the source.",
                "The summary accurately notes that the function checks the expected versus actual pipe state and logs an assertion failure when they differ, which is directly supported by the WARN call comparing cur_state and state. However, it omits specific details like handling PIPE_A quirks, conditions related to intel_using_power_well and TRANSCODER_EDP, and the register reading logic, meaning it covers only the core action without important supporting logic.",
                "The summary accurately captures the core logic: the function compares the expected display pipe state with the current state in the i915 driver and logs a warning if they differ. This is explicitly evident from the use of state comparisons and the WARN macro in the source. The detail is accurate but somewhat generic, lacking mention of specifics like the PIPE_A quirk handling, cpu_transcoder mapping, and register reads, which would provide deeper domain insight."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic int pcmcia_card_add(struct pcmcia_socket *s)\n{\n\tcistpl_longlink_mfc_t mfc;\n\tunsigned int no_funcs, i, no_chains;\n\tint ret = -EAGAIN;\n\n\tmutex_lock(&s->ops_mutex);\n\tif (!(s->resource_setup_done)) {\n\t\tdev_dbg(&s->dev,\n\t\t\t   \"no resources available, delaying card_add\\n\");\n\t\tmutex_unlock(&s->ops_mutex);\n\t\treturn -EAGAIN; /* try again, but later... */\n\t}\n\n\tif (pcmcia_validate_mem(s)) {\n\t\tdev_dbg(&s->dev, \"validating mem resources failed, \"\n\t\t       \"delaying card_add\\n\");\n\t\tmutex_unlock(&s->ops_mutex);\n\t\treturn -EAGAIN; /* try again, but later... */\n\t}\n\tmutex_unlock(&s->ops_mutex);\n\n\tret = pccard_validate_cis(s, &no_chains);\n\tif (ret || !no_chains) {\n\t\tdev_dbg(&s->dev, \"invalid CIS or invalid resources\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (!pccard_read_tuple(s, BIND_FN_ALL, CISTPL_LONGLINK_MFC, &mfc))\n\t\tno_funcs = mfc.nfn;\n\telse\n\t\tno_funcs = 1;\n\ts->functions = no_funcs;\n\n\tfor (i = 0; i < no_funcs; i++)\n\t\tpcmcia_device_add(s, i);\n\n\treturn ret;\n}",
    "comment": "Adds a PCMCIA card to the socket after validating resources and reading its function information from the card's CIS.",
    "prorec_sum": "Initializes and validates a device context, retrieves configuration data, and executes a series of operations based on returned device count.",
    "filter_prorec_sum": "Initializes and validates a device context, reads a configuration byte, and triggers processing routines for each configured subdevice if available.",
    "prorec_aug_sum": "Initializes device state, validates configuration, retrieves a byte count, and iteratively invokes a processing routine for each available entry.",
    "filter_prorec_aug_sum": "Executes a series of device-specific initialization and configuration steps, invoking subhandlers for each reported channel or unit before returning a status code.",
    "work_score": {
        "prorec": {
            "summary": "Initializes and validates a device context, retrieves configuration data, and executes a series of operations based on returned device count.",
            "score": [
                0.7666666666666666,
                0.5666666666666667,
                0.5333333333333333
            ],
            "reason": [
                "The summary captures some accurate high-level actions: the function does validate resources, retrieves configuration tuples, and loops over a device count to perform operations. However, it omits explicit mention of certain specific steps like `mutex_lock` usage, handling of `EAGAIN` and `ENODEV` return codes, and the fact that the data retrieved is from `pccard_read_tuple` into `mfc.nfn`. It also generalizes 'device context' and 'configuration data' without naming the explicit structs and functions shown in the source, making it partially accurate but missing several concrete details from the code.",
                "The summary captures the general idea of validation and executing operations based on a count, but it omits critical logic such as the specific error handling for missing resources, failed memory validation, and invalid CIS conditions. It also lacks mention of the locking/unlocking mechanism, determination of `no_funcs` via reading a tuple or defaulting to 1, and iterating over functions to add devices. These omissions mean the accurate portion does not form a complete picture of the code's behavior.",
                "The summary claims the function initializes and validates a device context, retrieves configuration data, and executes operations based on a returned device count. Validation steps are explicitly present via resource checks, pcmcia_validate_mem, and pccard_validate_cis calls, which is accurate. Retrieving configuration data and determining the number of functions through pccard_read_tuple and mfc.nfn is accurate. Executing operations based on device count matches the loop calling pcmcia_device_add. However, the term 'initializes a device context' is somewhat vague and not explicitly evidenced in the code, which performs resource checks and setup rather than a full initialization. Overall, most details are accurate and provide specific insight into logic flow."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes and validates a device context, reads a configuration byte, and triggers processing routines for each configured subdevice if available.",
            "score": [
                0.39999999999999997,
                0.4666666666666666,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies: the source code shows locking a mutex, validating resources and CIS, reading a multi-function tuple, and adding devices per function. There is no explicit evidence of 'initializing a device context' as stated, no reading of a single 'configuration byte' (it reads a tuple structure), and the term 'processing routines' is not directly supported\u2014the code calls pcmcia_device_add, which is more specific. Only the notion of iterating over subdevices corresponds loosely to iterating over functions, meaning most details are unverified assumptions.",
                "The summary omits key accurate details from the source code such as mutex locking/unlocking, specific error returns (-EAGAIN, -ENODEV), and validation steps like pcmcia_validate_mem and pccard_validate_cis. It also introduces inaccurate details such as 'reads a configuration byte', which is not present in the code. While it correctly conveys that processing routines are triggered for each subdevice, most of the important control flow and validation logic are missing, resulting in incomplete coverage.",
                "The summary contains multiple inaccuracies. While the code does validate resources and loops over functions to add devices, it does not initialize a generic 'device context', nor does it read a 'configuration byte'\u2014it reads a CIS tuple structure into a multi-function card struct. The 'triggers processing routines' phrasing vaguely maps to pcmcia_device_add calls, but lacks specificity about PCMCIA and CIS validation, and omits key details like mutex locking and error handling. Over half of the semantic details are inaccurate, so the kill switch applies."
            ]
        }
    }
}
{
    "source_code": "\nint cms_SignedData_final(CMS_ContentInfo *cms, BIO *chain)\n\t{\n\tSTACK_OF(CMS_SignerInfo) *sinfos;\n\tCMS_SignerInfo *si;\n\tint i;\n\tsinfos = CMS_get0_SignerInfos(cms);\n\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t{\n\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\tif (!cms_SignerInfo_content_sign(cms, si, chain))\n\t\t\treturn 0;\n\t\t}\n\tcms->d.signedData->encapContentInfo->partial = 0;\n\treturn 1;\n\t}",
    "comment": "Finalizes the signing process for all signer information in the CMS_ContentInfo structure by signing the content and marking it as complete.",
    "prorec_sum": "Finalizes CMS signed-data by computing message digests and signatures for each signer and updating associated signature or authenticated attributes.",
    "filter_prorec_sum": "Generates and attaches digital signatures or signed attributes for all CMS signer infos using provided digest contexts and keys.",
    "prorec_aug_sum": "Generates digital signatures or signed attributes for all CMS signer infos using provided digest context, handling both direct signature and attribute-based signing paths.",
    "filter_prorec_aug_sum": "Finalizes CMS SignedData by computing digests and signatures for each signer, adding signature attributes, and updating the CMS structure before returning success.",
    "work_score": {
        "prorec": {
            "summary": "Finalizes CMS signed-data by computing message digests and signatures for each signer and updating associated signature or authenticated attributes.",
            "score": [
                0.16666666666666666,
                0.5,
                0.0
            ],
            "reason": [
                "The summary claims that the function computes message digests, generates signatures, and updates signature or authenticated attributes. The source code only shows looping through signer infos, invoking cms_SignerInfo_content_sign, and setting the partial flag to 0. There is no explicit evidence of digest computation, signature generation, or attribute updates in the visible code. These details are unverified and therefore inaccurate, leading to a low proportion of accurate information.",
                "The summary claims that the function computes message digests, generates signatures, and updates signature or authenticated attributes for each signer. The source code only shows iteration over signers, calling `cms_SignerInfo_content_sign` and setting `partial` to 0. There is no explicit evidence in the code of computing digests or updating authenticated attributes, so these are hallucinations. The only accurate detail is that it processes each signer and finalizes the content, which covers part of the core logic but misses important specifics such as the exact mechanics of `cms_SignerInfo_content_sign` and error handling behavior beyond returning 0. This results in a partial picture of the function.",
                "The summary claims that the function computes message digests, generates signatures, and updates signature/authenticated attributes. The source code shows looping over signer infos and calling cms_SignerInfo_content_sign, then setting 'partial' to 0, but provides no explicit evidence of computing message digests or updating attributes. These claimed operations are inferred, not directly supported by the code. Since the majority of details are inaccurate, this triggers the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Generates and attaches digital signatures or signed attributes for all CMS signer infos using provided digest contexts and keys.",
            "score": [
                0.26666666666666666,
                0.5,
                0.0
            ],
            "reason": [
                "The summary claims the function generates and attaches digital signatures or signed attributes using digest contexts and keys, but the source code only iterates through CMS signer infos and calls a content signing function without any explicit evidence of digest contexts, keys, or attaching signed attributes. As these elements are not present in the code, most details are unverified and likely hallucinated, resulting in a low accuracy ratio.",
                "The summary claims that the function generates and attaches digital signatures or signed attributes using digest contexts and keys, but the source code only shows iteration over signer infos and invoking cms_SignerInfo_content_sign with cms, signer info, and a BIO chain. There is no explicit evidence of digest contexts, keys, or attaching signed attributes. After discarding these inaccuracies, the remaining accurate detail is that it processes all CMS signer infos by signing their content, which only partially covers the code's logic and omits setting partial to 0 at the end.",
                "The summary claims that the function generates and attaches digital signatures or signed attributes using provided digest contexts and keys, but the source code only loops through signer infos and calls cms_SignerInfo_content_sign, without explicit evidence of digest contexts or key handling. While it does process CMS signer infos, most of the described implementation details in the summary are unsupported, resulting in more than half of the details being inaccurate."
            ]
        }
    }
}
{
    "source_code": "static void tcp_set_skb_tso_segs(const struct sock *sk, struct sk_buff *skb,\n\t\t\t\t unsigned int mss_now)\n{\n\tif (skb->len <= mss_now || !sk_can_gso(sk) ||\n\t    skb->ip_summed == CHECKSUM_NONE) {\n\t\t/* Avoid the costly divide in the normal\n\t\t * non-TSO case.\n\t\t */\n\t\tskb_shinfo(skb)->gso_segs = 1;\n\t\tskb_shinfo(skb)->gso_size = 0;\n\t\tskb_shinfo(skb)->gso_type = 0;\n\t} else {\n\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss_now);\n\t\tskb_shinfo(skb)->gso_size = mss_now;\n\t\tskb_shinfo(skb)->gso_type = sk->sk_gso_type;\n\t}\n}",
    "comment": "Sets the TCP segmentation offload parameters for a socket buffer based on its length and the maximum segment size.",
    "prorec_sum": "Configures TCP output header fields based on packet size, connection state, and flags, logging anomalies once for diagnostic purposes.",
    "filter_prorec_sum": "Updates TCP header fields in the packet buffer based on segment size and connection state, with a one-time debug log for unexpected conditions.",
    "prorec_aug_sum": "Configures TCP output header fields based on connection state and segment sizing, with a one-time debug log trigger for unexpected conditions.",
    "filter_prorec_aug_sum": "Calculates and writes TCP option fields for a packet based on connection state, segment size, and flags, then returns the current option offset.",
    "work_score": {
        "prorec": {
            "summary": "Configures TCP output header fields based on packet size, connection state, and flags, logging anomalies once for diagnostic purposes.",
            "score": [
                0.19999999999999998,
                0.16666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims configuration of TCP output header fields and logging anomalies for diagnostics, but the source code shows only setting skb_shinfo fields (gso_segs, gso_size, gso_type) based on packet length, MSS, and GSO capability. There is no evidence of header field configuration beyond GSO settings, no explicit connection state checks, and no logging logic present. All described details are either inaccurate or not substantiated by the code.",
                "The summary claims configuration of TCP output header fields and anomaly logging, but the source code focuses solely on adjusting SKB GSO segmentation parameters based on packet size, GSO capability, and checksum state. There is no evidence of TCP header manipulation or logging logic. All details in the summary are unsupported, leaving no accurate content after filtering.",
                "The summary claims configuration of TCP output header fields and logging anomalies for diagnostics. The source code shows setting skb_shinfo fields based on packet length, MSS, and GSO capability, which partially aligns with 'based on packet size and connection state' through sk_can_gso and skb parameters. However, there is no evidence of logging anomalies or any diagnostic logging in the code. The 'output header fields' wording is misleading, since the function updates internal SKB metadata, not TCP headers. More than half of the details (logging, header fields) are unsupported, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Updates TCP header fields in the packet buffer based on segment size and connection state, with a one-time debug log for unexpected conditions.",
            "score": [
                0.09999999999999999,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims the function updates TCP header fields based on segment size and connection state, and includes a one-time debug log for unexpected conditions. While the code does adjust skb_shinfo fields related to segmentation size and type (somewhat aligning with the first part), there is no explicit evidence of updates to TCP header fields nor any debug logging in the source. References to connection state and debug logs are hallucinations. Only the general idea of adjusting packet segmentation parameters is accurate, meaning less than half of the details are supported.",
                "The summary claims updates to TCP header fields and a one-time debug log for unexpected conditions, but the source code shows updates to skb_shinfo fields related to TSO segmentation (gso_segs, gso_size, gso_type) with conditional logic and no evidence of TCP header modifications or any debug log. All details in the summary are inaccurate, leaving no valid content to map to the source code\u2019s actual logic.",
                "The summary claims that the function updates TCP header fields and includes a one-time debug log for unexpected conditions. The source code shows it updates gso_segs, gso_size, and gso_type in skb_shinfo based on MSS and connection capabilities, not TCP header fields directly, and there is no debug logging present. Both key details in the summary are inaccurate, exceeding the 50% threshold."
            ]
        }
    }
}
{
    "source_code": "\nSEXP attribute_hidden do_dynunload(SEXP call, SEXP op, SEXP args, SEXP env)\n{\n    char buf[2 * PATH_MAX];\n\n    checkArity(op,args);\n    if (!isString(CAR(args)) || LENGTH(CAR(args)) != 1)\n\terror(_(\"character argument expected\"));\n    GetFullDLLPath(call, buf, translateChar(STRING_ELT(CAR(args), 0)));\n    if(!DeleteDLL(buf))\n\terror(_(\"shared object '%s\\' was not loaded\"), buf);\n    return R_NilValue;\n}",
    "comment": "Unloads a shared object from memory by verifying the argument and deleting its associated DLL using the full path derived from the input.",
    "prorec_sum": "Validates a single string argument representing a shared object name, then reports an error if the specified object is not loaded.",
    "filter_prorec_sum": "Validates a single string argument and reports an error if the referenced shared object was not successfully loaded.",
    "prorec_aug_sum": "Validates a single string argument and reports an error if the referenced shared object is not loaded.",
    "filter_prorec_aug_sum": "Validates a single string argument and reports an error if the referenced shared object is not currently loaded in the R environment.",
    "work_score": {
        "prorec": {
            "summary": "Validates a single string argument representing a shared object name, then reports an error if the specified object is not loaded.",
            "score": [
                1.0,
                0.6333333333333333,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly states that the function validates a single string argument and reports an error if the specified shared object is not loaded, which matches the explicit checks (`isString`, `LENGTH == 1`) and the `error` call conditioned on `DeleteDLL(buf)` returning false. No extraneous or unverified details are present, making all semantic elements supported by the source code.",
                "The summary includes accurate details about validating a single string argument and reporting an error if the specified shared object is not loaded. These are explicitly supported by the code via the string type and length check, and the conditional error on DeleteDLL failure. However, it omits other important logic such as calling checkArity, obtaining the full DLL path using GetFullDLLPath, and returning R_NilValue, so the coverage of the code's full behavior is incomplete.",
                "The summary accurately describes that the function validates a single string argument and reports an error if the shared object is not loaded. These details are explicitly supported by the code: the `isString` and `LENGTH` checks enforce the single string argument requirement, and `DeleteDLL(buf)` followed by `error()` handles the case where the object is not loaded. Both semantic details are accurate and domain-relevant, though relatively straightforward rather than deeply insightful."
            ]
        },
        "filter_prorec": {
            "summary": "Validates a single string argument and reports an error if the referenced shared object was not successfully loaded.",
            "score": [
                0.4000000000000001,
                0.5333333333333333,
                0.19999999999999998
            ],
            "reason": [
                "The summary correctly notes validation of a single string argument, which is explicitly shown in the source via `isString` and `LENGTH` checks. However, it inaccurately states that an error is reported if the shared object was not successfully loaded, while the code actually reports an error if the object was not deleted (`DeleteDLL` returned false). This misinterpretation means only half of the details are accurate.",
                "The summary accurately notes that the function validates a single string argument and triggers an error if a shared object condition fails. However, it misstates the error condition: the code reports an error when the shared object was not loaded (i.e., not found for unloading), not when it was not successfully loaded in the first place. Additionally, it omits important logic such as path resolution via GetFullDLLPath and the specific handling via DeleteDLL. Thus, while it covers the main action, key details and nuances are missing.",
                "The summary contains two main details: validation of a single string argument and reporting an error if the shared object was not successfully loaded. The first detail is accurate, as the code checks that CAR(args) is a string of length 1. The second detail is inaccurate, since the code reports an error if the shared object was not deleted (indicating it was not loaded at the time of deletion), not if it failed to load. With 50% of the details inaccurate, the kill switch is triggered and scoring stops."
            ]
        }
    }
}
{
    "source_code": "int audit_alloc(struct task_struct *tsk)\n{\n\tstruct audit_context *context;\n\tenum audit_state     state;\n\tchar *key = NULL;\n\n\tif (likely(!audit_ever_enabled))\n\t\treturn 0; /* Return if not auditing. */\n\n\tstate = audit_filter_task(tsk, &key);\n\tif (state == AUDIT_DISABLED)\n\t\treturn 0;\n\n\tif (!(context = audit_alloc_context(state))) {\n\t\tkfree(key);\n\t\taudit_log_lost(\"out of memory in audit_alloc\");\n\t\treturn -ENOMEM;\n\t}\n\tcontext->filterkey = key;\n\n\ttsk->audit_context  = context;\n\tset_tsk_thread_flag(tsk, TIF_SYSCALL_AUDIT);\n\treturn 0;\n}",
    "comment": "Allocates an audit context for a given task if auditing is enabled and filters the task based on its audit state.",
    "prorec_sum": "Allocates and initializes an audit data structure for the given object, linking it into global lists and marking the object\u2019s state flags.",
    "filter_prorec_sum": "Allocates and initializes an audit-related structure for a given object, populating fields and linking it into the object's state if resources permit.",
    "prorec_aug_sum": "Allocates and initializes an audit data structure for the given task, linking it to a list entry and setting status fields.",
    "filter_prorec_aug_sum": "Allocates and initializes an audit data structure for the given task context, linking it to internal lists and setting status fields based on lookup results.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes an audit data structure for the given object, linking it into global lists and marking the object\u2019s state flags.",
            "score": [
                0.3333333333333333,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims that the function links the audit data structure into global lists and marks the object's state flags. The source code shows allocation of an audit_context, setting it to the task\u2019s audit_context, and setting a thread flag, but there is no evidence of linking into any global lists. The claim about marking the object\u2019s state flags is partially accurate in the sense of setting TIF_SYSCALL_AUDIT, but the rest is unverifiable. Overall, only a small portion matches the source code, with most details being unsupported.",
                "The summary claims that the function links the audit structure into global lists, but the source code does not show any list operations, making this detail inaccurate. It also omits key logic such as the audit enable check using 'audit_ever_enabled', audit state filtering, memory allocation failure handling, freeing 'key' on failure, setting 'filterkey', and enabling syscall audit via thread flag. The only accurate element is that an audit-related structure is allocated and associated with the task object, which is insufficient to cover the main logic.",
                "The summary claims that the function links the allocated audit data structure into global lists, which is not present in the source code, and mentions marking the object\u2019s state flags without accurate reflection of the actual thread flag set (TIF_SYSCALL_AUDIT). While it correctly notes allocation and initialization of an audit-related structure, the majority of details are inaccurate, exceeding the 50% threshold and triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes an audit-related structure for a given object, populating fields and linking it into the object's state if resources permit.",
            "score": [
                0.8333333333333334,
                0.6,
                0.5666666666666668
            ],
            "reason": [
                "The summary correctly notes that the function allocates an audit-related structure and links it to the task's state, which is supported by the use of `audit_alloc_context` and `tsk->audit_context`. However, it omits mention of key details present in the source, such as conditional checks for `audit_ever_enabled` and `AUDIT_DISABLED`, freeing `key` on failure, logging an error, and setting the `TIF_SYSCALL_AUDIT` flag. The description of 'initializes' and 'populating fields' is partially accurate but lacks specificity tied to explicit code evidence, resulting in only some details being verified.",
                "The summary accurately describes the main action: allocating an audit-related structure (audit_context) for a given task_struct, populating its field (filterkey), and linking it into the task's state (tsk->audit_context) if allocation succeeds. It omits specific details from the code such as early exits when auditing is disabled, the use of audit_filter_task, explicit error handling and logging when allocation fails, and setting of the TIF_SYSCALL_AUDIT flag. While the described core behavior matches the source, the explanation lacks several important logic paths and conditions present in the code.",
                "The summary correctly captures the core function: allocating and initializing an audit-related structure (`audit_context`), filling a field (`filterkey`) and attaching it to the task's state (`tsk->audit_context`) when resources are available. It omits specifics such as conditional checks for `audit_ever_enabled`, use of `audit_filter_task`, error handling with `audit_log_lost`, and setting the syscall audit flag, but these omissions do not render the included details inaccurate. The accurate details are moderately specific to the domain but remain somewhat generic without key technical depth."
            ]
        }
    }
}
{
    "source_code": "int Xorriso_register_matched_adr(struct XorrisO *xorriso,\n                                char *adr, int count_limit,\n                                int *filec, char **filev, off_t *mem, int flag)\n{\n int l;\n\n if(flag&1) {\n   (*filec)++;\n   l= strlen(adr)+1;\n   (*mem)+= sizeof(char *)+l;\n   if(l % sizeof(char *))\n     (*mem)+= sizeof(char *)-(l % sizeof(char *));\n } else {\n   if(*filec >= count_limit) {\n     sprintf(xorriso->info_text,\n         \"Number of matching files changed unexpectedly (> %d)\",\n         count_limit);\n     Xorriso_msgs_submit(xorriso, 0, xorriso->info_text, 0,\n                         (flag&2 ? \"FATAL\" : \"WARNING\"), 0);\n     return(flag&2 ? -1 : 0);\n   }\n   filev[*filec]= strdup(adr);\n   if(filev[*filec]==NULL) {\n     Xorriso_no_pattern_memory(xorriso, (off_t) (strlen(adr)+1), 0);\n     return(-1);\n   }\n   (*filec)++;\n }\n return(1);\n}",
    "comment": "Registers a matched address by updating file count, allocating memory for the address, and handling errors based on a specified flag.",
    "prorec_sum": "Handles adding a file path to a list, updating counters and memory alignment, and logging warnings or fatal errors if count limits are exceeded.",
    "filter_prorec_sum": "Handles adding a matching file path to a list, updating counters and memory alignment, and logging warnings or fatal errors if limits are exceeded.",
    "prorec_aug_sum": "Manages a list of matching file names, updating counters, tracking memory usage, and issuing warnings or fatal errors when count constraints are exceeded.",
    "filter_prorec_aug_sum": "Handles adding a matching file name to a list, updating counters and memory alignment, and logging warnings or fatal errors if limits are exceeded.",
    "work_score": {
        "prorec": {
            "summary": "Handles adding a file path to a list, updating counters and memory alignment, and logging warnings or fatal errors if count limits are exceeded.",
            "score": [
                1.0,
                0.7999999999999999,
                0.9
            ],
            "reason": [
                "The summary correctly reflects that the function adds a file path to a list (`filev[*filec] = strdup(adr)`), updates a counter (`(*filec)++`), adjusts memory usage with alignment logic (`if (l % sizeof(char *))...`), and issues warnings or fatal errors when count limits are exceeded (`Xorriso_msgs_submit` with 'WARNING' or 'FATAL'). All these details have explicit evidence in the source code, with no unverified assumptions or hallucinations present.",
                "The summary accurately captures the function's core behavior: it adds a file path to a list (via strdup into filev), increments counters, adjusts memory usage with pointer-alignment logic, and issues warnings or fatal errors if the count limit is exceeded. All these elements are explicitly present in the source code, and the description reflects the actual control flow. No key elements of the main logic are missing, so the coverage is complete.",
                "The summary correctly identifies the core functionality: adding a file path to a list, incrementing the file count, adjusting memory alignment, and logging warnings or fatal errors when count limits are exceeded. These elements are explicitly present in the source code through operations on `filec`, `mem`, `filev`, alignment calculations, and calls to `Xorriso_msgs_submit`. All details in the summary are accurate, and they describe meaningful, domain-specific logic rather than being generic."
            ]
        },
        "filter_prorec": {
            "summary": "Handles adding a matching file path to a list, updating counters and memory alignment, and logging warnings or fatal errors if limits are exceeded.",
            "score": [
                1.0,
                0.8666666666666667,
                0.9
            ],
            "reason": [
                "The summary correctly identifies that the function adds a matching file path to a list (via strdup into filev), updates counters (*filec), adjusts memory alignment (*mem adjustments when flag&1), and logs warnings or fatal errors if a count limit is exceeded (using Xorriso_msgs_submit with 'WARNING' or 'FATAL'). All these details are explicitly supported by the source code, with no evident hallucinations.",
                "The summary accurately states that the function adds matching file paths to a list, updates counters, adjusts memory alignment, and logs warnings or fatal errors when limits are exceeded. These points are explicitly supported by the code: `filev[*filec] = strdup(adr)` adds the path, `(*filec)++` updates counters, memory alignment is handled via size calculations and padding with `sizeof(char *)`, and logging is done through `Xorriso_msgs_submit` when `*filec >= count_limit`. The summary captures all key logic without introducing unsupported details, providing a complete picture of the function\u2019s purpose.",
                "The summary accurately states that the function adds a matching file path to a list, updates counters, handles memory alignment, and logs warnings or fatal errors when limits are exceeded. All these details are explicitly supported by the source code: the code increments file count, adjusts memory size with alignment considerations, uses strdup to add filenames, and calls logging functions depending on limit checks. The details are specific to the domain and reflect the actual code behavior."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\ngmbus_xfer_read(struct drm_i915_private *dev_priv, struct i2c_msg *msg,\n\t\tu32 gmbus1_index)\n{\n\tint reg_offset = dev_priv->gpio_mmio_base;\n\tu16 len = msg->len;\n\tu8 *buf = msg->buf;\n\n\tI915_WRITE(GMBUS1 + reg_offset,\n\t\t   gmbus1_index |\n\t\t   GMBUS_CYCLE_WAIT |\n\t\t   (len << GMBUS_BYTE_COUNT_SHIFT) |\n\t\t   (msg->addr << GMBUS_SLAVE_ADDR_SHIFT) |\n\t\t   GMBUS_SLAVE_READ | GMBUS_SW_RDY);\n\twhile (len) {\n\t\tint ret;\n\t\tu32 val, loop = 0;\n\n\t\tret = gmbus_wait_hw_status(dev_priv, GMBUS_HW_RDY,\n\t\t\t\t\t   GMBUS_HW_RDY_EN);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tval = I915_READ(GMBUS3 + reg_offset);\n\t\tdo {\n\t\t\t*buf++ = val & 0xff;\n\t\t\tval >>= 8;\n\t\t} while (--len && ++loop < 4);\n\t}\n\n\treturn 0;\n}",
    "comment": "Reads data from a GMBUS device into a buffer, handling timing and status checks during the transfer process.",
    "prorec_sum": "Processes data from a buffer in 256-byte chunks, issuing commands and transferring bytes via helper routines until all requested bytes are handled.",
    "filter_prorec_sum": "Transfers chunks of up to 256 bytes from a buffer into hardware registers, invoking helper routines for each block until all data is written.",
    "prorec_aug_sum": "Transfers data from the provided buffer to hardware registers in fixed-size chunks, invoking helper routines and returning on error.",
    "filter_prorec_aug_sum": "Processes a data buffer in 256-byte chunks, writes values to device registers, and transfers bytes with repeated calls to lower-level I/O functions.",
    "work_score": {
        "prorec": {
            "summary": "Processes data from a buffer in 256-byte chunks, issuing commands and transferring bytes via helper routines until all requested bytes are handled.",
            "score": [
                0.2333333333333333,
                0.26666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims processing in 256-byte chunks, but the source code shows data is read in groups of up to 4 bytes per loop iteration based on shifting a 32-bit register value, not 256-byte blocks. While it is true that bytes are transferred until all requested bytes are handled, there is no explicit evidence of 256-byte chunking or issuing commands via unspecified helper routines beyond gmbus_wait_hw_status. This means less than half of the details are accurate.",
                "The summary claims processing in 256-byte chunks, which is not supported by the source code. The code processes bytes in loops of up to 4 bytes at a time by reading from a register and shifting, with no indication of a 256-byte chunk size. After discarding this inaccurate detail, no other accurate description remains, meaning the core logic is missed entirely.",
                "The summary claims the function processes data in 256-byte chunks and uses helper routines to issue commands until all bytes are handled. The source code shows data being processed in up-to-4-byte loops inside a while loop based on message length, with no evidence of 256-byte chunking. It does call a helper function (gmbus_wait_hw_status) and uses hardware read/write macros, but the chunk size claim is inaccurate. Since more than half of the details (e.g., chunk size) are incorrect, this triggers the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Transfers chunks of up to 256 bytes from a buffer into hardware registers, invoking helper routines for each block until all data is written.",
            "score": [
                0.13333333333333333,
                0.0,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies. The source code clearly shows a read operation (`GMBUS_SLAVE_READ`) that transfers data from hardware registers into a buffer, not writing from a buffer to hardware. The summary also states a 256-byte chunk limit, but the code handles data in blocks of up to 4 bytes per loop iteration, not 256. The claim about invoking helper routines for each block is partially accurate as it calls `gmbus_wait_hw_status`, but the rest of the description misrepresents critical details of direction, size, and transfer logic. Most semantic details are inaccurate, indicating a low accuracy ratio.",
                "The summary describes writing chunks of up to 256 bytes from a buffer into hardware registers, but the source code actually performs a read operation from hardware registers into a buffer and does not reference a 256-byte limit. It uses gmbus_wait_hw_status, reads GMBUS3 contents, and processes up to 4 bytes per loop, which is different from the described write behavior. No details in the summary align accurately with the actual code logic, so all elements are discarded as inaccurate.",
                "The summary claims 256-byte chunks, buffer-to-hardware register writes, and a write process, but the source code actually performs a read operation from hardware into a buffer, processing up to 4 bytes per loop, not 256. It also does not show 'invoking helper routines for each block' beyond a single wait helper. These are major inaccuracies in core operation, chunk size, and direction of data transfer, exceeding the allowed inaccuracy proportion."
            ]
        }
    }
}
{
    "source_code": "static void purge_old_ps_buffers(struct ieee80211_local *local)\n{\n\tint total = 0, purged = 0;\n\tstruct sk_buff *skb;\n\tstruct ieee80211_sub_if_data *sdata;\n\tstruct sta_info *sta;\n\n\tlist_for_each_entry_rcu(sdata, &local->interfaces, list) {\n\t\tstruct ps_data *ps;\n\n\t\tif (sdata->vif.type == NL80211_IFTYPE_AP)\n\t\t\tps = &sdata->u.ap.ps;\n\t\telse if (ieee80211_vif_is_mesh(&sdata->vif))\n\t\t\tps = &sdata->u.mesh.ps;\n\t\telse\n\t\t\tcontinue;\n\n\t\tskb = skb_dequeue(&ps->bc_buf);\n\t\tif (skb) {\n\t\t\tpurged++;\n\t\t\tdev_kfree_skb(skb);\n\t\t}\n\t\ttotal += skb_queue_len(&ps->bc_buf);\n\t}\n\n\t/*\n\t * Drop one frame from each station from the lowest-priority\n\t * AC that has frames at all.\n\t */\n\tlist_for_each_entry_rcu(sta, &local->sta_list, list) {\n\t\tint ac;\n\n\t\tfor (ac = IEEE80211_AC_BK; ac >= IEEE80211_AC_VO; ac--) {\n\t\t\tskb = skb_dequeue(&sta->ps_tx_buf[ac]);\n\t\t\ttotal += skb_queue_len(&sta->ps_tx_buf[ac]);\n\t\t\tif (skb) {\n\t\t\t\tpurged++;\n\t\t\t\tieee80211_free_txskb(&local->hw, skb);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tlocal->total_ps_buffered = total;\n\tps_dbg_hw(&local->hw, \"PS buffers full - purged %d frames\\n\", purged);\n}",
    "comment": "Purges old Power Save buffers from access points and stations, freeing memory and updating the total buffered frame count.",
    "prorec_sum": "Iterates two linked lists, processes specific entries via a helper function, accumulates a count, and stores the total at a fixed offset.",
    "filter_prorec_sum": "Iterates two linked lists, processes selected entries via sub_FFFFFFFF817319E0, accumulates a count, and stores the total at offset 4032 in the main structure.",
    "prorec_aug_sum": "Iterates two linked lists, invokes a processing routine on matching entries, accumulates a count from their fields, and stores the total in the parent structure.",
    "filter_prorec_aug_sum": "Iterates two linked lists to process eligible entries via a helper function, accumulates a total from each, and stores it in the parent structure.",
    "work_score": {
        "prorec": {
            "summary": "Iterates two linked lists, processes specific entries via a helper function, accumulates a count, and stores the total at a fixed offset.",
            "score": [
                0.4666666666666666,
                0.5333333333333333,
                0.16666666666666666
            ],
            "reason": [
                "The summary correctly notes that the code iterates over two linked lists and accumulates a count stored into a struct field, which is supported by list_for_each_entry_rcu loops and the assignment to local->total_ps_buffered. However, it inaccurately states that processing is done via a helper function and mentions a 'fixed offset', both of which have no explicit evidence in the source code. The code performs processing inline rather than via a helper, and there is no concept of a fixed offset in the assignment, making these hallucinations. The ratio of accurate details is about half, leading to a mixed accuracy assessment.",
                "The summary correctly identifies that the function iterates over two linked lists, processes specific entries, and accumulates a total count, which is then stored in a struct member. However, it omits crucial details like the conditions for selecting entries, the purging and freeing of buffers, handling of different interface types, and the logic for selecting frames to drop per station. While no evident hallucinations are present, the description lacks key parts of the control flow and edge-case handling, giving only a partial picture of the code's logic.",
                "The summary omits key domain-specific details from the source code, such as handling of AP and mesh interfaces, use of ps_data structures, dequeueing from bc_buf and ps_tx_buf arrays per AC, freeing SKBs with specific functions, and logging via ps_dbg_hw. While it correctly notes iteration over two lists and accumulation of a total stored in local->total_ps_buffered, much is generalized ('helper function', 'fixed offset') rather than accurately reflecting the logic. The generalized descriptions reduce the specificity and insight value of the accurate details."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates two linked lists, processes selected entries via sub_FFFFFFFF817319E0, accumulates a count, and stores the total at offset 4032 in the main structure.",
            "score": [
                0.3,
                0.43333333333333335,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies. It claims the function processes entries via 'sub_FFFFFFFF817319E0', which is not present in the source code. The summary also states that the total is stored at offset 4032 in the main structure, which is not evidenced; the code explicitly assigns to 'local->total_ps_buffered'. While it correctly notes iteration over two linked lists and accumulating a count, the presence of these hallucinated details lowers accuracy significantly.",
                "The summary claims use of a function named sub_FFFFFFFF817319E0 and a specific offset 4032 in the main structure, neither of which appear in the source code, making these details inaccurate. The accurate part is that two linked lists are iterated and a count is accumulated and stored, which maps to iterating local->interfaces and local->sta_list, accumulating 'total' and storing it in local->total_ps_buffered. However, the summary omits most of the logic, including conditional selection of ps_data, purging buffers, AC loop, and freeing memory, meaning significant logic is missing.",
                "The summary claims use of a function named sub_FFFFFFFF817319E0 and storing the total at offset 4032, but neither appears in the source code, making these details inaccurate. It also omits accurate, domain-specific elements such as the real functions used (skb_dequeue, skb_queue_len, dev_kfree_skb, ieee80211_free_txskb) and the actual fields referenced (local->total_ps_buffered). With more than half of the stated details being hallucinated, the content is misleading."
            ]
        }
    }
}
{
    "source_code": "\nstatic void mroute_netlink_event(struct mr_table *mrt, struct mfc_cache *mfc,\n\t\t\t\t int cmd)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct sk_buff *skb;\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(mroute_msgsize(mfc->mfc_parent >= MAXVIFS, mrt->maxvif),\n\t\t\tGFP_ATOMIC);\n\tif (skb == NULL)\n\t\tgoto errout;\n\n\terr = ipmr_fill_mroute(mrt, skb, 0, 0, mfc, cmd);\n\tif (err < 0)\n\t\tgoto errout;\n\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV4_MROUTE, NULL, GFP_ATOMIC);\n\treturn;\n\nerrout:\n\tkfree_skb(skb);\n\tif (err < 0)\n\t\trtnl_set_sk_err(net, RTNLGRP_IPV4_MROUTE, err);\n}",
    "comment": "Notifies the kernel about multicast route changes by creating and sending a netlink message based on the provided mfc_cache and command.",
    "prorec_sum": "Allocates and initializes a route-related structure with given parameters, invoking setup or cleanup routines and reporting success or error to the network context.",
    "filter_prorec_sum": "Allocates a data structure based on device parameters, initializes it, handles errors, and dispatches it for further processing via specific callbacks.",
    "prorec_aug_sum": "Allocates a structure with provided parameters, initializes it for the given device context, and handles errors by cleanup and reporting a status code.",
    "filter_prorec_aug_sum": "Allocates and initializes a data structure with provided parameters, performs an operation on it, and handles cleanup and error reporting if the operation fails.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a route-related structure with given parameters, invoking setup or cleanup routines and reporting success or error to the network context.",
            "score": [
                0.39999999999999997,
                0.3333333333333333,
                0.16666666666666666
            ],
            "reason": [
                "The summary is mostly inaccurate. While it mentions reporting success or error to the network context\u2014which loosely aligns with rtnl_notify and rtnl_set_sk_err\u2014the rest is incorrect. The code does not allocate or initialize a generic route-related structure; instead, it creates a netlink message (skb) using nlmsg_new, fills it with ipmr_fill_mroute, and frees it on error. There is no generic setup/cleanup routine, and the parameters are not generic route parameters. As a result, the ratio of accurate details is well below 50%.",
                "The summary claims allocation and initialization of a route-related structure, setup/cleanup routines, and reporting success or error to the network context. While the code allocates an sk_buff (`nlmsg_new`) and performs cleanup (`kfree_skb`) on error, there is no explicit initialization of a route-related structure or invocation of setup routines as described. Error reporting to the network context via `rtnl_set_sk_err` is accurate, but other key elements in the summary are unsupported by the source code. The remaining accurate details capture only part of the logic, missing specifics about function calls like `ipmr_fill_mroute` and `rtnl_notify` that handle message preparation and notification.",
                "The summary claims allocation and initialization of a route-related structure with given parameters and reporting success or error, but the source code shows allocation of an sk_buff via nlmsg_new and filling it with ipmr_fill_mroute, followed by notification or error handling. There is no explicit initialization of a route-related structure beyond the sk_buff, nor setup routines in the form described. Most semantic details are inaccurate, exceeding the 50% threshold."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates a data structure based on device parameters, initializes it, handles errors, and dispatches it for further processing via specific callbacks.",
            "score": [
                0.3,
                0.5333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims allocation based on device parameters, initialization, and dispatch via specific callbacks, but the source code shows allocation via nlmsg_new with parameters tied to mfc and mrt fields, error handling, and routing notifications via rtnl_notify. There is no explicit evidence of 'device parameters' or a general 'initialization' step in the code, nor generic callbacks\u2014it uses specific netlink and routing API calls. This means most semantic details in the summary are unverifiable or inaccurate, with only the allocation and error handling aspects partially supported.",
                "The summary is partly accurate \u2014 the function allocates a socket buffer using nlmsg_new based on parameters from mfc and mrt, and it has error handling with goto labels. However, it inaccurately generalizes these as 'device parameters' and 'initializes it' without evidence of initialization beyond allocation and population via ipmr_fill_mroute. It also mischaracterizes rtnl_notify as dispatching via 'specific callbacks' without such callbacks being shown. While allocation, error handling, and a final dispatch step are present, the summary omits important specifics (like message size calculation logic, use of err variable) and includes vague or inaccurate descriptions.",
                "The summary claims allocation based on device parameters, initialization, and dispatch via specific callbacks. In the source code, allocation occurs via `nlmsg_new` with parameters from `mfc` and `mrt`, and there is error handling. However, there is no clear evidence of 'device parameters' being used, nor generic 'initialization' of a data structure\u2014the code primarily allocates an skb and fills it with route data. Furthermore, while there are function calls (`ipmr_fill_mroute`, `rtnl_notify`) they aren't generic callbacks but explicit functions. The majority of the details (device parameters, initialization steps, generic callbacks) are inaccurate, exceeding 50% inaccuracies."
            ]
        }
    }
}
{
    "source_code": "\nvoid inet_twdr_twkill_work(struct work_struct *work)\n{\n\tstruct inet_timewait_death_row *twdr =\n\t\tcontainer_of(work, struct inet_timewait_death_row, twkill_work);\n\tint i;\n\n\tBUILD_BUG_ON((INET_TWDR_TWKILL_SLOTS - 1) >\n\t\t\t(sizeof(twdr->thread_slots) * 8));\n\n\twhile (twdr->thread_slots) {\n\t\tspin_lock_bh(&twdr->death_lock);\n\t\tfor (i = 0; i < INET_TWDR_TWKILL_SLOTS; i++) {\n\t\t\tif (!(twdr->thread_slots & (1 << i)))\n\t\t\t\tcontinue;\n\n\t\t\twhile (inet_twdr_do_twkill_work(twdr, i) != 0) {\n\t\t\t\tif (need_resched()) {\n\t\t\t\t\tspin_unlock_bh(&twdr->death_lock);\n\t\t\t\t\tschedule();\n\t\t\t\t\tspin_lock_bh(&twdr->death_lock);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ttwdr->thread_slots &= ~(1 << i);\n\t\t}\n\t\tspin_unlock_bh(&twdr->death_lock);\n\t}\n}",
    "comment": "Processes and removes active threads from the timewait death row while managing concurrency using spin locks and checking for rescheduling needs.",
    "prorec_sum": "Processes up to eight flagged channels, repeatedly invoking handler functions until each is cleared, with special handling when a status bit in thread-local storage is set.",
    "filter_prorec_sum": "Processes and clears active flags in an 8-bit mask, invoking sub_FFFFFFFF8162FA30 and related handlers until all pending bit operations are completed.",
    "prorec_aug_sum": "Processes active flags from a bitmask, invoking helper routines for each set bit until all bits are cleared or processing conditions are met.",
    "filter_prorec_aug_sum": "Iterates over active channel bits, invoking processing functions for each until completion, with handling for specific status flags during repeated execution attempts.",
    "work_score": {
        "prorec": {
            "summary": "Processes up to eight flagged channels, repeatedly invoking handler functions until each is cleared, with special handling when a status bit in thread-local storage is set.",
            "score": [
                0.3333333333333333,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies. While it is correct that the function iterates over slots and repeatedly invokes a handler function until completion, there is no explicit evidence in the source code about 'eight' channels\u2014the actual number is determined by INET_TWDR_TWKILL_SLOTS\u2014and no mention of 'status bit in thread-local storage'; instead, it checks bits in twdr->thread_slots. The 'special handling' described does not match the actual logic, which is about rescheduling when needed. With more than half of the claims unsupported or incorrect, accuracy is low.",
                "The summary claims processing of 'up to eight flagged channels,' but the source code does not define the number of slots as eight, only as INET_TWDR_TWKILL_SLOTS. The mention of 'status bit in thread-local storage' is inaccurate\u2014thread_slots is a field in the struct, not thread-local storage. The only partially accurate aspect is that the code processes flagged slots and repeatedly invokes a handler (inet_twdr_do_twkill_work) until cleared, but significant details such as the locking/unlocking mechanism and rescheduling logic are missing from the summary.",
                "The summary claims the function processes up to eight flagged channels, but the source code does not explicitly limit channels to eight; instead it iterates over INET_TWDR_TWKILL_SLOTS, whose value is not shown. It also references status bits in thread-local storage, which is inaccurate since the code manipulates bits in twdr->thread_slots, a struct member, not thread-local storage. The claim about repeatedly invoking handler functions until each is cleared is accurate based on the repeated calls to inet_twdr_do_twkill_work within a loop until completion, and the clearing of bits afterward. More than half of the details are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Processes and clears active flags in an 8-bit mask, invoking sub_FFFFFFFF8162FA30 and related handlers until all pending bit operations are completed.",
            "score": [
                0.3666666666666667,
                0.5,
                0.0
            ],
            "reason": [
                "The summary claims use of an 8\u2011bit mask, but the code never specifies an 8\u2011bit type; it uses twdr->thread_slots and a compile\u2011time check against its bit capacity, which could vary by type. The assertion that sub_FFFFFFFF8162FA30 is invoked is inaccurate, as the function call in the code is to inet_twdr_do_twkill_work, and no related handlers named are present. While it is true that the code processes flags in a bitmask and clears them until no pending operations remain, multiple key details are unverified or incorrect, resulting in mixed accuracy.",
                "The summary correctly notes that the code processes and clears flags in a bitmask until no pending bits remain, as seen with `twdr->thread_slots` and the loop clearing bits. However, it inaccurately specifies an '8-bit mask' and references 'sub_FFFFFFFF8162FA30 and related handlers', neither of which are present in the source code. After discarding these hallucinations, the remaining accurate detail only partially reflects the main logic and omits key aspects like the locking mechanism, rescheduling checks, and iterative work processing for each slot.",
                "The summary claims the function processes and clears flags in an 8-bit mask, but the mask size is determined by sizeof(twdr->thread_slots) * 8 and verified against INET_TWDR_TWKILL_SLOTS, not strictly 8 bits. It also names a non-existent sub_FFFFFFFF8162FA30 function, which is a hallucination. While it is accurate that the code processes and clears flags in a bitmask until completion, the proportion of inaccurate details (incorrect bit width and non-existent function) is over 50%, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic int unix_getname(struct socket *sock, struct sockaddr *uaddr, int *uaddr_len, int peer)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct unix_sock *u;\n\tDECLARE_SOCKADDR(struct sockaddr_un *, sunaddr, uaddr);\n\tint err = 0;\n\n\tif (peer) {\n\t\tsk = unix_peer_get(sk);\n\n\t\terr = -ENOTCONN;\n\t\tif (!sk)\n\t\t\tgoto out;\n\t\terr = 0;\n\t} else {\n\t\tsock_hold(sk);\n\t}\n\n\tu = unix_sk(sk);\n\tunix_state_lock(sk);\n\tif (!u->addr) {\n\t\tsunaddr->sun_family = AF_UNIX;\n\t\tsunaddr->sun_path[0] = 0;\n\t\t*uaddr_len = sizeof(short);\n\t} else {\n\t\tstruct unix_address *addr = u->addr;\n\n\t\t*uaddr_len = addr->len;\n\t\tmemcpy(sunaddr, addr->name, *uaddr_len);\n\t}\n\tunix_state_unlock(sk);\n\tsock_put(sk);\nout:\n\treturn err;\n}",
    "comment": "Retrieves the Unix socket's address or initializes it as empty if not connected, handling peer connections appropriately.",
    "prorec_sum": "Initializes connection-related state, retrieves or sets address data, manages reference counts, and triggers cleanup when no references remain.",
    "filter_prorec_sum": "Initializes or copies connection-related data from a socket context into a target buffer while managing reference counts and releasing resources if needed.",
    "prorec_aug_sum": "Handles object reference counting, retrieves associated entry data into a buffer, and triggers cleanup when no references remain.",
    "filter_prorec_aug_sum": "Initializes or copies data into the target buffer from a referenced object, managing reference counts and invoking a cleanup routine when no references remain.",
    "work_score": {
        "prorec": {
            "summary": "Initializes connection-related state, retrieves or sets address data, manages reference counts, and triggers cleanup when no references remain.",
            "score": [
                0.5,
                0.6,
                0.3666666666666667
            ],
            "reason": [
                "The summary accurately notes that the function manages reference counts and retrieves or sets address data, as shown by the use of sock_hold, sock_put, and memcpy to copy address information. However, the claim about initializing connection-related state is vague and not explicitly supported in the code, and the mention of triggering cleanup when no references remain is not present in the given snippet. This results in a mix of accurate and unverified details.",
                "The summary correctly notes that the function manages connection-related state (peer retrieval, address copying) and reference counts (sock_hold/sock_put). However, it inaccurately claims that it 'sets address data' in a general sense, since the code only copies from existing address structures and sets default values when no address is present. The statement about 'triggers cleanup when no references remain' is not explicitly evidenced in the source; while sock_put may eventually lead to cleanup, that is not shown in this function. The accurate parts cover some main actions but omit key details like error handling with -ENOTCONN, AF_UNIX family setup, and address-length assignment, so coverage is incomplete.",
                "The summary contains multiple inaccuracies. While the code indeed retrieves address data and manages reference counts with sock_hold and sock_put, it does not initialize a general 'connection-related state' \u2014 rather, it conditionally retrieves a peer socket or holds the current one. Most critically, there's no logic to 'trigger cleanup when no references remain' in this function; cleanup would occur elsewhere. These inaccuracies exceed half of the stated details, activating the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes or copies connection-related data from a socket context into a target buffer while managing reference counts and releasing resources if needed.",
            "score": [
                0.9666666666666667,
                0.6,
                0.5333333333333333
            ],
            "reason": [
                "The summary correctly captures that the function deals with socket connection-related data, uses reference counting via sock_hold/sock_put, and copies data into a target buffer (memcpy into sunaddr). However, it omits explicit mention of conditional handling for peer sockets, address family setup, and other control flow present in the code. All stated details are supported by evidence in the source, with no unverified assumptions, making the alignment strong.",
                "The summary accurately captures the general idea that the function works with socket-related connection data and manages resources (reference counts via sock_hold/sock_put). However, it misses specific, critical details like conditional peer socket retrieval, error handling when connection is absent, and the precise structure copying logic with AF_UNIX family and sun_path handling. These omissions mean it only partially reflects the actual code's logic.",
                "The summary generally captures the function\u2019s purpose of handling connection-related socket data and resource management, but it omits key specifics found in the code, such as conditional logic for peer sockets, explicit setting of AF_UNIX family, handling of null addresses, and use of unix_state_lock/unlock. While these omissions make the description generic, the details present are broadly accurate, with no clear false claims. The accurate points offer only a high-level understanding without domain-rich insight."
            ]
        }
    }
}
{
    "source_code": "void sqlite3AddDefaultValue(Parse *pParse, ExprSpan *pSpan){\n  Table *p;\n  Column *pCol;\n  sqlite3 *db = pParse->db;\n  p = pParse->pNewTable;\n  if( p!=0 ){\n    pCol = &(p->aCol[p->nCol-1]);\n    if( !sqlite3ExprIsConstantOrFunction(pSpan->pExpr, db->init.busy) ){\n      sqlite3ErrorMsg(pParse, \"default value of column [%s] is not constant\",\n          pCol->zName);\n    }else{\n      /* A copy of pExpr is used instead of the original, as pExpr contains\n      ** tokens that point to volatile memory. The 'span' of the expression\n      ** is required by pragma table_info.\n      */\n      Expr x;\n      sqlite3ExprDelete(db, pCol->pDflt);\n      memset(&x, 0, sizeof(x));\n      x.op = TK_SPAN;\n      x.u.zToken = sqlite3DbStrNDup(db, (char*)pSpan->zStart,\n                                    (int)(pSpan->zEnd - pSpan->zStart));\n      x.pLeft = pSpan->pExpr;\n      x.flags = EP_Skip;\n      pCol->pDflt = sqlite3ExprDup(db, &x, EXPRDUP_REDUCE);\n      sqlite3DbFree(db, x.u.zToken);\n    }\n  }\n  sqlite3ExprDelete(db, pSpan->pExpr);\n}",
    "comment": "Validates and sets a default value for the last column of a new table, ensuring it is a constant expression before storing it.",
    "prorec_sum": "Validates and sets a constant default value for a database table column, updating associated structures and resources when conditions are met.",
    "filter_prorec_sum": "Updates a table column's default constant value by creating and assigning a new object, or reports an error if the value is non-constant.",
    "prorec_aug_sum": "Updates a table column\u2019s stored value if it passes a constant check, otherwise logs an error about a non-constant default value.",
    "filter_prorec_aug_sum": "Updates a table column\u2019s default value if it is constant, creating related data structures, otherwise logs an error about non-constant defaults.",
    "work_score": {
        "prorec": {
            "summary": "Validates and sets a constant default value for a database table column, updating associated structures and resources when conditions are met.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function validates and sets a constant default value for a table column when conditions are met, which is explicitly shown in the call to sqlite3ExprIsConstantOrFunction and subsequent assignment to pCol->pDflt. It also accurately notes the updating of associated structures and resources, as the code updates the column's default value and frees/duplicates related memory. All details match the source code with no unverified assumptions.",
                "The summary accurately states that the function validates if a default value is constant and sets it for a table column, which is evident from the check using sqlite3ExprIsConstantOrFunction and subsequent assignment to pCol->pDflt. However, it omits important details such as the specific error handling when the value is not constant, the usage of an Expr copy to handle volatile memory, freeing previous defaults, and cleanup operations on pSpan->pExpr. These omissions mean the depiction of logic is incomplete.",
                "The summary correctly reflects that the function validates if a default value is constant and sets it for a database table column when the condition is met. It omits specific implementation details such as handling of token spans, memory cleanup, and use of functions like sqlite3ExprDup and sqlite3DbFree. All elements mentioned in the summary are accurate according to the source code, but they are expressed in a generic manner without domain-rich specifics."
            ]
        },
        "filter_prorec": {
            "summary": "Updates a table column's default constant value by creating and assigning a new object, or reports an error if the value is non-constant.",
            "score": [
                1.0,
                0.6,
                0.6666666666666666
            ],
            "reason": [
                "The summary correctly states that the function updates a column's default value and reports an error if it is not a constant, which aligns with the check using sqlite3ExprIsConstantOrFunction and the sqlite3ErrorMsg call. It accurately notes that a new object is created and assigned in the constant-value branch, corresponding to constructing an Expr and assigning it to pCol->pDflt. All details are explicitly supported by the source code, with no unverifiable assumptions present.",
                "The summary accurately captures the main control flow: it checks whether the new default value is a constant and either updates the column's default or reports an error. These behaviors are explicitly shown in the code via the call to sqlite3ExprIsConstantOrFunction for validation, sqlite3ErrorMsg for errors, and sqlite3ExprDup for creating and assigning the new default. However, it omits important details such as the operation on the most recently added column, the use of TK_SPAN and EP_Skip flags, memory management with sqlite3DbFree, and deletion of previous defaults, which are key parts of the function's logic.",
                "The summary accurately reflects the core logic: it describes checking if the default value is constant, reporting an error for non-constant values, and otherwise creating and assigning a new object to update the column's default. These behaviors are explicitly shown in the source code via the constant/function check, error message, and creation/assignment of a copied expression for pCol->pDflt. While accurate, the details are somewhat generic and omit specifics such as the span handling and memory management steps present in the code."
            ]
        }
    }
}
{
    "source_code": "\nstatic void igmp_group_added(struct ip_mc_list *im)\n{\n\tstruct in_device *in_dev = im->interface;\n\n\tif (im->loaded == 0) {\n\t\tim->loaded = 1;\n\t\tip_mc_filter_add(in_dev, im->multiaddr);\n\t}\n\n#ifdef CONFIG_IP_MULTICAST\n\tif (im->multiaddr == IGMP_ALL_HOSTS)\n\t\treturn;\n\n\tif (in_dev->dead)\n\t\treturn;\n\tif (IGMP_V1_SEEN(in_dev) || IGMP_V2_SEEN(in_dev)) {\n\t\tspin_lock_bh(&im->lock);\n\t\tigmp_start_timer(im, IGMP_Initial_Report_Delay);\n\t\tspin_unlock_bh(&im->lock);\n\t\treturn;\n\t}\n\t/* else, v3 */\n\n\tim->crcount = in_dev->mr_qrv ? in_dev->mr_qrv :\n\t\tIGMP_Unsolicited_Report_Count;\n\tigmp_ifc_event(in_dev);\n#endif\n}",
    "comment": "The function processes the addition of an IGMP multicast group, initializing it and managing timers based on the interface's multicast version and state.",
    "prorec_sum": "Handles initial state setup for a network-related object and triggers actions or status updates based on its flags and timing conditions.",
    "filter_prorec_sum": "Initializes station-specific state and, based on multiple status checks, either triggers wake/block operations or updates a status byte before invoking a handler.",
    "prorec_aug_sum": "Initializes specific state for the given structure and conditionally triggers associated operations or state updates based on multiple device status checks.",
    "filter_prorec_aug_sum": "Initializes a network-related structure once, then updates state or triggers associated handler calls based on specific status flags and timestamp comparisons.",
    "work_score": {
        "prorec": {
            "summary": "Handles initial state setup for a network-related object and triggers actions or status updates based on its flags and timing conditions.",
            "score": [
                0.7666666666666666,
                0.6,
                0.5
            ],
            "reason": [
                "The summary correctly captures that the function handles initial state setup for a network-related object (`im->loaded` flag) and that subsequent actions depend on specific conditions (checks for multicast address, dead interface, IGMP version, and timers). While it is high-level and omits many specifics like function names and constants, the details it does include are grounded in the source code and do not introduce unverified assumptions.",
                "The summary correctly identifies that the function sets an initial state and triggers actions based on conditions, which matches the code's behavior of setting 'loaded' to 1, adding a multicast filter, and initiating IGMP actions based on address and protocol version flags. However, it omits several critical details such as skipping IGMP_ALL_HOSTS, handling 'dead' devices, version-specific timer handling, and setting 'crcount'. These missing elements prevent it from fully covering the code's logic, but the core behavior is captured accurately.",
                "The summary is very generic, mentioning initial state setup and conditional actions without specifying explicit details like function names, variables (e.g., im->loaded, im->multiaddr), or timing logic present in the source code. While the gist aligns loosely with the function's behavior, it omits concrete evidence-based elements from the source, making most details vague rather than domain-rich. Only the broad concept of conditionally triggering actions based on state and timing matches, but this is minimal value."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes station-specific state and, based on multiple status checks, either triggers wake/block operations or updates a status byte before invoking a handler.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary includes details such as 'station-specific state', 'wake/block operations', and 'status byte' that are not present in the source code. The actual function deals with IGMP group initialization, multicast filtering, conditionally starting IGMP timers, and handling IGMP v3 events, none of which match the described operations. All semantic details in the summary are hallucinations with no support from the source code, resulting in no accurate matches.",
                "The summary describes initializing station-specific state, triggering wake/block operations, and updating a status byte before invoking a handler. None of these actions are present in the source code. The actual function handles IGMP group addition by checking if a multicast group is loaded, adding a filter, and processing IGMP version-specific logic with timers and counters. Since all details in the summary lack explicit evidence in the code, they are hallucinations, leaving no accurate content.",
                "The summary's claims about initializing station-specific state, triggering wake/block operations, and updating a status byte before invoking a handler are not supported by the source code. The actual code manages IGMP group membership for an interface, with conditions for multicast filter addition, IGMP protocol version checks, timer starts, and interface change events. None of the summary's details match the actual functions or logic present, making all semantic details inaccurate and triggering the kill switch due to over 50% inaccuracy."
            ]
        }
    }
}
{
    "source_code": "static int shrink_dqcache_memory(struct shrinker *shrink,\n\t\t\t\t struct shrink_control *sc)\n{\n\tint nr = sc->nr_to_scan;\n\n\tif (nr) {\n\t\tspin_lock(&dq_list_lock);\n\t\tprune_dqcache(nr);\n\t\tspin_unlock(&dq_list_lock);\n\t}\n\treturn ((unsigned)\n\t\tpercpu_counter_read_positive(&dqstats.counter[DQST_FREE_DQUOTS])\n\t\t/100) * sysctl_vfs_cache_pressure;\n}",
    "comment": "Releases disk quota cache memory by pruning unused entries based on the specified number of entries to scan and adjusts the cache pressure accordingly.",
    "prorec_sum": "Iterates over and dismantles tracked objects from a global list, clears their links, invokes cleanup callbacks, and returns a scaled usage counter value.",
    "filter_prorec_sum": "Cleans up and unlinks queued objects from a global list, invokes their destructor, and returns a scaled count of remaining items.",
    "prorec_aug_sum": "Cleans up and removes task or object entries from linked lists, invokes their destructor, and returns a scaled value based on a global counter.",
    "filter_prorec_aug_sum": "Iterates over and dismantles a global list of objects, freeing associated links, invoking cleanup callbacks, and returning a scaled usage counter.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over and dismantles tracked objects from a global list, clears their links, invokes cleanup callbacks, and returns a scaled usage counter value.",
            "score": [
                0.26666666666666666,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims iteration over a global list, clearing links, and invoking cleanup callbacks, which are not explicitly evidenced in the source code. The code instead locks a dq_list_lock, calls prune_dqcache with nr, unlocks, and returns a computed value based on a counter and sysctl_vfs_cache_pressure. Only the part about returning a scaled usage counter value is supported; the rest are unverifiable assumptions, making most details inaccurate.",
                "The summary claims iteration over a global list, clearing links, and invoking cleanup callbacks, but the source code only shows locking `dq_list_lock`, calling `prune_dqcache` with `nr`, and returning a scaled counter based on `percpu_counter_read_positive` and `sysctl_vfs_cache_pressure`. The specific actions of iterating tracked objects, clearing links, and cleanup callbacks are not explicitly evidenced, so those are hallucinations. The only accurate detail is returning a scaled usage counter, which covers part of the logic but omits key control flow and parameter handling.",
                "The summary claims iteration over tracked objects in a global list, clearing links, and invoking cleanup callbacks, none of which are explicitly present in the source code. The actual code conditionally locks dq_list_lock, calls prune_dqcache, and computes a scaled counter value, making the only accurate detail the scaled usage counter return. Since more than half of the summary's details are unsupported, the evaluation must stop under the kill switch rule."
            ]
        },
        "filter_prorec": {
            "summary": "Cleans up and unlinks queued objects from a global list, invokes their destructor, and returns a scaled count of remaining items.",
            "score": [
                0.3,
                0.4000000000000001,
                0.0
            ],
            "reason": [
                "The summary claims it unlinks queued objects from a global list and invokes their destructor, but the source code only shows acquiring a spinlock on dq_list_lock, calling prune_dqcache, and returning a scaled value of a counter. There is no explicit evidence of a destructor or unlinking of queued objects in the code. The only accurate part is that it returns a scaled count of remaining items, making most details hallucinations.",
                "The summary incorrectly mentions unlinking queued objects from a global list and invoking destructors, which are not evidenced in the source code. The code only locks the dq_list, calls prune_dqcache with nr_to_scan, unlocks the list, and returns a scaled per-CPU counter value. The accurate portion is that it returns a scaled count of remaining items, but the cleanup and destructor details are hallucinations. As a result, while part of the return behavior is captured, most of the core logic is missing.",
                "The summary claims queued objects are unlinked from a global list and their destructor is invoked, but the source code only shows pruning via prune_dqcache under a spin lock with no destructor invocation visible. The return value is indeed a scaled count of remaining items from a percpu counter multiplied by sysctl_vfs_cache_pressure, which is accurate. However, more than half of the described logic (unlinking queued objects and invoking a destructor) is not supported by the code, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nvoid BN_CTX_end(BN_CTX *ctx)\n\t{\n\tCTXDBG_ENTRY(\"BN_CTX_end\", ctx);\n\tif(ctx->err_stack)\n\t\tctx->err_stack--;\n\telse\n\t\t{\n\t\tunsigned int fp = BN_STACK_pop(&ctx->stack);\n\t\t/* Does this stack frame have anything to release? */\n\t\tif(fp < ctx->used)\n\t\t\tBN_POOL_release(&ctx->pool, ctx->used - fp);\n\t\tctx->used = fp;\n\t\t/* Unjam \"too_many\" in case \"get\" had failed */\n\t\tctx->too_many = 0;\n\t\t}\n\tCTXDBG_EXIT(ctx);\n\t}",
    "comment": "Releases resources associated with the BN_CTX structure, updating the used stack frame and resetting the too_many flag if necessary.",
    "prorec_sum": "Ends a BN_CTX allocation frame, restoring stack pointers and depth counters, and releasing allocated BIGNUM entries back to the context pool.",
    "filter_prorec_sum": "Finalizes a BN_CTX context frame by restoring previous stack state, updating allocation counters, and resetting depth tracking variables.",
    "prorec_aug_sum": "Decrements the BN_CTX stack depth, updates internal indices, and restores frame state for released big number temporary variables.",
    "filter_prorec_aug_sum": "Finalizes a BN_CTX usage frame by restoring stack offsets, adjusting pool pointers, and resetting allocation tracking state.",
    "work_score": {
        "prorec": {
            "summary": "Ends a BN_CTX allocation frame, restoring stack pointers and depth counters, and releasing allocated BIGNUM entries back to the context pool.",
            "score": [
                1.0,
                0.8000000000000002,
                0.7666666666666666
            ],
            "reason": [
                "The summary correctly states that the function ends a BN_CTX allocation frame, restores the stack pointer (via BN_STACK_pop), and releases allocated items back to the pool (BN_POOL_release). These actions have explicit evidence in the source code. The mention of 'depth counters' corresponds to updating ctx->used and ctx->too_many, which also appears. All semantic details in the summary are supported by the code, with no hallucinated claims.",
                "The summary is mostly accurate: it correctly states that BN_CTX_end ends an allocation frame, restores stack pointers, adjusts depth counters, and releases allocated BIGNUM entries to the pool. These are evidenced by BN_STACK_pop restoring fp, used being updated, and BN_POOL_release freeing entries. However, the summary omits certain logic details present in the source such as handling err_stack decrement, the condition on fp < used, and resetting too_many. This means while the core function is captured, some control flow and edge case handling are missing.",
                "The summary claims the function restores stack pointers and depth counters, and releases allocated BIGNUM entries back to the pool. The source code confirms a stack pointer restoration (`ctx->used = fp` after `BN_STACK_pop`), and pool release (`BN_POOL_release`) when appropriate. However, the summary introduces 'depth counters' and explicitly calls allocations 'BIGNUM entries', neither of which is evident from the source code\u2014'depth counters' and specific allocation type are not directly supported by the visible code. The majority of details align with code behavior, but there are some minor inaccuracies."
            ]
        },
        "filter_prorec": {
            "summary": "Finalizes a BN_CTX context frame by restoring previous stack state, updating allocation counters, and resetting depth tracking variables.",
            "score": [
                1.0,
                0.7333333333333334,
                0.9
            ],
            "reason": [
                "The summary accurately reflects the source code's behavior: the function restores the previous stack state by popping the frame pointer, updates allocation counters via BN_POOL_release, and resets depth tracking variables like ctx->too_many and ctx->used. All described details have explicit evidence in the code, with no unverifiable or hallucinated elements.",
                "The summary accurately captures the main purpose of BN_CTX_end: restoring the previous stack state via BN_STACK_pop, updating allocation counters through BN_POOL_release adjustments and ctx->used assignment, and resetting the depth tracking variable ctx->too_many. These details are explicitly present in the source code and form a coherent picture of the function's logic, though it omits mention of the err_stack decrement path and conditional handling, which are also part of the core logic.",
                "The summary accurately reflects the function's purpose: it restores the previous stack state via BN_STACK_pop, updates allocation counters by adjusting ctx->used and triggering BN_POOL_release, and resets depth tracking variables, notably ctx->too_many. All these details are explicitly evidenced in the source code, and they provide domain-specific insight into BN_CTX's memory and state management."
            ]
        }
    }
}
{
    "source_code": "\nstatic ssize_t\narray_size_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tsector_t sectors;\n\n\tif (strncmp(buf, \"default\", 7) == 0) {\n\t\tif (mddev->pers)\n\t\t\tsectors = mddev->pers->size(mddev, 0, 0);\n\t\telse\n\t\t\tsectors = mddev->array_sectors;\n\n\t\tmddev->external_size = 0;\n\t} else {\n\t\tif (strict_blocks_to_sectors(buf, &sectors) < 0)\n\t\t\treturn -EINVAL;\n\t\tif (mddev->pers && mddev->pers->size(mddev, 0, 0) < sectors)\n\t\t\treturn -E2BIG;\n\n\t\tmddev->external_size = 1;\n\t}\n\n\tmddev->array_sectors = sectors;\n\tif (mddev->pers) {\n\t\tset_capacity(mddev->gendisk, mddev->array_sectors);\n\t\trevalidate_disk(mddev->gendisk);\n\t}\n\treturn len;\n}",
    "comment": "Sets the array size for a storage device based on input, updating capacity and validating the disk if a specific size is provided.",
    "prorec_sum": "Sets a device\u2019s configuration value to \u201cdefault\u201d or a specified parameter, validates it, updates internal state, and triggers further processing with provided coordinates.",
    "filter_prorec_sum": "Sets a device parameter to either a default or validated value and updates hardware configuration with provided floating\u2011point settings.",
    "prorec_aug_sum": "Sets a configuration value to either a default or parsed numeric option, validates it, updates internal state, and triggers a related callback with parameters.",
    "filter_prorec_aug_sum": "Sets a configuration value to default or parsed input, updates related state, and applies parameters through a linked object callback if available.",
    "work_score": {
        "prorec": {
            "summary": "Sets a device\u2019s configuration value to \u201cdefault\u201d or a specified parameter, validates it, updates internal state, and triggers further processing with provided coordinates.",
            "score": [
                0.6,
                0.5666666666666667,
                0.16666666666666666
            ],
            "reason": [
                "The summary correctly notes that the function handles a 'default' case or a user-provided parameter, performs validation, and updates internal state, which matches the code's checks for 'default', calls to strict_blocks_to_sectors, and assignments to mddev fields. However, it inaccurately mentions 'triggers further processing with provided coordinates', which is not supported by the source code \u2014 there are no coordinates processed. This introduces a hallucination, making the accuracy mixed rather than near-perfect.",
                "The summary correctly captures that the function can set a configuration value to 'default' or a specified parameter, validates it, and updates internal state. However, it inaccurately mentions 'coordinates', which are not present in the source code, and omits important details such as the specific validation against mddev->pers->size, error handling with -EINVAL and -E2BIG, and post-update actions like set_capacity and revalidate_disk. This results in partial coverage of the core logic but missing significant semantic units.",
                "The summary claims the function triggers processing with provided coordinates, but the source code contains no logic involving coordinates. It does correctly indicate setting a configuration value to 'default' or a specified parameter, validating it, and updating internal state. However, half of the identified details are inaccurate, with the coordinate claim being a clear hallucination and no mention of coordinates in the code. This leads to more than 50% inaccurate details, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Sets a device parameter to either a default or validated value and updates hardware configuration with provided floating\u2011point settings.",
            "score": [
                0.4666666666666666,
                0.10000000000000002,
                0.26666666666666666
            ],
            "reason": [
                "The summary inaccurately claims the function uses floating-point settings, which is not supported by the source code \u2014 all operations are on 'sector_t' integers. While it is correct that the function sets a device parameter (array size) to either a default or validated value and updates hardware configuration (via set_capacity and revalidate_disk), the addition of floating-point detail is a hallucination. This results in mixed accuracy.",
                "The summary is largely inaccurate: it claims the function updates hardware configuration using floating\u2011point settings, which is not supported by the source code. The source code deals with sector counts and integer logic, checks for 'default' input, validates sector size with strict_blocks_to_sectors, sets flags, and updates device capacity. No floating\u2011point parameters are used. After discarding inaccuracies, almost none of the summary's content aligns with the actual control flow and data handling, leaving the core logic unrepresented.",
                "The summary claims the function updates hardware configuration with floating\u2011point settings, but the source code uses integer types (sector_t) and performs string comparison, capacity setting, and disk revalidation. The 'default or validated value' part loosely matches the branch handling \"default\" and strict_blocks_to_sectors validation, but the floating\u2011point detail is inaccurate. With more than half of the semantic details (floating\u2011point settings, hardware configuration context) lacking explicit evidence, the proportion of inaccurate details exceeds the threshold, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "void exit_itimers(struct signal_struct *sig)\n{\n\tstruct k_itimer *tmr;\n\n\twhile (!list_empty(&sig->posix_timers)) {\n\t\ttmr = list_entry(sig->posix_timers.next, struct k_itimer, list);\n\t\titimer_delete(tmr);\n\t}\n}",
    "comment": "Deletes all posix timers associated with the given signal structure by iterating through and removing each timer from the list.",
    "prorec_sum": "Removes and cleans up expired POSIX timer entries from a linked list, invoking type-specific handlers and deallocating associated resources.",
    "filter_prorec_sum": "Removes and cleans up POSIX timer entries from a linked list, invoking type-specific handlers and logging unexpected timer types.",
    "prorec_aug_sum": "Iterates through a linked list of POSIX timers, invoking callback operations for valid entries and removing or cleaning up invalid or expired timers.",
    "filter_prorec_aug_sum": "Removes and cleans up expired or invalid POSIX timer entries from a task\u2019s timer list, invoking associated callbacks when applicable.",
    "work_score": {
        "prorec": {
            "summary": "Removes and cleans up expired POSIX timer entries from a linked list, invoking type-specific handlers and deallocating associated resources.",
            "score": [
                0.3,
                0.39999999999999997,
                0.0
            ],
            "reason": [
                "The summary claims removal of expired POSIX timers, invocation of type-specific handlers, and deallocation of resources. The source code only shows iterating over the posix_timers list and calling itimer_delete, with no explicit checks for expiration or type-specific handlers. Only the removal from a linked list is verifiable, making most details unverified assumptions.",
                "The summary contains inaccuracies: the source code removes all POSIX timers from the list, not specifically expired timers, and there is no evidence of invoking type-specific handlers or explicit deallocation beyond calling itimer_delete. The accurate portion is that it iteratively removes POSIX timers from a linked list, but significant logic details are missing and replaced with hallucinations.",
                "The summary claims removal of expired timers, invocation of type-specific handlers, and deallocation of resources, but the source code only shows iterating through a list of POSIX timers in a signal_struct and calling itimer_delete without any explicit expiry checks or type-specific handler logic. More than half of the claims are unsupported, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Removes and cleans up POSIX timer entries from a linked list, invoking type-specific handlers and logging unexpected timer types.",
            "score": [
                0.4333333333333333,
                0.5666666666666668,
                0.0
            ],
            "reason": [
                "The summary correctly notes the removal of POSIX timer entries from a linked list, which is evidenced by the use of list_empty, list_entry, and itimer_delete in the source code. However, claims about invoking type-specific handlers and logging unexpected timer types are not supported by any explicit code elements, making them hallucinations. With half of the details unsupported, the accuracy ratio is below 50%.",
                "The summary correctly states that the function removes and cleans up POSIX timer entries from a linked list, which matches the while loop checking for list_empty and using list_entry on sig->posix_timers, followed by itimer_delete. However, claims about invoking type-specific handlers and logging unexpected timer types are not supported by the source code \u2014 there is no evidence of logging or type-specific dispatch. The accurate portion covers the main action but omits details such as looping until the list is empty and direct call to itimer_delete without conditional handling.",
                "The summary claims that the function invokes type-specific handlers and logs unexpected timer types, but the source code only shows deletion of POSIX timers from a linked list using itimer_delete without any logging or type-specific handler calls. The accurate detail is that it removes POSIX timers from a linked list, but over half of the stated details are inaccurate, which triggers the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic int snd_pcm_unlink(struct snd_pcm_substream *substream)\n{\n\tstruct snd_pcm_substream *s;\n\tint res = 0;\n\n\tdown_write(&snd_pcm_link_rwsem);\n\twrite_lock_irq(&snd_pcm_link_rwlock);\n\tif (!snd_pcm_stream_linked(substream)) {\n\t\tres = -EALREADY;\n\t\tgoto _end;\n\t}\n\tlist_del(&substream->link_list);\n\tsubstream->group->count--;\n\tif (substream->group->count == 1) {\t/* detach the last stream, too */\n\t\tsnd_pcm_group_for_each_entry(s, substream) {\n\t\t\trelink_to_local(s);\n\t\t\tbreak;\n\t\t}\n\t\tkfree(substream->group);\n\t}\n\trelink_to_local(substream);\n       _end:\n\twrite_unlock_irq(&snd_pcm_link_rwlock);\n\tup_write(&snd_pcm_link_rwsem);\n\treturn res;\n}",
    "comment": "Unlinks a PCM substream from its group and releases resources if it was the last linked stream in the group.",
    "prorec_sum": "Removes a node from an internal linked structure, updates related counters, reinitializes list links, and triggers a follow\u2011up processing routine with given parameters.",
    "filter_prorec_sum": "Removes an element from a linked list, updates related counters and pointers, invokes a processing callback, and restores synchronization state.",
    "prorec_aug_sum": "Removes a linked substream from its list, updates related counters, resets pointers, and triggers follow-up audio processing before restoring global state.",
    "filter_prorec_aug_sum": "Removes and resets a linked substream structure, updates related counters, invokes a handler if needed, and reinitializes audio stream linkage.",
    "work_score": {
        "prorec": {
            "summary": "Removes a node from an internal linked structure, updates related counters, reinitializes list links, and triggers a follow\u2011up processing routine with given parameters.",
            "score": [
                0.6666666666666666,
                0.6,
                0.4666666666666666
            ],
            "reason": [
                "The summary correctly reflects that a node is removed from an internal linked structure and that related counters are updated, as seen with list_del, count decrement, and relink_to_local calls. However, it inaccurately adds the notion of a 'follow\u2011up processing routine with given parameters,' which is not evidenced in the source code, and does not reference locking mechanisms or conditional logic explicitly present. With roughly half of the details grounded in the code and the rest being unverified assumptions, accuracy is mixed.",
                "The summary correctly notes removal from a linked structure and updating counters, which matches the list_del call and group->count decrement in the code. It also captures reinitialization of links via relink_to_local. However, it inaccurately describes triggering a follow-up routine with given parameters, as there is no evidence in the code of parameter-based processing beyond the local relinking and cleanup of group resources. The accurate details cover the main action but omit key control flow elements such as the early EALREADY return and conditional detachment of the last stream, so coverage is incomplete.",
                "The summary contains some accurate elements such as the removal from a linked structure (`list_del`), updating counters (`group->count--`), and reinitializing links (`relink_to_local`). However, the claim about triggering a follow-up processing routine with given parameters is inaccurate, as there is no explicit evidence in the code of a distinct processing routine with parameters beyond link adjustments and memory freeing. Since the majority of details are accurate and they identify specific operations relevant to kernel linked list and synchronization logic, the content is domain\u2011specific and informative."
            ]
        },
        "filter_prorec": {
            "summary": "Removes an element from a linked list, updates related counters and pointers, invokes a processing callback, and restores synchronization state.",
            "score": [
                0.4666666666666666,
                0.5,
                0.26666666666666666
            ],
            "reason": [
                "The summary correctly notes the removal of an element from a linked list and the update of related counters, which are explicitly shown via list_del and group->count operations. However, it inaccurately claims that a 'processing callback' is invoked\u2014there is no such callback in the source, only calls to relink_to_local. Likewise, 'restores synchronization state' is an inferred interpretation rather than an explicit code detail, as the code releases locks but does not explicitly restore any broader state. With two out of four details accurate, less than half are substantiated.",
                "The summary accurately notes the removal of an element from a linked list and updating of a related counter, both of which are explicitly present in the source code via list_del and group count decrement. However, it incorrectly mentions invoking a processing callback and restoring synchronization state, which are not evident; instead, the code calls relink_to_local and kfree, and handles locking/unlocking. The accurate parts cover part of the core logic but miss key elements like conditional handling for the last stream, group deallocation, and synchronization primitives, so the overall coverage is partial.",
                "The summary correctly notes removal from a linked list and updating counters, which are explicitly present in the source code via `list_del` and `substream->group->count--`. It also aligns with restoring synchronization state through locking/unlocking functions. However, the claim about invoking a processing callback is inaccurate, as there is no evidence of a callback in the source code. With only one clear inaccuracy out of four details, the proportion of inaccuracies is below the kill switch threshold. The accurate parts are domain\u2011specific and give meaningful insight into list operations and synchronization in kernel audio code."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic ngx_int_t\nngx_http_chunked_header_filter(ngx_http_request_t *r)\n{\n    ngx_http_core_loc_conf_t       *clcf;\n    ngx_http_chunked_filter_ctx_t  *ctx;\n\n    if (r->headers_out.status == NGX_HTTP_NOT_MODIFIED\n        || r->headers_out.status == NGX_HTTP_NO_CONTENT\n        || r->headers_out.status < NGX_HTTP_OK\n        || r != r->main\n        || r->method == NGX_HTTP_HEAD)\n    {\n        return ngx_http_next_header_filter(r);\n    }\n\n    if (r->headers_out.content_length_n == -1\n        || r->expect_trailers)\n    {\n        clcf = ngx_http_get_module_loc_conf(r, ngx_http_core_module);\n\n        if (r->http_version >= NGX_HTTP_VERSION_11\n            && clcf->chunked_transfer_encoding)\n        {\n            if (r->expect_trailers) {\n                ngx_http_clear_content_length(r);\n            }\n\n            r->chunked = 1;\n\n            ctx = ngx_pcalloc(r->pool, sizeof(ngx_http_chunked_filter_ctx_t));\n            if (ctx == NULL) {\n                return NGX_ERROR;\n            }\n\n            ngx_http_set_ctx(r, ctx, ngx_http_chunked_filter_module);\n\n        } else if (r->headers_out.content_length_n == -1) {\n            r->keepalive = 0;\n        }\n    }\n\n    return ngx_http_next_header_filter(r);\n}",
    "comment": "The function processes HTTP responses to enable chunked transfer encoding when conditions regarding content length and HTTP version are met.",
    "prorec_sum": "Handles HTTP request state checks, clearing or allocating chunked filter context based on conditions before proceeding with further processing.",
    "filter_prorec_sum": "Handles HTTP request state checks and allocates chunked filter context when conditions are met, otherwise resets related fields and returns a default result.",
    "prorec_aug_sum": "Evaluates request state and flags, resets or clears associated data, and allocates a chunked filter context before returning a status value.",
    "filter_prorec_aug_sum": "Evaluates HTTP request state for chunked transfer, resets related fields, and allocates filter context before continuing response processing.",
    "work_score": {
        "prorec": {
            "summary": "Handles HTTP request state checks, clearing or allocating chunked filter context based on conditions before proceeding with further processing.",
            "score": [
                0.8333333333333334,
                0.6,
                0.6
            ],
            "reason": [
                "The summary accurately reflects the main logic in the source code: it checks HTTP request state (status codes, method, main request check), conditionally clears content length (when trailers are expected), allocates a chunked filter context when conditions are met, and then proceeds to the next header filter. The only minor shortcoming is that it omits some specific conditions (e.g., HTTP version check, keepalive adjustments) but contains no false or unverifiable details.",
                "The summary accurately notes that the function checks HTTP request state and conditionally clears or allocates a chunked filter context before continuing processing, which matches the code's conditional checks on status, method, content length, and trailers, as well as calls to clear the content length and allocate context. However, it omits significant logic such as disabling keepalive when content length is -1 without chunked encoding, detailed conditions for chunked encoding, and early return scenarios, so the coverage is partial rather than complete.",
                "The summary accurately notes that the code handles HTTP request state checks and allocates a chunked filter context based on certain conditions before passing control to the next header filter. These details are explicitly supported by status checks, chunked flag setting, context allocation, and the call to ngx_http_next_header_filter in the source. While accurate, the description is fairly generic and omits specifics such as the exact status codes, content length, http_version checks, and trailer handling, limiting the domain richness."
            ]
        },
        "filter_prorec": {
            "summary": "Handles HTTP request state checks and allocates chunked filter context when conditions are met, otherwise resets related fields and returns a default result.",
            "score": [
                0.6999999999999998,
                0.6666666666666666,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly notes HTTP request state checks and allocation of a chunked filter context when conditions are met, which matches the checks for status codes, method, content length, and trailers in the code. However, the claim about 'resets related fields' is vague and only partially accurate\u2014while the code sets keepalive to 0 under certain conditions and clears content length when expecting trailers, the summary lacks specificity and omits key details such as the HTTP version check and chunked_transfer_encoding flag. Overall, most details are broadly accurate but some are underspecified or generalized.",
                "The summary accurately notes HTTP request state checks and allocation of a chunked filter context when conditions are met, which is explicitly present in the code. However, it vaguely states 'resets related fields' without specifying actions like clearing content length or setting keepalive to 0, and it omits important conditional details such as specific status checks, HTTP version checks, and expect_trailers handling. This results in partial coverage of the main logic but misses significant specificity and edge-case handling present in the source code.",
                "The summary correctly captures the main semantics: the function performs HTTP request state checks, conditionally allocates a chunked filter context when appropriate, and otherwise resets fields or returns without modification. These details are explicitly reflected in the code through checks on status codes, method types, and conditions controlling chunked allocation. The only minor omission is that it generically describes 'resets related fields' rather than specifying keepalive or content-length handling, but overall the summary is accurate and domain-relevant."
            ]
        }
    }
}
{
    "source_code": "static int compute_partition_size(Ecma119Image *t, char *disk_path,\n                                  uint32_t *size, int flag)\n{\n    int ret, keep;\n    off_t num;\n    struct stat stbuf;\n    struct iso_interval_reader *ivr;\n    off_t byte_count;\n\n    if (flag & 1) {\n        ret = iso_interval_reader_new(t->image, disk_path,\n                                      &ivr, &byte_count, 0);\n        if (ret < 0)\n            return ret;\n        *size = (byte_count + BLOCK_SIZE - 1) / BLOCK_SIZE;\n        keep = iso_interval_reader_keep(t, ivr, 0);\n        iso_interval_reader_destroy(&ivr, 0);\n        if (keep < 0)\n            return keep;\n        return ISO_SUCCESS + (keep > 0);\n    }\n\n    *size = 0;\n    ret = stat(disk_path, &stbuf);\n    if (ret == -1)\n        return ISO_BAD_PARTITION_FILE;\n    if (! S_ISREG(stbuf.st_mode))\n        return ISO_BAD_PARTITION_FILE;\n    num = ((stbuf.st_size + 2047) / 2048);\n    if (num > 0x3fffffff || num == 0)\n        return ISO_BAD_PARTITION_FILE;\n    *size = num;\n    return ISO_SUCCESS;\n}",
    "comment": "Calculates the partition size from a disk path or an image based on a specified flag, ensuring valid file attributes and conditions.",
    "prorec_sum": "Calculates a file\u2019s size in 2KB blocks, using a cache if requested, and returns an error for non-regular or invalid-sized files.",
    "filter_prorec_sum": "Determines a file\u2019s data block count from its size or a device-specific lookup, returning error codes for invalid files or operation failures.",
    "prorec_aug_sum": "Determines file size in 2KB block units after validating existence and type, using optional custom lookup or direct `stat` for regular files.",
    "filter_prorec_aug_sum": "Calculates a file\u2019s block count from its size or device info, returning status codes based on existence, type, and processing results.",
    "work_score": {
        "prorec": {
            "summary": "Calculates a file\u2019s size in 2KB blocks, using a cache if requested, and returns an error for non-regular or invalid-sized files.",
            "score": [
                0.8333333333333334,
                0.7333333333333333,
                0.6666666666666666
            ],
            "reason": [
                "The summary accurately notes that the function calculates a file\u2019s size in 2KB blocks and returns errors for non-regular or invalid-sized files, which is supported by the use of `stat`, `S_ISREG`, and the computation `(stbuf.st_size + 2047) / 2048`. However, the claim about 'using a cache if requested' is not explicitly evidenced in the source code; while a flag triggers use of `iso_interval_reader_new` and related functions, there is no clear indication that this is a cache mechanism. This introduces some unverified assumption, lowering the accuracy ratio.",
                "The summary correctly identifies that the function computes a file size in 2KB blocks (consistent with 2048-byte divisions) and returns errors for non-regular or invalid-sized files. It also accurately notes the presence of an alternate behavior controlled by a flag \u2014 the section using iso_interval_reader_new provides a cached or precomputed path. Slight abstraction in describing this as a 'cache' rather than an interval reader is minor, so the summary is nearly complete and faithful to the code\u2019s logic.",
                "The summary correctly notes that the function calculates the size in 2KB blocks and returns errors for non\u2011regular or invalid\u2011sized files, which is evident from the use of 2048-byte division and S_ISREG checks. However, the claim about 'using a cache if requested' is inaccurate, as the source code uses an iso_interval_reader when the flag is set, with no explicit caching mechanism. With only one of three details inaccurate (33%), the majority are accurate, but the correct details are straightforward rather than domain-rich, making them moderately valuable."
            ]
        },
        "filter_prorec": {
            "summary": "Determines a file\u2019s data block count from its size or a device-specific lookup, returning error codes for invalid files or operation failures.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly describes that the function calculates a block count either from file size or via a device-specific operation and handles error conditions for invalid files or failures. Both these details are explicitly supported in the source: size is calculated using either iso_interval_reader_new (device-specific) or stat() and division by 2048, and error codes are returned for invalid files or negative results. No unverified or hallucinated details are present.",
                "The summary accurately captures the main logic: it computes a block count from either a size calculation or a specialized reader when a flag is set, and returns error codes for invalid files or failures. These details are supported by the source code\u2019s conditional branch for 'flag & 1', the use of iso_interval_reader_new and related cleanup, and the stat-based file size path with validation and error constants. However, it omits specifics like threshold checks (e.g., num > 0x3fffffff) and the precise rounding calculations, so while main actions are covered, some critical edge cases are missing.",
                "The summary accurately reflects that the function computes a block count from either a file size or via a device-specific mechanism, and that it returns error codes for invalid files or failed operations. These details are supported by the source code: the non-flag path uses `stat` on a file and computes block count from its size, while the flag path leverages `iso_interval_reader_new` for device-related logic; multiple error returns validate the failure handling. The description is concise but stays generic, lacking specific references to constants or functions used."
            ]
        }
    }
}
{
    "source_code": "\nstruct timeval* dtls1_get_timeout(SSL *s, struct timeval* timeleft)\n\t{\n\tstruct timeval timenow;\n\n\t/* If no timeout is set, just return NULL */\n\tif (s->d1->next_timeout.tv_sec == 0 && s->d1->next_timeout.tv_usec == 0)\n\t\t{\n\t\treturn NULL;\n\t\t}\n\n\t/* Get current time */\n\tget_current_time(&timenow);\n\n\t/* If timer already expired, set remaining time to 0 */\n\tif (s->d1->next_timeout.tv_sec < timenow.tv_sec ||\n\t\t(s->d1->next_timeout.tv_sec == timenow.tv_sec &&\n\t\t s->d1->next_timeout.tv_usec <= timenow.tv_usec))\n\t\t{\n\t\tmemset(timeleft, 0, sizeof(struct timeval));\n\t\treturn timeleft;\n\t\t}\n\n\t/* Calculate time left until timer expires */\n\tmemcpy(timeleft, &(s->d1->next_timeout), sizeof(struct timeval));\n\ttimeleft->tv_sec -= timenow.tv_sec;\n\ttimeleft->tv_usec -= timenow.tv_usec;\n\tif (timeleft->tv_usec < 0)\n\t\t{\n\t\ttimeleft->tv_sec--;\n\t\ttimeleft->tv_usec += 1000000;\n\t\t}\n\n\t/* If remaining time is less than 15 ms, set it to 0\n\t * to prevent issues because of small devergences with\n\t * socket timeouts.\n\t */\n\tif (timeleft->tv_sec == 0 && timeleft->tv_usec < 15000)\n\t\t{\n\t\tmemset(timeleft, 0, sizeof(struct timeval));\n\t\t}\n\t\n\n\treturn timeleft;\n\t}",
    "comment": "Calculates the remaining timeout for a DTLS connection and returns a struct timeval with the time left until expiration.",
    "prorec_sum": "Calculates the remaining time until a DTLS handshake deadline by comparing stored expiry values with the current system time.",
    "filter_prorec_sum": "Calculates the remaining time until a DTLS handshake deadline and returns zero if the timeout has expired or is under 15 milliseconds.",
    "prorec_aug_sum": "Calculates the remaining time until a DTLS handshake or retransmission deadline, returning zero if expired or below a 15ms threshold.",
    "filter_prorec_aug_sum": "Calculates the remaining time until a DTLS handshake timer expires and returns zero if already expired or below a 15\u202fms threshold.",
    "work_score": {
        "prorec": {
            "summary": "Calculates the remaining time until a DTLS handshake deadline by comparing stored expiry values with the current system time.",
            "score": [
                0.9,
                0.6,
                0.43333333333333335
            ],
            "reason": [
                "The summary correctly describes the core behavior of the function: it calculates the remaining time until a deadline by comparing a stored timeout (next_timeout) with the current time. This logic is explicitly present in the source code through get_current_time, comparisons of tv_sec and tv_usec, and subtraction to determine timeleft. No extraneous or unverifiable details were added, so all semantic elements in the summary are accurate.",
                "The summary correctly states that the function calculates remaining time until a DTLS deadline by comparing stored timeout values with the current time, which matches the code's logic using next_timeout and timenow. However, it omits several important details found in the source, such as handling cases with no timeout set, zeroing timeleft if the timer has expired or if the remaining time is less than 15 ms, and adjusting for negative microseconds. These omissions leave the picture incomplete.",
                "The summary accurately describes that the function calculates the remaining time until a deadline by comparing stored expiry values with the current time, which matches the code's behavior using next_timeout and timenow. However, the mention of a 'DTLS handshake deadline' is inaccurate because the source code does not specify that the timeout is for a handshake; it only deals with a generic DTLS timeout. Since there is only one specific detail and it is partially inaccurate, over 50% of the claimed detail is inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Calculates the remaining time until a DTLS handshake deadline and returns zero if the timeout has expired or is under 15 milliseconds.",
            "score": [
                0.9,
                0.6666666666666666,
                0.6
            ],
            "reason": [
                "The summary correctly describes the core logic in the source code: it calculates the remaining time until a deadline, returns zero if the timeout has expired, and returns zero if remaining time is under 15 milliseconds. Although the source code refers generally to a 'timer' rather than explicitly to a DTLS handshake deadline, the context of 'd1' structures in DTLS suggests the detail is plausible but not explicitly stated, making that part an unverified assumption. Overall, most details are supported, but there is a minor unverified claim about the specific deadline type.",
                "The summary correctly identifies the main functionality: computing the remaining time until a timeout and zeroing it if expired or below 15 ms. These details are explicitly reflected in the source code through checks for expiration and the 15 ms threshold. However, the reference to a 'DTLS handshake deadline' is not explicitly present in the code, which only operates on a general 'next_timeout' field. Despite this minor inaccuracy, the accurate parts capture the core logic, including edge case handling.",
                "The summary accurately reflects the function's purpose and logic: it computes the remaining time until a DTLS-related timeout and returns zero if the timeout has expired or is less than 15 ms. These details are explicitly supported in the source code by the calculations involving `next_timeout`, checks for expiration, and the final condition for times under 15 ms. The accurate details are domain-rich and directly tied to the source logic."
            ]
        }
    }
}
{
    "source_code": "static int mmc_get_leadin_text_al(struct burn_drive *d,\n                                  unsigned char **text_packs, int *alloc_len,\n                                  int flag)\n{\n\tstruct buffer *buf = NULL;\n\tstruct command *c = NULL;\n\tunsigned char *data;\n\tint ret, data_length;\n\n\t*text_packs = NULL;\n\n\tBURN_ALLOC_MEM(buf, struct buffer, 1);\n\tBURN_ALLOC_MEM(c, struct command, 1);\n\n\tscsi_init_command(c, MMC_GET_LEADTEXT, sizeof(MMC_GET_LEADTEXT));\n\tc->dxfer_len = *alloc_len;\n\tc->opcode[7]= (c->dxfer_len >> 8) & 0xff;\n\tc->opcode[8]= c->dxfer_len & 0xff;\n\tc->retry = 1;\n\tc->page = buf;\n\tc->page->bytes = 0;\n\tc->page->sectors = 0;\n\n\tc->dir = FROM_DRIVE;\n\td->issue_command(d, c);\n\tif (c->error)\n\t\t{ret = 0; goto ex;}\n\n\tdata = c->page->data;\t\n\tdata_length = (data[0] << 8) + data[1];\n\t*alloc_len = data_length + 2;\n\tif (*alloc_len >= 22 && !(flag & 1)) {\n\t\tBURN_ALLOC_MEM(*text_packs, unsigned char, *alloc_len - 4);\n\t\tmemcpy(*text_packs, data + 4, *alloc_len - 4);\n\t}\n\tret = 1;\t\nex:;\n\tBURN_FREE_MEM(c);\n\tBURN_FREE_MEM(buf);\n\treturn ret;\n}",
    "comment": "Retrieves lead-in text from a drive and allocates memory for the text if the conditions are met, returning success or failure.",
    "prorec_sum": "Allocates and initializes two related data blocks, invokes a callback with one, then extracts and optionally copies payload data into the provided output buffer.",
    "filter_prorec_sum": "Allocates and initializes two data blocks, invokes a handler, then extracts and optionally copies payload bytes based on header length and flags.",
    "prorec_aug_sum": "Allocates buffers, invokes a callback to fill them, extracts a length-prefixed payload, and optionally copies it into the provided output pointer.",
    "filter_prorec_aug_sum": "Allocates buffers, invokes a handler to fill them, then extracts, validates, and optionally copies payload data into the provided output pointer.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes two related data blocks, invokes a callback with one, then extracts and optionally copies payload data into the provided output buffer.",
            "score": [
                0.5333333333333333,
                0.5666666666666668,
                0.16666666666666666
            ],
            "reason": [
                "The summary's claim about allocating and initializing two data blocks matches the calls to BURN_ALLOC_MEM for 'buf' and 'c', which is accurate. However, describing 'issue_command' as invoking a callback with one of them is inaccurate since it directly issues a command rather than functioning as a generic callback. The mention of copying payload data is partially accurate as the code copies data into '*text_packs' conditionally, but the summary omits critical specifics such as conditional length checks and flag use, introducing vagueness. Overall, accuracy is mixed with some correct allocations but flawed characterizations of function behavior.",
                "The summary correctly notes allocation and initialization of two related data structures (`buf` and `c`) and that data is extracted from the command's buffer, optionally copied based on a condition. However, the description inaccurately describes invoking a callback; the source code calls `d->issue_command`, which is not clearly a callback but a method to issue a SCSI command. The summary omits important logic such as setting opcodes, handling errors with `goto ex`, computing `alloc_len` from data bytes, and the conditional check involving `flag & 1`. While some core actions are present, significant control flow and data manipulation details are missing.",
                "The summary accurately notes allocation and initialization of two data structures and conditional copying of payload data, but it misstates key details: there is no callback invocation, rather a direct method call `d->issue_command`. The described 'output buffer' is allocated inside the function, not provided externally. With over half of the semantic details inaccurate, the description is misleading per the kill switch criteria."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes two data blocks, invokes a handler, then extracts and optionally copies payload bytes based on header length and flags.",
            "score": [
                1.0,
                0.6666666666666666,
                0.7000000000000001
            ],
            "reason": [
                "The summary accurately captures the key steps: memory allocation for two structures (buf and c), initialization of a command, invoking a handler via d->issue_command, extracting payload length from header bytes, and conditional copying of data based on length and flag. All these details are explicitly present in the source code, with no unverified assumptions, indicating full alignment.",
                "The summary accurately identifies the allocation of two data structures, initialization, invocation of a command handler, data extraction, and conditional copying based on header length and flags. These details are explicitly supported by the source code through BURN_ALLOC_MEM calls, scsi_init_command, d->issue_command, extraction from data[0]/data[1], and the conditional memcpy logic. It captures the main logic flow, but omits some specifics such as the retry parameter, dxfer_len setup, and error handling path, so while coverage is strong, it is not fully comprehensive.",
                "The summary correctly notes the allocation of two data structures, the invocation of a command handler, and conditional copying of payload bytes based on length and flags, all explicitly present in the source code. These details are specific to the function\u2019s logic and data flow, demonstrating domain relevance. No inaccurate elements were found, and the accurate elements give clear insight into the function\u2019s operation."
            ]
        }
    }
}
{
    "source_code": "\nstatic int mntns_install(struct nsproxy *nsproxy, void *ns)\n{\n\tstruct fs_struct *fs = current->fs;\n\tstruct mnt_namespace *mnt_ns = ns;\n\tstruct path root;\n\n\tif (!ns_capable(mnt_ns->user_ns, CAP_SYS_ADMIN) ||\n\t    !nsown_capable(CAP_SYS_CHROOT) ||\n\t    !nsown_capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tif (fs->users != 1)\n\t\treturn -EINVAL;\n\n\tget_mnt_ns(mnt_ns);\n\tput_mnt_ns(nsproxy->mnt_ns);\n\tnsproxy->mnt_ns = mnt_ns;\n\n\t/* Find the root */\n\troot.mnt    = &mnt_ns->root->mnt;\n\troot.dentry = mnt_ns->root->mnt.mnt_root;\n\tpath_get(&root);\n\twhile(d_mountpoint(root.dentry) && follow_down_one(&root))\n\t\t;\n\n\t/* Update the pwd and root */\n\tset_fs_pwd(fs, &root);\n\tset_fs_root(fs, &root);\n\n\tpath_put(&root);\n\treturn 0;\n}",
    "comment": "Validates permissions, checks filesystem usage, updates the mount namespace in the nsproxy, and sets the current process's root and working directory.",
    "prorec_sum": "Validates parameters and state, updates a stored pointer, and performs a series of linked object operations when the current context flag equals one.",
    "filter_prorec_sum": "Validates parameters with multiple checks, updates a linked reference, processes associated data structures, and performs final cleanup when a specific state flag is set.",
    "prorec_aug_sum": "Validates multiple operation permissions, updates a reference, processes linked data structures, and performs cleanup when specific runtime conditions are met.",
    "filter_prorec_aug_sum": "Validates parameters with sub_FFFFFFFF81047* checks, then updates and processes a file or inode-related structure through multiple linked helper functions.",
    "work_score": {
        "prorec": {
            "summary": "Validates parameters and state, updates a stored pointer, and performs a series of linked object operations when the current context flag equals one.",
            "score": [
                0.3,
                0.43333333333333335,
                0.0
            ],
            "reason": [
                "The summary misrepresents several aspects of the source code. The claim about validating parameters and state is partially accurate, as the function checks permissions and `fs->users`. However, it inaccurately describes the condition as 'when the current context flag equals one,' which is not present; the only numeric comparison is `fs->users != 1`. The phrase 'updates a stored pointer' is accurate for `nsproxy->mnt_ns`. The rest, such as 'linked object operations,' is vague and not explicitly supported by identifiable evidence in the code. Overall, fewer than half of the described details can be directly confirmed from the source code.",
                "The summary claims a condition based on a 'current context flag equals one', which is not present in the source code. The actual check is 'fs->users != 1', along with capability validations. The remaining parts of the summary (validates parameters/state and updates a stored pointer) partially align with the code\u2014capability and user count checks, and setting 'nsproxy->mnt_ns'. However, it omits significant logic like namespace reference management, root path resolution, mount point traversal, and updating both root and pwd. Thus, after discarding the inaccurate conditional detail, the accurate content covers only part of the core logic.",
                "The summary omits key specifics visible in the source code such as capability checks (ns_capable, nsown_capable), namespace reference manipulation (get_mnt_ns, put_mnt_ns), and filesystem path handling (path_get, follow_down_one, set_fs_pwd, set_fs_root). It inaccurately claims logic is driven by a 'current context flag equals one', which is unsupported by the source; the actual check is on fs->users being 1. Most semantic details are either missing or incorrect, leading to more than half being inaccurate."
            ]
        },
        "filter_prorec": {
            "summary": "Validates parameters with multiple checks, updates a linked reference, processes associated data structures, and performs final cleanup when a specific state flag is set.",
            "score": [
                0.39999999999999997,
                0.26666666666666666,
                0.0
            ],
            "reason": [
                "The summary contains vague, generic claims that are not explicitly supported by the source code. While the code does perform multiple checks and updates a reference (`nsproxy->mnt_ns`), there is no evidence of processing linked data structures in the sense described, nor any state flag controlling final cleanup. The cleanup mentioned in the summary is not present; instead, the code releases a path (`path_put`) unconditionally. Most details are either too generic to be confirmed or are inaccurate based on the actual logic, leading to a low accuracy ratio.",
                "The summary mentions parameter validation, which aligns with the multiple capability and user count checks in the source code. However, it describes updating a linked reference and performing cleanup based on a specific state flag, which are not explicitly present in the code. The code updates namespace references and adjusts root/pwd paths but does not reference a linked structure or state flag-driven cleanup. After filtering out hallucinated details, only the parameter validation maps accurately to the source, leaving most of the core logic unrepresented.",
                "The summary is largely inaccurate. While the source code does validate parameters with multiple capability checks and updates references to the mount namespace, there is no evidence of processing a generic 'associated data structures' beyond specific namespace and path handling, and no logic for 'final cleanup when a specific state flag is set'. Over 50% of the stated details are unsupported by the code, triggering the kill switch for misleading content."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic void gen6_bsd_ring_write_tail(struct intel_ring_buffer *ring,\n\t\t\t\t     u32 value)\n{\n\tdrm_i915_private_t *dev_priv = ring->dev->dev_private;\n\n       /* Every tail move must follow the sequence below */\n\n\t/* Disable notification that the ring is IDLE. The GT\n\t * will then assume that it is busy and bring it out of rc6.\n\t */\n\tI915_WRITE(GEN6_BSD_SLEEP_PSMI_CONTROL,\n\t\t   _MASKED_BIT_ENABLE(GEN6_BSD_SLEEP_MSG_DISABLE));\n\n\t/* Clear the context id. Here be magic! */\n\tI915_WRITE64(GEN6_BSD_RNCID, 0x0);\n\n\t/* Wait for the ring not to be idle, i.e. for it to wake up. */\n\tif (wait_for((I915_READ(GEN6_BSD_SLEEP_PSMI_CONTROL) &\n\t\t      GEN6_BSD_SLEEP_INDICATOR) == 0,\n\t\t     50))\n\t\tDRM_ERROR(\"timed out waiting for the BSD ring to wake up\\n\");\n\n\t/* Now that the ring is fully powered up, update the tail */\n\tI915_WRITE_TAIL(ring, value);\n\tPOSTING_READ(RING_TAIL(ring->mmio_base));\n\n\t/* Let the ring send IDLE messages to the GT again,\n\t * and so let it sleep to conserve power when idle.\n\t */\n\tI915_WRITE(GEN6_BSD_SLEEP_PSMI_CONTROL,\n\t\t   _MASKED_BIT_DISABLE(GEN6_BSD_SLEEP_MSG_DISABLE));\n}",
    "comment": "Updates the tail of the BSD ring buffer after ensuring the ring is active and managing power-saving notifications.",
    "prorec_sum": "Writes commands to the BSD GPU ring, waits for it to become idle with timeout handling, then issues further ring buffer operations.",
    "filter_prorec_sum": "Writes commands to the Gen6 BSD ring, waits for it to become active with a timeout, then issues additional ring commands.",
    "prorec_aug_sum": "Writes commands to the gen6 BSD ring buffer, waits for it to become ready with a timeout, then issues additional ring operations.",
    "filter_prorec_aug_sum": "Writes commands to the BSD ring buffer and waits for it to become ready before issuing subsequent operations.",
    "work_score": {
        "prorec": {
            "summary": "Writes commands to the BSD GPU ring, waits for it to become idle with timeout handling, then issues further ring buffer operations.",
            "score": [
                0.43333333333333335,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies. The source code explicitly waits for the BSD ring to wake up (not become idle) and includes specific steps like disabling idle notification, clearing the context ID, updating the tail, and re-enabling idle messages, none of which are mentioned. The claim about waiting for the ring to become idle is contradicted by the code. Thus, most semantic details are unverified or incorrect, leading to a low accuracy ratio.",
                "The summary incorrectly states that the function waits for the ring to become idle, whereas the source code explicitly waits for the ring to wake up (not be idle). The accurate part is that it interacts with the BSD GPU ring and performs ring buffer tail updates. However, the summary misses critical steps such as disabling and re-enabling sleep messages, clearing the context ID, and the specific order of operations. These omissions mean the accurate details only partially cover the main logic.",
                "The summary inaccurately states that the function waits for the BSD ring to become idle, whereas the source code explicitly waits for the ring to not be idle (wake up). This is a core logic misrepresentation, constituting a hallucination. Since this is the only specific semantic detail given and it is incorrect, the proportion of inaccurate details exceeds 50%, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Writes commands to the Gen6 BSD ring, waits for it to become active with a timeout, then issues additional ring commands.",
            "score": [
                0.7333333333333334,
                0.6,
                0.5333333333333333
            ],
            "reason": [
                "The summary accurately notes that the function writes commands to the Gen6 BSD ring and waits for it to become active with a timeout, which matches the code's logic of writing to registers, using wait_for with a timeout, and then updating the tail. However, it inaccurately claims that additional ring commands are issued afterward; the code only updates the tail and restores ring idle messaging, with no other commands evident. This results in a mostly accurate but slightly overstated description.",
                "The summary correctly identifies that the function writes to the Gen6 BSD ring and waits for it to become active with a timeout, which matches the I915_WRITE calls and the wait_for logic in the code. However, it omits critical steps such as disabling and later re-enabling idle notifications, clearing the context ID, and posting a read after updating the tail. These omissions mean the accurate details do not fully capture the complete logic, especially the power management and sequence of operations present in the source code.",
                "The summary captures some aspects of the source code, such as writing commands to the Gen6 BSD ring and waiting for it to become active with a timeout, which are accurate. However, the claim about issuing additional ring commands beyond updating the tail is inaccurate, as the code only updates the tail and restores idle message settings, not any other commands. Since this single inaccuracy is less than half of the total details, the accurate portions are specific to the low-level power state handling and tail update, providing moderate domain value."
            ]
        }
    }
}
{
    "source_code": "int ata_qc_complete_multiple(struct ata_port *ap, u32 qc_active)\n{\n\tint nr_done = 0;\n\tu32 done_mask;\n\n\tdone_mask = ap->qc_active ^ qc_active;\n\n\tif (unlikely(done_mask & qc_active)) {\n\t\tata_port_err(ap, \"illegal qc_active transition (%08x->%08x)\\n\",\n\t\t\t     ap->qc_active, qc_active);\n\t\treturn -EINVAL;\n\t}\n\n\twhile (done_mask) {\n\t\tstruct ata_queued_cmd *qc;\n\t\tunsigned int tag = __ffs(done_mask);\n\n\t\tqc = ata_qc_from_tag(ap, tag);\n\t\tif (qc) {\n\t\t\tata_qc_complete(qc);\n\t\t\tnr_done++;\n\t\t}\n\t\tdone_mask &= ~(1 << tag);\n\t}\n\n\treturn nr_done;\n}",
    "comment": "Processes and completes multiple ATA queued commands based on the active command status while checking for illegal state transitions.",
    "prorec_sum": "Validates `qc_active` state transitions, logs illegal changes, and processes each newly activated device slot that meets readiness and capability checks.",
    "filter_prorec_sum": "Validates and processes changes in a qc_active bitmask, rejecting illegal transitions and invoking handlers for each newly activated queue context bit.",
    "prorec_aug_sum": "Validates and applies changes to a qc_active bitmask, rejecting illegal transitions and invoking handlers for each newly activated queue command.",
    "filter_prorec_aug_sum": "Validates and processes changes in a device\u2019s qc_active bitmask, logging illegal transitions and invoking handlers for newly activated command slots.",
    "work_score": {
        "prorec": {
            "summary": "Validates `qc_active` state transitions, logs illegal changes, and processes each newly activated device slot that meets readiness and capability checks.",
            "score": [
                0.4666666666666666,
                0.5,
                0.0
            ],
            "reason": [
                "The summary correctly notes that the function validates `qc_active` state transitions and logs illegal changes, which is supported by the presence of the `if (unlikely(...))` block and `ata_port_err` call. However, the claim that it processes each newly activated device slot with readiness and capability checks is inaccurate; the source code processes completed queued commands by iterating through `done_mask` and calling `ata_qc_complete`, with no evidence of readiness or capability checks. Thus, there is a mix of accurate and inaccurate details.",
                "The summary correctly identifies that the function validates qc_active state transitions and logs illegal changes, which is explicitly shown by the check using done_mask & qc_active and the ata_port_err logging. However, it inaccurately describes processing 'newly activated device slots' with 'readiness and capability checks'; the code instead processes completed commands based on tags without any readiness or capability verification. Significant aspects like looping through done_mask and calling ata_qc_complete are omitted in the accurate details, leaving the description incomplete regarding the main logic.",
                "The summary correctly mentions validating qc_active state transitions and logging illegal changes, which are explicitly seen in the source code through the comparison of ap->qc_active and qc_active and the ata_port_err call. However, it inaccurately claims processing of 'newly activated device slots' and checks for 'readiness and capability,' which are not present; the code instead processes completed commands via done_mask and ata_qc_complete without readiness/capability logic. More than half of the details are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Validates and processes changes in a qc_active bitmask, rejecting illegal transitions and invoking handlers for each newly activated queue context bit.",
            "score": [
                0.5,
                0.5,
                0.0
            ],
            "reason": [
                "The summary correctly notes validation of qc_active changes and rejection of illegal transitions, which is evident from the xor computation of done_mask and the conditional returning -EINVAL. However, it inaccurately describes invoking handlers for newly activated bits: the code instead processes completed commands where bits have transitioned from active to inactive. The term 'newly activated queue context bit' is a hallucination, as the function calls ata_qc_complete for completed commands. This results in less than half of the details being accurate.",
                "The summary inaccurately describes the processing of 'newly activated' bits, whereas the source code handles bits changing from active to inactive (completion). It correctly notes validation of qc_active transitions and rejection of illegal ones, but misstates the handler purpose, as the function calls completion routines for finished queued commands, not activation handlers. The remaining accurate detail covers only part of the logic, missing error handling specifics and iteration over completed commands.",
                "The summary contains inaccuracies: while it correctly mentions validation of qc_active bitmask changes and rejection of illegal transitions, it falsely describes invoking handlers for newly activated bits. The source code instead processes completed (done) commands, not newly activated ones. Over half of the details are inaccurate, triggering the kill switch due to the misleading nature of the summary."
            ]
        }
    }
}
{
    "source_code": "\nstatic bin_tree_t *\nparse_reg_exp (re_string_t *regexp, regex_t *preg, re_token_t *token,\n\t       reg_syntax_t syntax, Idx nest, reg_errcode_t *err)\n{\n  re_dfa_t *dfa = preg->buffer;\n  bin_tree_t *tree, *branch = NULL;\n  bitset_word_t initial_bkref_map = dfa->completed_bkref_map;\n  tree = parse_branch (regexp, preg, token, syntax, nest, err);\n  if (__glibc_unlikely (*err != REG_NOERROR && tree == NULL))\n    return NULL;\n\n  while (token->type == OP_ALT)\n    {\n      fetch_token (token, regexp, syntax | RE_CARET_ANCHORS_HERE);\n      if (token->type != OP_ALT && token->type != END_OF_RE\n\t  && (nest == 0 || token->type != OP_CLOSE_SUBEXP))\n\t{\n\t  bitset_word_t accumulated_bkref_map = dfa->completed_bkref_map;\n\t  dfa->completed_bkref_map = initial_bkref_map;\n\t  branch = parse_branch (regexp, preg, token, syntax, nest, err);\n\t  if (__glibc_unlikely (*err != REG_NOERROR && branch == NULL))\n\t    {\n\t      if (tree != NULL)\n\t\tpostorder (tree, free_tree, NULL);\n\t      return NULL;\n\t    }\n\t  dfa->completed_bkref_map |= accumulated_bkref_map;\n\t}\n      else\n\tbranch = NULL;\n      tree = create_tree (dfa, tree, branch, OP_ALT);\n      if (__glibc_unlikely (tree == NULL))\n\t{\n\t  *err = REG_ESPACE;\n\t  return NULL;\n\t}\n    }\n  return tree;\n}",
    "comment": "Parses a regular expression into a binary tree structure while managing alternative branches and backreference mapping.",
    "prorec_sum": "Processes and merges linked symbol data when a specific type code is encountered, invoking helper routines and updating link state fields accordingly.",
    "filter_prorec_sum": "Processes and links symbol or node data when a specific type flag is set, retrying lookups and merging results until conditions are met or errors occur.",
    "prorec_aug_sum": "Processes input records with type 10 by repeatedly invoking helper routines, caching state, merging results, and halting on errors indicated via the status pointer.",
    "filter_prorec_aug_sum": "Processes repeated 0x0A control codes in a data stream by invoking sub_475C40, updating state, merging results, and handling error conditions.",
    "work_score": {
        "prorec": {
            "summary": "Processes and merges linked symbol data when a specific type code is encountered, invoking helper routines and updating link state fields accordingly.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes processing and merging linked symbol data with type codes, helper routines, and link state updates, none of which appear in the source code. The code actually parses regular expressions, handles alternation tokens, manages back-reference maps, and builds parse trees. There is no evidence of linked symbol data or type code logic, resulting in all details being inaccurate.",
                "The summary claims the code processes and merges linked symbol data, handles specific type codes, invokes helper routines, and updates link state fields. None of these details are present in the source code, which instead parses regular expressions, handles alternation tokens, manages backreference maps, and performs error handling. All the summary's semantic points are inaccurate, leaving no accurate details to map to the source logic.",
                "The summary claims processing and merging of linked symbol data with specific type code handling, helper routine invocation, and link state updates, none of which have explicit evidence in the source code. The actual source code handles parsing of regular expressions via parse_branch, fetch_token, and create_tree, with alternate branch logic and bitset back-reference maps, not linked symbol data. All semantic details in the summary are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Processes and links symbol or node data when a specific type flag is set, retrying lookups and merging results until conditions are met or errors occur.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims processing and linking of symbol or node data based on a type flag, retrying lookups and merging results, but the source code instead shows parsing of regular expression branches, handling OP_ALT tokens, managing backreference maps, and creating a tree structure. None of the described semantic details in the summary are explicitly evidenced in the code, so all are hallucinations.",
                "The summary refers to processing and linking symbol or node data with specific type flags, retrying lookups, and merging results. None of these elements (symbols, lookups, type flags) are explicitly evident in the source code, which actually parses regular expression branches, handles alternation tokens, manipulates backreference maps, and performs error handling. As a result, the summary details are hallucinations and fail to capture any accurate semantic components of the code.",
                "The summary's claims about processing and linking symbol or node data with type flags, retrying lookups, and merging results are not explicitly supported in the source code. The code deals with parsing branches in a regular expression, handling OP_ALT tokens, managing backreference maps, and constructing a parse tree. Since none of the summary's details directly align with the actual operations in the code, all extracted details are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "static int\nefivar_create_sysfs_entry(struct efivar_entry *new_var)\n{\n\tint i, short_name_size;\n\tchar *short_name;\n\tunsigned long variable_name_size;\n\tefi_char16_t *variable_name;\n\n\tvariable_name = new_var->var.VariableName;\n\tvariable_name_size = ucs2_strlen(variable_name) * sizeof(efi_char16_t);\n\n\t/*\n\t * Length of the variable bytes in ASCII, plus the '-' separator,\n\t * plus the GUID, plus trailing NUL\n\t */\n\tshort_name_size = variable_name_size / sizeof(efi_char16_t)\n\t\t\t\t+ 1 + EFI_VARIABLE_GUID_LEN + 1;\n\n\tshort_name = kzalloc(short_name_size, GFP_KERNEL);\n\n\tif (!short_name)\n\t\treturn 1;\n\n\t/* Convert Unicode to normal chars (assume top bits are 0),\n\t   ala UTF-8 */\n\tfor (i=0; i < (int)(variable_name_size / sizeof(efi_char16_t)); i++) {\n\t\tshort_name[i] = variable_name[i] & 0xFF;\n\t}\n\t/* This is ugly, but necessary to separate one vendor's\n\t   private variables from another's.         */\n\n\t*(short_name + strlen(short_name)) = '-';\n\tefi_guid_unparse(&new_var->var.VendorGuid,\n\t\t\t short_name + strlen(short_name));\n\n\tnew_var->kobj.kset = efivars_kset;\n\n\ti = kobject_init_and_add(&new_var->kobj, &efivar_ktype,\n\t\t\t\t   NULL, \"%s\", short_name);\n\tkfree(short_name);\n\tif (i)\n\t\treturn 1;\n\n\tkobject_uevent(&new_var->kobj, KOBJ_ADD);\n\tefivar_entry_add(new_var, &efivar_sysfs_list);\n\n\treturn 0;\n}",
    "comment": "Creates a sysfs entry for a new EFI variable by converting its Unicode name to ASCII and adding it to the kernel's object hierarchy.",
    "prorec_sum": "Allocates and formats a buffer with device-specific data, updates control structures, and finalizes registration for an associated hardware component.",
    "filter_prorec_sum": "Allocates and formats a buffer with a driver-specific identifier, updates related state, invokes driver registration, and performs cleanup on failure.",
    "prorec_aug_sum": "Constructs a formatted identifier string from input data, updates related memory structures, invokes registration routines, and finalizes setup for the specified object.",
    "filter_prorec_aug_sum": "Allocates and initializes a data buffer, formats an identifier string, updates related state, and finalizes registration with a specified handler.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and formats a buffer with device-specific data, updates control structures, and finalizes registration for an associated hardware component.",
            "score": [
                0.26666666666666666,
                0.2333333333333333,
                0.0
            ],
            "reason": [
                "The summary contains vague and generic claims about device-specific data, control structures, and hardware component registration that are not explicitly supported by the source code. The code specifically deals with creating a sysfs entry for EFI variables, including Unicode to ASCII conversion, GUID formatting, kobject initialization, and sysfs list addition, but makes no direct reference to generic device data or hardware component registration. The lack of alignment between claimed details and explicit evidence results in a low accuracy ratio.",
                "The summary contains mostly inaccurate details: it refers to 'device-specific data' and 'hardware component', which are not explicitly indicated in the source code. The code deals with creating a sysfs entry for an EFI variable, formatting a short_name with variable name and GUID, and updating kernel object structures. While 'updates control structures' and 'finalizes registration' loosely match kobject initialization and uevent calls, the summary omits key logic like Unicode to ASCII conversion, memory allocation checks, and GUID handling, and misrepresents the context as hardware device-specific rather than EFI variables. The accurate parts do not form a complete picture of the code's logic.",
                "The summary claims allocation and formatting of a buffer with device-specific data, structure updates, and hardware component registration. While the source does allocate and format a buffer (short_name) and updates kobject structures before registration events, it makes no explicit mention of hardware components or device-specific data\u2014it operates on EFI variables in sysfs. These unsubstantiated hardware claims are inaccurate and comprise more than half of the details, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and formats a buffer with a driver-specific identifier, updates related state, invokes driver registration, and performs cleanup on failure.",
            "score": [
                0.4666666666666666,
                0.5666666666666667,
                0.0
            ],
            "reason": [
                "The summary contains some accurate elements, such as allocating and formatting a buffer and performing cleanup on failure, which match the use of kzalloc, setting up short_name, and kfree in the source. However, it introduces unverified assumptions: 'driver-specific identifier' is not explicit in the code, 'updates related state' is vague and not directly matched, and 'invokes driver registration' is inaccurate since the code uses kobject_init_and_add and kobject_uevent for sysfs and kobject handling, not driver registration. With mixed accuracy, fewer than half the details are explicitly supported by the source.",
                "The summary captures partial logic: allocation of a buffer and formatting a driver-specific identifier is accurate, as the code allocates `short_name` and formats it with variable name and GUID. Updating related state is partially accurate, since it sets `new_var->kobj.kset`. However, 'invokes driver registration' is inaccurate because the function performs kobject initialization, uevent signaling, and adds to a sysfs list, not a generic driver registration. 'Performs cleanup on failure' is accurate only for the cleanup of `short_name` after allocation failure or initialization failure. Significant details such as Unicode conversion, GUID formatting, and specific kobject/sysfs interactions are omitted, so the accurate content does not form a complete picture.",
                "The summary contains several inaccurate details: it mentions a 'driver-specific identifier' and 'driver registration' which are not explicitly evidenced in the source code. The code is in the kernel efivars context, formatting a short_name with a GUID, initializing a kobject, triggering a uevent, and adding to efivar list, but there is no explicit 'driver registration' call. While it does allocate and format a buffer, update state, and cleanup on failure, the proportion of inaccurate details exceeds 50%, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nvoid __cpuinit start_secondary(void)\n{\n\tunsigned int cpu;\n\tunsigned long thread_ptr;\n\n\t/*  Calculate thread_info pointer from stack pointer  */\n\t__asm__ __volatile__(\n\t\t\"%0 = SP;\\n\"\n\t\t: \"=r\" (thread_ptr)\n\t);\n\n\tthread_ptr = thread_ptr & ~(THREAD_SIZE-1);\n\n\t__asm__ __volatile__(\n\t\tQUOTED_THREADINFO_REG \" = %0;\\n\"\n\t\t:\n\t\t: \"r\" (thread_ptr)\n\t);\n\n\t/*  Set the memory struct  */\n\tatomic_inc(&init_mm.mm_count);\n\tcurrent->active_mm = &init_mm;\n\n\tcpu = smp_processor_id();\n\n\tsetup_irq(BASE_IPI_IRQ + cpu, &ipi_intdesc);\n\n\t/*  Register the clock_event dummy  */\n\tsetup_percpu_clockdev();\n\n\tprintk(KERN_INFO \"%s cpu %d\\n\", __func__, current_thread_info()->cpu);\n\n\tnotify_cpu_starting(cpu);\n\n\tset_cpu_online(cpu, true);\n\n\tlocal_irq_enable();\n\n\tcpu_startup_entry(CPUHP_ONLINE);\n}",
    "comment": "Initializes the secondary CPU by configuring memory management, enabling interrupts, and signaling readiness for operation within a multiprocessor environment.",
    "prorec_sum": "Initializes a newly started CPU in an SMP system, synchronizing its state, setting up handlers, and enabling interrupts before entering operation.",
    "filter_prorec_sum": "Initializes and synchronizes an x86 CPU during SMP startup, setting processor state, running setup routines, and enabling interrupts before entering operation.",
    "prorec_aug_sum": "Initializes a secondary CPU during SMP startup, synchronizing with other cores, setting per\u2011CPU structures, and enabling interrupts before entering normal operation.",
    "filter_prorec_aug_sum": "Initializes a secondary CPU during SMP startup, performing synchronization, hardware setup, timekeeping, and enabling interrupts before entering normal operation.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a newly started CPU in an SMP system, synchronizing its state, setting up handlers, and enabling interrupts before entering operation.",
            "score": [
                0.8333333333333334,
                0.6333333333333333,
                0.6666666666666666
            ],
            "reason": [
                "The summary accurately describes that the function initializes a newly started CPU in an SMP system, sets up IRQ handlers, enables interrupts, and transitions it into operation. These actions are explicitly evidenced in the source code by calls such as `setup_irq`, `setup_percpu_clockdev`, `local_irq_enable`, and `cpu_startup_entry`. No unverified assumptions or hallucinations are present, and all details correspond directly to the logic in the code.",
                "The summary correctly captures the overall purpose of initializing a secondary CPU in an SMP system, which aligns with explicit operations in the code such as setting memory structs, setting up IRQ handlers, enabling interrupts, and entering the startup loop. However, it omits several critical details, including calculating the thread_info pointer from the stack, registering a dummy clock event device, and specific calls to functions like notify_cpu_starting and set_cpu_online. This results in a partial picture of the code's logic rather than full coverage.",
                "The summary accurately captures that the function initializes a CPU in an SMP context, sets up handlers, enables interrupts, and transitions to operational state. All mentioned details are supported by explicit code evidence: `setup_irq` and `setup_percpu_clockdev` for handler setup, `local_irq_enable` for enabling interrupts, and `cpu_startup_entry` signaling entry into operation. No claims in the summary are inaccurate, but the description remains somewhat generic, lacking direct reference to specific code entities or data manipulations such as `thread_ptr` calculation and `init_mm` handling."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes and synchronizes an x86 CPU during SMP startup, setting processor state, running setup routines, and enabling interrupts before entering operation.",
            "score": [
                0.4333333333333333,
                0.5,
                0.0
            ],
            "reason": [
                "The summary claims x86-specific CPU initialization and synchronization during SMP startup, but the source code does not indicate architecture-specifics like x86; it shows generic CPU startup for secondary processors. While enabling interrupts and running setup routines before entering normal operation is accurate, the mention of x86 and SMP synchronization is unverified from the code. This results in a mix of accurate and inaccurate details, with the architecture claim being a clear hallucination.",
                "The summary claims x86-specific CPU initialization, synchronization, and SMP startup, but the source code does not indicate x86 architecture explicitly. While it does perform secondary CPU initialization in SMP context\u2014calculating thread_info from SP, setting active_mm, setting up IRQ and per-CPU devices, enabling interrupts, and entering cpu_startup_entry\u2014these are architecture-neutral in the given snippet. The architecture claim is inaccurate, but the core logic of preparing a CPU, enabling interrupts, and entering its main loop is correctly described, covering the main actions but lacking detail on data manipulations and specific setup calls present in the code.",
                "The summary claims the code is for x86 CPU initialization during SMP startup, but there is no explicit evidence in the source code indicating x86 architecture; the function and macros are generic or architecture-specific but not labeled as x86. While it correctly notes setting processor state, running setup routines, and enabling interrupts, the SMP-specific and architecture claim is unsupported. More than half of the details (x86 reference, synchronization aspect) are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic acpi_status acpi_dev_process_resource(struct acpi_resource *ares,\n\t\t\t\t\t     void *context)\n{\n\tstruct res_proc_context *c = context;\n\tstruct resource r;\n\tint i;\n\n\tif (c->preproc) {\n\t\tint ret;\n\n\t\tret = c->preproc(ares, c->preproc_data);\n\t\tif (ret < 0) {\n\t\t\tc->error = ret;\n\t\t\treturn AE_CTRL_TERMINATE;\n\t\t} else if (ret > 0) {\n\t\t\treturn AE_OK;\n\t\t}\n\t}\n\n\tmemset(&r, 0, sizeof(r));\n\n\tif (acpi_dev_resource_memory(ares, &r)\n\t    || acpi_dev_resource_io(ares, &r)\n\t    || acpi_dev_resource_address_space(ares, &r)\n\t    || acpi_dev_resource_ext_address_space(ares, &r))\n\t\treturn acpi_dev_new_resource_entry(&r, c);\n\n\tfor (i = 0; acpi_dev_resource_interrupt(ares, i, &r); i++) {\n\t\tacpi_status status;\n\n\t\tstatus = acpi_dev_new_resource_entry(&r, c);\n\t\tif (ACPI_FAILURE(status))\n\t\t\treturn status;\n\t}\n\n\treturn AE_OK;\n}",
    "comment": "Processes ACPI resources by calling preprocessing functions, handling memory, I/O, and address space resources, and creating new resource entries as needed.",
    "prorec_sum": "Processes an input structure through a sequence of handler functions, invoking a target operation for each matching case and returning the first non\u2011zero result.",
    "filter_prorec_sum": "Processes ACPI operand data into a temporary package structure and dispatches it through sub_FFFFFFFF81302180 for final handling based on operand type.",
    "prorec_aug_sum": "Processes an input object through a sequence of handler and subtype functions, invoking a target operation for matching types and iterating over multiple indexed elements.",
    "filter_prorec_aug_sum": "Processes an ACPI region object by invoking its handler or iterating subfields, then dispatches them to a common processing routine with supplied parameters.",
    "work_score": {
        "prorec": {
            "summary": "Processes an input structure through a sequence of handler functions, invoking a target operation for each matching case and returning the first non\u2011zero result.",
            "score": [
                0.3,
                0.3,
                0.0
            ],
            "reason": [
                "The summary claims a generic process of invoking a target operation for each matching case and returning the first non\u2011zero result. While the source code does process an input structure through multiple resource handler functions, it does not explicitly 'return the first non\u2011zero result' across all handlers; instead, it calls different functions conditionally, may terminate early only in the preproc stage based on the ret value, and returns AE_OK at the end. Key details like the specific set of handler function calls (acpi_dev_resource_memory, acpi_dev_resource_io, etc.) and loop over interrupts are omitted, making the description overly generic and lacking explicit verification. Accurate details are minimal, resulting in a low accuracy ratio.",
                "The summary makes only a vague claim about processing an input structure through several handlers and returning the first non-zero result. While the code does call multiple resource handler functions and returns early in some conditions, the summary omits critical details such as the preproc check with specific return value handling, zeroing of the resource structure, the exact sequence of resource type checks, and the interrupt loop with error handling. The description is overly abstract and misses the majority of the core logic, so the covered details do not form a complete picture of the code\u2019s behavior.",
                "The summary inaccurately claims that the function returns the first non-zero result, which is not supported by the source code \u2014 the code only returns early in specific conditional cases (negative ret, positive ret, or certain resource matches) and processes multiple resources sequentially. While it correctly notes processing through handler functions, it omits key specifics such as the use of specialized ACPI resource functions and context handling. Inaccurate details exceed 50%, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Processes ACPI operand data into a temporary package structure and dispatches it through sub_FFFFFFFF81302180 for final handling based on operand type.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims that the function processes ACPI operand data into a temporary package structure and uses a specific function (sub_FFFFFFFF81302180) for final handling based on operand type. These details are unsupported by the source code, which instead shows processing of ACPI resources using functions like acpi_dev_resource_memory, acpi_dev_resource_io, and acpi_dev_new_resource_entry. There is no mention of operand data, package structures, or the cited function, making all stated details hallucinations.",
                "The summary's claim about processing ACPI operand data into a temporary package and dispatching via sub_FFFFFFFF81302180 is unsupported by the source code. The code handles ACPI resource processing through functions like acpi_dev_resource_memory, acpi_dev_resource_io, and acpi_dev_new_resource_entry, with no mention of operand types or the sub_FFFFFFFF81302180 function. All details in the summary are hallucinations, leaving no accurate content to map to the code's logic.",
                "The summary claims that the function processes ACPI operand data into a temporary package structure and dispatches it through 'sub_FFFFFFFF81302180' based on operand type, but none of these details are present in the source code. The source code processes ACPI resources through various 'acpi_dev_resource_*' functions and passes them to 'acpi_dev_new_resource_entry', with no mention of operand data, package structures, or the named sub-function. All semantic details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nvoid native_play_dead(void)\n{\n\tplay_dead_common();\n\ttboot_shutdown(TB_SHUTDOWN_WFS);\n\n\tmwait_play_dead();\t/* Only returns on failure */\n\tif (cpuidle_play_dead())\n\t\thlt_play_dead();\n}",
    "comment": "Initiates a shutdown sequence and enters a low-power state, managing transitions based on CPU idle status and system power states.",
    "prorec_sum": "Initializes CPU idle monitoring and mwait parameters, flushes caches, and enters a wait loop until a wake condition or bug check triggers a system halt.",
    "filter_prorec_sum": "Initializes CPU idle state monitoring by checking system flags, retrieving CPUID data, and executing cache flush and wait instructions until a wake condition occurs.",
    "prorec_aug_sum": "Enters a CPU idle loop using MONITOR/MWAIT based on CPUID-detected parameters, flushing caches, and halts if specific GS-segment status conditions are met.",
    "filter_prorec_aug_sum": "Implements the CPU idle routine using monitor/mwait instructions, flushing caches, and halting when specific processor and system state conditions are met.",
    "work_score": {
        "prorec": {
            "summary": "Initializes CPU idle monitoring and mwait parameters, flushes caches, and enters a wait loop until a wake condition or bug check triggers a system halt.",
            "score": [
                0.03333333333333333,
                0.03333333333333333,
                0.0
            ],
            "reason": [
                "The summary describes CPU idle monitoring initialization, mwait parameter setup, cache flushing, and a conditional wake loop with bug check and system halt. None of these specifics are directly evidenced in the source code. The code only calls functions like play_dead_common(), tboot_shutdown(), mwait_play_dead(), cpuidle_play_dead(), and hlt_play_dead(), without explicit references to cache flushing, CPU idle monitoring initialization, or bug check logic. All summary details are unverified, making the content dominated by hallucinations.",
                "The summary contains multiple inaccuracies. The source code only calls play_dead_common(), tboot_shutdown(TB_SHUTDOWN_WFS), mwait_play_dead(), and conditionally cpuidle_play_dead() followed by hlt_play_dead(). There is no explicit evidence of CPU idle monitoring initialization, mwait parameter setup, cache flushing, or a wake loop with bug check handling. After discarding these hallucinations, no accurate details remain that map to the code\u2019s actual logic.",
                "The summary claims actions such as initializing CPU idle monitoring, setting mwait parameters, flushing caches, and handling wake conditions or bug checks, none of which are explicitly shown in the source code. The source only calls specific functions like play_dead_common, tboot_shutdown, mwait_play_dead, cpuidle_play_dead, and hlt_play_dead. Since more than half of the claimed details are not evidenced, the summary contains a majority of inaccuracies."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes CPU idle state monitoring by checking system flags, retrieving CPUID data, and executing cache flush and wait instructions until a wake condition occurs.",
            "score": [
                0.06666666666666667,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims CPU idle state monitoring, checking system flags, retrieving CPUID data, and executing cache flush instructions, none of which are explicitly present in the source code. The code only calls functions such as play_dead_common(), tboot_shutdown(), mwait_play_dead(), cpuidle_play_dead(), and hlt_play_dead(), with no evidence of system flag checks, CPUID retrieval, or cache-related instructions. All details in the summary are therefore hallucinations, resulting in no accurate matches.",
                "The summary contains multiple inaccuracies: it mentions CPU idle state monitoring, checking system flags, retrieving CPUID data, and executing cache flush and wait instructions, none of which are explicitly present in the source code. The code simply calls functions `play_dead_common()`, `tboot_shutdown(TB_SHUTDOWN_WFS)`, `mwait_play_dead()`, checks `cpuidle_play_dead()`, and possibly calls `hlt_play_dead()`. There is no evidence of system flag checks, CPUID retrieval, or cache operations, leaving no accurate semantic details to map to the code's logic.",
                "The summary claims initialization of CPU idle state monitoring, checking system flags, retrieving CPUID data, and executing cache flush operations, none of which are explicitly present in the source code. The code only invokes functions related to 'play_dead' behavior (play_dead_common, tboot_shutdown, mwait_play_dead, cpuidle_play_dead, hlt_play_dead), with no evidence of cache flushing, CPUID retrieval, or specific flag checks. All described details are inaccurate, exceeding the 50% threshold."
            ]
        }
    }
}
{
    "source_code": "static int apply_envelope(struct ml_effect_state *state, int value,\n\t\t\t  struct ff_envelope *envelope)\n{\n\tstruct ff_effect *effect = state->effect;\n\tunsigned long now = jiffies;\n\tint time_from_level;\n\tint time_of_envelope;\n\tint envelope_level;\n\tint difference;\n\n\tif (envelope->attack_length &&\n\t    time_before(now,\n\t\t\tstate->play_at + msecs_to_jiffies(envelope->attack_length))) {\n\t\tpr_debug(\"value = 0x%x, attack_level = 0x%x\\n\",\n\t\t\t value, envelope->attack_level);\n\t\ttime_from_level = jiffies_to_msecs(now - state->play_at);\n\t\ttime_of_envelope = envelope->attack_length;\n\t\tenvelope_level = min_t(u16, envelope->attack_level, 0x7fff);\n\n\t} else if (envelope->fade_length && effect->replay.length &&\n\t\t   time_after(now,\n\t\t\t      state->stop_at - msecs_to_jiffies(envelope->fade_length)) &&\n\t\t   time_before(now, state->stop_at)) {\n\t\ttime_from_level = jiffies_to_msecs(state->stop_at - now);\n\t\ttime_of_envelope = envelope->fade_length;\n\t\tenvelope_level = min_t(u16, envelope->fade_level, 0x7fff);\n\t} else\n\t\treturn value;\n\n\tdifference = abs(value) - envelope_level;\n\n\tpr_debug(\"difference = %d\\n\", difference);\n\tpr_debug(\"time_from_level = 0x%x\\n\", time_from_level);\n\tpr_debug(\"time_of_envelope = 0x%x\\n\", time_of_envelope);\n\n\tdifference = difference * time_from_level / time_of_envelope;\n\n\tpr_debug(\"difference = %d\\n\", difference);\n\n\treturn value < 0 ?\n\t\t-(difference + envelope_level) : (difference + envelope_level);\n}",
    "comment": "Adjusts the input value based on an attack or fade envelope, modifying the output according to the elapsed time and specified envelope levels.",
    "prorec_sum": "Scales the given signed value toward a target limit based on buffer usage thresholds and parameters from the provided 16\u2011bit input array.",
    "filter_prorec_sum": "Computes and returns an adjusted signed value based on input magnitude, limits, and scaling factors when certain word-sized thresholds are exceeded.",
    "prorec_aug_sum": "Computes and returns a scaled integer value based on input parameters and resource limits, using conditional checks and adjustment factors.",
    "filter_prorec_aug_sum": "Computes and returns an adjusted integer value based on input parameters, constrained by threshold checks and scaled proportionally using computed difference ratios.",
    "work_score": {
        "prorec": {
            "summary": "Scales the given signed value toward a target limit based on buffer usage thresholds and parameters from the provided 16\u2011bit input array.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims scaling toward a target limit based on buffer usage thresholds and parameters from a 16\u2011bit input array, but the source code shows scaling based on envelope timing (attack/fade lengths) and levels. There is no mention of buffer usage thresholds or a 16\u2011bit input array structure in the code. All described details are inaccurate because they do not match explicit elements in the function, resulting in no accurate matches.",
                "The summary mentions buffer usage thresholds and parameters from a 16\u2011bit input array, but the source code makes no reference to buffers or input arrays. The function instead adjusts a signed value based on attack and fade envelope parameters, using timing calculations from jiffies and specific envelope levels, which are not captured in the summary. All details in the summary are inaccurate given the code, leaving no accurate content to map to the logic.",
                "The summary claims scaling of a signed value based on buffer usage thresholds and parameters from a 16-bit input array, but the source code instead applies envelope attack/fade logic using struct fields (attack_length, attack_level, fade_length, fade_level) without any mention of buffer usage or an input array. All semantic details are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Computes and returns an adjusted signed value based on input magnitude, limits, and scaling factors when certain word-sized thresholds are exceeded.",
            "score": [
                0.3,
                0.23333333333333336,
                0.0
            ],
            "reason": [
                "The summary is largely inaccurate because it introduces concepts like 'word-sized thresholds' and 'limits' that are not evidenced in the source code. The code adjusts the input value based on attack and fade envelope parameters, using jiffies timing and minimum value constraints, not explicitly 'word-sized thresholds.' While it is correct that the function computes and returns an adjusted signed value, most of the described details in the summary are unsupported, resulting in less than half of the details being accurate.",
                "The summary is largely inaccurate as it does not reference any concrete elements from the source code such as the handling of 'attack_length', 'fade_length', 'jiffies', or the conditional checks with 'time_before'/'time_after'. The mention of 'word-sized thresholds' and generic scaling factors is vague and not explicitly evidenced in the code. As a result, after discarding the inaccurate parts, there is no substantive accurate content left to map to the core logic.",
                "The summary's claim about 'word-sized thresholds' and 'limits' is inaccurate, as the source code operates with attack_length, fade_length, time calculations, and clamps values to 0x7fff (a u16 max), rather than any explicit word-sized threshold checks. It omits key domain-specific details such as handling of jiffies timing, envelope attack/fade logic, and use of min_t with u16 types. The only partially accurate part is that the function returns an adjusted signed value based on scaling, but the majority of semantic claims are unsupported, exceeding the 50% inaccuracy threshold."
            ]
        }
    }
}
{
    "source_code": "\nvoid write_xattr(char *pathname, unsigned int xattr)\n{\n\tunsigned int count;\n\tstruct xattr_list *xattr_list;\n\tint i;\n\tstatic int nonsuper_error = FALSE;\n\tstatic int ignore_xattrs = FALSE;\n\tstatic int nospace_error = 0;\n\n\tif(ignore_xattrs || xattr == SQUASHFS_INVALID_XATTR ||\n\t\t\tsBlk.s.xattr_id_table_start == SQUASHFS_INVALID_BLK)\n\t\treturn;\n\n\txattr_list = get_xattr(xattr, &count, 1);\n\tif(xattr_list == NULL) {\n\t\tERROR(\"Failed to read xattrs for file %s\\n\", pathname);\n\t\treturn;\n\t}\n\n\tfor(i = 0; i < count; i++) {\n\t\tint prefix = xattr_list[i].type & SQUASHFS_XATTR_PREFIX_MASK;\n\n\t\tif(user_xattrs && prefix != SQUASHFS_XATTR_USER)\n\t\t\tcontinue;\n\n\t\tif(root_process || prefix == SQUASHFS_XATTR_USER) {\n\t\t\tint res = lsetxattr(pathname, xattr_list[i].full_name,\n\t\t\t\txattr_list[i].value, xattr_list[i].vsize, 0);\n\n\t\t\tif(res == -1) {\n\t\t\t\tif(errno == ENOTSUP) {\n\t\t\t\t\t/*\n\t\t\t\t\t * If the destination filesystem cannot\n\t\t\t\t\t * suppport xattrs, print error, and\n\t\t\t\t\t * disable xattr output as this error is\n\t\t\t\t\t * unlikely to go away, and printing\n\t\t\t\t\t * screenfulls of the same error message\n\t\t\t\t\t * is rather annoying\n\t\t\t\t\t */\n\t\t\t\t\tERROR(\"write_xattr: failed to write \"\n\t\t\t\t\t\t\"xattr %s for file %s because \" \n\t\t\t\t\t\t\"extended attributes are not \"\n\t\t\t\t\t\t\"supported by the destination \"\n\t\t\t\t\t\t\"filesystem\\n\",\n\t\t\t\t\t\txattr_list[i].full_name,\n\t\t\t\t\t\tpathname);\n\t\t\t\t\tERROR(\"Ignoring xattrs in \"\n\t\t\t\t\t\t\t\t\"filesystem\\n\");\n\t\t\t\t\tERROR(\"To avoid this error message, \"\n\t\t\t\t\t\t\"specify -no-xattrs\\n\");\n\t\t\t\t\tignore_xattrs = TRUE;\n\t\t\t\t} else if((errno == ENOSPC || errno == EDQUOT)\n\t\t\t\t\t\t&& nospace_error < NOSPACE_MAX) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Many filesystems like ext2/3/4 have\n\t\t\t\t\t * limits on the amount of xattr\n\t\t\t\t\t * data that can be stored per file\n\t\t\t\t\t * (typically one block or 4K), so\n\t\t\t\t\t * we shouldn't disable xattr ouput,\n\t\t\t\t\t * as the error may be restriced to one\n\t\t\t\t\t * file only.  If we get a lot of these\n\t\t\t\t\t * then suppress the error messsage\n\t\t\t\t\t */\n\t\t\t\t\tERROR(\"write_xattr: failed to write \"\n\t\t\t\t\t\t\"xattr %s for file %s because \" \n\t\t\t\t\t\t\"no extended attribute space \"\n\t\t\t\t\t\t\"remaining (per file or \"\n\t\t\t\t\t\t\"filesystem limit)\\n\",\n\t\t\t\t\t\txattr_list[i].full_name,\n\t\t\t\t\t\tpathname);\n\t\t\t\t\tif(++ nospace_error == NOSPACE_MAX)\n\t\t\t\t\t\tERROR(\"%d of these errors \"\n\t\t\t\t\t\t\t\"printed, further error \"\n\t\t\t\t\t\t\t\"messages of this type \"\n\t\t\t\t\t\t\t\"are suppressed!\\n\",\n\t\t\t\t\t\t\tNOSPACE_MAX);\n\t\t\t\t} else\n\t\t\t\t\tERROR(\"write_xattr: failed to write \"\n\t\t\t\t\t\t\"xattr %s for file %s because \"\n\t\t\t\t\t\t\"%s\\n\", xattr_list[i].full_name,\n\t\t\t\t\t\tpathname, strerror(errno));\n\t\t\t}\n\t\t} else if(nonsuper_error == FALSE) {\n\t\t\t/*\n\t\t\t * if extract user xattrs only then\n\t\t\t * error message is suppressed, if not\n\t\t\t * print error, and then suppress further error\n\t\t\t * messages to avoid possible screenfulls of the\n\t\t\t * same error message!\n\t\t\t */\n\t\t\tERROR(\"write_xattr: could not write xattr %s \"\n\t\t\t\t\t\"for file %s because you're not \"\n\t\t\t\t\t\"superuser!\\n\",\n\t\t\t\t\txattr_list[i].full_name, pathname);\n\t\t\tERROR(\"write_xattr: to avoid this error message, either\"\n\t\t\t\t\" specify -user-xattrs, -no-xattrs, or run as \"\n\t\t\t\t\"superuser!\\n\");\n\t\t\tERROR(\"Further error messages of this type are \"\n\t\t\t\t\"suppressed!\\n\");\n\t\t\tnonsuper_error = TRUE;\n\t\t}\n\t}\n\n\tfree_xattr(xattr_list, count);\n}",
    "comment": "Writes extended attributes to a specified file while handling errors for unsupported filesystems, space limitations, and non-superuser access.",
    "prorec_sum": "Sets multiple extended attributes on the specified filesystem path, handling specific error codes and tracking repeated failures with global state variables.",
    "filter_prorec_sum": "Sets extended file attributes from a retrieved metadata list onto the given path, handling specific errno conditions and updating related global status flags.",
    "prorec_aug_sum": "Sets multiple extended file attributes on the given path from a descriptor, handling specific error codes and updating related global state flags.",
    "filter_prorec_aug_sum": "Sets multiple extended file attributes on the given path from descriptor data, handling specific errno cases and maintaining related global error state flags.",
    "work_score": {
        "prorec": {
            "summary": "Sets multiple extended attributes on the specified filesystem path, handling specific error codes and tracking repeated failures with global state variables.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6333333333333333
            ],
            "reason": [
                "The summary correctly states that the function sets multiple extended attributes on a filesystem path and handles specific error codes, which is evident from the loop iterating over `xattr_list` and conditional checks on `errno`. It also accurately notes tracking repeated failures using global state variables like `ignore_xattrs`, `nospace_error`, and `nonsuper_error`. There are no unsupported or fabricated claims, and all mentioned details are explicitly supported by the source code.",
                "The summary accurately states that the function sets multiple extended attributes on a specified filesystem path and handles specific error codes, as evidenced by the loop over xattr_list entries and checks against errno values like ENOTSUP, ENOSPC, and EDQUOT. It also correctly notes the tracking of repeated failures with global state variables such as ignore_xattrs, nospace_error, and nonsuper_error. However, it omits important control flow details, such as filtering by xattr type/prefix, conditions for skipping attributes, and the suppression of further error messages, which reduces completeness.",
                "The summary correctly states that the function sets multiple extended attributes on a given filesystem path and handles specific error codes while tracking repeated failures via global/static variables. These points are explicitly supported by the source code through loops over xattr_list, use of lsetxattr, and handling of ENOTSUP, ENOSPC, EDQUOT with counters like nospace_error and flags like ignore_xattrs and nonsuper_error. Although the summary is general, all details are accurate and grounded in the code, but it lacks deeper domain-specific insights such as mentioning specific prefix filtering or conditions for applying attributes."
            ]
        },
        "filter_prorec": {
            "summary": "Sets extended file attributes from a retrieved metadata list onto the given path, handling specific errno conditions and updating related global status flags.",
            "score": [
                1.0,
                0.6999999999999998,
                0.6333333333333333
            ],
            "reason": [
                "The summary correctly captures that the function sets extended file attributes from a retrieved list, applies them to a given path, and handles specific errno codes while updating global flags such as ignore_xattrs and nonsuper_error. All these elements are explicitly present in the source code, indicating no unverified assumptions or missing core details in the described behavior.",
                "The summary correctly states that the function sets extended file attributes from a retrieved list for a given pathname, handles specific errno conditions, and updates global status flags. These elements are explicitly supported by the source code: attributes are written via lsetxattr, errno cases like ENOTSUP and ENOSPC are addressed, and global flags ignore_xattrs, nospace_error, and nonsuper_error are updated accordingly. However, the summary omits control flow details such as conditions for user_xattrs, root_process, and suppression of repeated error messages, meaning it does not capture the full code logic.",
                "The summary accurately reflects core functionality: applying extended attributes from retrieved metadata to a specified path, handling different errno cases, and toggling global status flags such as ignore_xattrs and nonsuper_error. While generic, these elements are explicitly present in the source code. No inaccurate or hallucinated details are found, but the description lacks deeper specifics like conditional handling based on xattr prefixes, suppression rules, and specific errno constants, making the insights less domain-rich."
            ]
        }
    }
}
{
    "source_code": "static void __synchronize_srcu(struct srcu_struct *sp, int trycount)\n{\n\tstruct rcu_synchronize rcu;\n\tstruct rcu_head *head = &rcu.head;\n\tbool done = false;\n\n\trcu_lockdep_assert(!lock_is_held(&sp->dep_map) &&\n\t\t\t   !lock_is_held(&rcu_bh_lock_map) &&\n\t\t\t   !lock_is_held(&rcu_lock_map) &&\n\t\t\t   !lock_is_held(&rcu_sched_lock_map),\n\t\t\t   \"Illegal synchronize_srcu() in same-type SRCU (or RCU) read-side critical section\");\n\n\tmight_sleep();\n\tinit_completion(&rcu.completion);\n\n\thead->next = NULL;\n\thead->func = wakeme_after_rcu;\n\tspin_lock_irq(&sp->queue_lock);\n\tif (!sp->running) {\n\t\t/* steal the processing owner */\n\t\tsp->running = true;\n\t\trcu_batch_queue(&sp->batch_check0, head);\n\t\tspin_unlock_irq(&sp->queue_lock);\n\n\t\tsrcu_advance_batches(sp, trycount);\n\t\tif (!rcu_batch_empty(&sp->batch_done)) {\n\t\t\tBUG_ON(sp->batch_done.head != head);\n\t\t\trcu_batch_dequeue(&sp->batch_done);\n\t\t\tdone = true;\n\t\t}\n\t\t/* give the processing owner to work_struct */\n\t\tsrcu_reschedule(sp);\n\t} else {\n\t\trcu_batch_queue(&sp->batch_queue, head);\n\t\tspin_unlock_irq(&sp->queue_lock);\n\t}\n\n\tif (!done)\n\t\twait_for_completion(&rcu.completion);\n}",
    "comment": "Synchronizes SRCU processing by queuing a completion task and waiting for it to finish if not already done by the processing owner.",
    "prorec_sum": "Initializes synchronization structures, enables interrupts, and invokes processing routines to update state using provided parameters and linked list management.",
    "filter_prorec_sum": "Initializes lock-related state, updates linked structures, enables interrupts, and dispatches processing with provided parameters based on current pointer and flag conditions.",
    "prorec_aug_sum": "Initializes internal state, links queue structures, enables interrupts, and dispatches further processing based on provided parameters and structure pointers.",
    "filter_prorec_aug_sum": "Initializes and links internal queue structures, enables interrupts, and dispatches processing based on provided parameters and a1\u2019s linked list state.",
    "work_score": {
        "prorec": {
            "summary": "Initializes synchronization structures, enables interrupts, and invokes processing routines to update state using provided parameters and linked list management.",
            "score": [
                0.39999999999999997,
                0.46666666666666673,
                0.0
            ],
            "reason": [
                "The summary claims enabling interrupts and using linked list management, but the source code contains no explicit interrupt enabling functions and does not show generic linked list operations\u2014only specific RCU batch queue handling. While it correctly notes initialization of synchronization structures and invocation of processing routines with parameters, over half of the described details are unsupported, leading to mixed accuracy.",
                "The summary accurately notes initialization of synchronization structures, which is evidenced by 'init_completion(&rcu.completion)' and initialization of 'head'. However, it incorrectly claims that interrupts are enabled, which is not present in the code; in fact, the code uses 'spin_lock_irq' which disables interrupts. It also generically mentions linked list management without explicitly connecting to the batch queue operations in the source. As a result, only a small portion of the summary is accurate, and it omits significant control flow and error handling details present in the code.",
                "The summary claims that the code enables interrupts, which is inaccurate as the function uses spin_lock_irq and spin_unlock_irq but does not explicitly enable interrupts; it also mentions linked list management without explicit evidence in the source code. While it correctly notes initialization of synchronization structures (init_completion) and invocation of processing routines (srcu_advance_batches, rcu_batch_queue), more than half of the stated details are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes lock-related state, updates linked structures, enables interrupts, and dispatches processing with provided parameters based on current pointer and flag conditions.",
            "score": [
                0.39999999999999997,
                0.43333333333333335,
                0.0
            ],
            "reason": [
                "The summary makes broad claims such as 'initializes lock-related state', 'updates linked structures', 'enables interrupts', and 'dispatches processing based on pointer and flag conditions'. While initialization of lock-related state and linked structures is supported by evidence in the code (e.g., rcu_lockdep_assert, init_completion, head->next assignment), there is no indication in the source that interrupts are explicitly enabled, making that claim inaccurate. The rest of the statements are overly generic and fail to match specific function names or logic structure from the code. Overall, only some details align with the source, resulting in mixed accuracy.",
                "The summary vaguely mentions initializing lock-related state, updating linked structures, enabling interrupts, and dispatching processing based on conditions. While the code does initialize completion structures, manipulate linked list pointers (`head->next`, `head->func`), and perform conditional dispatch via queues, there is no explicit action in the source code that 'enables interrupts'. The summary omits critical details such as the specific assertion checks via `rcu_lockdep_assert`, the conditional ownership transfer (`sp->running` logic), and the waiting for completion. The accurate parts capture only a fraction of the logic, missing key control flow and error handling, so the coverage is incomplete.",
                "The summary claims interrupt enabling, which is not evidenced in the source code, and omits key specifics such as the use of spin locks, RCU batch queueing, completion mechanisms, and conditional logic based on 'sp->running'. Most details are either generic or inaccurate, with more than half lacking explicit support in the source code, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nint kernel_ident_mapping_init(struct x86_mapping_info *info, pgd_t *pgd_page,\n\t\t\t      unsigned long addr, unsigned long end)\n{\n\tunsigned long next;\n\tint result;\n\tint off = info->kernel_mapping ? pgd_index(__PAGE_OFFSET) : 0;\n\n\tfor (; addr < end; addr = next) {\n\t\tpgd_t *pgd = pgd_page + pgd_index(addr) + off;\n\t\tpud_t *pud;\n\n\t\tnext = (addr & PGDIR_MASK) + PGDIR_SIZE;\n\t\tif (next > end)\n\t\t\tnext = end;\n\n\t\tif (pgd_present(*pgd)) {\n\t\t\tpud = pud_offset(pgd, 0);\n\t\t\tresult = ident_pud_init(info, pud, addr, next);\n\t\t\tif (result)\n\t\t\t\treturn result;\n\t\t\tcontinue;\n\t\t}\n\n\t\tpud = (pud_t *)info->alloc_pgt_page(info->context);\n\t\tif (!pud)\n\t\t\treturn -ENOMEM;\n\t\tresult = ident_pud_init(info, pud, addr, next);\n\t\tif (result)\n\t\t\treturn result;\n\t\tset_pgd(pgd, __pgd(__pa(pud) | _KERNPG_TABLE));\n\t}\n\n\treturn 0;\n}",
    "comment": "Initializes kernel identity mapping by setting up page entries in the page global directory for the specified address range, allocating pages as needed.",
    "prorec_sum": "Maps a range of IO virtual addresses to physical memory pages, allocating new mappings when absent and delegating page-level handling to a helper function.",
    "filter_prorec_sum": "Maps a virtual address range to physical memory, allocating and updating page table entries when necessary within an IOMMU domain.",
    "prorec_aug_sum": "Traverses a virtual address range, mapping pages as needed and invoking a sub-handler for each, updating page table entries accordingly.",
    "filter_prorec_aug_sum": "Traverses a virtual address range, allocating and mapping page table entries as needed, and delegates subrange handling to a subordinate function.",
    "work_score": {
        "prorec": {
            "summary": "Maps a range of IO virtual addresses to physical memory pages, allocating new mappings when absent and delegating page-level handling to a helper function.",
            "score": [
                0.5333333333333333,
                0.5,
                0.16666666666666666
            ],
            "reason": [
                "The summary claims IO virtual address mapping, but the source code shows kernel virtual address mapping using pgd/pud structures in x86, with no mention of IO-specific regions. It correctly notes allocation of new tables when absent and delegation to a helper function, which matches the calls to alloc_pgt_page and ident_pud_init. Overall, only part of the summary is supported; the IO-specific detail is a hallucination, reducing accuracy below half.",
                "The summary\u2019s claim of mapping IO virtual addresses is inaccurate, as the source code operates on kernel-space address mappings using pgd/pud tables, with no evidence of IO-specific handling. The part describing allocation when mappings are absent and delegating to a helper is accurate, reflected in calls to alloc_pgt_page and ident_pud_init. However, with the IO mapping detail removed, the remaining accurate description captures only part of the logic, missing specifics like pgd offset calculation, loop progression, and error handling edge cases.",
                "The summary claims mapping of IO virtual addresses to physical memory pages, but the source code shows kernel address space mapping using page tables, not specifically IO virtual addresses. It also omits key details such as use of pgd_index with __PAGE_OFFSET when kernel_mapping is set, allocation via alloc_pgt_page, and the use of ident_pud_init for page-level initialization. Most claims about IO-specific behavior are unsupported by the source code, making them inaccurate, and the remaining details are generic and lacking in domain-specific insight."
            ]
        },
        "filter_prorec": {
            "summary": "Maps a virtual address range to physical memory, allocating and updating page table entries when necessary within an IOMMU domain.",
            "score": [
                0.4666666666666666,
                0.5,
                0.0
            ],
            "reason": [
                "The summary claims the function operates within an IOMMU domain, but the source code shows no evidence of IOMMU-related structures or API calls. It accurately notes mapping a virtual address range to physical memory and allocating/updating page table entries when necessary, which is supported by calls like alloc_pgt_page, set_pgd, and ident_pud_init. The IOMMU domain detail is a hallucination, leading to mixed accuracy overall.",
                "The summary claims the function operates within an IOMMU domain, which is not supported by the source code\u2014there is no reference to IOMMU structures or APIs. The source code does handle mapping of a virtual address range to page table entries, allocating new pages when needed and updating mappings, which matches part of the summary. However, the inaccurate IOMMU detail means that only the general mapping logic is correct, leaving significant context misstated.",
                "The summary claims the function operates within an IOMMU domain, but there is no evidence in the source code for any IOMMU-specific structures, functions, or contexts, making this detail inaccurate. The mapping logic described in the summary is partially accurate in that the function maps a virtual address range to physical memory and updates page table entries when needed. However, the domain context is wrong, and the summary omits key specifics present in the code such as conditional offsets based on `info->kernel_mapping`, the role of `pgd_present`, and the explicit page allocation via `alloc_pgt_page`. With the single inaccurate domain-related claim out of two key points, the proportion of inaccuracies is at least 50%, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic reg_errcode_t\n__attribute_warn_unused_result__\nregister_state (const re_dfa_t *dfa, re_dfastate_t *newstate,\n\t\tre_hashval_t hash)\n{\n  struct re_state_table_entry *spot;\n  reg_errcode_t err;\n  Idx i;\n\n  newstate->hash = hash;\n  err = re_node_set_alloc (&newstate->non_eps_nodes, newstate->nodes.nelem);\n  if (BE (err != REG_NOERROR, 0))\n    return REG_ESPACE;\n  for (i = 0; i < newstate->nodes.nelem; i++)\n    {\n      Idx elem = newstate->nodes.elems[i];\n      if (!IS_EPSILON_NODE (dfa->nodes[elem].type))\n\tif (! re_node_set_insert_last (&newstate->non_eps_nodes, elem))\n\t  return REG_ESPACE;\n    }\n\n  spot = dfa->state_table + (hash & dfa->state_hash_mask);\n  if (BE (spot->alloc <= spot->num, 0))\n    {\n      Idx new_alloc = 2 * spot->num + 2;\n      re_dfastate_t **new_array = re_realloc (spot->array, re_dfastate_t *,\n\t\t\t\t\t      new_alloc);\n      if (BE (new_array == NULL, 0))\n\treturn REG_ESPACE;\n      spot->array = new_array;\n      spot->alloc = new_alloc;\n    }\n  spot->array[spot->num++] = newstate;\n  return REG_NOERROR;\n}",
    "comment": "Registers a new DFA state in the state table, allocating memory as needed and populating non-epsilon nodes.",
    "prorec_sum": "Initializes an entry structure with provided parameters, allocates supporting arrays, validates elements, and links it into a dynamically resized bucket list.",
    "filter_prorec_sum": "Allocates and initializes an entry structure, validates its elements, and inserts it into a dynamically resized array within the primary data table.",
    "prorec_aug_sum": "Initializes and validates an entry structure, allocates memory for its elements, and appends it to a dynamically managed list in the target container.",
    "filter_prorec_aug_sum": "Initializes and validates a2\u2019s entries, allocates its storage array, and links it into a1\u2019s indexed list, returning 0 or error code 12.",
    "work_score": {
        "prorec": {
            "summary": "Initializes an entry structure with provided parameters, allocates supporting arrays, validates elements, and links it into a dynamically resized bucket list.",
            "score": [
                0.8000000000000002,
                0.6666666666666666,
                0.7333333333333334
            ],
            "reason": [
                "The summary's claim about initializing with provided parameters and allocating arrays aligns with setting `newstate->hash` and calling `re_node_set_alloc`, as well as potentially reallocating `spot->array`. Validation of elements is accurate due to the loop checking `IS_EPSILON_NODE` before inserting. However, the phrase 'dynamically resized bucket list' is inaccurate since the code resizes an array within a state table entry, not a generic bucket list. Overall, most details map directly to explicit evidence in the source, with only one unverified term.",
                "The summary correctly notes initialization with parameters, allocation of arrays, validation of elements, and insertion into a resized bucket list, all of which are explicitly implemented in the source via setting `newstate->hash`, calling `re_node_set_alloc`, checking non-epsilon nodes, conditionally reallocating `spot->array`, and linking `newstate`. However, it omits important details such as error handling paths (`REG_ESPACE` returns on failures) and the specific hash-index lookup for the bucket (`hash & dfa->state_hash_mask`), which are critical to a complete understanding of the logic.",
                "The summary contains generic descriptions that are partially accurate but omit critical specifics from the source code. It correctly notes allocation of supporting structures and dynamic resizing of a bucket array, but it inaccurately rephrases 'dfa->state_table' as a 'bucket list' without explicit evidence of that terminology in the code. It also fails to mention key conditions, such as filtering non-epsilon nodes, use of hash masking, and error handling, resulting in mostly vague coverage of the actual logic."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes an entry structure, validates its elements, and inserts it into a dynamically resized array within the primary data table.",
            "score": [
                0.8666666666666667,
                0.6333333333333333,
                0.5333333333333333
            ],
            "reason": [
                "The summary correctly captures the dynamic resizing of an array within the main state table and the insertion of a new element (newstate). However, it inaccurately claims allocation and initialization of an 'entry structure' without explicit evidence from the code; the code allocates a node set and updates specific fields rather than a distinct entry structure. It also generalizes 'validates its elements' without directly referencing the explicit epsilon node filtering logic shown. Overall, it contains mixed accuracy with some details grounded in the source and others as unverified generalizations.",
                "The summary accurately reflects that the function allocates and initializes a structure, checks elements, and inserts it into a dynamically resized array in a data table. These actions are directly supported by the code: allocation via re_node_set_alloc, validation through IS_EPSILON_NODE checks, and insertion with possible resizing of spot->array. However, the summary omits finer details such as error handling returning REG_ESPACE on allocation failures and specific hash-based placement in the table, leaving some critical logic uncovered.",
                "The summary contains partially accurate details: it correctly notes insertion into a dynamically resized array within a main table and some form of validation, which is supported by the `re_node_set_insert_last` calls and array reallocation logic. However, it inaccurately claims allocation and initialization of an 'entry structure'; the code works with an existing `newstate` and `spot` from the DFA rather than creating a new entry structure. Since fewer than half the details are inaccurate, but the accurate ones are generic and lack domain-specific richness, the value of the accurate details is modest."
            ]
        }
    }
}
{
    "source_code": "\napr_fileperms_t apr_unix_mode2perms(mode_t mode)\n{\n    apr_fileperms_t perms = 0;\n\n    if (mode & S_ISUID)\n        perms |= APR_USETID;\n    if (mode & S_IRUSR)\n        perms |= APR_UREAD;\n    if (mode & S_IWUSR)\n        perms |= APR_UWRITE;\n    if (mode & S_IXUSR)\n        perms |= APR_UEXECUTE;\n\n    if (mode & S_ISGID)\n        perms |= APR_GSETID;\n    if (mode & S_IRGRP)\n        perms |= APR_GREAD;\n    if (mode & S_IWGRP)\n        perms |= APR_GWRITE;\n    if (mode & S_IXGRP)\n        perms |= APR_GEXECUTE;\n\n#ifdef S_ISVTX\n    if (mode & S_ISVTX)\n        perms |= APR_WSTICKY;\n#endif\n    if (mode & S_IROTH)\n        perms |= APR_WREAD;\n    if (mode & S_IWOTH)\n        perms |= APR_WWRITE;\n    if (mode & S_IXOTH)\n        perms |= APR_WEXECUTE;\n\n    return perms;\n}",
    "comment": "Converts a Unix file mode into an APR file permissions representation by checking user, group, and others' read, write, and execute bits.",
    "prorec_sum": "Converts a Unix file mode bitmask into an APR permission bitfield, mapping standard, special, and owner/group/world flags to corresponding permission bits.",
    "filter_prorec_sum": "Converts a Unix file mode bitmask into an internal permission flags representation with bitwise mapping for special, owner, group, and other access rights.",
    "prorec_aug_sum": "Converts a Unix file mode bitmask into a corresponding APR permission bitfield representation.",
    "filter_prorec_aug_sum": "Converts a 16-bit UNIX file mode value into an APR permission bitmask representing special flags and read, write, execute rights.",
    "work_score": {
        "prorec": {
            "summary": "Converts a Unix file mode bitmask into an APR permission bitfield, mapping standard, special, and owner/group/world flags to corresponding permission bits.",
            "score": [
                1.0,
                0.9,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly describes the core logic: converting a Unix file mode bitmask into an APR permission bitfield and mapping owner, group, world, and special flags to corresponding APR constants. All key details are explicitly confirmed in the source code through checks for standard permission bits (S_IRUSR, S_IWUSR, etc.), special bits (S_ISUID, S_ISGID, S_ISVTX), and mappings to APR_* values. No hallucinated or unverifiable claims are present.",
                "The summary correctly states that the function converts a Unix file mode bitmask into an APR permission bitfield and maps owner, group, and world flags along with special flags, which matches the explicit checks and bitwise mappings in the source code. However, it does not mention the conditional handling of S_ISVTX via a preprocessor directive or the specific constants used (e.g., APR_USETID, APR_WSTICKY), omitting some key implementation details and edge cases.",
                "The summary accurately describes the function's purpose: converting a Unix mode bitmask into an APR permission bitfield, mapping owner, group, and world permissions along with special flags like setuid, setgid, and sticky bit. All these details are explicitly present in the source code via conditional checks and corresponding APR_* constants. The description is domain-relevant and specific, reflecting the full logic without adding unsupported claims."
            ]
        },
        "filter_prorec": {
            "summary": "Converts a Unix file mode bitmask into an internal permission flags representation with bitwise mapping for special, owner, group, and other access rights.",
            "score": [
                1.0,
                0.9333333333333332,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly identifies the purpose of the function: converting a Unix file mode bitmask into an internal permission flag representation, and notes the bitwise mapping for special, owner, group, and other access rights. All these details are explicitly supported by the source code, which performs conditional bitwise checks for S_ISUID, S_ISGID, S_ISVTX, and respective read/write/execute flags for owner, group, and others before mapping them to APR_* constants. There are no unverified or hallucinated claims.",
                "The summary accurately captures the core functionality by describing the conversion of a Unix file mode bitmask into internal permission flags using bitwise checks for special, owner, group, and other rights. This matches the source code, which uses if statements to map S_ISUID, S_IRUSR, etc., to APR_* flags. However, it omits details about specific flags like sticky bit handling (#ifdef S_ISVTX) and exact mapping for each permission type, which means some edge cases are not covered.",
                "The summary accurately captures the function\u2019s purpose of converting a Unix file mode bitmask into an internal permission flags representation with distinct mappings for special, owner, group, and other access rights. All mentioned details are explicitly evidenced in the source code through checks of mode bits (S_ISUID, S_IRUSR, etc.) and corresponding APR_* flag assignments, so there are no inaccuracies. While the description is correct, it remains fairly generic and lacks specific naming of constants or detailed logic steps found in the code, which limits its domain richness."
            ]
        }
    }
}
{
    "source_code": "\nstatic int check_policy(X509_STORE_CTX *ctx)\n\t{\n\tint ret;\n\tif (ctx->parent)\n\t\treturn 1;\n\tret = X509_policy_check(&ctx->tree, &ctx->explicit_policy, ctx->chain,\n\t\t\t\tctx->param->policies, ctx->param->flags);\n\tif (ret == 0)\n\t\t{\n\t\tX509err(X509_F_CHECK_POLICY,ERR_R_MALLOC_FAILURE);\n\t\treturn 0;\n\t\t}\n\t/* Invalid or inconsistent extensions */\n\tif (ret == -1)\n\t\t{\n\t\t/* Locate certificates with bad extensions and notify\n\t\t * callback.\n\t\t */\n\t\tX509 *x;\n\t\tint i;\n\t\tfor (i = 1; i < sk_X509_num(ctx->chain); i++)\n\t\t\t{\n\t\t\tx = sk_X509_value(ctx->chain, i);\n\t\t\tif (!(x->ex_flags & EXFLAG_INVALID_POLICY))\n\t\t\t\tcontinue;\n\t\t\tctx->current_cert = x;\n\t\t\tctx->error = X509_V_ERR_INVALID_POLICY_EXTENSION;\n\t\t\tif(!ctx->verify_cb(0, ctx))\n\t\t\t\treturn 0;\n\t\t\t}\n\t\treturn 1;\n\t\t}\n\tif (ret == -2)\n\t\t{\n\t\tctx->current_cert = NULL;\n\t\tctx->error = X509_V_ERR_NO_EXPLICIT_POLICY;\n\t\treturn ctx->verify_cb(0, ctx);\n\t\t}\n\n\tif (ctx->param->flags & X509_V_FLAG_NOTIFY_POLICY)\n\t\t{\n\t\tctx->current_cert = NULL;\n\t\tctx->error = X509_V_OK;\n\t\tif (!ctx->verify_cb(2, ctx))\n\t\t\treturn 0;\n\t\t}\n\n\treturn 1;\n\t}",
    "comment": "Validates X509 certificate policies, checks for invalid extensions, and invokes a callback for policy notifications or errors during the verification process.",
    "prorec_sum": "Validates X.509 certificate policies using `X509_policy_check` and triggers appropriate error handling or callbacks based on the verification outcome.",
    "filter_prorec_sum": "Validates an X.509 certificate chain\u2019s policy using `X509_policy_check`, handling special error codes and invoking a callback for policy-related issues.",
    "prorec_aug_sum": "Validates X.509 certificate policies with `X509_policy_check` and triggers appropriate error handling or callbacks based on the check\u2019s result codes.",
    "filter_prorec_aug_sum": "Performs X.509 certificate policy verification using `X509_policy_check` and triggers appropriate error handling or callbacks based on the returned status code.",
    "work_score": {
        "prorec": {
            "summary": "Validates X.509 certificate policies using `X509_policy_check` and triggers appropriate error handling or callbacks based on the verification outcome.",
            "score": [
                1.0,
                0.6,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly states that the function validates X.509 certificate policies using `X509_policy_check` and triggers error handling or callbacks based on the verification result. This is directly supported by the source code, which calls `X509_policy_check` and uses conditions to set errors and invoke `verify_cb`. No unsupported or hallucinated details are present.",
                "The summary accurately notes that the function validates X.509 certificate policies using `X509_policy_check` and triggers error handling or callbacks based on outcomes. This is directly supported by the code's use of `X509_policy_check` followed by branching on return values (0, -1, -2) to set errors and invoke `verify_cb`. However, the summary omits key specifics such as distinct return value handling, the notification flag path, and the check for `ctx->parent`. While the main action is covered, substantial control flow and edge case details are missing.",
                "The summary correctly states that the function validates X.509 certificate policies using `X509_policy_check` and invokes callbacks or error handling depending on results, which is supported by multiple branches handling errors and calling `verify_cb`. These details are accurate, domain-specific, and match explicit evidence in the source code. No inaccurate details were found, and the information is specific to the code's verification logic."
            ]
        },
        "filter_prorec": {
            "summary": "Validates an X.509 certificate chain\u2019s policy using `X509_policy_check`, handling special error codes and invoking a callback for policy-related issues.",
            "score": [
                1.0,
                0.6,
                0.7666666666666666
            ],
            "reason": [
                "The summary accurately reflects the core logic in the source code: it describes policy validation on an X.509 certificate chain using `X509_policy_check`, and notes the handling of special error codes with callback invocation for policy issues. All these details are explicitly present in the code, with no unverified assumptions or missing key points relevant to the summary.",
                "The summary accurately captures the main function purpose\u2014validating an X.509 certificate chain's policy via `X509_policy_check`\u2014and notes handling of special return codes and invoking a callback for policy issues, both of which are explicitly present in the source code. However, it omits notable specifics such as handling flags like `X509_V_FLAG_NOTIFY_POLICY`, distinct responses for ret values 0, -1, and -2, and setting `ctx->error` and `ctx->current_cert`. These missing details mean the accurate content covers the core action but not the full logic including edge cases.",
                "The summary accurately identifies that the function validates an X.509 certificate chain\u2019s policy using `X509_policy_check`, processes specific return codes, and calls a verification callback to handle policy issues. All these details are explicitly supported by the source code through the function calls, error checks, and callback invocations. Although the summary is somewhat high-level, it captures the main domain-specific elements correctly."
            ]
        }
    }
}
{
    "source_code": "void\nmpz_rootrem (mpz_t x, mpz_t r, const mpz_t y, unsigned long z)\n{\n  int sgn;\n  mpz_t t, u;\n\n  sgn = y->_mp_size < 0;\n  if ((~z & sgn) != 0)\n    gmp_die (\"mpz_rootrem: Negative argument, with even root.\");\n  if (z == 0)\n    gmp_die (\"mpz_rootrem: Zeroth root.\");\n\n  if (mpz_cmpabs_ui (y, 1) <= 0) {\n    if (x)\n      mpz_set (x, y);\n    if (r)\n      r->_mp_size = 0;\n    return;\n  }\n\n  mpz_init (u);\n  mpz_init (t);\n  mpz_setbit (t, mpz_sizeinbase (y, 2) / z + 1);\n\n  if (z == 2) /* simplify sqrt loop: z-1 == 1 */\n    do {\n      mpz_swap (u, t);\t\t\t/* u = x */\n      mpz_tdiv_q (t, y, u);\t\t/* t = y/x */\n      mpz_add (t, t, u);\t\t/* t = y/x + x */\n      mpz_tdiv_q_2exp (t, t, 1);\t/* x'= (y/x + x)/2 */\n    } while (mpz_cmpabs (t, u) < 0);\t/* |x'| < |x| */\n  else /* z != 2 */ {\n    mpz_t v;\n\n    mpz_init (v);\n    if (sgn)\n      mpz_neg (t, t);\n\n    do {\n      mpz_swap (u, t);\t\t\t/* u = x */\n      mpz_pow_ui (t, u, z - 1);\t\t/* t = x^(z-1) */\n      mpz_tdiv_q (t, y, t);\t\t/* t = y/x^(z-1) */\n      mpz_mul_ui (v, u, z - 1);\t\t/* v = x*(z-1) */\n      mpz_add (t, t, v);\t\t/* t = y/x^(z-1) + x*(z-1) */\n      mpz_tdiv_q_ui (t, t, z);\t\t/* x'=(y/x^(z-1) + x*(z-1))/z */\n    } while (mpz_cmpabs (t, u) < 0);\t/* |x'| < |x| */\n\n    mpz_clear (v);\n  }\n\n  if (r) {\n    mpz_pow_ui (t, u, z);\n    mpz_sub (r, y, t);\n  }\n  if (x)\n    mpz_swap (x, u);\n  mpz_clear (u);\n  mpz_clear (t);\n}",
    "comment": "Computes the nth root and remainder of a multi-precision integer, handling special cases for negative and zero values.",
    "prorec_sum": "Computes the integer n\u2011th root of a big number and optionally returns the remainder, rejecting invalid roots such as zero or even roots of negatives.",
    "filter_prorec_sum": "Computes the integer nth root of a multi-precision number and optionally returns the remainder and root result with input validation.",
    "prorec_aug_sum": "Computes the integer nth root of a multi-precision number and optionally returns both the root and the remainder.",
    "filter_prorec_aug_sum": "Computes the integer n\u2011th root of a large number and optionally returns the remainder using iterative approximation and error checks.",
    "work_score": {
        "prorec": {
            "summary": "Computes the integer n\u2011th root of a big number and optionally returns the remainder, rejecting invalid roots such as zero or even roots of negatives.",
            "score": [
                1.0,
                0.6666666666666666,
                0.9
            ],
            "reason": [
                "The summary captures several accurate details: the function computes the integer n-th root (logic in sqrt loop and general z loop), can return a remainder when 'r' is provided, and rejects invalid cases such as zeroth roots and even roots of negative numbers, which are explicitly checked in the code. All key claims are supported by explicit evidence in the source. There are no unverified or hallucinated details.",
                "The summary accurately describes that the function computes the integer n-th root of a big number and can optionally return the remainder. It also correctly notes rejection of invalid cases: zeroth root and even roots of negatives. These match explicit checks and logic in the source code (e.g., gmp_die calls, final remainder computation). However, the summary does not mention significant details such as separate handling for square roots (z == 2), initialization/cleanup of temporary variables, or iterative update logic used in root calculation, so coverage of the full logic is incomplete.",
                "The summary accurately states that the function computes the integer n\u2011th root of a big number and optionally returns the remainder, as seen in the calculation loops for z==2 and z!=2 and the final remainder computation. It also correctly notes rejection of invalid roots such as zero or even roots of negatives, matching explicit checks for z==0 and for negative arguments with even roots. All key details are directly supported by explicit logic and function calls in the source code, and these are specific and domain\u2011rich rather than generic."
            ]
        },
        "filter_prorec": {
            "summary": "Computes the integer nth root of a multi-precision number and optionally returns the remainder and root result with input validation.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function computes the integer n-th root of a multi-precision number and optionally returns the remainder along with the root, which is explicit in the source code through use of `mpz_pow_ui`, `mpz_sub`, and swapping into `x` and `r`. It also notes input validation, which is present in checks for negative even roots and zeroth root. All semantic details from the summary are supported by the source code, with no unverified assumptions.",
                "The summary accurately states that the function computes the integer nth root of a multi-precision number, optionally returns both the remainder and the root, and includes input validation steps. These are explicitly supported in the source code: nth root computation logic for z == 2 and z != 2, remainder calculation if r is provided, and validation for negative arguments with even roots and zeroth roots. However, it omits specific details of the iterative algorithms, edge case handling for abs(y) <= 1, and how sign adjustments are managed, so while correct, it is not fully comprehensive.",
                "The summary accurately describes that the function computes the integer nth root of a multi-precision number, optionally returning the remainder and root result, and includes input validation for negative arguments with even roots and for zeroth root cases. However, it omits detailed specifics such as the special handling for square roots (z == 2) and the iterative algorithms used, making the accurate details somewhat generic rather than domain-rich."
            ]
        }
    }
}
{
    "source_code": "\nint\nmutil_parse_field_map (const char *map, mu_assoc_t *passoc_tab, int *perr)\n{\n  int rc;\n  int i;\n  struct mu_wordsplit ws;\n  mu_assoc_t assoc_tab = NULL;\n\n  ws.ws_delim = \":\";\n  if (mu_wordsplit (map, &ws, MU_WRDSF_DEFFLAGS|MU_WRDSF_DELIM))\n    {\n      mu_error (_(\"cannot split line `%s': %s\"), map,\n\t\tmu_wordsplit_strerror (&ws));\n      return errno;\n    }\n\n  for (i = 0; i < ws.ws_wordc; i++)\n    {\n      char *tok = ws.ws_wordv[i];\n      char *p = strchr (tok, '=');\n      char *pptr;\n      \n      if (!p)\n\t{\n\t  rc = EINVAL;\n\t  break;\n\t}\n      if (!assoc_tab)\n\t{\n\t  rc = mu_assoc_create (&assoc_tab, 0);\n\t  if (rc)\n\t    break;\n\t  mu_assoc_set_destroy_item (assoc_tab, mu_list_free_item);\n\t  *passoc_tab = assoc_tab;\n\t}\n      *p++ = 0;\n      pptr = strdup (p);\n      if (!pptr)\n\t{\n\t  rc = errno;\n\t  break;\n\t}\n      rc = mu_assoc_install (assoc_tab, tok, pptr);\n      if (rc)\n\t{\n\t  free (p);\n\t  break;\n\t}\n    }\n\n  mu_wordsplit_free (&ws);\n  if (rc && perr)\n    *perr = i;\n  return rc;\n}",
    "comment": "Parses a colon-delimited string into a key-value association table, handling errors for malformed entries and memory allocation failures.",
    "prorec_sum": "Parses a colon-delimited string into key-value pairs and stores them in an associative map, returning errors on format or allocation failure.",
    "filter_prorec_sum": "Parses a colon-delimited string of key=value pairs into an associative map, reporting errors and returning the failing pair index if provided.",
    "prorec_aug_sum": "Parses a colon-delimited string into key-value pairs, storing them in an association object and returning an error code on failure.",
    "filter_prorec_aug_sum": "Parses a colon-delimited input line into key-value pairs, storing them in an association table and returning any error code encountered.",
    "work_score": {
        "prorec": {
            "summary": "Parses a colon-delimited string into key-value pairs and stores them in an associative map, returning errors on format or allocation failure.",
            "score": [
                1.0,
                0.7333333333333334,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function parses a colon-delimited string into key-value pairs, stores them in an associative map, and returns errors on format or allocation failure. All these claims are explicitly supported by the source code: colon delimiter set via ws.ws_delim, splitting into tokens, checking for '=' for key-value, storing in assoc_tab, and returning errors such as EINVAL or errno. No unverified assumptions are present.",
                "The summary accurately states that the function parses a colon-delimited string into key-value pairs and stores them in an associative map, and that it returns errors for format or allocation failures. These points are directly supported by the source code: `ws.ws_delim = \":\"` shows colon-delimited parsing, `strchr(tok, '=')` enforces key-value format, and `mu_assoc_install` stores pairs in `assoc_tab`. Error handling for format (`EINVAL`) and allocation failures is clearly implemented. However, the summary omits mention of some finer details such as the use of `mu_wordsplit` flags, explicit freeing via `mu_wordsplit_free`, and specific error positions (`perr`), so it does not fully capture all edge cases.",
                "The summary correctly describes parsing a colon-delimited string into key-value pairs and storing them in an associative map, as evidenced by `ws.ws_delim = \":\"`, `strchr(tok, '=')`, and use of `mu_assoc_install`. It also notes error handling for format or allocation failures, which matches checks for a missing '=' and allocation failures (`strdup`, `mu_assoc_create`). All key details are supported in the source code, and they provide specific and domain-relevant insight into the function's logic."
            ]
        },
        "filter_prorec": {
            "summary": "Parses a colon-delimited string of key=value pairs into an associative map, reporting errors and returning the failing pair index if provided.",
            "score": [
                1.0,
                0.9666666666666667,
                0.9
            ],
            "reason": [
                "The summary\u2019s details are fully supported by the source code: the function uses `ws.ws_delim = ':'` with `mu_wordsplit` to split the input string, processes tokens containing `key=value`, inserts them into an associative map via `mu_assoc_install`, and if an error occurs, sets `*perr` to the index `i`. No hallucinated details are present.",
                "The summary correctly describes the colon-delimited parsing of key=value pairs using an associative map, error handling, and returning the index of the failing pair if 'perr' is provided. These details are supported by explicit evidence in the source code: ws.ws_delim is set to ':', tokens are split, validated for '=', stored via mu_assoc_install, and 'perr' is set to the loop index on error. This aligns closely with the code's core logic and covers error reporting and data mapping steps, with no hallucinations found.",
                "The summary accurately reflects that the function parses a colon-delimited string of key=value pairs into an associative map and reports errors, returning the failing index via `perr` if set. These details match explicit evidence in the code, such as `ws.ws_delim = \":\"`, use of `strchr(tok, '=')`, creation and installation into `assoc_tab`, and setting `*perr = i`. The points are specific to the implementation, indicating domain-aware analysis."
            ]
        }
    }
}
{
    "source_code": "static int\nxmlRelaxNGRegisterTypeLibrary(const xmlChar * namespace, void *data,\n                              xmlRelaxNGTypeHave have,\n                              xmlRelaxNGTypeCheck check,\n                              xmlRelaxNGTypeCompare comp,\n                              xmlRelaxNGFacetCheck facet,\n                              xmlRelaxNGTypeFree freef)\n{\n    xmlRelaxNGTypeLibraryPtr lib;\n    int ret;\n\n    if ((xmlRelaxNGRegisteredTypes == NULL) || (namespace == NULL) ||\n        (check == NULL) || (comp == NULL))\n        return (-1);\n    if (xmlHashLookup(xmlRelaxNGRegisteredTypes, namespace) != NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"Relax-NG types library '%s' already registered\\n\",\n                        namespace);\n        return (-1);\n    }\n    lib =\n        (xmlRelaxNGTypeLibraryPtr)\n        xmlMalloc(sizeof(xmlRelaxNGTypeLibrary));\n    if (lib == NULL) {\n        xmlRngVErrMemory(NULL, \"adding types library\\n\");\n        return (-1);\n    }\n    memset(lib, 0, sizeof(xmlRelaxNGTypeLibrary));\n    lib->namespace = xmlStrdup(namespace);\n    lib->data = data;\n    lib->have = have;\n    lib->comp = comp;\n    lib->check = check;\n    lib->facet = facet;\n    lib->freef = freef;\n    ret = xmlHashAddEntry(xmlRelaxNGRegisteredTypes, namespace, lib);\n    if (ret < 0) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"Relax-NG types library failed to register '%s'\\n\",\n                        namespace);\n        xmlRelaxNGFreeTypeLibrary(lib, namespace);\n        return (-1);\n    }\n    return (0);\n}",
    "comment": "Registers a new Relax-NG types library with a given namespace and associated functions in the xmlRelaxNGRegisteredTypes hash table.",
    "prorec_sum": "Registers a new Relax-NG types library in a global hash table, allocating and storing its callbacks, with error handling for duplicates or allocation failure.",
    "filter_prorec_sum": "Registers a new Relax-NG types library in a global hash, allocating and storing provided callbacks, and logs errors if registration fails.",
    "prorec_aug_sum": "Registers a new Relax-NG types library into a global hash table, allocating and storing its associated callbacks, with error handling for duplicates or failures.",
    "filter_prorec_aug_sum": "Registers a new Relax-NG types library in a global hash table, allocating and storing its associated callbacks, with error reporting on duplicate or failure.",
    "work_score": {
        "prorec": {
            "summary": "Registers a new Relax-NG types library in a global hash table, allocating and storing its callbacks, with error handling for duplicates or allocation failure.",
            "score": [
                1.0,
                0.9,
                0.9
            ],
            "reason": [
                "The summary accurately reflects the core operations in the source code: registering a Relax-NG types library in a global hash table (`xmlHashAddEntry`), allocating a struct for the library with its callbacks (`have`, `check`, `comp`, `facet`, `freef`), and handling errors for duplicate registration and allocation failure. All these details have explicit evidence in the code, with no unverified or hallucinated elements.",
                "The summary accurately describes the core logic: registering a Relax-NG type library in a global hash table, storing provided callbacks and namespace, and handling errors for duplicates and memory allocation failures. These elements are explicitly present in the source code, including checks for existing entries, malloc failure handling, and storing the callback pointers. No significant hallucinations are present, and the description covers the main workflow and error cases, though it omits the facet-specific and freeing logic details.",
                "The summary accurately reflects the source code: it describes registering a Relax-NG types library in a global hash table, allocating memory for the library struct, storing provided callbacks (have, check, comp, facet, freef), and handling errors for duplicate entries via xmlHashLookup or memory allocation failure. All these actions are explicitly present in the code. The details are specific, domain-relevant, and directly linked to the function's logic."
            ]
        },
        "filter_prorec": {
            "summary": "Registers a new Relax-NG types library in a global hash, allocating and storing provided callbacks, and logs errors if registration fails.",
            "score": [
                1.0,
                0.7666666666666666,
                0.9
            ],
            "reason": [
                "The summary correctly identifies that the function registers a new Relax-NG types library into a global hash, allocates memory for the library, stores provided callbacks, and logs errors if registration fails. All these details are explicitly supported by the code: use of xmlHashAddEntry for registration, malloc and memset for allocation, assignment of callback pointers, and xmlGenericError calls for logging errors. No unverified or hallucinated details are present.",
                "The summary accurately captures the core logic: the function registers a new Relax-NG types library in a global hash, allocates memory, stores provided callbacks, and logs errors on failure. These elements are explicitly present in the source code, including global hash insertion, allocation via xmlMalloc, assignment of callback fields, and error logging in multiple failure cases. No hallucinated details are present, and the main logic is fully covered.",
                "The summary's claim about registering a new Relax-NG types library in a global hash is accurate, as seen in the use of xmlHashAddEntry with xmlRelaxNGRegisteredTypes. It correctly notes allocation and storage of provided callbacks, matching the assignments to lib's fields. Error logging on registration failure is also accurate, given the xmlGenericError calls. All details align explicitly with the source code, making them accurate and providing specific, domain-relevant insight into the function's behavior."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nevhttp_read_header(struct evhttp_connection *evcon,\n\t\t   struct evhttp_request *req)\n{\n\tenum message_read_status res;\n\tevutil_socket_t fd = evcon->fd;\n\n\tres = evhttp_parse_headers_(req, bufferevent_get_input(evcon->bufev));\n\tif (res == DATA_CORRUPTED || res == DATA_TOO_LONG) {\n\t\t/* Error while reading, terminate */\n\t\tevent_debug((\"%s: bad header lines on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, EV_SOCK_ARG(fd)));\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\treturn;\n\t} else if (res == MORE_DATA_EXPECTED) {\n\t\t/* Need more header lines */\n\t\treturn;\n\t}\n\n\t/* Callback can shut down connection with negative return value */\n\tif (req->header_cb != NULL) {\n\t\tif ((*req->header_cb)(req, req->cb_arg) < 0) {\n\t\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_EOF);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Done reading headers, do the real work */\n\tswitch (req->kind) {\n\tcase EVHTTP_REQUEST:\n\t\tevent_debug((\"%s: checking for post data on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, EV_SOCK_ARG(fd)));\n\t\tevhttp_get_body(evcon, req);\n\t\t/* note the request may have been freed in evhttp_get_body */\n\t\tbreak;\n\n\tcase EVHTTP_RESPONSE:\n\t\t/* Start over if we got a 100 Continue response. */\n\t\tif (req->response_code == 100) {\n\t\t\tstruct evbuffer *output = bufferevent_get_output(evcon->bufev);\n\t\t\tevbuffer_add_buffer(output, req->output_buffer);\n\t\t\tevhttp_start_write_(evcon);\n\t\t\treturn;\n\t\t}\n\t\tif (!evhttp_response_needs_body(req)) {\n\t\t\tevent_debug((\"%s: skipping body for code %d\\n\",\n\t\t\t\t\t__func__, req->response_code));\n\t\t\tevhttp_connection_done(evcon);\n\t\t} else {\n\t\t\tevent_debug((\"%s: start of read body for %s on \"\n\t\t\t\tEV_SOCK_FMT\"\\n\",\n\t\t\t\t__func__, req->remote_host, EV_SOCK_ARG(fd)));\n\t\t\tevhttp_get_body(evcon, req);\n\t\t\t/* note the request may have been freed in\n\t\t\t * evhttp_get_body */\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tevent_warnx(\"%s: bad header on \"EV_SOCK_FMT, __func__,\n\t\t    EV_SOCK_ARG(fd));\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\tbreak;\n\t}\n\t/* request may have been freed above */\n}",
    "comment": "Processes incoming HTTP headers, validates them, invokes a callback if present, and handles the request or response body based on the type and status.",
    "prorec_sum": "Parses HTTP headers from a bufferevent, handles status-specific logic, and manages connection failure or response writing based on parsing results.",
    "filter_prorec_sum": "Parses HTTP headers from a bufferevent, invokes callbacks, and handles response status codes to continue processing or fail the connection.",
    "prorec_aug_sum": "Parses HTTP headers from a buffered event, handles interim and no-body responses, and manages connection failure or response writing accordingly.",
    "filter_prorec_aug_sum": "Parses HTTP headers from a buffered event, handles specific status codes, and manages connection state or failure based on parsing and response conditions.",
    "work_score": {
        "prorec": {
            "summary": "Parses HTTP headers from a bufferevent, handles status-specific logic, and manages connection failure or response writing based on parsing results.",
            "score": [
                1.0,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly notes that the function parses HTTP headers from a bufferevent, applies status-specific logic, and manages connection failures or response writing based on parsing outcomes. These behaviors are explicitly present in the source code through calls to evhttp_parse_headers_, switch cases on req->kind, and actions such as evhttp_connection_fail_ and evhttp_start_write_. No unsupported details or hallucinations were introduced, and all elements in the summary are directly evidenced in the code.",
                "The summary accurately reflects that the code parses HTTP headers from a bufferevent and includes status-specific handling (checking parse results, managing connection failure, writing responses). However, it omits significant details such as handling specific parse error codes (DATA_CORRUPTED, DATA_TOO_LONG, MORE_DATA_EXPECTED), invoking a header callback that can terminate the connection, conditional body reading based on request kind, and special handling for a 100 Continue response. While the main action is captured, important control flow branches and edge cases are missing.",
                "The summary states that the function parses HTTP headers from a bufferevent, applies status-specific handling, and manages connection failure or response writing based on results. All these details are explicitly supported in the source code: headers are parsed via evhttp_parse_headers_ using bufferevent_get_input, different statuses trigger distinct logic paths, failure cases call evhttp_connection_fail_, and response code handling includes writing or skipping body content. These accurate details are domain-specific and convey meaningful insight into HTTP parsing and connection management."
            ]
        },
        "filter_prorec": {
            "summary": "Parses HTTP headers from a bufferevent, invokes callbacks, and handles response status codes to continue processing or fail the connection.",
            "score": [
                1.0,
                0.6,
                0.6666666666666666
            ],
            "reason": [
                "The summary correctly states that HTTP headers are parsed from a bufferevent and that callbacks are invoked, which is explicitly shown by the use of evhttp_parse_headers_ with bufferevent_get_input and header_cb invocation. It also accurately describes handling of response status codes to either continue processing (e.g., checking for 100 Continue, skipping body) or fail the connection, all of which are present in the source. No extraneous or unsupported details are included, indicating nearly full alignment with the source code.",
                "The summary accurately reflects key operations in the source code: parsing HTTP headers from a bufferevent, invoking a header callback, and handling response codes to either continue processing or fail the connection. While it omits specific branches like handling DATA_TOO_LONG/DATA_CORRUPTED, 100 Continue responses, and the distinction between request and response kinds, it correctly captures the main control flow and purposes of these steps.",
                "The summary correctly identifies header parsing from a bufferevent, invocation of a header callback, and handling of response codes to decide whether to continue or terminate the connection. These elements are explicitly present in the source code via calls to evhttp_parse_headers_, conditional invocation of req->header_cb, and branching logic based on response_code. However, the summary is somewhat generic and omits key specifics such as distinct handling for different req->kind cases (EVHTTP_REQUEST vs EVHTTP_RESPONSE) and exact error conditions like DATA_CORRUPTED or 100 Continue. Since the accurate details are domain-relevant but not deeply specific, the value is moderate."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nset_level_indent(const char *str)\n{\n     long n;\n     const char *p;\n     char *q;\n     \n     n = strtol(str, &q, 0);\n     if (*q == 0 && n > 0) {\n\t  char *s = xmalloc(n+1);\n\t  memset(s, ' ', n-1);\n\t  s[n-1] = 0;\n\t  level_indent[0] = level_indent[1] = s;\n\t  return;\n     }\n     \n     p = str;\n     while (*p != '=') {\n\t  if (*p == 0)\n\t       error(EX_USAGE, 0, _(\"level-indent syntax\"));\n\t  p++;\n     }\n     ++p;\n    \n     switch (find_option_type(level_indent_optype, str, p - str - 1)) {\n     case LEVEL_BEGIN:\n\t  parse_level_string(p, &level_begin);\n\t  break;\n     case LEVEL_INDENT0:\n\t  parse_level_string(p, &level_indent[0]);\n\t  break;\n     case LEVEL_INDENT1:\n\t  parse_level_string(p, &level_indent[1]);\n\t  break;\n     case LEVEL_END0:\n\t  parse_level_string(p, &level_end[0]);\n\t  break;\n     case LEVEL_END1:\n\t  parse_level_string(p, &level_end[1]);\n\t  break;\n     default:\n\t  error(EX_USAGE, 0, _(\"unknown level indent option: %s\"), str);\n     }\n}",
    "comment": "Sets the level indentation based on a string input, allocating space for indentation or parsing specific level configuration options.",
    "prorec_sum": "Parses a level-indent configuration string or number and updates corresponding global indent settings, reporting errors for invalid syntax or unknown options.",
    "filter_prorec_sum": "Parses a level\u2011indent option string, validating syntax and setting corresponding global indentation style or spaces based on the provided value.",
    "prorec_aug_sum": "Parses a level-indent option from a string, validating syntax and updating global indentation settings or applying a specified numeric space width.",
    "filter_prorec_aug_sum": "Parses a level-indent configuration string, validates its syntax, and updates global indentation settings or specific option pointers accordingly.",
    "work_score": {
        "prorec": {
            "summary": "Parses a level-indent configuration string or number and updates corresponding global indent settings, reporting errors for invalid syntax or unknown options.",
            "score": [
                1.0,
                0.7666666666666666,
                0.9
            ],
            "reason": [
                "The summary correctly captures that the function parses a level-indent configuration string or number, updates global indent settings, and reports errors for invalid syntax or unknown options. All these points are explicitly supported by the source code: parsing numeric input with strtol, allocating space, setting level_indent globals, parsing based on option types, and calling error() on syntax or unknown options. No details appear to be hallucinated.",
                "The summary accurately states that the function parses a level-indent configuration string or number, updates global indent settings (level_indent, level_begin, level_end), and reports errors for invalid syntax or unknown options. These behaviors are explicitly evident from the code via the strtol parsing, conditional logic, updating of global arrays, and error calls. While the summary omits the detailed parsing paths for specific option types (LEVEL_BEGIN, LEVEL_INDENT0/1, LEVEL_END0/1), it conveys the core logic sufficiently.",
                "The summary accurately captures key semantic details: the function parses a level-indent configuration string or number, updates global indent settings like level_indent, and reports errors for invalid syntax or unknown options. All these points are explicitly evidenced in the source code through calls to strtol, assignments to level_indent, and error handling for invalid or unknown options. The details are domain-rich and focus on specific behavior rather than being generic."
            ]
        },
        "filter_prorec": {
            "summary": "Parses a level\u2011indent option string, validating syntax and setting corresponding global indentation style or spaces based on the provided value.",
            "score": [
                1.0,
                0.7333333333333334,
                0.8333333333333334
            ],
            "reason": [
                "The summary correctly reflects that the function parses a level-indent option string, validates its syntax, and sets global indentation based on the provided value. These details are explicitly supported by the source code, which shows syntax checking, branching on option types, and setting global variables or space strings accordingly. There are no unsupported claims or hallucinations present.",
                "The summary accurately notes that the function parses a level-indent option string, validates syntax, and sets corresponding global indentation values or spaces based on the provided value. This is supported by evidence in the source code: numeric values are converted using strtol and used to allocate space strings for level_indent[0] and [1], while other options after '=' are dispatched via find_option_type to set global level-related variables. However, it omits key details like specific parsing branches for LEVEL_BEGIN, LEVEL_END0, LEVEL_END1, and the explicit error handling for unknown options, so the coverage is partial rather than complete.",
                "The summary correctly states that the function parses a level-indent option string, validates syntax, and sets indentation style or spaces based on the value, which is explicitly shown via strtol parsing, syntax checks, and assignments to level_indent or related globals. These details are accurate and provide specific insights into the parsing and setting logic, though they are relatively generic in scope without covering the distinct handling of multiple option types in the switch statement."
            ]
        }
    }
}
{
    "source_code": "\n\nvoid *\nngx_http_map_find(ngx_http_request_t *r, ngx_http_map_t *map, ngx_str_t *match)\n{\n    void        *value;\n    u_char      *low;\n    size_t       len;\n    ngx_uint_t   key;\n\n    len = match->len;\n\n    if (len) {\n        low = ngx_pnalloc(r->pool, len);\n        if (low == NULL) {\n            return NULL;\n        }\n\n    } else {\n        low = NULL;\n    }\n\n    key = ngx_hash_strlow(low, match->data, len);\n\n    value = ngx_hash_find_combined(&map->hash, key, low, len);\n    if (value) {\n        return value;\n    }\n\n#if (NGX_PCRE)\n\n    if (len && map->nregex) {\n        ngx_int_t              n;\n        ngx_uint_t             i;\n        ngx_http_map_regex_t  *reg;\n\n        reg = map->regex;\n\n        for (i = 0; i < map->nregex; i++) {\n\n            n = ngx_http_regex_exec(r, reg[i].regex, match);\n\n            if (n == NGX_OK) {\n                return reg[i].value;\n            }\n\n            if (n == NGX_DECLINED) {\n                continue;\n            }\n\n            /* NGX_ERROR */\n\n            return NULL;\n        }\n    }\n\n#endif\n\n    return NULL;\n}",
    "comment": "Finds a corresponding value in a hash map or regex patterns for a given string in an HTTP request.",
    "prorec_sum": "Finds a matching value in a combined hash for a given key, falling back to regex matching if no direct hash entry is found.",
    "filter_prorec_sum": "Performs a case-insensitive lookup in a combined hash for a key string, falling back to regex matching if no direct match is found.",
    "prorec_aug_sum": "Finds a mapping entry by hashing a given key and, if not found, searches configured regular expressions for a matching entry.",
    "filter_prorec_aug_sum": "Finds a matching value in an nginx map by case-normalized hash key, falling back to regex-based matching if no direct hash match exists.",
    "work_score": {
        "prorec": {
            "summary": "Finds a matching value in a combined hash for a given key, falling back to regex matching if no direct hash entry is found.",
            "score": [
                1.0,
                0.6333333333333333,
                0.9
            ],
            "reason": [
                "The summary accurately describes the main logic of the function: looking up a value in a combined hash based on a key and falling back to regex matching if the hash lookup fails. Both the hash-based lookup using `ngx_hash_find_combined` and the conditional regex matching via `ngx_http_regex_exec` are explicitly present in the source. There are no unverified or hallucinated details, making the description fully aligned with the code.",
                "The summary correctly identifies that the function first attempts to find a match in a combined hash and then falls back to regex matching if no hash match is found, which aligns with the source code's sequence: computing a hash key, using ngx_hash_find_combined, and conditionally executing regex searches when NGX_PCRE is enabled. However, it omits important specifics such as memory allocation for 'low', the condition checking for 'len', and handling of error cases like NULL allocation or regex execution errors. These missing details mean the accurate content covers the main logic but not all critical semantic units.",
                "The summary correctly identifies the function's purpose of finding a value in a combined hash and falling back to regex matching if no direct hash entry is found. These details are explicitly supported by the source code, with evidence of `ngx_hash_find_combined` being used first and a subsequent regex loop under the `NGX_PCRE` directive. No inaccurate or hallucinated details are present, and the accurate points convey relevant domain-specific logic."
            ]
        },
        "filter_prorec": {
            "summary": "Performs a case-insensitive lookup in a combined hash for a key string, falling back to regex matching if no direct match is found.",
            "score": [
                1.0,
                0.6,
                0.8666666666666667
            ],
            "reason": [
                "The summary correctly notes the case-insensitive lookup in a combined hash, which is evident from the use of ngx_hash_strlow and ngx_hash_find_combined. It also accurately describes the fallback to regex matching when no direct match is found, as shown by the conditional using map->nregex and ngx_http_regex_exec. All semantic details stated in the summary are explicitly supported by the source code, with no unverified assumptions or hallucinations.",
                "The summary correctly identifies the main logic of performing a lookup in a combined hash and falling back to regex matching if no direct match is found. However, it inaccurately claims the lookup is case-insensitive without explicitly noting the source code transforms the string to lowercase before hashing; while ngx_hash_strlow suggests case-insensitive behavior, this detail is implied but not explicitly documented in the summary. The accurate portion covers the key control flow, including the sequence of hash lookup followed by regex fallback under NGX_PCRE conditions, but omits mention of memory allocation, null returns, and specific error handling for regex execution, leaving some important logic uncovered.",
                "The summary's claim about case-insensitive lookup in a combined hash is accurate, as evidenced by the use of ngx_hash_strlow to lowercase the key and ngx_hash_find_combined for lookup. The fallback to regex matching if no direct match is found is also accurate, shown by the NGX_PCRE block calling ngx_http_regex_exec when hash lookup fails. Both details are explicitly supported in the source code, and they convey specific domain-relevant logic relating to HTTP request handling and lookup mechanisms."
            ]
        }
    }
}
{
    "source_code": "\n\nngx_int_t\nngx_http_request_body_save_filter(ngx_http_request_t *r, ngx_chain_t *in)\n{\n    ngx_buf_t                 *b;\n    ngx_chain_t               *cl;\n    ngx_http_request_body_t   *rb;\n\n    rb = r->request_body;\n\n#if (NGX_DEBUG)\n\n#if 0\n    for (cl = rb->bufs; cl; cl = cl->next) {\n        ngx_log_debug7(NGX_LOG_DEBUG_EVENT, r->connection->log, 0,\n                       \"http body old buf t:%d f:%d %p, pos %p, size: %z \"\n                       \"file: %O, size: %O\",\n                       cl->buf->temporary, cl->buf->in_file,\n                       cl->buf->start, cl->buf->pos,\n                       cl->buf->last - cl->buf->pos,\n                       cl->buf->file_pos,\n                       cl->buf->file_last - cl->buf->file_pos);\n    }\n#endif\n\n    for (cl = in; cl; cl = cl->next) {\n        ngx_log_debug7(NGX_LOG_DEBUG_EVENT, r->connection->log, 0,\n                       \"http body new buf t:%d f:%d %p, pos %p, size: %z \"\n                       \"file: %O, size: %O\",\n                       cl->buf->temporary, cl->buf->in_file,\n                       cl->buf->start, cl->buf->pos,\n                       cl->buf->last - cl->buf->pos,\n                       cl->buf->file_pos,\n                       cl->buf->file_last - cl->buf->file_pos);\n    }\n\n#endif\n\n    /* TODO: coalesce neighbouring buffers */\n\n    if (ngx_chain_add_copy(r->pool, &rb->bufs, in) != NGX_OK) {\n        return NGX_HTTP_INTERNAL_SERVER_ERROR;\n    }\n\n    if (r->request_body_no_buffering) {\n        return NGX_OK;\n    }\n\n    if (rb->rest > 0) {\n\n        if (rb->buf && rb->buf->last == rb->buf->end\n            && ngx_http_write_request_body(r) != NGX_OK)\n        {\n            return NGX_HTTP_INTERNAL_SERVER_ERROR;\n        }\n\n        return NGX_OK;\n    }\n\n    /* rb->rest == 0 */\n\n    if (rb->temp_file || r->request_body_in_file_only) {\n\n        if (ngx_http_write_request_body(r) != NGX_OK) {\n            return NGX_HTTP_INTERNAL_SERVER_ERROR;\n        }\n\n        if (rb->temp_file->file.offset != 0) {\n\n            cl = ngx_chain_get_free_buf(r->pool, &rb->free);\n            if (cl == NULL) {\n                return NGX_HTTP_INTERNAL_SERVER_ERROR;\n            }\n\n            b = cl->buf;\n\n            ngx_memzero(b, sizeof(ngx_buf_t));\n\n            b->in_file = 1;\n            b->file_last = rb->temp_file->file.offset;\n            b->file = &rb->temp_file->file;\n\n            rb->bufs = cl;\n        }\n    }\n\n    return NGX_OK;\n}",
    "comment": "Saves the request body data by copying buffers and managing temporary files for further processing in an NGINX HTTP request.",
    "prorec_sum": "Stores incoming HTTP request body buffers into a temporary chain and conditionally allocates a free buffer for further processing or returns an error.",
    "filter_prorec_sum": "Handles saving of an HTTP request body by copying buffer chains, flushing data when needed, and allocating a free buffer if available.",
    "prorec_aug_sum": "Adds the request body buffer chain to storage, conditionally finalizes processing, and prepares a free buffer or returns HTTP 500 on errors.",
    "filter_prorec_aug_sum": "Copies incoming request body data into a buffer chain and conditionally finalizes or allocates a free buffer, returning HTTP 500 on failure.",
    "work_score": {
        "prorec": {
            "summary": "Stores incoming HTTP request body buffers into a temporary chain and conditionally allocates a free buffer for further processing or returns an error.",
            "score": [
                0.6,
                0.5666666666666668,
                0.3666666666666667
            ],
            "reason": [
                "The summary captures only part of the function's behavior. It correctly states that incoming HTTP request body buffers are stored into a chain (accurate), but inaccurately generalizes 'temporary chain' without explicit evidence of that term in the code. The mention of 'conditionally allocates a free buffer' is partially accurate \u2014 allocation occurs only if rb->temp_file exists and has non-zero offset. However, the summary omits significant details such as specific conditions for writing request body to a file, handling of buffering flags, and error returns tied to different logical branches. The limited accurate detail results in less than half of the summary being verifiable.",
                "The summary accurately notes storing incoming HTTP request body buffers into a chain and returning an error conditionally, which matches the use of ngx_chain_add_copy and NGX_HTTP_INTERNAL_SERVER_ERROR in the code. However, the mention of 'temporary chain' and 'conditionally allocates a free buffer for further processing' omits important conditions, such as handling r->request_body_no_buffering, rb->rest checks, and writing request body to a temp file. Significant logic and edge cases present in the source code are missing, so the coverage is incomplete.",
                "The summary accurately notes that incoming HTTP request body buffers are stored and that buffer allocation and error conditions can occur. However, it omits multiple specific logic paths in the code: the conditional handling based on `request_body_no_buffering`, `rb->rest`, and temporary file logic, as well as functions like `ngx_chain_add_copy` and `ngx_http_write_request_body` which influence behavior. These omissions mean the description is oversimplified and generic, lacking domain-rich detail despite some factual accuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Handles saving of an HTTP request body by copying buffer chains, flushing data when needed, and allocating a free buffer if available.",
            "score": [
                1.0,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly identifies that the function handles saving an HTTP request body, involves copying buffer chains (matching the call to ngx_chain_add_copy), and allocates a free buffer if available (matching the use of ngx_chain_get_free_buf). It also mentions flushing data when needed, which is supported by the calls to ngx_http_write_request_body under certain conditions. All details have direct evidence in the source code, with no unverifiable assumptions present.",
                "The summary accurately captures key actions from the source code: copying buffer chains via ngx_chain_add_copy, flushing data through ngx_http_write_request_body when certain conditions are met, and allocating a free buffer with ngx_chain_get_free_buf if available. However, it omits several critical logic flows, such as handling the request_body_no_buffering flag, rb->rest checks, writing to temp files, and error return paths, which means it does not present a complete picture of the code\u2019s logic.",
                "The summary mentions copying buffer chains, flushing data when needed, and allocating a free buffer if available. All these actions are explicitly present in the source code: `ngx_chain_add_copy` handles copying, multiple conditions trigger `ngx_http_write_request_body` for flushing, and `ngx_chain_get_free_buf` allocates a free buffer. No inaccurate details were found, but the description is fairly generic and does not reference specific conditional logic or data structures beyond broad operations."
            ]
        }
    }
}
{
    "source_code": "\nint __init APIC_init_uniprocessor(void)\n{\n\tif (disable_apic) {\n\t\tpr_info(\"Apic disabled\\n\");\n\t\treturn -1;\n\t}\n#ifdef CONFIG_X86_64\n\tif (!cpu_has_apic) {\n\t\tdisable_apic = 1;\n\t\tpr_info(\"Apic disabled by BIOS\\n\");\n\t\treturn -1;\n\t}\n#else\n\tif (!smp_found_config && !cpu_has_apic)\n\t\treturn -1;\n\n\t/*\n\t * Complain if the BIOS pretends there is one.\n\t */\n\tif (!cpu_has_apic &&\n\t    APIC_INTEGRATED(apic_version[boot_cpu_physical_apicid])) {\n\t\tpr_err(\"BIOS bug, local APIC 0x%x not detected!...\\n\",\n\t\t\tboot_cpu_physical_apicid);\n\t\treturn -1;\n\t}\n#endif\n\n\tdefault_setup_apic_routing();\n\n\tverify_local_APIC();\n\tconnect_bsp_APIC();\n\n#ifdef CONFIG_X86_64\n\tapic_write(APIC_ID, SET_APIC_ID(boot_cpu_physical_apicid));\n#else\n\t/*\n\t * Hack: In case of kdump, after a crash, kernel might be booting\n\t * on a cpu with non-zero lapic id. But boot_cpu_physical_apicid\n\t * might be zero if read from MP tables. Get it from LAPIC.\n\t */\n# ifdef CONFIG_CRASH_DUMP\n\tboot_cpu_physical_apicid = read_apic_id();\n# endif\n#endif\n\tphysid_set_mask_of_physid(boot_cpu_physical_apicid, &phys_cpu_present_map);\n\tsetup_local_APIC();\n\n#ifdef CONFIG_X86_IO_APIC\n\t/*\n\t * Now enable IO-APICs, actually call clear_IO_APIC\n\t * We need clear_IO_APIC before enabling error vector\n\t */\n\tif (!skip_ioapic_setup && nr_ioapics)\n\t\tenable_IO_APIC();\n#endif\n\n\tbsp_end_local_APIC_setup();\n\n#ifdef CONFIG_X86_IO_APIC\n\tif (smp_found_config && !skip_ioapic_setup && nr_ioapics)\n\t\tsetup_IO_APIC();\n\telse {\n\t\tnr_ioapics = 0;\n\t}\n#endif\n\n\tx86_init.timers.setup_percpu_clockev();\n\treturn 0;\n}",
    "comment": "Initializes the local APIC for uniprocessor systems, verifying configuration and enabling IO-APICs as necessary for proper operation.",
    "prorec_sum": "Handles a specific ACPI-enabled initialization path by invoking timing, memory setup, and callback routines, otherwise logging an error and returning failure.",
    "filter_prorec_sum": "Handles system initialization by invoking hardware-specific routines, updating control flags, modifying a shared buffer, and triggering follow-up ACPI or DMA-related operations based on configuration state.",
    "prorec_aug_sum": "Handles a hardware-interrupt enabled path to update a large CPU-related bitmap, invoke several initialization callbacks, and optionally trigger additional processing based on global flags.",
    "filter_prorec_aug_sum": "Handles a hardware-interrupt\u2013related initialization path, configuring CPU-affinity bitmaps, invoking platform callbacks, and updating global state based on control flags.",
    "work_score": {
        "prorec": {
            "summary": "Handles a specific ACPI-enabled initialization path by invoking timing, memory setup, and callback routines, otherwise logging an error and returning failure.",
            "score": [
                0.10000000000000002,
                0.0,
                0.0
            ],
            "reason": [
                "The summary incorrectly claims the code handles an ACPI-enabled initialization path, includes memory setup, and invokes callback routines, none of which are evidenced in the source. The code is focused on APIC initialization, checking conditions such as `disable_apic`, `cpu_has_apic`, and `smp_found_config`, performing APIC setup functions, and setting up timers. There is no mention of ACPI-specific logic or memory setup, making all key details in the summary hallucinations and unverified.",
                "The summary references an ACPI-enabled initialization path, timing, memory setup, and callbacks, but none of these terms or specific actions appear in the source code. The actual code focuses on APIC initialization, conditional checks for APIC presence, BIOS configuration handling, routing setup, and IO-APIC setup, which are unrelated to ACPI. After discarding inaccuracies, no accurate details remain, so the core logic is entirely missed.",
                "The summary claims ACPI involvement, timing, memory setup, and callback routines, none of which are explicitly present in the source code. The code focuses on APIC initialization, with checks for disable_apic, cpu_has_apic, BIOS conditions, and functions like default_setup_apic_routing, verify_local_APIC, and setup_IO_APIC. There is no mention of ACPI, memory setup, or generic callbacks beyond APIC-specific routines. Over 50% of the summary\u2019s details are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Handles system initialization by invoking hardware-specific routines, updating control flags, modifying a shared buffer, and triggering follow-up ACPI or DMA-related operations based on configuration state.",
            "score": [
                0.3,
                0.26666666666666666,
                0.0
            ],
            "reason": [
                "The summary introduces several details such as modifying a shared buffer and triggering ACPI or DMA-related operations that have no explicit evidence in the source code, making them hallucinations. While 'invoking hardware-specific routines' and 'updating control flags' align with calls like default_setup_apic_routing(), verify_local_APIC(), and setting disable_apic, most other claimed operations are unverified or inaccurate. The majority of details lack direct support from the code, resulting in a low accuracy ratio.",
                "The summary contains multiple inaccuracies, such as claims about modifying a shared buffer and triggering ACPI or DMA-related operations, which have no evidence in the source code. The actual code focuses on APIC and IO-APIC initialization, hardware checks, and control flow based on system configuration. After discarding the inaccurate details, no accurate and complete description of the code's logic remains.",
                "The summary contains multiple inaccurate details: there is no evidence in the source code of modifying a shared buffer, nor of triggering ACPI or DMA-related operations. The summary vaguely mentions hardware-specific routines and updating control flags, which partially align with the APIC setup and flag changes in the source, but more than half of the stated details are hallucinated, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic int asn1_template_ex_d2i(ASN1_VALUE **val,\n\t\t\t\tconst unsigned char **in, long inlen,\n\t\t\t\tconst ASN1_TEMPLATE *tt, char opt,\n\t\t\t\t\t\t\tASN1_TLC *ctx)\n\t{\n\tint flags, aclass;\n\tint ret;\n\tlong len;\n\tconst unsigned char *p, *q;\n\tchar exp_eoc;\n\tif (!val)\n\t\treturn 0;\n\tflags = tt->flags;\n\taclass = flags & ASN1_TFLG_TAG_CLASS;\n\n\tp = *in;\n\n\t/* Check if EXPLICIT tag expected */\n\tif (flags & ASN1_TFLG_EXPTAG)\n\t\t{\n\t\tchar cst;\n\t\t/* Need to work out amount of data available to the inner\n\t\t * content and where it starts: so read in EXPLICIT header to\n\t\t * get the info.\n\t\t */\n\t\tret = asn1_check_tlen(&len, NULL, NULL, &exp_eoc, &cst,\n\t\t\t\t\t&p, inlen, tt->tag, aclass, opt, ctx);\n\t\tq = p;\n\t\tif (!ret)\n\t\t\t{\n\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tERR_R_NESTED_ASN1_ERROR);\n\t\t\treturn 0;\n\t\t\t}\n\t\telse if (ret == -1)\n\t\t\treturn -1;\n\t\tif (!cst)\n\t\t\t{\n\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tASN1_R_EXPLICIT_TAG_NOT_CONSTRUCTED);\n\t\t\treturn 0;\n\t\t\t}\n\t\t/* We've found the field so it can't be OPTIONAL now */\n\t\tret = asn1_template_noexp_d2i(val, &p, len, tt, 0, ctx);\n\t\tif (!ret)\n\t\t\t{\n\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tERR_R_NESTED_ASN1_ERROR);\n\t\t\treturn 0;\n\t\t\t}\n\t\t/* We read the field in OK so update length */\n\t\tlen -= p - q;\n\t\tif (exp_eoc)\n\t\t\t{\n\t\t\t/* If NDEF we must have an EOC here */\n\t\t\tif (!asn1_check_eoc(&p, len))\n\t\t\t\t{\n\t\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\t\tASN1_R_MISSING_EOC);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\telse\n\t\t\t{\n\t\t\t/* Otherwise we must hit the EXPLICIT tag end or its\n\t\t\t * an error */\n\t\t\tif (len)\n\t\t\t\t{\n\t\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tASN1_R_EXPLICIT_LENGTH_MISMATCH);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse \n\t\t\treturn asn1_template_noexp_d2i(val, in, inlen,\n\t\t\t\t\t\t\t\ttt, opt, ctx);\n\n\t*in = p;\n\treturn 1;\n\n\terr:\n\tASN1_template_free(val, tt);\n\treturn 0;\n\t}",
    "comment": "Parses an ASN.1 encoded structure, handling explicit tags and validating length, while managing errors and memory for the decoded value.",
    "prorec_sum": "Decodes an ASN.1 template with specific flags, validates structure and content, reports parsing errors, and updates the input pointer on success.",
    "filter_prorec_sum": "Parses and validates ASN.1 data using decoding helpers, updating buffer pointers and reporting errors for invalid length or structure conditions.",
    "prorec_aug_sum": "Parses ASN.1 encoded data with optional indefinite-length handling, validates structure, reports specific decoding errors, and updates the input buffer position.",
    "filter_prorec_aug_sum": "Decodes an ASN.1 template with optional indefinite-length content, validates structure, updates buffer position, and reports errors for invalid or unexpected data.",
    "work_score": {
        "prorec": {
            "summary": "Decodes an ASN.1 template with specific flags, validates structure and content, reports parsing errors, and updates the input pointer on success.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function decodes an ASN.1 template, checks flags, validates structure, reports parsing errors, and updates the input pointer on success, all of which are explicitly evidenced in the source code through the use of flags, error handling via ASN1err, and updating '*in'. No unverified or hallucinated details are present, making the alignment very high.",
                "The summary accurately captures that the function decodes an ASN.1 template, uses flags, validates structure and content, performs error reporting, and updates the input pointer on success. These details are explicitly supported by the source code through flag checks, calls to parsing functions, multiple ASN1err error reports, and *in being updated to p on success. However, the summary omits significant logic such as handling explicit and non-explicit tags, managing length mismatches, EOC checks, and freeing resources on errors, which are critical to the function's behavior.",
                "The summary contains several accurate details: it correctly notes that the function decodes an ASN.1 template using specific flags, performs structure/content validation, reports errors using ASN1err, and updates the input pointer on success. These are all explicitly evidenced in the source code through the use of 'flags', checks for EXPLICIT tags, calls to error reporting functions, and pointer updates. No details in the summary are inaccurate, but the description is fairly generic and does not capture deeper specifics like the handling of explicit vs. non-explicit tags or EOC checks, which limits domain richness."
            ]
        },
        "filter_prorec": {
            "summary": "Parses and validates ASN.1 data using decoding helpers, updating buffer pointers and reporting errors for invalid length or structure conditions.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function parses ASN.1 data using decoding helpers and reports errors for invalid length or structure, which is explicitly supported by calls to helpers like `asn1_check_tlen`, `asn1_template_noexp_d2i`, and error handling with `ASN1err`. It also mentions updating buffer pointers, which is evident from modifications to `p` and `*in`. All details in the summary are directly verifiable in the source code, with no unsubstantiated claims.",
                "The summary accurately captures that the function processes ASN.1 data, uses decoding helper functions, updates buffer pointers, and reports errors for invalid lengths or structural issues. These points are directly supported by the code\u2019s calls to asn1_check_tlen, asn1_template_noexp_d2i, ASN1err, pointer adjustments, and explicit length/EOC checks. However, the summary is high-level and omits detailed control flow specifics such as handling EXPLICIT tags, optional fields, and the exact branching for NDEF/EOC. This results in partial coverage of the complete logic.",
                "The summary accurately notes parsing and validation of ASN.1 data, use of decoding helpers, updating of buffer pointers, and error reporting for invalid length or structure, all of which are explicitly present in the source code via functions like asn1_check_tlen, asn1_template_noexp_d2i, pointer adjustments, and multiple ASN1err calls. However, these details are somewhat generic and don't capture deeper specifics such as handling EXPLICIT tags, NDEF EOC checks, or optional fields, reducing the domain richness of the insights."
            ]
        }
    }
}
{
    "source_code": "\nstatic psmouse_ret_t cypress_protocol_handler(struct psmouse *psmouse)\n{\n\tstruct cytp_data *cytp = psmouse->private;\n\n\tif (psmouse->pktcnt >= cytp->pkt_size) {\n\t\tcypress_process_packet(psmouse, 0);\n\t\treturn PSMOUSE_FULL_PACKET;\n\t}\n\n\treturn cypress_validate_byte(psmouse);\n}",
    "comment": "Handles packet processing for a Cypress device, validating bytes and triggering full packet processing when the expected packet size is reached.",
    "prorec_sum": "Updates a control field based on status and flag checks, or triggers a helper function when index bounds or mask conditions are unmet.",
    "filter_prorec_sum": "Checks and updates a device state counter, modifying configuration flags, or triggering a reset routine when specific bitmask conditions are unmet.",
    "prorec_aug_sum": "Validates index bounds and updates hardware control fields based on status flags, or triggers a reset routine when conditions are not met.",
    "filter_prorec_aug_sum": "Checks state fields and flags in a1, updates a control value, or resets via sub_FFFFFFFF814F66A0, returning status codes accordingly.",
    "work_score": {
        "prorec": {
            "summary": "Updates a control field based on status and flag checks, or triggers a helper function when index bounds or mask conditions are unmet.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes operations involving control field updates, status and flag checks, index bounds, and mask conditions, none of which are evident in the source code. The code instead checks a packet count against a packet size, calls cypress_process_packet or cypress_validate_byte, and returns constants. All summary details are hallucinations, resulting in no accurate details.",
                "The summary claims updates to a control field based on status and flag checks, and triggering a helper function under certain index or mask conditions. None of these details have explicit evidence in the source code, which only checks if pktcnt >= pkt_size, calls cypress_process_packet, returns PSMOUSE_FULL_PACKET, or calls cypress_validate_byte. The described control field updates, status/flag checks, index bounds, and mask conditions are entirely absent, making the summary wholly inaccurate.",
                "The summary claims updates to a control field and the use of status/flag checks, index bounds, and mask conditions, none of which are evident in the source code. The code only checks if pktcnt >= pkt_size and then calls cypress_process_packet or cypress_validate_byte. All described details in the summary are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Checks and updates a device state counter, modifying configuration flags, or triggering a reset routine when specific bitmask conditions are unmet.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims updates to a device state counter, modification of configuration flags, and triggering of a reset routine based on bitmask conditions, but the source code strictly checks packet count against a size, calls cypress_process_packet, returns constants, and validates bytes. None of the described bitmask logic or configuration changes are present, meaning all semantic details are inaccurate.",
                "The summary's claims about modifying configuration flags, triggering a reset routine, and checking bitmask conditions have no evidence in the source code. The code only checks whether the packet count meets or exceeds the packet size, processes the packet if so, and returns results from either the processing function or a validation function. None of the described operations in the summary are present, leaving no accurate details to map to the critical semantic units.",
                "The summary mentions modifying configuration flags, triggering a reset routine, and specific bitmask conditions, none of which are present in the source code. The actual code checks if the packet count reaches a defined size, processes the packet, and returns specific constants or validates a byte. All claimed details in the summary are inaccurate, exceeding the inaccuracy threshold, so the evaluation stops at the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\ninfo_signal_proc (int sig)\n{\n  signal_info *old_signal_handler = NULL;\n\n#if !defined (HAVE_SIGACTION)\n  /* best effort: first increment this counter and later block signals */\n  if (term_conf_busy)\n    return;\n  term_conf_busy++;\n#if defined (HAVE_SIGPROCMASK)\n    {\n      sigset_t nvar, ovar;\n      sigemptyset (&nvar);\n      mask_termsig (&nvar);\n      sigprocmask (SIG_BLOCK, &nvar, &ovar);\n    }\n#endif /* HAVE_SIGPROCMASK */\n#endif /* !HAVE_SIGACTION */\n  switch (sig)\n    {\n#if defined (SIGTSTP)\n    case SIGTSTP:\n    case SIGTTOU:\n    case SIGTTIN:\n#endif\n#if defined (SIGQUIT)\n    case SIGQUIT:\n#endif\n#if defined (SIGINT)\n    case SIGINT:\n#endif\n#if defined (SIGTERM)\n    case SIGTERM:\n#endif\n      {\n#if defined (SIGTSTP)\n        if (sig == SIGTSTP)\n          old_signal_handler = &old_TSTP;\n        if (sig == SIGTTOU)\n          old_signal_handler = &old_TTOU;\n        if (sig == SIGTTIN)\n          old_signal_handler = &old_TTIN;\n#endif /* SIGTSTP */\n#if defined (SIGQUIT)\n        if (sig == SIGQUIT)\n          old_signal_handler = &old_QUIT;\n#endif /* SIGQUIT */\n#if defined (SIGINT)\n        if (sig == SIGINT)\n          old_signal_handler = &old_INT;\n#endif /* SIGINT */\n#if defined (SIGTERM)\n        if (sig == SIGTERM)\n          old_signal_handler = &old_TERM;\n#endif /* SIGTERM */\n\n        /* For stop signals, restore the terminal IO, leave the cursor\n           at the bottom of the window, and stop us. */\n        terminal_goto_xy (0, screenheight - 1);\n        terminal_clear_to_eol ();\n        fflush (stdout);\n        terminal_unprep_terminal ();\n\trestore_termsig (sig, old_signal_handler);\n\tUNBLOCK_SIGNAL (sig);\n\tkill (getpid (), sig);\n\n        /* The program is returning now.  Restore our signal handler,\n           turn on terminal handling, redraw the screen, and place the\n           cursor where it belongs. */\n        terminal_prep_terminal ();\n\tset_termsig (sig, old_signal_handler);\n\t/* window size might be changed while sleeping */\n\treset_info_window_sizes ();\n      }\n      break;\n\n#if defined (SIGWINCH) || defined (SIGUSR1)\n#ifdef SIGWINCH\n    case SIGWINCH:\n#endif\n#ifdef SIGUSR1\n    case SIGUSR1:\n#endif\n      {\n\t/* Turn off terminal IO, tell our parent that the window has changed,\n\t   then reinitialize the terminal and rebuild our windows. */\n#ifdef SIGWINCH\n\tif (sig == SIGWINCH)\n\t  old_signal_handler = &old_WINCH;\n#endif\n#ifdef SIGUSR1\n\tif (sig == SIGUSR1)\n\t  old_signal_handler = &old_USR1;\n#endif\n\n        /* This seems risky: what if we receive a (real) signal before\n           the next line is reached? */\n#if 0\n\trestore_termsig (sig, old_signal_handler);\n\tkill (getpid (), sig);\n#endif\n\n\t/* After our old signal handler returns... */\n\tset_termsig (sig, old_signal_handler); /* needless? */\n\n        if (sigwinch_block_count != 0)\n          abort ();\n\n        /* Avoid any of the code unblocking the signal too early.  This\n           should set the variable to 1 because we shouldn't be here if\n           sigwinch_block_count > 0. */\n        sigwinch_block_count++;\n\n\treset_info_window_sizes ();\n\n        sigwinch_block_count--;\n        /* Don't unblock the signal until after we've finished. */\n\tUNBLOCK_SIGNAL (sig);\n      }\n      break;\n#endif /* SIGWINCH || SIGUSR1 */\n    }\n#if !defined (HAVE_SIGACTION)\n  /* at this time it is safer to perform unblock after decrement */\n  term_conf_busy--;\n#if defined (HAVE_SIGPROCMASK)\n    {\n      sigset_t nvar, ovar;\n      sigemptyset (&nvar);\n      mask_termsig (&nvar);\n      sigprocmask (SIG_UNBLOCK, &nvar, &ovar);\n    }\n#endif /* HAVE_SIGPROCMASK */\n#endif /* !HAVE_SIGACTION */\n}",
    "comment": "Handles various signals by restoring terminal settings, blocking signals during critical sections, and managing terminal window size changes.",
    "prorec_sum": "Handles specific signals by temporarily swapping handlers, blocking and raising them, performing cleanup or abort logic, then restoring original signal actions.",
    "filter_prorec_sum": "Handles specific Unix signals by temporarily replacing handlers, performing cleanup, sending the signal to itself, and restoring the original handlers.",
    "prorec_aug_sum": "Handles specific signals by temporarily changing their handlers, triggering the signal for self-processing, and restoring original handlers and signal masks.",
    "filter_prorec_aug_sum": "Handles specific signals by temporarily changing their handlers, sending the signal to itself, executing cleanup routines, and restoring the original handlers.",
    "work_score": {
        "prorec": {
            "summary": "Handles specific signals by temporarily swapping handlers, blocking and raising them, performing cleanup or abort logic, then restoring original signal actions.",
            "score": [
                0.9333333333333332,
                0.6666666666666666,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly notes that the function handles specific signals and restores original actions, which is explicitly shown in the switch statement and calls to set_termsig/restore_termsig. It also mentions blocking signals, which is evidenced by sigprocmask and UNBLOCK_SIGNAL calls, and raising them via kill. However, it omits key details about separate logic for SIGWINCH/SIGUSR1 and the terminal preparation/cleanup steps, and introduces 'abort logic' without directly supported evidence for most signals (abort only occurs for SIGWINCH with a block count check). Thus, while the main points are mostly accurate, there is a slight overgeneralization and omission of context-specific behavior.",
                "The summary correctly captures that the function handles specific signals, swaps to stored old handlers, blocks signals, and performs cleanup before restoring. These behaviors are explicitly evidenced in the code via setting 'old_signal_handler', calling 'UNBLOCK_SIGNAL', 'kill', 'restore_termsig', 'set_termsig', and cleanup functions like 'terminal_unprep_terminal'. It also recognizes abort logic for SIGWINCH via 'abort()'. However, the summary omits important details such as the different handling paths for stop signals vs. window change signals, and the specific terminal state adjustments and window size resets. Thus, while the main idea is accurate, it lacks completeness on control flow nuances and edge handling.",
                "The summary's claim about handling specific signals is supported by the source code, which demonstrates cases for SIGTSTP, SIGTTOU, SIGTTIN, SIGQUIT, SIGINT, SIGTERM, SIGWINCH, and SIGUSR1, along with saving/restoring old signal handlers. Blocking via sigprocmask and raising signals with kill() are present, as is restoration of handlers and terminal cleanup. However, the summary omits the terminal-specific operations and the conditional abort logic for SIGWINCH, making it less domain-rich and somewhat generic despite accuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Handles specific Unix signals by temporarily replacing handlers, performing cleanup, sending the signal to itself, and restoring the original handlers.",
            "score": [
                1.0,
                0.6333333333333333,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly identifies that the function handles specific Unix signals and involves temporarily replacing handlers, performing cleanup, sending the signal to itself, and restoring the original handlers. These behaviors are explicitly evidenced in the source code through `set_termsig`, `restore_termsig`, cleanup functions like `terminal_unprep_terminal`, the `kill(getpid(), sig)` call, and subsequent restoration steps. All key details mentioned in the summary are directly supported, with no unverified claims.",
                "The summary correctly states that the function handles specific Unix signals, temporarily replaces handlers, performs cleanup, sends the signal to itself, and restores the original handlers \u2014 all of which are explicitly shown in the source code through assignments to old_signal_handler, cleanup functions like terminal_unprep_terminal, kill(getpid(), sig), and set_termsig calls. However, it omits mention of key logic for SIGWINCH/SIGUSR1 handling, conditional compilation for signal types, and counter variables (term_conf_busy, sigwinch_block_count). These omissions mean it covers the core behavior but lacks important signal-specific edge cases.",
                "The summary accurately reflects core behaviors evident in the source code, including handling of specific Unix signals, temporary replacement of signal handlers, performing terminal cleanup, invoking `kill` on the current process, and restoring original handlers after execution. These details are supported by the explicit calls to `set_termsig`, `restore_termsig`, terminal-related cleanup functions, and `kill(getpid(), sig)`. The description is concise but domain-relevant, giving a clear picture of the signal handling flow without introducing unsupported claims."
            ]
        }
    }
}
{
    "source_code": "int ENGINE_add(ENGINE *e)\n\t{\n\tint to_return = 1;\n\tif(e == NULL)\n\t\t{\n\t\tENGINEerr(ENGINE_F_ENGINE_ADD,\n\t\t\tERR_R_PASSED_NULL_PARAMETER);\n\t\treturn 0;\n\t\t}\n\tif((e->id == NULL) || (e->name == NULL))\n\t\t{\n\t\tENGINEerr(ENGINE_F_ENGINE_ADD,\n\t\t\tENGINE_R_ID_OR_NAME_MISSING);\n\t\t}\n\tCRYPTO_w_lock(CRYPTO_LOCK_ENGINE);\n\tif(!engine_list_add(e))\n\t\t{\n\t\tENGINEerr(ENGINE_F_ENGINE_ADD,\n\t\t\tENGINE_R_INTERNAL_LIST_ERROR);\n\t\tto_return = 0;\n\t\t}\n\tCRYPTO_w_unlock(CRYPTO_LOCK_ENGINE);\n\treturn to_return;\n\t}",
    "comment": "Adds an ENGINE structure to a list after validating its parameters and managing thread safety with locks.",
    "prorec_sum": "Registers a new ENGINE into the global linked list, ensuring unique names, updating pointers, and reporting errors with locking for thread safety.",
    "filter_prorec_sum": "Adds a new ENGINE to the global engine list with locking, duplicate checks, error reporting, and linked-list maintenance.",
    "prorec_aug_sum": "Registers a new ENGINE into the global engine list, ensuring unique names, linking list pointers, and reporting errors for invalid or duplicate entries.",
    "filter_prorec_aug_sum": "Registers a new ENGINE into the global engine list, ensuring unique names, updating linked pointers, and reporting errors under locking.",
    "work_score": {
        "prorec": {
            "summary": "Registers a new ENGINE into the global linked list, ensuring unique names, updating pointers, and reporting errors with locking for thread safety.",
            "score": [
                0.43333333333333335,
                0.5333333333333333,
                0.0
            ],
            "reason": [
                "The summary contains multiple details not supported by the source code. While it correctly states that it registers an ENGINE, reports errors, and uses locking for thread safety (accurate to CRYPTO_w_lock/CRYPTO_w_unlock), the source code does not explicitly ensure unique names or update pointers, nor does it mention a global linked list by name; these are unverified assumptions. This results in fewer than half of the details being accurate.",
                "The summary contains several inaccuracies: there is no explicit logic ensuring unique names or updating pointers in the source code. The code does add an ENGINE to a global list with locking for thread safety and error reporting when parameters are null or missing, which is accurately reflected. However, after discarding the hallucinated details, only the basic addition to the list with locking and error handling remains, missing critical specifics like internal edge cases beyond the evident ones.",
                "The summary claims uniqueness checking and pointer updating, but the source code shows no logic enforcing uniqueness or performing pointer updates; only null checks on id and name, error reporting, and use of CRYPTO_w_lock/unlock around engine_list_add are present. While it correctly notes registration into a global list, error handling, and locking for thread safety, the majority of the details are inaccurate, leading to failure at the kill switch step."
            ]
        },
        "filter_prorec": {
            "summary": "Adds a new ENGINE to the global engine list with locking, duplicate checks, error reporting, and linked-list maintenance.",
            "score": [
                0.5333333333333333,
                0.6,
                0.4666666666666666
            ],
            "reason": [
                "The summary correctly notes adding a new ENGINE to a global list and the presence of locking and error reporting, which are supported by functions like CRYPTO_w_lock/unlock and ENGINEerr in the code. However, it introduces details about duplicate checks and linked-list maintenance that are not explicitly evident in the provided source code. Without direct evidence of these specific operations in the snippet, those claims are considered inaccuracies, resulting in a mixed accuracy assessment.",
                "The summary correctly notes adding an ENGINE to a global list with locking and error reporting, which is evident from CRYPTO_w_lock, CRYPTO_w_unlock, and ENGINEerr calls. However, 'duplicate checks' and 'linked-list maintenance' are not explicitly supported in the source code, and there is no direct global list reference\u2014only a call to engine_list_add without clear duplicate logic. After filtering inaccuracies, the remaining accurate details cover main operations but omit specifics about parameter validation and internal list error handling, leaving the description incomplete.",
                "The summary claims duplicate checks, which are not explicitly present in the source code; locking, error reporting, and linked-list maintenance via engine_list_add are accurate. Of the four distinct details, one is inaccurate, keeping inaccurate proportion at 25%. The accurate details are domain-specific, citing locking routines, error handling, and list updates, which offer meaningful insight into the code\u2019s behavior."
            ]
        }
    }
}
{
    "source_code": "\nstatic int inet6_addr_del(struct net *net, int ifindex, const struct in6_addr *pfx,\n\t\t\t  unsigned int plen)\n{\n\tstruct inet6_ifaddr *ifp;\n\tstruct inet6_dev *idev;\n\tstruct net_device *dev;\n\n\tif (plen > 128)\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tif ((idev = __in6_dev_get(dev)) == NULL)\n\t\treturn -ENXIO;\n\n\tread_lock_bh(&idev->lock);\n\tlist_for_each_entry(ifp, &idev->addr_list, if_list) {\n\t\tif (ifp->prefix_len == plen &&\n\t\t    ipv6_addr_equal(pfx, &ifp->addr)) {\n\t\t\tin6_ifa_hold(ifp);\n\t\t\tread_unlock_bh(&idev->lock);\n\n\t\t\tipv6_del_addr(ifp);\n\n\t\t\t/* If the last address is deleted administratively,\n\t\t\t   disable IPv6 on this interface.\n\t\t\t */\n\t\t\tif (list_empty(&idev->addr_list))\n\t\t\t\taddrconf_ifdown(idev->dev, 1);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tread_unlock_bh(&idev->lock);\n\treturn -EADDRNOTAVAIL;\n}",
    "comment": "Removes an IPv6 address from a network interface and disables IPv6 if it becomes the last address.",
    "prorec_sum": "Searches for a matching entry by ID and identifier, updates counters, and executes follow-up operations with provided parameters if found.",
    "filter_prorec_sum": "Searches a linked list for a matching entry by ID and key, then updates reference counts and triggers associated processing functions.",
    "prorec_aug_sum": "Searches a linked list for a matching entry by ID and key, then updates related data structures and triggers follow\u2011up processing if found.",
    "filter_prorec_aug_sum": "Searches a linked data structure for a matching entry by key and OWORD value, then updates reference count and processes with provided parameters.",
    "work_score": {
        "prorec": {
            "summary": "Searches for a matching entry by ID and identifier, updates counters, and executes follow-up operations with provided parameters if found.",
            "score": [
                0.20000000000000004,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims the code searches by ID and identifier, updates counters, and executes follow-up operations with provided parameters. In the source, the function searches for a matching IPv6 address based on prefix length and address, but there is no evidence of searching by a generic ID, updating counters, or using provided parameters in the way described. The operations include removing the address and possibly disabling IPv6, not generic 'follow-up operations.' These mismatches indicate that the majority of details are hallucinations.",
                "The summary's claims about searching by ID and identifier, updating counters, and executing follow-up operations are inaccurate. The source code searches for a matching IPv6 address and prefix length, performs address deletion, and handles error cases, but there is no evidence of counters being updated or operations tied to an ID/identifier unrelated to network interface indexing. After filtering out inaccuracies, no accurate details remain to describe the core logic.",
                "The summary claims the code searches by ID and identifier, updates counters, and performs follow-up operations with provided parameters, none of which are explicitly evidenced in the source. The source code actually searches for an IPv6 address matching a prefix length and address, uses locks, and invokes functions to remove the address and potentially disable IPv6. Since all stated details in the summary are inaccurate, the proportion of inaccuracies exceeds 50%, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Searches a linked list for a matching entry by ID and key, then updates reference counts and triggers associated processing functions.",
            "score": [
                0.3,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims a search in a linked list by ID and key, reference count updates, and triggering associated processing functions. In the source, the search is in a linked list of IPv6 addresses matched by prefix length and address, not ID and key. It does call in6_ifa_hold (reference count increment) and ipv6_del_addr (processing function), which partially aligns, but most semantic details about ID, key, and generic processing are inaccurate. Less than half of the details are explicitly supported by the code.",
                "The summary describes searching a linked list by ID and key, updating reference counts, and triggering processing functions. The source code actually searches a linked list of IPv6 interface addresses by prefix length and address, holds a reference to the matching address, deletes it, and potentially disables IPv6 if the list becomes empty. The summary\u2019s mention of an ID and key does not match the address and prefix logic, and it omits key edge case handling such as length validation, device lookup errors, and IPv6 disable behavior. After discarding the inaccurate details, the remaining content fails to capture the core logic.",
                "The summary claims a search by ID and key, which is inaccurate because the code searches a linked list of IPv6 addresses by prefix length and address, not by an arbitrary ID/key combination. It also omits critical specific details such as the checks for prefix length, device retrieval, lock management, and IPv6 disable logic. More than half of the semantic elements in the summary are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic char *\nstyle_sheet_mixed_new (const uchar * ancestors)\n{\n  struct style_sheet *sheet, *ancestor;\n  char *ancestor_key, *key, *cp;\n  char *ancestors_keys;\n  struct darray *ancestors_array;\n\n  /* It cannot be longer than ancestors_keys. */\n  key = ALLOCA (char, ustrlen (ancestors) + 1);\n  astrcpy (ancestors_keys, ancestors);\n\n  /* Create the darray of ancestors keys, and build the final key. */\n  ancestors_array = ancestors_new ();\n  ancestor_key = strtok (ancestors_keys, MIXED_SHEET_SEP);\n  da_append (ancestors_array, ancestor_key);\n  ancestor = get_style_sheet (ancestor_key);\n  cp = stpcpy (key, ancestor->key);\n\n  while ((ancestor_key = strtok (NULL, MIXED_SHEET_SEP)))\n    {\n      da_append (ancestors_array, ancestor_key);\n      ancestor = get_style_sheet (ancestor_key);\n      *cp++ =',';\n      cp = stpcpy (cp, ancestor->key);\n    }\n  *cp = '\\0';\n  key = xstrdup (key);\n\n  /* Create the style sheet. */\n  message (msg_sheet,\n\t   (stderr, \"Creating a mixed style sheet \\\"%s\\\"\\n\", key));\n  /* Its name is its key. */\n  sheet = new_style_sheet ((uchar *) key);\n  sheet->key = strdup (key);\n  da_concat (sheet->ancestors, ancestors_array);\n  da_erase (ancestors_array);\n  style_sheet_finalize (sheet);\n\n  return key;\n}",
    "comment": "Creates a new style sheet by concatenating keys from ancestor style sheets, storing them in a darray, and finalizing the new sheet.",
    "prorec_sum": "Parses a comma- or plus-separated style list, registers each style under \u201cAncestors,\u201d and creates a mixed style sheet entry from them.",
    "filter_prorec_sum": "Parses a comma/semicolon/plus-separated list of ancestor style sheets, registers them, builds a combined sheet name, and updates related style sheet structures.",
    "prorec_aug_sum": "Parses a comma/semicolon/plus-separated list of ancestor style sheets, registers them, builds a combined sheet, and associates it with the stylesheet group.",
    "filter_prorec_aug_sum": "Processes a comma\u2011delimited list of ancestor stylesheet names, builds a combined mixed stylesheet object, and registers it for subsequent use.",
    "work_score": {
        "prorec": {
            "summary": "Parses a comma- or plus-separated style list, registers each style under \u201cAncestors,\u201d and creates a mixed style sheet entry from them.",
            "score": [
                0.5666666666666668,
                0.4666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims that the function parses a comma- or plus-separated style list, but the source code shows it specifically parses using the MIXED_SHEET_SEP constant without evidence of plus separation. It also mentions registering each style under 'Ancestors,' which is not explicitly present; the code appends to an ancestors_array but does not show a registration step named 'Ancestors.' The final claim about creating a mixed style sheet entry is accurate, as the code constructs a key, creates a new style sheet, and sets its key. Overall, only part of the summary is directly supported, so accuracy is mixed, with some unverifiable assumptions.",
                "The summary claims comma- or plus-separated parsing, but the source code only shows splitting by the MIXED_SHEET_SEP constant with no evidence of plus separator. The 'registers each style under Ancestors' phrase is vague and not explicitly validated in the code; instead, the code appends ancestor keys to a darray and retrieves style sheets. The creation of a mixed style sheet entry is accurate, but key control flow and data manipulations such as key building, message logging, and da_concat are omitted. As a result, only part of the core logic is captured, and important steps are missing.",
                "The summary claims the function parses a comma- or plus-separated style list and registers each style under 'Ancestors', but the source code only shows splitting by MIXED_SHEET_SEP and appending to a darray, without explicit evidence that the separator is comma or plus, nor any registration under a structure named 'Ancestors'. The accurate detail is that it creates a mixed style sheet from parts obtained via strtok and get_style_sheet, but most specifics about separators and registration are unsupported, leading to more than half of the details being inaccurate."
            ]
        },
        "filter_prorec": {
            "summary": "Parses a comma/semicolon/plus-separated list of ancestor style sheets, registers them, builds a combined sheet name, and updates related style sheet structures.",
            "score": [
                0.6666666666666666,
                0.6,
                0.0
            ],
            "reason": [
                "The summary claims support for comma, semicolon, and plus-separated lists, but the source code only uses the MIXED_SHEET_SEP macro in strtok calls without explicit evidence of it covering all three separators. While it correctly notes that ancestor style sheets are registered (via da_append and get_style_sheet) and a combined name is built (concatenating ancestor->key values), the assertion about multiple separator types is unverified and likely inaccurate. The portion about updating related style sheet structures is accurate, supported by da_concat, style_sheet_finalize, and assigning sheet->key. This yields a mix of accurate and inaccurate details.",
                "The summary claims that the code parses a list of ancestor style sheets separated by comma, semicolon, or plus, but the source code only shows usage of a single separator defined by MIXED_SHEET_SEP, with no explicit evidence of multiple separator types. The part about registering ancestor sheets and building a combined sheet name is accurate, as the code calls da_append, get_style_sheet, and concatenates keys with commas to form the final name. The mention of 'updates related style sheet structures' is partially accurate \u2014 sheet->key assignment and da_concat occur \u2014 but lacks detail about other potential structure updates or edge cases in the code. Since some details are hallucinated and the accurate ones cover the main flow but omit finer points such as error handling or memory management specifics, completeness is moderate.",
                "The summary claims parsing a list separated by commas, semicolons, or plus signs, but the source code only shows the use of a single separator constant 'MIXED_SHEET_SEP' without evidence of multiple separator types, making that detail inaccurate. The code does create a combined key from ancestor style sheets and updates style sheet structures, which aligns with registering ancestors and building a combined sheet name. However, more than half of the specific separator-related details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "EXPORT BITCODE_H\ndwg_find_tablehandle (Dwg_Data *restrict dwg, const char *restrict name,\n                      const char *restrict table)\n{\n  BITCODE_BL i, num_entries = 0;\n  BITCODE_H ctrl = NULL, *hdlv = NULL;\n  Dwg_Object *obj;\n  Dwg_Object_APPID_CONTROL *_obj; // just some random generic type\n  Dwg_Header_Variables *vars = &dwg->header_vars;\n\n  if (!dwg || !name || !table)\n    return NULL;\n  // look for the _CONTROL table, and search for name in all entries\n  ctrl = dwg_ctrl_table (dwg, table);\n  if (strEQc (table, \"LTYPE\"))\n    {\n      if (strEQc (name, \"BYLAYER\") || strEQc (name, \"ByLayer\"))\n        {\n          if (vars->LTYPE_BYLAYER)\n            return vars->LTYPE_BYLAYER;\n        }\n      else if (strEQc (name, \"BYBLOCK\") || strEQc (name, \"ByBlock\"))\n        {\n          if (vars->LTYPE_BYBLOCK)\n            return vars->LTYPE_BYBLOCK;\n        }\n      else if (strEQc (name, \"CONTINUOUS\") || strEQc (name, \"Continuous\"))\n        {\n          if (vars->LTYPE_CONTINUOUS)\n            return vars->LTYPE_CONTINUOUS;\n        }\n    }\n  if (!ctrl)\n    { // TODO: silently search table_control. header_vars can be empty\n      LOG_TRACE (\"dwg_find_tablehandle: Empty header_vars table %s\\n\", table);\n      return NULL;\n    }\n  obj = dwg_resolve_handle (dwg, ctrl->absolute_ref);\n  if (!obj)\n    {\n      LOG_TRACE (\"dwg_find_tablehandle: Could not resolve table %s\\n\", table);\n      return NULL;\n    }\n  if (obj->type == DWG_TYPE_DICTIONARY)\n    return dwg_find_dicthandle_objname (dwg, ctrl, name);\n  if (!dwg_obj_is_control (obj))\n    {\n      LOG_ERROR (\"dwg_find_tablehandle: Could not resolve CONTROL object %s \"\n                 \"for table %s\",\n                 obj->name, table);\n      return NULL;\n    }\n  _obj = obj->tio.object->tio.APPID_CONTROL; // just random type\n  dwg_dynapi_entity_value (_obj, obj->name, \"num_entries\", &num_entries, NULL);\n  if (!num_entries)\n    return NULL;\n  dwg_dynapi_entity_value (_obj, obj->name, \"entries\", &hdlv, NULL);\n  if (!hdlv)\n    return NULL;\n  for (i = 0; i < num_entries; i++)\n    {\n      char *hdlname;\n      Dwg_Object *hobj;\n      Dwg_Object_APPID *_o;\n      int isnew = 0;\n      bool ok;\n\n      if (!hdlv[i])\n        continue;\n      hobj = dwg_resolve_handle (dwg, hdlv[i]->absolute_ref);\n      if (!hobj || !hobj->tio.object || !hobj->tio.object->tio.APPID)\n        continue;\n      _o = hobj->tio.object->tio.APPID;\n      ok = dwg_dynapi_entity_utf8text (_o, hobj->name, \"name\", &hdlname, &isnew, NULL);\n      LOG_HANDLE (\" %s.%s[%d] => %s.name: %s\\n\", obj->name, \"entries\", i,\n                  hobj->name, hdlname ? hdlname : \"NULL\");\n      if (ok && hdlname && (strEQ (name, hdlname) || !strcasecmp (name, hdlname)))\n        {\n          if (isnew)\n            free (hdlname);\n          return hdlv[i];\n        }\n      if (ok && isnew && hdlname)\n        free (hdlname);\n    }\n\n  return NULL;\n}",
    "comment": "Retrieves a handle for a specified named entry in a given table from a DWG file's control structure.",
    "prorec_sum": "Retrieves a DWG table handle for a specified table and entry name, with special cases for common linetypes and error reporting on failures.",
    "filter_prorec_sum": "Retrieves a DWG table entry handle by name, with special-case handling for LTYPE values like BYLAYER, BYBLOCK, and CONTINUOUS.",
    "prorec_aug_sum": "Retrieves a specific DWG table handle by name, with special handling for common linetypes such as BYLAYER, BYBLOCK, and CONTINUOUS.",
    "filter_prorec_aug_sum": "Retrieves a specific DWG table handle for given table and entry names, using special-case shortcuts for common linetypes like ByLayer, ByBlock, and Continuous.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves a DWG table handle for a specified table and entry name, with special cases for common linetypes and error reporting on failures.",
            "score": [
                1.0,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly states that the function retrieves a DWG table handle for a given table and entry name, and notes special handling for common linetypes (BYLAYER, BYBLOCK, CONTINUOUS) and error reporting on failures, all of which are explicitly present in the source code. These cover the main functional and conditional aspects without introducing unverified details.",
                "The summary accurately reflects the function's core purpose of retrieving a DWG table handle by table and name, notes special handling for common linetypes ('BYLAYER', 'BYBLOCK', 'CONTINUOUS') and mentions error reporting on failures, all of which are explicitly implemented in the source code. However, it omits significant logic such as null checks for inputs, resolution of control and dictionary objects, looping through entries with string comparisons, and freeing allocated memory. This results in incomplete coverage of the code's operational flow.",
                "The summary correctly states that the function retrieves a DWG table handle for a specified table and entry name, notes special-case handling for common linetypes (BYLAYER, BYBLOCK, CONTINUOUS) and mentions error reporting on failures, all of which are explicitly present in the source code. However, it omits details about internal resolution logic, type checks, and iteration through entries, making the accurate details somewhat generic rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves a DWG table entry handle by name, with special-case handling for LTYPE values like BYLAYER, BYBLOCK, and CONTINUOUS.",
            "score": [
                1.0,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly states that the function retrieves a DWG table entry handle by name and notes special-case handling for LTYPE values BYLAYER, BYBLOCK, and CONTINUOUS, all of which are explicitly present in the code. There are no additional claims beyond what is verifiable in the source, so all details are accurate, resulting in a perfect accuracy ratio.",
                "The summary correctly identifies that the function retrieves a DWG table entry handle by name and includes special-case handling for LTYPE values such as BYLAYER, BYBLOCK, and CONTINUOUS. These details are explicitly supported by the code\u2019s conditional checks for 'LTYPE' and specific name strings, and the logic for returning associated header variables. However, the summary omits significant parts of the logic, such as resolving control objects, handling dictionary types, iterating through entries, comparing names case-insensitively, and multiple null checks, meaning it does not capture the full control flow or edge case handling present in the source.",
                "The summary accurately captures the function's main purpose of retrieving a DWG table entry handle by name and notes the explicit special-case handling for LTYPE values BYLAYER, BYBLOCK, and CONTINUOUS, which is clearly present in the source code logic. It omits other control flow details but contains no inaccurate claims, and the accurate details are specific and domain-relevant."
            ]
        }
    }
}
{
    "source_code": "static void\nPerform_Justification(FIELD *field, WINDOW *win)\n{\n  FIELD_CELL *bp;\n  int len;\n\n  bp = (Field_Has_Option(field, O_NO_LEFT_STRIP)\n\t? field->buf\n\t: Get_Start_Of_Data(field->buf, Buffer_Length(field)));\n  len = (int)(After_End_Of_Data(field->buf, Buffer_Length(field)) - bp);\n\n  if (len > 0)\n    {\n      int col = 0;\n\n      assert(win && (field->drows == 1));\n\n      if (field->cols - len >= 0)\n\tswitch (field->just)\n\t  {\n\t  case JUSTIFY_LEFT:\n\t    break;\n\t  case JUSTIFY_CENTER:\n\t    col = (field->cols - len) / 2;\n\t    break;\n\t  case JUSTIFY_RIGHT:\n\t    col = field->cols - len;\n\t    break;\n\t  default:\n\t    break;\n\t  }\n\n      wmove(win, 0, col);\n      myADDNSTR(win, bp, len);\n    }\n}",
    "comment": "Justifies the contents of a field within a window by aligning text based on specified justification (left, center, right) and current field length.",
    "prorec_sum": "Trims leading and trailing space characters from a buffer segment and writes the resulting trimmed data to the destination via helper functions.",
    "filter_prorec_sum": "Trims leading and trailing space characters from a data buffer and writes the cleaned segment to the output via helper functions.",
    "prorec_aug_sum": "Trims leading and trailing space characters from a structured byte buffer and writes the cleaned segment to the specified output location.",
    "filter_prorec_aug_sum": "Trims leading and trailing spaces from a buffer segment and copies the cleaned data into the destination with optional size adjustment.",
    "work_score": {
        "prorec": {
            "summary": "Trims leading and trailing space characters from a buffer segment and writes the resulting trimmed data to the destination via helper functions.",
            "score": [
                0.26666666666666666,
                0.13333333333333333,
                0.0
            ],
            "reason": [
                "The summary claims that both leading and trailing spaces are trimmed from a buffer, but in the source code only leading spaces may be stripped, depending on the O_NO_LEFT_STRIP option. There is no logic to trim trailing spaces, and the trimming is not presented as explicitly removing space characters but rather finding the start and end of data. Additionally, the summary omits key justification logic and column positioning based on field->just, which is clearly present in the source. Thus, most details in the summary are inaccurate or unsupported.",
                "The summary claims the function trims both leading and trailing spaces, but the source code only conditionally strips leading spaces based on the O_NO_LEFT_STRIP option and does not explicitly handle trailing spaces. The actual logic adjusts the display column based on justification type and writes the data to the window, rather than focusing primarily on trimming. This makes the summary largely inaccurate, with no accurate details forming a complete picture of the code's logic.",
                "The summary claims that the function trims both leading and trailing spaces, but the source code only conditionally strips leading spaces using Get_Start_Of_Data unless O_NO_LEFT_STRIP is set; there is no explicit trailing space trimming logic. It also describes writing trimmed data to a destination via helper functions, which is partially accurate since myADDNSTR writes data to the window, but the data is not necessarily trimmed as claimed. Over 50% of the summary's details are unsupported by the code, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Trims leading and trailing space characters from a data buffer and writes the cleaned segment to the output via helper functions.",
            "score": [
                0.39999999999999997,
                0.26666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims that the function trims both leading and trailing spaces from a buffer, but the source code only conditionally strips leading spaces based on the O_NO_LEFT_STRIP option and determines the data end via After_End_Of_Data without explicit trailing space removal. It also omits details about text justification logic (LEFT, CENTER, RIGHT) and window positioning using wmove and myADDNSTR. Therefore, the majority of claimed behavior is not directly evidenced in the source code.",
                "The summary incorrectly claims that both leading and trailing spaces are trimmed from the buffer. The source code only conditionally strips leading spaces unless the O_NO_LEFT_STRIP option is set, and does not perform trailing space trimming\u2014it determines length using After_End_Of_Data. The writing to output via helper functions is accurate, as wmove and myADDNSTR handle that in the code. Overall, most of the described logic is not evidenced in the source, leaving only partial coverage of the core behavior.",
                "The summary claims the function trims both leading and trailing spaces before output, but in the source code only leading spaces may be stripped depending on the O_NO_LEFT_STRIP option; there is no explicit logic for trailing spaces removal. The accurate part is that the function writes a segment of the data buffer to the output using helper functions like wmove and myADDNSTR. Since more than half of the claimed behaviors (trimming leading and trailing) are inaccurate, this triggers the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nvoid acpi_ut_mutex_terminate(void)\n{\n\tu32 i;\n\n\tACPI_FUNCTION_TRACE(ut_mutex_terminate);\n\n\t/* Delete each predefined mutex object */\n\n\tfor (i = 0; i < ACPI_NUM_MUTEX; i++) {\n\t\tacpi_ut_delete_mutex(i);\n\t}\n\n\tacpi_os_delete_mutex(acpi_gbl_osi_mutex);\n\n\t/* Delete the spinlocks */\n\n\tacpi_os_delete_lock(acpi_gbl_gpe_lock);\n\tacpi_os_delete_lock(acpi_gbl_hardware_lock);\n\tacpi_os_delete_lock(acpi_gbl_reference_count_lock);\n\n\t/* Delete the reader/writer lock */\n\n\tacpi_ut_delete_rw_lock(&acpi_gbl_namespace_rw_lock);\n\treturn_VOID;\n}",
    "comment": "Terminates and deletes all predefined mutex objects, spinlocks, and a reader/writer lock to clean up synchronization mechanisms.",
    "prorec_sum": "Processes and clears multiple global data entries, invokes related subroutines on specific structures, and finalizes operations using provided floating-point and integer parameters.",
    "filter_prorec_sum": "Flushes and resets multiple global data entries, then processes remaining elements through helper routines before performing a final aggregated operation.",
    "prorec_aug_sum": "Processes and clears multiple global data entries, then invokes several helper routines with provided parameters to update or finalize a related data structure.",
    "filter_prorec_aug_sum": "Processes and resets multiple global data entries, then performs final update operations using provided parameters before returning the aggregated result.",
    "work_score": {
        "prorec": {
            "summary": "Processes and clears multiple global data entries, invokes related subroutines on specific structures, and finalizes operations using provided floating-point and integer parameters.",
            "score": [
                0.26666666666666666,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims the function processes and clears multiple global data entries, invokes related subroutines on specific structures, and uses floating-point and integer parameters. While the code does delete multiple global mutexes and locks via subroutines, there is no evidence of floating-point parameters or explicit handling of general global data entries beyond mutexes/locks. The mention of floating-point parameters is a clear hallucination, and 'specific structures' is too vague without direct code evidence. Most details are unsupported, resulting in low accuracy.",
                "The summary's claims about processing global data entries and using floating-point parameters are inaccurate, as the source code deals exclusively with deleting mutexes, locks, and reader/writer locks using integer indices and does not involve floating-point parameters or arbitrary global data entries. After discarding these hallucinations, there are no accurate details remaining to map to the source code's logic.",
                "The summary claims use of floating-point and integer parameters and operations on global data entries, which are not substantiated by the source code. The code deletes mutexes, locks, and a reader/writer lock, but there is no evidence of floating-point usage or processing of multiple global data entries beyond lock objects. Most key details are inaccurate, triggering the kill switch due to over 50% inaccuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Flushes and resets multiple global data entries, then processes remaining elements through helper routines before performing a final aggregated operation.",
            "score": [
                0.09999999999999999,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims flushing and resetting of global data entries, processing elements through helper routines, and a final aggregated operation. The source code shows deletion of various mutexes, spinlocks, and locks, but there is no evidence of flushing, resetting, or aggregation of data. Only the idea of processing elements via helper routines (e.g., acpi_ut_delete_mutex, acpi_os_delete_lock) is partially accurate. Most details are unverified and not explicitly supported by the code, resulting in a low accuracy ratio.",
                "The summary's claims about flushing and resetting global data entries, processing elements through helper routines, and performing a final aggregated operation are not explicitly supported by the source code. The actual code deletes predefined mutexes, spinlocks, and a reader/writer lock without any flushing, resetting, or aggregated final operation. After discarding these inaccurate details, no valid content remains, so the core logic is entirely missed.",
                "The summary's claims of flushing and resetting global data, processing remaining elements through helper routines, and performing a final aggregated operation are not explicitly supported by the source code. The code focuses on deleting mutexes, locks, and a reader/writer lock, with no evidence of flushing, resetting, or any aggregated operation. All described details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic bool\ndigest_file (const char *filename, int *binary, unsigned char *bin_result,\n             bool *missing)\n{\n  FILE *fp;\n  int err;\n  bool is_stdin = STREQ (filename, \"-\");\n\n  *missing = false;\n\n  if (is_stdin)\n    {\n      have_read_stdin = true;\n      fp = stdin;\n      if (O_BINARY && *binary)\n        {\n          if (*binary < 0)\n            *binary = ! isatty (STDIN_FILENO);\n          if (*binary)\n            xset_binary_mode (STDIN_FILENO, O_BINARY);\n        }\n    }\n  else\n    {\n      fp = fopen (filename, (O_BINARY && *binary ? \"rb\" : \"r\"));\n      if (fp == NULL)\n        {\n          if (ignore_missing && errno == ENOENT)\n            {\n              *missing = true;\n              return true;\n            }\n          error (0, errno, \"%s\", quotef (filename));\n          return false;\n        }\n    }\n\n  fadvise (fp, FADVISE_SEQUENTIAL);\n\n#if HASH_ALGO_BLAKE2\n  err = DIGEST_STREAM (fp, bin_result, b2_length / 8);\n#else\n  err = DIGEST_STREAM (fp, bin_result);\n#endif\n  if (err)\n    {\n      error (0, errno, \"%s\", quotef (filename));\n      if (fp != stdin)\n        fclose (fp);\n      return false;\n    }\n\n  if (!is_stdin && fclose (fp) != 0)\n    {\n      error (0, errno, \"%s\", quotef (filename));\n      return false;\n    }\n\n  return true;\n}",
    "comment": "Calculates a digest of the specified file or standard input, handling binary mode and error management for file operations.",
    "prorec_sum": "Opens the specified file or standard input, reports errors via `error()`, and returns status while optionally flagging a missing file condition.",
    "filter_prorec_sum": "Opens the specified file or stdin for reading, reports errors via `error()`, and sets a flag if the file is missing.",
    "prorec_aug_sum": "Opens the specified file or stdin, performs initialization and validation, and reports errors while setting a flag if the file is missing.",
    "filter_prorec_aug_sum": "Opens the specified file or standard input, initializes it for reading, and reports errors while flagging ENOENT conditions via an output byte.",
    "work_score": {
        "prorec": {
            "summary": "Opens the specified file or standard input, reports errors via `error()`, and returns status while optionally flagging a missing file condition.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function opens the specified file or standard input, uses the `error()` function to report errors, returns a status value, and can flag a missing file condition via the `missing` pointer. All these details are explicitly supported by the source code with direct evidence in the implementation. There are no unverified or hallucinated details in the summary.",
                "The summary accurately describes that the function opens either the specified file or standard input, reports errors using the error() function, returns a status, and can flag a missing file condition through the *missing parameter. These are all explicitly supported by the source code: the code checks for standard input, attempts to fopen for regular files, uses error() for failures, and sets *missing when ignore_missing and ENOENT occur. However, it omits significant details such as binary mode handling, use of fadvise, conditional DIGEST_STREAM invocation, and file closing logic, meaning it captures the main action but not the complete picture.",
                "The summary accurately reflects the core logic: the function opens a file or standard input, uses the error() function to report issues, returns a boolean status, and can set a flag when a file is missing, all of which are explicitly present in the source code. The details are specific to the function's parameters and behavior, but the description is somewhat generic and omits finer points like binary mode handling, fadvise calls, and conditional digest computation."
            ]
        },
        "filter_prorec": {
            "summary": "Opens the specified file or stdin for reading, reports errors via `error()`, and sets a flag if the file is missing.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary captures three main details: opening the specified file or stdin, reporting errors via `error()`, and setting a flag if the file is missing. All of these are explicitly supported in the source code: there is branching on `is_stdin` to handle stdin or opening via `fopen()`, calls to `error()` when file operations fail, and logic setting `*missing = true` when the file is not found and `ignore_missing` is true. No details are hallucinated, making all statements accurate.",
                "The summary correctly describes that the function opens either the specified file or stdin, uses the error() function to report errors, and sets a 'missing' flag when the file is absent under certain conditions. These details are explicitly present in the source code. However, it omits several critical aspects such as binary mode handling, advice for sequential file access, conditional digest logic depending on HASH_ALGO_BLAKE2, and proper closure of the file, meaning the accurate content covers only the main action without important logic details.",
                "The summary accurately notes that the function opens the specified file or stdin, reports errors via `error()`, and sets a flag when the file is missing. All these details are explicitly supported by the source code. However, the accurate details are generic and lack deeper coverage of domain-specific behaviors such as binary mode handling, sequential read advice, and conditional digest function calls. This limits the informational value of the summary."
            ]
        }
    }
}
{
    "source_code": "static noinline_for_stack\nvoid ext4_mb_simple_scan_group(struct ext4_allocation_context *ac,\n\t\t\t\t\tstruct ext4_buddy *e4b)\n{\n\tstruct super_block *sb = ac->ac_sb;\n\tstruct ext4_group_info *grp = e4b->bd_info;\n\tvoid *buddy;\n\tint i;\n\tint k;\n\tint max;\n\n\tBUG_ON(ac->ac_2order <= 0);\n\tfor (i = ac->ac_2order; i <= sb->s_blocksize_bits + 1; i++) {\n\t\tif (grp->bb_counters[i] == 0)\n\t\t\tcontinue;\n\n\t\tbuddy = mb_find_buddy(e4b, i, &max);\n\t\tBUG_ON(buddy == NULL);\n\n\t\tk = mb_find_next_zero_bit(buddy, max, 0);\n\t\tBUG_ON(k >= max);\n\n\t\tac->ac_found++;\n\n\t\tac->ac_b_ex.fe_len = 1 << i;\n\t\tac->ac_b_ex.fe_start = k << i;\n\t\tac->ac_b_ex.fe_group = e4b->bd_group;\n\n\t\text4_mb_use_best_found(ac, e4b);\n\n\t\tBUG_ON(ac->ac_b_ex.fe_len != ac->ac_g_ex.fe_len);\n\n\t\tif (EXT4_SB(sb)->s_mb_stats)\n\t\t\tatomic_inc(&EXT4_SB(sb)->s_bal_2orders);\n\n\t\tbreak;\n\t}\n}",
    "comment": "Scans the buddy system for free blocks, updates allocation context, and records statistics for memory management in an ext4 filesystem.",
    "prorec_sum": "Validates allocation metadata, retrieves and adjusts extent parameters, updates inode preallocation state, and records changes with consistency checks and error triggers.",
    "filter_prorec_sum": "Updates inode allocation state for a specific extent index, validating parameters, setting related fields, and incrementing usage counters with strict BUG-on failure checks.",
    "prorec_aug_sum": "Updates inode group allocation metadata, validates block parameters, and increments related counters during an ext4 filesystem block group handling operation.",
    "filter_prorec_aug_sum": "Updates inode group allocation metadata, validates block parameters, and triggers related consistency checks during an ext4 filesystem group addition or resize operation.",
    "work_score": {
        "prorec": {
            "summary": "Validates allocation metadata, retrieves and adjusts extent parameters, updates inode preallocation state, and records changes with consistency checks and error triggers.",
            "score": [
                0.4666666666666666,
                0.5,
                0.0
            ],
            "reason": [
                "The summary includes some accurate elements, such as performing consistency checks (via BUG_ON) and adjusting extent parameters (fe_len, fe_start, fe_group). However, it also contains inaccuracies: there is no explicit evidence of 'validates allocation metadata' beyond internal checks, no operations on 'inode preallocation state', and no explicit 'records changes' functionality. These unverified claims lower the accuracy ratio to below half.",
                "The summary contains several inaccuracies. While the source code does validate conditions with BUG_ON and adjusts extent parameters, there is no explicit evidence of 'retrieving allocation metadata' in a broad sense, 'updating inode preallocation state', or 'recording changes' beyond incrementing a statistic counter. References to inode preallocation are hallucinated, and the notion of recording changes is vague compared to the actual atomic_inc call. After filtering out these inaccuracies, only a small portion of the code's logic is captured, missing key steps like looping through orders, checking counters, finding buddies, and invoking ext4_mb_use_best_found.",
                "The summary claims inode preallocation state updates, which have no explicit evidence in the source code, making that detail inaccurate. The source does validate allocation metadata via BUG_ON checks, retrieves and adjusts extent parameters (fe_len, fe_start, fe_group), and performs consistency checks. However, the mention of recording changes and inode preallocation is unsupported. With more than half of the details being inaccurate, the kill switch applies and the summary is misleading."
            ]
        },
        "filter_prorec": {
            "summary": "Updates inode allocation state for a specific extent index, validating parameters, setting related fields, and incrementing usage counters with strict BUG-on failure checks.",
            "score": [
                0.3,
                0.5333333333333333,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies. The source code operates on an ext4 allocation context and buddy structures, not directly on inode allocation state, and it doesn't explicitly handle a specific extent index as claimed. While it does validate parameters using BUG_ON checks and sets fields in ac->ac_b_ex, the description of 'incrementing usage counters' is only partly accurate since it conditionally increments s_bal_2orders based on s_mb_stats. Most semantic details in the summary are either unsupported or misrepresented, leading to a low accuracy ratio.",
                "The summary incorrectly claims that the function updates inode allocation state, which is not supported by the source code. The accurate aspects are that it validates parameters using BUG_ON checks, sets fields in a structure related to block extents (fe_len, fe_start, fe_group), and increments usage counters if a condition is met. However, it omits critical details such as the loop structure, use of mb_find_buddy and mb_find_next_zero_bit, and the break condition, meaning the accurate content does not cover the full logic.",
                "The summary inaccurately describes inode allocation state updates and extent indexing, which are not evidenced in the source code. The function operates on an allocation context and group info, scanning for available blocks and setting block extent fields, not inode states. While it correctly mentions parameter validation and counter increments with BUG_ON checks, the majority of details (inode allocation, specific index focus) are unsupported, exceeding the 50% inaccuracy threshold."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_linalg_cholesky_scale_apply(gsl_matrix * A, const gsl_vector * S)\n{\n  const size_t M = A->size1;\n  const size_t N = A->size2;\n\n  if (M != N)\n    {\n      GSL_ERROR(\"A is not a square matrix\", GSL_ENOTSQR);\n    }\n  else if (N != S->size)\n    {\n      GSL_ERROR(\"S must have length N\", GSL_EBADLEN);\n    }\n  else\n    {\n      size_t i, j;\n\n      /* compute: A <- diag(S) A diag(S) using lower triangle */\n      for (j = 0; j < N; ++j)\n        {\n          double sj = gsl_vector_get(S, j);\n\n          for (i = j; i < N; ++i)\n            {\n              double si = gsl_vector_get(S, i);\n              double *Aij = gsl_matrix_ptr(A, i, j);\n              *Aij *= si * sj;\n            }\n        }\n\n      return GSL_SUCCESS;\n    }\n}",
    "comment": "Scales the elements of square matrix A by the elements of vector S using diagonal multiplication in a Cholesky decomposition context.",
    "prorec_sum": "Validates matrix and vector dimensions, then scales a Cholesky-decomposed matrix by the products of corresponding scale vector elements.",
    "filter_prorec_sum": "Validates matrix and scale vector dimensions, then applies element-wise scaling to a Cholesky-decomposed matrix using the provided scale factors.",
    "prorec_aug_sum": "Validates matrix and vector dimensions, then scales a Cholesky-decomposed matrix by the product of corresponding scaling vector and matrix elements.",
    "filter_prorec_aug_sum": "Validates matrix and scale vector sizes, then applies element-wise scaling to a Cholesky-decomposed matrix, returning error codes on dimension mismatches.",
    "work_score": {
        "prorec": {
            "summary": "Validates matrix and vector dimensions, then scales a Cholesky-decomposed matrix by the products of corresponding scale vector elements.",
            "score": [
                0.5666666666666668,
                0.5666666666666668,
                0.19999999999999998
            ],
            "reason": [
                "The summary correctly notes that the function validates matrix and vector dimensions, which is explicitly shown in the code. However, it inaccurately claims the matrix is Cholesky-decomposed; the source code operates on a generic matrix without evidence of prior Cholesky decomposition. The scaling step description is generally correct but the 'Cholesky-decomposed' detail is a hallucination, making the overall accuracy mixed.",
                "The summary accurately notes the validation of matrix and vector dimensions and the scaling using products of elements from the scale vector, which is evident from the dimension checks and multiplication logic in the source code. However, it inaccurately claims the matrix is Cholesky-decomposed, as there is no explicit Cholesky decomposition in the function; the code only applies scaling to the lower triangle of a matrix. This missing and incorrect detail reduces completeness, as the accurate part only covers main dimension validation and scaling.",
                "The summary correctly notes the validation of matrix and vector dimensions, which is explicitly present in the code through checks for a square matrix and matching vector length. However, it inaccurately claims the matrix is Cholesky-decomposed; the code simply scales the given matrix without verifying or performing a Cholesky decomposition. Since this is a significant inaccuracy and constitutes more than half of the details, the kill switch applies."
            ]
        },
        "filter_prorec": {
            "summary": "Validates matrix and scale vector dimensions, then applies element-wise scaling to a Cholesky-decomposed matrix using the provided scale factors.",
            "score": [
                0.6333333333333333,
                0.6,
                0.19999999999999998
            ],
            "reason": [
                "The summary correctly notes dimension validation and scaling based on provided scale factors, both of which are explicitly present in the code. However, it inaccurately claims the matrix is Cholesky-decomposed; there is no evidence in the source code of a prior Cholesky decomposition, only scaling of the lower triangle. This hallucination reduces the accuracy ratio to 2 accurate details out of 3 total.",
                "The summary correctly states that the function validates matrix and scale vector dimensions and applies element-wise scaling using provided scale factors. However, the claim about a 'Cholesky-decomposed matrix' is inaccurate, as the source code works on the given matrix directly and does not perform or assume a Cholesky decomposition. The remaining accurate details capture the main control flow and core logic but miss specifics such as using the lower triangle and detailed computation of scaling via si * sj.",
                "The summary correctly describes validation of matrix and vector dimensions and element-wise scaling using provided scale factors, which are evidenced by checks for square matrix, matching size, and nested loops applying si * sj scaling. However, it inaccurately claims the matrix is Cholesky-decomposed\u2014there is no explicit Cholesky decomposition in the code. With only one inaccurate detail out of three, the proportion of inaccurate details is below the threshold, but the accurate parts are moderately generic rather than domain-rich."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\nfb_mmap(struct file *file, struct vm_area_struct * vma)\n{\n\tstruct fb_info *info = file_fb_info(file);\n\tstruct fb_ops *fb;\n\tunsigned long mmio_pgoff;\n\tunsigned long start;\n\tu32 len;\n\n\tif (!info)\n\t\treturn -ENODEV;\n\tfb = info->fbops;\n\tif (!fb)\n\t\treturn -ENODEV;\n\tmutex_lock(&info->mm_lock);\n\tif (fb->fb_mmap) {\n\t\tint res;\n\t\tres = fb->fb_mmap(info, vma);\n\t\tmutex_unlock(&info->mm_lock);\n\t\treturn res;\n\t}\n\n\t/*\n\t * Ugh. This can be either the frame buffer mapping, or\n\t * if pgoff points past it, the mmio mapping.\n\t */\n\tstart = info->fix.smem_start;\n\tlen = info->fix.smem_len;\n\tmmio_pgoff = PAGE_ALIGN((start & ~PAGE_MASK) + len) >> PAGE_SHIFT;\n\tif (vma->vm_pgoff >= mmio_pgoff) {\n\t\tif (info->var.accel_flags) {\n\t\t\tmutex_unlock(&info->mm_lock);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tvma->vm_pgoff -= mmio_pgoff;\n\t\tstart = info->fix.mmio_start;\n\t\tlen = info->fix.mmio_len;\n\t}\n\tmutex_unlock(&info->mm_lock);\n\n\tvma->vm_page_prot = vm_get_page_prot(vma->vm_flags);\n\tfb_pgprotect(file, vma, start);\n\n\treturn vm_iomap_memory(vma, start, len);\n}",
    "comment": "Maps the framebuffer or MMIO memory region into the process's address space based on the provided virtual memory area structure.",
    "prorec_sum": "Validates a block device context, adjusts resource counters, and invokes device-specific or generic handlers to process the provided request parameters.",
    "filter_prorec_sum": "Validates device state, updates buffer metadata, and invokes a handler or fallback routine to process parameters and submit an I/O request.",
    "prorec_aug_sum": "Validates object state, adjusts memory counters, and either invokes a callback or performs a mapped memory operation with updated flags.",
    "filter_prorec_aug_sum": "Validates a hardware or memory region, updates allocation counters, and invokes a follow\u2011up routine to configure or map the specified resources.",
    "work_score": {
        "prorec": {
            "summary": "Validates a block device context, adjusts resource counters, and invokes device-specific or generic handlers to process the provided request parameters.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary mentions validating a block device context, adjusting resource counters, and invoking handlers for request parameters, none of which are explicitly evidenced in the source code. The source code handles a framebuffer mmap operation, checks for fb_info and fb_ops, uses mutexes, optionally calls fb->fb_mmap, calculates offsets, and maps memory via vm_iomap_memory. There is no indication of block device context or resource counter adjustments. All details in the summary are inaccurate, leading to a low accuracy ratio.",
                "The summary describes validation of a block device context, adjustment of resource counters, and invocation of handlers for request parameters, none of which are explicitly present in the source code. The code actually deals with framebuffer memory mapping, mutex locking, function pointer invocations for fb_mmap, and handling of memory offsets and protection. Since none of the described steps match the actual operations in the code, all details are inaccurate and the core logic is entirely missed.",
                "The summary claims that the code validates a block device context, adjusts resource counters, and processes request parameters via device-specific or generic handlers. The source code instead operates in a framebuffer context, handling memory mapping via fb_mmap, mutex locking, optional fb->fb_mmap calls, and mmio/frame buffer offsets. There is no evidence of block device logic, resource counters, or request parameter handling, making all details in the summary inaccurate. Since the proportion of inaccurate details exceeds half, the evaluation stops here."
            ]
        },
        "filter_prorec": {
            "summary": "Validates device state, updates buffer metadata, and invokes a handler or fallback routine to process parameters and submit an I/O request.",
            "score": [
                0.3666666666666667,
                0.16666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims validation of device state, buffer metadata updates, invocation of a handler or fallback routine, and submission of an I/O request. While the source code does validate the device state (`info` and `fb` checks) and conditionally invokes a handler (`fb->fb_mmap`), there is no explicit evidence of buffer metadata updates or an I/O request submission in the code. The remaining logic focuses on memory mapping operations, making several summary details inaccurate. Accurate details are outnumbered by unverified assumptions.",
                "The summary claims validation of device state, buffer metadata updates, handler invocation, and submission of an I/O request. In the source code, only the device state validation via null checks on `info` and `fb` is explicitly present. There is no explicit updating of buffer metadata, no generalized parameter processing, and no I/O request submission; instead, the code handles mmap operations, mmio mapping logic, and invokes driver-specific `fb_mmap` if available. Most of the summary details are hallucinated, leaving only partial alignment with the actual logic.",
                "The summary claims actions such as updating buffer metadata and submitting an I/O request, but the source code shows locking, conditional calls to fb->fb_mmap, address calculation for framebuffer or mmio mapping, and mapping memory via vm_iomap_memory. There is no explicit evidence of buffer metadata updates, parameter processing, or I/O request submission. All details are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "static void vt_disallocate_all(void)\n{\n\tstruct vc_data *vc[MAX_NR_CONSOLES];\n\tint i;\n\n\tconsole_lock();\n\tfor (i = 1; i < MAX_NR_CONSOLES; i++)\n\t\tif (!VT_BUSY(i))\n\t\t\tvc[i] = vc_deallocate(i);\n\t\telse\n\t\t\tvc[i] = NULL;\n\tconsole_unlock();\n\n\tfor (i = 1; i < MAX_NR_CONSOLES; i++) {\n\t\tif (vc[i] && i >= MIN_NR_CONSOLES) {\n\t\t\ttty_port_destroy(&vc[i]->port);\n\t\t\tkfree(vc[i]);\n\t\t}\n\t}\n}",
    "comment": "Deallocates all virtual consoles that are not busy, destroying associated tty ports and freeing memory for those consoles.",
    "prorec_sum": "Iterates over 62 indexed objects, conditionally processes them into a local array, then applies two computational routines to each non-null entry.",
    "filter_prorec_sum": "Iterates through up to 62 indexed entries, skips invalid ones, processes valid entries, and applies two sequential operations using provided parameters.",
    "prorec_aug_sum": "Iterates through 62 indexed entries, conditionally initializes them, then processes each valid entry with two computational routines using provided parameters.",
    "filter_prorec_aug_sum": "Iterates through 62 device entries, gathers active ones, and applies two processing routines with supplied parameters to each valid entry.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over 62 indexed objects, conditionally processes them into a local array, then applies two computational routines to each non-null entry.",
            "score": [
                0.3333333333333333,
                0.5,
                0.0
            ],
            "reason": [
                "The summary claims iteration over 62 indexed objects, but the source code iterates from index 1 to MAX_NR_CONSOLES, whose value is not explicitly defined in the code snippet. It also describes 'two computational routines' which does not accurately reflect the specific functions called (tty_port_destroy and kfree). The conditional population of a local array is partially accurate, but most numeric and procedural details are unverifiable or misstated based on the provided code.",
                "The summary states that the function iterates over 62 indexed objects and applies two computational routines to each non-null entry. The source code iterates from index 1 to MAX_NR_CONSOLES (not explicitly 62), checks VT_BUSY, stores results from vc_deallocate or NULL, and for certain indices calls tty_port_destroy and kfree. The specific claim of '62 indexed objects' is unsupported and thus inaccurate. While it correctly captures the iteration and conditional application of two routines to non-null elements, it omits details about locking, index ranges, and the condition i >= MIN_NR_CONSOLES, leaving the description incomplete.",
                "The summary states that the function iterates over 62 indexed objects and applies two computational routines to each non-null entry. The source code actually iterates from index 1 to MAX_NR_CONSOLES, which is not explicitly shown to be 62 in the code provided, making the exact '62' claim unsupported. It does conditionally store results in a local array and later applies two operations (`tty_port_destroy` and `kfree`) to non-null entries, which matches part of the summary. However, the incorrect fixed count claim means more than half of the details are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates through up to 62 indexed entries, skips invalid ones, processes valid entries, and applies two sequential operations using provided parameters.",
            "score": [
                0.3666666666666667,
                0.26666666666666666,
                0.0
            ],
            "reason": [
                "The summary claims iteration through up to 62 entries and skipping invalid ones, but there is no explicit mention in the source code of 62 as a limit or of 'invalid' entries; MAX_NR_CONSOLES and MIN_NR_CONSOLES are used instead, without a specific numeric value shown. The 'two sequential operations using provided parameters' also lacks direct evidence\u2014while the code does perform operations (tty_port_destroy and kfree), these are based on structure fields and constants, not explicitly 'provided parameters'. Only the notion of iterating and processing valid entries aligns generally, so most details are unverified assumptions.",
                "The summary contains unverifiable details such as the fixed count of 62 entries, skipping 'invalid ones', and processing entries with 'provided parameters', none of which are explicitly indicated in the source code. The code iterates from 1 to MAX_NR_CONSOLES, checks VT_BUSY to decide whether to deallocate or set NULL, then conditionally destroys the tty port and frees memory. The summary omits the use of console_lock/unlock and specific conditions like i >= MIN_NR_CONSOLES, resulting in inaccurate and incomplete coverage of the actual logic.",
                "The summary claims iteration through 62 indexed entries, skipping invalid ones, and applying two sequential operations using provided parameters. The source code iterates from 1 to MAX_NR_CONSOLES, but the constant's value is not given, so '62' is unsupported and inaccurate. 'Skips invalid ones' loosely matches the VT_BUSY check and NULL assignment. The 'two sequential operations using provided parameters' is misleading: the code uses fixed functions (tty_port_destroy, kfree) on vc entries, not arbitrary provided parameters. Most details (specific number, parameter use) are inaccurate, exceeding 50% and triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nvoid FAST_FUNC bb_herror_msg(const char *s, ...)\n{\n\tva_list p;\n\n\tva_start(p, s);\n\tbb_verror_msg(s, p, hstrerror(h_errno));\n\tva_end(p);\n}",
    "comment": "Formats and displays an error message using a variable argument list and the current error description from `hstrerror(h_errno)`.",
    "prorec_sum": "Prepares structured parameters and SIMD vector data, retrieves configuration, and delegates computation to sub_5176F5 for final processing.",
    "filter_prorec_sum": "Constructs a parameter block from scalar and vector inputs, retrieves auxiliary state, and invokes a processing routine with extracted double-precision values.",
    "prorec_aug_sum": "Constructs parameter structures from provided arguments and invokes sub_5176F5 to process vector and scalar data using configuration obtained from helper functions.",
    "filter_prorec_aug_sum": "Prepares structured parameters and vector data, retrieves auxiliary configuration, and invokes a processing routine for formatted floating-point and byte array output.",
    "work_score": {
        "prorec": {
            "summary": "Prepares structured parameters and SIMD vector data, retrieves configuration, and delegates computation to sub_5176F5 for final processing.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes preparing structured parameters, SIMD vector data, retrieving configuration, and delegating computation to a function named sub_5176F5, but none of these elements are present in the source code. The actual code only initializes a va_list, starts it with va_start, calls bb_verror_msg with hstrerror(h_errno), and ends the list with va_end. There is no evidence of SIMD processing, configuration retrieval, or a sub_5176F5 function, making all reported details inaccurate.",
                "The summary's claims about preparing structured parameters, SIMD vector data, retrieving configuration, and delegating to sub_5176F5 are unsupported by the source code. The code only initializes a va_list, calls bb_verror_msg with hstrerror(h_errno), and finalizes the va_list. No configuration retrieval, SIMD processing, or delegation to sub_5176F5 is present, leaving no accurate details from the summary.",
                "The summary's claims about preparing structured parameters, SIMD vector data, retrieving configuration, and delegating to sub_5176F5 have no explicit support in the source code. The source code only shows a function bb_herror_msg setting up a va_list, calling bb_verror_msg with hstrerror(h_errno), and contains no SIMD operations, configuration retrieval, or a call to sub_5176F5. All details are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Constructs a parameter block from scalar and vector inputs, retrieves auxiliary state, and invokes a processing routine with extracted double-precision values.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes constructing parameter blocks from scalar/vector inputs, retrieving auxiliary state, and processing double-precision values, none of which are present in the source code. The code simply defines a function that starts a variable argument list, calls another function with an error message, and ends the argument list. All details in the summary are hallucinations, resulting in no accurate matches to the source.",
                "The summary's details about constructing parameter blocks, handling scalar/vector inputs, retrieving auxiliary state, and invoking routines with double-precision values have no explicit evidence in the source code. The code only defines a function wrapping bb_verror_msg with a variable argument list and hstrerror, and none of the described operations occur. All summary details are inaccurate, leaving no valid content to represent the code's actual logic.",
                "The summary claims construction of a parameter block from scalar and vector inputs, retrieval of auxiliary state, and invocation of a processing routine with double-precision values. None of these elements\u2014scalar/vector inputs, parameter block, auxiliary state, or double-precision handling\u2014are present in the source code, which simply formats and outputs an error message using variadic arguments and hstrerror. All details are inaccurate, exceeding the 50% threshold and triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "int sysfs_merge_group(struct kobject *kobj,\n\t\t       const struct attribute_group *grp)\n{\n\tstruct sysfs_dirent *dir_sd;\n\tint error = 0;\n\tstruct attribute *const *attr;\n\tint i;\n\n\tdir_sd = sysfs_get_dirent(kobj->sd, NULL, grp->name);\n\tif (!dir_sd)\n\t\treturn -ENOENT;\n\n\tfor ((i = 0, attr = grp->attrs); *attr && !error; (++i, ++attr))\n\t\terror = sysfs_add_file(dir_sd, *attr, SYSFS_KOBJ_ATTR);\n\tif (error) {\n\t\twhile (--i >= 0)\n\t\t\tsysfs_hash_and_remove(dir_sd, NULL, (*--attr)->name);\n\t}\n\tsysfs_put(dir_sd);\n\n\treturn error;\n}",
    "comment": "Merges a specified attribute group into a kobject's sysfs directory, adding attributes and handling errors by removing any added attributes on failure.",
    "prorec_sum": "Processes a sequence of linked entries with a reference-counted object, performing conditional operations and cleanup, and returns a status code.",
    "filter_prorec_sum": "Processes a list of xattr entries, invoking comparison and removal routines, and releases resources before returning a status code.",
    "prorec_aug_sum": "Processes a list of linked objects with validation and cleanup, returning the status code from the first successful operation or zero if none succeed.",
    "filter_prorec_aug_sum": "Initializes and processes a list of items with repeated sub-operations, cleans up on failure, and returns a status code from the last processed item.",
    "work_score": {
        "prorec": {
            "summary": "Processes a sequence of linked entries with a reference-counted object, performing conditional operations and cleanup, and returns a status code.",
            "score": [
                0.3,
                0.3333333333333333,
                0.0
            ],
            "reason": [
                "The summary describes linked entries and a reference-counted object, which are not explicitly evidenced in the source code. The code handles a sysfs_dirent object obtained via sysfs_get_dirent, iterates through an attribute array, conditionally calls sysfs_add_file, performs cleanup using sysfs_hash_and_remove on error, and releases the object with sysfs_put. While returning a status code is accurate, the mention of linked entries and reference counting is unsupported, resulting in mostly hallucinated details.",
                "The summary's claims about 'linked entries' and 'reference-counted object' are not explicitly supported in the source code, making them inaccurate. The source code shows iteration over a group's attributes, adding them to a sysfs directory entry, and removing them on error before releasing the directory entry, but the summary fails to mention attributes, sysfs functions, or the specific error handling loop. After removing hallucinated elements, only a vague notion of performing conditional operations and returning a status code remains, which omits critical control flow and data manipulation details.",
                "The summary describes processing linked entries with a reference-counted object, but the source code explicitly operates on sysfs_dirent structures retrieved via sysfs_get_dirent, iterates over attribute arrays, adds files, and removes them on error. There is no explicit evidence of linked list handling or reference-counted object semantics in the provided code. Thus, most details are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Processes a list of xattr entries, invoking comparison and removal routines, and releases resources before returning a status code.",
            "score": [
                0.10000000000000002,
                0.03333333333333333,
                0.0
            ],
            "reason": [
                "The summary incorrectly describes processing a list of xattr entries and invoking comparison routines, but the source code works with sysfs attribute groups, adding files through sysfs_add_file and removing them with sysfs_hash_and_remove. There is no evidence of xattr handling or comparison logic in the code, making the key details inaccurate. Only the mention of releasing resources and returning a status code is supported by the sysfs_put call and final return. The majority of semantic details are hallucinated.",
                "The summary incorrectly describes processing of 'xattr entries' and invoking 'comparison routines', which are not present in the source code. The code actually iterates over a list of attributes from an attribute group, adds them via sysfs_add_file, and removes them if an error occurs. After discarding the inaccurate xattr and comparison details, no accurate semantic content remains from the summary.",
                "The summary claims processing of xattr entries with comparison and removal routines, but the source code deals with sysfs attribute groups, iterating over 'grp->attrs' and adding files with sysfs_add_file. There is no evidence of xattr handling or comparison operations, making most details inaccurate. The inaccuracies exceed half of the claims, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "static int __kprobes write_mem(unsigned long val, unsigned long ea, int nb,\n\t\t\t       struct pt_regs *regs)\n{\n\tif (!address_ok(regs, ea, nb))\n\t\treturn -EFAULT;\n\tif ((ea & (nb - 1)) == 0)\n\t\treturn write_mem_aligned(val, ea, nb);\n\treturn write_mem_unaligned(val, ea, nb, regs);\n}",
    "comment": "Writes specified bytes from a buffer to a target object's memory section, logging the operation if enabled.",
    "prorec_sum": "Copies data in page-aligned chunks from a source buffer into memory starting at *a4, enforcing address limits and returning the bytes successfully written.",
    "filter_prorec_sum": "Reads data in page-aligned chunks from a mapped address into a buffer, enforcing address limits and updating the consumed offset counter.",
    "prorec_aug_sum": "Writes data from a buffer to memory in page-aligned chunks, updating the offset and enforcing address range limits.",
    "filter_prorec_aug_sum": "Copies the specified byte range into memory pages at the destination address, enforcing size limits and updating the transferred byte count.",
    "work_score": {
        "prorec": {
            "summary": "Copies data in page-aligned chunks from a source buffer into memory starting at *a4, enforcing address limits and returning the bytes successfully written.",
            "score": [
                0.20000000000000004,
                0.0,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies: it describes copying data in page-aligned chunks from a source buffer using pointer *a4, enforcing address limits, and returning bytes written. The source code shows a function that writes a value to a specified address if it passes an address check, chooses aligned or unaligned write paths based on address alignment, and returns error codes from these helpers. There is no evidence of a source buffer, page alignment, pointer *a4, or returning the number of bytes written. Only the address checking detail roughly aligns with 'enforcing address limits'. The ratio of accurate details is very low, well below half.",
                "The summary's claims about copying data from a source buffer, using page-aligned chunks, starting at *a4, and returning bytes successfully written are not present in the source code. The actual code checks address validity, alignment for the given size, and then routes to either aligned or unaligned write functions with no mention of a source buffer, page alignment, or byte count returns. All details in the summary are inaccurate, leaving no valid content to map to the code's logic.",
                "The summary claims that the function copies data in page-aligned chunks from a source buffer into memory at *a4, enforces address limits, and returns bytes written. In the source, there is no evidence of page-aligned chunk copying, source buffer usage, or returning byte counts; instead, the code checks address validity, alignment, and calls appropriate write functions. These discrepancies make the majority of details inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Reads data in page-aligned chunks from a mapped address into a buffer, enforcing address limits and updating the consumed offset counter.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims reading data in page-aligned chunks from a mapped address into a buffer, enforcing address limits, and updating an offset counter. The source code, however, shows a function 'write_mem' performing write operations with alignment checks via 'write_mem_aligned' or 'write_mem_unaligned', and checking address validity with 'address_ok'. There is no evidence of reading operations, page-aligned chunk handling, mapping to a buffer, or offset counter updates. All details in the summary are inaccurate relative to the source code.",
                "The summary claims the function reads data in page-aligned chunks into a buffer, enforces address limits, and updates a consumed offset counter. The source code, however, shows a function that writes memory, checks address validity with `address_ok`, and calls either `write_mem_aligned` or `write_mem_unaligned` based on alignment, with no evidence of reading, buffers, page alignment handling, or offset counters. All details in the summary are unsupported and therefore inaccurate, leaving no valid content to map to the actual logic.",
                "The summary claims the function reads data in page-aligned chunks into a buffer, enforces address limits, and updates a consumed offset counter. The source code actually writes memory using aligned or unaligned methods depending on address alignment, checks address validity, and makes no mention of reading, buffers, page alignment, or offset counters. All key details in the summary are inaccurate, exceeding the kill switch threshold."
            ]
        }
    }
}
{
    "source_code": "\nstatic int __init i8042_create_aux_port(int idx)\n{\n\tstruct serio *serio;\n\tint port_no = idx < 0 ? I8042_AUX_PORT_NO : I8042_MUX_PORT_NO + idx;\n\tstruct i8042_port *port = &i8042_ports[port_no];\n\n\tserio = kzalloc(sizeof(struct serio), GFP_KERNEL);\n\tif (!serio)\n\t\treturn -ENOMEM;\n\n\tserio->id.type\t\t= SERIO_8042;\n\tserio->write\t\t= i8042_aux_write;\n\tserio->start\t\t= i8042_start;\n\tserio->stop\t\t= i8042_stop;\n\tserio->port_data\t= port;\n\tserio->dev.parent\t= &i8042_platform_device->dev;\n\tif (idx < 0) {\n\t\tstrlcpy(serio->name, \"i8042 AUX port\", sizeof(serio->name));\n\t\tstrlcpy(serio->phys, I8042_AUX_PHYS_DESC, sizeof(serio->phys));\n\t\tserio->close = i8042_port_close;\n\t} else {\n\t\tsnprintf(serio->name, sizeof(serio->name), \"i8042 AUX%d port\", idx);\n\t\tsnprintf(serio->phys, sizeof(serio->phys), I8042_MUX_PHYS_DESC, idx + 1);\n\t}\n\n\tport->serio = serio;\n\tport->mux = idx;\n\tport->irq = I8042_AUX_IRQ;\n\n\treturn 0;\n}",
    "comment": "Initializes an i8042 auxiliary port, allocating a serio structure and configuring it for communication with the specified input device.",
    "prorec_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) serio port structure, setting handlers, naming, and storing it in global device tables.",
    "filter_prorec_sum": "Initializes and registers an i8042 AUX PS/2 port device structure with handlers, naming, and global tracking based on the provided port index.",
    "prorec_aug_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) port device structure with associated handlers, naming, and global table entries based on the given index.",
    "filter_prorec_aug_sum": "Initializes and registers an i8042 AUX port device structure with appropriate names, handlers, and global tables based on the provided port index.",
    "work_score": {
        "prorec": {
            "summary": "Initializes and registers an i8042 AUX (PS/2 mouse) serio port structure, setting handlers, naming, and storing it in global device tables.",
            "score": [
                0.8000000000000002,
                0.6,
                0.5333333333333333
            ],
            "reason": [
                "The summary correctly notes initialization of an i8042 AUX serio port structure and setting handlers and naming, which are explicitly shown in the code through assignments to serio fields like write, start, stop, and name/phys. However, the claim about 'registers' and 'storing it in global device tables' is partially inaccurate\u2014there is no registration function call, and while the port is assigned to a global array element (i8042_ports), the summary's wording overstates this aspect. This results in mostly accurate details with minor overreach.",
                "The summary accurately notes initialization of an i8042 AUX serio port, setting handlers (write, start, stop, close), and naming. However, it incorrectly claims registration and storage in global device tables, which is not evidenced in the source code; the code only stores the port in a local array and sets fields, with no registration logic. While the accurate parts capture the main creation and setup process, the omission of specifics about conditional naming and absence of registration details means the picture is incomplete.",
                "The summary correctly notes initialization of an i8042 AUX serio port structure and its handler assignments, but incorrectly claims registration and storage in global device tables, which is not explicitly shown in the source code. This claim about registration and global device tables is unsupported, making it inaccurate. Since there is more than 50% inaccuracy by proportion (half of the claims are unsupported), the evaluation halts at the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes and registers an i8042 AUX PS/2 port device structure with handlers, naming, and global tracking based on the provided port index.",
            "score": [
                1.0,
                0.6666666666666666,
                0.7333333333333334
            ],
            "reason": [
                "The summary correctly states that the function initializes an i8042 AUX PS/2 port device structure and sets handlers, names, and tracking based on the port index, all of which are explicitly evident in the code through assignments to the serio structure and conditional naming logic. No additional unverified or hallucinated details are present.",
                "The summary correctly captures that the function initializes an i8042 AUX port device structure with appropriate handlers, name assignments, and uses the provided index to determine configuration. These details are directly supported by the source code, which allocates a serio struct, sets function pointers, assigns names/phys strings depending on index, and stores the serio in global tracking structures. However, the summary inaccurately states that the port is 'registered' \u2014 the code only initializes and assigns it, without calling any registration function. This omission reduces completeness slightly.",
                "The summary correctly notes initialization of an i8042 AUX port structure and inclusion of handlers, naming, and index-based logic, which are explicitly present in the source via assignments to serio fields, conditional naming based on idx, and tracking via the port structure. No unsupported claims or hallucinations are present, making all details accurate. However, the description is somewhat generic and does not highlight specific function names, constants, or deeper domain details from the code, limiting its value."
            ]
        }
    }
}
{
    "source_code": "long keyctl_keyring_unlink(key_serial_t id, key_serial_t ringid)\n{\n\tkey_ref_t keyring_ref, key_ref;\n\tlong ret;\n\n\tkeyring_ref = lookup_user_key(ringid, 0, KEY_WRITE);\n\tif (IS_ERR(keyring_ref)) {\n\t\tret = PTR_ERR(keyring_ref);\n\t\tgoto error;\n\t}\n\n\tkey_ref = lookup_user_key(id, KEY_LOOKUP_FOR_UNLINK, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = PTR_ERR(key_ref);\n\t\tgoto error2;\n\t}\n\n\tret = key_unlink(key_ref_to_ptr(keyring_ref), key_ref_to_ptr(key_ref));\n\n\tkey_ref_put(key_ref);\nerror2:\n\tkey_ref_put(keyring_ref);\nerror:\n\treturn ret;\n}",
    "comment": "Unlinks a key from a specified keyring after verifying the existence of both the key and the keyring.",
    "prorec_sum": "Allocates two memory/page buffers, processes them with provided double parameters, and performs additional operations before returning the final allocation or result value.",
    "filter_prorec_sum": "Allocates two memory/pages for given IDs, processes them with provided double parameters, and returns the final processed or allocated pointer value.",
    "prorec_aug_sum": "Fetches two kernel objects by IDs, processes them with numerical parameters, updates their state, and returns a computed or fetched result pointer.",
    "filter_prorec_aug_sum": "Processes two unsigned integer handles through allocation and comparison, invoking related operations with multiple double parameters, and returns a resulting handle or status value.",
    "work_score": {
        "prorec": {
            "summary": "Allocates two memory/page buffers, processes them with provided double parameters, and performs additional operations before returning the final allocation or result value.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary mentions allocation of memory/page buffers, processing with double parameters, and returning a final allocation result, none of which are present in the source code. The code is concerned with looking up key references, handling errors, unlinking a key from a keyring, and releasing references. There is no evidence of memory buffer allocation or use of double parameters, meaning all details in the summary are hallucinated.",
                "The summary's claims about allocating memory/page buffers, processing them with double parameters, and performing additional operations are unsupported by the source code. The source code focuses on looking up keys in a keyring, handling errors, unlinking keys, and cleaning up references. No memory allocation functions, page buffer handling, or double parameter processing are present, leaving no accurate details after filtering.",
                "The summary claims memory/page buffer allocation and processing with double parameters, none of which are present in the source code. The code only looks up keys, unlinks them, and manages references, with no allocation logic or double data types. All semantic details in the summary are inaccurate, exceeding the 50% inaccuracy threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates two memory/pages for given IDs, processes them with provided double parameters, and returns the final processed or allocated pointer value.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims allocation of memory/pages, use of double parameters, and returning a processed or allocated pointer value. The source code shows no memory/page allocation, no double parameters, and returns a long integer, not a pointer. All mentioned details are unsupported, making the summary entirely inaccurate.",
                "The summary's claims about allocating memory/pages, processing with double parameters, and returning a pointer value are all inaccurate, as the source code performs key lookups, unlink operations, and reference handling without any memory allocation or double parameters. No accurate details remain after filtering, leaving the core logic entirely unrepresented.",
                "The summary claims memory/page allocation, usage of double parameters, and returning a processed or allocated pointer value. None of these details are supported by the source code, which actually performs key lookups, unlinking, and reference release in a keyring system with functions like lookup_user_key and key_unlink. All semantic details are inaccurate, exceeding the 50% threshold, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nbool ssh2_common_filter_queue(PacketProtocolLayer *ppl)\n{\n    static const char *const ssh2_disconnect_reasons[] = {\n        NULL,\n        \"host not allowed to connect\",\n        \"protocol error\",\n        \"key exchange failed\",\n        \"host authentication failed\",\n        \"MAC error\",\n        \"compression error\",\n        \"service not available\",\n        \"protocol version not supported\",\n        \"host key not verifiable\",\n        \"connection lost\",\n        \"by application\",\n        \"too many connections\",\n        \"auth cancelled by user\",\n        \"no more auth methods available\",\n        \"illegal user name\",\n    };\n\n    PktIn *pktin;\n    ptrlen msg;\n    int reason;\n\n    while ((pktin = pq_peek(ppl->in_pq)) != NULL) {\n        switch (pktin->type) {\n          case SSH2_MSG_DISCONNECT:\n            reason = get_uint32(pktin);\n            msg = get_string(pktin);\n\n            ssh_remote_error(\n                ppl->ssh, \"Remote side sent disconnect message\\n\"\n                \"type %d (%s):\\n\\\"%.*s\\\"\", reason,\n                ((reason > 0 && reason < lenof(ssh2_disconnect_reasons)) ?\n                 ssh2_disconnect_reasons[reason] : \"unknown\"),\n                PTRLEN_PRINTF(msg));\n            /* don't try to pop the queue, because we've been freed! */\n            return true;               /* indicate that we've been freed */\n\n          case SSH2_MSG_DEBUG:\n            /* XXX maybe we should actually take notice of the return value */\n            get_bool(pktin);\n            msg = get_string(pktin);\n            ppl_logevent(\"Remote debug message: %.*s\", PTRLEN_PRINTF(msg));\n            pq_pop(ppl->in_pq);\n            break;\n\n          case SSH2_MSG_IGNORE:\n            /* Do nothing, because we're ignoring it! Duhh. */\n            pq_pop(ppl->in_pq);\n            break;\n\n          default:\n            return false;\n        }\n    }\n\n    return false;\n}",
    "comment": "Processes incoming SSH2 packets, handling disconnect messages, debug messages, and ignores messages, while managing packet queue operations.",
    "prorec_sum": "Processes events from an object at a1+16, handling specific type codes with callbacks and parameters, and terminates when no more events are available.",
    "filter_prorec_sum": "Processes items from a queued source, handling specific type codes with predefined arguments, and invokes a callback for type\u202f1 entries.",
    "prorec_aug_sum": "Processes events from the object at `a1+16`, handling specific type codes with corresponding data and invoking a secondary callback until no events remain.",
    "filter_prorec_aug_sum": "Processes commands from an object at offset 16, handling specific type codes and invoking sub_11CF or issuing secondary calls with preset parameters.",
    "work_score": {
        "prorec": {
            "summary": "Processes events from an object at a1+16, handling specific type codes with callbacks and parameters, and terminates when no more events are available.",
            "score": [
                0.2333333333333333,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims processing events from an object at a1+16, handling type codes with callbacks and parameters, and terminating when no more events are available. The source code shows handling of queued packets via pq_peek on ppl->in_pq, switching on pktin->type, and using specific functions such as ssh_remote_error and ppl_logevent\u2014not callbacks on a1+16. The 'a1+16' reference and callbacks detail are hallucinations. Only the general notion of processing events and terminating when none remain is accurate, so most details are unverified or inaccurate.",
                "The summary describes processing events from an object at a memory offset (a1+16) with callbacks and termination logic, but none of these details are explicitly present in the source code. The source code handles queued packets based on SSH2 message types, processes disconnect, debug, and ignore messages, and returns status flags, without any mention of a1+16 or generic callbacks. After discarding these inaccurate details, no accurate content remains, meaning the summary misses the core logic.",
                "The summary claims interaction with an object at a1+16, use of type codes with callbacks and parameters, and termination on event exhaustion. None of these specific details are explicitly supported by the source code: there is no reference to a1+16, callbacks, or parameter handling in the described form. The source handles queued packet types via switch cases but these accurate elements are not in the summary. More than half of the summary's statements are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Processes items from a queued source, handling specific type codes with predefined arguments, and invokes a callback for type\u202f1 entries.",
            "score": [
                0.26666666666666666,
                0.10000000000000002,
                0.0
            ],
            "reason": [
                "The summary claims a callback is invoked for type 1 entries, but the source code contains no reference to type 1 or such a callback; it handles SSH2_MSG_DISCONNECT, SSH2_MSG_DEBUG, and SSH2_MSG_IGNORE codes. While it correctly notes processing items from a queue and handling specific type codes, the predefined arguments mentioned are vague and not clearly supported by explicit evidence. Most of the summary's details are unsupported or inaccurate.",
                "The summary is inaccurate because it claims handling of type\u202f1 entries with a callback, which is not supported by the source code. The code processes specific SSH2 message types such as DISCONNECT, DEBUG, and IGNORE with distinct logic paths, and no evidence exists of a generic 'type 1' or predefined arguments as described. After discarding hallucinations, no accurate details remain to represent the actual logic.",
                "The summary claims that type\u202f1 entries invoke a callback and uses generic phrasing about predefined arguments, but the source code shows handling of specific SSH2 message types (DISCONNECT, DEBUG, IGNORE) with distinct logic, none of which are identified as 'type 1'. This means the key detail about type\u202f1 and callbacks is inaccurate, and most other content is overly generic without reflecting the explicit message handling or data extraction in the code. Over 50% of the details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nint __net_init fib4_rules_init(struct net *net)\n{\n\tint err;\n\tstruct fib_rules_ops *ops;\n\n\tops = fib_rules_register(&fib4_rules_ops_template, net);\n\tif (IS_ERR(ops))\n\t\treturn PTR_ERR(ops);\n\n\terr = fib_default_rules_init(ops);\n\tif (err < 0)\n\t\tgoto fail;\n\tnet->ipv4.rules_ops = ops;\n\tnet->ipv4.fib_has_custom_rules = false;\n\treturn 0;\n\nfail:\n\t/* also cleans all rules already added */\n\tfib_rules_unregister(ops);\n\treturn err;\n}",
    "comment": "Initializes IPv4 fib rules for a specified network, registering operations and setting default rules, or cleaning up on failure.",
    "prorec_sum": "Initializes a socket-related object with specific parameters, performs three configuration steps, and stores it in the parent structure or cleans up on failure.",
    "filter_prorec_sum": "Initializes a data structure via multiple configuration calls, handles errors by cleanup, and stores the resulting pointer into the caller\u2019s context.",
    "prorec_aug_sum": "Allocates and initializes a structure with multiple configuration steps, cleans up on failure, and stores it in the specified context structure.",
    "filter_prorec_aug_sum": "Initializes a data structure with multiple configuration steps, aborting and freeing resources on any failure, then storing it into the provided context object.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a socket-related object with specific parameters, performs three configuration steps, and stores it in the parent structure or cleans up on failure.",
            "score": [
                0.26666666666666666,
                0.13333333333333333,
                0.0
            ],
            "reason": [
                "The summary incorrectly describes initialization of a socket-related object, which is not evident in the source code. The source function initializes IPv4 FIB rules using fib_rules_register, fib_default_rules_init, and assigns the operations to net->ipv4.rules_ops. While it mentions configuration and cleanup on failure (which matches the goto fail block and fib_rules_unregister), the claimed object type and context are inaccurate. Only the general notion of multi-step configuration and cleanup is supported, resulting in less than half of the details being accurate.",
                "The summary claims initialization of a socket-related object and mentions three configuration steps, which are not supported by the source code. The code initializes IPv4 FIB rules via fib_rules_register, sets default rules, stores the ops in net->ipv4.rules_ops, and unregisters on failure. No socket-related object or three explicit configuration steps are present, so all mentioned details are inaccurate, leaving no valid content after filtering.",
                "The summary claims a socket-related object is initialized with specific parameters, which is inaccurate, as the source code initializes IPv4 routing rules via fib_rules_register and not a socket. It also states there are three configuration steps, but the code shows registering rules, possibly initializing default rules, and updating fields, so step count is unclear. Most details, including 'socket-related' and 'specific parameters', are hallucinated, exceeding 50% inaccurate details."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a data structure via multiple configuration calls, handles errors by cleanup, and stores the resulting pointer into the caller\u2019s context.",
            "score": [
                1.0,
                0.8000000000000002,
                0.7000000000000001
            ],
            "reason": [
                "The summary accurately describes initializing a data structure through multiple calls, error handling with cleanup, and storing a pointer into the caller\u2019s context. All these elements are explicitly present in the source code: initialization via fib_rules_register and fib_default_rules_init, cleanup through fib_rules_unregister on error, and storing ops in net->ipv4.rules_ops. No details are hallucinated, yielding full accuracy.",
                "The summary correctly states that the function initializes a structure through multiple calls, handles errors via cleanup, and stores a pointer into a context. These details are explicitly supported in the source: initialization via fib_rules_register and fib_default_rules_init, error handling with fib_rules_unregister on failure, and assigning ops to net->ipv4.rules_ops. However, the summary is high-level and omits specifics such as the flag assignment (fib_has_custom_rules = false) and the exact control flow, so while the core logic is captured, some important details are missing.",
                "The summary\u2019s claims about initialization, error handling through cleanup, and storing a pointer in context are supported by explicit code evidence: the function registers ops, checks for errors, cleans up with fib_rules_unregister on failure, and assigns ops to net->ipv4.rules_ops. These details are accurate but expressed generically without domain-specific references such as function names or specific structure fields beyond 'pointer'. While truthful, the summary lacks deeper, domain-rich insight into the network subsystem or the precise role of fib4_rules_ops_template."
            ]
        }
    }
}
{
    "source_code": "static int whereLoopCheaperProperSubset(\n  const WhereLoop *pX,       /* First WhereLoop to compare */\n  const WhereLoop *pY        /* Compare against this WhereLoop */\n){\n  int i, j;\n  if( pX->nLTerm-pX->nSkip >= pY->nLTerm-pY->nSkip ){\n    return 0; /* X is not a subset of Y */\n  }\n  if( pY->nSkip > pX->nSkip ) return 0;\n  if( pX->rRun >= pY->rRun ){\n    if( pX->rRun > pY->rRun ) return 0;    /* X costs more than Y */\n    if( pX->nOut > pY->nOut ) return 0;    /* X costs more than Y */\n  }\n  for(i=pX->nLTerm-1; i>=0; i--){\n    if( pX->aLTerm[i]==0 ) continue;\n    for(j=pY->nLTerm-1; j>=0; j--){\n      if( pY->aLTerm[j]==pX->aLTerm[i] ) break;\n    }\n    if( j<0 ) return 0;  /* X not a subset of Y since term X[i] not used by Y */\n  }\n  return 1;  /* All conditions meet */\n}",
    "comment": "Determines if WhereLoop `pX` is a proper subset of WhereLoop `pY` based on terms, costs, and skip values.",
    "prorec_sum": "Checks positional bounds and iterates two indexed 64\u2011bit arrays to verify matching entries, returning success if all relevant elements correspond.",
    "filter_prorec_sum": "Checks bounds and iterates two indexed arrays to confirm matching elements exist in corresponding positions before returning success.",
    "prorec_aug_sum": "Checks coordinate and index ranges, then verifies corresponding 64\u2011bit entries in two tables match for all relevant positions.",
    "filter_prorec_aug_sum": "Checks positional and index bounds, then verifies matching 64\u2011bit entries between two tables before confirming a valid sequential relationship.",
    "work_score": {
        "prorec": {
            "summary": "Checks positional bounds and iterates two indexed 64\u2011bit arrays to verify matching entries, returning success if all relevant elements correspond.",
            "score": [
                0.39999999999999997,
                0.3,
                0.0
            ],
            "reason": [
                "The summary claims the function checks positional bounds on two indexed 64\u2011bit arrays, but the source code shows it operates on struct fields like nLTerm, nSkip, rRun, nOut, and arrays aLTerm without any indication they are 64\u2011bit. Iteration and matching logic is present, but the data type detail is unsupported. The bounds checking is partly accurate in comparing element counts and costs, yet the inclusion of '64\u2011bit' is a hallucination. Overall, only some aspects of the logic are correctly described, leading to mixed accuracy.",
                "The summary incorrectly describes iteration over two indexed 64\u2011bit arrays, which is not evidenced in the source code. The code operates on WhereLoop structures with nLTerm, nSkip, rRun, nOut, and aLTerm pointers, and the data type size (64\u2011bit) is not specified. While the summary vaguely matches the concept of iterating and checking corresponding elements, key details about data types and positional bounds are inaccurate. Discarding those leaves only a partial description of verifying matching entries, missing important logic such as cost comparisons and subset conditions.",
                "The summary claims that the code checks positional bounds and iterates two indexed 64\u2011bit arrays, but the source code does not specify 64\u2011bit arrays; it handles arrays of pointers (`aLTerm`) and integer counts (`nLTerm`, `nSkip`). The description of 'positional bounds' is vague compared to the explicit subset, skip, and cost checks in the code. Matching array entries is mentioned, which partially aligns with the nested loops comparing `aLTerm` values. However, most semantic details such as '64\u2011bit arrays' and 'positional bounds' are inaccurate, exceeding 50% inaccuracies, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Checks bounds and iterates two indexed arrays to confirm matching elements exist in corresponding positions before returning success.",
            "score": [
                0.26666666666666666,
                0.20000000000000004,
                0.0
            ],
            "reason": [
                "The summary claims the function checks bounds and confirms matching elements in corresponding positions, but the source code does not check array bounds explicitly beyond loop control, nor does it enforce matching elements in the same positions\u2014it searches for matches in any position of the second array. The only partially accurate element is the iteration over arrays to find matches. Most details are inaccurate or unverified, resulting in a low accuracy ratio.",
                "The summary incorrectly claims the code checks corresponding positions for matching elements, but the source instead confirms all elements in pX->aLTerm exist somewhere in pY->aLTerm, regardless of position. It omits key logic such as subset size checks, skip value comparison, and run/output cost comparisons. After discarding the inaccurate positional detail, the remaining content fails to capture the main control flow.",
                "The summary claims that the function checks bounds and compares matching elements in corresponding positions, but the code does not explicitly perform bounds checking beyond normal loop limits, nor does it require corresponding positions \u2014 it searches for each element of pX in any position of pY. This makes the position-based claim inaccurate. The accurate aspect is that the function iterates two arrays to find matches, but most semantic details in the summary misrepresent the code's actual logic, crossing the 50% inaccuracy threshold."
            ]
        }
    }
}
{
    "source_code": "\nacpi_status acpi_ut_mutex_initialize(void)\n{\n\tu32 i;\n\tacpi_status status;\n\n\tACPI_FUNCTION_TRACE(ut_mutex_initialize);\n\n\t/* Create each of the predefined mutex objects */\n\n\tfor (i = 0; i < ACPI_NUM_MUTEX; i++) {\n\t\tstatus = acpi_ut_create_mutex(i);\n\t\tif (ACPI_FAILURE(status)) {\n\t\t\treturn_ACPI_STATUS(status);\n\t\t}\n\t}\n\n\t/* Create the spinlocks for use at interrupt level or for speed */\n\n\tstatus = acpi_os_create_lock (&acpi_gbl_gpe_lock);\n\tif (ACPI_FAILURE (status)) {\n\t\treturn_ACPI_STATUS (status);\n\t}\n\n\tstatus = acpi_os_create_lock (&acpi_gbl_hardware_lock);\n\tif (ACPI_FAILURE (status)) {\n\t\treturn_ACPI_STATUS (status);\n\t}\n\n\tstatus = acpi_os_create_lock(&acpi_gbl_reference_count_lock);\n\tif (ACPI_FAILURE(status)) {\n\t\treturn_ACPI_STATUS(status);\n\t}\n\n\t/* Mutex for _OSI support */\n\n\tstatus = acpi_os_create_mutex(&acpi_gbl_osi_mutex);\n\tif (ACPI_FAILURE(status)) {\n\t\treturn_ACPI_STATUS(status);\n\t}\n\n\t/* Create the reader/writer lock for namespace access */\n\n\tstatus = acpi_ut_create_rw_lock(&acpi_gbl_namespace_rw_lock);\n\treturn_ACPI_STATUS(status);\n}",
    "comment": "Initializes predefined mutexes and locks for synchronization, including mutexes for _OSI support and a reader/writer lock for namespace access.",
    "prorec_sum": "Initializes several global data structures and invokes a secondary routine to set up required components, returning an error code if any allocation or initialization fails.",
    "filter_prorec_sum": "Initializes a set of global pointer slots by allocating buffers and invoking a helper function, returning an error code on allocation or initialization failure.",
    "prorec_aug_sum": "Initializes and allocates several global data structures, then invokes a setup routine, retrying or returning an error code if allocation or initialization fails.",
    "filter_prorec_aug_sum": "Initializes multiple global word buffers and invokes a secondary routine to configure or register them, returning an error code if any allocation fails.",
    "work_score": {
        "prorec": {
            "summary": "Initializes several global data structures and invokes a secondary routine to set up required components, returning an error code if any allocation or initialization fails.",
            "score": [
                0.9333333333333332,
                0.6,
                0.5333333333333333
            ],
            "reason": [
                "The summary correctly notes that the function initializes multiple global components and returns an error if any setup step fails, which is supported by the loop creating mutexes, spinlocks, a mutex for _OSI, and a reader/writer lock, with error checks after each. However, the mention of 'global data structures' is somewhat vague compared to the code, and 'invokes a secondary routine to set up required components' is partially accurate since the function calls several routines like acpi_ut_create_mutex and acpi_os_create_lock directly rather than a single secondary routine. Overall, most key details are accurate, with minor generalization.",
                "The summary correctly captures the main action that the function initializes multiple global structures through other routines and returns early on failure, which is supported by repeated calls to initialization functions and `return_ACPI_STATUS` on error. However, it omits specific critical details such as creation of predefined mutexes, spinlocks for GPE, hardware and reference count, the mutex for _OSI support, and the reader/writer lock for namespace access. These omissions mean that not all core logic and edge cases are reflected.",
                "The summary accurately reflects the high-level behavior in the source code, noting initialization of components, use of secondary routines (e.g., acpi_ut_create_mutex, acpi_os_create_lock, acpi_ut_create_rw_lock), and returning error codes on failure. While it omits specific details such as mutex, spinlocks, and locks for particular global variables, the claims made are supported by explicit evidence in the code. The details are generic rather than domain-rich, providing only a general overview of initialization rather than describing specific ACPI constructs or functions."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a set of global pointer slots by allocating buffers and invoking a helper function, returning an error code on allocation or initialization failure.",
            "score": [
                0.20000000000000004,
                0.03333333333333333,
                0.0
            ],
            "reason": [
                "The summary describes initializing global pointer slots via buffer allocation, which is not supported by the source code. The code initializes mutexes, spinlocks, and a reader/writer lock using helper functions like acpi_ut_create_mutex, acpi_os_create_lock, and acpi_ut_create_rw_lock. There is no buffer allocation or explicit manipulation of pointer slots. Only the detail about returning an error code on failure aligns with the actual logic, making most details inaccurate.",
                "The summary inaccurately describes the code as initializing global pointer slots by allocating buffers, which is not evident in the source. The code actually initializes predefined mutexes, spinlocks, a mutex for _OSI support, and a reader/writer lock using specific ACPI helper functions, with error handling for each step. After discarding the incorrect buffer allocation and pointer slot details, none of the accurate semantic content remains, resulting in the core logic being completely missed.",
                "The summary states that the function initializes global pointer slots by allocating buffers, which is inaccurate since the source code does not allocate buffers or reference pointer slots. Instead, it creates predefined mutex objects, spinlocks, and locks using helper functions. It also correctly notes returning an error code on failures, but most details about data structures and logic in the summary are unsupported. More than half of the claims are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "void __key_link(struct key *keyring, struct key *key,\n\t\tunsigned long *_prealloc)\n{\n\tstruct keyring_list *klist, *nklist;\n\tstruct key *discard;\n\n\tnklist = (struct keyring_list *)(*_prealloc & ~KEY_LINK_FIXQUOTA);\n\t*_prealloc = 0;\n\n\tkenter(\"%d,%d,%p\", keyring->serial, key->serial, nklist);\n\n\tklist = rcu_dereference_locked_keyring(keyring);\n\n\tatomic_inc(&key->usage);\n\tkeyring->last_used_at = key->last_used_at =\n\t\tcurrent_kernel_time().tv_sec;\n\n\t/* there's a matching key we can displace or an empty slot in a newly\n\t * allocated list we can fill */\n\tif (nklist) {\n\t\tkdebug(\"reissue %hu/%hu/%hu\",\n\t\t       nklist->delkey, nklist->nkeys, nklist->maxkeys);\n\n\t\tRCU_INIT_POINTER(nklist->keys[nklist->delkey], key);\n\n\t\trcu_assign_pointer(keyring->payload.subscriptions, nklist);\n\n\t\t/* dispose of the old keyring list and, if there was one, the\n\t\t * displaced key */\n\t\tif (klist) {\n\t\t\tkdebug(\"dispose %hu/%hu/%hu\",\n\t\t\t       klist->delkey, klist->nkeys, klist->maxkeys);\n\t\t\tcall_rcu(&klist->rcu, keyring_unlink_rcu_disposal);\n\t\t}\n\t} else if (klist->delkey < klist->nkeys) {\n\t\tkdebug(\"replace %hu/%hu/%hu\",\n\t\t       klist->delkey, klist->nkeys, klist->maxkeys);\n\n\t\tdiscard = rcu_dereference_protected(\n\t\t\tklist->keys[klist->delkey],\n\t\t\trwsem_is_locked(&keyring->sem));\n\t\trcu_assign_pointer(klist->keys[klist->delkey], key);\n\t\t/* The garbage collector will take care of RCU\n\t\t * synchronisation */\n\t\tkey_put(discard);\n\t} else {\n\t\t/* there's sufficient slack space to append directly */\n\t\tkdebug(\"append %hu/%hu/%hu\",\n\t\t       klist->delkey, klist->nkeys, klist->maxkeys);\n\n\t\tRCU_INIT_POINTER(klist->keys[klist->delkey], key);\n\t\tsmp_wmb();\n\t\tklist->nkeys++;\n\t}\n}",
    "comment": "Links a key to a keyring, replacing an existing key if necessary, while managing memory and usage references appropriately.",
    "prorec_sum": "Initializes linkage between two objects, updates reference counters, and inserts the target into the appropriate slot of a container or parent structure.",
    "filter_prorec_sum": "Associates a new object with a parent structure, updating reference counts and linked entries, and triggers follow\u2011up processing if a previous link existed.",
    "prorec_aug_sum": "Updates object linkage in a hierarchical structure, increments reference count, and triggers callbacks or data transfer depending on existing parent association.",
    "filter_prorec_aug_sum": "Links a new object into an existing structure, updates reference counters, and invokes callbacks or initialization based on prior linkage state.",
    "work_score": {
        "prorec": {
            "summary": "Initializes linkage between two objects, updates reference counters, and inserts the target into the appropriate slot of a container or parent structure.",
            "score": [
                0.9666666666666667,
                0.6,
                0.5666666666666668
            ],
            "reason": [
                "The summary captures some accurate elements, such as establishing a linkage between two objects (`keyring` and `key`), updating a reference counter (`atomic_inc(&key->usage)`), and inserting the key into a slot within a container (`nklist` or `klist`). However, it omits specific technical details like handling displacement, usage of RCU mechanisms, condition branches, and time updates, and makes generalized statements without explicitly confirming all operations from the source. Still, most of the stated actions are directly evidenced in the code, indicating high alignment with the source.",
                "The summary accurately mentions initializing a linkage between two objects (keyring and key), updating reference counters (atomic_inc on key->usage), and inserting into the appropriate slot of a container structure (keyring_list via RCU pointers). However, it omits key control flow paths such as handling preallocated lists, replacing existing entries, disposing of the old list, and appending new keys, meaning several significant logic steps are not covered.",
                "The summary correctly notes that the function links two objects, updates a usage counter, and places the target into a slot in a container structure, which aligns with evidence in the code showing atomic_inc on usage, assignments to keyring list slots, and conditional insertion logic. However, it omits specific domain details such as the use of RCU mechanisms, time updates, and quota handling, making the accurate details generic rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Associates a new object with a parent structure, updating reference counts and linked entries, and triggers follow\u2011up processing if a previous link existed.",
            "score": [
                0.9333333333333332,
                0.6,
                0.6666666666666666
            ],
            "reason": [
                "The summary accurately notes that the function links a new object (key) to a parent structure (keyring), updates reference counts via atomic_inc, and modifies linked entries in keyring_list. However, the claim about triggering follow-up processing if a previous link existed is only loosely supported; while the code disposes of old lists and handles RCU-based cleanup, this is not explicitly characterized as follow-up processing in the source. Overall, most semantic details are grounded in the code, with minimal unverified assumptions.",
                "The summary is generally accurate in describing that the function links a new object to a parent structure, updates reference counts (`atomic_inc` on usage), and handles replacing or appending in the list when a previous link existed. However, it omits important details found in the code such as time updates (`last_used_at`), use of multiple conditional branches for replacing, appending, or reissuing keys, and disposal of old allocations with RCU functions. This means it captures the main action but lacks significant logic coverage, including edge and cleanup cases.",
                "The summary correctly captures that a new object (key) is linked to a parent structure (keyring), reference counts are incremented (atomic_inc on usage), and entries in the list are updated. However, the claim about triggering follow\u2011up processing if a previous link existed is only loosely supported \u2014 the code disposes of the old keyring list via call_rcu, but this isn't clearly described as 'follow\u2011up processing' in the summary. Most details are accurate and drawn from explicit code evidence, and the accurate parts provide meaningful insight into the code's function."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic void\nngx_http_upstream_keepalive_close_handler(ngx_event_t *ev)\n{\n    ngx_http_upstream_keepalive_srv_conf_t  *conf;\n    ngx_http_upstream_keepalive_cache_t     *item;\n\n    int                n;\n    char               buf[1];\n    ngx_connection_t  *c;\n\n    ngx_log_debug0(NGX_LOG_DEBUG_HTTP, ev->log, 0,\n                   \"keepalive close handler\");\n\n    c = ev->data;\n\n    if (c->close || c->read->timedout) {\n        goto close;\n    }\n\n    n = recv(c->fd, buf, 1, MSG_PEEK);\n\n    if (n == -1 && ngx_socket_errno == NGX_EAGAIN) {\n        ev->ready = 0;\n\n        if (ngx_handle_read_event(c->read, 0) != NGX_OK) {\n            goto close;\n        }\n\n        return;\n    }\n\nclose:\n\n    item = c->data;\n    conf = item->conf;\n\n    ngx_http_upstream_keepalive_close(c);\n\n    ngx_queue_remove(&item->queue);\n    ngx_queue_insert_head(&conf->free, &item->queue);\n}",
    "comment": "Closes an upstream keepalive connection, handling read timeouts and queue management for connection reuse.",
    "prorec_sum": "Closes a network connection when certain read conditions or errors occur, releasing its memory pool and updating linked list pointers.",
    "filter_prorec_sum": "Handles read-event errors or closure conditions by destroying the memory pool, closing the connection, and unlinking it from associated connection lists.",
    "prorec_aug_sum": "Closes an Nginx connection and cleans up its memory pool when specific socket flags, recv results, or event handling conditions indicate termination is needed.",
    "filter_prorec_aug_sum": "Closes an Nginx upstream connection and cleans up resources when read event handling fails or the connection is flagged for termination.",
    "work_score": {
        "prorec": {
            "summary": "Closes a network connection when certain read conditions or errors occur, releasing its memory pool and updating linked list pointers.",
            "score": [
                0.6,
                0.6,
                0.16666666666666666
            ],
            "reason": [
                "The summary correctly describes that the function closes a network connection under certain conditions, which matches checks for `c->close`, `c->read->timedout`, and recv errors in the source code. It also notes updating linked list pointers, which aligns with `ngx_queue_remove` and `ngx_queue_insert_head`. However, it inaccurately claims that the memory pool is released\u2014there is no explicit memory pool release in the source code\u2014making that detail a hallucination. This yields mostly accurate details but with at least one unverified assumption.",
                "The summary accurately notes that the function closes a network connection under certain read conditions or errors, as evidenced by checks on 'c->close' and 'c->read->timedout' and the recv result, followed by a call to 'ngx_http_upstream_keepalive_close'. However, the claim about releasing its memory pool is inaccurate, as the source code only manipulates linked list pointers via 'ngx_queue_remove' and 'ngx_queue_insert_head', with no explicit memory pool operations. While the accurate part covers the main closing logic and queue updates, it omits other details like the handling of 'EAGAIN' to re-register the read event, meaning some execution paths are missing.",
                "The summary incorrectly claims that the function releases its memory pool, which is not evidenced in the source code. The code closes the connection, removes the item from a queue, and reinserts it into a free list, but there is no explicit memory pool release. The accurate part is the closing of a network connection under specific read conditions or errors, and updating linked list pointers. Since only one of the two details is accurate, over 50% of the claims are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Handles read-event errors or closure conditions by destroying the memory pool, closing the connection, and unlinking it from associated connection lists.",
            "score": [
                0.3666666666666667,
                0.3,
                0.0
            ],
            "reason": [
                "The summary includes unverified details such as destroying the memory pool, which is not present in the source code. The source only shows handling closure conditions by checking flags, peeking at the socket, calling ngx_http_upstream_keepalive_close, and manipulating queues. The claim about unlinking from associated connection lists is partially accurate as queue removal and insertion occur, but 'closing the connection' is more specifically handled by ngx_http_upstream_keepalive_close. Overall, most details are hallucinations or unverifiable from the code.",
                "The summary claims destruction of the memory pool and closing the connection, which is partially incorrect. The source code closes the connection via `ngx_http_upstream_keepalive_close(c)` and manages the connection queues with `ngx_queue_remove` and `ngx_queue_insert_head`, but there is no evidence of memory pool destruction or unlinking from general connection lists. These parts of the summary are hallucinations, and after discarding them, little content remains, covering only part of the actual logic.",
                "The summary claims that the function destroys the memory pool, which is not present in the source code. It also omits specific, accurate details about how the handler checks for closure conditions (`c->close` or `c->read->timedout`), uses `recv` with `MSG_PEEK`, handles EAGAIN by re-registering the read event, then closes the connection and updates queue structures. While some aspects of handling closure and unlinking from lists are accurate, the majority of the statements involve inaccurate or missing actions, resulting in more than half of the details being false."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nshow_arch (FILE *stream, int ext, int check)\n{\n  static char message[] = MESSAGE_TEMPLATE;\n  char *start = message + 27;\n  char *p;\n  int size = sizeof (MESSAGE_TEMPLATE);\n  int left;\n  const char *name;\n  int len;\n  unsigned int j;\n\n  p = start;\n  left = size - (start - message);\n  for (j = 0; j < ARRAY_SIZE (cpu_arch); j++)\n    {\n      /* Should it be skipped?  */\n      if (cpu_arch [j].skip)\n\tcontinue;\n\n      name = cpu_arch [j].name;\n      len = cpu_arch [j].len;\n      if (*name == '.')\n\t{\n\t  /* It is an extension.  Skip if we aren't asked to show it.  */\n\t  if (ext)\n\t    {\n\t      name++;\n\t      len--;\n\t    }\n\t  else\n\t    continue;\n\t}\n      else if (ext)\n\t{\n\t  /* It is an processor.  Skip if we show only extension.  */\n\t  continue;\n\t}\n      else if (check && ! cpu_arch[j].flags.bitfield.cpui386)\n\t{\n\t  /* It is an impossible processor - skip.  */\n\t  continue;\n\t}\n\n      p = output_message (stream, p, message, start, &left, name, len);\n    }\n\n  /* Display disabled extensions.  */\n  if (ext)\n    for (j = 0; j < ARRAY_SIZE (cpu_noarch); j++)\n      {\n\tname = cpu_noarch [j].name;\n\tlen = cpu_noarch [j].len;\n\tp = output_message (stream, p, message, start, &left, name,\n\t\t\t    len);\n      }\n\n  *p = '\\0';\n  fprintf (stream, \"%s\\n\", message);\n}",
    "comment": "Outputs architecture information to a specified stream, including enabled processors and disabled extensions, based on provided flags and conditions.",
    "prorec_sum": "Generates a formatted string from predefined symbol lists based on flags and writes it to the given output stream.",
    "filter_prorec_sum": "Generates a formatted filename string from predefined segments based on flags and writes it to the output stream.",
    "prorec_aug_sum": "Generates a formatted string from predefined entries and writes it to the given stream, conditionally including items based on input flags.",
    "filter_prorec_aug_sum": "Generates a formatted string from predefined entries based on flags and writes it to the given stream.",
    "work_score": {
        "prorec": {
            "summary": "Generates a formatted string from predefined symbol lists based on flags and writes it to the given output stream.",
            "score": [
                0.6,
                0.6,
                0.5666666666666668
            ],
            "reason": [
                "The summary correctly states that the function writes to the given output stream, which is evident from the use of fprintf at the end. However, the claim about generating a formatted string from predefined symbol lists is only partially accurate; the code operates on arrays cpu_arch and cpu_noarch containing name and len fields, which are CPU data structures, not generic symbol lists. This introduces an unverified assumption. Therefore, only part of the summary is grounded in explicit evidence from the source code.",
                "The summary captures the main purpose of the function\u2014producing a formatted string from predefined lists (cpu_arch and cpu_noarch) based on flags (ext, check) and outputting it to the provided stream\u2014which is directly supported by the code. However, it omits critical details of the control flow: skipping logic based on 'skip', handling extensions vs processors, exclusion conditions for unsupported processors, and inclusion of disabled extensions. These omissions mean it does not form a complete picture of the function's logic.",
                "The summary accurately captures the high-level behavior: the function constructs a message from predefined lists (`cpu_arch` and `cpu_noarch`) based on flag conditions (`ext` and `check`) and writes it to a stream. However, it omits all specific details such as the handling of extensions, skipping processors without `cpui386` flag, and the explicit use of conditions that affect iteration. The description is generic and lacks domain-rich specifics evident in the source code logic, resulting in limited value for understanding the code\u2019s precise operation."
            ]
        },
        "filter_prorec": {
            "summary": "Generates a formatted filename string from predefined segments based on flags and writes it to the output stream.",
            "score": [
                0.0,
                0.06666666666666667,
                0.0
            ],
            "reason": [
                "The summary claims the function generates a formatted filename string from predefined segments based on flags, but the source code shows it constructs a message about CPU architectures and extensions, not filenames. None of the semantic details in the summary\u2014such as generating filenames\u2014are evidenced in the code, which focuses on iterating over cpu_arch and cpu_noarch arrays, handling skip conditions, and outputting a message. Therefore, all details are inaccurate and the ratio of accurate details is 0.",
                "The summary claims the function generates a formatted filename string from predefined segments based on flags, but the source code actually builds a message based on CPU architecture arrays and writes it to the stream. There is no evidence of filename handling or predefined filename segments in the code. After discarding this inaccurate detail, no accurate content remains to reflect the actual logic, which includes skipping conditions, handling extensions, and outputting the constructed message.",
                "The summary claims that the function generates a formatted filename string from predefined segments based on flags, but the source code shows it constructs and writes an architecture-related message using cpu_arch and cpu_noarch data, not filenames. There is no evidence of filename construction or predefined segments for filenames in the code. All semantic details in the summary are inaccurate, triggering the kill switch due to over 50% inaccuracy."
            ]
        }
    }
}
{
    "source_code": "\nstatic boolean ReadICCProfile(j_decompress_ptr jpeg_info)\n{\n  char\n    magick[12];\n\n  ErrorManager\n    *error_manager;\n\n  Image\n    *image;\n\n  long\n    length;\n\n  register long\n    i;\n\n  unsigned char\n    *profile;\n\n  /*\n    Determine length of color profile.\n  */\n  length=(long) GetCharacter(jpeg_info) << 8;\n  length+=(long) GetCharacter(jpeg_info);\n  length-=2;\n  if (length <= 14)\n    {\n      while (--length >= 0)\n        (void) GetCharacter(jpeg_info);\n      return(True);\n    }\n  for (i=0; i < 12; i++)\n    magick[i]=GetCharacter(jpeg_info);\n  if (LocaleCompare(magick,\"ICC_PROFILE\") != 0)\n    {\n      /*\n        Not a ICC profile, return.\n      */\n      for (i=0; i < length-12; i++)\n        (void) GetCharacter(jpeg_info);\n      return(True);\n    }\n  (void) GetCharacter(jpeg_info);  /* id */\n  (void) GetCharacter(jpeg_info);  /* markers */\n  length-=14;\n  error_manager=(ErrorManager *) jpeg_info->client_data;\n  image=error_manager->image;\n\n  /*\n    Read color profile.\n  */\n  profile=error_manager->buffer;\n\n  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"ICC profile chunk: %ld bytes\",\n    length);\n\n  for (i=0 ; i < length; i++)\n   profile[i]=GetCharacter(jpeg_info);\n\n  (void) AppendImageProfile(image,\"ICM\",profile,length);\n\n  return(True);\n}",
    "comment": "Reads an ICC color profile from JPEG data, storing it in an image's buffer if the profile is valid.",
    "prorec_sum": "Processes JPEG segment data, discarding non\u2011ICC_PROFILE markers or storing ICC color profile bytes and invoking a handler to apply the embedded ICM profile.",
    "filter_prorec_sum": "Reads JPEG segment bytes from the input, detects an ICC_PROFILE marker, and stores associated ICM profile data into the image structure.",
    "prorec_aug_sum": "Parses JPEG ICC profile segment data and stores it in the image structure, discarding non\u2011ICC segments.",
    "filter_prorec_aug_sum": "Parses a JPEG segment from the input, skipping non-profile data or extracting and storing ICC color profile bytes for further processing.",
    "work_score": {
        "prorec": {
            "summary": "Processes JPEG segment data, discarding non\u2011ICC_PROFILE markers or storing ICC color profile bytes and invoking a handler to apply the embedded ICM profile.",
            "score": [
                1.0,
                0.6999999999999998,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function processes JPEG segment data, checks for the 'ICC_PROFILE' marker, discards non-matching markers, and stores ICC profile bytes. It also notes that the profile is applied, which aligns with the 'AppendImageProfile' call in the source. All elements in the summary are directly evidenced in the source code, with no unverified assumptions.",
                "The summary accurately states that the function processes JPEG segment data, checks for the 'ICC_PROFILE' marker, discards non-matching segments, and reads ICC profile bytes when found. It also correctly notes the application of an embedded ICM profile via a handler, which is implemented as 'AppendImageProfile(image, \"ICM\", profile, length)'. However, it omits key logic such as initial length calculation and checks for small profile lengths, meaning some control flow and edge case handling are missing from the description.",
                "The summary correctly captures that the function processes JPEG segment data, checks if the marker matches 'ICC_PROFILE', and if so, reads the ICC profile bytes and applies them via AppendImageProfile using the 'ICM' tag. This is explicitly supported by the code's logic and function calls. No inaccurate details are present, and the accurate points are domain\u2011specific and directly tied to the code's implementation."
            ]
        },
        "filter_prorec": {
            "summary": "Reads JPEG segment bytes from the input, detects an ICC_PROFILE marker, and stores associated ICM profile data into the image structure.",
            "score": [
                1.0,
                0.7333333333333334,
                0.8333333333333334
            ],
            "reason": [
                "The summary accurately reflects the core functionality found in the source code: it reads JPEG segment bytes, checks for the 'ICC_PROFILE' marker, and stores profile data into the image as an ICM profile via AppendImageProfile. All described details have explicit evidence in the code, with no unverified assumptions or hallucinations.",
                "The summary accurately notes that the function reads JPEG segment bytes, checks for an ICC_PROFILE marker, and stores related profile data into the image structure as an ICM profile using AppendImageProfile. These details are explicitly present in the source code through GetCharacter calls, the LocaleCompare check for \"ICC_PROFILE\", and storing the profile data in the image. While correct, the summary omits nuances such as handling short segments, skipping non-ICC segments, and logging events, which are part of the function's control flow.",
                "The summary accurately describes reading JPEG segment bytes, detecting the 'ICC_PROFILE' marker, and storing the profile data in the image structure. The source code explicitly reads bytes via GetCharacter, checks for 'ICC_PROFILE', and calls AppendImageProfile with \"ICM\" to store the data. All key details are supported in the code, and they provide clear domain insights into ICC profile handling in JPEG processing."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_permutation_linear_to_canonical (gsl_permutation * q,\n                                     const gsl_permutation * p)\n{\n  const size_t n = p->size;\n  size_t i, k, s;\n  size_t t = n;\n\n  const size_t *const pp = p->data;\n  size_t *const qq = q->data;\n\n  if (q->size != p->size)\n    {\n      GSL_ERROR (\"size of q does not match size of p\", GSL_EINVAL);\n    }\n\n  for (i = 0; i < n; i++)\n    {\n\n      k = pp[i];\n      s = 1;\n\n      while (k > i)\n        {\n          k = pp[k];\n          s++;\n        }\n\n      if (k < i)\n        continue;\n\n      /* Now have k == i, i.e the least in its cycle, and s == cycle length */\n\n      t -= s;\n\n      qq[t] = i;\n\n      k = pp[i];\n      s = 1;\n\n      while (k > i)\n        {\n          qq[t + s] = k;\n          k = pp[k];\n          s++;\n        }\n\n      if (t == 0)\n        break;\n    }\n\n  return GSL_SUCCESS;\n}",
    "comment": "Converts a given permutation `p` into its canonical form and stores the result in `q`.",
    "prorec_sum": "Converts a linear permutation array into its canonical form after verifying matching sizes, storing ordered cycles in the destination array.",
    "filter_prorec_sum": "Converts a linear permutation array into its canonical cycle representation after verifying both permutations have the same size.",
    "prorec_aug_sum": "Converts a linear permutation representation into canonical form by traversing cycles and writing reordered elements after validating matching permutation sizes.",
    "filter_prorec_aug_sum": "Converts a linear permutation array into its canonical cycle form while validating matching sizes and reporting an error on mismatch.",
    "work_score": {
        "prorec": {
            "summary": "Converts a linear permutation array into its canonical form after verifying matching sizes, storing ordered cycles in the destination array.",
            "score": [
                0.8666666666666667,
                0.6999999999999998,
                0.5666666666666667
            ],
            "reason": [
                "The summary correctly notes that the function converts a linear permutation into a canonical form and verifies that the sizes of the input and output permutations match, which is explicitly shown in the size check and error handling in the code. However, the claim about 'storing ordered cycles' is only partially accurate; while the code processes cycles and stores elements in the destination array, there is no explicit indication in the source code that the cycles are ordered beyond their canonical representation. This introduces a minor unverified assumption, but most of the summary\u2019s details are supported by the code.",
                "The summary correctly states that the function converts a linear permutation to a canonical form and verifies the sizes of the source and destination arrays, which matches the explicit `GSL_ERROR` size check in the code. It also accurately mentions storing ordered cycles in the destination array, which is reflected in the loop that writes cycle elements into `qq`. These details cover the main logic; however, the summary omits some specifics such as how `t` is decremented by cycle length and the early break when `t` reaches zero, so it is not a complete picture of the edge case handling.",
                "The summary correctly states that the function converts a linear permutation into a canonical form and checks for matching sizes, which are explicitly evidenced by the GSL_ERROR check and the transformation logic. However, the claim about 'storing ordered cycles' is inaccurate, as the source code does not explicitly order cycles beyond the inherent traversal, and the summary omits specifics about the step-by-step traversal and cycle length calculation present in the code. The accurate details present are generic and lack deeper domain-specific insights."
            ]
        },
        "filter_prorec": {
            "summary": "Converts a linear permutation array into its canonical cycle representation after verifying both permutations have the same size.",
            "score": [
                1.0,
                0.6,
                0.7999999999999999
            ],
            "reason": [
                "The summary accurately reflects that the function verifies both permutations have the same size via the size comparison and error handling, and that it transforms a linear permutation into a canonical cycle form as evidenced by the loop structure and cycle detection logic. There are no additional unverified or incorrect claims, making all details accurate.",
                "The summary is accurate in describing the core purpose of converting a linear permutation into its canonical cycle form and noting the size check between the two permutations, both of which are explicitly present in the code. However, it omits significant implementation details such as cycle detection logic, the handling of 't' as a counter, and loop-based population of the output array, which are critical to the function's behavior.",
                "The summary correctly states that the function converts a linear permutation into a canonical cycle representation and verifies both permutations have the same size, which is explicit in the code (size check with GSL_ERROR and cycle construction logic). These details are accurate and domain-relevant, with no additional inaccurate claims present."
            ]
        }
    }
}
{
    "source_code": "\nstatic int slave_update(struct link_slave *slave)\n{\n\tstruct snd_ctl_elem_value *uctl;\n\tint err, ch;\n\n\tuctl = kmalloc(sizeof(*uctl), GFP_KERNEL);\n\tif (!uctl)\n\t\treturn -ENOMEM;\n\tuctl->id = slave->slave.id;\n\terr = slave->slave.get(&slave->slave, uctl);\n\tfor (ch = 0; ch < slave->info.count; ch++)\n\t\tslave->vals[ch] = uctl->value.integer.value[ch];\n\tkfree(uctl);\n\treturn 0;\n}",
    "comment": "Updates the values of a slave device by retrieving its current control element values and storing them in the slave's array.",
    "prorec_sum": "Allocates and initializes a 0xD0-byte structure from fields of `a1`, invokes a callback with it, updates state fields, and performs further processing.",
    "filter_prorec_sum": "Allocates and initializes a 0xD0-byte structure from source object fields, invokes its callback, updates related state, and finalizes it with additional parameters.",
    "prorec_aug_sum": "Allocates a 0xD0-byte structure, copies fields from the source object, invokes a callback, updates state fields, and performs further initialization with provided doubles.",
    "filter_prorec_aug_sum": "Allocates and initializes a 0xD0\u2011byte structure from fields in `a1`, invokes a callback, updates related fields, and finalizes it with another setup call.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a 0xD0-byte structure from fields of `a1`, invokes a callback with it, updates state fields, and performs further processing.",
            "score": [
                0.2333333333333333,
                0.3666666666666667,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies. The source code allocates a structure using kmalloc with sizeof(*uctl) rather than a fixed 0xD0-byte size, there is no reference to 'a1', and the initialization comes from slave->slave.id rather than unspecified fields of 'a1'. While the code does invoke a callback via slave->slave.get and update vals from uctl->value.integer.value[], there is no explicit evidence of 'further processing' beyond copying values and freeing memory. Accurate details are limited, leading to a low ratio of correctness.",
                "The summary claims allocation of a 0xD0-byte structure, initialization from fields of `a1`, further processing, and a callback. The source code instead allocates `sizeof(*uctl)` using kmalloc, sets its `id` from `slave->slave.id`, calls `slave->slave.get`, updates `vals` from `uctl->value.integer.value[]`, and frees the allocation. The 0xD0-byte size, reference to `a1`, and mention of further processing steps are not supported by the code, leaving only the allocation, callback invocation, and state update as accurate. Much of the logic in the summary is hallucinated, and the accurate parts do not provide a complete picture of the code's flow.",
                "The summary claims a 0xD0-byte structure allocation, initialization from fields of `a1`, and further processing steps. The source code shows allocation with kmalloc(sizeof(*uctl)), assignment from slave->slave.id, a callback invocation, and value updates, but provides no evidence for the specific 0xD0 size, use of `a1`, or unspecified further processing. Over half of the details are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a 0xD0-byte structure from source object fields, invokes its callback, updates related state, and finalizes it with additional parameters.",
            "score": [
                0.26666666666666666,
                0.3666666666666667,
                0.0
            ],
            "reason": [
                "The summary contains multiple unverified or incorrect details. The claim of allocating a 0xD0-byte structure is not supported in the source code, which uses kmalloc(sizeof(*uctl), GFP_KERNEL) without specifying byte size. The phrase 'initializes from source object fields' loosely applies to setting uctl->id from slave->slave.id, which is accurate. However, 'invokes its callback' is accurate as slave->slave.get is called. Claims about 'finalizes it with additional parameters' and specific byte size are hallucinations. Overall, less than half of the details are supported by explicit code evidence.",
                "The summary's mention of a '0xD0-byte structure' and 'additional parameters' is unsupported by the source code, making those details inaccurate. While the source code shows allocation via kmalloc of a snd_ctl_elem_value structure, initialization from slave->slave.id, invocation of a callback (slave->slave.get), state update via copying values into slave->vals[], and freeing the structure, the summary omits the specific loop over channels and the exact data copying logic. Thus, only partial and broadly correct elements are present, with key details missing and several hallucinations.",
                "The summary claims a 0xD0-byte allocation, initialization from source object fields, invocation of a callback, state updates, and finalization with additional parameters. In the source code, there is an allocation using kmalloc based on sizeof(*uctl), copying of an id field, invocation of a get callback, update of vals array from uctl values, and freeing the allocation. There is no explicit evidence of a 0xD0-byte size, nor any mention of 'finalizing with additional parameters'; these details are inaccurate. More than half of the summary's claims lack direct support from the source, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\n\f\nint\nalias_cb(enum grecs_callback_command cmd,\n\t grecs_locus_t *locus,\n\t void *varptr,\n\t grecs_value_t *value,\n\t void *cb_data)\n{\n    char **argv;\n    int argc;\n    int i;\n\n    if (cmd != grecs_callback_set_value) {\n\tgrecs_error(locus, 0, _(\"Unexpected block statement\"));\n\treturn 1;\n    }\n    if (value->type != GRECS_TYPE_ARRAY) {\n\tgrecs_error(locus, 0, _(\"Not enough arguments for alias\"));\n\treturn 1;\n    }\n    argc = value->v.arg.c - 1;\n    argv = xcalloc(argc + 1, sizeof(argv[0]));\n    for (i = 0; i < argc; i++) {\n\tif (value->v.arg.v[i+1]->type != GRECS_TYPE_STRING) {\n\t    grecs_error(locus, 0, _(\"argument %d has wrong type\"), i+1);\n\t    return 1;\n\t}\n\targv[i] = xstrdup(value->v.arg.v[i+1]->v.string);\n    }\n    argv[i] = NULL;\n    return alias_install(value->v.arg.v[0]->v.string, argc, argv, locus);\n}",
    "comment": "Processes a callback to set an alias by checking argument types and installing the alias with provided string parameters.",
    "prorec_sum": "Validates alias block arguments, converts them to internal form, and invokes a subroutine with the alias name and processed argument list.",
    "filter_prorec_sum": "Validates an alias block\u2019s arguments, converts them to strings, and invokes a handler with the alias name, argument count, and argument list.",
    "prorec_aug_sum": "Validates alias statement arguments, converts them to internal form, and invokes a handler, reporting errors for unexpected blocks or wrong argument types.",
    "filter_prorec_aug_sum": "Validates alias command arguments, converts them to strings, and invokes a handler with the alias name and processed argument list.",
    "work_score": {
        "prorec": {
            "summary": "Validates alias block arguments, converts them to internal form, and invokes a subroutine with the alias name and processed argument list.",
            "score": [
                1.0,
                0.7333333333333334,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly states that the function validates alias block arguments, processes them into an internal form, and calls another subroutine with the alias name and processed arguments. The code explicitly checks the command type, validates the input array and string types, builds an argv array, and calls alias_install with the alias name and processed list. All semantic details in the summary are supported by the source code, with no evident hallucinations.",
                "The summary accurately describes the core logic: the function checks alias block arguments for validity, processes them into an internal array format, and calls a subroutine (`alias_install`) with the alias name and processed argument list. This matches the source code's validation of `cmd` and `value` types, conversion of string arguments, and final function invocation. However, the summary omits some specific error conditions and type checks (e.g., handling `GRECS_TYPE_ARRAY` requirement, argument type validation), which means it doesn't fully capture edge case handling present in the code.",
                "The summary accurately reflects the main functional flow in the source code: it checks alias block arguments (via conditional error handling), processes them into an internal form (string array creation and duplication), and calls a subroutine with the alias name and processed arguments. All claims are supported directly by function logic and variable handling in the code, though the description is generic and lacks mention of specific type checks or data structures such as GRECS_TYPE_ARRAY and GRECS_TYPE_STRING. These accurate but high-level details provide only moderate domain value."
            ]
        },
        "filter_prorec": {
            "summary": "Validates an alias block\u2019s arguments, converts them to strings, and invokes a handler with the alias name, argument count, and argument list.",
            "score": [
                1.0,
                0.6999999999999998,
                0.9
            ],
            "reason": [
                "The summary correctly identifies that the function checks alias block arguments, ensures they are strings, and calls a handler with the alias name, argument count, and list. All these details are explicitly supported in the source code: type checks for GRECS_TYPE_ARRAY and GRECS_TYPE_STRING, string conversion via xstrdup, and invocation of alias_install with relevant parameters. There are no unsupported claims or hallucinations.",
                "The summary accurately reflects the core logic of the source code: it checks the alias block\u2019s arguments, ensures they are strings, converts them, and calls a handler function with the alias name, argument count, and argument list. While it omits some details like specific error conditions for unexpected commands and type validation, it captures the main processing steps and final invocation, covering the primary functionality without hallucinations.",
                "The summary\u2019s details \u2014 validation of alias block arguments, converting them to strings, and invoking a handler with alias name, argument count, and list \u2014 are directly supported in the source code via type checks for GRECS_TYPE_ARRAY and GRECS_TYPE_STRING, string duplication, and the call to alias_install with these parameters. All details are accurate and domain-specific, providing a precise reflection of the code\u2019s logic."
            ]
        }
    }
}
{
    "source_code": "static int\nis_hidden_fd(struct redirtab *rp, int fd)\n{\n\tint i;\n\tstruct parsefile *pf;\n\n\tif (fd == -1)\n\t\treturn 0;\n\t/* Check open scripts' fds */\n\tpf = g_parsefile;\n\twhile (pf) {\n\t\t/* We skip pf_fd == 0 case because of the following case:\n\t\t * $ ash  # running ash interactively\n\t\t * $ . ./script.sh\n\t\t * and in script.sh: \"exec 9>&0\".\n\t\t * Even though top-level pf_fd _is_ 0,\n\t\t * it's still ok to use it: \"read\" builtin uses it,\n\t\t * why should we cripple \"exec\" builtin?\n\t\t */\n\t\tif (pf->pf_fd > 0 && fd == pf->pf_fd) {\n\t\t\treturn 1;\n\t\t}\n\t\tpf = pf->prev;\n\t}\n\n\tif (!rp)\n\t\treturn 0;\n\t/* Check saved fds of redirects */\n\tfd |= COPYFD_RESTORE;\n\tfor (i = 0; i < rp->pair_count; i++) {\n\t\tif (rp->two_fd[i].copy == fd) {\n\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}",
    "comment": "Checks if a file descriptor is already in use by open scripts or saved redirects in the given redirection table.",
    "prorec_sum": "Checks whether the given integer identifier matches an entry in a global linked list or a1\u2019s indexed records, returning 1 if found.",
    "filter_prorec_sum": "Checks if the given identifier matches any in a global linked list or a1\u2019s array, treating matches with high-bit set as valid.",
    "prorec_aug_sum": "Checks whether the given integer identifier exists and is valid in a global linked list or a1\u2019s associated array entries.",
    "filter_prorec_aug_sum": "Checks whether the given integer ID matches an entry in a global linked list or a1\u2019s table, including handling high-bit\u2013flagged IDs.",
    "work_score": {
        "prorec": {
            "summary": "Checks whether the given integer identifier matches an entry in a global linked list or a1\u2019s indexed records, returning 1 if found.",
            "score": [
                0.3,
                0.39999999999999997,
                0.0
            ],
            "reason": [
                "The summary omits and misstates key semantic details. It incorrectly describes a 'global linked list' and 'a1\u2019s indexed records', which are not explicitly present in the source code. The code actually iterates over a 'g_parsefile' linked structure to compare 'pf_fd' values and checks 'rp->two_fd' entries after applying 'COPYFD_RESTORE'. These specifics are missing or replaced by inaccurate, generic terms, resulting in most details being unverified assumptions.",
                "The summary vaguely mentions checking against a global linked list or 'a1\u2019s indexed records', which partially aligns with verifying the fd against g_parsefile (global linked list) and rp->two_fd array (indexed records). However, it omits critical logic present in the source code: handling fd == -1, skipping pf_fd == 0, bitwise modification with COPYFD_RESTORE, and returning 0 in several default conditions. The term 'a1' is also inaccurate and not present in the source code, reducing completeness.",
                "The summary's mention of 'global linked list' is partially accurate as the code iterates over a global pointer (g_parsefile) with a linked structure. However, the reference to 'a1\u2019s indexed records' is inaccurate since the code actually uses 'rp' (struct redirtab) and not 'a1'. Additionally, the summary omits important logic details such as the handling of fd == -1, the pf_fd > 0 condition, and the COPYFD_RESTORE bitwise operation. More than half of the details are incorrect or missing, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Checks if the given identifier matches any in a global linked list or a1\u2019s array, treating matches with high-bit set as valid.",
            "score": [
                0.06666666666666667,
                0.06666666666666667,
                0.0
            ],
            "reason": [
                "The summary contains multiple inaccuracies. The source code checks if the given file descriptor matches any in a global linked list of parsefile structures or in a struct redirtab array, but there is no concept of 'identifier', 'a1\u2019s array', or treating matches with the high-bit set as valid. The 'high-bit set' detail and 'a1\u2019s array' are hallucinations not evidenced in the code. Only the part about checking a global linked list and an array is partially correct, but most specific claims are unverified or false.",
                "The summary describes checking an identifier in a global linked list and 'a1\u2019s array' with a special rule for high-bit set matches. The source code actually checks file descriptors in a global parsefile chain and in a redirtab array, with bitwise OR using COPYFD_RESTORE\u2014not high-bit validation. None of the summary\u2019s details have explicit evidence in the code, so all are inaccurate and the core logic is missed.",
                "The summary claims the function checks an identifier against a global linked list or 'a1\u2019s array', and treats matches with a high-bit set as valid. In the source code, the function actually accepts a file descriptor, compares it against the 'pf_fd' fields of a global linked list of 'parsefile' structures, and against the 'copy' fields in the 'two_fd' array of the 'redirtab' struct after OR-ing with COPYFD_RESTORE. There is no evidence for 'a1\u2019s array' or high-bit logic, so these are inaccurate. Since more than half of the summary's details are incorrect, the kill switch applies."
            ]
        }
    }
}
{
    "source_code": "\nvoid ironlake_edp_panel_off(struct intel_dp *intel_dp)\n{\n\tstruct drm_device *dev = intel_dp_to_dev(intel_dp);\n\tstruct drm_i915_private *dev_priv = dev->dev_private;\n\tu32 pp;\n\tu32 pp_ctrl_reg;\n\n\tif (!is_edp(intel_dp))\n\t\treturn;\n\n\tDRM_DEBUG_KMS(\"Turn eDP power off\\n\");\n\n\tWARN(!intel_dp->want_panel_vdd, \"Need VDD to turn off panel\\n\");\n\n\tpp = ironlake_get_pp_control(intel_dp);\n\t/* We need to switch off panel power _and_ force vdd, for otherwise some\n\t * panels get very unhappy and cease to work. */\n\tpp &= ~(POWER_TARGET_ON | EDP_FORCE_VDD | PANEL_POWER_RESET | EDP_BLC_ENABLE);\n\n\tpp_ctrl_reg = IS_VALLEYVIEW(dev) ? PIPEA_PP_CONTROL : PCH_PP_CONTROL;\n\n\tI915_WRITE(pp_ctrl_reg, pp);\n\tPOSTING_READ(pp_ctrl_reg);\n\n\tintel_dp->want_panel_vdd = false;\n\n\tironlake_wait_panel_off(intel_dp);\n}",
    "comment": "Turns off eDP panel power by modifying control registers and ensuring no VDD is supplied, preventing panel damage during shutdown.",
    "prorec_sum": "Turns off an Ironlake eDP panel, logs the action, updates hardware registers, waits for power\u2011off delay, and clears the VDD flag.",
    "filter_prorec_sum": "Turns off the Ironlake eDP panel power, logs debug messages, updates hardware state, and waits for the panel power-off timing.",
    "prorec_aug_sum": "Turns off an Ironlake eDP panel, logs the action, updates power state, and waits for the panel power-off delay.",
    "filter_prorec_aug_sum": "Turns off the Ironlake eDP panel power, logs the action, updates state, waits for power-down timing, and issues related hardware commands.",
    "work_score": {
        "prorec": {
            "summary": "Turns off an Ironlake eDP panel, logs the action, updates hardware registers, waits for power\u2011off delay, and clears the VDD flag.",
            "score": [
                1.0,
                0.9333333333333332,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function turns off an Ironlake eDP panel, logs the action via DRM_DEBUG_KMS, updates hardware registers using I915_WRITE, waits for the panel to power off via ironlake_wait_panel_off, and clears the VDD flag by setting want_panel_vdd to false. All these details are explicitly present in the source code, with no unsupported or hallucinated claims.",
                "The summary accurately describes turning off the Ironlake eDP panel, logging the action via DRM_DEBUG_KMS, updating hardware registers with I915_WRITE, waiting for power-off using ironlake_wait_panel_off, and clearing the VDD flag by setting want_panel_vdd to false. These details are explicitly present in the source code and together cover the main logic, control flow, and final state change, providing a complete picture of the function's purpose and behavior.",
                "The summary correctly identifies key operations in the code: turning off the eDP panel when is_edp() passes, logging via DRM_DEBUG_KMS, updating hardware registers with I915_WRITE, waiting for panel power-off using ironlake_wait_panel_off, and clearing the want_panel_vdd flag. All these details are explicitly present in the source. The description is concise but provides domain-specific insights related to register operations and power management logic."
            ]
        },
        "filter_prorec": {
            "summary": "Turns off the Ironlake eDP panel power, logs debug messages, updates hardware state, and waits for the panel power-off timing.",
            "score": [
                1.0,
                0.7333333333333334,
                0.8333333333333334
            ],
            "reason": [
                "The summary accurately reflects the source code\u2019s main actions: it describes turning off the Ironlake eDP panel power (matching function intent), logging a debug message (DRM_DEBUG_KMS call), updating hardware state via register writes (I915_WRITE and POSTING_READ), and waiting for the panel to power off (ironlake_wait_panel_off). All mentioned details are explicitly present in the code, with no unsupported assumptions.",
                "The summary correctly captures that the function turns off the Ironlake eDP panel, logs a debug message, updates hardware registers, and waits for the panel power-off timing. All these details are explicitly supported by the source code: the `DRM_DEBUG_KMS` call logs the message, register values are altered via `I915_WRITE` and `POSTING_READ`, and `ironlake_wait_panel_off` handles timing. While these points are accurate and represent the main logic, the summary omits key conditions like the early return if `!is_edp(intel_dp)` and the `WARN` on `want_panel_vdd`, which are part of the code\u2019s edge-case handling.",
                "The summary accurately reflects the main function behavior: it turns off the eDP panel power, logs a debug message, updates hardware state via register writes, and waits for the panel to power off. All these details are explicitly supported by the source code through calls to DRM_DEBUG_KMS, I915_WRITE, POSTING_READ, and ironlake_wait_panel_off. There are no inaccurate or hallucinated elements, though the description is somewhat generic and lacks mention of specific conditions, constants, and safeguards present in the code."
            ]
        }
    }
}
{
    "source_code": "\nstatic void die_if_script(unsigned lineno, const char *fmt, ...)\n{\n\tva_list p;\n\n#if HUSH_DEBUG >= 2\n\tbb_error_msg(\"hush.c:%u\", lineno);\n#endif\n\tva_start(p, fmt);\n\tbb_verror_msg(fmt, p, NULL);\n\tva_end(p);\n\tif (!G_interactive_fd)\n\t\txfunc_die();\n}",
    "comment": "Logs an error message with the line number and format specified, then terminates the program if not in interactive mode.",
    "prorec_sum": "Packages provided doubles and parameters into a structured array, calls a processing routine, and triggers a secondary handler if a global status flag is unset.",
    "filter_prorec_sum": "Prepares parameters including multiple doubles and invokes sub_5176F5, then conditionally calls sub_517B39, returning a global status code.",
    "prorec_aug_sum": "Prepares argument and data buffers, invokes sub_5176F5 with multiple double parameters, and conditionally calls sub_517B39 based on a global status flag.",
    "filter_prorec_aug_sum": "Prepares structured parameters including optional SIMD data and invokes sub_5176F5, followed by sub_517B39 if a global status flag is unset.",
    "work_score": {
        "prorec": {
            "summary": "Packages provided doubles and parameters into a structured array, calls a processing routine, and triggers a secondary handler if a global status flag is unset.",
            "score": [
                0.06666666666666667,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims about handling doubles, parameters in a structured array, a processing routine, and a secondary handler triggered by a global status flag bear no explicit evidence in the source code. The code defines a function that logs an error message using varargs and conditionally calls xfunc_die based on G_interactive_fd, with no mention of doubles, arrays, or structured data. All details in the summary are hallucinations, resulting in no accurate match to the source.",
                "The summary describes packaging doubles into an array, calling a processing routine, and triggering a secondary handler based on a global status flag. None of these actions are explicitly present in the source code, which instead formats and prints an error message, handles variadic arguments, and calls a termination function when a global file descriptor flag is unset. Since all details in the summary are unsupported, the core logic of the code is completely missed.",
                "The summary claims about handling doubles, creating a structured array, and invoking a secondary handler based on a global status flag are not supported by the source code. The source code instead defines a function that logs an error message, formats it with varargs, and conditionally calls xfunc_die if G_interactive_fd is false. None of the specific details in the summary are explicitly present, meaning all are inaccurate, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Prepares parameters including multiple doubles and invokes sub_5176F5, then conditionally calls sub_517B39, returning a global status code.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes preparing multiple doubles, invoking functions named sub_5176F5 and sub_517B39, and returning a global status code. None of these elements appear in the provided source code, which instead defines die_if_script with va_list handling and calls bb_error_msg, bb_verror_msg, and xfunc_die. As there is no explicit evidence for any of the summary's claims, all details are inaccurate.",
                "The summary describes preparing multiple double parameters, invoking functions sub_5176F5 and sub_517B39, and returning a global status code, none of which appear in the provided source code. The actual function die_if_script uses va_list to handle variable arguments, formats error messages, and calls xfunc_die() based on G_interactive_fd, with no evidence of the described functions or double parameters. All details in the summary are inaccurate, leaving no valid content to map to the code's logic.",
                "The summary describes preparing multiple double parameters, invoking functions sub_5176F5 and sub_517B39, and returning a global status code, none of which are present in the source code. The actual source defines die_if_script, uses va_list for variadic arguments, conditionally calls bb_error_msg and xfunc_die, with no doubles or functions named in the summary. All details are inaccurate, exceeding the kill switch threshold."
            ]
        }
    }
}
{
    "source_code": "\nasmlinkage long compat_sys_getdents64(unsigned int fd,\n\t\tstruct linux_dirent64 __user * dirent, unsigned int count)\n{\n\tstruct fd f;\n\tstruct linux_dirent64 __user * lastdirent;\n\tstruct compat_getdents_callback64 buf;\n\tint error;\n\n\tif (!access_ok(VERIFY_WRITE, dirent, count))\n\t\treturn -EFAULT;\n\n\tf = fdget(fd);\n\tif (!f.file)\n\t\treturn -EBADF;\n\n\tbuf.current_dir = dirent;\n\tbuf.previous = NULL;\n\tbuf.count = count;\n\tbuf.error = 0;\n\n\terror = vfs_readdir(f.file, compat_filldir64, &buf);\n\tif (error >= 0)\n\t\terror = buf.error;\n\tlastdirent = buf.previous;\n\tif (lastdirent) {\n\t\ttypeof(lastdirent->d_off) d_off = f.file->f_pos;\n\t\tif (__put_user_unaligned(d_off, &lastdirent->d_off))\n\t\t\terror = -EFAULT;\n\t\telse\n\t\t\terror = count - buf.count;\n\t}\n\tfdput(f);\n\treturn error;\n}",
    "comment": "Retrieves directory entries from a file descriptor and populates a user-provided buffer with the results, handling errors and offsets.",
    "prorec_sum": "Handles a file fallocate request by validating parameters, invoking allocation operations, and optionally performing follow-up processing based on mode and results.",
    "filter_prorec_sum": "Handles a file operation by initializing related structures, invoking a helper, and optionally processing ranges using provided double-precision parameters.",
    "prorec_aug_sum": "Handles a futex-related operation, setting up parameters, invoking a callback, and performing additional processing based on result and provided timing values.",
    "filter_prorec_aug_sum": "Handles a futex operation by validating parameters, initializing related structures, invoking a callback, and optionally processing timing and additional synchronization data.",
    "work_score": {
        "prorec": {
            "summary": "Handles a file fallocate request by validating parameters, invoking allocation operations, and optionally performing follow-up processing based on mode and results.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims the function handles a file fallocate request with parameter validation, allocation operations, and optional follow-up based on mode and results. The source code instead implements compat_sys_getdents64 for reading directory entries, with logic for access checks, reading via vfs_readdir, and updating offsets. No evidence supports any fallocate-related operations, allocation, or mode handling. All semantic details are inaccurate, resulting in a complete mismatch.",
                "The summary describes handling a file fallocate request with parameter validation, allocation operations, and mode-based follow-up. None of these actions are present in the source code, which instead implements compat_sys_getdents64 to read directory entries, perform access checks, use vfs_readdir, and update offsets. All details in the summary are inaccurate and do not match any functions, variables, or logic in the source code.",
                "The summary claims the code handles a file fallocate request with parameter validation, allocation operations, and follow-up processing based on mode and results. The source code actually implements compat_sys_getdents64, which validates user-space buffers, retrieves a file descriptor, reads directory entries using vfs_readdir, and updates offsets. None of the details about fallocate or allocation operations are present, making all extracted details inaccurate and triggering the kill switch due to 100% inaccuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Handles a file operation by initializing related structures, invoking a helper, and optionally processing ranges using provided double-precision parameters.",
            "score": [
                0.3,
                0.2333333333333333,
                0.0
            ],
            "reason": [
                "The summary's claims about handling file operations and initializing related structures are partially accurate, as the code does set up structures and calls a helper function (vfs_readdir). However, it incorrectly refers to 'processing ranges' and 'double-precision parameters', which are not present in the source code. The code deals with file descriptors and directory entries, not floating-point values. This results in most details being unverified or inaccurate.",
                "The summary claims that the function processes ranges using double-precision parameters, which is not supported by the source code. The code deals with directory reading (`vfs_readdir`), access checks, structure initialization, and updating offsets, with no evidence of double-precision parameters or range processing. After discarding the inaccurate detail, only a vague notion of initializing structures and invoking a helper remains, which misses the core logic involving error handling, access verification, and offset updates.",
                "The summary claims use of double-precision parameters and processing of ranges, which has no explicit evidence in the source code and is therefore inaccurate. The code actually performs a directory read operation with `linux_dirent64` structures, calls `vfs_readdir` with a callback, and uses user-space copying functions\u2014none of which mention double-precision or range processing. With over 50% of the details being inaccurate, the evaluation stops due to the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_multilarge_nlinear_eval_df(const CBLAS_TRANSPOSE_t TransJ,\n                               const gsl_vector *x,\n                               const gsl_vector *f,\n                               const gsl_vector *u,\n                               const gsl_vector *swts,\n                               const double h,\n                               const gsl_multilarge_nlinear_fdtype fdtype,\n                               gsl_multilarge_nlinear_fdf *fdf,\n                               gsl_vector *v,\n                               gsl_matrix *JTJ,\n                               gsl_vector *work)\n{\n  const size_t n = fdf->n;\n  const size_t p = fdf->p;\n\n  if (u != NULL && ((TransJ == CblasNoTrans && u->size != p) ||\n                    (TransJ == CblasTrans && u->size != n)))\n    {\n      GSL_ERROR(\"u vector has wrong size\", GSL_EBADLEN);\n    }\n  else if (v != NULL && ((TransJ == CblasNoTrans && v->size != n) ||\n                         (TransJ == CblasTrans && v->size != p)))\n    {\n      GSL_ERROR(\"v vector has wrong size\", GSL_EBADLEN);\n    }\n  else if (JTJ != NULL && ((JTJ->size1 != p) || (JTJ->size2 != p)))\n    {\n      GSL_ERROR(\"JTJ matrix has wrong size\", GSL_EBADLEN);\n    }\n  else\n    {\n      int status;\n\n      if (fdf->df)\n        {\n          /* call user-supplied function */\n          status = ((*((fdf)->df)) (TransJ, x, u, fdf->params, v, JTJ));\n\n          if (v)\n            ++(fdf->nevaldfu);\n\n          if (JTJ)\n            ++(fdf->nevaldf2);\n        }\n      else\n        {\n#if 0\n          /* use finite difference Jacobian approximation */\n          status = gsl_multilarge_nlinear_df(h, fdtype, x, swts, fdf, f, df, work);\n#endif\n        }\n\n      return status;\n    }\n}",
    "comment": "Evaluates the Jacobian or its finite difference approximation for a nonlinear optimization problem, checking vector and matrix sizes for validity.",
    "prorec_sum": "Validates vector and matrix dimensions for nonlinear large-scale evaluation, reports size errors, and calls the model\u2019s derivative function if inputs are correct.",
    "filter_prorec_sum": "Validates vector and matrix dimensions for a non-linear large-scale evaluation, then invokes the model\u2019s derivative function, reporting errors on size mismatches.",
    "prorec_aug_sum": "Validates vector and matrix sizes, then invokes the solver\u2019s derivative-evaluation callback for large-scale nonlinear fitting, updating evaluation counters when outputs are provided.",
    "filter_prorec_aug_sum": "Validates vector and matrix dimensions for a nonlinear large-scale evaluator, then invokes the associated callback to compute derivatives and function values.",
    "work_score": {
        "prorec": {
            "summary": "Validates vector and matrix dimensions for nonlinear large-scale evaluation, reports size errors, and calls the model\u2019s derivative function if inputs are correct.",
            "score": [
                1.0,
                0.6999999999999998,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly states that the function validates vector and matrix dimensions, returns size errors, and calls a derivative function if inputs are valid. These details are explicitly confirmed in the source code through size checks for `u`, `v`, and `JTJ` and conditionally invoking `fdf->df`. All semantic elements in the summary match the code without introducing unverified assumptions.",
                "The summary accurately captures key logic present in the source code: it checks vector and matrix dimensions for correctness, triggers size error reporting with GSL_ERROR when sizes mismatch, and calls the derivative function (fdf->df) when inputs are valid. However, it omits details on conditional handling based on TransJ orientation, the specific increment of evaluation counters, and the absence of the finite difference fallback since that block is disabled (#if 0), which reduces completeness.",
                "The summary correctly identifies vector and matrix dimension validation, error reporting when sizes mismatch, and invocation of the derivative function when inputs are valid, all of which are explicitly present in the source code. These details are domain-relevant, mentioning specific function purposes tied to nonlinear large-scale evaluation. No inaccurate details were found, and the accurate ones reflect meaningful functionality rather than trivial facts."
            ]
        },
        "filter_prorec": {
            "summary": "Validates vector and matrix dimensions for a non-linear large-scale evaluation, then invokes the model\u2019s derivative function, reporting errors on size mismatches.",
            "score": [
                1.0,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly states that the function validates vector and matrix dimensions and reports errors for size mismatches, which is explicitly shown in multiple conditional checks with GSL_ERROR calls. It also accurately notes that the model\u2019s derivative function is invoked via fdf->df when present. No unverified claims or hallucinations were found, making all details supported by the source code.",
                "The summary accurately captures validation of vector and matrix dimensions and invocation of the derivative function, including error reporting for size mismatches, all of which are explicitly present in the source code. However, it omits other critical details such as conditional checks for 'u', 'v', and 'JTJ' against 'TransJ', increments of evaluation counters, and handling of finite difference approximation in the absence of a user-supplied derivative. This partial coverage misses important aspects of the control flow and edge case handling.",
                "The summary accurately reflects key elements from the source code: it checks vector and matrix dimensions for specific cases before calling the derivative function via fdf->df, and returns errors on mismatches using GSL_ERROR. All mentioned details have explicit evidence in the function logic. While accurate, the details are somewhat generic and do not capture nuances like handling TransJ variants, incrementing counters, or optional finite difference fallback, which limits the depth of domain insight."
            ]
        }
    }
}
{
    "source_code": "\nvoid\njitter_hash_table_add (struct jitter_hash_table *t,\n                       const union jitter_word key,\n                       const union jitter_word value,\n                       jitter_hash_function f)\n{\n  /* We only enlarge the table (when it's getting too full) on add, and never\n     shrink it. */\n  if (jitter_hash_table_overfull (t))\n    jitter_hash_table_enlarge (t, f);\n\n  t->binding_no ++;\n  jitter_uint bucket_index = f (key) % t->bucket_no;\n\n  /* Find the bucket; make it if needed. */\n  struct jitter_hash_bucket *b = t->buckets [bucket_index];\n  if (b == NULL)\n    {\n      b = jitter_xmalloc (sizeof (struct jitter_hash_bucket));\n      b->allocated_binding_no = INITIAL_BINDING_NO_PER_BUCKET;\n      b->used_binding_no = 0;\n      b->bindings\n        = jitter_xmalloc (sizeof (struct jitter_hash_binding)\n                          * INITIAL_BINDING_NO_PER_BUCKET);\n      t->buckets [bucket_index] = b;\n    }\n\n  /* Find the binding where we need to write within the bucket; make place and\n     reallocate if needed. */\n  if (b->used_binding_no == b->allocated_binding_no)\n    {\n      //printf (\"enlarging the %i-th bucket: %li to %li\\n\", (int)bucket_index, (long)b->allocated_binding_no, (long)(b->allocated_binding_no * 2));\n\n      b->bindings = jitter_xrealloc (b->bindings,\n                                     sizeof (struct jitter_hash_binding)\n                                     * (b->allocated_binding_no *= 2));\n    }\n  struct jitter_hash_binding *bi = b->bindings + (b->used_binding_no ++);\n  bi->key = key;\n  bi->value = value;\n}",
    "comment": "Adds a key-value pair to a jitter hash table, reallocating bucket space if necessary, while ensuring the table size increases when overfull.",
    "prorec_sum": "Inserts a key\u2013value pair into a hash table, allocating or expanding bucket arrays as needed based on load factor and bucket capacity.",
    "filter_prorec_sum": "Inserts a key\u2013value pair into a dynamically resized hash table, allocating and expanding bucket storage when necessary.",
    "prorec_aug_sum": "Inserts a key\u2013value pair into a hash table, allocating or expanding bucket storage when needed based on the hash of the key.",
    "filter_prorec_aug_sum": "Inserts a key\u2013value pair into a hash table, allocating or expanding per-bucket arrays when necessary based on the hash of the key.",
    "work_score": {
        "prorec": {
            "summary": "Inserts a key\u2013value pair into a hash table, allocating or expanding bucket arrays as needed based on load factor and bucket capacity.",
            "score": [
                0.9333333333333332,
                0.6666666666666666,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly describes inserting a key\u2013value pair and allocating or expanding bucket arrays as needed based on capacity. The source code confirms this behavior with logic to allocate a new bucket if NULL and reallocate its bindings when capacity is reached. However, the mention of 'based on load factor' is only partially accurate; the code checks if the table is overfull and enlarges it, but 'load factor' terminology is not explicitly evidenced. This is a minor unverifiable assumption, with most details grounded in the code.",
                "The summary correctly identifies insertion of a key\u2013value pair into a hash table and the allocation or expansion of bucket arrays when needed. The load factor condition is accurately implied by checking for overfull tables before enlarging them, and capacity checks trigger bucket expansion. However, the summary omits several key details present in the source code, such as incrementing the binding count, specific bucket index calculation using the hash function, and the distinction between table enlargement and bucket reallocation. These omissions mean the accurate details cover the main action but miss significant parts of the logic.",
                "The summary correctly states that the function inserts a key\u2013value pair and allocates or expands bucket arrays as needed based on capacity, which is explicitly supported by the use of jitter_xmalloc and jitter_xrealloc. However, the mention of 'load factor' is inaccurate, as the source code uses a specific check via jitter_hash_table_overfull rather than calculating a generic load factor. With only one inaccuracy and most details accurate but fairly generic, the content provides moderate domain value."
            ]
        },
        "filter_prorec": {
            "summary": "Inserts a key\u2013value pair into a dynamically resized hash table, allocating and expanding bucket storage when necessary.",
            "score": [
                1.0,
                0.8000000000000002,
                0.7333333333333334
            ],
            "reason": [
                "The summary correctly states that the function inserts a key\u2013value pair into a hash table and that the table and bucket storage are allocated and expanded as necessary. This matches the code, which inserts the key and value into a bucket, enlarges the entire table if it is overfull, and reallocates bucket storage when full. All semantic details from the summary are explicitly supported by the source code, with no extra unverified assumptions.",
                "The summary accurately captures the core function of adding a key\u2013value pair to the hash table and the dynamic resizing behavior\u2014both table enlargement when overfull and bucket expansion when full. These details directly match the source code's logic flow, including bucket allocation when NULL and reallocation on capacity limits. While it omits specifics like computing the bucket index or incrementing binding counts, it still represents the main action and both resize mechanisms.",
                "The summary correctly notes that the function inserts a key\u2013value pair into a hash table and that the table and buckets are dynamically resized or allocated when necessary. These details are explicitly present in the source code: the function increments binding counts, calculates a bucket index from a hash, allocates a new bucket if NULL, and doubles allocation when the bucket is full. All details are accurate and provide a succinct but meaningful description of the core logic."
            ]
        }
    }
}
{
    "source_code": "\n\nvoid generate_file_priorities(struct dir_info *dir, int priority,\n\tstruct stat *buf)\n{\n\tstruct dir_ent *dir_ent = dir->list;\n\n\tpriority = get_priority(dir->pathname, buf, priority);\n\n\tfor(; dir_ent; dir_ent = dir_ent->next) {\n\t\tstruct stat *buf = &dir_ent->inode->buf;\n\t\tif(dir_ent->inode->root_entry)\n\t\t\tcontinue;\n\n\t\tswitch(buf->st_mode & S_IFMT) {\n\t\t\tcase S_IFREG:\n\t\t\t\tadd_priority_list(dir_ent,\n\t\t\t\t\tget_priority(pathname(dir_ent), buf,\n\t\t\t\t\tpriority));\n\t\t\t\tbreak;\n\t\t\tcase S_IFDIR:\n\t\t\t\tgenerate_file_priorities(dir_ent->dir,\n\t\t\t\t\tpriority, buf);\n\t\t\t\tbreak;\n\t\t}\n\t}\n}",
    "comment": "Recursively assigns priority values to regular files and directories within a specified directory structure based on their pathnames and inode information.",
    "prorec_sum": "Traverses a linked list and hash table to match identifiers, invoking recursive or helper functions based on node type and updating with resolved values.",
    "filter_prorec_sum": "Recursively traverses a linked structure, matching entries via a lookup table, and invokes operations based on specific type flags.",
    "prorec_aug_sum": "Recursively traverses a linked structure to match entries in a global lookup table and process nodes based on type-specific conditions.",
    "filter_prorec_aug_sum": "Traverses hierarchical objects and uses an ID lookup table to propagate or update state values through child nodes matching specific type and identifier criteria.",
    "work_score": {
        "prorec": {
            "summary": "Traverses a linked list and hash table to match identifiers, invoking recursive or helper functions based on node type and updating with resolved values.",
            "score": [
                0.26666666666666666,
                0.20000000000000004,
                0.0
            ],
            "reason": [
                "The summary claims the code traverses both a linked list and a hash table to match identifiers, which is inaccurate because the source code only shows traversal of a linked list via `dir_ent = dir_ent->next` without any hash table operations or identifier matching logic. While the recursive call to `generate_file_priorities` based on node type is an accurate reflection of the `S_IFDIR` case, most other details \u2014 including hash table usage and updating with resolved values \u2014 are not supported by the provided source code. The majority of claims lack explicit evidence, resulting in a low accuracy ratio.",
                "The summary claims traversal of both a linked list and a hash table with identifier matching, which is inaccurate because the source code only traverses a linked list of directory entries and does not show any hash table operations or identifier matching logic. The summary omits accurate details such as the use of get_priority to compute priorities, conditional checks for root entries, handling of file and directory types via a switch statement, and recursive calls for subdirectories. After discarding the inaccurate parts, very little of the code\u2019s actual logic is covered.",
                "The summary claims traversal of both a linked list and a hash table with identifier matching, but the source code only shows traversal of a linked list via `dir_ent` pointers. There is no hash table or identifier matching logic present, making these details inaccurate. The only accurate part is invoking recursive or helper functions based on node type (`S_IFREG` calls `add_priority_list`, `S_IFDIR` calls `generate_file_priorities`). Since more than half the details are inaccurate, the evaluation stops at the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Recursively traverses a linked structure, matching entries via a lookup table, and invokes operations based on specific type flags.",
            "score": [
                0.4333333333333333,
                0.5666666666666668,
                0.0
            ],
            "reason": [
                "The summary correctly notes recursive traversal over a linked structure, as the function iterates over dir_ent linked list and recurses into subdirectories. However, it inaccurately claims use of a lookup table, which is not evidenced in the code, and does not precisely match invoking operations based on 'specific type flags'\u2014instead it uses a switch on file type macros from st_mode. These extra claims are not explicitly supported, leading to mixed accuracy.",
                "The summary's claim about matching entries via a lookup table is not supported by the source code, making it inaccurate. The code does recursively traverse a linked structure and invokes operations based on type flags (S_IFREG and S_IFDIR), which are accurate details. However, with the lookup table detail discarded, the remaining accurate points only partly cover the main logic, missing specifics like the use of get_priority and add_priority_list for data manipulation.",
                "The summary claims the code matches entries via a lookup table, which has no evidence in the source; this is inaccurate. It also omits mention of key functions present such as get_priority and add_priority_list, and misrepresents the decision logic solely as type flags in a generic sense. While it correctly notes recursive traversal of a linked structure with type-based branching, over half of the details are inaccurate or unsupported, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "void ZSTDMT_compressChunk(void* jobDescription)\n{\n    ZSTDMT_jobDescription* const job = (ZSTDMT_jobDescription*)jobDescription;\n    const void* const src = (const char*)job->srcStart + job->dictSize;\n    buffer_t const dstBuff = job->dstBuff;\n    DEBUGLOG(3, \"job (first:%u) (last:%u) : dictSize %u, srcSize %u\", job->firstChunk, job->lastChunk, (U32)job->dictSize, (U32)job->srcSize);\n    if (job->cdict) {\n        size_t const initError = ZSTD_compressBegin_usingCDict(job->cctx, job->cdict, job->fullFrameSize);\n        if (job->cdict) DEBUGLOG(3, \"using CDict \");\n        if (ZSTD_isError(initError)) { job->cSize = initError; goto _endJob; }\n    } else {\n        size_t const initError = ZSTD_compressBegin_advanced(job->cctx, job->srcStart, job->dictSize, job->params, job->fullFrameSize);\n        if (ZSTD_isError(initError)) { job->cSize = initError; goto _endJob; }\n        ZSTD_setCCtxParameter(job->cctx, ZSTD_p_forceWindow, 1);\n    }\n    if (!job->firstChunk) {  /* flush frame header */\n        size_t const hSize = ZSTD_compressContinue(job->cctx, dstBuff.start, dstBuff.size, src, 0);\n        if (ZSTD_isError(hSize)) { job->cSize = hSize; goto _endJob; }\n        ZSTD_invalidateRepCodes(job->cctx);\n    }\n\n    DEBUGLOG(4, \"Compressing : \");\n    DEBUG_PRINTHEX(4, job->srcStart, 12);\n    job->cSize = (job->lastChunk) ?   /* last chunk signal */\n                 ZSTD_compressEnd     (job->cctx, dstBuff.start, dstBuff.size, src, job->srcSize) :\n                 ZSTD_compressContinue(job->cctx, dstBuff.start, dstBuff.size, src, job->srcSize);\n    DEBUGLOG(3, \"compressed %u bytes into %u bytes   (first:%u) (last:%u)\", (unsigned)job->srcSize, (unsigned)job->cSize, job->firstChunk, job->lastChunk);\n\n_endJob:\n    PTHREAD_MUTEX_LOCK(job->jobCompleted_mutex);\n    job->jobCompleted = 1;\n    job->jobScanned = 0;\n    pthread_cond_signal(job->jobCompleted_cond);\n    pthread_mutex_unlock(job->jobCompleted_mutex);\n}",
    "comment": "Compresses data chunks using a context or dictionary, managing the compression state and signaling job completion through condition variables.",
    "prorec_sum": "Initializes or opens a database tree cursor using provided parameters, selecting appropriate creation or opening routines, and updates internal state to active.",
    "filter_prorec_sum": "Initializes or opens a B-tree cursor based on provided parameters, using alternate creation paths, and marks the cursor as active.",
    "prorec_aug_sum": "Creates or retrieves a resource handle from parameters, with alternative initialization paths, and stores it in the context structure before marking completion.",
    "filter_prorec_aug_sum": "Creates or reuses an internal resource handle based on stored state, falling back to alternate creation paths, and updates object flags and references.",
    "work_score": {
        "prorec": {
            "summary": "Initializes or opens a database tree cursor using provided parameters, selecting appropriate creation or opening routines, and updates internal state to active.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes initializing or opening a database tree cursor and updating its state, which has no explicit evidence in the source code. The source code is entirely focused on compression of data chunks using ZSTD functions, mutex locking, and condition signaling, with no mention of databases, cursors, or related routines. All details in the summary are hallucinations, resulting in no accurate matches.",
                "The summary is entirely inaccurate, describing database tree cursor initialization and state activation, which has no correspondence in the source code. The actual code handles multi-threaded compression via ZSTD, including initialization with or without a compression dictionary, error handling, and signaling job completion. No semantic elements from the summary match the source code, leaving no accurate details after filtering.",
                "The summary's details about initializing or opening a database tree cursor, choosing creation/opening routines, and updating state to active are entirely unsupported by the source code. The source code instead implements a compression function for chunks using ZSTD, with no database operations or cursor logic. All semantic details in the summary are inaccurate, exceeding the 50% inaccuracy threshold, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes or opens a B-tree cursor based on provided parameters, using alternate creation paths, and marks the cursor as active.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes B-tree cursor initialization, alternate creation paths, and marking the cursor as active, none of which are present in the source code. The source code deals exclusively with chunk compression logic for ZSTDMT, handling CDict usage, compression continuation and completion, debug logging, and thread synchronization. All summary details are hallucinations, with no explicit evidence in the code.",
                "The summary's claims about initializing or opening a B-tree cursor and marking it as active are entirely inaccurate, as the source code deals with compressing data chunks using ZSTD, handling dictionaries, managing compression contexts, and signaling job completion via mutex and condition variables. No elements of the summary align with the actual code's logic, parameters, or data structures.",
                "The summary claims operations related to initializing or opening a B-tree cursor, alternate creation paths, and marking the cursor as active. None of these details are present in the source code, which instead deals with compressing data chunks using Zstandard functions, handling contexts, dictionaries, buffer sizes, and thread synchronization primitives. All summary details are inaccurate, triggering the kill switch due to more than 50% inaccuracy."
            ]
        }
    }
}
{
    "source_code": "\nSEXP attribute_hidden do_Rhome(SEXP call, SEXP op, SEXP args, SEXP rho)\n{\n    char *path;\n    checkArity(op, args);\n    if (!(path = R_HomeDir()))\n\terror(_(\"unable to determine R home location\"));\n    return mkString(path);\n}",
    "comment": "Returns the R home directory path as a string after verifying the function's arity and checking if the path can be determined.",
    "prorec_sum": "Allocates an R string vector containing the home directory path, raising an error if the R home location cannot be determined.",
    "filter_prorec_sum": "Returns a STRSXP vector containing the R home directory path, raising an error if the home location cannot be determined.",
    "prorec_aug_sum": "Creates an R character vector containing the R home directory path, handling errors and using the R protection stack for memory safety.",
    "filter_prorec_aug_sum": "Creates a single-element character vector containing the R home directory path, allocating and protecting it, and errors if the path cannot be determined.",
    "work_score": {
        "prorec": {
            "summary": "Allocates an R string vector containing the home directory path, raising an error if the R home location cannot be determined.",
            "score": [
                1.0,
                0.7333333333333334,
                0.9
            ],
            "reason": [
                "The summary correctly describes that the function returns an R string containing the home directory path, and that it raises an error if the R home location cannot be determined. Both claims are explicitly supported by mkString(path) and the error call after checking R_HomeDir() in the source code. No unverified or hallucinated details are present, yielding a perfect accuracy ratio.",
                "The summary correctly states that the function returns an R string containing the home directory path and raises an error if the R home cannot be determined, both of which are explicitly in the code via mkString(path) and the error() call after a failed R_HomeDir(). However, it omits mention of the checkArity() validation, leaving out a notable control flow step; still, the main functionality is fully covered.",
                "The summary accurately describes that the function returns an R string containing the home directory path using mkString(path) and raises an error if R_HomeDir() fails, both of which are explicitly present in the source code. These are specific and domain-relevant details directly supported by the function's logic, providing clear insight into its purpose and behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Returns a STRSXP vector containing the R home directory path, raising an error if the home location cannot be determined.",
            "score": [
                0.7666666666666666,
                0.7333333333333334,
                0.8666666666666667
            ],
            "reason": [
                "The summary correctly states that the function returns the R home directory path and raises an error if it can't be determined, which is explicitly shown via `R_HomeDir()` and `error(...)`. However, it inaccurately specifies that the return type is a STRSXP vector; while `mkString(path)` does return a STRSXP, the summary's term 'vector' is unverified from the source code context. Thus, most but not all details are accurate, leading to a mixed accuracy assessment.",
                "The summary correctly states that the function returns the R home directory path and raises an error if it cannot be determined, matching the use of R_HomeDir(), error(), and mkString() in the source code. However, it inaccurately claims the return type as STRSXP, which is not explicitly shown; mkString returns a SEXP without specifying the STRSXP symbol in the code. The accurate details cover the main action and error handling but omit the argument arity check, so the full logic is not captured.",
                "The summary correctly states that the function returns an R string vector containing the R home directory path and raises an error if it cannot be determined, both of which are explicitly shown in the source code via mkString(path) and the error call. These details are accurate, specific, and domain-relevant, with no inaccuracies present."
            ]
        }
    }
}
{
    "source_code": "int snd_hda_mixer_amp_volume_get(struct snd_kcontrol *kcontrol,\n\t\t\t\t struct snd_ctl_elem_value *ucontrol)\n{\n\tstruct hda_codec *codec = snd_kcontrol_chip(kcontrol);\n\thda_nid_t nid = get_amp_nid(kcontrol);\n\tint chs = get_amp_channels(kcontrol);\n\tint dir = get_amp_direction(kcontrol);\n\tint idx = get_amp_index(kcontrol);\n\tunsigned int ofs = get_amp_offset(kcontrol);\n\tlong *valp = ucontrol->value.integer.value;\n\n\tif (chs & 1)\n\t\t*valp++ = read_amp_value(codec, nid, 0, dir, idx, ofs);\n\tif (chs & 2)\n\t\t*valp = read_amp_value(codec, nid, 1, dir, idx, ofs);\n\treturn 0;\n}",
    "comment": "Retrieves and stores the volume values for specified audio channels from a sound codec's amplifier settings into the provided control element structure.",
    "prorec_sum": "Computes adjusted values from hardware register bits via sub_FFFFFFFF81593DC0 and stores them to specific offsets in the provided output structure.",
    "filter_prorec_sum": "Computes adjusted 7\u2011bit values from input parameters and stores them into specified offsets based on bitfield conditions in the control word.",
    "prorec_aug_sum": "Computes adjusted values from codec register fields using sub_FFFFFFFF81593DC0 and stores results into specific offsets of the provided output structure.",
    "filter_prorec_aug_sum": "Computes adjusted 7\u2011bit values from codec register data using sub_FFFFFFFF81593DC0 and stores them into specified offsets of the target structure.",
    "work_score": {
        "prorec": {
            "summary": "Computes adjusted values from hardware register bits via sub_FFFFFFFF81593DC0 and stores them to specific offsets in the provided output structure.",
            "score": [
                0.06666666666666667,
                0.09999999999999999,
                0.0
            ],
            "reason": [
                "The summary mentions computing adjusted values from hardware register bits via a specific function named sub_FFFFFFFF81593DC0 and storing them at specific offsets, but there is no evidence of such a function or register bit manipulation in the source code. The code instead uses read_amp_value and various get_amp_* helper functions to fetch volume values into ucontrol->value.integer.value. All key details in the summary are unsupported, making the description entirely inaccurate.",
                "The summary's claim about computing 'adjusted values from hardware register bits' via a function 'sub_FFFFFFFF81593DC0' is not supported by the source code, which instead calls 'read_amp_value' with parameters derived from helper functions. There is no mention of bit-level adjustments or the named subroutine, making these statements hallucinations. After removing inaccuracies, no accurate semantic details remain, so the core logic of retrieving and storing channel-specific amp values from the codec is missing.",
                "The summary claims computation of adjusted values from hardware register bits via a function named sub_FFFFFFFF81593DC0 and mentions storing them to specific offsets. These details are inaccurate: the source code uses read_amp_value, not sub_FFFFFFFF81593DC0, and it does not reference hardware register bit manipulation explicitly. While the code does write values into the output structure (ucontrol->value.integer.value), most of the summary\u2019s technical details are unsupported by the source, resulting in more than half of the claims being inaccurate."
            ]
        },
        "filter_prorec": {
            "summary": "Computes adjusted 7\u2011bit values from input parameters and stores them into specified offsets based on bitfield conditions in the control word.",
            "score": [
                0.06666666666666667,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims that the function computes adjusted 7\u2011bit values and uses bitfield conditions from a control word, but there is no explicit evidence of 7\u2011bit value computation or bitfield manipulation in the source code. The source code reads amplifier values directly via read_amp_value calls based on channel flags, not bitfields in a control word, and no adjustment or specific 7\u2011bit operations are present. All semantic details in the summary are unsupported, resulting in a low accuracy ratio.",
                "The summary claims computation of adjusted 7\u2011bit values and use of bitfield conditions in a control word, but the source code shows direct retrieval of amplifier values via read_amp_value for specific channels determined by chs bits, with no evidence of 7\u2011bit adjustment or control word bitfield manipulation. All details in the summary are unsupported and thus inaccurate, leaving no valid content after filtering.",
                "The summary claims the function computes adjusted 7-bit values and uses bitfield conditions in a control word, but the source code does not reference any 7-bit computation or a control word. Instead, it retrieves parameters like nid, channels, direction, index, and offset, then reads amp values based on channel bitmask. These discrepancies mean the majority of details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic struct demangle_component *\nd_make_comp (struct d_info *di, enum demangle_component_type type,\n             struct demangle_component *left,\n             struct demangle_component *right)\n{\n  struct demangle_component *p;\n\n  /* We check for errors here.  A typical error would be a NULL return\n     from a subroutine.  We catch those here, and return NULL\n     upward.  */\n  switch (type)\n    {\n      /* These types require two parameters.  */\n    case DEMANGLE_COMPONENT_QUAL_NAME:\n    case DEMANGLE_COMPONENT_LOCAL_NAME:\n    case DEMANGLE_COMPONENT_TYPED_NAME:\n    case DEMANGLE_COMPONENT_TAGGED_NAME:\n    case DEMANGLE_COMPONENT_TEMPLATE:\n    case DEMANGLE_COMPONENT_CONSTRUCTION_VTABLE:\n    case DEMANGLE_COMPONENT_VENDOR_TYPE_QUAL:\n    case DEMANGLE_COMPONENT_PTRMEM_TYPE:\n    case DEMANGLE_COMPONENT_UNARY:\n    case DEMANGLE_COMPONENT_BINARY:\n    case DEMANGLE_COMPONENT_BINARY_ARGS:\n    case DEMANGLE_COMPONENT_TRINARY:\n    case DEMANGLE_COMPONENT_TRINARY_ARG1:\n    case DEMANGLE_COMPONENT_LITERAL:\n    case DEMANGLE_COMPONENT_LITERAL_NEG:\n    case DEMANGLE_COMPONENT_COMPOUND_NAME:\n    case DEMANGLE_COMPONENT_VECTOR_TYPE:\n    case DEMANGLE_COMPONENT_CLONE:\n      if (left == NULL || right == NULL)\n\treturn NULL;\n      break;\n\n      /* These types only require one parameter.  */\n    case DEMANGLE_COMPONENT_VTABLE:\n    case DEMANGLE_COMPONENT_VTT:\n    case DEMANGLE_COMPONENT_TYPEINFO:\n    case DEMANGLE_COMPONENT_TYPEINFO_NAME:\n    case DEMANGLE_COMPONENT_TYPEINFO_FN:\n    case DEMANGLE_COMPONENT_THUNK:\n    case DEMANGLE_COMPONENT_VIRTUAL_THUNK:\n    case DEMANGLE_COMPONENT_COVARIANT_THUNK:\n    case DEMANGLE_COMPONENT_JAVA_CLASS:\n    case DEMANGLE_COMPONENT_GUARD:\n    case DEMANGLE_COMPONENT_TLS_INIT:\n    case DEMANGLE_COMPONENT_TLS_WRAPPER:\n    case DEMANGLE_COMPONENT_REFTEMP:\n    case DEMANGLE_COMPONENT_HIDDEN_ALIAS:\n    case DEMANGLE_COMPONENT_TRANSACTION_CLONE:\n    case DEMANGLE_COMPONENT_NONTRANSACTION_CLONE:\n    case DEMANGLE_COMPONENT_POINTER:\n    case DEMANGLE_COMPONENT_REFERENCE:\n    case DEMANGLE_COMPONENT_RVALUE_REFERENCE:\n    case DEMANGLE_COMPONENT_COMPLEX:\n    case DEMANGLE_COMPONENT_IMAGINARY:\n    case DEMANGLE_COMPONENT_VENDOR_TYPE:\n    case DEMANGLE_COMPONENT_CAST:\n    case DEMANGLE_COMPONENT_CONVERSION:\n    case DEMANGLE_COMPONENT_JAVA_RESOURCE:\n    case DEMANGLE_COMPONENT_DECLTYPE:\n    case DEMANGLE_COMPONENT_PACK_EXPANSION:\n    case DEMANGLE_COMPONENT_GLOBAL_CONSTRUCTORS:\n    case DEMANGLE_COMPONENT_GLOBAL_DESTRUCTORS:\n    case DEMANGLE_COMPONENT_NULLARY:\n    case DEMANGLE_COMPONENT_TRINARY_ARG2:\n      if (left == NULL)\n\treturn NULL;\n      break;\n\n      /* This needs a right parameter, but the left parameter can be\n\t empty.  */\n    case DEMANGLE_COMPONENT_ARRAY_TYPE:\n    case DEMANGLE_COMPONENT_INITIALIZER_LIST:\n      if (right == NULL)\n\treturn NULL;\n      break;\n\n      /* These are allowed to have no parameters--in some cases they\n\t will be filled in later.  */\n    case DEMANGLE_COMPONENT_FUNCTION_TYPE:\n    case DEMANGLE_COMPONENT_RESTRICT:\n    case DEMANGLE_COMPONENT_VOLATILE:\n    case DEMANGLE_COMPONENT_CONST:\n    case DEMANGLE_COMPONENT_ARGLIST:\n    case DEMANGLE_COMPONENT_TEMPLATE_ARGLIST:\n    FNQUAL_COMPONENT_CASE:\n      break;\n\n      /* Other types should not be seen here.  */\n    default:\n      return NULL;\n    }\n\n  p = d_make_empty (di);\n  if (p != NULL)\n    {\n      p->type = type;\n      p->u.s_binary.left = left;\n      p->u.s_binary.right = right;\n    }\n  return p;\n}",
    "comment": "Constructs a demangle component by validating parameters based on type and initializing its properties, returning NULL for errors or invalid types.",
    "prorec_sum": "Adds an entry with given type and parameters to an internal list if it passes specific type-based and null-check conditions.",
    "filter_prorec_sum": "Adds an entry with specified type and parameters to a bounded list if validation rules on a3 and a4 are satisfied.",
    "prorec_aug_sum": "Adds an entry with given type and parameters to a bounded list at offset 32 if specific type codes and nonzero arguments meet conditions.",
    "filter_prorec_aug_sum": "Appends a new entry with given type and associated data to a bounded array if switch case and non\u2011null argument conditions are satisfied.",
    "work_score": {
        "prorec": {
            "summary": "Adds an entry with given type and parameters to an internal list if it passes specific type-based and null-check conditions.",
            "score": [
                0.7999999999999999,
                0.4333333333333333,
                0.0
            ],
            "reason": [
                "The summary accurately reflects the function's core behavior of creating a component entry only after passing type-based and null-check conditions. The source code shows multiple switch cases that impose specific null checks on parameters based on the type, followed by allocation via d_make_empty and assignment of type and parameters. While the term 'internal list' is somewhat vague and not explicitly evidenced in the code (it operates on a single struct, not a list), the central logic description is correct, making most details accurate with only one minor unverifiable assumption.",
                "The summary captures the conditional logic based on type and null-checks before creating a new component, which aligns with the source code's type-specific parameter validation and subsequent allocation via d_make_empty. However, it inaccurately describes this as adding to an 'internal list', which is not evidenced in the code; the function returns a constructed struct rather than performing list insertion. This misstatement removes completeness of the logic representation, though core action is partially covered.",
                "The summary is inaccurate because the source code does not add entries to an internal list; it constructs and returns a 'demangle_component' struct. While the null-check conditions based on type are correctly mentioned, the core action described in the summary does not match the code's logic, making over 50% of the details incorrect."
            ]
        },
        "filter_prorec": {
            "summary": "Adds an entry with specified type and parameters to a bounded list if validation rules on a3 and a4 are satisfied.",
            "score": [
                0.06666666666666667,
                0.06666666666666667,
                0.0
            ],
            "reason": [
                "The summary is inaccurate because the source code does not involve adding entries to a bounded list, nor does it reference parameters named a3 or a4. Instead, the function creates and returns a demangle_component after validating 'left' and 'right' pointers based on the component type. The described bounded list behavior and parameter names are unsupported by the explicit evidence in the source code, making all claimed details hallucinations.",
                "The summary is inaccurate because the source code does not manipulate or add to a 'bounded list'; instead, it creates and returns a 'demangle_component' structure after validating its 'left' and 'right' parameters based on the component type. References to 'a3' and 'a4' do not match the actual parameter naming or logic in the code, and the core logic of type-based parameter validation and structure creation is entirely missing.",
                "The summary claims the function adds an entry to a bounded list, referencing parameters a3 and a4, but the source code does not indicate any bounded list or such parameter names. The actual code constructs a demangle_component object using 'left' and 'right' after type-specific validation, with no mention of a bounded list or variables a3/a4. This means all described details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "static enum mu_filter_result\n_c_escape_decoder (void *xd MU_ARG_UNUSED,\n\t\t   enum mu_filter_command cmd,\n\t\t   struct mu_filter_io *iobuf)\n{\n  size_t i, j;\n  const unsigned char *iptr;\n  size_t isize;\n  char *optr;\n  size_t osize;\n  \n  switch (cmd)\n    {\n    case mu_filter_init:\n    case mu_filter_done:\n      return mu_filter_ok;\n    default:\n      break;\n    }\n  \n  iptr = (const unsigned char *) iobuf->input;\n  isize = iobuf->isize;\n  optr = iobuf->output;\n  osize = iobuf->osize;\n\n  for (i = j = 0; i < isize && j < osize; i++)\n    {\n      unsigned char c = *iptr++;\n      if (c == '\\\\')\n\t{\n\t  int x;\n\t  if (i + 1 == isize)\n\t    break;\n\t  c = *iptr++;\n\t  i++;\n\t  x = mu_wordsplit_c_unquote_char (c);\n\t  optr[j++] = (x == -1) ? c : x;\n\t}\n      else\n\toptr[j++] = c;\n    }\n\n  iobuf->isize = i;\n  iobuf->osize = j;\n  return mu_filter_ok;\n}",
    "comment": "Decodes escape sequences in the input buffer by replacing backslash-prefixed characters with their unquoted equivalents, storing results in the output buffer.",
    "prorec_sum": "Processes an input byte stream, interpreting backslash escape sequences via mu_wordsplit_c_unquote_char, and writes the resulting unescaped bytes to the output buffer.",
    "filter_prorec_sum": "Processes an input byte stream, interpreting backslash escape sequences into corresponding characters and storing the result in an output buffer with updated counters.",
    "prorec_aug_sum": "Processes an input byte stream, decoding backslash-escaped sequences into their unquoted characters and writing the results to an output buffer.",
    "filter_prorec_aug_sum": "Processes an input byte stream, copying to output while interpreting backslash escape sequences via `mu_wordsplit_c_unquote_char` and updating consumed and produced byte counts.",
    "work_score": {
        "prorec": {
            "summary": "Processes an input byte stream, interpreting backslash escape sequences via mu_wordsplit_c_unquote_char, and writes the resulting unescaped bytes to the output buffer.",
            "score": [
                1.0,
                0.6999999999999998,
                0.9
            ],
            "reason": [
                "The summary correctly identifies that the function processes an input byte stream, that it interprets backslash escape sequences, that it uses mu_wordsplit_c_unquote_char for interpreting those sequences, and that it writes the unescaped result to the output buffer. All these details are explicitly supported by the source code, and no unverified assumptions are present.",
                "The summary accurately describes the core logic: it processes an input byte stream, detects backslash escape sequences, uses mu_wordsplit_c_unquote_char for interpretation, and writes unescaped bytes to the output buffer. These details are explicitly evidenced in the source code via the input/output buffer handling, the backslash check, and the call to mu_wordsplit_c_unquote_char. However, the summary omits handling of filter commands such as mu_filter_init and mu_filter_done, and the updating of iobuf sizes at the end, which are also part of the code's logic.",
                "The summary correctly identifies that the function processes an input byte stream, interprets backslash escape sequences using mu_wordsplit_c_unquote_char, and writes the unescaped bytes to the output buffer. All these details are explicitly evident in the source code through variable assignments, loop logic, and function calls. No inaccurate elements were found, and the details are specific and domain-relevant, reflecting clear and precise alignment with the source."
            ]
        },
        "filter_prorec": {
            "summary": "Processes an input byte stream, interpreting backslash escape sequences into corresponding characters and storing the result in an output buffer with updated counters.",
            "score": [
                1.0,
                0.6999999999999998,
                0.6333333333333333
            ],
            "reason": [
                "The summary correctly states that the code processes an input byte stream, interprets backslash escape sequences into corresponding characters using a decoding function, and stores the result in an output buffer while updating the size counters. All described behaviors are explicitly reflected in the source code, with no unsupported claims or omissions affecting accuracy.",
                "The summary correctly describes the core logic of processing an input byte stream, detecting backslash escape sequences, converting them using a helper function, and writing the results to an output buffer while updating counters. These details are explicitly present in the source code, including the loop over input bytes, conditional backslash handling, use of `mu_wordsplit_c_unquote_char`, writing to `optr`, and updating `iobuf->isize` and `iobuf->osize`. The summary omits control flow aspects like handling of `mu_filter_init` and `mu_filter_done` commands, but it captures the main action accurately.",
                "The summary correctly captures the function's purpose: it processes an input byte stream, interprets backslash escape sequences with the help of a decoding function, writes to an output buffer, and updates the size counters. All these details are explicitly supported by the source code structure and variables. While accurate, the description is fairly high-level and lacks deeper domain-specific insights such as naming the specific helper function `mu_wordsplit_c_unquote_char`, the handling of `mu_filter_command` cases, or the early break condition when size limits are reached. This limits its value to a more generic level."
            ]
        }
    }
}
{
    "source_code": "int\nevutil_read_file_(const char *filename, char **content_out, size_t *len_out,\n    int is_binary)\n{\n\tint fd, r;\n\tstruct stat st;\n\tchar *mem;\n\tsize_t read_so_far=0;\n\tint mode = O_RDONLY;\n\n\tEVUTIL_ASSERT(content_out);\n\tEVUTIL_ASSERT(len_out);\n\t*content_out = NULL;\n\t*len_out = 0;\n\n#ifdef O_BINARY\n\tif (is_binary)\n\t\tmode |= O_BINARY;\n#endif\n\n\tfd = evutil_open_closeonexec_(filename, mode, 0);\n\tif (fd < 0)\n\t\treturn -1;\n\tif (fstat(fd, &st) || st.st_size < 0 ||\n\t    st.st_size > EV_SSIZE_MAX-1 ) {\n\t\tclose(fd);\n\t\treturn -2;\n\t}\n\tmem = mm_malloc((size_t)st.st_size + 1);\n\tif (!mem) {\n\t\tclose(fd);\n\t\treturn -2;\n\t}\n\tread_so_far = 0;\n#ifdef _WIN32\n#define N_TO_READ(x) ((x) > INT_MAX) ? INT_MAX : ((int)(x))\n#else\n#define N_TO_READ(x) (x)\n#endif\n\twhile ((r = read(fd, mem+read_so_far, N_TO_READ(st.st_size - read_so_far))) > 0) {\n\t\tread_so_far += r;\n\t\tif (read_so_far >= (size_t)st.st_size)\n\t\t\tbreak;\n\t\tEVUTIL_ASSERT(read_so_far < (size_t)st.st_size);\n\t}\n\tclose(fd);\n\tif (r < 0) {\n\t\tmm_free(mem);\n\t\treturn -2;\n\t}\n\tmem[read_so_far] = 0;\n\n\t*len_out = read_so_far;\n\t*content_out = mem;\n\treturn 0;\n}",
    "comment": "Reads the contents of a specified file into a dynamically allocated buffer, returning the length and handling binary mode if specified.",
    "prorec_sum": "Reads the entire contents of a specified file into a newly allocated buffer, returning its size and handling errors appropriately.",
    "filter_prorec_sum": "Reads an entire file into a newly allocated buffer, null-terminates it, and returns its size and pointer via output parameters.",
    "prorec_aug_sum": "Reads the entire contents of a file into a newly allocated buffer, null\u2011terminates it, and returns its size and pointer via output parameters.",
    "filter_prorec_aug_sum": "Reads the entire contents of a file into a newly allocated buffer, returning its size and handling errors and resource cleanup.",
    "work_score": {
        "prorec": {
            "summary": "Reads the entire contents of a specified file into a newly allocated buffer, returning its size and handling errors appropriately.",
            "score": [
                1.0,
                0.6666666666666666,
                0.7000000000000001
            ],
            "reason": [
                "The summary accurately describes the high-level behavior of the function: reading a specified file into a newly allocated buffer, returning the size, and handling errors. The source code explicitly allocates memory, reads the file fully, sets output pointers and size, and includes multiple error checks. No extraneous or hallucinated details are present, and all elements mentioned are supported by the code.",
                "The summary accurately describes the core function of the code: it reads the entire contents of a file into a newly allocated buffer, returns its size via an output parameter, and handles errors with various return codes. However, it omits some important implementation details from the source code such as handling binary mode flags, explicit assertions for output parameters, file size validation against EV_SSIZE_MAX, and special handling for Windows read limits. Still, the main action is captured correctly.",
                "The summary accurately reflects the main functionality of the code: opening a specified file, reading its entire contents into a newly allocated buffer, returning its size, and performing error handling. It does not introduce any details not supported by the source, but it is somewhat generic and lacks specific references to implementation aspects such as use of `EVUTIL_ASSERT`, `O_BINARY` handling, or the read loop mechanics. While correct, the accurate details are high-level rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Reads an entire file into a newly allocated buffer, null-terminates it, and returns its size and pointer via output parameters.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6333333333333333
            ],
            "reason": [
                "The summary accurately states that the function reads a file into a newly allocated buffer, null-terminates it, and returns its size and pointer via output parameters. All these details are directly supported by the source code: the file is read into 'mem', a null terminator is added, and '*len_out' and '*content_out' are set. There are no extraneous or hallucinated details.",
                "The summary accurately states that the function reads a file into a newly allocated buffer, null-terminates it, and returns its size and pointer via output parameters. This matches the code's logic: the function opens the file, allocates memory, reads its contents, null-terminates the buffer, and sets both the content and length via output parameters before returning. However, it omits error handling details, conditional binary mode handling, and the reading loop's edge case checks, so while the core action is covered, some significant logic is missing.",
                "The summary accurately describes the key functionality: the function reads a file entirely into a newly allocated buffer, null-terminates the buffer, and uses output parameters to return both the file size and the pointer. These behaviors are explicitly present in the source code via the read loop, null-termination, and assignments to *len_out and *content_out. The description is correct but generic, focusing on overall behavior without mentioning specifics like binary mode handling, error cases, or platform-dependent read size limits."
            ]
        }
    }
}
{
    "source_code": "\nstatic int disk_status(struct dm_dirty_log *log, status_type_t status,\n\t\t       char *result, unsigned int maxlen)\n{\n\tint sz = 0;\n\tstruct log_c *lc = log->context;\n\n\tswitch(status) {\n\tcase STATUSTYPE_INFO:\n\t\tDMEMIT(\"3 %s %s %c\", log->type->name, lc->log_dev->name,\n\t\t       lc->log_dev_flush_failed ? 'F' :\n\t\t       lc->log_dev_failed ? 'D' :\n\t\t       'A');\n\t\tbreak;\n\n\tcase STATUSTYPE_TABLE:\n\t\tDMEMIT(\"%s %u %s %u \", log->type->name,\n\t\t       lc->sync == DEFAULTSYNC ? 2 : 3, lc->log_dev->name,\n\t\t       lc->region_size);\n\t\tDMEMIT_SYNC;\n\t}\n\n\treturn sz;\n}",
    "comment": "Generates and emits status information for a dirty log based on the provided status type, including device name and synchronization details.",
    "prorec_sum": "Formats and writes mapping or sync-related status information into a buffer based on input parameters and fields from a provided context structure.",
    "filter_prorec_sum": "Formats and writes status information, including synchronization flags, into a provided buffer based on input mode and the state fields of a context structure.",
    "prorec_aug_sum": "Formats and writes connection-related status information into a buffer, optionally appending a sync state string based on internal flags.",
    "filter_prorec_aug_sum": "Formats connection-related information into a buffer using snprintf-like calls, including sync status or a type code depending on the mode parameter.",
    "work_score": {
        "prorec": {
            "summary": "Formats and writes mapping or sync-related status information into a buffer based on input parameters and fields from a provided context structure.",
            "score": [
                1.0,
                0.6,
                0.5666666666666667
            ],
            "reason": [
                "The summary accurately states that the function formats and writes status information into a buffer based on provided parameters and the context structure. The source code confirms it uses fields from 'log' and 'lc' to format strings via DMEMIT, influenced by the 'status' parameter. There are no extraneous or hallucinated details such as specific library references or unrelated logic steps, so all semantic details are directly supported by the source.",
                "The summary correctly identifies that the function formats and writes status information into a buffer using fields from a context structure, which is explicitly evidenced by the use of DMEMIT with log->type->name, lc->log_dev->name, and lc->region_size. However, the mention of 'mapping or sync-related' is only partially supported: while sync status is explicitly conveyed via lc->sync and DMEMIT_SYNC, there is no clear mapping logic in the source code. The accurate parts cover the main action but omit specifics such as the conditional formatting for failure states and the distinction between STATUSTYPE_INFO and STATUSTYPE_TABLE cases.",
                "The summary vaguely states that the function formats and writes status information based on parameters and a context structure, which is supported by the source code showing DMEMIT calls with context fields and formatting logic. However, it does not include specific domain-rich details from the source, such as the distinct handling of STATUSTYPE_INFO and STATUSTYPE_TABLE, the use of fields like log_dev_flush_failed, log_dev_failed, sync comparisons to DEFAULTSYNC, or region_size. All extracted details from the summary are accurate but generic, offering minimal insight into the actual implementation."
            ]
        },
        "filter_prorec": {
            "summary": "Formats and writes status information, including synchronization flags, into a provided buffer based on input mode and the state fields of a context structure.",
            "score": [
                1.0,
                0.6,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly identifies that the function formats and writes status information into a provided buffer, using the input mode (status) and fields from a context structure (lc). The presence of synchronization flags is also accurate, as the code uses lc->sync with DEFAULTSYNC to influence output. All mentioned details are directly evident in the code, with no unverified assumptions.",
                "The summary is generally accurate in describing that the function formats and writes status information into a buffer based on input mode and context state fields. Evidence in the source code shows conditional formatting via switch on status, use of lc->sync, and various flags like log_dev_flush_failed. However, the summary omits explicit mention of specific flags for device failure and the two distinct output formats for STATUSTYPE_INFO and STATUSTYPE_TABLE, which are critical semantic units in the code logic. The coverage is partial, capturing the main action but missing important details related to edge cases and exact field usage.",
                "The summary accurately describes that the function formats and writes status information into a buffer based on the mode (`status` parameter) and fields from a context structure (`lc`). This is explicitly supported by the use of `DMEMIT` to output information from `log->type->name`, `lc->log_dev->name`, and flags like `log_dev_flush_failed`, `log_dev_failed`, and `sync`. While the summary omits specific variable names and conditional outputs, the key claim about synchronization flags and conditional formatting is consistent with the source code. The accurate details are domain-relevant but somewhat generic."
            ]
        }
    }
}
{
    "source_code": "int\nrl_insert_text (const char *string)\n{\n  register int i, l;\n\n  l = (string && *string) ? strlen (string) : 0;\n  if (l == 0)\n    return 0;\n\n  if (rl_end + l >= rl_line_buffer_len)\n    rl_extend_line_buffer (rl_end + l);\n\n  for (i = rl_end; i >= rl_point; i--)\n    rl_line_buffer[i + l] = rl_line_buffer[i];\n\n  strncpy (rl_line_buffer + rl_point, string, l);\n\n  /* Remember how to undo this if we aren't undoing something. */\n  if (_rl_doing_an_undo == 0)\n    {\n      /* If possible and desirable, concatenate the undos. */\n      if ((l == 1) &&\n\t  rl_undo_list &&\n\t  (rl_undo_list->what == UNDO_INSERT) &&\n\t  (rl_undo_list->end == rl_point) &&\n\t  (rl_undo_list->end - rl_undo_list->start < 20))\n\trl_undo_list->end++;\n      else\n\trl_add_undo (UNDO_INSERT, rl_point, rl_point + l, (char *)NULL);\n    }\n  rl_point += l;\n  rl_end += l;\n  rl_line_buffer[rl_end] = '\\0';\n  return l;\n}",
    "comment": "Inserts a given string into a line buffer at a specified point, adjusting the buffer and managing undo operations accordingly.",
    "prorec_sum": "Inserts a given text into the readline buffer at the cursor position, shifting existing content and updating undo history and buffer state.",
    "filter_prorec_sum": "Inserts the given text into the readline buffer at the current cursor position, shifting existing content and updating undo history and buffer pointers.",
    "prorec_aug_sum": "Inserts the given text into the readline buffer at the cursor position, shifting existing content and updating undo history and buffer metadata.",
    "filter_prorec_aug_sum": "Inserts the given text into the readline buffer at the cursor position, shifting existing content and updating undo history and buffer metadata.",
    "work_score": {
        "prorec": {
            "summary": "Inserts a given text into the readline buffer at the cursor position, shifting existing content and updating undo history and buffer state.",
            "score": [
                1.0,
                0.6999999999999998,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly states that the function inserts text into the readline buffer at the current cursor (rl_point), shifts existing content to make space, updates the buffer state (rl_point, rl_end, and null terminator), and modifies undo history when appropriate. All these elements are explicitly shown in the source code, with no unverifiable or hallucinated claims.",
                "The summary accurately captures the core logic: inserting text into the readline buffer at the cursor, shifting content, updating undo history, and maintaining buffer state. All these elements are explicitly present in the source code via string length checks, buffer resizing, content shifting, strncpy insertion, undo handling, and cursor/end updates. However, it omits specific nuances such as conditional undo concatenation and buffer extension logic triggers, meaning it conveys the main workflow but not all edge case details.",
                "The summary correctly states that the function inserts text into the readline buffer at the cursor position, shifts existing content, and updates undo history and buffer state. All these details are explicitly supported by the source code via the insertion loop, undo history logic, and buffer adjustments. There are no inaccurate details, but the summary is somewhat generic, lacking mention of specific conditions and variables such as handling empty strings, buffer extension, or concatenation limits in undo actions."
            ]
        },
        "filter_prorec": {
            "summary": "Inserts the given text into the readline buffer at the current cursor position, shifting existing content and updating undo history and buffer pointers.",
            "score": [
                1.0,
                0.9,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function inserts text into the readline buffer at the current cursor position, shifts existing content, updates undo history, and adjusts buffer pointers. All these details are explicitly supported by the source code: insertion is done via strncpy, shifting via a for-loop, undo history management via rl_add_undo or modification of rl_undo_list, and pointer updates with rl_point and rl_end. No unverified assumptions or hallucinations are present.",
                "The summary is accurate: the function inserts text into the readline buffer at the cursor (rl_point), shifts existing content, updates undo history via rl_add_undo or by extending an existing undo entry, adjusts rl_point and rl_end, and maintains buffer termination. These points match explicit code elements, providing a complete picture of the logic including control flow and data manipulation.",
                "The summary accurately reflects the core behavior in the source code: inserting text into the readline buffer at the current cursor position, shifting existing content, updating undo history, and adjusting buffer pointers. All details are explicitly supported by the code (use of rl_point, rl_end, rl_line_buffer shifting, undo handling). The accurate details are domain-specific and informative."
            ]
        }
    }
}
{
    "source_code": "\nstatic int restore(struct ks *ks, char x[])\n{     int j, k, z;\n      z = ks->c0;\n      for (j = 1, k = 0; j <= ks->orig_n; j++)\n      {  if (ks->x[j] & 0x10)\n         {  k++;\n            xassert(k <= ks->n);\n            xassert(x[k] == 0 || x[k] == 1);\n            if (ks->x[j] & 1)\n               ks->x[j] = 1 - x[k];\n            else\n               ks->x[j] = x[k];\n            if (x[k])\n               z += ks->c[k];\n         }\n      }\n      xassert(k == ks->n);\n      return z;\n}",
    "comment": "Restores values in the `ks->x` array based on conditions and updates a sum `z` based on corresponding values from the `x` array.",
    "prorec_sum": "Processes flagged items in a structure, validates associated binary values, applies conditional inversion, updates total sum, and enforces consistency assertions.",
    "filter_prorec_sum": "Updates element flags and values in a structure based on binary inputs, enforcing constraints, and accumulates a weighted sum of selected entries.",
    "prorec_aug_sum": "Iterates over flagged items, validates binary values, conditionally inverts them, updates a keyed sum, and asserts expected processed count before returning the total.",
    "filter_prorec_aug_sum": "Processes flagged elements in a structure, validates binary values, conditionally inverts them, updates a count sum, and asserts expected element totals.",
    "work_score": {
        "prorec": {
            "summary": "Processes flagged items in a structure, validates associated binary values, applies conditional inversion, updates total sum, and enforces consistency assertions.",
            "score": [
                1.0,
                0.9,
                0.9
            ],
            "reason": [
                "The summary correctly reflects the actions in the source code: iterating over flagged items (ks->x[j] & 0x10), validating binary values via assertions, conditionally inverting values, updating a cumulative sum (z += ks->c[k]), and enforcing consistency with final assertions. All details are explicitly supported by the source logic, so no hallucinations are present.",
                "The summary accurately reflects the core logic of the source code: it processes flagged items via the `if (ks->x[j] & 0x10)` check, validates binary values through `xassert(x[k] == 0 || x[k] == 1)`, applies conditional inversion when `(ks->x[j] & 1)` is true, updates the total sum `z` if `x[k]` is set, and enforces consistency via assertions on `k`. These points correspond directly to explicit constructs in the code, and no details are hallucinated. The description captures the main actions and critical control flow without omitting key logic.",
                "The summary accurately reflects the logic in the source code: it correctly identifies processing flagged items (ks->x[j] & 0x10), binary value validation (x[k] == 0 || x[k] == 1 enforced via xassert), conditional inversion (ks->x[j] = 1 - x[k] when ks->x[j] & 1), updating a sum (z += ks->c[k] when x[k] is true), and consistency checks (xassert(k == ks->n)). All details are explicitly evidenced in the code, none are inaccurate, and the description is domain-specific and detailed."
            ]
        },
        "filter_prorec": {
            "summary": "Updates element flags and values in a structure based on binary inputs, enforcing constraints, and accumulates a weighted sum of selected entries.",
            "score": [
                1.0,
                0.8333333333333334,
                0.8000000000000002
            ],
            "reason": [
                "The summary correctly captures that the function updates elements in a structure based on binary inputs, enforces constraints via assertions, and accumulates a sum influenced by selected entries, aligning with the loop logic, bitmask checks, and `z` accumulation in the source code. All semantic elements described are explicitly verifiable in the source code, with no unsubstantiated assumptions.",
                "The summary correctly captures that the function updates fields in a structure based on binary input values, enforces constraints via assertions, and accumulates a sum using an array of weights when certain conditions are met. These behaviors match the explicit code logic involving bitmask checks, assignments, xassert validations, and summation. However, the summary omits key control flow specifics, such as the iteration over indices 1 to orig_n, the use of bitwise checks on ks->x[j], and the conditional inversion of values when a bit is set. This limits completeness despite overall accuracy.",
                "The summary correctly captures that the function updates values in a structure based on binary inputs, applies constraints, and accumulates a sum, all of which are evidenced by checks like `xassert(x[k] == 0 || x[k] == 1)` and conditional updates to `ks->x[j]` and `z`. However, the term 'element flags' is not explicitly supported by the code, and calling the sum 'weighted' is inaccurate since it simply adds `ks->c[k]` without variable weighting logic. Most core points are accurate and domain-specific, providing meaningful insight into the code's functionality."
            ]
        }
    }
}
{
    "source_code": "\nconst ProtobufCFieldDescriptor *\nprotobuf_c_message_descriptor_get_field_by_name(const ProtobufCMessageDescriptor *desc,\n\t\t\t\t\t\tconst char *name)\n{\n\tunsigned start = 0;\n\tunsigned count;\n\tconst ProtobufCFieldDescriptor *field;\n\n\tif (desc == NULL || desc->fields_sorted_by_name == NULL)\n\t\treturn NULL;\n\n\tcount = desc->n_fields;\n\n\twhile (count > 1) {\n\t\tunsigned mid = start + count / 2;\n\t\tint rv;\n\t\tfield = desc->fields + desc->fields_sorted_by_name[mid];\n\t\trv = strcmp(field->name, name);\n\t\tif (rv == 0)\n\t\t\treturn field;\n\t\telse if (rv < 0) {\n\t\t\tcount = start + count - (mid + 1);\n\t\t\tstart = mid + 1;\n\t\t} else\n\t\t\tcount = mid - start;\n\t}\n\tif (count == 0)\n\t\treturn NULL;\n\tfield = desc->fields + desc->fields_sorted_by_name[start];\n\tif (strcmp(field->name, name) == 0)\n\t\treturn field;\n\treturn NULL;\n}",
    "comment": "Retrieves the field descriptor with a matching name from a sorted list of fields in a ProtobufC message descriptor.",
    "prorec_sum": "Searches an index array with binary search to locate an entry whose computed key is zero and returns its associated structure pointer.",
    "filter_prorec_sum": "Performs a binary search in an index array to locate and return a related 72-byte record address, or zero if not found.",
    "prorec_aug_sum": "Searches an indexed table for an entry with a zero-valued key and returns its associated data pointer, or null if none is found.",
    "filter_prorec_aug_sum": "Performs a binary search over indexed entries in a structure, returning the matching element\u2019s address or zero if not found.",
    "work_score": {
        "prorec": {
            "summary": "Searches an index array with binary search to locate an entry whose computed key is zero and returns its associated structure pointer.",
            "score": [
                0.5,
                0.4000000000000001,
                0.0
            ],
            "reason": [
                "The summary claims that the function searches an index array with binary search for an entry whose computed key is zero, then returns its associated structure pointer. While the source code does perform a binary search on an index array (`fields_sorted_by_name`) and returns a `ProtobufCFieldDescriptor` pointer, there is no concept of a 'computed key' being zero; instead it compares field names using `strcmp`. Thus, the binary search detail is accurate, but the 'computed key is zero' is a hallucination. Given mixed accuracy and unverified assumptions about the key concept, the accuracy ratio is below full alignment.",
                "The summary incorrectly describes searching for an entry whose computed key is zero, which is not present in the source code. The code actually compares a field name with the provided name using strcmp within a binary search over fields_sorted_by_name. While 'binary search' over an index array and returning its associated structure pointer is accurate, the 'computed key is zero' detail is a hallucination. This omission and misstatement mean that most of the main logic\u2014string comparison for name matching\u2014is missing or distorted in the summary.",
                "The summary claims the function searches an index array using binary search for an entry whose computed key is zero, but the source code actually compares field->name to the input name using strcmp and returns the matching field descriptor. The 'computed key is zero' detail is inaccurate, as is the implication of an abstract key rather than a string comparison. Only the mention of binary search over an index array is accurate. With more than half of the details being inaccurate, the evaluation stops."
            ]
        },
        "filter_prorec": {
            "summary": "Performs a binary search in an index array to locate and return a related 72-byte record address, or zero if not found.",
            "score": [
                0.3333333333333333,
                0.39999999999999997,
                0.0
            ],
            "reason": [
                "The summary's claim about performing a binary search in an index array is accurate, as the code iterates with mid-point calculations over fields_sorted_by_name to locate a matching name. However, the mention of a '72-byte record address' is unsupported and cannot be verified in the source code. The return is a pointer to a ProtobufCFieldDescriptor, not necessarily 72 bytes, and 'zero if not found' is inaccurate since NULL is returned when not found. With only part of the summary aligning to the source, accuracy is below half.",
                "The summary's mention of a '72-byte record address' is unsupported by the source code, which only returns a pointer to a matching ProtobufCFieldDescriptor without any indication of record size. The claim of returning zero if not found is also inaccurate; the code returns NULL. The only accurate detail is that the function performs a binary search over an index array (fields_sorted_by_name) to find a matching field name. However, this alone does not form a complete picture of the code's logic, as key conditions, error handling, and termination cases are missing.",
                "The summary claims the function returns a 72-byte record address and uses an index array, but the source code shows it returns a pointer to a ProtobufCFieldDescriptor (not a fixed-size 72-byte record) and uses fields_sorted_by_name for binary search. While the binary search on an index array detail is accurate, most details (record size, returned data type description, zero vs NULL) are inaccurate, making over 50% of the claims incorrect."
            ]
        }
    }
}
{
    "source_code": "\nvoid\npkl_asm_for (pkl_asm pasm, pkl_ast_node head)\n{\n  pkl_asm_pushlevel (pasm, PKL_ASM_ENV_FOR_LOOP);\n\n  pasm->level->node1 = ASTREF (head);\n  pasm->level->label1 = pvm_program_fresh_label (pasm->program);\n  pasm->level->label2 = pvm_program_fresh_label (pasm->program);\n  pasm->level->label3 = pvm_program_fresh_label (pasm->program);\n  pasm->level->continue_label = pvm_program_fresh_label (pasm->program);\n  pasm->level->break_label = pvm_program_fresh_label (pasm->program);\n\n  if (head)\n    pkl_asm_insn (pasm, PKL_INSN_PUSHF, 0);\n}",
    "comment": "Initializes a for loop's environment in the assembly context, assigning labels and pushing the loop node if a valid head is provided.",
    "prorec_sum": "Initializes a data structure at a1+16 with values from sub_8A6E0 calls, links it to a2, and optionally triggers sub_81880.",
    "filter_prorec_sum": "Initializes a structure at a1+16 with values from sub_8A6E0 calls and associates it with a2 before optionally invoking sub_81880.",
    "prorec_aug_sum": "Initializes fields in a structure from repeated sub_8A6E0 results, links it to a2, and optionally invokes sub_81880 for further processing.",
    "filter_prorec_aug_sum": "Initializes a structure's fields with repeated sub_8A6E0 results, links it to a2, and optionally triggers sub_81880 when a2 is provided.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a data structure at a1+16 with values from sub_8A6E0 calls, links it to a2, and optionally triggers sub_81880.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes operations involving memory offsets (a1+16), functions sub_8A6E0 and sub_81880, and linkage to a2, none of which are present in the source code. The actual code defines a function pkl_asm_for that sets up loop labels using pvm_program_fresh_label, assigns an AST node reference, and conditionally pushes an instruction. All details in the summary are unsupported by any strings or logic in the source code, resulting in complete mismatch.",
                "The summary describes initialization at a specific memory offset and calls to functions sub_8A6E0 and sub_81880, none of which are present in the source code. The actual code creates a for-loop environment, assigns labels using pvm_program_fresh_label, and conditionally calls pkl_asm_insn. Since no details from the summary are supported by explicit evidence in the source code, all claims are inaccurate and the core logic is entirely missed.",
                "All details in the summary are inaccurate. The source code contains no references to memory offsets like a1+16, functions named sub_8A6E0 or sub_81880, or linking to variables named a2. Instead, it defines pkl_asm_for, which pushes a loop environment, stores AST node references, generates labels via pvm_program_fresh_label, and optionally calls pkl_asm_insn. Since 100% of the summary details do not exist in the code, the kill switch is triggered."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a structure at a1+16 with values from sub_8A6E0 calls and associates it with a2 before optionally invoking sub_81880.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes initialization at a specific memory offset (a1+16), calls to sub_8A6E0, association with a2, and optional invocation of sub_81880. None of these functions, variables, or memory operations are present in the source code, which instead involves pkl_asm_pushlevel, ASTREF, and pvm_program_fresh_label calls. All details in the summary are hallucinations, with no explicit evidence in the provided code.",
                "The summary details about initializing a structure at a1+16, using sub_8A6E0 calls, and associating with a2 before invoking sub_81880 have no explicit evidence in the source code. The source code instead shows function pkl_asm_for setting loop-related labels and optionally pushing a frame when head is present, without any of the functions or data structures mentioned in the summary. All semantic details in the summary are inaccurate, leaving no valid content after filtering.",
                "The summary's claims about initializing a structure at a1+16, using sub_8A6E0 calls, associating it with a2, and possibly invoking sub_81880 have no correspondence in the source code. The actual code is in C, defines pkl_asm_for, and calls functions like pkl_asm_pushlevel, ASTREF, pvm_program_fresh_label, and pkl_asm_insn. None of the functions or memory operations mentioned in the summary are present. All semantic details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "BITCODE_BL\ndwg_object_polyline_2d_get_numpoints (const dwg_object *restrict obj,\n                                      int *restrict error)\n{\n  if (obj && obj->type == DWG_TYPE_POLYLINE_2D)\n    {\n      BITCODE_BL num_points = 0;\n      Dwg_Data *dwg = obj->parent;\n      Dwg_Entity_POLYLINE_2D *_obj = obj->tio.entity->tio.POLYLINE_2D;\n      Dwg_Entity_VERTEX_2D *vertex;\n      *error = 0;\n\n      if (dwg->header.version >= R_2004)\n        return obj->tio.entity->tio.POLYLINE_2D->num_owned;\n      // iterate over first_vertex - last_vertex\n      else if (dwg->header.version >= R_13)\n        {\n          Dwg_Object *vobj = dwg_ref_object (dwg, _obj->first_vertex);\n          Dwg_Object *vlast = dwg_ref_object (dwg, _obj->last_vertex);\n          if (!vobj)\n            *error = 1;\n          else\n            {\n              do\n                {\n                  if ((vertex = dwg_object_to_VERTEX_2D (vobj)))\n                    {\n                      num_points++;\n                    }\n                  else\n                    {\n                      *error = 1; // return not all vertices, but some\n                    }\n                }\n              while ((vobj = dwg_next_object (vobj)) && vobj != vlast);\n            }\n        }\n      else // <r13: iterate over vertices until seqend\n        {\n          Dwg_Object *vobj;\n          while ((vobj = dwg_next_object (obj))\n                 && vobj->type != DWG_TYPE_SEQEND)\n            {\n              if ((vertex = dwg_object_to_VERTEX_2D (vobj)))\n                num_points++;\n              else\n                *error = 1; // return not all vertices, but some\n            }\n        }\n      return num_points;\n    }\n  else\n    {\n      LOG_ERROR (\"%s: empty or wrong arg\", __FUNCTION__)\n      *error = 1;\n      return 0L;\n    }\n}",
    "comment": "Counts the number of 2D vertices in a polyline object based on DWG version and returns the count or an error code.",
    "prorec_sum": "Counts the number of 2D vertex objects in a DWG polyline, returning errors if object type mismatches or required references are invalid.",
    "filter_prorec_sum": "Counts the number of VERTEX_2D entities in a 2D polyline DWG object, returning errors via a2 when invalid or unexpected objects are encountered.",
    "prorec_aug_sum": "Counts the number of 2D vertex objects in a DWG polyline entity, returning an error flag if the object type or structure is invalid.",
    "filter_prorec_aug_sum": "Returns the number of 2D vertex objects in a polyline entity, setting an error flag if the entity type or vertices are invalid.",
    "work_score": {
        "prorec": {
            "summary": "Counts the number of 2D vertex objects in a DWG polyline, returning errors if object type mismatches or required references are invalid.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function counts the number of 2D vertex objects in a DWG polyline, which is explicitly shown in the code via loops incrementing num_points when dwg_object_to_VERTEX_2D succeeds. It also accurately notes that errors are returned if the object type mismatches or if references (vobj or vertex) are invalid, which is evident from error checks in the code. All semantic details in the summary are supported by the source code, with no unverified assumptions.",
                "The summary correctly states that the function counts 2D vertex objects in a DWG polyline and flags errors if the object type is incorrect or if required references are invalid. These claims are explicitly supported by checks for `DWG_TYPE_POLYLINE_2D`, error handling when vertex references are null or conversion fails, and returning counts. However, the summary omits key logic details such as version-based branching for different iteration strategies (R_2004, R_13, and before R_13) and nuances in how `num_points` is determined in each case, so it does not fully capture the code's flow.",
                "The summary correctly captures that the function counts 2D vertices in a DWG polyline and returns errors when the object type is wrong or vertex references are invalid, which is directly supported by checks against DWG_TYPE_POLYLINE_2D and error handling in the code. However, it omits specific conditional logic based on DWG version, iteration methods, and handling of partial vertex retrieval. While all stated details are accurate, they are somewhat generic and lack domain-rich specifics from the source code."
            ]
        },
        "filter_prorec": {
            "summary": "Counts the number of VERTEX_2D entities in a 2D polyline DWG object, returning errors via a2 when invalid or unexpected objects are encountered.",
            "score": [
                0.7333333333333334,
                0.6333333333333333,
                0.7666666666666667
            ],
            "reason": [
                "The summary correctly states that the function counts the number of VERTEX_2D entities in a 2D polyline DWG object, which is supported by multiple calls to dwg_object_to_VERTEX_2D and version-dependent iteration logic. It also accurately reflects that an error flag is set when invalid or unexpected objects are found. However, the summary's reference to 'a2' as the error output parameter is inaccurate; in the source code, the parameter is named 'error'. This is a minor detail mislabel but most of the core behavior is described accurately.",
                "The summary correctly captures the core logic: the function counts VERTEX_2D entities in a 2D polyline DWG object and sets an error flag when invalid or unexpected objects are encountered. These points are explicitly supported by the source code\u2019s loops over vertices, type checks, and error assignments. However, it inaccurately refers to the error variable as 'a2' instead of '*error', which introduces a minor discrepancy. Despite this, the accurate details map well to the primary control flow and conditions in the code, covering its main operations but not mentioning version-based branching or iteration specifics.",
                "The summary correctly states that the function counts VERTEX_2D entities in a 2D polyline DWG object and returns an error when invalid or unexpected objects are encountered, which is supported by the code's vertex iteration and error flagging. However, it inaccurately refers to returning errors via 'a2', a parameter name not present in the source code, making this detail a hallucination. Since only this single detail is inaccurate and most of the summary reflects the explicit code behavior, the proportion of inaccurate details is low and the accurate parts offer moderately domain-specific insights."
            ]
        }
    }
}
{
    "source_code": "int ed_main(int argc UNUSED_PARAM, char **argv)\n{\n\tINIT_G();\n\n\tbufSize = INITBUF_SIZE;\n\tbufBase = xmalloc(bufSize);\n\tbufPtr = bufBase;\n\tlines.next = &lines;\n\tlines.prev = &lines;\n\n\tif (argv[1]) {\n\t\tfileName = xstrdup(argv[1]);\n\t\tif (!readLines(fileName, 1)) {\n\t\t\treturn EXIT_SUCCESS;\n\t\t}\n\t\tif (lastNum)\n\t\t\tsetCurNum(1);\n\t\tdirty = FALSE;\n\t}\n\n\tdoCommands();\n\treturn EXIT_SUCCESS;\n}",
    "comment": "Initializes a buffer, reads lines from a specified file if provided, and then executes commands in a loop.",
    "prorec_sum": "Initializes a data structure with provided parameters, links related resources, validates a retrieved entry, triggers follow-up processing, and finalizes state updates.",
    "filter_prorec_sum": "Initializes a data structure with provided parameters, invokes helper routines, conditionally processes a resource from a10, and finalizes with a cleanup or state update.",
    "prorec_aug_sum": "Initializes a data structure with parameters, invokes multiple setup routines, validates a retrieved resource, and performs final configuration before returning.",
    "filter_prorec_aug_sum": "Initializes a data structure with provided parameters, links related resources, validates a retrieved entry, and performs follow\u2011up processing before returning.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a data structure with provided parameters, links related resources, validates a retrieved entry, triggers follow-up processing, and finalizes state updates.",
            "score": [
                0.26666666666666666,
                0.43333333333333335,
                0.0
            ],
            "reason": [
                "The summary makes general claims not explicitly supported by the source code. While the code does perform initialization of buffers and linked list pointers, the summary's references to 'provided parameters', 'links related resources', 'validates a retrieved entry', and 'finalizes state updates' are vague and not directly verifiable from specific functions or variables in the code. Most semantic details are high-level abstractions rather than explicit evidence from the source, resulting in a low ratio of accurate details.",
                "The summary is too vague and does not explicitly capture key details from the source code, such as initialization of buffer variables, self-referential linking of the 'lines' structure, conditional file reading with use of argv[1], setting the current line number if lastNum is true, resetting the 'dirty' flag, and calling doCommands before returning. While it generally references initialization and follow-up processing, it omits most specific logic and thus only partially aligns with the source code\u2019s actual operations.",
                "The summary is mostly inaccurate: it omits specific and verifiable code details such as the use of INIT_G(), allocation with xmalloc, list self-referencing initialization, reading lines from a file, setting the current number, and dirty flag handling. Instead, it uses vague phrases like 'links related resources' and 'validates a retrieved entry' without grounding them in explicit source code constructs. More than half of the described actions cannot be directly matched to the code, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a data structure with provided parameters, invokes helper routines, conditionally processes a resource from a10, and finalizes with a cleanup or state update.",
            "score": [
                0.3333333333333333,
                0.5333333333333333,
                0.0
            ],
            "reason": [
                "The summary mentions initialization and invoking helper routines, which is supported by INIT_G(), buffer allocation, and doCommands() in the source. However, it inaccurately describes the parameter as 'a10' (not present; should be argv[1]), and implies a final cleanup which is not explicit in the source (only a return occurs). About half of the details are accurate, with the rest being unverified or hallucinated.",
                "The summary's claims are mostly inaccurate. The source code initializes buffers and linked-list pointers, calls initialization routines, optionally processes a file from argv[1], sets current number and dirty flag, then runs doCommands before exiting. The mention of 'a10' as a resource and 'finalizes with a cleanup' are unsupported. Only the general idea of initialization and invoking helper routines match the code, but several core details like buffer setup, conditional file reading, and state flag handling are missing or misrepresented, leaving the description incomplete.",
                "The summary is vague and introduces inaccurate elements, such as referencing 'a10' which does not exist in the source code, and suggesting a 'cleanup' step that is not explicitly present. While it correctly notes initialization of data structures and invocation of helper routines, most of its semantic claims lack direct evidence from the code. More than half of the details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nmpn_dcpi1_bdiv_q_n (mp_ptr qp,\n\t\t    mp_ptr np, mp_srcptr dp, mp_size_t n,\n\t\t    mp_limb_t dinv, mp_ptr tp)\n{\n  while (ABOVE_THRESHOLD (n, DC_BDIV_Q_THRESHOLD))\n    {\n      mp_size_t lo, hi;\n      mp_limb_t cy;\n\n      lo = n >> 1;\t\t\t/* floor(n/2) */\n      hi = n - lo;\t\t\t/* ceil(n/2) */\n\n      cy = mpn_dcpi1_bdiv_qr_n (qp, np, dp, lo, dinv, tp);\n\n      mpn_mullo_n (tp, qp, dp + hi, lo);\n      mpn_add_n (np + hi, np + hi, tp, lo);\n\n      if (lo < hi)\n\t{\n\t  cy += mpn_addmul_1 (np + lo, qp, lo, dp[lo]);\n\t  np[n - 1] += cy;\n\t}\n      qp += lo;\n      np += lo;\n      n -= lo;\n    }\n  mpn_sbpi1_bdiv_q (qp, np, n, dp, n, dinv);\n}",
    "comment": "Divides a multi-precision number by another using a divide-and-conquer approach, updating quotient and remainder for large input sizes.",
    "prorec_sum": "Performs recursive multi-precision division using divide-and-conquer algorithms and GMP low-level routines, producing the quotient for large integer operands.",
    "filter_prorec_sum": "Performs recursive multi-precision division using GMP\u2019s divide-and-conquer and basecase algorithms, producing the quotient from large integer limb arrays.",
    "prorec_aug_sum": "Performs high-performance multi-limb division using divide-and-conquer algorithms, combining partial quotient/remainder computation with multiplication and addition for large operand sizes.",
    "filter_prorec_aug_sum": "Performs multi-limb division using divide-and-conquer and schoolbook algorithms, updating quotient and remainder buffers with GMP low-level arithmetic functions.",
    "work_score": {
        "prorec": {
            "summary": "Performs recursive multi-precision division using divide-and-conquer algorithms and GMP low-level routines, producing the quotient for large integer operands.",
            "score": [
                0.9333333333333332,
                0.6333333333333333,
                0.9
            ],
            "reason": [
                "The summary states that the function performs recursive multi-precision division using divide-and-conquer algorithms and GMP low-level routines to produce the quotient for large integer operands. The source code confirms the use of GMP-style low-level routines (e.g., mpn_dcpi1_bdiv_qr_n, mpn_mullo_n, mpn_add_n, mpn_addmul_1, mpn_sbpi1_bdiv_q) and a divide-and-conquer approach via splitting 'n' into high and low parts in a loop until a threshold is met. The notion of producing a quotient is supported by the function name and operations on qp. All semantic details in the summary are directly supported by explicit evidence in the code.",
                "The summary correctly identifies that the function uses a divide-and-conquer approach and GMP low-level routines to compute a quotient for large integers, which is supported by loops over halves (`lo`, `hi`), calls to functions like `mpn_dcpi1_bdiv_qr_n`, `mpn_mullo_n`, `mpn_add_n`, and `mpn_sbpi1_bdiv_q`. However, it omits key logic details found in the code, such as carry handling (`cy`), adjustments when `lo < hi`, and threshold checks (`ABOVE_THRESHOLD`). This means the accurate content covers the core operation, but misses significant portions of the function's mechanics.",
                "The summary claims the function performs recursive multi-precision division via divide-and-conquer and GMP low-level routines to produce the quotient for large integers. The source code confirms use of divide-and-conquer logic through halving 'n' and recursively processing segments, and it calls GMP internal functions like 'mpn_dcpi1_bdiv_qr_n', 'mpn_mullo_n', and 'mpn_sbpi1_bdiv_q', matching the low-level GMP routines claim. Producing the quotient is supported by the 'qp' output parameter. There are no inaccurate details detected, and the description is domain-specific and precise."
            ]
        },
        "filter_prorec": {
            "summary": "Performs recursive multi-precision division using GMP\u2019s divide-and-conquer and basecase algorithms, producing the quotient from large integer limb arrays.",
            "score": [
                0.9666666666666667,
                0.6333333333333333,
                0.9
            ],
            "reason": [
                "The summary correctly notes that the function performs multi-precision division and uses a divide-and-conquer threshold with a basecase fallback, which is explicitly shown by the ABOVE_THRESHOLD check and calls to mpn_dcpi1_bdiv_qr_n and mpn_sbpi1_bdiv_q. It is also accurate that the quotient is produced from large integer limb arrays, as indicated by parameters like mp_ptr qp and mp_ptr np. The mention of GMP is plausible since the naming conventions match GMP internals, but there is no direct textual evidence in the code confirming it is GMP; this is an unverified assumption. Overall, most details match the source code structure, with only a minor unverified attribution.",
                "The summary correctly identifies that the function performs multi-precision division using a divide-and-conquer approach and falls back to a basecase algorithm (mpn_sbpi1_bdiv_q), producing a quotient from limb arrays. These details are explicitly supported by the source code through calls to mpn_dcpi1_bdiv_qr_n, mpn_sbpi1_bdiv_q, and operations on mp_ptr arrays. However, the summary omits specifics of the control flow, such as threshold checking, splitting into lo/hi parts, intermediate multiplication and addition adjustments, and carry handling, which are important to fully capture the code's logic.",
                "The summary claims that the function performs recursive multi-precision division using GMP\u2019s divide-and-conquer and basecase algorithms, producing the quotient from large integer limb arrays. The source code confirms it is part of GMP\u2019s mpn layer, uses a divide-and-conquer pattern via looping with ABOVE_THRESHOLD and mpn_dcpi1_bdiv_qr_n, and falls back to mpn_sbpi1_bdiv_q for the basecase. It also operates on limb arrays (mp_ptr, mp_limb_t) and produces a quotient array (qp). All key details are explicitly supported by the code, giving the summary high truthfulness and domain precision."
            ]
        }
    }
}
{
    "source_code": "\nstatic int create_dir(struct kobject *kobj, struct sysfs_dirent *parent_sd,\n\tenum kobj_ns_type type, const void *ns, const char *name,\n\tstruct sysfs_dirent **p_sd)\n{\n\tumode_t mode = S_IFDIR| S_IRWXU | S_IRUGO | S_IXUGO;\n\tstruct sysfs_addrm_cxt acxt;\n\tstruct sysfs_dirent *sd;\n\tint rc;\n\n\t/* allocate */\n\tsd = sysfs_new_dirent(name, mode, SYSFS_DIR);\n\tif (!sd)\n\t\treturn -ENOMEM;\n\n\tsd->s_flags |= (type << SYSFS_NS_TYPE_SHIFT);\n\tsd->s_ns = ns;\n\tsd->s_dir.kobj = kobj;\n\n\t/* link in */\n\tsysfs_addrm_start(&acxt, parent_sd);\n\trc = sysfs_add_one(&acxt, sd);\n\tsysfs_addrm_finish(&acxt);\n\n\tif (rc == 0)\n\t\t*p_sd = sd;\n\telse\n\t\tsysfs_put(sd);\n\n\treturn rc;\n}",
    "comment": "Creates a directory entry in a configuration filesystem, ensuring it does not already exist and managing reference counts for the parent directory.",
    "prorec_sum": "Allocates and initializes a structured object with provided parameters, performs setup routines, and returns either the prepared object or an error code.",
    "filter_prorec_sum": "Allocates and initializes a structured object with provided parameters, performs setup calls, and returns it or an error code depending on initialization success.",
    "prorec_aug_sum": "Allocates and initializes a data structure with provided parameters, performs setup calls, and returns it via output pointer or an error code.",
    "filter_prorec_aug_sum": "Allocates and initializes a structure with provided parameters, invokes two processing routines, and returns either an error code or the initialized object reference.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a structured object with provided parameters, performs setup routines, and returns either the prepared object or an error code.",
            "score": [
                1.0,
                0.6666666666666666,
                0.6
            ],
            "reason": [
                "The summary correctly captures that the function allocates a new object, initializes it using provided parameters, performs setup routines, and returns either the prepared object or an error code. All these points are explicitly supported by the source code: allocation via sysfs_new_dirent, initialization of fields, linking with sysfs_addrm_start/sysfs_add_one/sysfs_addrm_finish, and conditional return of either the object or freeing with sysfs_put on error. No unverified assumptions or hallucinations are present.",
                "The summary correctly captures the general flow: allocation of an object, initialization with provided parameters, execution of setup procedures, and returning either the initialized object or an error code. These details are supported by the code's allocation using sysfs_new_dirent, setting fields like s_flags, s_ns, and s_dir.kobj, performing setup via sysfs_addrm_start/add_one/finish, and returning rc or the object through p_sd. However, it omits specific mechanics such as mode settings, error handling via sysfs_put, and the conditional assignment of *p_sd, which are part of the critical semantics.",
                "The summary accurately captures that the function allocates and initializes an object (sysfs_dirent), uses provided parameters in the setup, and returns either the prepared object or an error code, which is clearly shown in the source code via allocation, initialization, linking, and return logic. However, the description is generic and omits specific domain details like the kobject association, namespace handling, mode flags, and sysfs-specific routines, reducing its domain value."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a structured object with provided parameters, performs setup calls, and returns it or an error code depending on initialization success.",
            "score": [
                1.0,
                0.6666666666666666,
                0.6
            ],
            "reason": [
                "The summary correctly notes that the function allocates and initializes an object based on provided parameters, performs setup calls, and returns either the object or an error code depending on success. These points are explicitly supported by the source code, which shows allocation via `sysfs_new_dirent`, initialization of struct members, calling setup functions (`sysfs_addrm_start`, `sysfs_add_one`, `sysfs_addrm_finish`), and conditional return of either the struct pointer or error code. There are no extraneous or unverified details, so accuracy is very high.",
                "The summary accurately captures the core logic that the function allocates and initializes a structure using provided parameters, performs setup calls, and conditionally returns it or an error based on success. These details match the code\u2019s allocation of a sysfs_dirent, initialization of its fields, calling of setup functions, and returning appropriate values. However, the summary omits significant specifics such as the exact type of object (sysfs_dirent), mode flags, namespace and kobj assignments, linking process via sysfs_addrm_* calls, and cleanup using sysfs_put on failure. Thus, it describes the main action but misses important implementation details.",
                "The summary accurately reflects that the function allocates a structured object, initializes it with provided parameters, performs setup calls, and returns either the initialized object via a pointer or an error code. All these details are directly evidenced in the source code by the allocation of 'sd' with 'sysfs_new_dirent', setting its fields, calling setup functions ('sysfs_addrm_start', 'sysfs_add_one', 'sysfs_addrm_finish'), and returning the pointer or handling errors. However, the details are fairly generic without domain-specific richness such as mention of 'sysfs_dirent', 'kobject', or specific flags and modes used."
            ]
        }
    }
}
{
    "source_code": "acpi_status acpi_unload_parent_table(acpi_handle object)\n{\n\tstruct acpi_namespace_node *node =\n\t    ACPI_CAST_PTR(struct acpi_namespace_node, object);\n\tacpi_status status = AE_NOT_EXIST;\n\tacpi_owner_id owner_id;\n\tu32 i;\n\n\tACPI_FUNCTION_TRACE(acpi_unload_parent_table);\n\n\t/* Parameter validation */\n\n\tif (!object) {\n\t\treturn_ACPI_STATUS(AE_BAD_PARAMETER);\n\t}\n\n\t/*\n\t * The node owner_id is currently the same as the parent table ID.\n\t * However, this could change in the future.\n\t */\n\towner_id = node->owner_id;\n\tif (!owner_id) {\n\n\t\t/* owner_id==0 means DSDT is the owner. DSDT cannot be unloaded */\n\n\t\treturn_ACPI_STATUS(AE_TYPE);\n\t}\n\n\t/* Must acquire the interpreter lock during this operation */\n\n\tstatus = acpi_ut_acquire_mutex(ACPI_MTX_INTERPRETER);\n\tif (ACPI_FAILURE(status)) {\n\t\treturn_ACPI_STATUS(status);\n\t}\n\n\t/* Find the table in the global table list */\n\n\tfor (i = 0; i < acpi_gbl_root_table_list.current_table_count; i++) {\n\t\tif (owner_id != acpi_gbl_root_table_list.tables[i].owner_id) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Allow unload of SSDT and OEMx tables only. Do not allow unload\n\t\t * of the DSDT. No other types of tables should get here, since\n\t\t * only these types can contain AML and thus are the only types\n\t\t * that can create namespace objects.\n\t\t */\n\t\tif (ACPI_COMPARE_NAME\n\t\t    (acpi_gbl_root_table_list.tables[i].signature.ascii,\n\t\t     ACPI_SIG_DSDT)) {\n\t\t\tstatus = AE_TYPE;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Ensure the table is actually loaded */\n\n\t\tif (!acpi_tb_is_table_loaded(i)) {\n\t\t\tstatus = AE_NOT_EXIST;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Invoke table handler if present */\n\n\t\tif (acpi_gbl_table_handler) {\n\t\t\t(void)acpi_gbl_table_handler(ACPI_TABLE_EVENT_UNLOAD,\n\t\t\t\t\t\t     acpi_gbl_root_table_list.\n\t\t\t\t\t\t     tables[i].pointer,\n\t\t\t\t\t\t     acpi_gbl_table_handler_context);\n\t\t}\n\n\t\t/*\n\t\t * Delete all namespace objects owned by this table. Note that\n\t\t * these objects can appear anywhere in the namespace by virtue\n\t\t * of the AML \"Scope\" operator. Thus, we need to track ownership\n\t\t * by an ID, not simply a position within the hierarchy.\n\t\t */\n\t\tstatus = acpi_tb_delete_namespace_by_owner(i);\n\t\tif (ACPI_FAILURE(status)) {\n\t\t\tbreak;\n\t\t}\n\n\t\tstatus = acpi_tb_release_owner_id(i);\n\t\tacpi_tb_set_table_loaded_flag(i, FALSE);\n\t\tbreak;\n\t}\n\n\t(void)acpi_ut_release_mutex(ACPI_MTX_INTERPRETER);\n\treturn_ACPI_STATUS(status);\n}",
    "comment": "Unloads ACPI tables by deleting namespace objects and calling the table handler, ensuring conditions to prevent unloading the DSDT are met.",
    "prorec_sum": "Processes a matched ACPI table entry by invoking related handlers and operations, returning a status code based on execution success or encountered conditions.",
    "filter_prorec_sum": "Processes an ACPI table entry matching a specific identifier, performing validation, optional callbacks, and executing associated operations with given parameters.",
    "prorec_aug_sum": "Processes an entry matching a specific byte identifier, invoking related handlers and operations, and returns a status code indicating the outcome.",
    "filter_prorec_aug_sum": "Processes an entry identified by a specific byte value, performing conditional callbacks and operations before returning a status code.",
    "work_score": {
        "prorec": {
            "summary": "Processes a matched ACPI table entry by invoking related handlers and operations, returning a status code based on execution success or encountered conditions.",
            "score": [
                0.6999999999999998,
                0.5666666666666667,
                0.5
            ],
            "reason": [
                "The summary correctly identifies that the function processes an ACPI table entry, invokes related handlers, and returns a status code based on conditions, which is supported by the code's logic involving handler invocation, namespace deletion, and status returns. However, it omits several specific and important details present in the source code, such as parameter validation, the prohibition of unloading DSDT, mutex acquisition/release, and table loaded checks. While not hallucinated, the summary is high-level and incomplete, reducing its alignment with the evaluation steps.",
                "The summary accurately identifies that the function processes a matched ACPI table entry, invokes handlers, and returns a status code based on execution outcome. However, it omits significant parts of the logic present in the source code, such as parameter validation, owner_id checks, restrictions on unloading DSDT, lock acquisition/release, checks for table existence, and namespace cleanup operations. While the main action is captured, many important execution details and edge cases are missing.",
                "The summary accurately captures the general process flow: finding a matching ACPI table entry, invoking potential handlers, performing operations, and returning a status based on success or errors. However, it omits many specific, domain-rich details evident in the source code such as the owner_id checks, mutex locking, restrictions on unloading DSDT, the table load checks, deletion of namespace objects, and release of resources. The details provided are generic and not specific to the nuanced logic in the code, but there are no explicit inaccuracies, so the kill switch does not apply."
            ]
        },
        "filter_prorec": {
            "summary": "Processes an ACPI table entry matching a specific identifier, performing validation, optional callbacks, and executing associated operations with given parameters.",
            "score": [
                0.4666666666666666,
                0.5333333333333333,
                0.26666666666666666
            ],
            "reason": [
                "The summary is overly general and omits key specifics from the source code, such as handling of owner_id, DSDT unload restrictions, mutex acquisition, iteration over acpi_gbl_root_table_list, and specific function calls like acpi_tb_is_table_loaded and acpi_tb_delete_namespace_by_owner. While it correctly notes that the code processes a table entry with validation and optional callbacks, most concrete details in the source are not reflected, leading to a mix of vague accuracy and numerous omissions.",
                "The summary captures only a vague notion of processing an ACPI table entry with validation, optional callbacks, and operations. While these elements are present in the source code\u2014such as parameter validation, conditional invocation of a table handler, and executing namespace deletion and owner release\u2014it omits many critical details like handling of owner_id values, restriction on unloading certain table types (DSDT), checking if a table is loaded, acquiring and releasing interpreter locks, and looping through the table list. The accurate parts reflect the general flow but miss substantial logic necessary for a complete picture.",
                "The summary is vague and omits key specific details from the source code, such as checks against owner_id, restrictions on unloading DSDT, acquisition/release of interpreter mutex, and specific function calls for unloading and cleanup. While it generally mentions validation, optional callbacks, and operations, it fails to correctly capture core logic elements evident in the source code, making most of its details generic and lacking domain-rich accuracy."
            ]
        }
    }
}
{
    "source_code": "int\n_rl_dispatch_callback (_rl_keyseq_cxt *cxt)\n{\n  int nkey, r;\n\n  /* For now */\n  /* The first time this context is used, we want to read input and dispatch\n     on it.  When traversing the chain of contexts back `up', we want to use\n     the value from the next context down.  We're simulating recursion using\n     a chain of contexts. */\n  if ((cxt->flags & KSEQ_DISPATCHED) == 0)\n    {\n      nkey = _rl_subseq_getchar (cxt->okey);\n      if (nkey < 0)\n\t{\n\t  _rl_abort_internal ();\n\t  return -1;\n\t}\n      r = _rl_dispatch_subseq (nkey, cxt->dmap, cxt->subseq_arg);\n      cxt->flags |= KSEQ_DISPATCHED;\n    }\n  else\n    r = cxt->childval;\n\n  /* For now */\n  if (r != -3)\t/* don't do this if we indicate there will be other matches */\n    r = _rl_subseq_result (r, cxt->oldmap, cxt->okey, (cxt->flags & KSEQ_SUBSEQ));\n\n  RL_CHECK_SIGNALS ();\n  /* We only treat values < 0 specially to simulate recursion. */\n  if (r >= 0 || (r == -1 && (cxt->flags & KSEQ_SUBSEQ) == 0))\t/* success! or failure! */\n    {\n      _rl_keyseq_chain_dispose ();\n      RL_UNSETSTATE (RL_STATE_MULTIKEY);\n      return r;\n    }\n\n  if (r != -3)\t\t\t/* magic value that says we added to the chain */\n    _rl_kscxt = cxt->ocxt;\n  if (_rl_kscxt)\n    _rl_kscxt->childval = r;\n  if (r != -3)\n    _rl_keyseq_cxt_dispose (cxt);\n\n  return r;\n}",
    "comment": "Handles key sequence input and dispatches actions based on the context, managing recursion through context chaining and returning results based on input validity.",
    "prorec_sum": "Handles a readline key sequence by dispatching its associated callback, processing results, managing signal interruptions, and cleaning up execution context.",
    "filter_prorec_sum": "Handles readline input dispatch by processing subsequences, managing signal callbacks, and cleaning up or updating context state based on execution results.",
    "prorec_aug_sum": "Processes a readline callback by dispatching input subsequences, handling signals, managing context cleanup, and returning the resulting status code.",
    "filter_prorec_aug_sum": "Handles readline command dispatch, processing subsequences, managing signal interruptions, and freeing or updating associated context before returning the execution status code.",
    "work_score": {
        "prorec": {
            "summary": "Handles a readline key sequence by dispatching its associated callback, processing results, managing signal interruptions, and cleaning up execution context.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly captures that the function handles a readline key sequence, dispatches processing, manages results, handles signals, and cleans up the context, all of which are explicitly shown in the source code via calls like _rl_dispatch_subseq, RL_CHECK_SIGNALS, and _rl_keyseq_cxt_dispose. No unverifiable or hallucinated details are present, making all semantic elements accurate.",
                "The summary correctly states that the function handles a readline key sequence, dispatches callbacks, processes results, manages signals, and cleans up execution context. These elements are explicitly supported by the source code: key sequence dispatch via `_rl_dispatch_subseq`, signal management with `RL_CHECK_SIGNALS()`, and cleanup through `_rl_keyseq_chain_dispose` and `_rl_keyseq_cxt_dispose`. However, the summary lacks mention of specific control flow steps and edge case handling (such as recursion simulation, special values like -3, or aborting on input errors) that are critical to the function's logic.",
                "The summary accurately captures the high-level function purpose: it processes a readline key sequence via a dispatch mechanism, interprets return values, manages signals (via RL_CHECK_SIGNALS), and cleans up execution context (via _rl_keyseq_chain_dispose and _rl_keyseq_cxt_dispose). All these actions are explicitly present in the source code. However, the description is generic and omits specifics like conditional branches, the meaning of specific return values, and flag checks, so the details provided are only moderately domain-specific."
            ]
        },
        "filter_prorec": {
            "summary": "Handles readline input dispatch by processing subsequences, managing signal callbacks, and cleaning up or updating context state based on execution results.",
            "score": [
                0.7333333333333334,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function handles readline input dispatch by processing subsequences and updating context state based on results, which is directly supported by calls to `_rl_subseq_getchar`, `_rl_dispatch_subseq`, `_rl_subseq_result`, and context flag manipulation in the source code. Cleanup of context state is also evidenced by calls like `_rl_keyseq_chain_dispose` and `_rl_keyseq_cxt_dispose`. However, the claim about managing signal callbacks is inaccurate because while `RL_CHECK_SIGNALS()` is called, it is a macro check rather than active callback management; thus this is an unsupported extrapolation. This results in mostly accurate details with one unverified assertion.",
                "The summary captures the general idea of handling input dispatch and context state updates, which is accurate given the code's reading of input via `_rl_subseq_getchar`, dispatching with `_rl_dispatch_subseq`, and disposing/updating contexts. However, the claim about managing signal callbacks is inaccurate, as the code only calls `RL_CHECK_SIGNALS` without implementing signal callback handling. The accurate details cover the main dispatch and cleanup logic but omit specifics of error handling and recursion simulation, resulting in partial coverage.",
                "The summary correctly identifies that the function handles readline input dispatch, processes subsequences, and updates or cleans up context state, all of which have explicit evidence in the code. However, the mention of managing signal callbacks is inaccurate; while RL_CHECK_SIGNALS appears in the code, there is no broader signal callback management logic beyond this macro invocation. Thus, most details are accurate but generic, providing only a high-level view without specific domain-rich insights."
            ]
        }
    }
}
{
    "source_code": "int burn_drive_obtain_scsi_adr(char *path,\n\t\t\t       int *bus_no, int *host_no, int *channel_no,\n\t\t\t       int *target_no, int *lun_no)\n{\n\tint ret, i;\n\tchar *adr = NULL;\n\n\tBURN_ALLOC_MEM(adr, char, BURN_DRIVE_ADR_LEN);\n\n\t/* open drives cannot be inquired by sg_obtain_scsi_adr() */\n\tfor (i = 0; i < drivetop + 1; i++) {\n\t\tif (drive_array[i].global_index < 0)\n\tcontinue;\n\t\tret = burn_drive_d_get_adr(&(drive_array[i]),adr);\n\t\tif (ret < 0)\n\t\t\t{ret = 1; goto ex;}\n\t\tif (ret == 0)\n\tcontinue;\n\t\tif (strcmp(adr, path) == 0) {\n\t\t\t*host_no = drive_array[i].host;\n\t\t\t*channel_no = drive_array[i].channel;\n\t\t\t*target_no = drive_array[i].id;\n\t\t\t*lun_no = drive_array[i].lun;\n\t\t\t*bus_no = drive_array[i].bus_no;\n\t\t\tif (*host_no < 0 || *channel_no < 0 ||\n\t\t\t    *target_no < 0 || *lun_no < 0)\n\t\t\t\t{ret = 0; goto ex;}\n\t\t\t{ret = 1; goto ex;}\n\t\t}\n\t}\n\n\tret = sg_obtain_scsi_adr(path, bus_no, host_no, channel_no,\n\t\t\t\t target_no, lun_no);\nex:;\n\tBURN_FREE_MEM(adr);\n\treturn ret;\n}",
    "comment": "Retrieves the SCSI address information for a specified drive path, utilizing both local and SCSI inquiry methods.",
    "prorec_sum": "Searches in-memory directory entries for a matching filename and returns associated metadata fields, or falls back to an alternate lookup function.",
    "filter_prorec_sum": "Searches for a matching file entry by name in an internal ISO9660 directory list and returns its associated metadata fields.",
    "prorec_aug_sum": "Searches an internal device table for a matching name and retrieves its stored parameters, falling back to an alternate lookup if not found.",
    "filter_prorec_aug_sum": "Searches a device table for a matching name, retrieves associated parameters into provided pointers, or falls back to an alternate lookup routine.",
    "work_score": {
        "prorec": {
            "summary": "Searches in-memory directory entries for a matching filename and returns associated metadata fields, or falls back to an alternate lookup function.",
            "score": [
                0.13333333333333333,
                0.06666666666666667,
                0.0
            ],
            "reason": [
                "The summary claims the function searches in-memory directory entries for a matching filename and returns metadata, then falls back to another lookup function. In the source code, however, the function iterates over drive_array entries comparing SCSI addresses to a given path, retrieves host, channel, target, LUN, and bus numbers, and uses sg_obtain_scsi_adr as a fallback. There is no evidence of directory entries or filenames, making all details in the summary inaccurate.",
                "The summary claims the function searches in-memory directory entries for a matching filename and returns metadata, but the source code actually iterates over an array of drive structures to match a SCSI address string against the provided path, returning bus, host, channel, target, and LUN numbers or falling back to sg_obtain_scsi_adr. The 'directory entries' and 'filename' details are inaccurate and not present in the code. After discarding these hallucinations, the only accurate part is the fallback to an alternate lookup function, which alone does not capture the core logic.",
                "The summary misrepresents the code\u2019s domain and purpose. The function actually iterates over drive_array entries searching by device path to obtain SCSI addressing values (bus, host, channel, target, lun), not filename metadata. Terms like 'in-memory directory entries' and 'metadata fields' are inaccurate, and all main semantic claims are false, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Searches for a matching file entry by name in an internal ISO9660 directory list and returns its associated metadata fields.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary claims the function searches an ISO9660 directory for a file and returns metadata, but the code instead retrieves SCSI address details for a drive path using structures like drive_array and functions like burn_drive_d_get_adr and sg_obtain_scsi_adr. None of the ISO9660 or file-search concepts appear in the code, so all details are inaccurate.",
                "The summary claims the function searches an ISO9660 directory list for a file by name and returns metadata, but the source code actually iterates over drive entries to match a device path and extract SCSI address components. None of the described operations or data structures (ISO9660, file metadata) appear in the code, so all details are inaccurate and the summary fails to describe any part of the actual logic.",
                "The summary claims the code searches a directory list for a file entry in an ISO9660 filesystem and returns metadata, but the source code actually retrieves SCSI address components for a device path using structures like drive_array and sg_obtain_scsi_adr. This is a complete mismatch; all semantic details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nint\ncontext_init (char *str)\n{\n  mem_init ();\n  context = mem_alloc (sizeof (struct context));\n  context->num_pat = expr_init (str);\n  if (!context->num_pat)\n    return 0;\n\n  context->tmp = mem_alloc (sizeof (struct line) - sizeof (char[4])\n      + opt.context + 1);\n\n  if (!opt.out_quiet)\n    {\n      register int i, j, occurrences;\n      struct line **line;\n\n      context->lines = mem_alloc (context->num_pat\n\t  * sizeof (struct line **));\n      occurrences = opt.occurrences ? opt.occurrences : 1;\n\n      for (i = 0; i < context->num_pat; i++)\n\t{\n\t  line = mem_alloc (occurrences * sizeof (struct line *));\n\t  for (j = 0; j < occurrences; j++)\n\t    line[j] = mem_alloc (sizeof (struct line) - sizeof (char[4])\n\t\t+ opt.context + 1);\n\n\t  context->lines[i] = line;\n\t}\n    }\n\n  return context->num_pat;\n}",
    "comment": "Initializes the context structure, allocating memory for patterns and lines based on given input and options, and returns the number of patterns.",
    "prorec_sum": "Initializes a global structure and allocates nested memory blocks based on an input parameter and global configuration values.",
    "filter_prorec_sum": "Allocates and initializes a nested structure of memory blocks based on input size, storing pointers for subsequent field-related data handling.",
    "prorec_aug_sum": "Initializes global data structures and allocates nested memory buffers based on the value returned from sub_402820 for the given input parameter.",
    "filter_prorec_aug_sum": "Initializes global data structures by allocating and populating multi-level arrays based on the count from `a1` and configuration flags.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a global structure and allocates nested memory blocks based on an input parameter and global configuration values.",
            "score": [
                0.9666666666666667,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly describes the function's behavior: it initializes a global structure ('context') and allocates nested memory blocks based on both the input parameter (passed to expr_init via str) and global configuration values (opt.context, opt.occurrences, opt.out_quiet). All these elements have direct evidence in the source code. The only minor omission is that it does not mention the function calling mem_init or returning context->num_pat, but these are small details and do not affect factual correctness.",
                "The summary accurately notes initialization of a global structure and nested memory allocation driven by an input parameter and global configuration values, which is directly supported by the context_init function's use of mem_alloc, expr_init(str), and opt fields. However, it omits important logic such as conditional allocation based on opt.out_quiet, computation of occurrences, and returning context->num_pat, meaning the description covers the main action but misses key control flow and edge case handling.",
                "The summary accurately reflects the main logic \u2014 a global structure is initialized and nested memory blocks are allocated using an input string parameter and global configuration (`opt.context`, `opt.occurrences`, `opt.out_quiet`). No specific claims about libraries or drivers are made, and all stated details are explicitly evidenced in the source code. The accurate details are somewhat generic, describing memory allocation broadly without deeper insight into data structures or algorithmic nuances."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a nested structure of memory blocks based on input size, storing pointers for subsequent field-related data handling.",
            "score": [
                0.7000000000000001,
                0.6,
                0.5666666666666668
            ],
            "reason": [
                "The summary correctly notes that the function allocates and initializes nested memory structures influenced by input size, which is evident from multiple mem_alloc calls using parameters like context->num_pat, occurrences, and opt.context. However, the claim about 'storing pointers for subsequent field-related data handling' is unsupported; the source code shows allocation of struct line pointers for patterns but no explicit mention of field-specific data handling. With one accurate detail and one unverified claim, accuracy is mixed.",
                "The summary captures some core aspects of the source code, such as memory allocation and initialization of a nested structure of pointers. These details are accurate, as the function allocates multiple `struct line` pointers stored in `context->lines` based on computed sizes from `opt.context` and `occurrences`. However, the summary omits key logic: conditional allocation based on `opt.out_quiet`, initialization of `num_pat` via `expr_init`, early return when `num_pat` is zero, and the specific dependency on input arguments and `opt` settings. Thus, while the main action is represented, significant control flow and edge case handling are not described.",
                "The summary correctly notes that the function allocates and initializes memory blocks in a nested fashion, as shown by the allocations for `context`, `context->tmp`, and the two-level allocations for `context->lines` and their elements. However, the claim about 'subsequent field-related data handling' is not supported by any explicit evidence in the source code, which only shows structural allocations and context pattern handling. This makes part of the description inaccurate, but less than half of the summary's details are unsupported, and the accurate portion provides some domain-specific insight into the memory structure."
            ]
        }
    }
}
{
    "source_code": "\n\nu_char *\nngx_proxy_protocol_write(ngx_connection_t *c, u_char *buf, u_char *last)\n{\n    ngx_uint_t  port, lport;\n\n    if (last - buf < NGX_PROXY_PROTOCOL_MAX_HEADER) {\n        return NULL;\n    }\n\n    if (ngx_connection_local_sockaddr(c, NULL, 0) != NGX_OK) {\n        return NULL;\n    }\n\n    switch (c->sockaddr->sa_family) {\n\n    case AF_INET:\n        buf = ngx_cpymem(buf, \"PROXY TCP4 \", sizeof(\"PROXY TCP4 \") - 1);\n        break;\n\n#if (NGX_HAVE_INET6)\n    case AF_INET6:\n        buf = ngx_cpymem(buf, \"PROXY TCP6 \", sizeof(\"PROXY TCP6 \") - 1);\n        break;\n#endif\n\n    default:\n        return ngx_cpymem(buf, \"PROXY UNKNOWN\" CRLF,\n                          sizeof(\"PROXY UNKNOWN\" CRLF) - 1);\n    }\n\n    buf += ngx_sock_ntop(c->sockaddr, c->socklen, buf, last - buf, 0);\n\n    *buf++ = ' ';\n\n    buf += ngx_sock_ntop(c->local_sockaddr, c->local_socklen, buf, last - buf,\n                         0);\n\n    port = ngx_inet_get_port(c->sockaddr);\n    lport = ngx_inet_get_port(c->local_sockaddr);\n\n    return ngx_slprintf(buf, last, \" %ui %ui\" CRLF, port, lport);\n}",
    "comment": "Constructs and writes a PROXY protocol header, including client and server IP addresses and ports, to the provided buffer.",
    "prorec_sum": "Constructs and writes a PROXY protocol header with source and destination addresses and ports for TCP4/TCP6 connections, or marks it as unknown.",
    "filter_prorec_sum": "Constructs and writes a PROXY protocol header with source and destination IP addresses and ports into the provided buffer based on the connection info.",
    "prorec_aug_sum": "Constructs and writes a PROXY protocol header with source and destination IP addresses and ports based on the connection\u2019s socket information.",
    "filter_prorec_aug_sum": "Constructs and writes a PROXY protocol line with source and destination IP addresses and ports based on the connection\u2019s sockaddr information.",
    "work_score": {
        "prorec": {
            "summary": "Constructs and writes a PROXY protocol header with source and destination addresses and ports for TCP4/TCP6 connections, or marks it as unknown.",
            "score": [
                1.0,
                0.8000000000000002,
                0.9
            ],
            "reason": [
                "The summary accurately states that the function constructs and writes a PROXY protocol header, includes source and destination addresses and ports, handles TCP4/TCP6, and marks unknown cases. Each of these details is explicitly supported by the source code: TCP4 and TCP6 strings are written depending on sa_family, addresses are obtained via ngx_sock_ntop for both remote and local sockaddrs, ports are retrieved with ngx_inet_get_port, and 'PROXY UNKNOWN' is used in the default case. No unverifiable assumptions or hallucinations are present.",
                "The summary accurately states that the function constructs and writes a PROXY protocol header containing source and destination addresses and ports for TCP4/TCP6 connections, and defaults to 'unknown' for other address families. These details are explicitly supported by the switch on sa_family, the ngx_sock_ntop calls for addresses, and ngx_inet_get_port calls for ports. The summary omits edge case handling, such as NULL returns when buffer space is insufficient or when local sockaddr retrieval fails, so while the core logic is captured, the completeness is not total.",
                "The summary correctly states that the function constructs and writes a PROXY protocol header, includes source and destination addresses and ports, differentiates between TCP4/TCP6, and marks unknown families accordingly. All these details are explicitly evidenced in the source code via the AF_INET/AF_INET6 cases, address copying with ngx_sock_ntop, and port retrieval with ngx_inet_get_port, making the summary accurate and domain-specific."
            ]
        },
        "filter_prorec": {
            "summary": "Constructs and writes a PROXY protocol header with source and destination IP addresses and ports into the provided buffer based on the connection info.",
            "score": [
                1.0,
                0.6666666666666666,
                0.7999999999999999
            ],
            "reason": [
                "The summary correctly states that the function constructs and writes a PROXY protocol header using source and destination IP addresses and ports based on the connection information. This is explicitly supported by the source code, which uses 'ngx_sock_ntop' to copy both remote and local addresses into the buffer and retrieves ports via 'ngx_inet_get_port'. No extraneous or unverified details are present, making all elements accurate.",
                "The summary accurately captures the main action: creating and writing a PROXY protocol header that includes source and destination IP addresses and their ports into the buffer based on the connection. This is supported by the code's use of ngx_cpymem to write the header, ngx_sock_ntop to output IP addresses, and ngx_inet_get_port to append the ports. However, the summary omits important control flow details such as the handling of different address families (AF_INET, AF_INET6, UNKNOWN), buffer length checks, and error handling when retrieving the local sockaddr, meaning it does not provide a complete picture of the logic.",
                "The summary claims the function writes a PROXY protocol header with source and destination IP addresses and ports based on connection info, which matches the code's use of ngx_sock_ntop to copy both remote and local addresses, and ngx_inet_get_port to append both ports. No inaccurate details are present, but the description is generic and lacks mention of specifics such as handling AF_INET/AF_INET6, buffer limits, or fallback to 'PROXY UNKNOWN'."
            ]
        }
    }
}
{
    "source_code": "\nint ext4_write_inline_data_end(struct inode *inode, loff_t pos, unsigned len,\n\t\t\t       unsigned copied, struct page *page)\n{\n\tint ret;\n\tvoid *kaddr;\n\tstruct ext4_iloc iloc;\n\n\tif (unlikely(copied < len)) {\n\t\tif (!PageUptodate(page)) {\n\t\t\tcopied = 0;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = ext4_get_inode_loc(inode, &iloc);\n\tif (ret) {\n\t\text4_std_error(inode->i_sb, ret);\n\t\tcopied = 0;\n\t\tgoto out;\n\t}\n\n\tdown_write(&EXT4_I(inode)->xattr_sem);\n\tBUG_ON(!ext4_has_inline_data(inode));\n\n\tkaddr = kmap_atomic(page);\n\text4_write_inline_data(inode, &iloc, kaddr, pos, len);\n\tkunmap_atomic(kaddr);\n\tSetPageUptodate(page);\n\t/* clear page dirty so that writepages wouldn't work for us. */\n\tClearPageDirty(page);\n\n\tup_write(&EXT4_I(inode)->xattr_sem);\n\tbrelse(iloc.bh);\nout:\n\treturn copied;\n}",
    "comment": "Writes inline data to the inode's page, marking it as up-to-date and clearing its dirty state after successfully copying the specified length.",
    "prorec_sum": "Finalizes and commits inline data writes in an ext4 inode, handling buffer access, journaling updates, and page state synchronization.",
    "filter_prorec_sum": "Finalizes writing of ext4 inline file data, performing journal access, buffer operations, and updating inode flags after successful or failed write attempts.",
    "prorec_aug_sum": "Handles completion of an ext4 inline data write, performing block allocation, updating inode and flags, and logging errors when necessary.",
    "filter_prorec_aug_sum": "Handles completion of ext4 inline data writes, updating inode state, performing required block operations, and logging errors when write constraints are violated.",
    "work_score": {
        "prorec": {
            "summary": "Finalizes and commits inline data writes in an ext4 inode, handling buffer access, journaling updates, and page state synchronization.",
            "score": [
                0.6,
                0.6,
                0.3333333333333333
            ],
            "reason": [
                "The summary correctly notes that the function deals with finalizing inline data writes in an ext4 inode and synchronizing page state, which is explicitly evident from the use of ext4_write_inline_data, SetPageUptodate, and ClearPageDirty. However, the mention of 'journaling updates' is inaccurate, as there is no explicit evidence of journaling mechanisms or log commits in the provided code; instead, error handling and data writes are performed without journal calls. This results in a mix of accurate and unverified details.",
                "The summary correctly notes that the function finalizes inline data writes in an ext4 inode and manages page state synchronization through SetPageUptodate, ClearPageDirty, and buffer mapping, which are evident in the source. However, it inaccurately mentions journaling updates, which have no explicit evidence in the code, and omits key control flow details such as error handling with ext4_get_inode_loc, ext4_std_error, and conditions involving copied < len and PageUptodate checks. As a result, the accurate details cover the main action but miss important logic steps.",
                "The summary claims handling of 'journaling updates', but there is no explicit journaling logic present in the source code. It also generalizes operations as 'finalizes and commits inline data writes', which partially aligns with the function's actual role of writing inline data, syncing page state, and managing buffer mapping. Buffer access and page state synchronization are accurate, evidenced by kmap_atomic/kunmap_atomic and SetPageUptodate/ClearPageDirty calls. However, since journaling updates are not supported by any explicit code lines, and only some details are accurate, less than half the details are incorrect. The accurate details are fairly generic rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Finalizes writing of ext4 inline file data, performing journal access, buffer operations, and updating inode flags after successful or failed write attempts.",
            "score": [
                0.4333333333333333,
                0.43333333333333335,
                0.0
            ],
            "reason": [
                "The summary correctly notes that the function finalizes writing of ext4 inline file data and handles operations after successful or failed attempts, which is supported by logic for copying data, calling ext4_write_inline_data, and conditionally setting 'copied' to 0. However, it inaccurately introduces 'journal access' and 'updating inode flags', which are not explicitly present in the source. No clear evidence of journaling calls or inode flag modifications exists, making some claims unverifiable.",
                "The summary mentions journal access and updating inode flags, but the source code contains no explicit journal-related operations or inode flag updates beyond setting and clearing page states. It also refers generally to buffer operations, which aligns partially with `kmap_atomic`, `kunmap_atomic`, and `brelse`, but omits key details like error handling for `ext4_get_inode_loc`, use of `xattr_sem` locking, inline data checks, and dirty-page clearing. The accurate details present are minimal and do not form a complete picture of the control flow.",
                "The summary introduces details such as 'performing journal access' and 'updating inode flags' that are not explicitly evidenced in the source code. The code handles ext4 inline data writing with buffer operations (`kmap_atomic`, `SetPageUptodate`, `ClearPageDirty`) and semaphore locking, but no journal-specific operations or explicit inode flag updates are present. More than half of the summary's claims are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "void luaS_resize(lua_State* L, int newsize) {\n  int i;\n  stringtable* tb = &G(L)->strt; // global string table\n  if (newsize > tb->size) { /* grow table if needed */\n    luaM_reallocvector(L, tb->hash, tb->size, newsize, TString*);\n    for (i = tb->size; i < newsize; i++)\n      // open hash table, tb->hash is the pointer for linked list\n      tb->hash[i] = NULL;\n  }\n  for (i = 0; i < tb->size; i++) { /* rehash */\n    TString* p = tb->hash[i];\n    tb->hash[i] = NULL;\n    while (p) { /* for each node in the list */\n      TString* hnext = p->u.hnext; /* save next */\n      unsigned int h = lmod(p->hash, newsize); /* new position */\n      p->u.hnext = tb->hash[h]; /* chain it */\n      tb->hash[h] = p;\n      p = hnext;\n    }\n  }\n  if (newsize < tb->size) { /* shrink table if needed */\n    /* vanishing slice should be empty */\n    lua_assert(tb->hash[newsize] == NULL && tb->hash[tb->size - 1] == NULL);\n    luaM_reallocvector(L, tb->hash, tb->size, newsize, TString*);\n  }\n  tb->size = newsize;\n}",
    "comment": "Resizes the global string table, rehashes existing strings, and reallocates memory based on the new size provided.",
    "prorec_sum": "Resizes a hash table\u2019s bucket array to the specified size and rehashes all existing entries into the new buckets.",
    "filter_prorec_sum": "Resizes a hash table\u2019s bucket array to the specified size and rehashes all existing entries into the new bucket layout.",
    "prorec_aug_sum": "Resizes a hash table\u2019s bucket array and rehashes all existing nodes into the new buckets, initializing any newly allocated entries to zero.",
    "filter_prorec_aug_sum": "Resizes a hash table\u2019s bucket array and rehashes all existing nodes into the new buckets, zero\u2011initializing any newly allocated entries.",
    "work_score": {
        "prorec": {
            "summary": "Resizes a hash table\u2019s bucket array to the specified size and rehashes all existing entries into the new buckets.",
            "score": [
                1.0,
                0.6666666666666666,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function resizes a hash table\u2019s bucket array and rehashes all existing entries into the new buckets, both of which are explicitly implemented in the source code. No additional unverified assumptions or missing details are present, making all semantic claims accurate.",
                "The summary accurately captures the core logic of resizing the hash table\u2019s bucket array and rehashing entries, which is explicitly evident in the code through the luaM_reallocvector calls, bucket initialization, and rehash loop. However, it omits specific edge-case handling such as the grow/shrink distinction, null-initialization of new buckets, and assertions when shrinking, meaning some important details from the source are missing.",
                "The summary accurately states that the function resizes a hash table\u2019s bucket array and rehashes existing entries into new buckets, which is explicitly supported by the code through allocation, nulling out old buckets, iterating entries, recalculating positions, and updating the size. No details are inaccurate, but the description is generic and lacks mention of specific structures like `stringtable`, `TString`, growth/shrink conditions, or linked list chaining logic."
            ]
        },
        "filter_prorec": {
            "summary": "Resizes a hash table\u2019s bucket array to the specified size and rehashes all existing entries into the new bucket layout.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function resizes a hash table\u2019s bucket array and rehashes existing entries, which is explicitly evidenced by the code's growth/shrink logic using luaM_reallocvector and the rehashing loop. There are no extra unsupported claims or hallucinations, making all details accurate.",
                "The summary is accurate in stating that the function resizes the hash table\u2019s bucket array and rehashes all entries, which is explicitly shown in the source code through growing or shrinking the vector and reassigning entries based on a recalculated position. However, it omits key details from the code such as conditional handling for both growth and shrink cases, initialization of new buckets to NULL, and the assertion ensuring empty slices when shrinking. These missing elements mean the summary does not fully capture the complete logic and edge cases present.",
                "The summary accurately describes the core operation of resizing the hash table and rehashing entries, which is clearly implemented in the source with growing, shrinking, and rehashing logic for `tb->hash`. There are no additional details to check for inaccuracy, so 100% of details are accurate. However, the description is generic and omits domain-specific insights such as the use of `luaM_reallocvector`, linked list chaining via `hnext`, and Lua's global string table context, limiting its depth."
            ]
        }
    }
}
{
    "source_code": "\nint ssl3_get_req_cert_type(SSL *s, unsigned char *p)\n\t{\n\tint ret=0;\n\tunsigned long alg_k;\n\n\talg_k = s->s3->tmp.new_cipher->algorithm_mkey;\n\n#ifndef OPENSSL_NO_GOST\n\tif (s->version >= TLS1_VERSION)\n\t\t{\n\t\tif (alg_k & SSL_kGOST)\n\t\t\t{\n\t\t\tp[ret++]=TLS_CT_GOST94_SIGN;\n\t\t\tp[ret++]=TLS_CT_GOST01_SIGN;\n\t\t\treturn(ret);\n\t\t\t}\n\t\t}\n#endif\n\n#ifndef OPENSSL_NO_DH\n\tif (alg_k & (SSL_kDHr|SSL_kEDH))\n\t\t{\n#  ifndef OPENSSL_NO_RSA\n\t\tp[ret++]=SSL3_CT_RSA_FIXED_DH;\n#  endif\n#  ifndef OPENSSL_NO_DSA\n\t\tp[ret++]=SSL3_CT_DSS_FIXED_DH;\n#  endif\n\t\t}\n\tif ((s->version == SSL3_VERSION) &&\n\t\t(alg_k & (SSL_kEDH|SSL_kDHd|SSL_kDHr)))\n\t\t{\n#  ifndef OPENSSL_NO_RSA\n\t\tp[ret++]=SSL3_CT_RSA_EPHEMERAL_DH;\n#  endif\n#  ifndef OPENSSL_NO_DSA\n\t\tp[ret++]=SSL3_CT_DSS_EPHEMERAL_DH;\n#  endif\n\t\t}\n#endif /* !OPENSSL_NO_DH */\n#ifndef OPENSSL_NO_RSA\n\tp[ret++]=SSL3_CT_RSA_SIGN;\n#endif\n#ifndef OPENSSL_NO_DSA\n\tp[ret++]=SSL3_CT_DSS_SIGN;\n#endif\n#ifndef OPENSSL_NO_ECDH\n\tif ((alg_k & (SSL_kECDHr|SSL_kECDHe)) && (s->version >= TLS1_VERSION))\n\t\t{\n\t\tp[ret++]=TLS_CT_RSA_FIXED_ECDH;\n\t\tp[ret++]=TLS_CT_ECDSA_FIXED_ECDH;\n\t\t}\n#endif\n\n#ifndef OPENSSL_NO_ECDSA\n\t/* ECDSA certs can be used with RSA cipher suites as well \n\t * so we don't need to check for SSL_kECDH or SSL_kEECDH\n\t */\n\tif (s->version >= TLS1_VERSION)\n\t\t{\n\t\tp[ret++]=TLS_CT_ECDSA_SIGN;\n\t\t}\n#endif\t\n\treturn(ret);\n\t}",
    "comment": "Determines and populates the required certificate types based on the SSL connection's cipher algorithms and version.",
    "prorec_sum": "Builds and returns a list of acceptable SSL/TLS client certificate types based on protocol version and configured capability flags.",
    "filter_prorec_sum": "Builds and returns a sequence of certificate type codes in `a2` based on connection version and option flags from the SSL session context.",
    "prorec_aug_sum": "Builds a list of acceptable SSL client certificate types in `a2` based on protocol version and capability flags, returning the list length.",
    "filter_prorec_aug_sum": "Generates a list of requested SSL certificate types based on connection version and capability flags, writing type codes into the provided buffer.",
    "work_score": {
        "prorec": {
            "summary": "Builds and returns a list of acceptable SSL/TLS client certificate types based on protocol version and configured capability flags.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function selects and returns acceptable SSL/TLS client certificate types based on protocol version and capability flags, which is explicitly reflected in the code through conditions on `s->version`, `alg_k`, and various certificate type constants before returning `ret`. No unsupported or incorrect claims are made, ensuring all semantic details are accurate.",
                "The summary correctly states that the function builds and returns acceptable SSL/TLS client certificate types based on protocol version and capability flags, which aligns with the code's use of `s->version` checks and `alg_k` capability masks to append specific certificate type constants to the output array. However, it omits explicit details of the certificate type additions, conditional compilation blocks, and edge cases such as handling of GOST, DH, ECDH, and ECDSA specifically, so it does not form a complete picture of the full logic.",
                "The summary correctly states that the function builds and returns a list of SSL/TLS client certificate types based on protocol version and capability flags, which matches the code\u2019s logic in ssl3_get_req_cert_type using s->version and algorithm flags to populate an array. However, it omits specific details such as the inclusion of GOST, DH, RSA, DSA, and ECDSA types, making the description generic rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Builds and returns a sequence of certificate type codes in `a2` based on connection version and option flags from the SSL session context.",
            "score": [
                0.7000000000000001,
                0.5666666666666668,
                0.13333333333333333
            ],
            "reason": [
                "The summary incorrectly names the output buffer as 'a2' instead of 'p', which is the parameter used in the code. While it correctly states that the function builds and returns certificate type codes, it omits the detailed conditional checks for algorithm flags and protocol versions that drive the sequence construction. The claim about 'option flags from the SSL session context' is partially supported by the use of the algorithm_mkey field, but the overall description lacks specificity and contains at least one inaccurate detail.",
                "The summary captures the general purpose of building and returning a sequence of certificate type codes based on the SSL session context and connection version, which is accurate as the function constructs an array `p` indexed by `ret` with various certificate type constants based on version and algorithm flags. However, it inaccurately names the output variable as `a2` instead of `p`, and omits key logic details such as multiple conditional checks for specific algorithm types (GOST, DH, RSA, DSA, ECDH, ECDSA) and the influence of compile-time flags. These omissions mean the description covers the main action but lacks significant logic detail.",
                "The summary inaccurately states that the sequence is built in `a2`, whereas the source code clearly uses the pointer `p` for storing certificate type codes. It also omits key specifics such as the multiple conditional checks for algorithm types (GOST, DH, RSA, DSA, ECDH, ECDSA) and version constraints, which are evident in the source. The only accurate element is that codes are built based on connection version and session context, but the majority of the details are either incorrect or overly vague, exceeding the 50% inaccuracy threshold."
            ]
        }
    }
}
{
    "source_code": "\nstatic void e1000_get_wol(struct net_device *netdev,\n\t\t\t  struct ethtool_wolinfo *wol)\n{\n\tstruct e1000_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\twol->supported = WAKE_UCAST | WAKE_MCAST |\n\t                 WAKE_BCAST | WAKE_MAGIC;\n\twol->wolopts = 0;\n\n\t/* this function will set ->supported = 0 and return 1 if wol is not\n\t * supported by this hardware\n\t */\n\tif (e1000_wol_exclusion(adapter, wol) ||\n\t    !device_can_wakeup(&adapter->pdev->dev))\n\t\treturn;\n\n\t/* apply any specific unsupported masks here */\n\tswitch (hw->device_id) {\n\tcase E1000_DEV_ID_82546GB_QUAD_COPPER_KSP3:\n\t\t/* KSP3 does not support UCAST wake-ups */\n\t\twol->supported &= ~WAKE_UCAST;\n\n\t\tif (adapter->wol & E1000_WUFC_EX)\n\t\t\te_err(drv, \"Interface does not support directed \"\n\t\t\t      \"(unicast) frame wake-up packets\\n\");\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (adapter->wol & E1000_WUFC_EX)\n\t\twol->wolopts |= WAKE_UCAST;\n\tif (adapter->wol & E1000_WUFC_MC)\n\t\twol->wolopts |= WAKE_MCAST;\n\tif (adapter->wol & E1000_WUFC_BC)\n\t\twol->wolopts |= WAKE_BCAST;\n\tif (adapter->wol & E1000_WUFC_MAG)\n\t\twol->wolopts |= WAKE_MAGIC;\n}",
    "comment": "Configures wake-on-LAN options for the network device based on adapter capabilities and supported wake-up frame types.",
    "prorec_sum": "Configures wake-up packet capabilities in a device context based on hardware flags, interface support, and specific status values.",
    "filter_prorec_sum": "Configures wake-up capability flags in the provided structure based on device status and supported frame types indicated by bitfields in the control data.",
    "prorec_aug_sum": "Configures wake-up capability flags in the provided structure based on hardware state and supported packet types retrieved from the device context.",
    "filter_prorec_aug_sum": "Configures wake-up packet capability flags in the output structure based on hardware status bits and interface support checks.",
    "work_score": {
        "prorec": {
            "summary": "Configures wake-up packet capabilities in a device context based on hardware flags, interface support, and specific status values.",
            "score": [
                1.0,
                0.6,
                0.5666666666666668
            ],
            "reason": [
                "The summary broadly states that the code configures wake-up packet capabilities based on hardware flags, interface support, and specific status values, which is accurate given the function sets 'wol->supported' and 'wol->wolopts' according to hardware device_id, adapter flags, and wake-up support checks. No extraneous or unverifiable details are introduced, so all elements in the summary are supported by the source code.",
                "The summary accurately reflects the core logic of configuring wake-up capabilities in the device context based on hardware flags and interface support. It aligns with the source code, which checks hardware support via e1000_wol_exclusion, applies a device-specific mask for certain hardware IDs, and sets wolopts based on adapter flags. However, the summary omits specific details such as clearing WAKE_UCAST for a specific device, error logging, and handling of multiple wake-up types, which means it does not provide a complete picture of the code\u2019s logic and edge cases.",
                "The summary correctly notes that the function configures wake-up packet capabilities based on hardware flags and interface support, which are evidenced by logic checking adapter->wol flags and device wakeup capability. However, it omits specifics such as the mask adjustments for certain device IDs and the initialization of supported wake types. These omissions make the accurate details generic rather than domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Configures wake-up capability flags in the provided structure based on device status and supported frame types indicated by bitfields in the control data.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function configures wake-up capability flags in a structure using device status and supported frame types from bitfields. This matches the source code where 'wol->supported' and 'wol->wolopts' are set based on hardware capability checks and bitfields in 'adapter->wol'. There are no extraneous or unverified claims, and the description aligns with the actual logic and data types present.",
                "The summary accurately states that the code configures wake-up capability flags in a provided structure based on device status and supported frame types indicated by bitfields, which matches the setting of 'supported' and 'wolopts' fields conditional on hardware/device ID and 'adapter->wol' bitmask values. However, it omits critical details such as specific wake types (WAKE_UCAST, WAKE_MCAST, WAKE_BCAST, WAKE_MAGIC), exclusion checks, device-specific adjustments, and associated error logging, resulting in an incomplete representation of the logic.",
                "The summary mentions configuration of wake-up capability flags based on device status and supported frame types via bitfields, which is explicitly reflected in the source code through assignments to the 'supported' and 'wolopts' fields of 'wol' using WAKE_* constants and conditional checks on 'adapter->wol'. All details are accurate but remain generic, lacking specifics such as the exclusion logic for certain device IDs or exact constants used, limiting domain-rich insight."
            ]
        }
    }
}
{
    "source_code": "\nint intel_pmu_setup_lbr_filter(struct perf_event *event)\n{\n\tint ret = 0;\n\n\t/*\n\t * no LBR on this PMU\n\t */\n\tif (!x86_pmu.lbr_nr)\n\t\treturn -EOPNOTSUPP;\n\n\t/*\n\t * setup SW LBR filter\n\t */\n\tret = intel_pmu_setup_sw_lbr_filter(event);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * setup HW LBR filter, if any\n\t */\n\tif (x86_pmu.lbr_sel_map)\n\t\tret = intel_pmu_setup_hw_lbr_filter(event);\n\n\treturn ret;\n}",
    "comment": "Configures both software and hardware LBR filters for a performance event if LBR support is available on the PMU.",
    "prorec_sum": "Configures device state flags from control bits at offset 232, validates conditions, and updates related registers and masks for subsequent hardware operations.",
    "filter_prorec_sum": "Configures flags in a device context from its mode bits, applies additional masks, and updates capability mappings based on a global configuration table.",
    "prorec_aug_sum": "Configures flags and masks in a CPU-related structure based on control bits, validating conditions and updating associated hardware state information.",
    "filter_prorec_aug_sum": "Configures CPU-related flags from a task structure\u2019s field and updates control masks, returning specific error codes on invalid or disallowed configurations.",
    "work_score": {
        "prorec": {
            "summary": "Configures device state flags from control bits at offset 232, validates conditions, and updates related registers and masks for subsequent hardware operations.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes configuring device state flags from control bits at a specific offset, performing condition validation, and updating registers and masks, but none of these operations are present in the source code. The actual code checks if LBR is supported by the PMU, sets up software and optional hardware LBR filters, and returns a status. All details in the summary are unsupported, making them hallucinations.",
                "The summary describes configuring device state flags from control bits at a specific offset, validating conditions, and updating registers and masks, but the source code only sets up LBR filters for a PMU by checking availability, configuring software filters, and optionally hardware filters. None of the details in the summary align with any explicit code structures or operations in the source, so all claims are inaccurate, leaving no valid content to represent the core logic.",
                "The summary claims configuration of device state flags from control bits at offset 232, validation of conditions, and updates to registers and masks, none of which are present in the source code. The source code only sets up software and hardware LBR filters for PMU events using specific function calls and checks against x86_pmu fields. All details in the summary are inaccurate, exceeding the threshold for the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Configures flags in a device context from its mode bits, applies additional masks, and updates capability mappings based on a global configuration table.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes configuring flags from mode bits, applying masks, and updating capability mappings from a global table, none of which are present in the source code. The actual code handles LBR filter setup by calling functions to configure software and hardware filters based on PMU properties. All details in the summary are hallucinations with no explicit evidence in the source code, leading to complete inaccuracy.",
                "The summary describes configuring flags from mode bits, applying masks, and updating capability mappings using a global configuration table, but none of these concepts or operations appear in the source code. The actual code handles LBR filter setup for a performance event, checking hardware support, and calling specific setup functions, which is unrelated to the summary. After discarding the inaccurate details, no accurate content remains.",
                "The summary describes configuring flags in a device context, applying masks, and updating capability mappings from a global table, but none of these actions are explicitly present in the source code. The code instead checks for LBR support, sets up software and possibly hardware LBR filters, and returns appropriate status codes. Since all semantic details in the summary are inaccurate and not supported by the source code, the proportion of inaccuracies exceeds the threshold, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic int __init dquot_init(void)\n{\n\tint i, ret;\n\tunsigned long nr_hash, order;\n\n\tprintk(KERN_NOTICE \"VFS: Disk quotas %s\\n\", __DQUOT_VERSION__);\n\n\tregister_sysctl_table(sys_table);\n\n\tdquot_cachep = kmem_cache_create(\"dquot\",\n\t\t\tsizeof(struct dquot), sizeof(unsigned long) * 4,\n\t\t\t(SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|\n\t\t\t\tSLAB_MEM_SPREAD|SLAB_PANIC),\n\t\t\tNULL);\n\n\torder = 0;\n\tdquot_hash = (struct hlist_head *)__get_free_pages(GFP_ATOMIC, order);\n\tif (!dquot_hash)\n\t\tpanic(\"Cannot create dquot hash table\");\n\n\tfor (i = 0; i < _DQST_DQSTAT_LAST; i++) {\n\t\tret = percpu_counter_init(&dqstats.counter[i], 0);\n\t\tif (ret)\n\t\t\tpanic(\"Cannot create dquot stat counters\");\n\t}\n\n\t/* Find power-of-two hlist_heads which can fit into allocation */\n\tnr_hash = (1UL << order) * PAGE_SIZE / sizeof(struct hlist_head);\n\tdq_hash_bits = 0;\n\tdo {\n\t\tdq_hash_bits++;\n\t} while (nr_hash >> dq_hash_bits);\n\tdq_hash_bits--;\n\n\tnr_hash = 1UL << dq_hash_bits;\n\tdq_hash_mask = nr_hash - 1;\n\tfor (i = 0; i < nr_hash; i++)\n\t\tINIT_HLIST_HEAD(dquot_hash + i);\n\n\tprintk(\"Dquot-cache hash table entries: %ld (order %ld, %ld bytes)\\n\",\n\t\t\tnr_hash, order, (PAGE_SIZE << order));\n\n\tregister_shrinker(&dqcache_shrinker);\n\n\treturn 0;\n}",
    "comment": "Initializes the disk quota subsystem by creating a cache, allocating a hash table, and setting up statistical counters.",
    "prorec_sum": "Initializes the dquot subsystem by allocating its hash table, setting up statistic counters, and logging the configured cache table parameters.",
    "filter_prorec_sum": "Initializes quota (\u201cdquot\u201d) subsystem by allocating hash table, setting up statistics counters, computing order and size, and reporting configuration details.",
    "prorec_aug_sum": "Initializes the dquot subsystem by allocating the hash table, setting up statistical counters, and logging cache table configuration details.",
    "filter_prorec_aug_sum": "Initializes in-memory quota (dquot) structures by allocating caches and hash table, zeroing entries, and setting up associated statistics counters.",
    "work_score": {
        "prorec": {
            "summary": "Initializes the dquot subsystem by allocating its hash table, setting up statistic counters, and logging the configured cache table parameters.",
            "score": [
                1.0,
                0.6,
                0.7999999999999999
            ],
            "reason": [
                "The summary captures three core details: allocation of the hash table, initialization of statistic counters, and logging cache table parameters. All of these actions are explicitly evidenced in the source code through calls to __get_free_pages for the hash table, percpu_counter_init for counters, and printk statements showing cache parameters. No unverified assumptions or hallucinations are present, resulting in complete accuracy per the evaluation steps.",
                "The summary accurately states that the function initializes the dquot subsystem, allocates the hash table, sets up statistic counters, and logs cache table parameters, all of which are explicitly shown in the source code via kmem_cache_create, __get_free_pages, percpu_counter_init loops, printk statements, and related initialization steps. However, it omits other key actions present in the code, such as registering sysctl tables, handling error cases with panic calls, computing hash bits and masks, initializing each hash bucket, and registering the shrinker, which limits completeness.",
                "The summary captures key accurate details: the function initializes the dquot subsystem, allocates its hash table, sets up statistic counters via percpu_counter_init, and logs cache table parameters using printk. All these elements are explicitly present in the source code. However, the summary is somewhat generic and omits richer specifics like kmem_cache_create usage, order/nr_hash calculations, and shrinker registration, reducing the domain insight provided."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes quota (\u201cdquot\u201d) subsystem by allocating hash table, setting up statistics counters, computing order and size, and reporting configuration details.",
            "score": [
                1.0,
                0.7000000000000001,
                0.8333333333333334
            ],
            "reason": [
                "The summary correctly states that the function initializes the quota subsystem, allocates a hash table, sets up statistics counters, computes order and size, and reports configuration details. All these elements are explicitly found in the source code through calls like kmem_cache_create, __get_free_pages, percpu_counter_init, calculation of nr_hash/order, and printk statements. There are no unverified or hallucinated details, resulting in full alignment with the source.",
                "The summary accurately reflects several key semantic units from the source code: initialization of the dquot subsystem, allocation of the hash table via __get_free_pages, setup of statistics counters using percpu_counter_init, computation of size and order, and printing configuration details with printk. These elements are explicitly present in the code. However, it omits notable actions such as creating a slab cache with kmem_cache_create, initializing hlist heads, registering sysctl table and shrinker, and handling panic conditions. The accurate details represent the main actions but miss important control flow and edge-case handling, reducing completeness.",
                "The summary includes accurate details: it describes initialization of the quota subsystem, allocation of the hash table (`dquot_hash`), setup of statistics counters (`percpu_counter_init` for `dqstats.counter`), computation of hash size (`dq_hash_bits`, `nr_hash`, `order`), and logging of configuration via `printk`. All these steps are explicitly present in the source code and match the logic and variable names used. While the summary omits some specific functions like cache creation and sysctl registration, the reported details are domain-relevant and informative rather than generic."
            ]
        }
    }
}
{
    "source_code": "static int netlbl_unlabel_list(struct sk_buff *skb, struct genl_info *info)\n{\n\tint ret_val = -EINVAL;\n\tstruct sk_buff *ans_skb;\n\tvoid *data;\n\n\tans_skb = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\n\tif (ans_skb == NULL)\n\t\tgoto list_failure;\n\tdata = genlmsg_put_reply(ans_skb, info, &netlbl_unlabel_gnl_family,\n\t\t\t\t 0, NLBL_UNLABEL_C_LIST);\n\tif (data == NULL) {\n\t\tret_val = -ENOMEM;\n\t\tgoto list_failure;\n\t}\n\n\tret_val = nla_put_u8(ans_skb,\n\t\t\t     NLBL_UNLABEL_A_ACPTFLG,\n\t\t\t     netlabel_unlabel_acceptflg);\n\tif (ret_val != 0)\n\t\tgoto list_failure;\n\n\tgenlmsg_end(ans_skb, data);\n\treturn genlmsg_reply(ans_skb, info);\n\nlist_failure:\n\tkfree_skb(ans_skb);\n\treturn ret_val;\n}",
    "comment": "Generates and replies with a netlabel unlabeling response containing an acceptance flag in a netlink message or returns an error.",
    "prorec_sum": "Initializes a data structure with provided parameters, applies a configuration byte, updates an offset field, and invokes a final processing routine returning its status.",
    "filter_prorec_sum": "Configures and initializes a network-related object, applies one byte setting, updates internal offsets, and invokes a final operation, returning any encountered error code.",
    "prorec_aug_sum": "Initializes a data structure, configures it with provided parameters, and invokes further processing, returning error codes on allocation or setup failure.",
    "filter_prorec_aug_sum": "Allocates and initializes a network-related structure, configures it with provided parameters, then performs a final operation and returns success or an error code.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a data structure with provided parameters, applies a configuration byte, updates an offset field, and invokes a final processing routine returning its status.",
            "score": [
                0.20000000000000004,
                0.20000000000000004,
                0.0
            ],
            "reason": [
                "The summary's claims about initializing a data structure with provided parameters, applying a configuration byte, and updating an offset field are not explicitly present in the source code. The source initializes an sk_buff, puts reply data, sets a flag with nla_put_u8, and sends the reply, but there is no evidence of an offset field update or a general 'final processing routine' exactly as described. Most details are either inaccurate or unverifiable from the given code, resulting in a low accuracy ratio.",
                "The summary describes initializing a data structure with provided parameters, applying a configuration byte, updating an offset field, and invoking a final processing routine. In the source code, there is initialization of ans_skb via nlmsg_new, insertion of a value via nla_put_u8, and final reply processing via genlmsg_reply, but there is no evidence of an 'offset field' update or generalized configuration byte concept beyond the specific accept flag, nor are 'provided parameters' explicitly used to initialize a structure in the way described. Most claims are inaccurate, leaving only partial alignment with the actual logic.",
                "The summary claims initialization with provided parameters, applying a configuration byte, updating an offset field, and invoking a final processing routine. In the source code, there is allocation of an sk_buff, message setup with genlmsg_put_reply, insertion of a single byte using nla_put_u8, and a reply routine. There is no evidence of an 'offset field' update, nor of generalized 'configuration byte' in the sense described, making most details inaccurate. More than half of the details are hallucinated, triggering the kill switch."
            ]
        },
        "filter_prorec": {
            "summary": "Configures and initializes a network-related object, applies one byte setting, updates internal offsets, and invokes a final operation, returning any encountered error code.",
            "score": [
                0.5333333333333333,
                0.39999999999999997,
                0.16666666666666666
            ],
            "reason": [
                "The summary includes several inaccuracies. While the source code does configure a network-related object and apply a one-byte setting via `nla_put_u8`, there is no explicit evidence of 'initializing' in a general sense beyond object allocation, nor of 'updating internal offsets' as stated. The final operation is correctly noted as returning a value from `genlmsg_reply`, but the claim about returning 'any encountered error code' is partially inaccurate because it conditionally returns `ret_val` only on failure paths. Overall, only about half of the stated details are explicitly supported in the source, with the rest being unverified or incorrect.",
                "The summary contains inaccuracies: there is no evidence in the source code of configuring a general network-related object or updating internal offsets. The code specifically allocates a new sk_buff, prepares a generic netlink message, sets a single byte accept flag, handles possible memory errors, and sends a reply, with cleanup. Of the summary's details, only the one-byte setting and final operation (reply) are accurate. Significant parts of the main logic, like allocation, error checks, and cleanup, are missing, resulting in incomplete coverage of the function's actions.",
                "The summary contains multiple inaccuracies: it claims configuration and initialization of a network-related object without specifying accurate function calls like nlmsg_new or genlmsg_put_reply, mentions 'updates internal offsets' which is not evidenced in the code, and omits explicit references to flags and skb memory handling present in the source. Only the 'applies one byte setting' vaguely matches nla_put_u8 usage, meaning over 50% of details are inaccurate, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nvoid\nS_SET_EXTERNAL (symbolS *s)\n{\n  if (LOCAL_SYMBOL_CHECK (s))\n    s = local_symbol_convert ((struct local_symbol *) s);\n  if ((s->bsym->flags & BSF_WEAK) != 0)\n    {\n      /* Let .weak override .global.  */\n      return;\n    }\n  if (s->bsym->flags & BSF_SECTION_SYM)\n    {\n      /* Do not reassign section symbols.  */\n      as_warn (_(\"section symbols are already global\"));\n      return;\n    }\n#ifndef TC_GLOBAL_REGISTER_SYMBOL_OK\n  if (S_GET_SEGMENT (s) == reg_section)\n    {\n      as_bad (\"can't make register symbol `%s' global\",\n\t      S_GET_NAME (s));\n      return;\n    }\n#endif\n  s->bsym->flags |= BSF_GLOBAL;\n  s->bsym->flags &= ~(BSF_LOCAL | BSF_WEAK);\n\n#ifdef TE_PE\n  if (! an_external_name && S_GET_NAME(s)[0] != '.')\n    an_external_name = S_GET_NAME (s);\n#endif\n}",
    "comment": "Sets a symbol as global, overriding weak and local flags while preventing reassignment of section or register symbols.",
    "prorec_sum": "Marks a section's symbol as global unless it is a register symbol, otherwise reports an error using localized diagnostic messages.",
    "filter_prorec_sum": "Marks a symbol as global, unless it is a register symbol or already global, displaying appropriate error messages when those conditions occur.",
    "prorec_aug_sum": "Marks a section symbol as global unless it is a register symbol, otherwise issues an error indicating register symbols cannot be made global.",
    "filter_prorec_aug_sum": "Marks a section symbol as global unless it is already global or represents a register symbol, issuing errors for prohibited cases.",
    "work_score": {
        "prorec": {
            "summary": "Marks a section's symbol as global unless it is a register symbol, otherwise reports an error using localized diagnostic messages.",
            "score": [
                0.6999999999999998,
                0.6,
                0.0
            ],
            "reason": [
                "The summary correctly notes that the function marks symbols as global and that register symbols cause an error, and it mentions use of diagnostic messages, all of which are explicitly shown in the code through setting BSF_GLOBAL, checking reg_section, and calling as_bad/as_warn. However, the summary omits key logic about weak symbols and section symbols and simplifies the condition to 'unless it is a register symbol', which is incomplete and therefore slightly inaccurate.",
                "The summary accurately reflects that the function marks a symbol as global unless it is a register symbol, in which case it reports an error, and that diagnostic messages are used. However, it omits other critical conditions from the code, such as skipping modification for weak symbols or section symbols, and related warning messages. As a result, it captures only part of the core logic while missing significant branches and edge cases.",
                "The summary omits multiple explicit conditions from the source code, such as early returns for weak symbols and section symbols, and does not mention setting or clearing BSF_GLOBAL, BSF_LOCAL, and BSF_WEAK flags. While it correctly notes that section symbols can be made global unless they are register symbols and that an error is reported for register symbols with localized diagnostics, more than half of the described logic steps are inaccurate or missing compared to the source code."
            ]
        },
        "filter_prorec": {
            "summary": "Marks a symbol as global, unless it is a register symbol or already global, displaying appropriate error messages when those conditions occur.",
            "score": [
                0.6,
                0.5333333333333333,
                0.0
            ],
            "reason": [
                "The summary correctly notes that the function marks a symbol as global and prevents this for register symbols with an error message, which is accurate. However, it inaccurately states 'unless it is... already global'; the source code actually prevents reassignment for section symbols and weak symbols, not based on already being global. It also omits important conditions regarding weak flags and section symbols, indicating mixed accuracy.",
                "The summary correctly identifies that the function marks a symbol as global and skips certain cases such as register symbols, issuing an error message in that case. However, it inaccurately states 'already global' as a skip condition, whereas the source code actually skips weak symbols and section symbols (with a warning) before reaching the register symbol case. The 'already global' phrasing does not match the code's actual flags checks, so this omits and misrepresents significant logic, including handling of BSF_WEAK and BSF_SECTION_SYM.",
                "The summary omits key conditions found in the source code, such as handling of weak symbols where the function returns early, section symbols triggering warnings, and conversion of local symbols. It inaccurately states that register symbols are prevented from being made global and that already-global symbols trigger errors without clarifying that section symbols receive warnings instead. These inaccuracies constitute more than half of the described behaviors, making the overall summary misleading."
            ]
        }
    }
}
{
    "source_code": "\nint FAST_FUNC ll_addr_a2n(unsigned char *lladdr, int len, char *arg)\n{\n\tint i;\n\n\tif (strchr(arg, '.')) {\n\t\tinet_prefix pfx;\n\t\tif (get_addr_1(&pfx, arg, AF_INET)) {\n\t\t\tbb_error_msg(\"\\\"%s\\\" is invalid lladdr\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tif (len < 4) {\n\t\t\treturn -1;\n\t\t}\n\t\tmemcpy(lladdr, pfx.data, 4);\n\t\treturn 4;\n\t}\n\n\tfor (i = 0; i < len; i++) {\n\t\tint temp;\n\t\tchar *cp = strchr(arg, ':');\n\t\tif (cp) {\n\t\t\t*cp = 0;\n\t\t\tcp++;\n\t\t}\n\t\tif (sscanf(arg, \"%x\", &temp) != 1 || (temp < 0 || temp > 255)) {\n\t\t\tbb_error_msg(\"\\\"%s\\\" is invalid lladdr\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tlladdr[i] = temp;\n\t\tif (!cp) {\n\t\t\tbreak;\n\t\t}\n\t\targ = cp;\n\t}\n\treturn i+1;\n}",
    "comment": "Converts a string representation of a link-layer address to its binary format, supporting both IPv4 addresses and hexadecimal notation.",
    "prorec_sum": "Parses and validates a link-layer address string, storing its bytes into the output buffer or reporting an error if the format is invalid.",
    "filter_prorec_sum": "Parses and validates a MAC address string in dot- or colon-separated format, storing parsed bytes into the provided buffer and reporting errors for invalid input.",
    "prorec_aug_sum": "Parses a MAC address string in colon or dotted format, validating each byte and storing the result into the provided output buffer.",
    "filter_prorec_aug_sum": "Parses a MAC address string in dot or colon notation into bytes, validating format and returning length or error on invalid input.",
    "work_score": {
        "prorec": {
            "summary": "Parses and validates a link-layer address string, storing its bytes into the output buffer or reporting an error if the format is invalid.",
            "score": [
                1.0,
                0.6333333333333333,
                0.6
            ],
            "reason": [
                "The summary correctly captures the core functionality: the function processes a link-layer address string, populates the output buffer, and reports an error on invalid formats. These behaviors are explicitly evident in the code through `lladdr` assignment, use of `bb_error_msg` for errors, and parsing logic for dotted or colon-separated formats. There are no extraneous or unverified claims, so all details are accurate.",
                "The summary accurately reflects the core function, which parses a link-layer address string, validates each component, stores valid bytes into the provided buffer, and reports an error for invalid formats. However, it omits specific branches in logic, such as handling dotted decimal IPv4-like input separately, checking length constraints, and returning specific sizes depending on format. These omissions mean it captures the main action but misses significant control flow details.",
                "The summary correctly conveys the high-level purpose of the function: parsing and validating a link-layer address string, storing its bytes into an output buffer, and producing an error message if invalid. These details are supported by explicit evidence in the source code, such as parsing via `sscanf`, validation checks, `memcpy` for byte storage, and `bb_error_msg` calls on invalid formats. However, the description is generic and omits specific logic paths (e.g., IPv4 detection using '.' and AF_INET handling), making the details less domain-rich."
            ]
        },
        "filter_prorec": {
            "summary": "Parses and validates a MAC address string in dot- or colon-separated format, storing parsed bytes into the provided buffer and reporting errors for invalid input.",
            "score": [
                0.43333333333333335,
                0.7666666666666666,
                0.19999999999999998
            ],
            "reason": [
                "The summary claims the function parses and validates MAC addresses in both dot- and colon-separated formats, but the source code shows that the dot-separated path uses get_addr_1 with AF_INET and expects IPv4 addresses, not MAC addresses. While the colon-separated parsing matches the code's byte-by-byte hex parsing, the MAC-specific terminology is inaccurate. Given only one detail about colon-separated parsing is accurate, and the MAC address claim is a hallucination, the majority of semantic details are unverified or incorrect.",
                "The summary accurately captures that the function parses and validates an address string in dot-separated (IPv4) or colon-separated format, writes parsed bytes into the provided buffer, and reports an error for invalid input, all of which are explicitly evident in the source code. However, it incorrectly specifies 'MAC address', which is not confirmed by the code\u2014the logic supports parsing generic link-layer addresses with variable lengths. This mislabeling slightly reduces completeness but the core parsing and validation logic is correctly represented.",
                "The summary claims the function parses and validates a MAC address in dot- or colon-separated format, which is partially inaccurate. The source code supports colon-separated parsing logic, but the dot-separated case uses `get_addr_1` with `AF_INET` and copies 4 bytes from an IPv4 address, indicating it parses IPv4 dotted decimal strings, not MAC addresses. This makes the dot-format MAC address claim incorrect. Since 50% of the key details are inaccurate, the kill switch applies and the evaluation stops."
            ]
        }
    }
}
{
    "source_code": "\nstatic void __activate_page(struct page *page, struct lruvec *lruvec,\n\t\t\t    void *arg)\n{\n\tif (PageLRU(page) && !PageActive(page) && !PageUnevictable(page)) {\n\t\tint file = page_is_file_cache(page);\n\t\tint lru = page_lru_base_type(page);\n\n\t\tdel_page_from_lru_list(page, lruvec, lru);\n\t\tSetPageActive(page);\n\t\tlru += LRU_ACTIVE;\n\t\tadd_page_to_lru_list(page, lruvec, lru);\n\n\t\t__count_vm_event(PGACTIVATE);\n\t\tupdate_page_reclaim_stat(lruvec, file, 1);\n\t}\n}",
    "comment": "Activates a page by removing it from the LRU list and updating its status if it is inactive and eligible for activation.",
    "prorec_sum": "Links a flagged memory control structure into zone statistics lists, updates related counters, and marks it as processed in the memory cgroup.",
    "filter_prorec_sum": "Transfers a memory-related object between linked lists, updates status flags and counters, and records zone statistics for a memory cgroup.",
    "prorec_aug_sum": "Handles state transition of an object flagged with 0x20, updating linked pointers, invoking sub_FFFFFFFF81101110, and incrementing related statistical counters.",
    "filter_prorec_aug_sum": "Updates linked list pointers and state flags for an object when specific bit conditions are met, invoking helper routines and incrementing related statistical counters.",
    "work_score": {
        "prorec": {
            "summary": "Links a flagged memory control structure into zone statistics lists, updates related counters, and marks it as processed in the memory cgroup.",
            "score": [
                0.06666666666666667,
                0.09999999999999999,
                0.0
            ],
            "reason": [
                "The summary claims involvement with a flagged memory control structure, zone statistics lists, and memory cgroup processing, none of which are explicitly present in the source code. The code operates on page structures, checking flags like PageLRU, PageActive, and PageUnevictable, manipulating LRU lists, and updating VM events and reclaim stats. There is no mention of zone statistics lists or memory cgroups, making all key details in the summary inaccurate.",
                "The summary's claims about linking a flagged memory control structure into zone statistics lists, marking it as processed in the memory cgroup, and updating related counters are inaccurate. The source code explicitly shows activation of a page in LRU lists with checks on PageLRU, PageActive, and PageUnevictable, removal and addition to LRU lists, setting the page active, incrementing counters like PGACTIVATE, and updating reclaim stats. There is no evidence of zone statistics lists or memory cgroup marking. As all summary details are hallucinated, the core logic of the code is entirely missed.",
                "The summary claims linking a flagged memory control structure into zone statistics lists and marking it as processed in the memory cgroup, but the source code instead manipulates pages in LRU lists, sets the page active, and updates VM event counts and reclaim stats. None of the summary\u2019s specific claims about zone statistics lists or memory cgroup are explicitly supported, making all details inaccurate and triggering the kill switch due to >50% inaccuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Transfers a memory-related object between linked lists, updates status flags and counters, and records zone statistics for a memory cgroup.",
            "score": [
                0.6333333333333333,
                0.6,
                0.4666666666666666
            ],
            "reason": [
                "The summary correctly notes that the function transfers a memory-related object between linked lists, updates a status flag, and increments counters, which are explicitly shown in the code where a page is moved from one LRU list to another, SetPageActive is called, and __count_vm_event is incremented. However, the summary inaccurately claims it records zone statistics for a memory cgroup\u2014there is no explicit evidence in the code of zone-level recording or memory cgroup handling; update_page_reclaim_stat deals with reclaim stats at the lruvec level, not necessarily memory cgroup zone statistics. This mix of accurate and hallucinated details results in moderate alignment.",
                "The summary correctly notes that the function moves a memory-related object between linked lists, updates status flags, and increments counters, which matches the del/add list operations, SetPageActive call, __count_vm_event, and update_page_reclaim_stat in the code. However, the claim about recording zone statistics for a memory cgroup is inaccurate, as the code only updates page reclaim statistics via lruvec without explicit zone or memory cgroup handling. While the accurate details cover the main actions, they omit conditional checks (PageLRU, !PageActive, !PageUnevictable) and data type usage (int file, int lru), meaning the description is not fully complete.",
                "The summary mentions transferring a memory-related object between linked lists, updating status flags and counters, which is supported by the code\u2019s operations (`del_page_from_lru_list`, `SetPageActive`, `add_page_to_lru_list`, `__count_vm_event`). However, it inaccurately claims recording zone statistics for a memory cgroup, as the code only calls `update_page_reclaim_stat` with `lruvec` and does not explicitly refer to zone statistics or memory cgroups. With one inaccurate detail out of four (~25%), the proportion is under the kill switch threshold, but the accurate parts are generic rather than deeply domain-rich."
            ]
        }
    }
}
{
    "source_code": "\nstatic void unix_sock_destructor(struct sock *sk)\n{\n\tstruct unix_sock *u = unix_sk(sk);\n\n\tskb_queue_purge(&sk->sk_receive_queue);\n\n\tWARN_ON(atomic_read(&sk->sk_wmem_alloc));\n\tWARN_ON(!sk_unhashed(sk));\n\tWARN_ON(sk->sk_socket);\n\tif (!sock_flag(sk, SOCK_DEAD)) {\n\t\tprintk(KERN_INFO \"Attempt to release alive unix socket: %p\\n\", sk);\n\t\treturn;\n\t}\n\n\tif (u->addr)\n\t\tunix_release_addr(u->addr);\n\n\tatomic_long_dec(&unix_nr_socks);\n\tlocal_bh_disable();\n\tsock_prot_inuse_add(sock_net(sk), sk->sk_prot, -1);\n\tlocal_bh_enable();\n#ifdef UNIX_REFCNT_DEBUG\n\tprintk(KERN_DEBUG \"UNIX %p is destroyed, %ld are still alive.\\n\", sk,\n\t\tatomic_long_read(&unix_nr_socks));\n#endif\n}",
    "comment": "Destroys a Unix socket, purging its receive queue and decrementing the count of active sockets if the socket is marked as dead.",
    "prorec_sum": "Closes and releases a UNIX domain socket, performing logging, reference count handling, and cleanup of associated resources and connections.",
    "filter_prorec_sum": "Closes a UNIX domain socket, logging state checks, releasing associated resources, decrementing reference counters, and invoking final cleanup routines.",
    "prorec_aug_sum": "Finalizes a UNIX socket\u2019s state, logs relevant events, updates reference counters, and releases associated resources based on its connection and usage flags.",
    "filter_prorec_aug_sum": "Finalizes a UNIX socket structure, logs state-dependent events, updates reference counters, and cleans up associated resources before returning control.",
    "work_score": {
        "prorec": {
            "summary": "Closes and releases a UNIX domain socket, performing logging, reference count handling, and cleanup of associated resources and connections.",
            "score": [
                0.8666666666666667,
                0.6,
                0.8333333333333334
            ],
            "reason": [
                "The summary correctly captures that the function releases a UNIX domain socket and performs logging, reference count updates, and cleanup of associated resources, all of which are explicitly shown in the source code. It mentions 'connections,' which is not directly evidenced in the code, making that part inaccurate. Overall, most details align with the code, but there is a minor hallucination.",
                "The summary accurately mentions releasing a UNIX domain socket, logging, and reference count handling, which are evidenced by functions like printk for logging, atomic_long_dec for reference count decrement, and cleanup via unix_release_addr and skb_queue_purge. However, it omits key explicit logic such as WARN_ON checks for socket state, SOCK_DEAD flag check preventing release of alive sockets, and disabling/enabling bottom halves. These omissions mean it does not present a complete picture of the code's logic.",
                "The summary accurately notes cleanup of a UNIX domain socket, logging, reference count handling, and resource release, all of which are clearly evidenced in the code through functions like printk for logging, atomic_long_dec for reference count, unix_release_addr for resource cleanup, and skb_queue_purge for queue cleanup. However, the mention of closing and releasing \"connections\" is inaccurate since the source code does not handle connection termination beyond purging the receive queue. Most details are accurate, and they offer domain-specific insights rather than being generic."
            ]
        },
        "filter_prorec": {
            "summary": "Closes a UNIX domain socket, logging state checks, releasing associated resources, decrementing reference counters, and invoking final cleanup routines.",
            "score": [
                0.9,
                0.8000000000000002,
                0.7000000000000001
            ],
            "reason": [
                "The summary correctly identifies that the function deals with closing a UNIX domain socket, includes logging state checks, releasing resources (like `u->addr`), and decrementing reference counters (`unix_nr_socks`). However, the mention of 'invoking final cleanup routines' is vague and not directly evidenced by a specific cleanup function call beyond resource release and counter decrement logic. Most key details are supported by explicit function calls and logging in the source code, resulting in high accuracy with only minor extrapolation.",
                "The summary accurately covers the primary logic: it describes closing a UNIX domain socket, performing state checks (evident via WARN_ON calls), releasing associated resources (skb_queue_purge and unix_release_addr), decrementing reference counters (atomic_long_dec, sock_prot_inuse_add), and final cleanup routines. These elements map directly to the source code's actions. However, it omits some specifics such as early return when the socket is not dead and local_bh_disable/enable for cleanup sequence, which are relevant edge cases in the control flow.",
                "The summary's semantic details largely align with the source code: the function does operate on a UNIX domain socket, performs state checks with WARN_ON, releases resources (addr and receive queue), decrements counters, and calls final cleanup routines like sock_prot_inuse_add within local_bh_disable/enable. No claims are made that contradict the code, and all are supported by explicit evidence. While accurate, the details are somewhat generic and do not mention specific function names or debug conditions, making the insights less domain-rich."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\n_nullstream_ctl (struct _mu_stream *str, int code, int opcode, void *arg)\n{\n  struct _mu_nullstream *np = (struct _mu_nullstream *)str;\n\n  if (code != MU_IOCTL_NULLSTREAM)\n    /* Only this code is supported */\n    return ENOSYS;\n  switch (opcode)\n    {\n    case MU_IOCTL_NULLSTREAM_SET_PATTERN:\n      if (!arg)\n\t_nullstream_free_pattern (np);\n      else\n\t{\n\t  struct mu_nullstream_pattern *pat = arg;\n\t  char *p;\n\t  \n\t  p = malloc (pat->size);\n\t  if (!p)\n\t    return ENOMEM;\n\t  memcpy (p, pat->pattern, pat->size);\n\t  _nullstream_free_pattern (np);\n\t  np->pattern = p;\n\t  np->patsize = pat->size;\n\t}\n      break;\n\n    case MU_IOCTL_NULLSTREAM_SET_PATCLASS:\n      if (!arg)\n\treturn EINVAL;\n      else\n\t{\n\t  char buf[256];\n\t  int cnt = 0, i;\n\t  int class = *(int*)arg;\n\t  char *p;\n\t  \n\t  for (i = 0; i < 256; i++)\n\t    {\n\t      if (mu_c_is_class (i, class))\n\t\tbuf[cnt++] = i;\n\t    }\n\n\t  p = malloc (cnt);\n\t  if (!p)\n\t    return ENOMEM;\n\t  memcpy (p, buf, cnt);\n\t  _nullstream_free_pattern (np);\n\t  np->pattern = p;\n\t  np->patsize = cnt;\n\t}\n      break;\n\t  \n    case MU_IOCTL_NULLSTREAM_SETSIZE:\n      if (!arg)\n\treturn EINVAL;\n      else\n\treturn _nullstream_truncate (str, *(mu_off_t*)arg);\n      break;\n\n    case MU_IOCTL_NULLSTREAM_CLRSIZE:\n      np->mode &= ~MU_NULLSTREAM_SIZE;\n      np->base.size = NULL;\n      break;\n      \n    default:\n      return ENOSYS;\n    }\n  return 0;\n}",
    "comment": "Handles control operations for a nullstream, including setting patterns, pattern classes, and managing size-related functionalities.",
    "prorec_sum": "Configures a path object's internal list data based on mode, copying from provided sources or masks, and manages memory allocation and cleanup accordingly.",
    "filter_prorec_sum": "Configures a structure\u2019s data buffer based on mode, filtering bytes via a lookup table, copying raw data, or adjusting related parameters.",
    "prorec_aug_sum": "Configures a data structure at `a1` based on `a3` mode, allocating and copying byte lists or invoking handlers, with strict parameter validation.",
    "filter_prorec_aug_sum": "Configures a data structure at `a1` based on mode `a3`, allocating and storing byte lists or invoking specialized handlers, with strict parameter validation.",
    "work_score": {
        "prorec": {
            "summary": "Configures a path object's internal list data based on mode, copying from provided sources or masks, and manages memory allocation and cleanup accordingly.",
            "score": [
                0.0,
                0.0,
                0.0
            ],
            "reason": [
                "The summary describes configuring a path object's internal list data based on mode and copying from sources or masks, which does not match the source code. The source code defines a control function for a nullstream structure, handling specific opcodes for setting patterns, setting pattern classes, setting size, and clearing size, with related memory allocation and cleanup. There is no evidence of path objects or source/mask concepts in the code, making the details in the summary inaccurate.",
                "The summary claims the code configures a path object's internal list data based on mode, copying from provided sources or masks, and handling memory allocation and cleanup. However, there is no evidence in the source code of a 'path object', internal list, or sources/masks. The actual code controls a nullstream object via IOCTL commands, sets pattern data, sets pattern classes, changes size, and clears size, with memory handling tied specifically to the nullstream structure. All details from the summary are inaccurate, leaving no valid content to map to critical code semantics.",
                "The summary's details about configuring a 'path' object's internal list and using sources or masks are inaccurate, as the source code deals with a '_nullstream_ctl' function that manages nullstream patterns, pattern classes, size settings, and memory allocation. No references to 'path' objects, list data, sources, or masks exist in the code, making all extracted semantic claims inaccurate. Since all details are inaccurate, the kill switch condition is met."
            ]
        },
        "filter_prorec": {
            "summary": "Configures a structure\u2019s data buffer based on mode, filtering bytes via a lookup table, copying raw data, or adjusting related parameters.",
            "score": [
                0.46666666666666673,
                0.3,
                0.0
            ],
            "reason": [
                "The summary incorrectly generalizes the code as configuring a structure\u2019s data buffer based on mode and filtering bytes via a lookup table without explicitly mentioning the supported ioctl codes, concrete functions, and data type casts in the source. While the code does copy raw data and filter using mu_c_is_class, there is no evidence of a general 'mode-based' approach across all operations; instead, behavior depends on specific opcodes. The summary omits explicit constants like MU_IOCTL_NULLSTREAM_SET_PATTERN and MU_IOCTL_NULLSTREAM_SETSIZE, and introduces vague concepts that are not directly supported in the source, making most details unverified.",
                "The summary omits explicit references to MU_IOCTL_NULLSTREAM opcodes, error handling, and the conditional logic seen in the code. While it vaguely mentions configuring a buffer and filtering bytes, it lacks accuracy about the specific mechanisms used: malloc, memcpy, mu_c_is_class filtering, freeing patterns, and adjusting size or mode fields. These omissions mean the captured details are too generic to form a complete picture of the control flow and edge cases present.",
                "The summary omits explicit constants, function names, and data types present in the source and introduces inaccurate elements such as 'based on mode' and 'lookup table' without clear code evidence. While the code does filter bytes using mu_c_is_class and copies raw data, there is no generic 'lookup table' concept described, and mode is only conditionally altered in MU_IOCTL_NULLSTREAM_CLRSIZE. Over 50% of the details lack direct confirmation from the source, triggering the kill switch."
            ]
        }
    }
}
{
    "source_code": "\nstatic int des_ede_cfb64_cipher(EVP_CIPHER_CTX *ctx, unsigned char *out,\n\t\t\t      const unsigned char *in, size_t inl)\n{\n\twhile (inl>=EVP_MAXCHUNK)\n\t\t{\n\t\tDES_ede3_cfb64_encrypt(in, out, (long)EVP_MAXCHUNK, \n\t\t\t       &data(ctx)->ks1, &data(ctx)->ks2, &data(ctx)->ks3,\n\t\t\t       (DES_cblock *)ctx->iv, &ctx->num, ctx->encrypt);\n\t\tinl-=EVP_MAXCHUNK;\n\t\tin +=EVP_MAXCHUNK;\n\t\tout+=EVP_MAXCHUNK;\n\t\t}\n\tif (inl)\n\t\tDES_ede3_cfb64_encrypt(in, out, (long)inl,\n\t\t\t       &data(ctx)->ks1, &data(ctx)->ks2, &data(ctx)->ks3,\n                               (DES_cblock *)ctx->iv, &ctx->num, ctx->encrypt);\n\treturn 1;\n}",
    "comment": "Encrypts input data using Triple DES in CFB64 mode, processing it in chunks of EVP_MAXCHUNK size.",
    "prorec_sum": "Encrypts data in chunks using triple-DES CFB64 mode, handling extremely large lengths by processing in 2^62-byte segments before a final partial block.",
    "filter_prorec_sum": "Encrypts data in large chunks using triple-DES in CFB64 mode, processing multi-terabyte lengths in segments before handling any remaining bytes.",
    "prorec_aug_sum": "Encrypts data in large sequential chunks using Triple DES in CFB64 mode, handling extremely large lengths by looping over fixed 2^62\u2011byte blocks.",
    "filter_prorec_aug_sum": "Processes input data in large chunks using triple-DES CFB64 mode encryption, handling extremely large lengths by splitting into multiple 2^62-byte segments.",
    "work_score": {
        "prorec": {
            "summary": "Encrypts data in chunks using triple-DES CFB64 mode, handling extremely large lengths by processing in 2^62-byte segments before a final partial block.",
            "score": [
                0.6,
                0.6,
                0.0
            ],
            "reason": [
                "The summary correctly identifies triple-DES CFB64 mode encryption and the chunked processing mechanism, which is evidenced by the use of DES_ede3_cfb64_encrypt and EVP_MAXCHUNK in the source code. However, the claim of handling extremely large lengths in 2^62-byte segments is inaccurate, as there is no explicit reference to 2^62 in the code; only EVP_MAXCHUNK is mentioned without its exact value. This introduces a significant unverified assumption, reducing overall accuracy.",
                "The summary correctly identifies that the function encrypts data using triple-DES in CFB64 mode and processes data in chunks, but the claim about handling lengths in 2^62-byte segments is inaccurate. The code explicitly uses EVP_MAXCHUNK for chunk size, not 2^62 bytes. After removing this hallucination, the remaining accurate detail covers the core loop and the final partial block handling, giving a reasonable picture of the function's logic but missing the exact chunk size specification.",
                "The summary claims processing in 2^62-byte segments, but the source code explicitly uses EVP_MAXCHUNK for large data, with no mention or evidence of 2^62-byte limits, making this detail inaccurate. The accurate portion is that it encrypts data in chunks using triple-DES CFB64 mode with a final partial block, which is explicitly shown through DES_ede3_cfb64_encrypt calls and loop logic. Since more than 50% of the semantic details are inaccurate, the kill switch triggers."
            ]
        },
        "filter_prorec": {
            "summary": "Encrypts data in large chunks using triple-DES in CFB64 mode, processing multi-terabyte lengths in segments before handling any remaining bytes.",
            "score": [
                0.7333333333333334,
                0.6,
                0.26666666666666666
            ],
            "reason": [
                "The summary correctly identifies the use of triple-DES in CFB64 mode and that the data is encrypted in chunks before processing remaining bytes, which is explicitly evident from calls to DES_ede3_cfb64_encrypt and the loop over EVP_MAXCHUNK. However, the mention of multi-terabyte lengths is unsupported and not indicated by the source code, making it an unverified assumption. Overall, most details are accurate except for this hallucination, resulting in mixed accuracy.",
                "The summary correctly identifies that the function uses triple-DES in CFB64 mode and processes input in chunks before handling remaining bytes, which is explicitly shown by calls to DES_ede3_cfb64_encrypt with EVP_MAXCHUNK and the final inl check. However, the claim about 'multi-terabyte lengths' is inaccurate, as the source code does not reference data size scales beyond the chunk logic. Despite this inaccuracy, the accurate details cover the main control flow of the function.",
                "The summary correctly identifies that the function uses triple-DES in CFB64 mode and processes data in chunks before handling remaining bytes, which is explicitly shown in the loop and DES_ede3_cfb64_encrypt calls. However, the claim about processing multi-terabyte lengths is inaccurate, as the source code only enforces chunking based on EVP_MAXCHUNK without any explicit indication of multi-terabyte handling. This results in more than half of the details being inaccurate, triggering the kill switch."
            ]
        }
    }
}
