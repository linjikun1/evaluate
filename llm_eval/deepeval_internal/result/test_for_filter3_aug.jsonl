{
    "source_code": "\nstatic void *\nxpalloc (void *pa, ptrdiff_t *nitems, ptrdiff_t nitems_incr_min,\n\t ptrdiff_t nitems_max, ptrdiff_t item_size)\n{\n  ptrdiff_t n0 = *nitems;\n\n  /* The approximate size to use for initial small allocation\n     requests.  This is the largest \"small\" request for the GNU C\n     library malloc.  */\n  enum { DEFAULT_MXFAST = 64 * sizeof (size_t) / 4 };\n\n  /* If the array is tiny, grow it to about (but no greater than)\n     DEFAULT_MXFAST bytes.  Otherwise, grow it by about 50%.\n     Adjust the growth according to three constraints: NITEMS_INCR_MIN,\n     NITEMS_MAX, and what the C language can represent safely.  */\n\n  ptrdiff_t n, nbytes;\n  if (INT_ADD_WRAPV (n0, n0 >> 1, &n))\n    n = PTRDIFF_MAX;\n  if (0 <= nitems_max && nitems_max < n)\n    n = nitems_max;\n\n  ptrdiff_t adjusted_nbytes\n    = ((INT_MULTIPLY_WRAPV (n, item_size, &nbytes) || SIZE_MAX < nbytes)\n       ? MIN (PTRDIFF_MAX, SIZE_MAX)\n       : nbytes < DEFAULT_MXFAST ? DEFAULT_MXFAST : 0);\n  if (adjusted_nbytes)\n    {\n      n = adjusted_nbytes / item_size;\n      nbytes = adjusted_nbytes - adjusted_nbytes % item_size;\n    }\n\n  if (! pa)\n    *nitems = 0;\n  if (n - n0 < nitems_incr_min\n      && (INT_ADD_WRAPV (n0, nitems_incr_min, &n)\n\t  || (0 <= nitems_max && nitems_max < n)\n\t  || INT_MULTIPLY_WRAPV (n, item_size, &nbytes)))\n    xalloc_die ();\n  pa = xrealloc (pa, nbytes);\n  *nitems = n;\n  return pa;\n}",
    "comment": "Allocates or reallocates memory for an array based on its current size, growth constraints, and item size, ensuring safe memory usage.",
    "prorec_sum": "Resizes a buffer\u2019s allocation size by growing it safely within limits, preventing integer overflow, and ensuring a minimum capacity before proceeding with further operations.",
    "filter_prorec_sum": "Resizes a memory buffer by growing its allocation size with overflow and limit checks, then allocates or adjusts it accordingly.",
    "prorec_aug_sum": "Resizes a memory buffer by increasing its element count with overflow and maximum size checks, then allocates or reallocates storage accordingly.",
    "filter_prorec_aug_sum": "Resizes a memory buffer, enforcing overflow checks and alignment, and invokes allocation routines when capacity needs to increase beyond the current size.",
    "work_score": {
        "prorec_aug": {
            "summary": "Resizes a memory buffer by increasing its element count with overflow and maximum size checks, then allocates or reallocates storage accordingly.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary captures the core behavior of increasing the element count, performing overflow and maximum size checks, and allocating or reallocating memory, which aligns closely with the source code's semantics. There are no evident inaccuracies or irrelevant statements, making the claims highly precise and relevant.",
                "The summary accurately captures the core purpose of the function: resizing a memory buffer by increasing element count with overflow and maximum size checks, then performing allocation/reallocation. This matches the source code's main behavior of adjusting array size with growth logic, constraints (MIN increment, MAX limit), and wraparound protection before calling xrealloc. However, it omits secondary details such as the DEFAULT_MXFAST optimization, the specific growth strategy (~50%), handling of a NULL pointer, and the fatal error path via xalloc_die. Coverage of secondary semantics is limited, focusing mainly on the high-level resizing and safety checks without finer implementation aspects.",
                "The summary correctly identifies the core purpose of the function \u2014 resizing a memory buffer by increasing the number of elements, performing overflow and maximum size checks, and then allocating or reallocating memory. This aligns accurately with the code's logic using INT_ADD_WRAPV, INT_MULTIPLY_WRAPV, nitems_max limits, and calls to xrealloc/xalloc_die. While the description is somewhat high-level and omits specific growth strategy details (like adjusting to DEFAULT_MXFAST or minimum increment constraints), there are no incorrect claims or irrelevant noise, and all statements target the function's semantics meaningfully."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Resizes a memory buffer, enforcing overflow checks and alignment, and invokes allocation routines when capacity needs to increase beyond the current size.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function resizes a memory buffer and performs overflow checks before allocation, aligning with the code's use of growth logic and wraparound checks. However, it inaccurately mentions enforcing alignment, which is not explicitly handled in the source, and omits important constraints like minimum and maximum item counts and the DEFAULT_MXFAST growth rule. Most claims are accurate but there is at least one incorrect detail and missing specificity, making precision moderate.",
                "The summary correctly notes that the function resizes a buffer and performs overflow checks, matching the source code\u2019s use of INT_ADD_WRAPV and INT_MULTIPLY_WRAPV for safety. However, it does not capture the core specific purpose of computing and adjusting the new size based on DEFAULT_MXFAST, growth rules (~50%), minimum/maximum constraints, and safe C size limits. These detailed allocation growth semantics are central to the function and missing from the summary, which makes coverage of secondary behavior thin and the core domain effect underrepresented.",
                "The summary captures the core purpose of resizing a memory buffer and mentions overflow checks and allocation routines, which aligns with the source code's use of INT_*_WRAPV checks and xrealloc. However, it incorrectly mentions 'alignment', which is not present in the code, and omits important growth logic details like the DEFAULT_MXFAST behavior and item increment constraints. This omission reduces specificity and insight. The worst failure mode here is mild NOISE from the inaccurate 'alignment' claim, with limited positive gain due to the summary's generic phrasing."
            ]
        }
    }
}
{
    "source_code": "\nint\nmu_get_host_name (char **host)\n{\n  char *hostname = NULL;\n  size_t size = 0;\n  char *p;\n\n  while (1)\n    {\n      if (size == 0)\n\t{\n\t  size = MAXHOSTNAMELEN;\n\t  p = malloc (size);\n\t}\n      else\n\t{\n\t  size_t ns = size * 2;\n\t  if (ns < size)\n\t    {\n\t      free (hostname);\n\t      return ENOMEM;\n\t    }\n\t  size = ns;\n\t  p = realloc (hostname, size);\n\t}\n      if (!p)\n\t{\n\t  free (hostname);\n\t  return ENOMEM;\n\t}\n      hostname = p;\n      hostname[size - 1] = 0;\n      if (gethostname (hostname, size - 1) == 0)\n\t{\n\t  if (!hostname[size - 1])\n\t    break;\n\t}\n      else if (errno != 0 && errno != ENAMETOOLONG && errno != EINVAL\n\t       && errno != ENOMEM)\n\t{\n\t  int rc = errno;\n\t  free (hostname);\n\t  return rc;\n\t}\n    }\n\n  /* Try to return fully qualified host name */\n  if (!strchr (hostname, '.'))\n    {\n      struct hostent *hp = gethostbyname (hostname);\n      if (hp)\n\t{\n\t  size_t len = strlen (hp->h_name);\n\t  if (size < len + 1)\n\t    {\n\t      p = realloc (hostname, len + 1);\n\t      if (!p)\n\t\t{\n\t\t  free (hostname);\n\t\t  return ENOMEM;\n\t\t}\n\t      hostname = p;\n\t    }\n\t  strcpy (hostname, hp->h_name);\n\t}\n    }\n  \n  *host = hostname;\n  return 0;\n}",
    "comment": "Retrieves the host name of the machine, expanding the buffer as needed, and attempts to return the fully qualified host name if not present.",
    "prorec_sum": "Retrieves the system's host name, expanding the buffer as needed and resolving the fully qualified name if no domain is present.",
    "filter_prorec_sum": "Retrieves the local host name, expanding buffer if needed, and resolves it to a fully qualified name when missing a domain.",
    "prorec_aug_sum": "Retrieves the local host name, expanding buffer as needed, and resolves it to a fully qualified domain name if missing a dot.",
    "filter_prorec_aug_sum": "Retrieves the local host name, expanding buffer as needed, and resolves it to a fully qualified name if no domain is present.",
    "work_score": {
        "prorec_aug": {
            "summary": "Retrieves the local host name, expanding buffer as needed, and resolves it to a fully qualified domain name if missing a dot.",
            "score": [
                1.0,
                0.5,
                0.9
            ],
            "reason": [
                "The summary contains two clear factual claims: that the function retrieves the local host name with dynamic buffer expansion, and that it attempts to resolve it to a fully qualified domain name if the result lacks a dot. Both behaviors are explicitly implemented in the source code, making them accurate and domain-specific. There are no inaccuracies or irrelevant statements present, resulting in a high proportion of accurate claims.",
                "The summary accurately captures the core purpose of obtaining the local hostname with dynamic buffer allocation and attempting to resolve it to a fully qualified domain name. However, it omits several secondary, behavior-critical details such as error handling for allocation failures (ENOMEM), specific errno checks to handle gethostname errors, and the buffer resizing loop logic. Coverage of the core purpose is present, but secondary coverage is limited.",
                "The summary correctly states that the function retrieves the local host name and expands the buffer as needed, which matches the loop logic that reallocates until the name fits. It also accurately mentions resolving to a fully qualified domain name if missing a dot, which is handled via gethostbyname. These are GOLD-level accurate claims targeting the core purpose and behavior. There is no contradictory or irrelevant information present, and noise is negligible. Gain is moderate to high due to specificity on buffer expansion and FQDN resolution."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Retrieves the local host name, expanding buffer as needed, and resolves it to a fully qualified name if no domain is present.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary contains two main claims: that the function retrieves the local host name with dynamic buffer resizing, and that it resolves the name to a fully qualified one if no domain is present. Both claims directly match the source code functionality: the loop reallocates memory until gethostname succeeds, and if no dot is found, gethostbyname is used to obtain the FQDN. No contradictory or irrelevant statements are present, so all claims are accurate.",
                "The summary accurately states that the function retrieves the local host name, dynamically expanding the buffer as needed, and resolves it to a fully qualified name if no domain is present, which aligns with the core behavior in the source code. However, it omits several important secondary details such as the initial allocation size, doubling strategy, specific error handling branches for allocation failures and gethostname errors, and the use of gethostbyname for resolution. Coverage of the core purpose is strong but secondary semantics are limited.",
                "The summary states that the function retrieves the local host name, expands the buffer as needed, and resolves it to a fully qualified name if no domain is present, all of which accurately reflect the core purpose and behavior of the code. The claims are specific, match the domain semantics (hostname retrieval, dynamic buffer resizing, conditional FQDN resolution) and contain no inaccuracies or irrelevant noise. The level of detail is high enough to give engineers a clear understanding of the function's key operations with minimal noise."
            ]
        }
    }
}
{
    "source_code": "static int do_sysinfo(struct sysinfo *info)\n{\n\tunsigned long mem_total, sav_total;\n\tunsigned int mem_unit, bitcount;\n\tstruct timespec tp;\n\n\tmemset(info, 0, sizeof(struct sysinfo));\n\n\tktime_get_ts(&tp);\n\tmonotonic_to_bootbased(&tp);\n\tinfo->uptime = tp.tv_sec + (tp.tv_nsec ? 1 : 0);\n\n\tget_avenrun(info->loads, 0, SI_LOAD_SHIFT - FSHIFT);\n\n\tinfo->procs = nr_threads;\n\n\tsi_meminfo(info);\n\tsi_swapinfo(info);\n\n\t/*\n\t * If the sum of all the available memory (i.e. ram + swap)\n\t * is less than can be stored in a 32 bit unsigned long then\n\t * we can be binary compatible with 2.2.x kernels.  If not,\n\t * well, in that case 2.2.x was broken anyways...\n\t *\n\t *  -Erik Andersen <andersee@debian.org>\n\t */\n\n\tmem_total = info->totalram + info->totalswap;\n\tif (mem_total < info->totalram || mem_total < info->totalswap)\n\t\tgoto out;\n\tbitcount = 0;\n\tmem_unit = info->mem_unit;\n\twhile (mem_unit > 1) {\n\t\tbitcount++;\n\t\tmem_unit >>= 1;\n\t\tsav_total = mem_total;\n\t\tmem_total <<= 1;\n\t\tif (mem_total < sav_total)\n\t\t\tgoto out;\n\t}\n\n\t/*\n\t * If mem_total did not overflow, multiply all memory values by\n\t * info->mem_unit and set it to 1.  This leaves things compatible\n\t * with 2.2.x, and also retains compatibility with earlier 2.4.x\n\t * kernels...\n\t */\n\n\tinfo->mem_unit = 1;\n\tinfo->totalram <<= bitcount;\n\tinfo->freeram <<= bitcount;\n\tinfo->sharedram <<= bitcount;\n\tinfo->bufferram <<= bitcount;\n\tinfo->totalswap <<= bitcount;\n\tinfo->freeswap <<= bitcount;\n\tinfo->totalhigh <<= bitcount;\n\tinfo->freehigh <<= bitcount;\n\nout:\n\treturn 0;\n}",
    "comment": "Populates the `sysinfo` structure with system uptime, load averages, process count, and adjusted memory and swap information, ensuring compatibility with older kernels.",
    "prorec_sum": "Initializes a 0x70-byte structure, populates fields via helper routines, and scales multiple size-related members based on calculated capacity thresholds.",
    "filter_prorec_sum": "Initializes a 0x70-byte structure with computed size fields and scales multiple capacity values based on aggregate limits before finalizing setup.",
    "prorec_aug_sum": "Initializes and scales multiple 64\u2011bit timing or counter fields in a data structure based on aggregated values and a scaling factor constraint.",
    "filter_prorec_aug_sum": "Initializes a 0x70-byte structure with timing and size parameters, then scales multiple fields to align memory or resource allocation thresholds.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes and scales multiple 64\u2011bit timing or counter fields in a data structure based on aggregated values and a scaling factor constraint.",
            "score": [
                0.2,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claim about initializing and scaling multiple 64\u2011bit timing or counter fields is inaccurate: the function initializes a struct sysinfo, retrieves uptime, load averages, process count, and memory/swap info, and scales various memory-related fields based on mem_unit and overflow checks. It does not specifically operate on 64\u2011bit timing or counter fields as described; the scaling applies to memory values, not timing counters. This mismatch means the claim does not target the actual semantics of the code, resulting in low accuracy.",
                "The summary misrepresents the core function: the source code gathers system information such as uptime, load averages, process count, RAM, and swap settings, then adjusts memory values to maintain compatibility constraints. The claim about initializing and scaling multiple 64\u2011bit timing or counter fields is inaccurate \u2014 the code works with discrete system info structures and memory units, not generic 64\u2011bit timing fields. The core purpose is not covered, and no accurate secondary details are provided.",
                "The summary inaccurately describes the function as initializing and scaling 64-bit timing or counter fields, which contradicts the source code's actual behavior of populating a sysinfo struct with uptime, load, process count, and memory statistics, then scaling memory values based on mem_unit constraints. This is a FATAL error targeting the primary purpose since the function does not deal with 64-bit timing fields or generic counters; its core is memory and system info initialization and adjustment. No accurate claims are present, so net benefit is essentially zero."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes a 0x70-byte structure with timing and size parameters, then scales multiple fields to align memory or resource allocation thresholds.",
            "score": [
                0.5,
                0.3,
                0.2
            ],
            "reason": [
                "The summary correctly notes initialization of a structure and scaling of fields, which are present in the code, but the claim that it is a '0x70-byte structure' and reference to 'memory or resource allocation thresholds' are not supported by the source. The size is determined by sizeof(struct sysinfo), not explicitly given as 0x70 bytes, and scaling occurs for backward compatibility rather than thresholds. This results in mixed accuracy with some factual elements and some unsupported or imprecise details.",
                "The summary mentions initializing a structure and scaling fields, which is partially accurate, but it omits the core domain purpose of populating a sysinfo structure with uptime, load averages, process count, and detailed RAM/swap information for compatibility across kernel versions. The reference to 'timing and size parameters' is vague compared to the specific data gathered in the code, and it fails to cover key secondary behaviors such as retrieving memory/swap stats, load averages, and handling overflow conditions.",
                "The summary claims the function initializes a 0x70-byte structure, which is inaccurate because the code zeroes out a struct sysinfo whose size is defined by its type, not fixed at 0x70 bytes. It generically notes initialization of timing and size parameters and scaling fields, which loosely matches the uptime calculation, memory info retrieval, and bit-shift scaling, but omits important specifics like load averages, process count, and swap info. The fixed size claim is a FATAL error about initialization details, affecting understanding of the structure's handling. Most other details are broad and low-info, yielding low gain."
            ]
        }
    }
}
{
    "source_code": "int drm_markbufs(struct drm_device *dev, void *data,\n\t\t struct drm_file *file_priv)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf_desc *request = data;\n\tint order;\n\tstruct drm_buf_entry *entry;\n\n\tif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\n\t\treturn -EINVAL;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tDRM_DEBUG(\"%d, %d, %d\\n\",\n\t\t  request->size, request->low_mark, request->high_mark);\n\torder = drm_order(request->size);\n\tif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\n\t\treturn -EINVAL;\n\tentry = &dma->bufs[order];\n\n\tif (request->low_mark < 0 || request->low_mark > entry->buf_count)\n\t\treturn -EINVAL;\n\tif (request->high_mark < 0 || request->high_mark > entry->buf_count)\n\t\treturn -EINVAL;\n\n\tentry->freelist.low_mark = request->low_mark;\n\tentry->freelist.high_mark = request->high_mark;\n\n\treturn 0;\n}",
    "comment": "Configures buffer management parameters, including size and free list thresholds, for a Direct Rendering Manager (DRM) device's DMA buffers.",
    "prorec_sum": "Validates DRM buffer parameters and updates buffer metadata entries after confirming alignment, size constraints, and device state readiness.",
    "filter_prorec_sum": "Validates DRM buffer parameters and updates specific buffer state fields after ensuring proper alignment, range limits, and feature enablement.",
    "prorec_aug_sum": "Validates DRM buffer parameters and updates buffer indices in the device structure, returning errors for misaligned sizes or out\u2011of\u2011range values.",
    "filter_prorec_aug_sum": "Validates DRM buffer parameters and updates ring buffer metadata for the given device context, returning errors on invalid sizes or indices.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates DRM buffer parameters and updates buffer indices in the device structure, returning errors for misaligned sizes or out\u2011of\u2011range values.",
            "score": [
                0.8,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly captures that the function validates DRM buffer parameters, enforces bounds checks, and updates values in the device structure, aligning with the code's logic. However, it inaccurately describes the updates as affecting 'buffer indices' rather than freelist low/high marks, and uses 'misaligned sizes' instead of the actual size order range check. Overall, most claims reflect the source code behavior with minor inaccuracies.",
                "The summary states that the function validates DRM buffer parameters and updates buffer indices, and returns errors for certain invalid conditions. This is generally accurate since the code checks for feature flags, DMA presence, size ordering, and low/high marks range, then updates the freelist's low/high marks. However, the core purpose is specifically to set the low and high marks in the freelist for a given buffer order after validation, not generic 'buffer indices'. The wording 'misaligned sizes' is imprecise compared to the actual check for order outside allowed bounds. Core domain action is only vaguely covered, and some key checks and constants are omitted, so secondary coverage is limited.",
                "The summary captures the primary purpose of validating DRM buffer parameters and returning errors for invalid ranges, which aligns with the code's checks against size and mark limits. It is slightly inaccurate in referring to 'misaligned sizes' since the code actually checks the size order bounds rather than memory alignment, and it misstates the effect as updating 'buffer indices' instead of low/high marks within the freelist. These are minor inaccuracies but do not severely distort the primary purpose. The description is generic with some domain relevance, giving low specific gain and moderate noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates DRM buffer parameters and updates ring buffer metadata for the given device context, returning errors on invalid sizes or indices.",
            "score": [
                0.8,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function validates buffer parameters and returns errors for invalid values, which aligns with the code's checks on size, low_mark, and high_mark. However, it inaccurately describes the update target as 'ring buffer metadata'\u2014the code actually updates freelist marks within a buffer entry, not a ring buffer structure. This mislabeling slightly reduces precision but most claims are grounded in the source behavior.",
                "The summary correctly captures that the function validates DRM buffer parameters and returns errors for invalid inputs, aligning with checks on size and mark indices. However, it inaccurately describes updating 'ring buffer metadata' instead of specifically setting the freelist low and high marks in the drm_buf_entry for a DMA-capable device. While the error handling is noted, the core purpose\u2014validating parameters and setting freelist marks\u2014is only partially covered, and secondary details like feature checks, DMA null checks, and order range checks are missing.",
                "The summary correctly states that the function validates DRM buffer parameters and returns errors for invalid values, which aligns with the code's checks for size, low_mark, and high_mark. However, it inaccurately describes the update target as 'ring buffer metadata'; the code updates freelist metadata within a buffer entry, not a ring buffer. This is a semantic error about the core side effect, making it a FATAL issue on the primary purpose. The gain from accurate parts is limited due to this critical inaccuracy."
            ]
        }
    }
}
{
    "source_code": "\nstatic const char* findlocal(lua_State* L, CallInfo* ci, int n, StkId* pos) {\n  const char* name = NULL;\n  StkId base;\n  if (isLua(ci)) {\n    if (n < 0) /* access to vararg values? */\n      return findvararg(ci, -n, pos);\n    else {\n      base = ci->u.l.base;\n      name = luaF_getlocalname(ci_func(ci)->p, n, currentpc(ci));\n    }\n  } else\n    base = ci->func + 1;\n  if (name == NULL) { /* no 'standard' name? */\n    StkId limit = (ci == L->ci) ? L->top : ci->next->func;\n    if (limit - base >= n && n > 0) /* is 'n' inside 'ci' stack? */\n      name = \"(*temporary)\"; /* generic name for any valid slot */\n    else\n      return NULL; /* no name */\n  }\n  *pos = base + (n - 1);\n  return name;\n}",
    "comment": "Retrieves the local variable name from a Lua function's call frame or returns a generic name for temporary slots if no name exists.",
    "prorec_sum": "Retrieves a specific argument or temporary variable from a parser\u2019s stack and returns its descriptive name, storing its memory address in the provided pointer.",
    "filter_prorec_sum": "Retrieves a function argument or temporary value index and returns its label while storing the corresponding memory location pointer.",
    "prorec_aug_sum": "Retrieves a specific argument or temporary value from a data frame and returns its descriptor string while updating the provided pointer.",
    "filter_prorec_aug_sum": "Retrieves a function argument or temporary value reference by index and returns its descriptive label along with its memory location.",
    "work_score": {
        "prorec_aug": {
            "summary": "Retrieves a specific argument or temporary value from a data frame and returns its descriptor string while updating the provided pointer.",
            "score": [
                0.6,
                0.5,
                0.5
            ],
            "reason": [
                "The summary describes retrieving an argument or temporary value, returning its descriptor string, and updating a pointer, which aligns with the function\u2019s logic of returning either a local variable name or a generic '(*)temporary' string and setting the position pointer. However, 'data frame' is inaccurate in this context, as the function operates on Lua stack frames and CallInfo structures. This introduces a semantic mismatch, reducing precision despite most of the functional intent being correct.",
                "The summary mentions retrieving an argument or temporary value and returning a descriptor string while updating a pointer, which loosely aligns with the code\u2019s functionality of finding a local variable or vararg and returning its name while setting the position pointer. However, it fails to capture the core primary purpose with domain-specific detail \u2014 locating a local variable name in a Lua function frame based on its index, handling varargs, and special cases for unnamed slots. Secondary behaviors such as vararg handling, distinction between Lua and C functions, conditional naming, and NULL return cases are omitted, leaving the coverage incomplete.",
                "The summary correctly conveys that the function retrieves some value and returns a descriptor string while updating a pointer, which aligns with the code's behavior of finding local or vararg names and setting the position. However, it inaccurately describes the source context as a 'data frame', which is unrelated to the Lua stack frame the code handles. This mislabeling is noise rather than a FATAL issue, and the rest of the summary remains generic, providing low informational gain with limited specificity to the actual source semantics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Retrieves a function argument or temporary value reference by index and returns its descriptive label along with its memory location.",
            "score": [
                0.8,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly conveys that the function retrieves a value by index and returns a descriptive label and position reference, aligning with the code\u2019s behavior of returning a local variable name and setting the position pointer. However, it inaccurately confuses scope by saying 'function argument' rather than 'local variable' (which can be varargs or temporaries), and omits conditional logic regarding varargs and temporary naming. Overall, most of the claims are accurate but the slight mislabeling makes it moderately precise rather than perfect.",
                "The summary vaguely states that the function retrieves an argument or temporary value by index, returning a label and location, which loosely aligns with the code\u2019s role of finding a local variable or vararg\u2019s name and stack position. However, it misses the core specificity: distinguishing between Lua and non-Lua functions, handling varargs through a special path, using `luaF_getlocalname` for standard names, and providing a fallback temporary name or NULL when appropriate. This means the core purpose is only generically implied and several critical behaviors, branches, and constants are omitted.",
                "The summary correctly conveys that the function retrieves a value by index and returns a label plus its position, which aligns with the code's retrieval of local or vararg names along with stack position. However, it inaccurately describes the retrieved value as a 'function argument or temporary value' only, omitting that it can also retrieve vararg values, and oversimplifies the label as a 'descriptive' one when in fact it may be a placeholder. This inaccuracy is minor and not a FATAL error, but there is little detail about the branching logic or conditions, resulting in low information gain and mostly generic phrasing."
            ]
        }
    }
}
{
    "source_code": "  \nvoid\nmu_ident_stat (mu_stream_t str)\n{\n  size_t count, i;\n  mu_iterator_t itr;\n  \n  mu_stream_printf (str, \"BEGIN IDENT STAT\\n\");\n\n  mu_assoc_count (nametab, &count);\n  mu_stream_printf (str, \"N=%zu\\n\", count);\n\n  if (count > 0)\n    {\n      int rc = mu_assoc_get_iterator (nametab, &itr);\n      if (rc)\n\tmu_stream_printf (str, \"mu_assoc_get_iterator: %s\\n\",\n\t\t\t  mu_strerror (rc));\n      else\n\t{\n\t  i = 0;\n\t  for (mu_iterator_first (itr); !mu_iterator_is_done (itr);\n\t       mu_iterator_next (itr), i++)\n\t    {\n\t      const char *key;\n\t      struct mu_ident_ref *ref;\n\t      \n\t      mu_iterator_current_kv (itr,\n\t\t\t\t      (const void **)&key, (void **)&ref);  \n\t      mu_stream_printf (str, \"%04zu: %s: %zu\\n\", i, key, ref->count);\n\t    }\n\t}\n      mu_iterator_destroy (&itr);\n    }\n  mu_stream_printf (str, \"END IDENT STAT\\n\");\n}",
    "comment": "Outputs the count and details of identifiers from a name table to a specified stream, including key-value pairs and their associated counts.",
    "prorec_sum": "Outputs association statistics, iterating over key-value pairs to print each entry\u2019s index, key, and value between BEGIN and END IDENT STAT markers.",
    "filter_prorec_sum": "Outputs identification statistics by counting entries in an association, iterating key-value pairs, and printing formatted results to the provided stream.",
    "prorec_aug_sum": "Outputs identification statistics by counting and iterating over entries in an association, printing each key-value pair and summary markers to a provided stream.",
    "filter_prorec_aug_sum": "Outputs identification statistics by counting entries in an association and listing each key with its value to the provided stream.",
    "work_score": {
        "prorec_aug": {
            "summary": "Outputs identification statistics by counting and iterating over entries in an association, printing each key-value pair and summary markers to a provided stream.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary captures the core behavior accurately: it describes counting entries in an association, iterating over them, outputting each key and its associated value, and printing summary markers to the provided stream. These elements match the source code's operations exactly, including the iteration mechanism and the formatted output. No contradictions or irrelevant details are present, and all fact-based claims align with the function's semantics.",
                "The summary correctly captures the core purpose\u2014producing identification statistics by counting and iterating over entries in the association and printing them to a stream\u2014which matches the main domain action in the source code. It also mentions summary markers, aligning with the BEGIN/END lines in the output. However, it omits secondary behaviors such as handling the case when there are no entries, reporting iterator acquisition errors, and printing specific reference counts instead of generic values. These omissions reduce coverage of critical secondary semantics.",
                "The summary correctly states that the function outputs identification statistics by counting and iterating over entries in an association, printing each key-value pair and summary markers to a provided stream. This matches the source code\u2019s behavior, including counting entries (mu_assoc_count), iterating with an iterator, and printing with a stream along with BEGIN/END markers. There are no inaccuracies targeting the core purpose or I/O, and noise is minimal. The claim is accurate but somewhat generic, providing a modest level of detail without deeply specific insights into error handling or value formats."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Outputs identification statistics by counting entries in an association and listing each key with its value to the provided stream.",
            "score": [
                1.0,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly conveys that the function outputs identification statistics, counts entries in an association, and lists each key with a value to a provided stream. All these points match the source code behavior: the function uses mu_assoc_count to get the entry count, iterates through each key-value pair, and prints them to the given stream. No inaccurate or irrelevant claims are present, and all fact-based claims align with the code.",
                "The summary accurately conveys that the function outputs identification statistics, counts entries in an association, and lists each key with its value to the provided stream, which matches the core domain purpose of the source code. However, it omits important secondary details such as the specific output formatting (BEGIN/END markers), handling of the count being zero, iterator error reporting, and the inclusion of each entry's associated count rather than a generic value. These omissions reduce completeness despite correct core coverage.",
                "The summary correctly captures the function\u2019s purpose: it outputs identification statistics by counting entries and listing keys with associated values to a stream. These are accurate domain-specific claims matching the source code\u2019s sequence of mu_assoc_count, iteration, and printing. However, the summary omits specific details such as printing entry indices, handling iterator errors, and showing the count field from struct mu_ident_ref. No inaccurate or noisy claims are present, but the gain is moderate due to the lack of fine-grained specifics."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\nnfs3_proc_link(struct inode *inode, struct inode *dir, struct qstr *name)\n{\n\tstruct nfs3_linkargs\targ = {\n\t\t.fromfh\t\t= NFS_FH(inode),\n\t\t.tofh\t\t= NFS_FH(dir),\n\t\t.toname\t\t= name->name,\n\t\t.tolen\t\t= name->len\n\t};\n\tstruct nfs3_linkres\tres;\n\tstruct rpc_message msg = {\n\t\t.rpc_proc\t= &nfs3_procedures[NFS3PROC_LINK],\n\t\t.rpc_argp\t= &arg,\n\t\t.rpc_resp\t= &res,\n\t};\n\tint status = -ENOMEM;\n\n\tdprintk(\"NFS call  link %s\\n\", name->name);\n\tres.fattr = nfs_alloc_fattr();\n\tres.dir_attr = nfs_alloc_fattr();\n\tif (res.fattr == NULL || res.dir_attr == NULL)\n\t\tgoto out;\n\n\tstatus = rpc_call_sync(NFS_CLIENT(inode), &msg, 0);\n\tnfs_post_op_update_inode(dir, res.dir_attr);\n\tnfs_post_op_update_inode(inode, res.fattr);\nout:\n\tnfs_free_fattr(res.dir_attr);\n\tnfs_free_fattr(res.fattr);\n\tdprintk(\"NFS reply link: %d\\n\", status);\n\treturn status;\n}",
    "comment": "Links a source inode to a target directory inode with a specified name using an NFS procedure and updates their attributes.",
    "prorec_sum": "Generates two data structures from input parameters, processes them through helper routines, and returns an operation status code.",
    "filter_prorec_sum": "Constructs two data structures from given parameters, processes them through storage-related operations, and returns a status code indicating success or resource error.",
    "prorec_aug_sum": "Constructs two attribute structures from provided parameters, updates them in the server context, invokes RPC handling, and returns the resulting status code.",
    "filter_prorec_aug_sum": "Prepares two data structures from input parameters, performs an operation on them via a server object, and cleans up before returning a status code.",
    "work_score": {
        "prorec_aug": {
            "summary": "Constructs two attribute structures from provided parameters, updates them in the server context, invokes RPC handling, and returns the resulting status code.",
            "score": [
                0.9,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly notes that the function constructs attribute structures, performs an RPC call, updates attributes from the server response, and returns a status code. It omits minor details, such as separate handling of directory and inode attributes and memory allocation checks, but over 80% of the described behavior aligns with the source code\u2019s semantics.",
                "The summary omits the core purpose of performing an NFSv3 link operation that links an inode into a target directory with a specific name via an RPC call. While it correctly mentions constructing attribute structures, invoking RPC, and returning a status, these are generic actions and do not capture the specific domain action. It also misses other key behaviors such as memory allocation checks, updating inode attributes post-operation, and freeing allocated resources.",
                "The summary correctly notes that the function constructs two structures from parameters, invokes an RPC, and returns a status code, which aligns with the code. However, it inaccurately states that the structures are updated in the server context\u2014though the server may update values via RPC, the code explicitly updates local inode attributes after the call. This phrasing is vague and omits key specific details like the use of `nfs_alloc_fattr` for attribute allocation and the freeing of resources, resulting in mostly generic SAFE claims with low informational gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Prepares two data structures from input parameters, performs an operation on them via a server object, and cleans up before returning a status code.",
            "score": [
                0.6,
                0.2,
                0.5
            ],
            "reason": [
                "The summary is overly generic, mentioning preparation of data structures, a server operation, and cleanup, but it omits key specifics such as the function being an NFSv3 link operation, the use of rpc_call_sync with nfs3_procedures[NFS3PROC_LINK], the allocation and free of fattr structures, and updating inode attributes. While the general flow matches the code, most claims are low-information SAFE statements, lacking precise domain semantics, resulting in only partial accuracy.",
                "The summary provides only vague, generic statements without specifying the core purpose of the function, which is to perform an NFSv3 link operation between two inodes in a directory with a given name. While it correctly notes preparation of data structures, an operation, and cleanup, these are boilerplate and lack domain-specific detail, so the core is not covered and secondary behavioral aspects like RPC procedure use, attribute handling, error handling, and updates are omitted.",
                "The summary contains a few accurate but overly generic claims, such as preparing data structures from inputs and cleaning up before returning a status, which align loosely with the code. However, it omits critical specifics like the RPC call to NFS3PROC_LINK, allocation and update of file attributes, and the exact nature of the server interaction. There are no outright contradictions, but the broad wording leads to low informational gain and leaves out the core NFS link semantics, making the description minimally useful."
            ]
        }
    }
}
{
    "source_code": "static void tsc_refine_calibration_work(struct work_struct *work)\n{\n\tstatic u64 tsc_start = -1, ref_start;\n\tstatic int hpet;\n\tu64 tsc_stop, ref_stop, delta;\n\tunsigned long freq;\n\n\t/* Don't bother refining TSC on unstable systems */\n\tif (check_tsc_unstable())\n\t\tgoto out;\n\n\t/*\n\t * Since the work is started early in boot, we may be\n\t * delayed the first time we expire. So set the workqueue\n\t * again once we know timers are working.\n\t */\n\tif (tsc_start == -1) {\n\t\t/*\n\t\t * Only set hpet once, to avoid mixing hardware\n\t\t * if the hpet becomes enabled later.\n\t\t */\n\t\thpet = is_hpet_enabled();\n\t\tschedule_delayed_work(&tsc_irqwork, HZ);\n\t\ttsc_start = tsc_read_refs(&ref_start, hpet);\n\t\treturn;\n\t}\n\n\ttsc_stop = tsc_read_refs(&ref_stop, hpet);\n\n\t/* hpet or pmtimer available ? */\n\tif (ref_start == ref_stop)\n\t\tgoto out;\n\n\t/* Check, whether the sampling was disturbed by an SMI */\n\tif (tsc_start == ULLONG_MAX || tsc_stop == ULLONG_MAX)\n\t\tgoto out;\n\n\tdelta = tsc_stop - tsc_start;\n\tdelta *= 1000000LL;\n\tif (hpet)\n\t\tfreq = calc_hpet_ref(delta, ref_start, ref_stop);\n\telse\n\t\tfreq = calc_pmtimer_ref(delta, ref_start, ref_stop);\n\n\t/* Make sure we're within 1% */\n\tif (abs(tsc_khz - freq) > tsc_khz/100)\n\t\tgoto out;\n\n\ttsc_khz = freq;\n\tpr_info(\"Refined TSC clocksource calibration: %lu.%03lu MHz\\n\",\n\t\t(unsigned long)tsc_khz / 1000,\n\t\t(unsigned long)tsc_khz % 1000);\n\nout:\n\tclocksource_register_khz(&clocksource_tsc, tsc_khz);\n}",
    "comment": "Refines TSC clocksource calibration by measuring timer frequencies and adjusting the TSC frequency if within 1% accuracy after initial readings.",
    "prorec_sum": "Computes and updates a CPU timing calibration value using hardware cycle counters, converting elapsed ticks into microseconds for scheduler timekeeping.",
    "filter_prorec_sum": "Calculates CPU time measurement using hardware or software clock sources, updates stored timing values, and triggers reporting if deviation exceeds threshold.",
    "prorec_aug_sum": "Computes elapsed time between high\u2011resolution counter reads to update and return a calibrated clock rate value in microseconds.",
    "filter_prorec_aug_sum": "Computes and updates a clock calibration value using TSC and stored timestamps, then returns the result through the kernel clock event interface.",
    "work_score": {
        "prorec_aug": {
            "summary": "Computes elapsed time between high\u2011resolution counter reads to update and return a calibrated clock rate value in microseconds.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as returning a calibrated clock rate in microseconds, which it does not; it updates the global tsc_khz variable and registers it but has no return value. While it partially identifies that the function computes elapsed time between counter reads for calibration, this is incomplete and mischaracterizes the output and units, resulting in less than half of the claims being accurate.",
                "The summary states that the function computes elapsed time between high-resolution counter reads and returns a calibrated clock rate in microseconds, but the source code\u2019s core purpose is to refine TSC clocksource calibration early in boot, using HPET or PM timer references, validating stability, and registering the adjusted frequency. The summary misses the specific context of TSC calibration and HPET/pmtimer usage, incorrectly mentions a return value where none exists, and does not cover error checks or the registration step. Therefore, the core domain action is not covered and the claim is partially inaccurate.",
                "The summary incorrectly states that the function returns a calibrated clock rate in microseconds, whereas in the source it updates the global TSC frequency (tsc_khz) in kHz and registers it, with no return value. This is a FATAL in describing the primary purpose and output. While it mentions computing elapsed time between counter reads, aligning with tsc_read_refs and delta calculation, this is overshadowed by the core output misrepresentation, making the description untrustworthy."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Computes and updates a clock calibration value using TSC and stored timestamps, then returns the result through the kernel clock event interface.",
            "score": [
                0.3,
                0.4,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function computes and updates a clock calibration value using TSC and stored timestamps, which matches the code's logic for refining TSC calibration. However, it inaccurately states that the result is returned through the kernel clock event interface; in reality, the function registers the updated frequency with the clocksource, and does not return a value or use a clock event interface. This introduces a significant inaccuracy, making less than half of the claims accurate.",
                "The summary mentions computing and updating a clock calibration using TSC and timestamps, which aligns with the core function's purpose of refining and updating the TSC frequency based on reference counters. However, it inaccurately states that the result is returned through the kernel clock event interface, which the source code does not do; instead, it registers the clocksource with the refined frequency. This misrepresentation of the output path undermines the coverage of the core semantics. While the main action is touched, critical secondary details such as early boot scheduling, unstable TSC checks, use of HPET or PM timer, and validation within 1% are missing.",
                "The summary correctly notes that the function refines a clock calibration value using TSC and timestamps, which matches the code\u2019s reading of TSC references and updating `tsc_khz`. However, it inaccurately claims that the result is returned through the kernel clock event interface \u2014 in reality, the function does not return a value but registers the refined frequency via `clocksource_register_khz`. This is a FATAL error on the primary I/O description, as it misstates how the output is conveyed, making the summary untrustworthy despite the partially accurate description of the computation."
            ]
        }
    }
}
{
    "source_code": "\nstatic int pci_pm_poweroff(struct device *dev)\n{\n\tstruct pci_dev *pci_dev = to_pci_dev(dev);\n\tconst struct dev_pm_ops *pm = dev->driver ? dev->driver->pm : NULL;\n\n\tif (pci_has_legacy_pm_support(pci_dev))\n\t\treturn pci_legacy_suspend(dev, PMSG_HIBERNATE);\n\n\tif (!pm) {\n\t\tpci_pm_default_suspend(pci_dev);\n\t\tgoto Fixup;\n\t}\n\n\tpci_dev->state_saved = false;\n\tif (pm->poweroff) {\n\t\tint error;\n\n\t\terror = pm->poweroff(dev);\n\t\tsuspend_report_result(pm->poweroff, error);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n Fixup:\n\tpci_fixup_device(pci_fixup_suspend, pci_dev);\n\n\treturn 0;\n}",
    "comment": "Handles the power-off process for PCI devices, utilizing legacy support or device-specific power management operations, and fixes up device state afterward.",
    "prorec_sum": "Manages PCI device power-off by checking conditions, invoking device-specific callbacks, and performing fallback shutdown if no suitable handler is available.",
    "filter_prorec_sum": "Handles PCI device power-off by checking conditions, invoking optional callbacks, and issuing fallback or alternative actions based on power management checks.",
    "prorec_aug_sum": "Handles PCI device power-off by checking hardware conditions, invoking callbacks, and performing shutdown or reinitialization procedures as necessary.",
    "filter_prorec_aug_sum": "Handles PCI device power management by checking conditions, invoking shutdown callbacks, and performing a \"pci_pm_poweroff\" sequence when appropriate.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles PCI device power-off by checking hardware conditions, invoking callbacks, and performing shutdown or reinitialization procedures as necessary.",
            "score": [
                0.6,
                0.2,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function handles PCI device power-off and involves checking conditions (e.g., hardware/PM support) and invoking callbacks. However, it adds 'shutdown or reinitialization procedures' which is not clearly reflected in the code \u2014 the code performs suspend operations and fixups, but not a full shutdown or reinitialization sequence. Most of the described behavior aligns generically with the source, but some terms are vague or misleading, resulting in mixed accuracy.",
                "The summary is vague and does not clearly capture the core purpose of performing PCI device suspension for hibernation, including the legacy PM path, driver-specific poweroff callback behavior, default suspend when no driver PM ops exist, and the subsequent device fixup call. While it generically mentions checking conditions and callbacks, it omits specific domain terms like 'PMSG_HIBERNATE', 'pci_legacy_suspend', and 'pci_fixup_device', so the core operation is not distinctly covered and only loose secondary information is present.",
                "The summary gives a generic description of the function\u2019s purpose (handling PCI device power-off, checking hardware conditions, invoking callbacks) that aligns broadly with the code. However, it lacks specific implementation details such as legacy PM handling, use of `pci_pm_default_suspend`, conditionally calling `pm->poweroff`, and `pci_fixup_device`. No claims are outright incorrect (no FATAL), but the statements are low-info SAFE and omit key specifics. Noise is minimal but gain is limited due to vagueness."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Handles PCI device power management by checking conditions, invoking shutdown callbacks, and performing a \"pci_pm_poweroff\" sequence when appropriate.",
            "score": [
                0.5,
                0.3,
                0.4
            ],
            "reason": [
                "The summary gives a generic description of PCI device power management but lacks specificity about the actual code behavior, such as legacy PM support checks, default suspend path, or fixup handling. While the general claim about checking conditions and invoking shutdown callbacks is correct, it misses key details and sequencing found in the source, making it only partially accurate.",
                "The summary generally describes PCI device power management and mentions shutdown callbacks but fails to convey the core primary purpose: transitioning a PCI device into a hibernation power-off state using either legacy suspend or driver-specific poweroff, and performing subsequent fixup. It lacks specifics such as handling legacy PM support, the default suspend path when no PM ops exist, error handling from driver callbacks, and the final fixup stage, providing only a generic outline.",
                "The summary provides a generic and low-information description, mentioning PCI device power management and shutdown callbacks, but it omits critical specifics from the code such as legacy PM support checks, invoking `pci_legacy_suspend` with `PMSG_HIBERNATE`, conditional use of `pm->poweroff`, error handling, and device fixups. While not contradictory (no FATAL errors), the content is broad SAFE noise with minimal GOLD detail, resulting in low net benefit."
            ]
        }
    }
}
{
    "source_code": "static void drm_cleanup_buf_error(struct drm_device * dev,\n\t\t\t\t  struct drm_buf_entry * entry)\n{\n\tint i;\n\n\tif (entry->seg_count) {\n\t\tfor (i = 0; i < entry->seg_count; i++) {\n\t\t\tif (entry->seglist[i]) {\n\t\t\t\tdrm_pci_free(dev, entry->seglist[i]);\n\t\t\t}\n\t\t}\n\t\tkfree(entry->seglist);\n\n\t\tentry->seg_count = 0;\n\t}\n\n\tif (entry->buf_count) {\n\t\tfor (i = 0; i < entry->buf_count; i++) {\n\t\t\tkfree(entry->buflist[i].dev_private);\n\t\t}\n\t\tkfree(entry->buflist);\n\n\t\tentry->buf_count = 0;\n\t}\n}",
    "comment": "Cleans up allocated buffer memory and frees associated resources in a DRM device's buffer entry structure.",
    "prorec_sum": "Processes and clears entries from two linked lists or arrays, invoking a specified handler on each element before resetting their counters.",
    "filter_prorec_sum": "Processes and releases pending and queued node structures, invoking cleanup routines for each before resetting their associated counters.",
    "prorec_aug_sum": "Processes and resets GPU-related data structures by iterating queued entries and invoking a rendering update routine with provided parameters.",
    "filter_prorec_aug_sum": "Processes and clears queued and secondary entries from a graphics-related structure, invoking a rendering or update routine for each with provided parameters.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes and resets GPU-related data structures by iterating queued entries and invoking a rendering update routine with provided parameters.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function processes and resets GPU-related data structures by iterating queued entries and invoking a rendering update routine. While the code does reset and free buffer entries and associated resources, there is no evidence it invokes any rendering update routine or processes queued entries in a GPU context beyond freeing memory. These inaccuracies mean less than half of the claims align with the actual semantics, as the summary introduces incorrect operations not present in the source.",
                "The summary incorrectly describes the function as processing GPU data and invoking a rendering update routine, which contradicts the source code. The function\u2019s core purpose is to clean up and free allocated segments and buffers in a DRM device buffer entry when an error occurs, resetting counts to zero. The core action of freeing memory and handling error cleanup is completely missing, and no accurate claims from the summary align with the actual semantics.",
                "The summary contains a FATAL inaccuracy about the primary purpose: it claims the function processes GPU-related data structures and invokes a rendering update routine, but in reality the code frees allocated memory in seglist and buflist, resets counts, and does not perform rendering updates or process queued entries. This core misrepresentation of the function's behavior makes the description unusable despite minimal other detail."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes and clears queued and secondary entries from a graphics-related structure, invoking a rendering or update routine for each with provided parameters.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims the function processes and clears queued and secondary entries from a graphics-related structure and invokes a rendering or update routine for each. In reality, the source code handles cleanup by freeing allocated PCI segments and buffer memory, without any rendering or updating. All claims in the summary target code semantics but are factually incorrect, resulting in no accurate matches.",
                "The summary's claims about processing queued and secondary entries and invoking a rendering or update routine are inaccurate compared to the source code, which actually frees allocated buffer and segment memory in a DRM device buffer entry on error. The core purpose of freeing memory and resetting counters is not mentioned at all, and no accurate secondary behaviors are described.",
                "The summary\u2019s main claims \u2014 that the function processes and clears queued and secondary entries and invokes a rendering or update routine for each \u2014 are inaccurate regarding the source code. The actual code frees memory for segments and buffers in a DRM buffer entry, without performing any rendering or updates. This is a FATAL error affecting the primary purpose, which is memory cleanup, not processing or rendering. No accurate claims are present, causing the description to be misleading and unusable."
            ]
        }
    }
}
{
    "source_code": "int Xorriso_register_node_target(struct XorrisO *xorriso, int node_idx,\n                                 char *disk_path, int flag)\n{\n int l;\n\n if(xorriso->node_targets_availmem == 0)\n   return(2);\n if(xorriso->hln_targets == NULL || node_idx < 0 ||\n    node_idx >= xorriso->hln_count)\n   return(0);\n if(xorriso->hln_targets[node_idx] != NULL) {\n   xorriso->node_targets_availmem+= strlen(xorriso->hln_targets[node_idx]) +1;\n   free(xorriso->hln_targets[node_idx]);\n }\n l= strlen(disk_path);\n if(xorriso->node_targets_availmem <= l + 1) {\n   sprintf(xorriso->info_text,\n \"Hardlink target buffer exceeds -temp_mem_limit. Hardlinks may get divided.\");\n   Xorriso_msgs_submit(xorriso, 0, xorriso->info_text, 0, \"FAILURE\", 0);\n   xorriso->node_targets_availmem= 0;\n   return(0);\n }\n xorriso->hln_targets[node_idx]= strdup(disk_path);\n if(xorriso->hln_targets[node_idx] == NULL) {\n   Xorriso_no_malloc_memory(xorriso, NULL, 0);\n   return(-1);\n }\n xorriso->node_targets_availmem-= (l + 1);\n return(1);\n}",
    "comment": "Registers a hardlink target for a specified node index in the Xorriso structure, managing memory and error handling accordingly.",
    "prorec_sum": "Updates a string entry in an indexed array within a filesystem structure, freeing old data, enforcing size limits, and reporting failure if constraints are exceeded.",
    "filter_prorec_sum": "Updates a string entry in a bounded array, adjusting remaining capacity, and reports failure if the new string exceeds the available space.",
    "prorec_aug_sum": "Updates a specified string entry in an array, adjusting remaining capacity and reporting failure if the new string exceeds the allowed buffer size.",
    "filter_prorec_aug_sum": "Updates a specified string entry in a tracked list, adjusting remaining capacity and reporting failure if the new string exceeds the available buffer space.",
    "work_score": {
        "prorec_aug": {
            "summary": "Updates a specified string entry in an array, adjusting remaining capacity and reporting failure if the new string exceeds the allowed buffer size.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function updates a specified string entry in an array, adjusts remaining capacity, and reports failure if the new string exceeds the allowed buffer size. However, it omits important conditions: the function returns different codes for various failure scenarios, checks for null target array and index bounds, handles freeing old entries, and processes memory availability before updating. While the core described behavior is accurate, the lack of these details makes the coverage incomplete but still mostly aligned with the source code semantics.",
                "The summary correctly captures that the function updates an entry in an array, adjusts remaining capacity, and reports failure if the new string exceeds a buffer size, which aligns with the core purpose of managing hardlink target paths within a memory limit. However, it omits domain-specific details such as this being for hardlink targets, handling of freeing existing entries, specific return codes, and the branch for allocation failure. Coverage of secondary behavior is minimal, lacking mention of memory restoration, message submission, and edge case checks.",
                "The summary correctly identifies that the function updates a specific entry in an array and adjusts remaining capacity, and that it reports failure if the new string exceeds the allowed buffer size. However, it omits key details such as handling invalid indices, freeing old entries, multiple distinct return codes, and other specific failure conditions (like NULL allocations). The omissions reduce the informational gain, but there are no contradictory claims\u2014noise is minimal and accuracy is adequate, with the summary being generally aligned with the core domain behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Updates a specified string entry in a tracked list, adjusting remaining capacity and reporting failure if the new string exceeds the available buffer space.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly describes updating a specific entry in a tracked list and adjusting remaining capacity. It also notes reporting failure if the new string exceeds available buffer space, which matches the code's check against node_targets_availmem with a failure message. However, it omits other specific behaviors, such as early returns for invalid indices or null hln_targets, and freeing existing entries before replacement. Despite these omissions, the claims present are accurate and directly reflect the core logic, covering more than 80% of the behavior described.",
                "The summary correctly notes updating an entry in a tracked list, adjusting capacity, and reporting buffer overflow, which aligns with the function\u2019s behavior of managing hardlink target strings with memory constraints. However, it omits the core domain purpose of registering a hardlink target in the Xorriso context, and misses other critical details like freeing existing entries, specific return codes for conditions, and handling allocation failures. Coverage of secondary behaviors is minimal.",
                "The summary correctly describes that the function updates an entry in a tracked list, adjusts remaining capacity, and reports failure if the new string exceeds available space, which matches the core logic in the source code. However, it omits several key details such as early return conditions when memory is zero or node index is invalid, freeing previous entries, specific return codes (e.g., 2, 0, -1, 1), and handling malloc failure. This omission limits the specificity and gain, though there is no inaccurate or contradictory claim, and noise is minimal."
            ]
        }
    }
}
{
    "source_code": "\nstatic const char *\nget_symbol_index_type (Filedata * filedata, unsigned int type)\n{\n  static char buff[32];\n\n  switch (type)\n    {\n    case SHN_UNDEF:\treturn \"UND\";\n    case SHN_ABS:\treturn \"ABS\";\n    case SHN_COMMON:\treturn \"COM\";\n    default:\n      if (type == SHN_IA_64_ANSI_COMMON\n\t  && filedata->file_header.e_machine == EM_IA_64\n\t  && filedata->file_header.e_ident[EI_OSABI] == ELFOSABI_HPUX)\n\treturn \"ANSI_COM\";\n      else if ((filedata->file_header.e_machine == EM_X86_64\n\t\t|| filedata->file_header.e_machine == EM_L1OM\n\t\t|| filedata->file_header.e_machine == EM_K1OM)\n\t       && type == SHN_X86_64_LCOMMON)\n\treturn \"LARGE_COM\";\n      else if ((type == SHN_MIPS_SCOMMON\n\t\t&& filedata->file_header.e_machine == EM_MIPS)\n\t       || (type == SHN_TIC6X_SCOMMON\n\t\t   && filedata->file_header.e_machine == EM_TI_C6000))\n\treturn \"SCOM\";\n      else if (type == SHN_MIPS_SUNDEFINED\n\t       && filedata->file_header.e_machine == EM_MIPS)\n\treturn \"SUND\";\n      else if (type >= SHN_LOPROC && type <= SHN_HIPROC)\n\tsprintf (buff, \"PRC[0x%04x]\", type & 0xffff);\n      else if (type >= SHN_LOOS && type <= SHN_HIOS)\n\tsprintf (buff, \"OS [0x%04x]\", type & 0xffff);\n      else if (type >= SHN_LORESERVE)\n\tsprintf (buff, \"RSV[0x%04x]\", type & 0xffff);\n      else if (type >= filedata->file_header.e_shnum)\n\tsprintf (buff, _(\"bad section index[%3d]\"), type);\n      else\n\tsprintf (buff, \"%3d\", type);\n      break;\n    }\n\n  return buff;\n}",
    "comment": "Returns a string representation of a symbol index type based on the provided type and file header information.",
    "prorec_sum": "Returns a descriptive string label or formatted code representing a section type based on the given numeric identifier and header field values.",
    "filter_prorec_sum": "Returns a descriptive string label for a given section code based on specific numeric values, structural fields, and predefined formatting rules.",
    "prorec_aug_sum": "Returns a descriptive string label for a given section or communication code based on numeric identifiers and contextual header field values.",
    "filter_prorec_aug_sum": "Maps a numeric section or type code to a corresponding identifier string or formatted label based on specific value and field checks.",
    "work_score": {
        "prorec_aug": {
            "summary": "Returns a descriptive string label for a given section or communication code based on numeric identifiers and contextual header field values.",
            "score": [
                0.7,
                0.2,
                0.4
            ],
            "reason": [
                "The summary correctly conveys that the function returns a descriptive string label based on a numeric type and contextual header fields, which matches the source code's use of switch cases and header checks. However, it mislabels the domain as 'section or communication code,' which is vague and partially inaccurate \u2014 the function deals with section index types, not communication codes. While the core behavior is captured, the lack of precise terminology reduces accuracy.",
                "The summary is vague and does not accurately capture the core purpose of mapping ELF section index constants and contextual machine/OSABI values to specific symbolic string labels. It generically refers to 'section or communication code' without mentioning ELF constants or the multiple conditional mappings, resulting in the core domain action being omitted and no coverage of critical branch-specific outputs or error cases.",
                "The summary makes a vague claim that the function returns a descriptive label based on numeric identifiers and header field values, which aligns generally with the source code's behavior. However, it uses inaccurate terminology ('communication code') that does not match the ELF section index logic in the source, making it partially misleading. The claim is generic and lacks specific details about the actual cases handled, leading to low informational gain. The worst failure mode is NOISE from imprecise wording rather than a direct contradiction of core semantics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Maps a numeric section or type code to a corresponding identifier string or formatted label based on specific value and field checks.",
            "score": [
                0.9,
                0.4,
                0.5
            ],
            "reason": [
                "The summary accurately conveys the core behavior of the function, which maps a numeric section/type code to a string or formatted label based on specific value and header field conditions. While it is general and lacks mention of detailed cases like SHN_UNDEF or machine-specific checks, it does not contradict the code and reflects its domain semantics. Given that this single claim is correct, the proportion of accurate claims is 100%.",
                "The summary correctly states that the function maps numeric codes to identifier strings or labels, which matches the core behavior in the source code. However, it is vague and omits the specific section indices, constants, and machine/OS checks that are critical to understanding the detailed mapping logic. It does not cover the various conditional branches, special values, or formatted outputs present in the code, resulting in weak secondary coverage beyond the core purpose.",
                "The summary contains one broad, generic claim correctly noting that the function maps numeric codes to identifier strings based on certain checks. This is accurate but low\u2011info and lacks specific mention of the detailed conditional mappings present in the source code (e.g., handling SHN_UNDEF, machine type checks, and formatted outputs). There is no inaccurate or contradictory detail, but the absence of granular specifics makes the gain minimal. Noise is not present, so the main shortcoming is low informational value."
            ]
        }
    }
}
{
    "source_code": "\nvoid *\nFcompile (char *pattern, idx_t size, reg_syntax_t ignored, bool exact)\n{\n  kwset_t kwset;\n  char *buf = NULL;\n  idx_t bufalloc = 0;\n\n  kwset = kwsinit (true);\n\n  char const *p = pattern;\n  do\n    {\n      char const *sep = rawmemchr (p, '\\n');\n      idx_t len = sep - p;\n\n      if (match_lines)\n        {\n          if (eolbyte == '\\n' && pattern < p)\n            p--;\n          else\n            {\n              if (bufalloc < len + 2)\n                {\n                  free (buf);\n                  bufalloc = len;\n                  buf = xpalloc (NULL, &bufalloc, 2, -1, 1);\n                  buf[0] = eolbyte;\n                }\n              memcpy (buf + 1, p, len);\n              buf[len + 1] = eolbyte;\n              p = buf;\n            }\n          len += 2;\n        }\n      kwsincr (kwset, p, len);\n\n      p = sep + 1;\n    }\n  while (p <= pattern + size);\n\n  free (buf);\n\n  idx_t words = kwswords (kwset);\n  kwsprep (kwset);\n\n  struct kwsearch *kwsearch = xmalloc (sizeof *kwsearch);\n  kwsearch->kwset = kwset;\n  kwsearch->words = words;\n  kwsearch->pattern = pattern;\n  kwsearch->size = size;\n  kwsearch->re = NULL;\n  return kwsearch;\n}",
    "comment": "Processes a pattern string, initializes a keyword set, and returns a structure containing the keyword set and its associated properties.",
    "prorec_sum": "Processes an obstack buffer line by line, conditionally modifies line endings, stores them in a new obstack, and returns related buffer references.",
    "filter_prorec_sum": "Processes an obstack by splitting at newline characters, optionally modifying lines, and returns a structure containing the processed and original data.",
    "prorec_aug_sum": "Processes an obstack buffer line by line, conditionally modifies line endings, stores them in a new obstack, and returns related buffer references.",
    "filter_prorec_aug_sum": "Processes newline-delimited data from two obstack buffers, conditionally modifies line endings, and returns a structure containing aggregated and original buffer references.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes an obstack buffer line by line, conditionally modifies line endings, stores them in a new obstack, and returns related buffer references.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains multiple inaccuracies: it claims the function processes an obstack buffer line by line when the code actually operates on a pattern string and uses a kwset data structure, not an obstack. It also mentions storing lines in a new obstack and returning buffer references, but the code stores altered lines in a dynamically allocated buffer and ultimately returns a struct containing kwset metadata. None of the claims are accurate representations of the function\u2019s semantics.",
                "The summary incorrectly describes processing an obstack buffer and storing results in a new obstack, which is not present in the source code. The function instead processes a pattern string into a keyword set, optionally modifies line endings based on match_lines and eolbyte, prepares the keyword set, and returns a kwsearch structure. The core purpose of compiling patterns into a keyword set is entirely missing, and most claims are inaccurate.",
                "The summary is inaccurate: it claims the function processes an obstack buffer and stores lines in a new obstack, but the source code shows no use of obstack structures. Instead, it uses dynamic allocation with xpalloc and kwset utility functions to process a pattern string. This misrepresents the primary purpose and I/O behavior, constituting a severe factual error about the core operation."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes newline-delimited data from two obstack buffers, conditionally modifies line endings, and returns a structure containing aggregated and original buffer references.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims processing from two obstack buffers, which is unsupported by the source code \u2014 it operates on a string pattern and uses a kwset, not obstack buffers. The mention of newline-delimited data and conditional line ending modification partially aligns with the source code\u2019s handling of newline-separated segments and `match_lines` logic. However, the claim about aggregated and original buffer references is inaccurate, as the returned structure contains kwset, words count, and the original pattern pointer, but no aggregation mechanism or obstack references. Overall, the majority of claims are inaccurate, with only partial correctness in identifying newline processing and conditional modifications.",
                "The summary does not accurately reflect the source code. It incorrectly references 'two obstack buffers' which are not present, and omits the core purpose of compiling a keyword set from a newline-delimited pattern string into a kwsearch structure. The core domain action \u2014 initializing and populating a kwset with conditional line-ending adjustments based on match_lines behavior, then preparing and returning it in a kwsearch struct \u2014 is not covered. Secondary details like use of rawmemchr, xpalloc, kwswords, and kwsprep are also missing.",
                "The summary contains a severe inaccuracy about the primary purpose: it claims the function processes data from two obstack buffers, but the source code shows it works with a single char* pattern and size, using kwset operations without obstack structures. This misstates the core I/O and data source. It also inaccurately describes returned structure contents as aggregated and original buffer references, whereas the code returns a kwsearch struct with kwset, words count, original pattern, and null regex pointer. These FATAL errors on core semantics make the description untrustworthy, with minimal accurate content."
            ]
        }
    }
}
{
    "source_code": "bool pm_wakeup_pending(void)\n{\n\tunsigned long flags;\n\tbool ret = false;\n\n\tspin_lock_irqsave(&events_lock, flags);\n\tif (events_check_enabled) {\n\t\tunsigned int cnt, inpr;\n\n\t\tsplit_counters(&cnt, &inpr);\n\t\tret = (cnt != saved_count || inpr > 0);\n\t\tevents_check_enabled = !ret;\n\t}\n\tspin_unlock_irqrestore(&events_lock, flags);\n\n\tif (ret)\n\t\tprint_active_wakeup_sources();\n\n\treturn ret;\n}",
    "comment": "Checks if a wakeup event is pending by comparing counters and prints active wakeup sources if there is a pending event.",
    "prorec_sum": "Checks a hardware unlock status flag, updates it, and triggers follow\u2011up actions on eligible devices in a linked list based on specific conditions.",
    "filter_prorec_sum": "Checks a hardware unlock status and, if successful, iterates registered devices to trigger specific actions on flagged or most recent entries.",
    "prorec_aug_sum": "Checks a global state flag and triggers specific callbacks for CPU idle devices, selecting one based on activity status and timestamp.",
    "filter_prorec_aug_sum": "Checks a global status flag, updates related data structures, and triggers callbacks for active or most recent entries before returning a success indicator.",
    "work_score": {
        "prorec_aug": {
            "summary": "Checks a global state flag and triggers specific callbacks for CPU idle devices, selecting one based on activity status and timestamp.",
            "score": [
                0.1,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about triggering callbacks for CPU idle devices, selecting based on activity status and timestamp, are not supported by the source code. The function actually checks `events_check_enabled`, compares counters, updates the flag, and possibly prints active wakeup sources. None of these match the CPU idle/timestamp narrative, making the claims inaccurate and unrelated to the code's actual semantics.",
                "The summary\u2019s claims about triggering callbacks for CPU idle devices with selection based on activity status and timestamp are inaccurate; the source code checks if wakeup events are pending using event counters and a lock, disables further checks when appropriate, and prints active wakeup sources. The core purpose of detecting pending PM wakeup events is entirely missing, and no secondary behaviors like counter comparison, locking, or side effects are covered.",
                "The summary inaccurately describes the function\u2019s purpose, introducing details about CPU idle devices, activity status, and timestamps, none of which are present in the source code. The actual function checks a global flag, inspects event counters, updates the flag, potentially prints wakeup sources, and returns a boolean indicating pending wakeups. These mismatches are severe because they misstate the core domain action, representing a FATAL error on the primary purpose. There are no accurate claims that align meaningfully with the code, resulting in zero net benefit."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Checks a global status flag, updates related data structures, and triggers callbacks for active or most recent entries before returning a success indicator.",
            "score": [
                0.2,
                0.1,
                0.4
            ],
            "reason": [
                "The summary's claims are largely inaccurate. It says the function checks a global status flag, updates data structures, and triggers callbacks for recent entries. In the source, the function locks a spinlock, checks the 'events_check_enabled' flag, compares counter values, updates the flag, optionally prints active wakeup sources, and returns a boolean. While the mention of checking a global flag loosely matches, there is no updating of general data structures nor callbacks for recent entries; instead, it performs counter checks and conditionally prints. Most claims do not accurately reflect the code's semantics, resulting in low accuracy.",
                "The summary fails to capture the core purpose of the function, which is to determine if a power management wakeup is pending by comparing event counters under a spinlock, updating a flag accordingly, and optionally printing active wakeup sources. Instead, it vaguely mentions checking a global flag, updating data structures, and triggering callbacks, which misrepresents the actual semantics. No claims in the summary accurately describe the specific domain operation, and secondary details like spinlock usage, counter comparison, and conditional printing are omitted or incorrectly generalized.",
                "The summary contains mostly inaccurate claims about the function's behavior. It incorrectly describes triggering callbacks for active or recent entries, which is not present in the code, and vaguely mentions updating related data structures without specifying the actual counter comparison and flag update logic. The only partial accuracy is in noting it checks a global status flag and returns an indicator, but the rest is noise. The worst failure mode is NOISE dominating with minimal accurate detail, resulting in low net benefit."
            ]
        }
    }
}
{
    "source_code": "\nstruct local_symbol *\nlocal_symbol_make (const char *name, segT section, valueT val, fragS *frag)\n{\n  const char *name_copy;\n  struct local_symbol *ret;\n\n  ++local_symbol_count;\n\n  name_copy = save_symbol_name (name);\n\n  ret = (struct local_symbol *) obstack_alloc (&notes, sizeof *ret);\n  ret->lsy_flags.sy_local_symbol = 1;\n  ret->lsy_flags.sy_resolved = 0;\n  ret->lsy_name = name_copy;\n  ret->lsy_section = section;\n  local_symbol_set_frag (ret, frag);\n  ret->lsy_value = val;\n\n  hash_jam (local_hash, name_copy, (void *) ret);\n\n  return ret;\n}",
    "comment": "Creates and initializes a local symbol structure, copying its name, setting properties, and storing it in a hash table.",
    "prorec_sum": "Allocates space in an obstack for a new object, stores provided fields, updates control flags, and registers it with a global table.",
    "filter_prorec_sum": "Allocates space in an obstack for a new object, stores provided parameters into it, and registers it through a handler function.",
    "prorec_aug_sum": "Allocates a new 40-byte object in an obstack, stores provided parameters, updates alignment and chunk pointers, and registers it via a callback.",
    "filter_prorec_aug_sum": "Allocates and initializes a new obstack object with supplied parameters and string data, then registers it using a dedicated handler function.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates a new 40-byte object in an obstack, stores provided parameters, updates alignment and chunk pointers, and registers it via a callback.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains multiple inaccurate claims: it specifies a 40-byte allocation, alignment updates, and chunk pointer modifications, none of which are evident in the source code. The source only shows allocation of a struct via obstack_alloc, assignment of provided parameters to fields, setting flags, and insertion into a hash table. The mention of 'registers it via a callback' is also unsupported. Very few, if any, claims accurately reflect the code's semantics, leading to low accuracy.",
                "The summary omits the core purpose of creating and initializing a local_symbol with name, section, value, frag, updating flags, and adding it to a hash table. Instead, it describes generic allocation details like byte size, alignment, and a callback, which are not mentioned in the source code. None of the claims accurately match the specific domain semantics, so the core function behavior is not covered.",
                "The summary introduces inaccurate, non-verifiable details not present in the source code, such as claiming a fixed 40-byte allocation, updates to alignment and chunk pointers, and registration via a callback. These statements contradict the actual function, which allocates sizeof(struct local_symbol) from an obstack, sets specific struct fields, and registers the symbol in a hash table. The inaccuracies target the core behavior, making them FATAL errors on primary purpose/I/O. There are no substantial accurate claims to offset this, resulting in severely low net benefit."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates and initializes a new obstack object with supplied parameters and string data, then registers it using a dedicated handler function.",
            "score": [
                0.2,
                0.3,
                0.2
            ],
            "reason": [
                "The summary contains mostly inaccurate claims: it describes allocating and initializing a generic obstack object rather than a `struct local_symbol`, omits mention of setting specific struct fields like `sy_local_symbol` and `sy_resolved`, and incorrectly generalizes 'string data' instead of copying the symbol name via `save_symbol_name`. It also misrepresents `hash_jam` as a generic 'dedicated handler function' without specific reference to hashing local symbols. These deviations mean less than half of the summary\u2019s claims align with the source code\u2019s actual semantics.",
                "The summary correctly notes allocation and initialization using obstack, and mentions using supplied parameters and string data, which aligns with the function creating and populating a local_symbol via obstack_alloc and save_symbol_name. However, it misrepresents the core purpose: the function specifically creates and registers a local_symbol in a hash table, not a generic obstack object. The claim 'registers it using a dedicated handler function' is vague and does not capture the domain-specific operation of inserting into local_hash. Overall, the core domain action is missing, with only partial accuracy on secondary details.",
                "The summary incorrectly describes the function as allocating and initializing a new obstack object, which contradicts the source code \u2014 the obstack is preexisting and used to allocate a local_symbol struct. This is a severe factual error targeting the core purpose (object type and initialization). While it correctly notes parameter use and registration via a handler function, the primary object type is misidentified, making this a FATAL error with low net benefit."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\ngss_pipe_release(struct inode *inode)\n{\n\tstruct net *net = inode->i_sb->s_fs_info;\n\tstruct rpc_pipe *pipe = RPC_I(inode)->pipe;\n\tstruct gss_upcall_msg *gss_msg;\n\nrestart:\n\tspin_lock(&pipe->lock);\n\tlist_for_each_entry(gss_msg, &pipe->in_downcall, list) {\n\n\t\tif (!list_empty(&gss_msg->msg.list))\n\t\t\tcontinue;\n\t\tgss_msg->msg.errno = -EPIPE;\n\t\tatomic_inc(&gss_msg->count);\n\t\t__gss_unhash_msg(gss_msg);\n\t\tspin_unlock(&pipe->lock);\n\t\tgss_release_msg(gss_msg);\n\t\tgoto restart;\n\t}\n\tspin_unlock(&pipe->lock);\n\n\tput_pipe_version(net);\n}",
    "comment": "Releases GSS upcall messages in a pipe by unhashing and incrementing the error count for empty message lists before freeing resources.",
    "prorec_sum": "Iterates through a linked list of objects, updates their state, invokes two processing callbacks with given parameters, and finalizes with a cleanup operation.",
    "filter_prorec_sum": "Iterates through and updates linked queue entries with new parameters, invoking specified callbacks, then finalizes processing via a related control structure.",
    "prorec_aug_sum": "Iterates over and updates linked service entries, applies numeric adjustments, triggers two processing callbacks, then finalizes using a secondary service pointer.",
    "filter_prorec_aug_sum": "Iterates through a linked list of structures, updates fields, invokes two processing callbacks with numeric parameters, and finalizes by calling a service-related function.",
    "work_score": {
        "prorec_aug": {
            "summary": "Iterates over and updates linked service entries, applies numeric adjustments, triggers two processing callbacks, then finalizes using a secondary service pointer.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains vague and inaccurate claims about 'linked service entries', 'numeric adjustments', and 'secondary service pointer' that do not align with the source code\u2019s explicit operations on gss_upcall_msg structures within rpc_pipe, setting errno to -EPIPE, incrementing a counter, unhashing, releasing messages, and updating pipe version. These mismatches indicate the claims are not targeting the actual code semantics, resulting in no accurate statements.",
                "The summary does not accurately capture the core behavior of the function, which is to iterate through GSS upcall messages in a pipe, mark empty ones with an error (-EPIPE), increment their reference count, unhash and release them within a lock-safe loop, and finally update the pipe version using the network context. The described actions about 'linked service entries', 'numeric adjustments', and 'secondary service pointer' do not match the domain semantics or include the specific error handling and message release logic shown in the code.",
                "The summary contains mostly inaccurate claims: it refers to 'linked service entries', 'numeric adjustments', and 'secondary service pointer', none of which directly correspond to the source code's actual handling of gss_upcall_msg structures, list traversal, error setting, reference counting, and cleanup functions. Core purpose is misstated, as the function releases messages in a pipe before updating the pipe version, not generic 'service entries'. These mismatches contradict the source code's semantics, making them FATAL with respect to the primary behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Iterates through a linked list of structures, updates fields, invokes two processing callbacks with numeric parameters, and finalizes by calling a service-related function.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary misrepresents key semantics of the code: it claims two processing callbacks with numeric parameters are invoked, but in reality the function calls `__gss_unhash_msg` and `gss_release_msg` without explicit numeric arguments. It also omits specific details like setting `errno` to `-EPIPE`, atomic increment of `count`, locking and unlocking the pipe, and the restart loop. While it correctly notes iteration over a linked list and a final call to a service-related function (`put_pipe_version`), most claims are either vague or inaccurate when compared to the code, resulting in less than half being accurate.",
                "The summary fails to capture the core purpose, which is to release GSS upcall messages from an RPC pipe, mark them with an EPIPE error, unhash and release them, and finally update the pipe version. While it mentions iterating through a linked list and updating fields, these are vague generics and omit the specific GSS/RPC context. It also inaccurately describes 'two processing callbacks with numeric parameters' instead of the actual unhash and release functions, and lacks coverage of error handling (-EPIPE), loop restart behavior, and final pipe version update.",
                "The summary generically describes iterating through a list and updating fields, but several details are inaccurate or missing. It incorrectly mentions two processing callbacks with numeric parameters, whereas the code locks, updates `errno` to -EPIPE, increments a count, unhashes and releases messages (these are specific functions, not generic callbacks). The 'service-related function' reference to `put_pipe_version` is vague and non-specific. The summary omits key accurate behaviors like locking/unlocking, conditional checking for empty lists, and restarting the loop. Noise outweighs accurate content, and there are no specific GOLD-level claims."
            ]
        }
    }
}
{
    "source_code": "void FAST_FUNC add_to_ino_dev_hashtable(const struct stat *statbuf, const char *name)\n{\n\tint i;\n\tino_dev_hashtable_bucket_t *bucket;\n\n\tif (!name)\n\t\tname = \"\";\n\tbucket = xmalloc(sizeof(ino_dev_hashtable_bucket_t) + strlen(name));\n\tbucket->ino = statbuf->st_ino;\n\tbucket->dev = statbuf->st_dev;\n\tbucket->isdir = !!S_ISDIR(statbuf->st_mode);\n\tstrcpy(bucket->name, name);\n\n\tif (!ino_dev_hashtable)\n\t\tino_dev_hashtable = xzalloc(HASH_SIZE * sizeof(*ino_dev_hashtable));\n\n\ti = hash_inode(statbuf->st_ino);\n\tbucket->next = ino_dev_hashtable[i];\n\tino_dev_hashtable[i] = bucket;\n}",
    "comment": "Adds a new entry to the inode-device hashtable using the provided stat structure and name, allocating memory for the bucket dynamically.",
    "prorec_sum": "Creates and links a new file entry from given parameters, handling symlink identification and inserting it into a global hash table.",
    "filter_prorec_sum": "Creates a new file entry structure using provided metadata and inserts it into a hash table, initializing fields and symlink-related attributes.",
    "prorec_aug_sum": "Allocates and links a new entry into a hash table, initializing fields from input parameters and copying identifier data from the provided source.",
    "filter_prorec_aug_sum": "Creates and links a new structure for the given key, initializes its fields from input data, and stores it in a global hash table.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and links a new entry into a hash table, initializing fields from input parameters and copying identifier data from the provided source.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function allocates and links a new entry into a hash table, initializes fields from input parameters, and copies identifier data from the provided source. These all align with the source code's behavior of malloc-ing a bucket, setting ino/dev/isdir from statbuf, copying the name, and inserting into the hash table. No inaccuracies are present, and the coverage is broadly faithful to the code semantics, though the summary is somewhat generic without naming specific fields.",
                "The summary correctly notes allocation, linking into a hash table, and initializing fields from input parameters, aligning with source code behavior. However, it omits the core domain specifics such as using inode and device values from the stat structure, handling a NULL name by substituting an empty string, determining if the entry is a directory, initializing the global hash table if needed, and calculating the hash index. Thus, while the core purpose of adding an entry to an inode/device hash table is partially implied, key details are missing, resulting in weak secondary coverage.",
                "The summary correctly states that the function allocates and links a new entry into a hash table and initializes fields from input parameters, which matches the source code\u2019s behavior. However, the phrase 'copying identifier data from the provided source' is vague and misses specific details such as extracting inode, device, and directory status or the handling of name defaulting to an empty string when null. No claims are inaccurate, but the gain is low due to the generic nature and omission of important specifics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Creates and links a new structure for the given key, initializes its fields from input data, and stores it in a global hash table.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly captures the creation of a new structure, initialization of fields from the provided stat data and name, and insertion into a global hash table, which aligns with the code's behavior. While it is generic and lacks specifics such as handling of null names or directory checks, it contains no inaccuracies and covers the primary semantics, making the claims fully accurate.",
                "The summary captures the generic idea of creating a structure, populating it from inputs, and placing it in a global hash table, which aligns with the code\u2019s behavior. However, it omits the core domain-specific purpose of adding an inode/device bucket keyed from a stat structure for hashed lookup, as well as specific secondary details like handling a NULL name by defaulting to an empty string, determining directory status, allocating memory sizes, and using a hash function on the inode. This results in coverage that is generic rather than specific to the actual function\u2019s semantics.",
                "The summary is largely accurate but generic. It reflects the core purpose \u2014 creating a structure, populating it from input, and inserting it into a global hash table \u2014 without introducing incorrect claims. However, the description omits specific and useful details from the source code such as handling a NULL name, memory allocation sizes, computing the isdir flag using S_ISDIR, initializing the global table if NULL, and using a hash function for positioning. The lack of these specifics limits the informational gain, making it low-benefit, but noise is minimal and there are no fatal inaccuracies."
            ]
        }
    }
}
{
    "source_code": "int loadkmap_main(int argc UNUSED_PARAM, char **argv)\n{\n\tstruct kbentry ke;\n\tint i, j, fd;\n\tuint16_t ibuff[NR_KEYS];\n/*\tconst char *tty_name = CURRENT_TTY; */\n\tRESERVE_CONFIG_BUFFER(flags, MAX_NR_KEYMAPS);\n\n\t/* When user accidentally runs \"loadkmap FILE\"\n\t * instead of \"loadkmap <FILE\", we end up waiting for input from tty.\n\t * Let's prevent it: */\n\tif (argv[1])\n\t\tbb_show_usage();\n/* bb_warn_ignoring_args(argv[1]); */\n\n\tfd = get_console_fd_or_die();\n/* or maybe:\n\topt = getopt32(argv, \"C:\", &tty_name);\n\tfd = xopen_nonblocking(tty_name);\n*/\n\n\txread(STDIN_FILENO, flags, 7);\n\tif (!is_prefixed_with(flags, BINARY_KEYMAP_MAGIC))\n\t\tbb_error_msg_and_die(\"not a valid binary keymap\");\n\n\txread(STDIN_FILENO, flags, MAX_NR_KEYMAPS);\n\n\tfor (i = 0; i < MAX_NR_KEYMAPS; i++) {\n\t\tif (flags[i] != 1)\n\t\t\tcontinue;\n\t\txread(STDIN_FILENO, ibuff, NR_KEYS * sizeof(uint16_t));\n\t\tfor (j = 0; j < NR_KEYS; j++) {\n\t\t\tke.kb_index = j;\n\t\t\tke.kb_table = i;\n\t\t\tke.kb_value = ibuff[j];\n\t\t\t/*\n\t\t\t * Note: table[idx:0] can contain special value\n\t\t\t * K_ALLOCATED (marks allocated tables in kernel).\n\t\t\t * dumpkmap saves the value as-is; but attempts\n\t\t\t * to load it here fail, since it isn't a valid\n\t\t\t * key value: it is K(KT_SPEC,126) == 2<<8 + 126,\n\t\t\t * whereas last valid KT_SPEC is\n\t\t\t * K_BARENUMLOCK == K(KT_SPEC,19).\n\t\t\t * So far we just ignore these errors:\n\t\t\t */\n\t\t\tioctl(fd, KDSKBENT, &ke);\n\t\t}\n\t}\n\n\tif (ENABLE_FEATURE_CLEAN_UP) {\n\t\tclose(fd);\n\t\tRELEASE_CONFIG_BUFFER(flags);\n\t}\n\treturn EXIT_SUCCESS;\n}",
    "comment": "Loads a binary keymap from standard input and updates the keyboard mapping using ioctl calls for each valid keymap.",
    "prorec_sum": "Processes a binary keymap file, validates its format, and registers all defined key mappings into the system using the provided device identifier.",
    "filter_prorec_sum": "Processes a binary keymap file, validates its header, and registers mappings for active keys using a given device identifier.",
    "prorec_aug_sum": "Processes a binary keymap file, validates its signature, and registers all defined key mappings using the specified device or configuration identifier.",
    "filter_prorec_aug_sum": "Processes a binary keymap file, validates its header, and registers key mappings by iterating through key codes and associated mapping values.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes a binary keymap file, validates its signature, and registers all defined key mappings using the specified device or configuration identifier.",
            "score": [
                0.6,
                0.6,
                0.5
            ],
            "reason": [
                "The summary contains some accurate elements, such as processing a binary keymap file and validating its signature, which match the code\u2019s reading and validation of BINARY_KEYMAP_MAGIC. However, the claim about registering key mappings using a specified device or configuration identifier is misleading; the code explicitly acquires the console file descriptor internally and does not use any externally specified identifier. This introduces an inaccuracy in code semantics, reducing overall precision to a mixed level.",
                "The summary states that the function processes a binary keymap file, validates its signature, and registers all defined key mappings using a specified device/config identifier. The first two parts are accurate: the code reads from STDIN, checks for the binary keymap magic prefix, and processes the mappings. However, the phrase about 'specified device or configuration identifier' is misleading; the code obtains a console file descriptor internally and does not use an externally specified device/config value. The core purpose\u2014reading a binary keymap from STDIN, validating it, and loading mappings via ioctl into the console\u2014is essentially covered, but secondary details like handling invalid signatures, skipping non-active tables, and ignoring certain invalid key values are omitted, and one part is inaccurately phrased.",
                "The summary correctly describes that the function processes a binary keymap file and validates its signature, which aligns with the code\u2019s reading from stdin and checking for the magic header. However, the phrase about registering all defined key mappings using a specified device or configuration identifier is somewhat inaccurate: the code uses a fixed console file descriptor from get_console_fd_or_die, not a user-specified device or arbitrary configuration identifier. This is a minor inaccuracy regarding the I/O semantics but not a severe FATAL error. Most of the content is accurate but quite general, offering limited detail beyond the basic steps, resulting in low gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes a binary keymap file, validates its header, and registers key mappings by iterating through key codes and associated mapping values.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary states that the function processes a binary keymap file, validates its header, and registers key mappings by iterating through key codes and mapping values. These are accurate representations of the source code: it reads from stdin, checks for the binary keymap magic in the header, and uses ioctl to register key mappings after looping through indices and tables. No inaccuracies or irrelevant claims are present.",
                "The summary correctly captures the core purpose of loading a binary keymap, validating its header, and registering key mappings, which aligns with the function's domain behavior using ioctl to set entries. However, it misses secondary details such as reading from STDIN rather than a file argument, handling accidental usage errors, the structure of data read (flags and ibuff per table), the magic constant check, and ignoring invalid key values. This results in incomplete coverage of key error handling and edge-case behavior found in the source.",
                "The summary captures the core purpose accurately: reading a binary keymap from stdin, checking its magic header, and iterating over key tables and key codes to set mappings via ioctl. No contradictory or irrelevant claims are present, and the points are specific enough to reflect the actual source logic. While the phrasing is somewhat general and omits details like reading flags arrays and handling invalid values, the alignment with the primary purpose is strong and noise is minimal."
            ]
        }
    }
}
{
    "source_code": "\nstatic int i915_ring_freq_table(struct seq_file *m, void *unused)\n{\n\tstruct drm_info_node *node = (struct drm_info_node *) m->private;\n\tstruct drm_device *dev = node->minor->dev;\n\tdrm_i915_private_t *dev_priv = dev->dev_private;\n\tint ret;\n\tint gpu_freq, ia_freq;\n\n\tif (!(IS_GEN6(dev) || IS_GEN7(dev))) {\n\t\tseq_printf(m, \"unsupported on this chipset\\n\");\n\t\treturn 0;\n\t}\n\n\tret = mutex_lock_interruptible(&dev_priv->rps.hw_lock);\n\tif (ret)\n\t\treturn ret;\n\n\tseq_printf(m, \"GPU freq (MHz)\\tEffective CPU freq (MHz)\\tEffective Ring freq (MHz)\\n\");\n\n\tfor (gpu_freq = dev_priv->rps.min_delay;\n\t     gpu_freq <= dev_priv->rps.max_delay;\n\t     gpu_freq++) {\n\t\tia_freq = gpu_freq;\n\t\tsandybridge_pcode_read(dev_priv,\n\t\t\t\t       GEN6_PCODE_READ_MIN_FREQ_TABLE,\n\t\t\t\t       &ia_freq);\n\t\tseq_printf(m, \"%d\\t\\t%d\\t\\t\\t\\t%d\\n\",\n\t\t\t   gpu_freq * GT_FREQUENCY_MULTIPLIER,\n\t\t\t   ((ia_freq >> 0) & 0xff) * 100,\n\t\t\t   ((ia_freq >> 8) & 0xff) * 100);\n\t}\n\n\tmutex_unlock(&dev_priv->rps.hw_lock);\n\n\treturn 0;\n}",
    "comment": "Retrieves and prints GPU, effective CPU, and effective Ring frequencies for Intel Gen6 and Gen7 chipsets, while protecting access with a mutex lock.",
    "prorec_sum": "Displays a formatted table of GPU, effective CPU, and ring frequencies if supported by the chipset, otherwise reports unsupported hardware.",
    "filter_prorec_sum": "Displays the GPU, effective CPU, and ring frequency table for supported Intel chipsets via a seq_file interface.",
    "prorec_aug_sum": "Outputs GPU, CPU, and ring frequencies in MHz for supported chipsets, iterating measurement points and printing formatted results via the provided stream.",
    "filter_prorec_aug_sum": "Outputs GPU, effective CPU, and Ring frequencies in MHz, iterating supported steps, or reports chipset unsupported if capability check fails.",
    "work_score": {
        "prorec_aug": {
            "summary": "Outputs GPU, CPU, and ring frequencies in MHz for supported chipsets, iterating measurement points and printing formatted results via the provided stream.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function outputs GPU, CPU, and ring frequencies in MHz for supported chipsets, and notes that it iterates over measurement points and prints formatted results to the provided stream. These are accurate descriptions of the core semantics from the source code, including the conditional chipset support, iteration over frequency values, and output via seq_printf. All stated claims align with the code without contradictions, and no irrelevant or incorrect details are present.",
                "The summary correctly states that the function outputs GPU, CPU, and ring frequencies in MHz and formats the results for supported chipsets, which matches the core purpose of iterating through the frequency range and printing to the seq_file stream. However, it omits several important secondary details such as the specific GEN6/GEN7 chipset check, use of a hardware mutex lock to protect access, the call to sandybridge_pcode_read to obtain CPU and ring frequencies, and the handling for unsupported chipsets. This results in partial coverage of key behavior beyond the core purpose.",
                "The summary correctly states that the function outputs GPU, CPU, and ring frequencies in MHz, only for supported chipsets, and that it iterates through measurement points to print formatted results via the provided stream. These claims align with the source code\u2019s purpose and behavior, including iteration over frequency values, chipset support checks, and formatted output via seq_printf. The summary omits some implementation details like the locking mechanism and exact chipset generation checks, but contains no inaccurate or misleading statements. The gain is moderate since the claims are accurate about the core purpose but not deeply specific (e.g., missing GEN6/GEN7 specifics and pcode read). Noise is minimal and there are no fatal errors."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Outputs GPU, effective CPU, and Ring frequencies in MHz, iterating supported steps, or reports chipset unsupported if capability check fails.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function outputs GPU, effective CPU, and Ring frequencies in MHz and reports unsupported chipsets after a capability check, matching the code's behavior for GEN6/GEN7 check. The mention of iterating supported steps aligns with the loop from min_delay to max_delay. All claims are accurate and grounded in the source code.",
                "The summary correctly captures the core purpose of outputting a table of GPU, effective CPU, and Ring frequencies in MHz for supported chipsets, which aligns with the code\u2019s loop over frequency steps and printing the results. It also mentions the chipset capability check and unsupported message. However, it omits key secondary details such as the requirement for Gen6/Gen7 hardware, the mutex lock/unlock around hardware access, and the use of sandybridge_pcode_read to populate values. This limits coverage of behavior-critical semantics and edge cases.",
                "The summary correctly captures the primary purpose of the function: outputting GPU, effective CPU, and Ring frequencies in MHz for supported chipsets, and reporting unsupported chipsets if the capability check fails. These are accurate GOLD claims since they reflect key I/O and domain semantics. Details about iterating over supported frequency steps are also accurate. There is no conflicting or irrelevant content (NOISE) and no fatal errors on core semantics. The claim coverage is concise but specific, providing clear insight into the function\u2019s behavior."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nlisting_page (list_info_type *list)\n{\n  /* Grope around, see if we can see a title or subtitle edict coming up\n     soon.  (we look down 10 lines of the page and see if it's there)  */\n  if ((eject || (on_page >= (unsigned int) paper_height))\n      && paper_height != 0)\n    {\n      unsigned int c = 10;\n      int had_title = 0;\n      int had_subtitle = 0;\n\n      page++;\n\n      while (c != 0 && list)\n\t{\n\t  if (list->edict == EDICT_SBTTL && !had_subtitle)\n\t    {\n\t      had_subtitle = 1;\n\t      subtitle = list->edict_arg;\n\t    }\n\t  if (list->edict == EDICT_TITLE && !had_title)\n\t    {\n\t      had_title = 1;\n\t      title = list->edict_arg;\n\t    }\n\t  list = list->next;\n\t  c--;\n\t}\n\n      if (page > 1)\n\t{\n\t  fprintf (list_file, \"\\f\");\n\t}\n\n      fprintf (list_file, \"%s %s \\t\\t\\tpage %d\\n\", LISTING_HEADER, fn, page);\n      fprintf (list_file, \"%s\\n\", title);\n      fprintf (list_file, \"%s\\n\", subtitle);\n      on_page = 3;\n      eject = 0;\n    }\n}",
    "comment": "The function checks for titles and subtitles in a list before printing the current page header, title, and subtitle to a file.",
    "prorec_sum": "Generates a formatted \u201cGAS LISTING\u201d page header and prints stored source and location lines to the listing output file.",
    "filter_prorec_sum": "Generates a formatted \u201cGAS LISTING\u201d page header and outputs associated title and subtitle strings to the listing file stream.",
    "prorec_aug_sum": "Generates a formatted \u201cGAS LISTING\u201d page header and prints stored title and subtitle lines to the listing output file.",
    "filter_prorec_aug_sum": "Generates a formatted \"GAS LISTING\" page header and outputs associated title and subtitle lines to the listing file stream.",
    "work_score": {
        "prorec_aug": {
            "summary": "Generates a formatted \u201cGAS LISTING\u201d page header and prints stored title and subtitle lines to the listing output file.",
            "score": [
                0.8,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly captures that the function outputs a formatted page header with stored title and subtitle lines to the listing output file, which matches the code behavior. However, it inaccurately specifies the header as \u201cGAS LISTING,\u201d a detail not present in the source, reducing precision. Most of the summary aligns with the actual semantics, but the header name is a significant unsupported addition.",
                "The summary correctly states that the function formats a listing page header and prints the title and subtitle, which matches the core purpose of writing a page header and associated lines to the listing output file. However, it omits other important details such as the conditional triggering based on page height/eject, scanning up to 10 lines for titles and subtitles, pagination handling, and resetting page state variables. Secondary behavior coverage is minimal.",
                "The summary correctly states that the function generates a page header and prints the stored title and subtitle to the listing file, which matches the code\u2019s behavior of writing the header, title, and subtitle via fprintf. However, it inaccurately specifies 'GAS LISTING' in quotes, which is not evident in the source code\u2014the header string comes from LISTING_HEADER and could be different. This is a minor inaccuracy but does not target core I/O fatally. The claim is otherwise brief and generic, offering low informational gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Generates a formatted \"GAS LISTING\" page header and outputs associated title and subtitle lines to the listing file stream.",
            "score": [
                0.7,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly notes that the function outputs a formatted page header and associated title/subtitle lines to the listing file stream, which matches the source code behavior using fprintf with header, title, and subtitle variables. However, it inaccurately specifies 'GAS LISTING' as the header text, while the actual code uses the LISTING_HEADER constant rather than a hardcoded 'GAS LISTING'. This makes the claim partially inaccurate, reducing precision overall.",
                "The summary correctly notes that the function outputs a formatted page header with title and subtitle to the listing file, which matches the core behavior. However, it omits important conditional logic such as checking eject status or page overflow, scanning up to 10 lines for edicts, incrementing the page only when conditions are met, and printing a form feed for pages beyond the first. This results in incomplete coverage of secondary behavior-critical details.",
                "The summary correctly states that the function generates a formatted listing page header and outputs the title and subtitle to a file, which aligns with the observed use of fprintf calls and the handling of LISTING_HEADER, title, and subtitle variables. However, it omits conditional logic details such as checking for eject state, page height constraints, scanning up to 10 entries to locate title/subtitle, and pagination behavior. While there is no incorrect claim (no FATAL), the description is generic and lacks these specific implementation details, resulting in low informational gain."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_multifit_fdfsolver_test (const gsl_multifit_fdfsolver * s,\n                             const double xtol, const double gtol,\n                             const double ftol, int *info)\n{\n  int status;\n  double gnorm, fnorm, phi;\n\n  *info = 0;\n\n  status = gsl_multifit_test_delta(s->dx, s->x, xtol*xtol, xtol);\n  if (status == GSL_SUCCESS)\n    {\n      *info = 1;\n      return GSL_SUCCESS;\n    }\n\n  /* compute gradient g = J^T f */\n  (s->type->gradient) (s->state, s->g);\n\n  /* compute gnorm = max_i( g_i * max(x_i, 1) ) */\n  gnorm = scaled_infnorm(s->x, s->g);\n\n  /* compute fnorm = ||f|| */\n  fnorm = gsl_blas_dnrm2(s->f);\n  phi = 0.5 * fnorm * fnorm;\n\n  if (gnorm <= gtol * GSL_MAX(phi, 1.0))\n    {\n      *info = 2;\n      return GSL_SUCCESS;\n    }\n\n#if 0\n  if (dfnorm <= ftol * GSL_MAX(fnorm, 1.0))\n    {\n      *info = 3;\n      return GSL_SUCCESS;\n    }\n#endif\n\n  return GSL_CONTINUE;\n}",
    "comment": "Evaluates the convergence of a multifit solver by checking parameter changes, gradient norms, and function norms against specified tolerances.",
    "prorec_sum": "Checks nonlinear fit convergence using delta and residual norms, updating status and returning codes based on scaled residual magnitude thresholds.",
    "filter_prorec_sum": "Checks nonlinear fit solver convergence using parameter changes and residual norms, updating status codes or invoking callbacks when thresholds are met.",
    "prorec_aug_sum": "Tests convergence of a GSL multifit solver using delta and residual norms, updating status codes based on tolerance and scaled Jacobian step magnitude.",
    "filter_prorec_aug_sum": "Tests convergence of a GSL multifit solver by comparing delta, residual norms, and Jacobian scaling, then sets the termination status accordingly.",
    "work_score": {
        "prorec_aug": {
            "summary": "Tests convergence of a GSL multifit solver using delta and residual norms, updating status codes based on tolerance and scaled Jacobian step magnitude.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function tests convergence for a GSL multifit solver by checking delta and residual norms, and updates status codes based on tolerance conditions. It also references the scaled Jacobian step magnitude, which corresponds to the gradient norm calculation in the code. All claims are relevant to the source and domain semantics, with no contradictions or off-topic statements, indicating high precision.",
                "The summary correctly identifies the function as testing convergence of a GSL multifit solver and mentions use of delta and residual norms, which matches core purpose and part of the logic. It also references updating status codes based on tolerance and scaled Jacobian step magnitude, aligned with the code's gradient and scaled infinity norm check. However, it omits some secondary details such as the specific handling of xtol vs. gtol thresholds, the exact sequence of checks, and lack of mention of phi computation or ignored ftol branch. Thus, while core coverage is strong, secondary coverage is limited.",
                "The summary correctly identifies that the function tests convergence of a GSL multifit solver and mentions use of delta tests, residual norms, and tolerance-based status codes, which aligns with the code's logic. However, it inaccurately refers to 'scaled Jacobian step magnitude'\u2014the code computes the scaled norm of the gradient vector, not the Jacobian step magnitude\u2014making this a semantic inaccuracy on an important detail. While most claims are accurate and concise, the presence of this specific but incorrect technical detail reduces trust but does not completely undermine the primary purpose. Noise is low, but gain is moderate due to lack of explicit detail on all stopping criteria and tolerances."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Tests convergence of a GSL multifit solver by comparing delta, residual norms, and Jacobian scaling, then sets the termination status accordingly.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly conveys that the function tests convergence of a GSL multifit solver using delta, residual norms, and gradient-based (Jacobian-derived) measures, and sets termination statuses accordingly. All claims relate directly to the function's logic: the delta check via gsl_multifit_test_delta, norms from residuals and gradient scaling, and setting the info flag before returning the appropriate status. There are no inaccurate or off-topic statements, making the description precise and aligned with the source code behavior.",
                "The summary correctly identifies the function's purpose of testing convergence for a GSL multifit solver and notes key elements like delta, residual norms, and Jacobian-based scaling, which matches the gradient norm computation in the code. This covers the core primary purpose with good specificity. However, it omits important secondary details such as the exact use of thresholds (xtol, gtol), the role of phi, the setting of *info codes for different conditions, and the continued execution path when convergence is not met. These omissions limit completeness of behavioral coverage.",
                "The summary captures the primary purpose of testing solver convergence and mentions checking delta and residual norms, which align with the function's comparison of dx and x as well as fnorm computation. However, the phrase 'Jacobian scaling' is inaccurate because the code computes a scaled infinity norm of the gradient, not scaling the Jacobian itself. This is a minor semantic mismatch but no fatal errors about core purpose, and there is minimal noise. The gain is moderate thanks to coverage of the main convergence checks."
            ]
        }
    }
}
{
    "source_code": "\nZSTD_CStream* ZSTD_createCStream_advanced(ZSTD_customMem customMem)\n{\n    ZSTD_CStream* zcs;\n\n    if (!customMem.customAlloc && !customMem.customFree) customMem = defaultCustomMem;\n    if (!customMem.customAlloc || !customMem.customFree) return NULL;\n\n    zcs = (ZSTD_CStream*)ZSTD_malloc(sizeof(ZSTD_CStream), customMem);\n    if (zcs==NULL) return NULL;\n    memset(zcs, 0, sizeof(ZSTD_CStream));\n    memcpy(&zcs->customMem, &customMem, sizeof(ZSTD_customMem));\n    zcs->cctx = ZSTD_createCCtx_advanced(customMem);\n    if (zcs->cctx == NULL) { ZSTD_freeCStream(zcs); return NULL; }\n    return zcs;\n}",
    "comment": "Creates and initializes a ZSTD_CStream object with custom memory allocation, returning NULL on failure or invalid parameters.",
    "prorec_sum": "Allocates and initializes a 200-byte structure with provided callback functions and parameters, invoking a secondary setup routine before returning the created object.",
    "filter_prorec_sum": "Allocates and initializes a 200\u2011byte structure with provided function pointers and context data, invoking a secondary setup routine before returning the created object.",
    "prorec_aug_sum": "Allocates and initializes a 200-byte structure with function callbacks and parameters, then performs a secondary setup step, returning the structure on success.",
    "filter_prorec_aug_sum": "Allocates and initializes a 200\u2011byte structure with provided callback pointers and parameters, invoking a secondary setup routine and cleaning up on failure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and initializes a 200-byte structure with function callbacks and parameters, then performs a secondary setup step, returning the structure on success.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims a fixed 200-byte structure is allocated, which is incorrect since the code uses sizeof(ZSTD_CStream) without indicating its size. It also inaccurately generalizes initialization as 'function callbacks and parameters,' omitting specific handling of custom memory allocation and the creation of a compression context. The secondary setup step mentioned loosely aligns with ZSTD_createCCtx_advanced call but lacks precision. Overall, most claims are inaccurate, with only a minor portion loosely matching the source behavior.",
                "The summary inaccurately states a fixed size of 200 bytes instead of the actual sizeof(ZSTD_CStream), and does not specify the function\u2019s core primary purpose of creating and initializing a ZSTD_CStream with a custom memory allocator and compressor context. While it vaguely mentions allocation, initialization, and a secondary setup step, it omits key specifics such as handling missing alloc/free callbacks, default memory usage, null checks with early returns, and freeing resources on failure. These shortcomings mean the core is not covered and secondary semantics are largely absent.",
                "The summary incorrectly claims the structure is 200 bytes, which contradicts the source code that uses sizeof(ZSTD_CStream) without specifying a fixed size, making this a FATAL error about the core allocation. While it mentions initialization and returning the structure, these are generic and omit key domain-specific steps like custom memory handling and the secondary setup using ZSTD_createCCtx_advanced. The most severe issue is the inaccurate size detail tied directly to the primary purpose, so the net benefit is negative."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates and initializes a 200\u2011byte structure with provided callback pointers and parameters, invoking a secondary setup routine and cleaning up on failure.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary incorrectly claims the function allocates a 200-byte structure, while the source code allocates based on sizeof(ZSTD_CStream), which is unspecified here. It also describes 'provided callback pointers and parameters' in a vague way that doesn't mention the explicit custom memory allocator checks. The invocation of a secondary setup routine and cleanup on failure is accurate, but these correct parts are outweighed by the major inaccuracy about structure size and incomplete coverage of the function's semantics.",
                "The summary incorrectly states a fixed size of 200 bytes, while the code allocates sizeof(ZSTD_CStream), making the byte count inaccurate. It omits the core purpose of creating and initializing a ZSTD compression stream with custom memory allocators, and the handling of default allocators when not provided. Although it notes initialization, a secondary routine, and cleanup on failure, these points are generic and do not capture the specific domain effect, resulting in the core not being covered and little accurate secondary detail.",
                "The summary contains a key inaccurate claim: it states the function allocates a 200\u2011byte structure, but the code clearly allocates sizeof(ZSTD_CStream), whose size is not indicated and is unlikely to be exactly 200 bytes. It correctly notes initialization with provided callbacks, a secondary setup routine, and cleanup on failure, which align with setting customMem, creating the context, and freeing on error. The incorrect size is a FATAL error about a core I/O detail, significantly undermining trust in the summary."
            ]
        }
    }
}
{
    "source_code": "static enum mu_filter_result\n_crlfdot_decoder (void *xd,\n\t\t  enum mu_filter_command cmd,\n\t\t  struct mu_filter_io *iobuf)\n{\n  int *pstate = xd;\n  size_t i, j;\n  const unsigned char *iptr;\n  size_t isize;\n  char *optr;\n  size_t osize;\n\n  switch (cmd)\n    {\n    case mu_filter_init:\n      *pstate = crlfdot_decode_init;\n      return mu_filter_ok;\n      \n    case mu_filter_done:\n      return mu_filter_ok;\n      \n    default:\n      break;\n    }\n  \n  iptr = (const unsigned char *) iobuf->input;\n  isize = iobuf->isize;\n  optr = iobuf->output;\n  osize = iobuf->osize;\n\n  for (i = j = 0; *pstate != crlfdot_decode_end && i < isize && j < osize; i++)\n    {\n      unsigned char c = *iptr++;\n\n      if (c == '\\r')\n\t{\n\t  if (i + 1 == isize)\n\t    break;\n\t  *pstate = new_decode_state (*pstate, c);\n\t  if (*iptr == '\\n')\n\t    continue;\n\t}\n      else if (c == '.' &&\n\t       (*pstate == crlfdot_decode_init ||\n\t\t*pstate == crlfdot_decode_crlf))\n\t{\n\t  /* Make sure we have two more characters in the buffer */\n\t  if (i + 2 == isize)\n\t    break;\n\t  *pstate = new_decode_state (*pstate, c);\n\t  if (*iptr != '\\r')\n\t    continue;\n\t}\n      else\n\t*pstate = new_decode_state (*pstate, c);\n      optr[j++] = c;\n    }\n  \n  if (*pstate == crlfdot_decode_end)\n    {\n      j -= 2; /* remove the trailing .\\n */\n      iobuf->eof = 1;\n    }\n  iobuf->isize = i;\n  iobuf->osize = j;\n  return mu_filter_ok;\n}",
    "comment": "Decodes input data by processing CRLF sequences and dots, modifying the state and output buffer accordingly, until reaching the end condition.",
    "prorec_sum": "Parses bytes from an input buffer into a destination, handling carriage returns, dots, and updating parsing state and processed lengths.",
    "filter_prorec_sum": "Processes an input byte stream, updating a parser state and output buffer while handling carriage return, line feed, and period characters with special rules.",
    "prorec_aug_sum": "Parses bytes from an input buffer into an output buffer while updating a parsing state and handling carriage return and period as special cases.",
    "filter_prorec_aug_sum": "Parses bytes from an input buffer into a destination buffer, updating state and handling carriage return, line feed, and period characters with specific rules.",
    "work_score": {
        "prorec_aug": {
            "summary": "Parses bytes from an input buffer into an output buffer while updating a parsing state and handling carriage return and period as special cases.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly describes the function\u2019s purpose of processing bytes from an input buffer to an output buffer while updating a parsing state, and notes that carriage return and period characters are treated as special cases. These claims align with the source code\u2019s loop behavior, conditional handling of '\\r' and '.', and use of a state machine. No contradictory or irrelevant statements are present, and all claims target the code\u2019s semantics accurately.",
                "The summary correctly identifies that the function transfers data from an input buffer to an output buffer, updates a parsing state, and treats carriage return and period characters specially, which matches the code\u2019s main behavior. However, it omits the core purpose of decoding CRLF-dot sequences used in protocols like SMTP, and does not mention critical details such as the removal of the trailing '.\\n', EOF signaling, or edge case handling for buffer limits. This results in coverage of the core mechanics but with weak domain-specific and secondary semantic coverage.",
                "The summary correctly states that the function reads from an input buffer to an output buffer, updates a parsing state, and treats carriage return and period specially, which matches the source code\u2019s core logic. It omits specific details such as conditions for skipping characters, handling end-of-data removal of '.\\n', and signaling EOF. There are no inaccurate claims, but the gain is low due to the generic nature and lack of specificity, with minor noise in the broad wording."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Parses bytes from an input buffer into a destination buffer, updating state and handling carriage return, line feed, and period characters with specific rules.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function processes bytes from an input buffer to an output buffer while updating state and applying specific handling for carriage returns, line feeds, and periods. These behaviors are directly reflected in the source code\u2019s loop and conditional checks. There are no inaccurate or irrelevant claims, though the summary remains somewhat high-level without mentioning all edge cases like early breaks or EOF marking, but it still aligns closely with the code\u2019s semantics.",
                "The summary accurately notes buffer parsing, state updates, and special handling for carriage return, line feed, and period characters, which matches the core behavior of decoding CRLF and dot sequences. However, it omits key specifics such as the intended decoding of a CRLF-dot termination sequence, EOF flag setting, and trimming the trailing '.\\n'. These omissions mean secondary behavior like end-state handling and output size adjustment are not covered.",
                "The summary captures the core purpose accurately: it states that the function processes bytes from an input buffer into an output buffer, updates state, and applies specific rules for carriage return, line feed, and period characters, which aligns with the code's handling of '\\r', '\\n', and '.' in different states. While it lacks detail on EOF handling and the removal of trailing '.\\n', there are no inaccurate claims, and noise is minimal. The gain is moderate due to the summary\u2019s brevity."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\ntry_load_plugin (const char *pname, bfd *abfd, int *has_plugin_p)\n{\n  void *plugin_handle;\n  struct ld_plugin_tv tv[4];\n  int i;\n  ld_plugin_onload onload;\n  enum ld_plugin_status status;\n\n  *has_plugin_p = 0;\n\n  plugin_handle = dlopen (pname, RTLD_NOW);\n  if (!plugin_handle)\n    {\n      _bfd_error_handler (\"%s\\n\", dlerror ());\n      return 0;\n    }\n\n  onload = dlsym (plugin_handle, \"onload\");\n  if (!onload)\n    goto err;\n\n  i = 0;\n  tv[i].tv_tag = LDPT_MESSAGE;\n  tv[i].tv_u.tv_message = message;\n\n  ++i;\n  tv[i].tv_tag = LDPT_REGISTER_CLAIM_FILE_HOOK;\n  tv[i].tv_u.tv_register_claim_file = register_claim_file;\n\n  ++i;\n  tv[i].tv_tag = LDPT_ADD_SYMBOLS;\n  tv[i].tv_u.tv_add_symbols = add_symbols;\n\n  ++i;\n  tv[i].tv_tag = LDPT_NULL;\n  tv[i].tv_u.tv_val = 0;\n\n  status = (*onload)(tv);\n\n  if (status != LDPS_OK)\n    goto err;\n\n  *has_plugin_p = 1;\n\n  abfd->plugin_format = bfd_plugin_no;\n\n  if (!claim_file)\n    goto err;\n\n  if (!try_claim (abfd))\n    goto err;\n\n  abfd->plugin_format = bfd_plugin_yes;\n\n  return 1;\n\n err:\n  return 0;\n}",
    "comment": "Loads a plugin from a specified path, initializes it, and claims a file if successful, returning the status of the operation.",
    "prorec_sum": "Loads a shared library, invokes its \"onload\" entry with callbacks, and updates file state flags based on plugin-provided data via lseek operations.",
    "filter_prorec_sum": "Loads a shared library, executes its \"onload\" routine with callbacks, and conditionally updates flags and state based on file descriptor operations.",
    "prorec_aug_sum": "Loads a shared library, invokes its \"onload\" entry with callbacks, and updates flags and file position based on plugin-provided data.",
    "filter_prorec_aug_sum": "Loads a shared library, calls its `onload` entry with callbacks, and updates state based on optional file descriptor and handler results.",
    "work_score": {
        "prorec_aug": {
            "summary": "Loads a shared library, invokes its \"onload\" entry with callbacks, and updates flags and file position based on plugin-provided data.",
            "score": [
                0.7,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function loads a shared library via dlopen and calls its 'onload' entry with callback structures, and mentions updating flags based on plugin data, which aligns with setting *has_plugin_p and abfd->plugin_format. However, it inaccurately includes 'updates file position,' which is not present in the source, and omits key conditions such as checks for claim_file and try_claim. Most claims are accurate, but there is at least one incorrect detail, reducing overall precision.",
                "The summary correctly notes loading a shared library, invoking the 'onload' function with callbacks, and updating internal state, which aligns with the core purpose of trying to load and initialize an ld plugin. However, it omits key specifics from the code such as handling errors from dlopen/dlsym, setting the plugin_format values, checking claim_file, attempting try_claim, and the role of has_plugin_p. The mention of updating 'file position' is inaccurate since the code updates plugin_format, not any file position, indicating partial inaccuracy in secondary details.",
                "The summary correctly states that the function loads a shared library and invokes its 'onload' entry with callbacks, aligning with the core code behavior (ACCURATE). However, the claim about updating 'file position' is inaccurate, as the function sets 'plugin_format' flags and boolean indicators but does not manipulate file position at all. This is a FATAL error targeting the primary purpose\u2019s side effects, reducing trust in the description despite partial accuracy."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Loads a shared library, calls its `onload` entry with callbacks, and updates state based on optional file descriptor and handler results.",
            "score": [
                0.6,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly captures that the function loads a shared library, invokes its `onload` function with callbacks, and updates some state based on results, which matches the source code. However, the phrase 'optional file descriptor' is inaccurate, as the code does not deal with file descriptors but rather plugin claims via `claim_file` and `try_claim`. This introduces a semantic error, resulting in a mix of accurate and inaccurate claims, with more than half but not all being correct.",
                "The summary correctly notes that the function loads a shared library and calls its `onload` entry with callbacks, which matches the core behavior of trying to load a plugin and initializing it via provided hooks. However, it omits key domain-specific details such as the use of `dlopen`/`dlsym`, the use of specific LDPT_* tags in the callback table, the status check for `LDPS_OK`, the handling of `has_plugin_p` and `plugin_format` fields, and the claim and try_claim checks before concluding success. The mention of 'optional file descriptor and handler results' is inaccurate or vague given the actual code flow, indicating the core purpose is covered but secondary semantics coverage is weak.",
                "The summary correctly states that the function loads a shared library and calls its `onload` entry with callbacks, which matches the source code. However, the phrase about updating state based on optional file descriptor and handler results is inaccurate\u2014there is no file descriptor involved, and state updates are tied to plugin claim logic, not generic handler results. This is a semantic mismatch targeting the code, but not on the primary purpose or core I/O, so it's noise rather than fatal. The gain is low because the accurate part is generic and omits key details such as the specific callbacks registered and the role of `has_plugin_p` and `plugin_format` updates."
            ]
        }
    }
}
{
    "source_code": "static int\nxmlDOMWrapNSNormGatherInScopeNs(xmlNsMapPtr *map,\n\t\t\t\txmlNodePtr node)\n{\n    xmlNodePtr cur;\n    xmlNsPtr ns;\n    xmlNsMapItemPtr mi;\n    int shadowed;\n\n    if ((map == NULL) || (*map != NULL))\n\treturn (-1);\n    if ((node == NULL) || (node->type == XML_NAMESPACE_DECL))\n        return (-1);\n    /*\n    * Get in-scope ns-decls of @parent.\n    */\n    cur = node;\n    while ((cur != NULL) && (cur != (xmlNodePtr) cur->doc)) {\n\tif (cur->type == XML_ELEMENT_NODE) {\n\t    if (cur->nsDef != NULL) {\n\t\tns = cur->nsDef;\n\t\tdo {\n\t\t    shadowed = 0;\n\t\t    if (XML_NSMAP_NOTEMPTY(*map)) {\n\t\t\t/*\n\t\t\t* Skip shadowed prefixes.\n\t\t\t*/\n\t\t\tXML_NSMAP_FOREACH(*map, mi) {\n\t\t\t    if ((ns->prefix == mi->newNs->prefix) ||\n\t\t\t\txmlStrEqual(ns->prefix, mi->newNs->prefix)) {\n\t\t\t\tshadowed = 1;\n\t\t\t\tbreak;\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\t\t    /*\n\t\t    * Insert mapping.\n\t\t    */\n\t\t    mi = xmlDOMWrapNsMapAddItem(map, 0, NULL,\n\t\t\tns, XML_TREE_NSMAP_PARENT);\n\t\t    if (mi == NULL)\n\t\t\treturn (-1);\n\t\t    if (shadowed)\n\t\t\tmi->shadowDepth = 0;\n\t\t    ns = ns->next;\n\t\t} while (ns != NULL);\n\t    }\n\t}\n\tcur = cur->parent;\n    }\n    return (0);\n}",
    "comment": "Gathers in-scope namespace declarations from the given node's ancestors and updates the namespace mapping, avoiding shadowed prefixes.",
    "prorec_sum": "Processes an XML namespace list, matching prefixes with existing entries and adding new ones using a provided construction routine.",
    "filter_prorec_sum": "Traverses XML node namespaces, matching names with an existing set, and adds unmatched namespaces to the target collection using xmlStrEqual for comparison.",
    "prorec_aug_sum": "Traverses XML node structures, matching element names, and adds corresponding entries to a collection using xmlStrEqual-based comparisons.",
    "filter_prorec_aug_sum": "Traverses XML node chains, matching names with an existing set, and adds missing nodes using xmlStrEqual comparisons until traversal completes or fails.",
    "work_score": {
        "prorec_aug": {
            "summary": "Traverses XML node structures, matching element names, and adds corresponding entries to a collection using xmlStrEqual-based comparisons.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes traversing XML nodes and matching element names, but the source code actually traverses ancestor nodes to gather in-scope namespace declarations, checking namespace prefixes with xmlStrEqual, and adding them to a namespace map. The mention of 'matching element names' is inaccurate, and while it correctly notes xmlStrEqual-based comparisons and adding to a collection, much of the semantic detail in the summary does not align with the function's actual behavior. Less than half of the claims are accurate.",
                "The summary incorrectly claims that the function matches element names, whereas the source code is actually traversing an XML node hierarchy to gather in-scope namespace declarations from ancestor elements and add them to a namespace map, skipping shadowed prefixes using xmlStrEqual. It fails to capture the core purpose of collecting namespace mappings and misrepresents the comparison target. No accurate coverage of the core domain action or secondary semantics is present.",
                "The summary incorrectly states that the function matches element names, which is a FATAL error regarding the core purpose. The source code matches namespace prefixes using xmlStrEqual, not element names. It also omits key behaviors such as traversing up the parent chain, skipping shadowed prefixes, and adding namespace mappings. Noise outweighs accurate content, and there is no specific GOLD information provided."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Traverses XML node chains, matching names with an existing set, and adds missing nodes using xmlStrEqual comparisons until traversal completes or fails.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function traverses XML node chains, matches names with an existing set, and adds missing nodes using xmlStrEqual comparisons until traversal completes or fails. While traversal and use of xmlStrEqual for comparisons are accurate, the summary incorrectly frames it as matching 'names' and 'adding missing nodes'\u2014the source code operates on namespace declarations, not arbitrary node names, and adds namespace mappings rather than nodes. This misrepresentation makes core semantics inaccurate, resulting in less than half of the claims aligning with the code.",
                "The summary inaccurately describes the core operation: the function gathers in-scope XML namespace declarations from ancestor nodes into a namespace map, skipping shadowed prefixes using xmlStrEqual. The summary instead talks about matching node names and adding missing nodes, which does not reflect the namespace-specific behavior in the code. It omits the core purpose and critical details like namespace handling, skipping shadowed prefixes, and error return conditions.",
                "The summary misrepresents the function's primary purpose. The function actually gathers in-scope XML namespace declarations from a given node's ancestry, skipping shadowed prefixes, and adds them to a namespace map using xmlStrEqual for prefix matching. The summary claims it matches names and adds missing nodes, which is inaccurate about the core domain semantics (it operates on namespaces, not general nodes) and omits key behavior like shadow detection and proper map initialization. This constitutes a FATAL error about the primary purpose, leaving no trustworthy core description."
            ]
        }
    }
}
{
    "source_code": "\nssize_t led_trigger_show(struct device *dev, struct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct led_classdev *led_cdev = dev_get_drvdata(dev);\n\tstruct led_trigger *trig;\n\tint len = 0;\n\n\tdown_read(&triggers_list_lock);\n\tdown_read(&led_cdev->trigger_lock);\n\n\tif (!led_cdev->trigger)\n\t\tlen += sprintf(buf+len, \"[none] \");\n\telse\n\t\tlen += sprintf(buf+len, \"none \");\n\n\tlist_for_each_entry(trig, &trigger_list, next_trig) {\n\t\tif (led_cdev->trigger && !strcmp(led_cdev->trigger->name,\n\t\t\t\t\t\t\ttrig->name))\n\t\t\tlen += sprintf(buf+len, \"[%s] \", trig->name);\n\t\telse\n\t\t\tlen += sprintf(buf+len, \"%s \", trig->name);\n\t}\n\tup_read(&led_cdev->trigger_lock);\n\tup_read(&triggers_list_lock);\n\n\tlen += sprintf(len+buf, \"\\n\");\n\treturn len;\n}",
    "comment": "Retrieves the current LED trigger state and lists available triggers, marking the active trigger with brackets in the output buffer.",
    "prorec_sum": "Formats a device-related status string into the provided buffer, listing active items or \u201cnone\u201d, and returns the total output length including newline.",
    "filter_prorec_sum": "Formats a status string into `a11` listing active entries or \"none\", then appends each matching item name with optional formatting.",
    "prorec_aug_sum": "Formats a string into the provided buffer listing \u201cnone\u201d or bracketed entries from a global list, then appends a newline and returns its length.",
    "filter_prorec_aug_sum": "Builds a textual list of registered items into the output buffer, inserting \"none\" if empty, and appends a newline before returning its length.",
    "work_score": {
        "prorec_aug": {
            "summary": "Formats a string into the provided buffer listing \u201cnone\u201d or bracketed entries from a global list, then appends a newline and returns its length.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly describes the core behavior: formatting a string into the buffer, listing 'none' or bracketed entries from a global list, appending a newline, and returning the length. All these details match the source code, though it omits the conditional distinction between '[none]' and 'none' and the use of locks. The claims are accurate and target the code semantics, with only minor omissions.",
                "The summary correctly describes formatting the buffer with 'none' or bracketed names from a list, newline appending, and length return, which aligns with the function\u2019s core purpose. However, it omits key domain-specific context that the list represents LED triggers, the lock handling around accessing global and per-device trigger lists, and the special case for '[none]' when the device has no trigger set. This makes coverage of secondary behavior details weak.",
                "The summary correctly captures the function\u2019s main purpose: formatting a string into a buffer, listing either 'none' or bracketed trigger names from a list, appending a newline, and returning the length. It omits minor implementation specifics such as lock usage and the distinction between '[none]' and 'none', but there are no contradictory (FATAL) inaccuracies. The description is concise and aligned with the source code\u2019s semantics, though it provides only moderate detail."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Builds a textual list of registered items into the output buffer, inserting \"none\" if empty, and appends a newline before returning its length.",
            "score": [
                0.6,
                0.2,
                0.2
            ],
            "reason": [
                "The summary captures that the function builds a text list in the output buffer and appends a newline before returning its length, which matches the code. However, it incorrectly states that it inserts \"none\" if empty, while the code inserts \"[none]\" when there is no active trigger and always includes \"none\" before listing triggers. This is a semantic mismatch, leading to reduced accuracy.",
                "The summary describes building a textual list and handling an empty case with 'none', but it does not accurately identify the core purpose of the function, which is to list registered LED triggers, mark the active one in brackets, and show '[none]' when no trigger is active. It omits the domain-specific context of LED triggers and the bracket marking of the current trigger, and thus fails to cover the primary purpose and other key behaviors like lock usage.",
                "The summary correctly notes that the function builds a textual list of registered items and appends a newline, which aligns with the code\u2019s behavior. However, it inaccurately states that 'none' is inserted if the list is empty \u2014 in reality, the function inserts '[none]' if no trigger is set, otherwise it lists all triggers with one possibly bracketed. This is a FATAL error affecting the primary purpose description, as it misrepresents core output conditions."
            ]
        }
    }
}
{
    "source_code": "\nvoid ping_rcv(struct sk_buff *skb)\n{\n\tstruct sock *sk;\n\tstruct net *net = dev_net(skb->dev);\n\tstruct iphdr *iph = ip_hdr(skb);\n\tstruct icmphdr *icmph = icmp_hdr(skb);\n\t__be32 saddr = iph->saddr;\n\t__be32 daddr = iph->daddr;\n\n\t/* We assume the packet has already been checked by icmp_rcv */\n\n\tpr_debug(\"ping_rcv(skb=%p,id=%04x,seq=%04x)\\n\",\n\t\t skb, ntohs(icmph->un.echo.id), ntohs(icmph->un.echo.sequence));\n\n\t/* Push ICMP header back */\n\tskb_push(skb, skb->data - (u8 *)icmph);\n\n\tsk = ping_v4_lookup(net, saddr, daddr, ntohs(icmph->un.echo.id),\n\t\t\t    skb->dev->ifindex);\n\tif (sk != NULL) {\n\t\tpr_debug(\"rcv on socket %p\\n\", sk);\n\t\tping_queue_rcv_skb(sk, skb_get(skb));\n\t\tsock_put(sk);\n\t\treturn;\n\t}\n\tpr_debug(\"no socket, dropping\\n\");\n\n\t/* We're called from icmp_rcv(). kfree_skb() is done there. */\n}",
    "comment": "Processes received ICMP packets, checks for an associated socket, and queues the packet for delivery if a corresponding socket is found.",
    "prorec_sum": "Processes packet-related buffer data by retrieving header fields, preparing a target buffer, copying data into it, and releasing the associated reference when done.",
    "filter_prorec_sum": "Processes SCTP packet data from buffer pointers, invokes helper routines to copy and prepare payload, and finalizes transmission with reference count management.",
    "prorec_aug_sum": "Processes routing entry data, acquires a related resource, performs an operation using provided parameters, and releases the resource when its reference count reaches zero.",
    "filter_prorec_aug_sum": "Processes routing cache entries by locating a matching destination, performing related operations, and releasing resources when reference counts drop to zero.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes routing entry data, acquires a related resource, performs an operation using provided parameters, and releases the resource when its reference count reaches zero.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains generic and inaccurate claims that do not align with the source code semantics. The function handles incoming ICMP ping packets, looks up a socket, queues the packet if found, and releases the socket reference, but there is no processing of routing entry data or explicit reference count checks to zero. While acquiring and releasing a resource (socket) is minimally correct, most claims are unrelated to or misrepresent the actual behavior, resulting in a low proportion of accurate statements.",
                "The summary omits the core purpose of handling an incoming ICMP echo request (ping) by looking up an associated socket and queuing the packet to it, which is the key domain-specific action in the source code. Instead, it describes generic routing entry processing and resource acquisition/release that do not match the actual code semantics, making its main claims inaccurate. As the core is not covered and no relevant secondary details are provided, alignment is minimal.",
                "The summary contains only vague, generic statements about processing data, acquiring and releasing a resource, and performing an operation with parameters, which do not match the specific ICMP echo handling in the source code. It incorrectly implies routing entry processing and reference-count-based resource release, neither of which occur here. This is a FATAL in describing the primary purpose, as the core action\u2014looking up a ping socket and queueing the packet\u2014is missed and replaced with unrelated behavior. Noise overwhelms accuracy, with no specific GOLD claims present."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes routing cache entries by locating a matching destination, performing related operations, and releasing resources when reference counts drop to zero.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about processing routing cache entries, finding matching destinations, and releasing resources on reference count reaching zero do not align with the source code. The code handles incoming ICMP echo packets by locating a matching socket, queuing the packet if found, and otherwise dropping it. None of the summary's points accurately describe the function's actual domain-semantic behavior, resulting in no accurate claims.",
                "The summary's claims describe processing routing cache entries and reference count handling, which do not align with the source code. The function actually handles incoming ICMP echo packets, looks up associated ping sockets, queues packets if a socket is found, and logs or drops otherwise. None of the [ACCURATE] claims in the summary state the core primary purpose, and the summary omits the packet processing, socket lookup, and queuing semantics entirely.",
                "The summary incorrectly describes routing cache operations, destination lookup, and reference count handling, none of which occur in the provided function. The actual code handles received ICMP echo packets by looking up a matching ping socket and queuing the packet if found. This represents a severe factual contradiction about the primary purpose, making the description unusable."
            ]
        }
    }
}
{
    "source_code": "static int snd_seq_device_free(struct snd_seq_device *dev)\n{\n\tstruct ops_list *ops;\n\n\tif (snd_BUG_ON(!dev))\n\t\treturn -EINVAL;\n\n\tops = find_driver(dev->id, 0);\n\tif (ops == NULL)\n\t\treturn -ENXIO;\n\n\t/* remove the device from the list */\n\tmutex_lock(&ops->reg_mutex);\n\tlist_del(&dev->list);\n\tops->num_devices--;\n\tmutex_unlock(&ops->reg_mutex);\n\n\tfree_device(dev, ops);\n\tif (dev->private_free)\n\t\tdev->private_free(dev);\n\tkfree(dev);\n\n\tunlock_driver(ops);\n\n\treturn 0;\n}",
    "comment": "Frees a sequencer device by removing it from the list, releasing resources, and invoking the device's private cleanup function if defined.",
    "prorec_sum": "Initializes and detaches internal codec structures, updates linked lists, invokes optional callbacks, and finalizes power or state changes for an audio device.",
    "filter_prorec_sum": "Initializes and detaches a codec-related structure, updates linked list pointers, invokes a codec callback, and performs cleanup before returning success or error.",
    "prorec_aug_sum": "Removes an object from linked lists, decrements its reference counters, invokes a callback, and finalizes related resources if the handle is valid.",
    "filter_prorec_aug_sum": "Removes an allocated object from linked structures, updates related counters, invokes cleanup callbacks, and finalizes the deallocation process for a given handle.",
    "work_score": {
        "prorec_aug": {
            "summary": "Removes an object from linked lists, decrements its reference counters, invokes a callback, and finalizes related resources if the handle is valid.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly notes object removal from a linked list, callback invocation, and resource finalization when the input is valid, which matches the code. However, it inaccurately describes decrementing a reference counter instead of decreasing the driver\u2019s device count, and omits important checks and error codes. Several details are generalized, reducing precision.",
                "The summary does not explicitly cover the core purpose of freeing a sequencer device from its driver and associated list, which includes validation checks for null devices, locating driver operations via find_driver, mutex locking, list removal, decrementing a device count, calling free_device, optional private_free, and unlocking the driver. While it vaguely mentions removing from lists and invoking a callback, it omits critical domain-specific details and mischaracterizes the decrement as a reference counter instead of a device count. Error handling and driver resource interaction are not reflected, leaving both core and secondary coverage incomplete.",
                "The summary correctly mentions removing an object from a linked list, invoking a callback, and finalizing resources, which matches the code. However, it inaccurately describes decrementing reference counters; the code decrements a device count, not a reference counter. It also omits key details such as validating the device pointer, error handling return values, specific mutex operations, and unlocking the driver. The main shortcoming is the presence of imprecise terminology on a core data operation, which misrepresents semantics, reducing trustworthiness. Noise is moderate and gain is low due to generic phrasing and missing specifics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Removes an allocated object from linked structures, updates related counters, invokes cleanup callbacks, and finalizes the deallocation process for a given handle.",
            "score": [
                0.9,
                0.5,
                0.9
            ],
            "reason": [
                "The summary accurately captures the core behaviors of the function: removing the device from linked lists, decrementing counters, invoking a cleanup callback if present, and freeing memory. These actions align with the source code steps like list_del, ops->num_devices--, dev->private_free, and kfree. While the terminology is slightly generic (e.g., 'linked structures' instead of 'list'), all claims are semantically consistent with the code and target its actual behavior without introducing inaccuracies.",
                "The summary generally describes removal from structures, counter updates, cleanup callbacks, and deallocation, which are accurate generic representations of the function\u2019s operations. However, it does not capture the core primary purpose \u2014 freeing an snd_seq_device after validating it and locating its associated driver, including explicit error handling (returning -EINVAL, -ENXIO), locking/unlocking the driver\u2019s mutex, and invoking driver-specific cleanup. These domain-specific details are missing, so while the core concept of removal/deallocation is covered, key behavior-critical semantics are absent.",
                "The summary correctly states that the function removes an object from linked structures (list_del), updates counters (ops->num_devices--), invokes cleanup callbacks (dev->private_free), and finalizes deallocation (kfree). These are accurate GOLD claims about the core behavior. There is no contradictory or irrelevant noise present, though terminology like 'given handle' is generic. Overall, the summary captures the primary purpose and key steps precisely with minimal loss of specificity."
            ]
        }
    }
}
{
    "source_code": "static void\nmixed_string_buffer_flush_curr (struct mixed_string_buffer *bp)\n{\n  if (bp->curr_type == utf8_encoded)\n    mixed_string_buffer_flush_utf16_surr (bp);\n  if (bp->curr_type != -1)\n    {\n      if (bp->curr_buflen > 0)\n        {\n          struct mixed_string_segment *segment =\n            segment_alloc (bp->curr_type, bp->curr_buffer, bp->curr_buflen);\n          mixed_string_buffer_add_segment (bp, segment);\n        }\n      bp->curr_buflen = 0;\n    }\n}",
    "comment": "Flushes the current buffer to segments based on its type, handling UTF-8 encoding and resetting the buffer length after addition.",
    "prorec_sum": "Stores the current element data with its type into a dynamically resized list and resets the element\u2019s temporary storage buffer.",
    "filter_prorec_sum": "Appends a new memory-copied data entry with its state code to a dynamically resized list and clears the pending buffer reference.",
    "prorec_aug_sum": "Stores the current state and associated data into a dynamically growing list, allocating memory and copying contents as needed.",
    "filter_prorec_aug_sum": "Stores the current state and associated data into a dynamically resized array, resetting temporary buffers and handling pending operations if flagged.",
    "work_score": {
        "prorec_aug": {
            "summary": "Stores the current state and associated data into a dynamically growing list, allocating memory and copying contents as needed.",
            "score": [
                0.3,
                0.2,
                0.5
            ],
            "reason": [
                "The summary claims that the function stores state and data into a dynamically growing list, allocating memory and copying contents, but the source code shows it conditionally flushing UTF-16 surrogates, creating a segment only when certain conditions are met, and adding it to a segment list. While 'allocating memory' via segment_alloc is accurate, the description of a 'dynamically growing list' and generic 'copying contents' is vague and partially misleading compared to the source's specific buffer flush and type checks. Less than half of the summary's claims are specific and accurately aligned with the code's semantics.",
                "The summary makes a generic statement about storing state in a list with memory allocation, which is too vague and does not capture the core behavior of flushing the current mixed string buffer segment with type-specific handling (including UTF-16 surrogate flush) and resetting the buffer length. While it loosely matches the notion of adding a segment after allocation, it omits the specific domain action and key branching logic, resulting in missing the core purpose and most secondary details.",
                "The summary claims that the function stores current state and data into a dynamically growing list with memory allocation and copying, which only partially aligns with the code. While the function does allocate a segment and add it to a buffer list, it omits key details such as the conditional flush for UTF-16 surrogate data and the reset of buffer length. It also inaccurately generalizes the behavior as always storing data, ignoring the conditional nature tied to `curr_type` and `curr_buflen`. The claim is overly generic, providing little specific insight into actual code semantics and containing notable noise rather than precise GOLD details."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Stores the current state and associated data into a dynamically resized array, resetting temporary buffers and handling pending operations if flagged.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function stores state into a dynamically resized array and handles pending operations if flagged, which is inaccurate. The code actually flushes the current buffer by possibly converting UTF-8 sequences to UTF-16 surrogate pairs, allocating a segment, adding it to a mixed string buffer, and resetting the buffer length. There is no evidence of dynamic resizing or flagged pending operations. Nearly all claims in the summary contradict the source code semantics, resulting in a very low proportion of accurate statements.",
                "The summary does not accurately describe the core domain operation, which is flushing the current segment from a mixed string buffer, including UTF-16 surrogate handling and adding allocated segments. Instead, it generically describes storing state in a dynamically resized array and handling flagged operations, which is not present in the code. It misses the core purpose entirely and provides only inaccurate, generic content unrelated to actual buffer flushing logic.",
                "The summary's claim that the function stores current state/data into a dynamically resized array and resets temporary buffers is inaccurate relative to the source. The code does not resize arrays; it allocates a segment from the current buffer and adds it to a list, flushing UTF-16 surrogates if needed. The 'pending operations if flagged' statement is noise, as no such flag-handling behavior is found. This is a FATAL error on the primary purpose since it misstates the core domain action, making the description unreliable."
            ]
        }
    }
}
{
    "source_code": "\nstruct sequence *\nnew_C_string_sequence (const char * delimitor)\n{\n  struct sequence * res = XMALLOC (struct sequence, 1);\n  res->open = rule_new (xustrdup (delimitor), NULL,\n\t\t\trhs_new_single (NULL, 0, Plain_fface),\n\t\t\t__FILE__, __LINE__);\n  res->face = String_fface;\n  res->exceptions = new_C_exceptions ();\n  res->close = words_new (\"C Close: strings\", \"C Close: regex\", 5, 5);\n  words_add_string (res->close,\n\t\t    rule_new (xustrdup (delimitor), NULL,\n\t\t\t      rhs_new_single (NULL, 0, Plain_fface),\n\t\t\t      __FILE__, __LINE__));\n  words_finalize (res->close);\n  return res;\n}",
    "comment": "Creates and initializes a new string sequence structure with a specified delimiter and associated rules for processing strings.",
    "prorec_sum": "Builds and returns a structure describing C string and regex exception patterns, including common escape sequences and matching rules for opening and closing.",
    "filter_prorec_sum": "Initializes a C language string handling structure with escape sequence rules and closure patterns for strings and regular expressions.",
    "prorec_aug_sum": "Constructs and returns a structure grouping C string and regex exceptions with specific escape patterns and related closing definitions.",
    "filter_prorec_aug_sum": "Constructs a C language parsing rule set for strings and regex, including escape sequence exceptions and closing conditions.",
    "work_score": {
        "prorec_aug": {
            "summary": "Constructs and returns a structure grouping C string and regex exceptions with specific escape patterns and related closing definitions.",
            "score": [
                0.3,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claim that the function groups C string and regex exceptions with specific escape patterns is inaccurate compared to the code. While the function constructs and returns a 'sequence' struct and adds closing rules with C string and regex labels, there is no evidence of 'specific escape patterns' in the implementation. Only some elements, like handling exceptions and closing definitions, align loosely with the source. Overall, less than half of the claims are precise and verifiable against the code.",
                "The summary does not accurately describe the core purpose of the function, which is to create and initialize a new 'sequence' structure configured with a given delimiter, specific face types, exceptions, and closing word patterns. The claim about 'C string and regex exceptions with specific escape patterns' is misleading and does not match the source code's actual behavior. There is no accurate coverage of the core action, and secondary semantics are also largely misrepresented or absent.",
                "The summary claims the function groups C string and regex exceptions with specific escape patterns, which is inaccurate. The source code shows it initializes a struct with opening and closing rules using the provided delimiter, sets face types, creates a C exceptions object, and adds a closing rule, but there is no mention of specific escape patterns or grouping exceptions with regex beyond setting close rules. This is a FATAL error on the primary purpose because it misrepresents the core domain action, making the description misleading and untrustworthy."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Constructs a C language parsing rule set for strings and regex, including escape sequence exceptions and closing conditions.",
            "score": [
                0.8,
                0.6,
                0.5
            ],
            "reason": [
                "The summary correctly notes that the function constructs parsing rules for C strings and regex and includes exceptions, which align with the creation of 'open', 'face', 'exceptions', and 'close' structures in the code. However, it adds the term 'escape sequence exceptions' that is not explicitly supported in the source, making that part speculative. Overall, most claims are accurate but with minor unsupported detail, leading to high but not perfect alignment.",
                "The summary accurately captures that the function builds a parsing rule set for C strings and regex, including exceptions and closing conditions, aligning with the core purpose of setting up open/close rules, faces, and exceptions based on a delimiter. However, it omits several secondary details such as the explicit use of the provided delimiter in both open and close rules, the specific 'String_fface' assignment, and the construction details of 'words_new' with fixed counts. These omissions reduce coverage of critical behavior-specific semantics beyond the core.",
                "The summary correctly notes that the function constructs rules involving strings, regex, and exceptions, which aligns with the source code\u2019s creation of a sequence with String_fface, escape exceptions, and closing conditions. However, it inaccurately frames this as a generic 'C language parsing rule set' when the code does not implement a full C parser but rather a specific sequence structure with associated rules and closing words. This is a mild inaccuracy (NOISE) rather than a severe contradiction. The accurate elements are relatively generic and low-detail, offering limited engineering value."
            ]
        }
    }
}
{
    "source_code": "int mmc_get_phys_format_info(struct burn_drive *d, int *disk_category,\n\t\t\tchar **book_name, int *part_version, int *num_layers,\n\t\t\tint *num_blocks, int flag)\n{\n\tint ret, reply_len, prf;\n\tchar *reply = NULL;\n\tstatic char book_names[][16] = {\n\t\t\"DVD-ROM\", \"DVD-RAM\", \"DVD-R\", \"DVD-RW\",\n\t\t\"HD DVD-ROM\", \"HD DVD-RAM\", \"HD DVD-R\", \"unknown\",\n\t\t\"unknown\", \"DVD+RW\", \"DVD+R\", \"unknown\", \"unknown\",\n\t\t\"unknown\", \"DVD+RW DL\", \"DVD+R DL\", \"unknown\"\n\t};\n\n\tprf = d->current_profile;\n\tif (!(prf == 0x11 || prf == 0x13 || prf == 0x14 || prf == 0x15 ||\n\t      prf == 0x51))\n\t\treturn 0; /* Not a [HD] DVD-R[W] loaded */\n\tret = mmc_read_disc_structure(d, 0, 0, 0x10, 12, &reply,\n\t\t\t\t\t\t\t &reply_len, 0);\n\tif (ret <= 0)\n\t\tgoto ex;\n\tif(reply_len < 12) {\n\t\tlibdax_msgs_submit(libdax_messenger, -1, 0x00000002,\n\t\t\tLIBDAX_MSGS_SEV_DEBUG, LIBDAX_MSGS_PRIO_ZERO,\n\t\t\t\"READ DISC STRUCTURE format 10h: Less than 12 bytes\",\n\t\t\t0, 0);\n\t\t{ret = 0; goto ex;}\n\t}\n\t*disk_category = (reply[0] >> 4) & 0xf;\n\t*book_name = book_names[*disk_category];\n\t*part_version = reply[0] & 0xf;\n\t*num_layers = ((reply[2] >> 5) & 0x3) + 1;\n\t*num_blocks = ((reply[9] << 16) | (reply[10] << 8) | reply[11]) -\n\t              ((reply[5] << 16) | (reply[6] << 8) | reply[7]) + 1;\n\tret = 1;\nex:;\n\tif (reply != NULL)\n\t\tfree(reply);\n\treturn ret;\n}",
    "comment": "Retrieves physical format information of a disc in the drive, including disk category, book name, version, layer count, and block count.",
    "prorec_sum": "Reads and parses disc structure format 0x10h to extract track, address, session, and sector count information, then frees allocated memory.",
    "filter_prorec_sum": "Reads and parses a disc structure format 0x10h from the device, extracting fields into output parameters and logging an error if data is too short.",
    "prorec_aug_sum": "Reads a disc structure format 0x10h from the device, extracts header fields, computes range length, and returns parsed values to callers.",
    "filter_prorec_aug_sum": "Reads and parses optical disc structure format 0x10h data, extracting fields like layer, format, and sector range before freeing allocated memory.",
    "work_score": {
        "prorec_aug": {
            "summary": "Reads a disc structure format 0x10h from the device, extracts header fields, computes range length, and returns parsed values to callers.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function reads disc structure format 0x10h, extracts header fields, computes a range length, and returns parsed values. These are all verifiable behaviors found in the source code, such as the mmc_read_disc_structure call with format 0x10, extraction of fields into output parameters, and the calculation of num_blocks as a range length. All claims are accurate and grounded in code semantics, with no contradictions or irrelevant noise.",
                "The summary accurately captures the core action \u2014 reading disc structure format 0x10h from the device and parsing header fields to compute the block range \u2014 which matches the function\u2019s main purpose of retrieving physical format info for certain DVD profiles. It omits important secondary details such as the specific profile check before reading, handling insufficient reply length with debug logging, mapping disk category to a book name, and freeing allocated memory. While the core is correctly covered, the absence of these error handling and auxiliary data extraction aspects reduces completeness.",
                "The summary correctly describes that the function reads disc structure format 0x10h from the device, extracts header fields, computes a range length, and returns parsed values, which matches the code\u2019s behavior of calling `mmc_read_disc_structure`, parsing `reply` to fill output parameters, and calculating block count. There are no inaccurate or noisy claims, but the description is somewhat generic and omits conditional checks (e.g., profile filtering, reply length validation) and specifics of parameters like disk category and book name mapping. The gain is moderate, as the main actions are captured, but detail level is limited."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Reads and parses optical disc structure format 0x10h data, extracting fields like layer, format, and sector range before freeing allocated memory.",
            "score": [
                0.6,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function reads and parses optical disc structure format 0x10h and frees allocated memory, which matches the code. However, it inaccurately describes extracted fields: the code retrieves disk category, book name, part version, number of layers, and number of blocks, not a generic 'format' or 'sector range'. The core idea is mostly accurate, but there is partial mismatch in specific field details, leading to moderate precision.",
                "The summary correctly notes reading and parsing disc structure format 0x10h and extracting fields, which matches the core purpose of obtaining physical format info for supported DVD profiles. However, it omits profile checking logic, specific mappings to book names, error handling for insufficient data, and the calculation of number of blocks. Secondary coverage is minimal beyond mentioning freeing memory.",
                "The summary correctly states that the function reads and parses disc structure format 0x10h and extracts certain fields, which matches the code\u2019s behavior of calling mmc_read_disc_structure and decoding reply bytes. However, the description is vague: it does not specify the actual extracted fields like disk category, book name, part version, number of layers, and block count. The mention of 'sector range' is imprecise compared to the code, which computes block count from start and end addresses. There are no fatal inaccuracies, but the gain is low due to lack of detail and minor noise from imprecision."
            ]
        }
    }
}
{
    "source_code": "int aaip_add_acl_st_mode(char *acl_text, mode_t st_mode, int flag)\n{\n char *wpt;\n int tag_types= 0;\n\n tag_types = aaip_cleanout_st_mode(acl_text, &st_mode, 1);\n if(!(tag_types & (4 | 32))) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"user::%c%c%c\\n\",\n           st_mode & S_IRUSR ? 'r' : '-',\n           st_mode & S_IWUSR ? 'w' : '-',\n           st_mode & S_IXUSR ? 'x' : '-');\n }\n if(!(tag_types & (2 | 16 | 1024))) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"group::%c%c%c\\n\",\n         st_mode & S_IRGRP ? 'r' : '-',\n         st_mode & S_IWGRP ? 'w' : '-',\n         st_mode & S_IXGRP ? 'x' : '-');\n }\n if(!(tag_types & (1 | 8))) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"other::%c%c%c\\n\",\n         st_mode & S_IROTH ? 'r' : '-',\n         st_mode & S_IWOTH ? 'w' : '-',\n         st_mode & S_IXOTH ? 'x' : '-');\n }\n if((tag_types & (128 | 256)) && !(tag_types & 512)) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"mask::%c%c%c\\n\",\n         st_mode & S_IRGRP ? 'r' : '-',\n         st_mode & S_IWGRP ? 'w' : '-',\n         st_mode & S_IXGRP ? 'x' : '-');\n }\n return(1); \n}",
    "comment": "Adds entries for user, group, other, and mask permissions to an ACL string based on the provided `mode_t` and existing ACL tags.",
    "prorec_sum": "Formats and appends user, group, other, and mask permission strings to a buffer based on bit flags in the provided permissions value.",
    "filter_prorec_sum": "Formats and appends user, group, other, and mask permission strings based on access flags into the provided buffer.",
    "prorec_aug_sum": "Formats and appends user, group, other, and mask permission strings to a buffer based on specified access mode bits.",
    "filter_prorec_aug_sum": "Appends formatted user, group, other, and mask permission strings to the buffer based on the provided access mode flags.",
    "work_score": {
        "prorec_aug": {
            "summary": "Formats and appends user, group, other, and mask permission strings to a buffer based on specified access mode bits.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function formats and appends 'user', 'group', 'other', and 'mask' permission strings based on access mode bits, which matches the code's sprintf calls and conditional checks using st_mode bitmasks. It omits the conditional logic based on tag_types and the invocation of aaip_cleanout_st_mode, but all claims provided are factually accurate with respect to the source code. The proportion of accurate claims is above 80%, indicating high precision.",
                "The summary accurately captures the core purpose of appending formatted user, group, other, and mask permission strings to the provided buffer based on mode bits, which aligns with the function\u2019s primary domain-specific action. It covers all four ACL entries and indicates their derivation from the st_mode bitmask. However, it omits secondary details such as the conditional logic to exclude existing tags, the role of tag_types bitmask checks, and the invocation of aaip_cleanout_st_mode before appending. This yields solid core coverage but incomplete description of behavior-critical conditions.",
                "The summary correctly captures the core purpose of the function: formatting and appending user, group, other, and mask permission strings based on mode bits. This is fully aligned with the source code, which conditionally writes these ACL entries depending on tag presence. There is no inaccurate or noisy information, but the claim is broad and omits specific conditional logic for each type, making the gain modest rather than high."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Appends formatted user, group, other, and mask permission strings to the buffer based on the provided access mode flags.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly reflects the function\u2019s behavior of appending formatted permission strings for user, group, other, and mask categories based on st_mode flags. It omits some conditional details about when each category is appended, but all stated claims are accurate and relevant to the source code semantics, yielding a high proportion of accurate claims.",
                "The summary accurately captures the core function of appending formatted user, group, other, and mask permission strings to the ACL text buffer based on mode flags, which matches the primary purpose of the source code. However, it omits secondary details such as the conditional checks using tag_types to determine whether each permission type should be appended, the use of aaip_cleanout_st_mode to preprocess the mode flags, and the specific bitmask values controlling behavior. Thus, while the core is well covered, coverage of other critical semantics is incomplete.",
                "The summary makes a single accurate claim: the function appends formatted user, group, other, and mask permission strings to the provided buffer based on the mode flags. This matches the source code\u2019s behavior, which conditionally adds these ACL entries depending on tag_types and st_mode bits. No contradictory or irrelevant statements are present, but the gain is low because the claim is broad and omits the conditional logic controlling which entries are appended. Noise is negligible and no fatal errors are found."
            ]
        }
    }
}
{
    "source_code": "int get_counters(struct thread_data *t, struct core_data *c, struct pkg_data *p)\n{\n\tint cpu = t->cpu_id;\n\tunsigned long long msr;\n\n\tif (cpu_migrate(cpu)) {\n\t\tfprintf(stderr, \"Could not migrate to CPU %d\\n\", cpu);\n\t\treturn -1;\n\t}\n\n\tt->tsc = rdtsc();\t/* we are running on local CPU of interest */\n\n\tif (has_aperf) {\n\t\tif (get_msr(cpu, MSR_IA32_APERF, &t->aperf))\n\t\t\treturn -3;\n\t\tif (get_msr(cpu, MSR_IA32_MPERF, &t->mperf))\n\t\t\treturn -4;\n\t}\n\n\tif (do_smi) {\n\t\tif (get_msr(cpu, MSR_SMI_COUNT, &msr))\n\t\t\treturn -5;\n\t\tt->smi_count = msr & 0xFFFFFFFF;\n\t}\n\tif (extra_delta_offset32) {\n\t\tif (get_msr(cpu, extra_delta_offset32, &msr))\n\t\t\treturn -5;\n\t\tt->extra_delta32 = msr & 0xFFFFFFFF;\n\t}\n\n\tif (extra_delta_offset64)\n\t\tif (get_msr(cpu, extra_delta_offset64, &t->extra_delta64))\n\t\t\treturn -5;\n\n\tif (extra_msr_offset32) {\n\t\tif (get_msr(cpu, extra_msr_offset32, &msr))\n\t\t\treturn -5;\n\t\tt->extra_msr32 = msr & 0xFFFFFFFF;\n\t}\n\n\tif (extra_msr_offset64)\n\t\tif (get_msr(cpu, extra_msr_offset64, &t->extra_msr64))\n\t\t\treturn -5;\n\n\t/* collect core counters only for 1st thread in core */\n\tif (!(t->flags & CPU_IS_FIRST_THREAD_IN_CORE))\n\t\treturn 0;\n\n\tif (do_nhm_cstates) {\n\t\tif (get_msr(cpu, MSR_CORE_C3_RESIDENCY, &c->c3))\n\t\t\treturn -6;\n\t\tif (get_msr(cpu, MSR_CORE_C6_RESIDENCY, &c->c6))\n\t\t\treturn -7;\n\t}\n\n\tif (do_snb_cstates)\n\t\tif (get_msr(cpu, MSR_CORE_C7_RESIDENCY, &c->c7))\n\t\t\treturn -8;\n\n\tif (do_dts) {\n\t\tif (get_msr(cpu, MSR_IA32_THERM_STATUS, &msr))\n\t\t\treturn -9;\n\t\tc->core_temp_c = tcc_activation_temp - ((msr >> 16) & 0x7F);\n\t}\n\n\n\t/* collect package counters only for 1st core in package */\n\tif (!(t->flags & CPU_IS_FIRST_CORE_IN_PACKAGE))\n\t\treturn 0;\n\n\tif (do_nhm_cstates) {\n\t\tif (get_msr(cpu, MSR_PKG_C3_RESIDENCY, &p->pc3))\n\t\t\treturn -9;\n\t\tif (get_msr(cpu, MSR_PKG_C6_RESIDENCY, &p->pc6))\n\t\t\treturn -10;\n\t}\n\tif (do_snb_cstates) {\n\t\tif (get_msr(cpu, MSR_PKG_C2_RESIDENCY, &p->pc2))\n\t\t\treturn -11;\n\t\tif (get_msr(cpu, MSR_PKG_C7_RESIDENCY, &p->pc7))\n\t\t\treturn -12;\n\t}\n\tif (do_c8_c9_c10) {\n\t\tif (get_msr(cpu, MSR_PKG_C8_RESIDENCY, &p->pc8))\n\t\t\treturn -13;\n\t\tif (get_msr(cpu, MSR_PKG_C9_RESIDENCY, &p->pc9))\n\t\t\treturn -13;\n\t\tif (get_msr(cpu, MSR_PKG_C10_RESIDENCY, &p->pc10))\n\t\t\treturn -13;\n\t}\n\tif (do_rapl & RAPL_PKG) {\n\t\tif (get_msr(cpu, MSR_PKG_ENERGY_STATUS, &msr))\n\t\t\treturn -13;\n\t\tp->energy_pkg = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_CORES) {\n\t\tif (get_msr(cpu, MSR_PP0_ENERGY_STATUS, &msr))\n\t\t\treturn -14;\n\t\tp->energy_cores = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_DRAM) {\n\t\tif (get_msr(cpu, MSR_DRAM_ENERGY_STATUS, &msr))\n\t\t\treturn -15;\n\t\tp->energy_dram = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_GFX) {\n\t\tif (get_msr(cpu, MSR_PP1_ENERGY_STATUS, &msr))\n\t\t\treturn -16;\n\t\tp->energy_gfx = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_PKG_PERF_STATUS) {\n\t\tif (get_msr(cpu, MSR_PKG_PERF_STATUS, &msr))\n\t\t\treturn -16;\n\t\tp->rapl_pkg_perf_status = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_DRAM_PERF_STATUS) {\n\t\tif (get_msr(cpu, MSR_DRAM_PERF_STATUS, &msr))\n\t\t\treturn -16;\n\t\tp->rapl_dram_perf_status = msr & 0xFFFFFFFF;\n\t}\n\tif (do_ptm) {\n\t\tif (get_msr(cpu, MSR_IA32_PACKAGE_THERM_STATUS, &msr))\n\t\t\treturn -17;\n\t\tp->pkg_temp_c = tcc_activation_temp - ((msr >> 16) & 0x7F);\n\t}\n\treturn 0;\n}",
    "comment": "Aggregates packet and byte counters from multiple CPU entries into a single counter array based on the provided old counters.",
    "prorec_sum": "Iterates over indexed structures, aggregating 64-bit values into an output buffer while pausing on concurrent access flags until all entries are processed.",
    "filter_prorec_sum": "Iterates through indexed data structures, aggregating 64-bit values into an output array while synchronizing access using memory pause when contention is detected.",
    "prorec_aug_sum": "Iterates over rule entries, aggregating matched IPv6 packet data into an output array while synchronizing access with spin-wait on shared state flags.",
    "filter_prorec_aug_sum": "Iterates over table entries, accumulating specific 64\u2011bit values into an output array while synchronizing on entry locks and skipping busy entries.",
    "work_score": {
        "prorec_aug": {
            "summary": "Iterates over rule entries, aggregating matched IPv6 packet data into an output array while synchronizing access with spin-wait on shared state flags.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary describes iterating over rule entries and processing IPv6 packet data with spin-wait synchronization, which is entirely unrelated to the provided source code. The function in the source code collects hardware performance counters and MSR values for CPU/core/package levels, without any networking, IPv6 handling, or spin-wait mechanisms. All claims in the summary contradict the actual code\u2019s semantics, resulting in no accurate matches.",
                "The summary is entirely inaccurate, describing IPv6 packet aggregation and spin-wait synchronization, which does not match the source code's actual purpose of gathering CPU, core, and package performance counters via MSR reads with conditional handling and early returns for different hardware features. No accurate claims were made, and the core domain operation was missed entirely.",
                "The summary makes entirely unrelated claims about iterating over IPv6 packet rules and synchronizing with spin-wait, which do not match the actual function\u2019s purpose of reading hardware MSR counters for CPU, core, and package metrics. This is a complete mismatch and constitutes a severe factual error about the primary purpose and key I/O behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Iterates over table entries, accumulating specific 64\u2011bit values into an output array while synchronizing on entry locks and skipping busy entries.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary describes iterating over table entries with locks and skipping busy entries, which is unrelated to the actual source code behavior of reading CPU, core, and package MSR counters and returning error codes. None of the claims target the function\u2019s real semantics, resulting in all claims being inaccurate.",
                "The summary describes iterating over table entries and handling locks, which does not match the source code. The function in the source migrates to a designated CPU and reads various MSR registers to collect CPU, core, and package performance/energy counters, with multiple conditional branches and specific error codes. There is no iteration over table entries or lock handling in the code, so the core purpose and secondary details are entirely missing.",
                "The summary describes iterating over table entries and manipulating an output array with locking and skipping busy entries, which is entirely unrelated to the actual function. The source code reads MSR counters for a specific CPU, core, and package, stores results in provided structs, and handles various conditions and errors, with no table iteration or entry locks. This is a FATAL inaccuracy about the primary purpose, making the description unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic R_xlen_t\ncompact_intseq_Get_region(SEXP sx, R_xlen_t i, R_xlen_t n, int *buf)\n{\n    /* should not get here if x is already expanded */\n    CHECK_NOT_EXPANDED(sx);\n\n    SEXP info = COMPACT_SEQ_INFO(sx);\n    R_xlen_t size = COMPACT_INTSEQ_INFO_LENGTH(info);\n    R_xlen_t n1 = COMPACT_INTSEQ_INFO_FIRST(info);\n    int inc = COMPACT_INTSEQ_INFO_INCR(info);\n\n    R_xlen_t ncopy = size - i > n ? n : size - i;\n    if (inc == 1) {\n\tfor (R_xlen_t k = 0; k < ncopy; k++)\n\t    buf[k] = (int) (n1 + k + i);\n\treturn ncopy;\n    }\n    else if (inc == -1) {\n\tfor (R_xlen_t k = 0; k < ncopy; k++)\n\t    buf[k] = (int) (n1 - k - i);\n\treturn ncopy;\n    }\n    else\n\terror(\"compact sequences with increment %d not supported yet\", inc);\n}",
    "comment": "Extracts a specified region from a compact integer sequence into a buffer, handling both increasing and decreasing increments.",
    "prorec_sum": "Generates a sequence of integer indices from compact vector metadata, supporting increments of 1 or -1, and raises errors for unsupported formats.",
    "filter_prorec_sum": "Generates a sequence of integer indices from a compact R vector representation, validating increment support and handling increasing or decreasing sequences.",
    "prorec_aug_sum": "Generates a sequence of integer indices from compact vector metadata, supporting increments of 1 or -1, and raises errors for unsupported increments or expanded vectors.",
    "filter_prorec_aug_sum": "Generates a compact integer sequence from vector metadata, enforcing unexpanded state and rejecting unsupported increments.",
    "work_score": {
        "prorec_aug": {
            "summary": "Generates a sequence of integer indices from compact vector metadata, supporting increments of 1 or -1, and raises errors for unsupported increments or expanded vectors.",
            "score": [
                0.8,
                0.9,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function uses compact vector metadata to generate integer sequences, correctly identifies supported increments of 1 and -1, and notes that errors are raised for unsupported increments. However, it inaccurately claims that errors are raised for expanded vectors; the actual code uses a `CHECK_NOT_EXPANDED` macro, which implies the function assumes it is not expanded rather than explicitly raising an error. Despite this minor inaccuracy, most claims align well with the source semantics.",
                "The summary correctly states that the function generates integer sequences from compact vector metadata and handles increments of 1 or -1, which matches the core logic of reading COMPACT_SEQ_INFO and iterating accordingly. It also accurately mentions the error for unsupported increments (the else branch) and the precondition check for expanded vectors via CHECK_NOT_EXPANDED. These points cover the core primary purpose and key secondary behaviors, including branches and error handling, with no evident inaccuracies.",
                "The summary correctly states that the function generates integer sequences using compact vector metadata and supports increments of 1 or -1, which matches the loop logic in the source. It also accurately notes that it raises errors for unsupported increments. However, it inaccurately claims that errors are raised for expanded vectors; in reality, expanded vectors are prevented via a check macro rather than triggering an error. This is a minor inaccuracy, with most claims being specific and aligned to the code, providing good insight into core behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Generates a compact integer sequence from vector metadata, enforcing unexpanded state and rejecting unsupported increments.",
            "score": [
                0.8,
                0.3,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function enforces an unexpanded state and rejects unsupported increments, which matches the CHECK_NOT_EXPANDED call and the error branch for unsupported increment values. However, it inaccurately generalizes the behavior as generating a sequence purely from vector metadata without specifying that it retrieves a specified region of the sequence based on parameters i and n. Despite this, most claims are consistent with the source code\u2019s semantics.",
                "The summary correctly notes that the function enforces an unexpanded state and rejects unsupported increments, which aligns with explicit error handling and the CHECK_NOT_EXPANDED call in the source. However, the core purpose\u2014retrieving and copying a specified region of an existing compact integer sequence into the provided buffer based on index, count, and increment\u2014is missing. The wording 'generates a compact integer sequence' is misleading since the code does not generate from scratch but accesses a segment, so the main domain action is not covered.",
                "The summary captures accurate core behavior: it uses vector metadata to derive sequence values, ensures the object is not expanded, and rejects unsupported increments. These align with the code's logic for increment handling and unexpanded state checking. However, it inaccurately frames the function as generating an entire compact integer sequence rather than copying a requested range into a buffer, omitting important key I/O details such as partial retrieval and returning the number of integers copied. This misrepresentation of the primary purpose is a significant semantic error affecting trustworthiness."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\nxmlIsDocNameStartChar(xmlDocPtr doc, int c) {\n    if ((doc == NULL) || (doc->properties & XML_DOC_OLD10) == 0) {\n        /*\n\t * Use the new checks of production [4] [4a] amd [5] of the\n\t * Update 5 of XML-1.0\n\t */\n\tif (((c >= 'a') && (c <= 'z')) ||\n\t    ((c >= 'A') && (c <= 'Z')) ||\n\t    (c == '_') || (c == ':') ||\n\t    ((c >= 0xC0) && (c <= 0xD6)) ||\n\t    ((c >= 0xD8) && (c <= 0xF6)) ||\n\t    ((c >= 0xF8) && (c <= 0x2FF)) ||\n\t    ((c >= 0x370) && (c <= 0x37D)) ||\n\t    ((c >= 0x37F) && (c <= 0x1FFF)) ||\n\t    ((c >= 0x200C) && (c <= 0x200D)) ||\n\t    ((c >= 0x2070) && (c <= 0x218F)) ||\n\t    ((c >= 0x2C00) && (c <= 0x2FEF)) ||\n\t    ((c >= 0x3001) && (c <= 0xD7FF)) ||\n\t    ((c >= 0xF900) && (c <= 0xFDCF)) ||\n\t    ((c >= 0xFDF0) && (c <= 0xFFFD)) ||\n\t    ((c >= 0x10000) && (c <= 0xEFFFF)))\n\t    return(1);\n    } else {\n        if (IS_LETTER(c) || (c == '_') || (c == ':'))\n\t    return(1);\n    }\n    return(0);\n}",
    "comment": "Determines if a character is a valid starting character for an XML document name based on XML-1.0 specifications or old document properties.",
    "prorec_sum": "Checks whether a character code is valid as an XML name character, considering optional extended Unicode ranges and context-specific constraints.",
    "filter_prorec_sum": "Determines if a character code is valid for XML names by checking allowed ASCII symbols, Unicode ranges, and base character groups.",
    "prorec_aug_sum": "Checks if a given Unicode code point is a valid XML name character, considering parser state and XML specification character ranges.",
    "filter_prorec_aug_sum": "Determines if a character code is valid for XML name characters, supporting ASCII letters, digits, certain symbols, and specific Unicode ranges.",
    "work_score": {
        "prorec_aug": {
            "summary": "Checks if a given Unicode code point is a valid XML name character, considering parser state and XML specification character ranges.",
            "score": [
                0.7,
                0.4,
                0.2
            ],
            "reason": [
                "The summary states the function checks if a given Unicode code point is a valid XML name character, depending on parser state and XML specification ranges. The source code indeed evaluates `c` against various Unicode ranges, allows certain characters, and considers `doc->properties` to decide between old and new XML 1.0 checks. However, the summary inaccurately generalizes to 'XML name character'; the function specifically checks for name *start* characters, not all name characters. This mismatch reduces precision but most other aspects (Unicode ranges, parser state consideration) match the code.",
                "The summary correctly identifies that the function checks a Unicode code point against XML specification ranges and considers parser state, which matches the code\u2019s purpose. However, it inaccurately generalizes to 'XML name character' instead of specifically 'XML name start character', omitting the distinction crucial to the core purpose. It also lacks details on the use of updated XML 1.0 checks versus older logic and the exact ranges or constants involved, so coverage of secondary behaviors is thin.",
                "The summary contains one core claim: it checks if a given Unicode code point is a valid XML name character. This is partially inaccurate because the function specifically checks for valid XML *name start* characters, not all name characters. It correctly notes that parser state and XML specification ranges are considered, which matches the code\u2019s conditional branches and range checks. However, the conflation of 'name character' with 'name start character' is a significant semantic error on the primary purpose, making it a FATAL in Step 1 and hence heavily reducing trust in the summary despite some accurate detail."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Determines if a character code is valid for XML name characters, supporting ASCII letters, digits, certain symbols, and specific Unicode ranges.",
            "score": [
                0.3,
                0.4,
                0.2
            ],
            "reason": [
                "The summary incorrectly includes digits as valid start characters, which contradicts the source code that only permits letters, underscores, colons, and specific Unicode ranges. While it correctly notes ASCII letters, certain symbols, and Unicode ranges, the erroneous digit claim reduces accuracy to below half of the claims being correct.",
                "The summary captures the general purpose of checking if a character code is valid for XML names, which aligns with the function's core of validating start characters per XML-1.0 rules. However, it inaccurately includes 'digits' as allowed, which the source code does not permit for start characters, and omits critical distinctions between old and new XML rules based on document properties. It also lacks coverage of the detailed Unicode ranges and branch logic for different XML versions, weakening secondary coverage.",
                "The summary inaccurately states that the function supports digits, which contradicts the source code that only permits letters, underscore, colon, and specific Unicode ranges. This is a FATAL error because it misrepresents the primary purpose and allowed input set. While it correctly notes symbols and Unicode ranges, the critical inaccuracy regarding digits undermines trust in the core semantics."
            ]
        }
    }
}
{
    "source_code": "\nstatic void uncore_pci_remove(struct pci_dev *pdev)\n{\n\tstruct intel_uncore_box *box = pci_get_drvdata(pdev);\n\tstruct intel_uncore_pmu *pmu = box->pmu;\n\tint cpu, phys_id = pcibus_to_physid[pdev->bus->number];\n\n\tif (WARN_ON_ONCE(phys_id != box->phys_id))\n\t\treturn;\n\n\tpci_set_drvdata(pdev, NULL);\n\n\traw_spin_lock(&uncore_box_lock);\n\tlist_del(&box->list);\n\traw_spin_unlock(&uncore_box_lock);\n\n\tfor_each_possible_cpu(cpu) {\n\t\tif (*per_cpu_ptr(pmu->box, cpu) == box) {\n\t\t\t*per_cpu_ptr(pmu->box, cpu) = NULL;\n\t\t\tatomic_dec(&box->refcnt);\n\t\t}\n\t}\n\n\tWARN_ON_ONCE(atomic_read(&box->refcnt) != 1);\n\tkfree(box);\n}",
    "comment": "Removes an uncore PCI device, updates reference counts, and frees associated resources while ensuring proper synchronization in a multi-CPU environment.",
    "prorec_sum": "Unregisters an Intel uncore performance event, removes it from tracking lists, decrements references, and logs anomalies during cleanup.",
    "filter_prorec_sum": "Removes and cleans up an Intel uncore performance event when its configuration matches, updating linked structures and logging inconsistencies.",
    "prorec_aug_sum": "Unregisters an Intel uncore performance event, removes related references, updates counters, and logs inconsistencies in refcount during cleanup.",
    "filter_prorec_aug_sum": "Finalizes and cleans up an Intel uncore performance event, removing references, updating counters, and logging mismatches in perf_event_intel_uncore.c.",
    "work_score": {
        "prorec_aug": {
            "summary": "Unregisters an Intel uncore performance event, removes related references, updates counters, and logs inconsistencies in refcount during cleanup.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function removes references to an Intel uncore performance monitoring unit, updates counters (via atomic_dec on refcnt), and logs inconsistencies in refcount (via WARN_ON_ONCE checks), which aligns with the code. The claim about 'unregistering an Intel uncore performance event' is a reasonable generalization of the cleanup process, though not literally stated in the code, and remains safe. Overall, all claims map accurately to observable semantics, indicating high precision.",
                "The summary correctly notes cleanup steps like removing references, updating counters, and logging inconsistencies in refcount, which align with the code's removal of the box from lists, clearing per-CPU pointers, decrementing refcounts, and WARN checks. However, it does not explicitly cover the core purpose \u2014 removing an Intel uncore PCI device and associated PMU box \u2014 and instead generically refers to unregistering a performance event. Secondary details are partially captured but lack mention of driver data clearing, lock usage, and specific checks like matching phys_id, making coverage incomplete.",
                "The summary correctly captures key behaviors: it describes unregistering an Intel uncore-related entity, removing references, updating counters (via atomic_dec on refcnt), and logging inconsistencies with WARN_ON_ONCE when refcount mismatches occur during cleanup. These are specific, fact-based and aligned with the source code, with minimal noise and no inaccurate or contradictory claims. The gain is moderate to high since the actions are clearly tied to core functionality and side effects."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Finalizes and cleans up an Intel uncore performance event, removing references, updating counters, and logging mismatches in perf_event_intel_uncore.c.",
            "score": [
                0.8,
                0.5,
                0.7
            ],
            "reason": [
                "The summary contains mostly accurate claims: it describes cleanup of Intel uncore performance-related structures, removing references and updating counters, which aligns with the code\u2019s removal of list entries, resetting CPU pointers, decrementing refcounts, and freeing memory. The mention of logging mismatches corresponds to the WARN_ON_ONCE checks. However, the wording 'finalizes and cleans up an Intel uncore performance event' and citing 'perf_event_intel_uncore.c' is mildly imprecise as the function specifically removes an uncore PCI device, not a generic performance event, and the file name is not verified in the source. Overall, most claims are aligned with the code, but there is slight overgeneralization.",
                "The summary correctly notes that the function deals with cleanup of Intel uncore performance monitoring resources, including removing references and updating counters, and mentions logging mismatches. This aligns with the core purpose of removing a PCI-based uncore PMU box from internal tracking and freeing it. However, it omits key specifics such as the lock protection while removing from the list, the per-CPU pointer cleanup, the phys_id consistency check, and the exact freeing of the structure. Thus the core purpose is covered, but secondary behavioral details are only partially captured.",
                "The summary correctly captures that the function performs cleanup of Intel uncore structures by removing references and updating counters, matching the source code's removal from lists, nullifying per\u2011CPU pointers, and decrementing refcounts. It also notes mismatch logging which aligns with WARN_ON_ONCE checks. However, the mention of 'performance event' is slightly misleading since the code operates on uncore box/PMU structures rather than actual perf events, adding minor noise. Overall accuracy is high with some generic phrasing and low specificity about the exact objects manipulated."
            ]
        }
    }
}
{
    "source_code": "\nstatic void sig_child_handler(int sig_no UNUSED_PARAM)\n{\n\tpid_t pid;\n\tint l;\n\n\tif (verbose)\n\t\tbb_error_msg(INFO\"sig%s received\", \"child\");\n\twhile ((pid = wait_any_nohang(&wstat)) > 0) {\n\t\tfor (l = 0; l < dirn; ++l) {\n\t\t\tif (dir[l].ppid == pid) {\n\t\t\t\tdir[l].ppid = 0;\n\t\t\t\tprocessorstop(&dir[l]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}",
    "comment": "Handles SIGCHLD signals by cleaning up and processing terminated child processes that match entries in the directory.",
    "prorec_sum": "Processes incoming event codes, logs an \"end\" message with type and details, and conditionally invokes a final handler based on a global state flag.",
    "filter_prorec_sum": "Processes incoming event codes, logs them as either \"signal\" or \"exit\" with details, and finalizes handling based on a global state flag.",
    "prorec_aug_sum": "Processes input events, logs an \"end\" message with event details, and conditionally triggers further handling based on global state.",
    "filter_prorec_aug_sum": "Processes incoming event codes, logs an \"end\" message with exit or signal status, and triggers final handling if the global active flag is set.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes input events, logs an \"end\" message with event details, and conditionally triggers further handling based on global state.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about processing input events, logging an 'end' message, and conditionally triggering further handling do not match the source code, which defines a signal handler for SIGCHLD, logs a specific 'sig child received' message when verbose, and iterates over tracked child processes to stop associated processors. None of the claims accurately reflect the actual function behavior, resulting in zero accurate matches.",
                "The summary does not accurately reflect the source code\u2019s core purpose, which is to handle SIGCHLD signals, perform non-blocking waits for terminated child processes, log receipt of the signal, and stop relevant processors by matching child PIDs in a directory structure. The claims about processing input events, logging an 'end' message, and triggering further handling based on global state are unrelated to the actual signal handling and child process termination logic, making the core purpose entirely uncovered and the details inaccurate.",
                "The summary contains only inaccurate claims relative to the source code. It incorrectly describes processing input events and logging an 'end' message, while the function actually handles SIGCHLD signals, logs a 'child' signal message if verbose, and stops associated processors by matching child process IDs. This is a FATAL error targeting the primary purpose, resulting in unusable guidance."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes incoming event codes, logs an \"end\" message with exit or signal status, and triggers final handling if the global active flag is set.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about logging an 'end' message with exit or signal status and triggering final handling based on a global active flag do not align with the source code. The code logs a 'sigchild received' message when verbose is enabled, loops over terminated child processes, and stops corresponding processors, with no mention of event codes, exit/signal status logging, or an active flag. All claims are inaccurate, resulting in a low alignment with the evaluation steps.",
                "The summary fails to capture the core behavior of the function, which is handling SIGCHLD by logging a 'child' signal receipt when verbose, iterating non-blocking waits for terminated child processes, matching them to entries in a directory array, clearing their parent PID, and invoking processorstop. The described 'event codes', 'exit or signal status', and 'global active flag' are inaccurate and do not reflect the actual source logic. No accurate claim matches the core purpose, and secondary details are also missing or incorrect.",
                "The summary is largely inaccurate: it claims processing of event codes, logging an \"end\" message with exit/signal status, and conditional handling based on a global active flag, none of which are reflected in the source code. The source actually handles SIGCHLD, logs a verbose signal message, and iterates over a directory array to stop processors for matching child PIDs. These are core purpose mismatches, representing a FATAL error on the primary function semantics, making the description untrustworthy."
            ]
        }
    }
}
{
    "source_code": "\nint\nrl_arrow_keys (int count, int key)\n{\n  int ch;\n\n  RL_SETSTATE(RL_STATE_MOREINPUT);\n  ch = rl_read_key ();\n  RL_UNSETSTATE(RL_STATE_MOREINPUT);\n  if (ch < 0)\n    return (1);\n\n  switch (_rl_to_upper (ch))\n    {\n    case 'A':\n      rl_get_previous_history (count, ch);\n      break;\n\n    case 'B':\n      rl_get_next_history (count, ch);\n      break;\n\n    case 'C':\n      if (MB_CUR_MAX > 1 && rl_byte_oriented == 0)\n\trl_forward_char (count, ch);\n      else\n\trl_forward_byte (count, ch);\n      break;\n\n    case 'D':\n      if (MB_CUR_MAX > 1 && rl_byte_oriented == 0)\n\trl_backward_char (count, ch);\n      else\n\trl_backward_byte (count, ch);\n      break;\n\n    default:\n      rl_ding ();\n    }\n\n  return 0;\n}",
    "comment": "Handles arrow key inputs to navigate command history or move the cursor forward/backward, depending on the key pressed and character encoding.",
    "prorec_sum": "Handles arrow key input in readline, updating history navigation or cursor movement based on key codes and character encoding settings.",
    "filter_prorec_sum": "Handles arrow key inputs in readline, moving through command history or cursor position based on key type and character encoding settings.",
    "prorec_aug_sum": "Handles terminal arrow key input to navigate command history or move the cursor, supporting both single-byte and multibyte character environments.",
    "filter_prorec_aug_sum": "Handles arrow key input for navigating history and moving the cursor within a readline interface, supporting both byte-oriented and multibyte character modes.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles terminal arrow key input to navigate command history or move the cursor, supporting both single-byte and multibyte character environments.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly captures that the function handles arrow key input to navigate command history (up/down keys triggering previous/next history) and move the cursor (left/right navigation) as implemented in the switch cases, and notes support for single-byte and multibyte environments via the MB_CUR_MAX and rl_byte_oriented checks. All claims are specific to the source code behavior and accurately reflect its semantics.",
                "The summary accurately describes handling arrow key input to navigate history and move the cursor, and notes the distinction between single-byte and multibyte environments. These match the core purpose of mapping specific arrow keys to history navigation or cursor movement with byte/char mode handling. However, it omits secondary details such as setting/unsetting RL_STATE_MOREINPUT, reading the key via rl_read_key, handling invalid input by returning 1, and invoking rl_ding for unsupported keys.",
                "The summary correctly describes the core purpose of the function as handling terminal arrow keys to navigate history or move the cursor, and notes support for single-byte and multibyte environments, both of which match the code\u2019s behavior. It omits low-level specifics such as use of rl_read_key and RL_STATE_MOREINPUT, but these omissions do not constitute inaccuracies. There is no noise or fatal error; gains are moderate due to the generic phrasing and lack of detailed mapping of specific arrow keys to actions."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Handles arrow key input for navigating history and moving the cursor within a readline interface, supporting both byte-oriented and multibyte character modes.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly describes that the function handles arrow key input for history navigation and cursor movement, and notes support for both byte-oriented and multibyte character modes, which matches the conditional branches in the source code. It omits some specifics such as handling of invalid input via rl_ding, but all provided claims align with the code\u2019s semantics, yielding a high proportion of accurate statements.",
                "The summary correctly states that the function handles arrow key input for navigating history and moving the cursor, which matches the core purpose of processing arrow keys to invoke history navigation and character movement functions. It also accurately notes support for both byte-oriented and multibyte character modes, reflecting the conditional branches in the source code. However, it omits secondary details such as the initial and final state changes, handling of invalid key input with a ding, and the early return when no input is read. This limits coverage of other behavior-critical semantics.",
                "The summary correctly captures the core purpose of the function: processing arrow key input within a readline interface to navigate history and move the cursor. It also accurately notes support for both byte-oriented and multibyte character modes. No claims contradict the source code, and there is no significant noise. However, the summary is somewhat generic and lacks specifics about individual key mappings or internal state handling, resulting in limited detail for engineering use."
            ]
        }
    }
}
{
    "source_code": "\nint rtc_update_irq_enable(struct rtc_device *rtc, unsigned int enabled)\n{\n\tint err = mutex_lock_interruptible(&rtc->ops_lock);\n\tif (err)\n\t\treturn err;\n\n#ifdef CONFIG_RTC_INTF_DEV_UIE_EMUL\n\tif (enabled == 0 && rtc->uie_irq_active) {\n\t\tmutex_unlock(&rtc->ops_lock);\n\t\treturn rtc_dev_update_irq_enable_emul(rtc, 0);\n\t}\n#endif\n\t/* make sure we're changing state */\n\tif (rtc->uie_rtctimer.enabled == enabled)\n\t\tgoto out;\n\n\tif (rtc->uie_unsupported) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (enabled) {\n\t\tstruct rtc_time tm;\n\t\tktime_t now, onesec;\n\n\t\t__rtc_read_time(rtc, &tm);\n\t\tonesec = ktime_set(1, 0);\n\t\tnow = rtc_tm_to_ktime(tm);\n\t\trtc->uie_rtctimer.node.expires = ktime_add(now, onesec);\n\t\trtc->uie_rtctimer.period = ktime_set(1, 0);\n\t\terr = rtc_timer_enqueue(rtc, &rtc->uie_rtctimer);\n\t} else\n\t\trtc_timer_remove(rtc, &rtc->uie_rtctimer);\n\nout:\n\tmutex_unlock(&rtc->ops_lock);\n#ifdef CONFIG_RTC_INTF_DEV_UIE_EMUL\n\t/*\n\t * Enable emulation if the driver did not provide\n\t * the update_irq_enable function pointer or if returned\n\t * -EINVAL to signal that it has been configured without\n\t * interrupts or that are not available at the moment.\n\t */\n\tif (err == -EINVAL)\n\t\terr = rtc_dev_update_irq_enable_emul(rtc, enabled);\n#endif\n\treturn err;\n\n}",
    "comment": "Updates the RTC interrupt state, enabling or disabling the timer based on the provided flag, while handling potential emulation requirements.",
    "prorec_sum": "Changes the device\u2019s power state, updating related timestamps and invoking appropriate initialization or shutdown routines depending on the requested state.",
    "filter_prorec_sum": "Switches a codec\u2019s power state between active and idle, updating timing fields and invoking helper routines for initialization or shutdown as needed.",
    "prorec_aug_sum": "Changes a device\u2019s operational state based on the given mode, updating timing parameters and invoking start or stop routines before releasing a synchronization lock.",
    "filter_prorec_aug_sum": "Switches the device between active and inactive states, updating timing parameters and invoking appropriate initialization or shutdown routines based on the requested state.",
    "work_score": {
        "prorec_aug": {
            "summary": "Changes a device\u2019s operational state based on the given mode, updating timing parameters and invoking start or stop routines before releasing a synchronization lock.",
            "score": [
                0.3,
                0.3,
                0.4
            ],
            "reason": [
                "The summary contains only generic statements like changing operational state, updating timing parameters, and invoking routines before releasing a lock. While broadly true, it omits key specific behaviors from the code such as conditional emulation handling, checks for unsupported operations, timing calculations from current RTC time, and the guarded state-change logic. The vagueness means few precise, verifiable claims about code semantics are made, resulting in low accuracy proportion.",
                "The summary generally describes toggling a device\u2019s state and adjusting timing, but it omits the specific core purpose of enabling or disabling the RTC update interrupt and managing its timer. Key semantics such as checking for unsupported modes, handling emulation paths, and scheduling or removing the UIE timer are missing. While the lock-release detail is accurate, the description remains vague and lacks most secondary behaviors critical in the source, resulting in incomplete coverage.",
                "The summary is too generic and does not capture the core domain-specific behavior of enabling or disabling RTC update IRQs. While it mentions changing operational state, updating timing parameters, and start/stop routines with a lock release, these are broad and could apply to many functions. Key specifics from the source, such as handling unsupported IRQs, conditional emulation paths, and precise timer setup/removal, are missing. There are no clear factual inaccuracies (no FATAL), but the lack of detail results in low informational gain and significant noise relative to the source code semantics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Switches the device between active and inactive states, updating timing parameters and invoking appropriate initialization or shutdown routines based on the requested state.",
            "score": [
                0.5,
                0.2,
                0.2
            ],
            "reason": [
                "The summary generically describes switching a device between active and inactive states with associated initialization or shutdown, which loosely matches the function's enable/disable behavior for RTC update interrupts. However, it omits key specifics such as mutex locking, handling of unsupported operations, emulation paths, and precise timer setup/removal logic, making it overly generic. While partially accurate in spirit, it misses most domain-specific details from the source code.",
                "The summary vaguely describes switching the device between states and updating timing parameters but does not mention the specific core purpose of enabling or disabling RTC update interrupts via the uie_rtctimer or emulation path. While it loosely implies activation/deactivation, it omits concrete domain details like handling unsupported cases, reading current time, scheduling one-second timers, removing timers, and emulated IRQ enabling. As a result, the core functionality is not clearly covered and secondary behavior-critical semantics are missing.",
                "The summary incorrectly frames the function as toggling the *whole* device between active/inactive states and running generic initialization/shutdown routines, which contradicts the code\u2019s actual purpose of enabling/disabling an RTC update interrupt and managing its timer configuration. This is a FATAL error regarding the primary purpose, as it misrepresents the core I/O behavior. While it vaguely mentions updating timing parameters, the context and specificity are wrong, and there are no accurate GOLD claims to offset the severe inaccuracy."
            ]
        }
    }
}
{
    "source_code": "\nstatic ngx_int_t\nngx_http_variable_tcpinfo(ngx_http_request_t *r, ngx_http_variable_value_t *v,\n    uintptr_t data)\n{\n    struct tcp_info  ti;\n    socklen_t        len;\n    uint32_t         value;\n\n    len = sizeof(struct tcp_info);\n    if (getsockopt(r->connection->fd, IPPROTO_TCP, TCP_INFO, &ti, &len) == -1) {\n        v->not_found = 1;\n        return NGX_OK;\n    }\n\n    v->data = ngx_pnalloc(r->pool, NGX_INT32_LEN);\n    if (v->data == NULL) {\n        return NGX_ERROR;\n    }\n\n    switch (data) {\n    case 0:\n        value = ti.tcpi_rtt;\n        break;\n\n    case 1:\n        value = ti.tcpi_rttvar;\n        break;\n\n    case 2:\n        value = ti.tcpi_snd_cwnd;\n        break;\n\n    case 3:\n        value = ti.tcpi_rcv_space;\n        break;\n\n    /* suppress warning */\n    default:\n        value = 0;\n        break;\n    }\n\n    v->len = ngx_sprintf(v->data, \"%uD\", value) - v->data;\n    v->valid = 1;\n    v->no_cacheable = 0;\n    v->not_found = 0;\n\n    return NGX_OK;\n}",
    "comment": "Retrieves TCP connection statistics like RTT, RTT variance, send window size, or receive space and stores the result in an HTTP variable.",
    "prorec_sum": "Retrieves TCP connection statistics via `getsockopt` and formats a selected metric into a string buffer for further use in the response structure.",
    "filter_prorec_sum": "Retrieves TCP connection statistics via getsockopt and writes a selected metric as a formatted string into a provided buffer structure.",
    "prorec_aug_sum": "Retrieves TCP connection statistics via getsockopt and formats a selected metric into a string buffer for later use in the associated structure.",
    "filter_prorec_aug_sum": "Retrieves TCP connection info via `getsockopt` and stores a selected metric as a formatted string into an NGINX buffer structure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Retrieves TCP connection statistics via getsockopt and formats a selected metric into a string buffer for later use in the associated structure.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function uses getsockopt to retrieve TCP statistics and formats the selected metric into a string buffer, matching the source code's behavior. It omits specific details about which metrics can be selected and handling for errors, but the claims present are factually accurate and directly grounded in the code, giving a high proportion of accurate statements.",
                "The summary accurately states that the function uses getsockopt to retrieve TCP connection statistics and formats a selected metric into a buffer for later use, which aligns with the core purpose of extracting specific TCP_INFO fields and converting them into string form for an Nginx variable. However, it omits important secondary details such as which exact metrics can be selected, error handling when getsockopt fails or memory allocation fails, and the specific fields set in the variable structure (e.g., valid, not_found flags).",
                "The summary correctly states that the function uses getsockopt to obtain TCP connection statistics and formats a selected metric into a string for storage in the supplied structure. This matches the source code's retrieval of tcp_info values and conversion to a string in v->data. The claim is accurate, specific to the code's core purpose, and contains minimal noise, though it lacks detailed enumeration of the possible metrics handled. No inaccurate or misleading statements are present."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Retrieves TCP connection info via `getsockopt` and stores a selected metric as a formatted string into an NGINX buffer structure.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function uses `getsockopt` to retrieve TCP connection info and formats a selected metric into an NGINX buffer structure, which aligns precisely with the source code's behavior. Although it omits specific metric details, the claims are accurate and relevant to the function's semantics, yielding a high proportion of accurate statements.",
                "The summary accurately states that the function uses `getsockopt` to obtain TCP connection info and stores a chosen metric formatted into an NGINX variable buffer, which matches the core domain purpose of retrieving specific TCP_INFO fields (RTT, RTT variance, send congestion window, or receive space) and formatting them for NGINX variables. However, it omits secondary details such as the selection mechanism via `data` cases, error handling for failed `getsockopt` and allocation, and the setting of validity flags on the variable value. Thus, while the core purpose is covered, secondary coverage is minimal.",
                "The summary correctly states that the function uses `getsockopt` to obtain TCP connection information and stores a selected metric as a formatted string in an NGINX buffer structure. This aligns with the code, which retrieves `struct tcp_info` and formats one of several fields into a buffer. The claim is accurate but broad, lacking detail about which metrics are selected based on the `data` parameter or how errors are handled. There are no inaccurate or noisy statements, but the gain is low due to its generic nature."
            ]
        }
    }
}
{
    "source_code": "\nint libjte_write_header(struct libjte_env *o)\n{\n    int ret;\n\n    if (o->jtemplate_out == NULL || o->jjigdo_out == NULL ||\n        o->outfile == NULL || o->jmd5_list == NULL) {\n        sprintf(o->message_buffer,\n               \"Undefined: template_path, jigdo_path, md5_paths, or outfile.\");\n        libjte_add_msg_entry(o, o->message_buffer, 0);\n        return 0;\n    }\n    \n    o->jttemplate = fopen(o->jtemplate_out, \"wb\");\n    if (o->jttemplate == NULL) {\n        sprintf(o->message_buffer,\n                \"Cannot open template file '%1.1024s' for writing. errno=%d\",\n                o->jtemplate_out, errno);\n        libjte_add_msg_entry(o, o->message_buffer, 0);\n        return 0;\n    }\n    o->jtjigdo = fopen(o->jjigdo_out, \"wb\");\n    if (o->jtjigdo == NULL) {\n        sprintf(o->message_buffer,\n                \"Cannot open jigdo file '%1.1024s' for writing. errno=%d\",\n                o->jjigdo_out, errno);\n        libjte_add_msg_entry(o, o->message_buffer, 0);\n        return 0;\n    }\n\n    ret = write_jt_header(o, o->jttemplate, o->jtjigdo);\n    if (ret <= 0)\n        return ret;\n    return 1;\n}",
    "comment": "Initializes output files for a template and jigdo, checks for errors, and writes the header using the provided environment structure.",
    "prorec_sum": "Opens specified template and jigdo output files for writing, reports detailed errors if opening fails, then processes them with a dedicated handler function.",
    "filter_prorec_sum": "Opens specified template and jigdo output files for writing, reports detailed errors if opening fails, and processes them through a subsequent file-handling routine.",
    "prorec_aug_sum": "Opens specified template and jigdo files for writing, reports detailed errors if opening fails, and processes them when both are successfully opened.",
    "filter_prorec_aug_sum": "Opens specified template and jigdo files for writing, reports detailed errors if opening fails, and processes them using a subsequent file-handling routine.",
    "work_score": {
        "prorec_aug": {
            "summary": "Opens specified template and jigdo files for writing, reports detailed errors if opening fails, and processes them when both are successfully opened.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly describes the function's core behavior: opening template and jigdo files for writing, reporting detailed errors on failure, and proceeding only if both are opened successfully. These are accurate and specific to the code, with no contradictions or irrelevant statements. Minor omission is that the summary does not mention the initial null-pointer checks for paths and md5 list, but the majority of claims align closely with the source semantics.",
                "The summary accurately describes the core behavior of opening the template and jigdo files and handling error reporting when opening fails, matching the source's primary purpose. It also notes subsequent processing upon successful opening, which corresponds to calling the header writing function. However, it omits edge-case checks for null path arguments and related early returns, as well as the specific involvement of message buffering and libjte_add_msg_entry. Secondary coverage is thus incomplete.",
                "The summary correctly captures the core purpose: opening template and jigdo files for writing, error reporting on failure, and proceeding to process when successful. It omits the initial check for required non-null parameters and the call to write_jt_header, but these are minor and do not contradict code semantics. The claims are accurate but relatively general, offering limited detail beyond the basic flow, resulting in moderate informational value with no noise or fatal inaccuracies."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Opens specified template and jigdo files for writing, reports detailed errors if opening fails, and processes them using a subsequent file-handling routine.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function opens specified template and jigdo files for writing, reports detailed errors if opening fails, and processes them using another routine. All these claims match the source code behavior, including error handling with messages and calling a subsequent routine (`write_jt_header`). No inaccurate or irrelevant claims were found, resulting in a very high proportion of accurate statements.",
                "The summary accurately captures the core purpose of opening the specified template and jigdo files for writing, including the detailed error reporting when opening fails, which matches the source code behavior. It also notes further processing through a subsequent routine, aligning with the call to write_jt_header. However, it omits initial validation of required output paths and MD5 list, as well as specifics about return values and exit conditions, which limits coverage of secondary details.",
                "The summary correctly states that the function opens template and jigdo files for writing, handles errors when opening fails, and then processes them via another routine. These are accurate reflections of the source code\u2019s core behavior. However, it omits the pre-check where the function ensures necessary output paths and md5 list are not NULL, returning early with an error message if they are missing. Overall, there are no inaccurate claims targeting the code, and the summary\u2019s statements are specific enough to capture the main purpose, providing moderate gain."
            ]
        }
    }
}
{
    "source_code": "\nint __ipv6_addr_type(const struct in6_addr *addr)\n{\n\t__be32 st;\n\n\tst = addr->s6_addr32[0];\n\n\t/* Consider all addresses with the first three bits different of\n\t   000 and 111 as unicasts.\n\t */\n\tif ((st & htonl(0xE0000000)) != htonl(0x00000000) &&\n\t    (st & htonl(0xE0000000)) != htonl(0xE0000000))\n\t\treturn (IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\n\n\tif ((st & htonl(0xFF000000)) == htonl(0xFF000000)) {\n\t\t/* multicast */\n\t\t/* addr-select 3.1 */\n\t\treturn (IPV6_ADDR_MULTICAST |\n\t\t\tipv6_addr_scope2type(IPV6_ADDR_MC_SCOPE(addr)));\n\t}\n\n\tif ((st & htonl(0xFFC00000)) == htonl(0xFE800000))\n\t\treturn (IPV6_ADDR_LINKLOCAL | IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_LINKLOCAL));\t\t/* addr-select 3.1 */\n\tif ((st & htonl(0xFFC00000)) == htonl(0xFEC00000))\n\t\treturn (IPV6_ADDR_SITELOCAL | IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_SITELOCAL));\t\t/* addr-select 3.1 */\n\tif ((st & htonl(0xFE000000)) == htonl(0xFC000000))\n\t\treturn (IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t\t\t/* RFC 4193 */\n\n\tif ((addr->s6_addr32[0] | addr->s6_addr32[1]) == 0) {\n\t\tif (addr->s6_addr32[2] == 0) {\n\t\t\tif (addr->s6_addr32[3] == 0)\n\t\t\t\treturn IPV6_ADDR_ANY;\n\n\t\t\tif (addr->s6_addr32[3] == htonl(0x00000001))\n\t\t\t\treturn (IPV6_ADDR_LOOPBACK | IPV6_ADDR_UNICAST |\n\t\t\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_LINKLOCAL));\t/* addr-select 3.4 */\n\n\t\t\treturn (IPV6_ADDR_COMPATv4 | IPV6_ADDR_UNICAST |\n\t\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t/* addr-select 3.3 */\n\t\t}\n\n\t\tif (addr->s6_addr32[2] == htonl(0x0000ffff))\n\t\t\treturn (IPV6_ADDR_MAPPED |\n\t\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t/* addr-select 3.3 */\n\t}\n\n\treturn (IPV6_ADDR_UNICAST |\n\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t/* addr-select 3.4 */\n}",
    "comment": "Determines the IPv6 address type (unicast, multicast, link-local, site-local, loopback, or any) based on the address structure and specific bit patterns.",
    "prorec_sum": "Classifies packet header data based on specific byte patterns and bit masks, returning distinct constant codes for recognized network protocol conditions.",
    "filter_prorec_sum": "Determines packet type codes by inspecting specific byte patterns and bitfields in a memory buffer, returning distinct constants for recognized protocol signatures.",
    "prorec_aug_sum": "Evaluates the first bytes of a data block against specific bit patterns and constants to identify and return a corresponding numeric type code.",
    "filter_prorec_aug_sum": "Evaluates the first bytes of a memory block against specific constants and returns a code identifying the detected data format or special marker.",
    "work_score": {
        "prorec_aug": {
            "summary": "Evaluates the first bytes of a data block against specific bit patterns and constants to identify and return a corresponding numeric type code.",
            "score": [
                0.6,
                0.2,
                0.5
            ],
            "reason": [
                "The summary states that the function evaluates the first bytes of a data block against bit patterns and constants to return a numeric type code, which is generally accurate in the context of the source code, as the function inspects the first 32 bits of an IPv6 address and returns constants representing the address type. However, the summary is overly generic, omits important specifics such as the classification of IPv6 addresses (unicast, multicast, link-local, etc.), and refers to 'data block' rather than 'IPv6 address', reducing precision. Most of the claim aligns with the code but lacks the detailed semantics necessary for high alignment.",
                "The summary correctly notes that the function inspects the initial bytes and uses bit patterns and constants to determine a type code, which aligns generically with the code\u2019s use of bit masks on the address prefix. However, it does not mention the core purpose of classifying an IPv6 address into specific categories like unicast, multicast, link-local, site-local, loopback, etc., nor does it cover the detailed branch conditions or scope determinations present in the code. Therefore, the core domain semantics are missing and secondary coverage is minimal.",
                "The summary captures the general idea that the function inspects the leading bytes of the address and compares them to constants to determine a type code, which aligns with the source code\u2019s use of bitmask checks and constant comparisons. However, it is overly generic, lacks detail on IPv6-specific address classifications or scope handling, and omits key return categories such as multicast, link-local, site-local, loopback, and mapped addresses. This results in low informational gain with no explicit inaccuracies but a noticeable amount of generic noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Evaluates the first bytes of a memory block against specific constants and returns a code identifying the detected data format or special marker.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary describes evaluating the first bytes of a memory block to detect a data format or marker, which does not match the source code's semantics of checking IPv6 address prefixes to determine address type and scope. All claims are inaccurate as they neither reference IPv6 addresses nor the specific constants used for address classification, leading to no alignment with the function's domain behavior.",
                "The summary incorrectly describes the function as checking a generic memory block for constants to identify data formats or markers, which contradicts the source code. The core purpose of the function is to classify an IPv6 address into specific types and scope categories based on its bit patterns, not to detect data formats. No accurate claims capture this domain-specific action or any secondary behaviors like distinguishing multicast, link-local, site-local, loopback, mapped addresses, or special constants. This results in a complete miss of the core and all key semantics.",
                "The summary incorrectly describes the function as evaluating a memory block for data format or markers, which contradicts the source code\u2019s actual purpose of classifying IPv6 addresses by type and scope based on their bit patterns. This is a severe factual error directly affecting the primary purpose, making the description misleading and unusable. No accurate, domain-relevant claims are present to offset the error."
            ]
        }
    }
}
{
    "source_code": "static void\nnlmsvc_insert_block_locked(struct nlm_block *block, unsigned long when)\n{\n\tstruct nlm_block *b;\n\tstruct list_head *pos;\n\n\tdprintk(\"lockd: nlmsvc_insert_block(%p, %ld)\\n\", block, when);\n\tif (list_empty(&block->b_list)) {\n\t\tkref_get(&block->b_count);\n\t} else {\n\t\tlist_del_init(&block->b_list);\n\t}\n\n\tpos = &nlm_blocked;\n\tif (when != NLM_NEVER) {\n\t\tif ((when += jiffies) == NLM_NEVER)\n\t\t\twhen ++;\n\t\tlist_for_each(pos, &nlm_blocked) {\n\t\t\tb = list_entry(pos, struct nlm_block, b_list);\n\t\t\tif (time_after(b->b_when,when) || b->b_when == NLM_NEVER)\n\t\t\t\tbreak;\n\t\t}\n\t\t/* On normal exit from the loop, pos == &nlm_blocked,\n\t\t * so we will be adding to the end of the list - good\n\t\t */\n\t}\n\n\tlist_add_tail(&block->b_list, pos);\n\tblock->b_when = when;\n}",
    "comment": "Inserts a network lock block into a sorted list based on its scheduled time, managing its reference count and handling the list initialization.",
    "prorec_sum": "Manipulates a doubly linked list to replace an element, handle reference counting, and update associated offset metadata.",
    "filter_prorec_sum": "Manages slab cache list pointers and reference counts, inserting or updating an entry based on object index and initializing kref when first accessed.",
    "prorec_aug_sum": "Updates doubly-linked list pointers for an object, increments its reference count, and positions it according to a computed offset value.",
    "filter_prorec_aug_sum": "Adjusts linked list pointers for an entry, updates its reference count, and sets its position based on an offset within a global list.",
    "work_score": {
        "prorec_aug": {
            "summary": "Updates doubly-linked list pointers for an object, increments its reference count, and positions it according to a computed offset value.",
            "score": [
                0.7,
                0.3,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function updates list pointers and increments the reference count, which matches the use of list_add_tail/list_del_init and kref_get in the code. However, the description of 'positions it according to a computed offset value' is imprecise and potentially misleading; the code uses a 'when' time value derived from jiffies, not a generic offset, to sort insertion order. Most core behaviors are captured, but the positioning logic is not described with domain-specific accuracy.",
                "The summary correctly notes that the function updates linked list pointers and increments a reference count, but it misrepresents the positioning logic as based on a computed offset value rather than an absolute time calculation relative to jiffies and NLM_NEVER semantics. It fails to state the core purpose\u2014ordering and inserting an NLM lock block into a global blocked list based on its scheduled time\u2014and omits key behavior such as handling list membership, NLM_NEVER special-case adjustment, and loop-based insertion point search.",
                "The summary correctly notes that the function updates doubly-linked list pointers and increments the object's reference count, which matches the list manipulation and kref_get logic in the code. However, the description of positioning based on a 'computed offset value' is inaccurate: the code positions the block in the list according to a computed absolute time (jiffies + when), not an offset value in a generic sense. This is a minor semantic mismatch but does not affect the primary purpose. Overall, the summary has low noise and some correctness but lacks detailed specifics about the time-based ordering logic, resulting in low net gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Adjusts linked list pointers for an entry, updates its reference count, and sets its position based on an offset within a global list.",
            "score": [
                0.6,
                0.3,
                0.6
            ],
            "reason": [
                "The summary correctly notes adjusting linked list pointers and updating the reference count, which matches the code's use of list operations and kref_get. However, the claim about setting position based on an 'offset within a global list' is misleading; the code places the block based on timing logic involving 'when' and 'jiffies', not a generic offset. This introduces inaccuracy, so only part of the summary precisely reflects the function's semantics.",
                "The summary mentions adjusting linked list pointers and updating a reference count, which matches accurate elements in the code. However, it describes the positioning as based on an 'offset' rather than the actual time-based ordering logic with the 'when' parameter and special handling for NLM_NEVER. This means the core primary purpose\u2014placing a block in the global nlm_blocked list in correct temporal order\u2014was not explicitly covered. Secondary details like conditionally incrementing 'when' or removing from the list when already present are also missing.",
                "The summary correctly notes that the function adjusts linked list pointers and updates a reference count when appropriate, which matches the code's handling of b_list and b_count. It also captures that the entry's position is set relative to a global list, partially reflecting the use of nlm_blocked and time-based insertion. However, 'offset' is inaccurate as it suggests a positional index rather than a time-based scheduling mechanism, and it omits specifics about how 'when' is computed and adjusted. The inaccuracies are minor and do not contradict the core purpose, but the description is overly generic with weak detail, limiting its usefulness."
            ]
        }
    }
}
{
    "source_code": "void mm_drop_all_locks(struct mm_struct *mm)\n{\n\tstruct vm_area_struct *vma;\n\tstruct anon_vma_chain *avc;\n\n\tBUG_ON(down_read_trylock(&mm->mmap_sem));\n\tBUG_ON(!mutex_is_locked(&mm_all_locks_mutex));\n\n\tfor (vma = mm->mmap; vma; vma = vma->vm_next) {\n\t\tif (vma->anon_vma)\n\t\t\tlist_for_each_entry(avc, &vma->anon_vma_chain, same_vma)\n\t\t\t\tvm_unlock_anon_vma(avc->anon_vma);\n\t\tif (vma->vm_file && vma->vm_file->f_mapping)\n\t\t\tvm_unlock_mapping(vma->vm_file->f_mapping);\n\t}\n\n\tmutex_unlock(&mm_all_locks_mutex);\n}",
    "comment": "Releases all locks on virtual memory areas and their associated anonymous virtual memory structures in the specified memory management structure.",
    "prorec_sum": "Cleans up and releases DRM file-private resources, iterating related objects to clear flags, drop references, and finalize associated synchronization primitives.",
    "filter_prorec_sum": "Traverses and cleans up file-private DRM data structures, releasing associated fences and reference counts before final global teardown.",
    "prorec_aug_sum": "Releases queued work items and clears pending flags before finalizing and freeing associated workqueue control structures.",
    "filter_prorec_aug_sum": "Cleans up and releases resources for a linked list of workqueue-related structures, resetting pending work bits and invoking required finalization routines.",
    "work_score": {
        "prorec_aug": {
            "summary": "Releases queued work items and clears pending flags before finalizing and freeing associated workqueue control structures.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary's single claim describes releasing queued work items, clearing pending flags, and freeing workqueue control structures, which is unrelated to the function's actual behavior of unlocking anon_vma and mapping structures for all VMAs in a memory descriptor and releasing a specific mutex. This is a complete semantic mismatch, resulting in no accurate claims.",
                "The summary claims the function releases queued work items and clears pending flags related to workqueue control structures, which is entirely unrelated to the source code. The function in the source code iterates over VMAs in an mm_struct to unlock anon_vma and mapping locks, ensuring preconditions via BUG_ON checks and finally unlocking a global mutex. There is no mention of workqueues or queued items, so the core purpose and any relevant behaviors are completely missed.",
                "The summary describes releasing work items and clearing flags for workqueue control structures, which is entirely unrelated to the source code\u2019s core purpose of unlocking anonymous VMAs and mappings in a memory management context. This is a severe FATAL error on the primary purpose, as the summary completely misstates the function\u2019s domain and semantics, making it untrustworthy and unusable."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Cleans up and releases resources for a linked list of workqueue-related structures, resetting pending work bits and invoking required finalization routines.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about workqueue-related structures, resetting pending work bits, and finalization routines do not align with the source code, which manages memory mappings, unlocks anon_vma and file mappings, and releases a mutex. None of the claims target the actual semantics in the function, resulting in no accurate statements.",
                "The summary incorrectly describes workqueue-related structures and pending work bits, which do not appear in the source code. The core purpose is to iterate through all VMAs in an mm_struct, unlocking anon_vma and file mapping locks, and then releasing a global mutex. None of these domain-specific operations are mentioned, so the core function behavior is entirely missed and the summary is unrelated.",
                "The summary describes cleanup of workqueue-related structures, resetting pending work bits, and finalization routines, which is entirely unrelated to the actual code. The function in the source code releases locks on anonymous VMAs and file mappings within a memory descriptor and unlocks a global mutex. This constitutes a severe FATAL error targeting the primary purpose, as the summary misidentifies the domain completely, leading to zero alignment and making it unusable."
            ]
        }
    }
}
{
    "source_code": "int\ngnet_stats_finish_copy(struct gnet_dump *d)\n{\n\tif (d->tail)\n\t\td->tail->nla_len = skb_tail_pointer(d->skb) - (u8 *)d->tail;\n\n\tif (d->compat_tc_stats)\n\t\tif (gnet_stats_copy(d, d->compat_tc_stats, &d->tc_stats,\n\t\t\tsizeof(d->tc_stats)) < 0)\n\t\t\treturn -1;\n\n\tif (d->compat_xstats && d->xstats) {\n\t\tif (gnet_stats_copy(d, d->compat_xstats, d->xstats,\n\t\t\td->xstats_len) < 0)\n\t\t\treturn -1;\n\t}\n\n\tspin_unlock_bh(d->lock);\n\treturn 0;\n}",
    "comment": "Finalizes the statistics copy process by updating lengths and copying compatible statistics into the provided structures before unlocking the spinlock.",
    "prorec_sum": "Frees and resets a PCM substream\u2019s allocated buffers after invoking preparation routines, returning status based on buffer validity checks.",
    "filter_prorec_sum": "Frees and cleans up a PCM substream\u2019s allocated buffers after attempting necessary data preparation or transfer operations.",
    "prorec_aug_sum": "Processes VLAN-related data from a network bridge, validates device state, invokes packet handling, and cleans up associated resources after execution.",
    "filter_prorec_aug_sum": "Processes VLAN-related data from a bridge structure, validates associated device state, invokes a handler, resets fields, and signals completion or failure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes VLAN-related data from a network bridge, validates device state, invokes packet handling, and cleans up associated resources after execution.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about processing VLAN-related data, validating device state, invoking packet handling, and cleaning up resources are unrelated to the actual function's semantics. The source code handles updating statistics structures, conditional copying of stats, and unlocking a spinlock, with no indication of VLAN processing or device state validation. All claims are inaccurate, yielding 0% accuracy.",
                "The summary's claims about processing VLAN data, validating device state, invoking packet handling, and resource cleanup are unrelated to the source code's actual domain behavior. The function in the source code calculates nla_len for a tail pointer, optionally copies statistics structures, handles compatibility cases, and unlocks a spinlock. None of the summary\u2019s claims accurately reflect these operations, so the core purpose is not covered and all claims are [INACCURATE].",
                "The summary claims VLAN-related data processing, device state validation, packet handling, and resource cleanup, none of which are reflected in the source code. The actual function finalizes a statistics copy operation, adjusts lengths, potentially copies stats, unlocks a spinlock, and returns a status code. These are core semantics misrepresented by the summary, leading to a severe FATAL error about the primary purpose. There are no accurate statements, and noise is complete."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes VLAN-related data from a bridge structure, validates associated device state, invokes a handler, resets fields, and signals completion or failure.",
            "score": [
                0.0,
                0.0,
                0.3
            ],
            "reason": [
                "The summary describes VLAN-related processing, device state validation, and handler invocation, none of which are present in the source code. The actual function finalizes a stats copy operation, updates length fields, conditionally copies statistics, releases a lock, and returns a status. All claims in the summary are unrelated to the code's semantics, resulting in no accurate matches.",
                "The summary's claims about VLAN-related data, bridge structures, device validation, and handler invocation do not correspond to any behavior in the source code, which handles gnet statistics copying, length adjustment, and spinlock release. The core purpose of finalizing and copying network statistics is not mentioned, and there is no accurate coverage of branches or error conditions. All claims are inaccurate relative to the source.",
                "The summary's claims about processing VLAN-related data, validating device state, invoking a handler, and resetting fields are unrelated to the actual source code, which deals with copying and finalizing generic network statistics from a gnet_dump structure, adjusting lengths, and unlocking a spinlock. These are entirely inaccurate (NOISE) and do not address the primary purpose or any key I/O/side effects, resulting in overwhelming noise and no correct claims."
            ]
        }
    }
}
{
    "source_code": "\nstatic int checkscript(void)\n{\n\tchar *prog[2];\n\tstruct stat s;\n\tint pid, w;\n\n\tif (stat(\"check\", &s) == -1) {\n\t\tif (errno == ENOENT) return 1;\n\t\tbb_perror_msg(WARN\"can't stat %s/check\", *service);\n\t\treturn 0;\n\t}\n\t/* if (!(s.st_mode & S_IXUSR)) return 1; */\n\tprog[0] = (char*)\"./check\";\n\tprog[1] = NULL;\n\tpid = spawn(prog);\n\tif (pid <= 0) {\n\t\tbb_perror_msg(WARN\"can't %s child %s/check\", \"run\", *service);\n\t\treturn 0;\n\t}\n\twhile (safe_waitpid(pid, &w, 0) == -1) {\n\t\tbb_perror_msg(WARN\"can't %s child %s/check\", \"wait for\", *service);\n\t\treturn 0;\n\t}\n\treturn WEXITSTATUS(w) == 0;\n}",
    "comment": "Checks for the existence of the \"check\" script, executes it, and returns true if it exits successfully.",
    "prorec_sum": "Checks for the existence and execution of a \"./check\" program, waits for its child process to finish, and returns success if it exits cleanly.",
    "filter_prorec_sum": "Checks for a \"./check\" file, executes it if present, waits for its child process, and returns success if the child exits cleanly.",
    "prorec_aug_sum": "Checks for the existence of the \"./check\" file, attempts to run and wait for it, and returns success status or logs warnings.",
    "filter_prorec_aug_sum": "Checks if the \"./check\" file exists, executes it as a child process, waits for completion, and returns success status with warnings on failure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Checks for the existence of the \"./check\" file, attempts to run and wait for it, and returns success status or logs warnings.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately captures key behaviors from the source: it notes checking for the './check' file, attempting to run it, waiting for execution to finish, and returning a status while logging warnings on errors. All claims are aligned with the code's logic, with no contradictory or irrelevant statements, indicating a high proportion of accurate claims.",
                "The summary correctly captures the core purpose of the function: checking for the existence of './check', executing it, waiting for completion, and returning success or logging warnings on failure. This aligns with the source code\u2019s logic and covers key secondary behaviors such as error logging, process spawning, and exit status handling. However, it omits certain specifics like the handling of ENOENT to return 1, the distinction between missing file and execution error, and the use of WEXITSTATUS comparison, making coverage decent but not exhaustive.",
                "The summary accurately captures the core behavior: it checks for './check', runs it, waits, and returns a status while logging warnings. All claims are supported by the source code with no contradictions or irrelevant noise. However, the description is generic and lacks detail on specific error handling paths and return values (e.g., distinct return codes for ENOENT vs. other errors, logging specifics on spawn/wait failures), which limits its informational gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Checks if the \"./check\" file exists, executes it as a child process, waits for completion, and returns success status with warnings on failure.",
            "score": [
                0.9,
                0.8,
                0.8
            ],
            "reason": [
                "The summary correctly captures the core behaviors of the function: verifying the existence of './check', spawning it as a child process, waiting for completion, and returning a success indicator while logging warnings on errors. All these claims align with the source code's semantics, with no contradictory or irrelevant statements. The only minor omission is the handling of 'ENOENT' returning 1, but this does not detract significantly from accuracy since the overall behavior is represented faithfully.",
                "The summary correctly states that the function checks if \"./check\" exists, runs it as a child process, waits for it to finish, and returns a success status, all of which match the source code. It also notes warnings on failure, aligning with the bb_perror_msg calls. The core behavior of executing a specific script after existence check is covered, and secondary points such as process waiting and error messages are included. However, it omits details about the ENOENT-specific return value and does not mention exact return semantics for other errors, leaving secondary coverage incomplete.",
                "The summary correctly states that the function checks for the existence of \"./check\", runs it as a child process, waits for its completion, and returns a success status, matching the core logic of the source code. It also captures the warning behavior on failure. There are no inaccurate claims and minimal noise, though the description is somewhat generic and lacks finer details such as the specific handling when the file is missing or process spawning fails. Overall, accuracy is high with moderate informational gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic int ieee80211_scan(struct wiphy *wiphy,\n\t\t\t  struct cfg80211_scan_request *req)\n{\n\tstruct ieee80211_sub_if_data *sdata;\n\n\tsdata = IEEE80211_WDEV_TO_SUB_IF(req->wdev);\n\n\tswitch (ieee80211_vif_type_p2p(&sdata->vif)) {\n\tcase NL80211_IFTYPE_STATION:\n\tcase NL80211_IFTYPE_ADHOC:\n\tcase NL80211_IFTYPE_MESH_POINT:\n\tcase NL80211_IFTYPE_P2P_CLIENT:\n\tcase NL80211_IFTYPE_P2P_DEVICE:\n\t\tbreak;\n\tcase NL80211_IFTYPE_P2P_GO:\n\t\tif (sdata->local->ops->hw_scan)\n\t\t\tbreak;\n\t\t/*\n\t\t * FIXME: implement NoA while scanning in software,\n\t\t * for now fall through to allow scanning only when\n\t\t * beaconing hasn't been configured yet\n\t\t */\n\tcase NL80211_IFTYPE_AP:\n\t\t/*\n\t\t * If the scan has been forced (and the driver supports\n\t\t * forcing), don't care about being beaconing already.\n\t\t * This will create problems to the attached stations (e.g. all\n\t\t * the  frames sent while scanning on other channel will be\n\t\t * lost)\n\t\t */\n\t\tif (sdata->u.ap.beacon &&\n\t\t    (!(wiphy->features & NL80211_FEATURE_AP_SCAN) ||\n\t\t     !(req->flags & NL80211_SCAN_FLAG_AP)))\n\t\t\treturn -EOPNOTSUPP;\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn ieee80211_request_scan(sdata, req);\n}",
    "comment": "Handles scanning requests for various Wi-Fi interface types, ensuring appropriate conditions are met before initiating a scan.",
    "prorec_sum": "Processes a network object based on its type and flags, invoking a routing-related handler when conditions meet specific protocol and state requirements.",
    "filter_prorec_sum": "Processes a network object's state and type to decide whether to forward IPv6 routing information or return an error code.",
    "prorec_aug_sum": "Checks connection state and type codes, then conditionally forwards parameters to a handler or returns an error based on device and session flags.",
    "filter_prorec_aug_sum": "Checks a device or connection state and conditionally forwards parameters to another handler based on mode, flags, and associated structure field values.",
    "work_score": {
        "prorec_aug": {
            "summary": "Checks connection state and type codes, then conditionally forwards parameters to a handler or returns an error based on device and session flags.",
            "score": [
                0.7,
                0.2,
                0.5
            ],
            "reason": [
                "The summary makes very general claims about checking connection state and type codes, and conditionally forwarding parameters or returning an error based on device/session flags. While this loosely matches the switch over interface types, conditional returns, and call to ieee80211_request_scan in the source code, it omits key specifics such as the exact interface types handled, AP beaconing logic, and hw_scan handling. The claims are mostly generic and safe, with limited detail, but still broadly accurate to the function's control flow.",
                "The summary generically mentions checking state and forwarding parameters or returning an error, but it fails to accurately state the core domain purpose of handling an IEEE 802.11 scan request based on interface type and AP beaconing conditions. While it loosely reflects conditional logic and branching, it omits key specifics such as the different interface type cases, support for hardware scanning, and special flags affecting AP scans. Without these, the core semantics are not covered and secondary details are minimal.",
                "The summary contains mostly generic and vague descriptions that don't convey the precise conditional logic from the source code. While it correctly notes that device type and flags influence whether parameters are forwarded or an error is returned, it omits specific type cases, hardware scan checks, beacon conditions, and the final call to ieee80211_request_scan. There are no direct contradictions (no FATAL), but the lack of detail makes the gain low and introduces noise by oversimplifying the semantics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Checks a device or connection state and conditionally forwards parameters to another handler based on mode, flags, and associated structure field values.",
            "score": [
                0.3,
                0.2,
                0.5
            ],
            "reason": [
                "The summary is overly generic and lacks specific fact-based claims tied to the actual source code logic. It vaguely references checking state and forwarding parameters, which is broadly accurate but misses critical, verifiable details such as specific interface types, P2P/ AP handling, and error returns based on beacon configuration and feature flags. This results in a low proportion of accurate, domain-specific claims.",
                "The summary makes a generic statement about checking state and forwarding parameters, which vaguely matches the existence of conditional logic and the final call to another function. However, it fails to mention the core domain-specific purpose of initiating a scan operation for wireless interfaces, the specific interface types handled, and the error conditions like returning EOPNOTSUPP when scanning is unsupported. No accurate claim captures the primary scan action or unique interface-type restrictions, resulting in omission of critical semantics.",
                "The summary provides a generic description of checking state and forwarding parameters, which loosely matches the code\u2019s conditional mode checks and eventual call to another function. However, it omits specific and important details such as the handling of different interface types, restrictions for AP mode with beaconing, and error returns for unsupported types. There are no outright contradictions, but the claim is very high-level and low-information, offering minimal insight into the actual function behavior, so the gain is low while noise is moderate."
            ]
        }
    }
}
{
    "source_code": "void dnotify_flush(struct file *filp, fl_owner_t id)\n{\n\tstruct fsnotify_mark *fsn_mark;\n\tstruct dnotify_mark *dn_mark;\n\tstruct dnotify_struct *dn;\n\tstruct dnotify_struct **prev;\n\tstruct inode *inode;\n\n\tinode = file_inode(filp);\n\tif (!S_ISDIR(inode->i_mode))\n\t\treturn;\n\n\tfsn_mark = fsnotify_find_inode_mark(dnotify_group, inode);\n\tif (!fsn_mark)\n\t\treturn;\n\tdn_mark = container_of(fsn_mark, struct dnotify_mark, fsn_mark);\n\n\tmutex_lock(&dnotify_mark_mutex);\n\n\tspin_lock(&fsn_mark->lock);\n\tprev = &dn_mark->dn;\n\twhile ((dn = *prev) != NULL) {\n\t\tif ((dn->dn_owner == id) && (dn->dn_filp == filp)) {\n\t\t\t*prev = dn->dn_next;\n\t\t\tkmem_cache_free(dnotify_struct_cache, dn);\n\t\t\tdnotify_recalc_inode_mask(fsn_mark);\n\t\t\tbreak;\n\t\t}\n\t\tprev = &dn->dn_next;\n\t}\n\n\tspin_unlock(&fsn_mark->lock);\n\n\t/* nothing else could have found us thanks to the dnotify_mark_mutex */\n\tif (dn_mark->dn == NULL)\n\t\tfsnotify_destroy_mark(fsn_mark, dnotify_group);\n\n\tmutex_unlock(&dnotify_mark_mutex);\n\n\tfsnotify_put_mark(fsn_mark);\n}",
    "comment": "Removes a dnotify structure associated with a file if the owner ID matches, and cleans up the corresponding fsnotify mark if no more notifications exist.",
    "prorec_sum": "Removes a matching entry from an inode-associated list, processes related metadata updates, and finalizes state changes with synchronization.",
    "filter_prorec_sum": "Removes a matching inode entry from an internal list, updates related structures, and finalizes state changes with synchronization locks.",
    "prorec_aug_sum": "Removes a matching entry from a linked list under a spinlock, processes it, updates reference counts, and finalizes state if the list becomes empty.",
    "filter_prorec_aug_sum": "Removes a matching lock entry from a linked list, updates related structures, and finalizes state synchronization for the targeted resource.",
    "work_score": {
        "prorec_aug": {
            "summary": "Removes a matching entry from a linked list under a spinlock, processes it, updates reference counts, and finalizes state if the list becomes empty.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly notes removal of a matching entry from a linked list under a spinlock and finalizing state if the list becomes empty, which matches the source code. However, it inaccurately claims that the function updates reference counts, a behavior not present in the code, and omits details such as the conditional checks for directory inodes and owner/file matching. Since not all claims are accurate, overall alignment is moderate.",
                "The summary captures a generic linked list removal under a lock and finalization if empty but fails to identify the core purpose of the function, which is flushing dnotify marks for a given file and owner in a directory inode using specific fsnotify/dnotify mechanisms. It omits critical domain specifics such as targeting dnotify marks, use of owner/file match criteria, and interaction with fsnotify destroy/recalc calls. Secondary details like the required inode type check and involved locking mechanisms beyond the spinlock are also missing, leaving it incomplete.",
                "The summary captures part of the function\u2019s behavior by noting removal of a matching entry under a spinlock, which aligns with the loop and locking in the source. However, it introduces inaccuracies: it claims updates to reference counts, which are not present, and omits key details such as the conditional inode type check, the involvement of dnotify_mark_mutex, freeing memory via kmem_cache_free, recalculating inode masks, and destroying marks when the list is empty. These omissions reduce informational value, and the inaccurate reference count claim is noise rather than a severe FATAL. The net benefit is low due to sparse accurate detail and notable generic/incorrect content."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Removes a matching lock entry from a linked list, updates related structures, and finalizes state synchronization for the targeted resource.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary provides a vague description of removing a linked list entry and updating structures, which loosely aligns with the function removing a matching dnotify_struct from a list and updating inode masks. However, it omits key specifics such as the function\u2019s checks for directory inodes, the use of synchronization primitives (mutex and spinlock), and the destruction of marks when the list is empty. The term 'lock entry' is inaccurate as the code deals with notification marks rather than lock objects, and \u2018finalizes state synchronization\u2019 is overly generic. More than half of the claims lack precise, domain-specific accuracy.",
                "The summary fails to cover the core primary purpose, which is flushing and removing a dnotify_struct from an inode\u2019s dnotify list for a given file and owner, with proper locking and cleanup. While it vaguely mentions removing a 'lock entry' and updating structures, it does not accurately reflect the specific domain behavior involving dnotify marks, inode checks, fsnotify mark handling, and cleanup operations. The core semantics are absent and only generic actions are described, providing minimal accurate detail tied to the code.",
                "The summary is inaccurate regarding the core purpose of the function. It describes removing a matching lock entry, which contradicts the source code's actual behavior of removing a matching dnotify_struct for a given file and owner from a linked list tied to a directory inode and updating associated fsnotify structures. This is a FATAL error because it misstates the primary domain action. There are no specific GOLD claims, and the misrepresentation of purpose means the content is unusable for understanding the actual function."
            ]
        }
    }
}
{
    "source_code": "\nint x86_pmu_handle_irq(struct pt_regs *regs)\n{\n\tstruct perf_sample_data data;\n\tstruct cpu_hw_events *cpuc;\n\tstruct perf_event *event;\n\tint idx, handled = 0;\n\tu64 val;\n\n\tcpuc = &__get_cpu_var(cpu_hw_events);\n\n\t/*\n\t * Some chipsets need to unmask the LVTPC in a particular spot\n\t * inside the nmi handler.  As a result, the unmasking was pushed\n\t * into all the nmi handlers.\n\t *\n\t * This generic handler doesn't seem to have any issues where the\n\t * unmasking occurs so it was left at the top.\n\t */\n\tapic_write(APIC_LVTPC, APIC_DM_NMI);\n\n\tfor (idx = 0; idx < x86_pmu.num_counters; idx++) {\n\t\tif (!test_bit(idx, cpuc->active_mask)) {\n\t\t\t/*\n\t\t\t * Though we deactivated the counter some cpus\n\t\t\t * might still deliver spurious interrupts still\n\t\t\t * in flight. Catch them:\n\t\t\t */\n\t\t\tif (__test_and_clear_bit(idx, cpuc->running))\n\t\t\t\thandled++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tevent = cpuc->events[idx];\n\n\t\tval = x86_perf_event_update(event);\n\t\tif (val & (1ULL << (x86_pmu.cntval_bits - 1)))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * event overflow\n\t\t */\n\t\thandled++;\n\t\tperf_sample_data_init(&data, 0, event->hw.last_period);\n\n\t\tif (!x86_perf_event_set_period(event))\n\t\t\tcontinue;\n\n\t\tif (perf_event_overflow(event, &data, regs))\n\t\t\tx86_pmu_stop(event, 0);\n\t}\n\n\tif (handled)\n\t\tinc_irq_stat(apic_perf_irqs);\n\n\treturn handled;\n}",
    "comment": "Handles performance monitoring unit interrupts by checking active counters, updating event values, and managing event overflows, while ensuring proper NMI handling.",
    "prorec_sum": "Scans a per-CPU list of memory structures, processes those matching conditions, and increments a global counter for successfully handled entries.",
    "filter_prorec_sum": "Iterates over CPU-associated entries, checks bit flags, processes eligible ones, and increments a global counter for successfully handled entries.",
    "prorec_aug_sum": "Iterates over active CPU entries, checking scheduling constraints and performing runtime updates, then increments a kernel per\u2011CPU counter if qualifying tasks are processed.",
    "filter_prorec_aug_sum": "Iterates over active CPU entries, checks scheduling conditions, and triggers task handling routines while updating a global counter for processed CPUs.",
    "work_score": {
        "prorec_aug": {
            "summary": "Iterates over active CPU entries, checking scheduling constraints and performing runtime updates, then increments a kernel per\u2011CPU counter if qualifying tasks are processed.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function iterates over active CPU entries, checks scheduling constraints, and processes qualifying tasks, which misrepresents the actual behavior. In reality, the function iterates over hardware performance counters, handles spurious interrupts, updates event counters, processes overflows, and increments a per\u2011CPU IRQ statistic. The described 'scheduling constraints' and 'qualifying tasks' do not align with the source code. Most claims are inaccurate, with little correct detail matching the actual semantics.",
                "The summary makes inaccurate claims: it mentions scheduling constraints and qualifying tasks, which do not appear in the source code, and omits the core purpose of handling PMU interrupt overflows for performance counters. The summary fails to cover the core domain operation of iterating over hardware performance counters, updating their state, handling spurious interrupts, setting periods, and stopping events on overflow. No accurate claim addresses the specific PMU IRQ handling behavior, resulting in no alignment with the core or secondary semantics.",
                "The summary contains a core FATAL error: it describes iterating over active CPU entries to check scheduling constraints and process qualifying tasks, which is unrelated to the actual function. The source code shows that the function handles performance monitoring unit (PMU) interrupts, updates performance event counters, and increments a per\u2011CPU IRQ stat when events are processed. The summary omits PMU interrupt handling and incorrectly frames the purpose as task scheduling, conflicting with the primary purpose and key I/O. This fatal mismatch on the WHAT makes the response unusable."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Iterates over active CPU entries, checks scheduling conditions, and triggers task handling routines while updating a global counter for processed CPUs.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about iterating over active CPU entries, checking scheduling conditions, and triggering task handling routines do not align with the source code, which handles x86 performance monitoring unit interrupts, processes hardware events, and updates counters for overflow events. None of the claims accurately describe the function's actual domain\u2011specific behavior, resulting in a lack of ACCURATE statements.",
                "The summary's claims about iterating over active CPU entries, checking scheduling conditions, and triggering task handling routines are inaccurate; the source code processes performance monitoring unit (PMU) interrupt events for hardware counters, not scheduling tasks. It also misrepresents the global counter as tracking processed CPUs instead of APIC performance IRQ occurrences. The core purpose\u2014handling PMU IRQs, updating event counters, managing overflows, and possibly stopping events\u2014is entirely missing, leaving the summary with no accurate coverage of the primary domain-specific behavior.",
                "The summary makes claims about iterating over active CPU entries, checking scheduling conditions, triggering task handling routines, and updating a global counter for processed CPUs, which do not match the actual code. The function iterates over hardware performance counters, processes overflow events, and increments a performance IRQ statistic. These mismatches are severe and directly contradict the core purpose (handling performance counter NMIs), representing a FATAL error on the primary functionality."
            ]
        }
    }
}
{
    "source_code": "int Findjob_set_name_expr(struct FindjoB *o, char *name_expr, int flag)\n{\n char *regexpr= NULL;\n regex_t *name_re;\n struct ExprtesT *t;\n int ret;\n\n regexpr= TSOB_FELD(char, 2*SfileadrL+2);\n if(regexpr == NULL)\n   {ret= -1; goto ex;}\n if(strlen(name_expr)>=SfileadrL)\n   {ret= 0; goto ex;};\n\n ret= Findjob_default_and(o, 0);\n if(ret <= 0)\n   goto ex;\n t= o->cursor->test;\n t->test_type= 1;\n if ((flag & 3) == 1)\n   t->test_type= 13;\n else if((flag & 3) == 2)\n   t->test_type= 16;\n else if((flag & 3) == 3)\n   t->test_type= 20;\n t->arg1= strdup(name_expr);\n if(t->arg1 == NULL)\n   {ret= -1; goto ex;};\n\n if((flag & 3) == 3)\n   {ret= 1; goto ex;}\n\n name_re= (regex_t *) calloc(1, sizeof(regex_t));\n if(name_re == NULL)\n   {ret= -1; goto ex;};\n Xorriso__bourne_to_reg(name_expr, regexpr, 0);\n if(regcomp(name_re, regexpr, 0) != 0) {\n   free((char *) name_re);\n   {ret= 0; goto ex;};\n }\n t->arg2= name_re;\n ret= 1;\nex:;\n Xorriso_free_meM(regexpr);\n return(ret);\n}",
    "comment": "Constructs a regex from a given name expression and updates a job's testing criteria based on a specified flag, returning success status.",
    "prorec_sum": "Compiles a regex from the given pattern string, stores it with associated mode flags in a target structure, and returns success or error status.",
    "filter_prorec_sum": "Compiles a provided pattern string into a regex object, stores it in a structure, and configures matching mode based on the given flag.",
    "prorec_aug_sum": "Compiles a regex from the given pattern string, stores it with configuration flags in a target structure, and returns success or failure.",
    "filter_prorec_aug_sum": "Compiles a provided pattern string into a regex object, stores it with associated mode, and updates the target structure accordingly.",
    "work_score": {
        "prorec_aug": {
            "summary": "Compiles a regex from the given pattern string, stores it with configuration flags in a target structure, and returns success or failure.",
            "score": [
                0.5,
                0.6,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function compiles a regex from the given string and returns success or failure, but it omits important specific behaviors shown in the code, such as allocation checks, handling of different flag values to set test_type, performing a duplicate of the input string, and different return codes (-1, 0, 1) depending on errors and flag conditions. It also mischaracterizes 'configuration flags'\u2014the flags influence test_type rather than regex compilation parameters. While partially accurate, several domain-specific details are missing or slightly misrepresented, making accuracy mixed.",
                "The summary correctly notes compiling a regex from the given pattern and storing it in a target structure with flags, which matches the core purpose of setting up a name-based test with a compiled regex in the source code. However, it omits key secondary behaviors such as allocating and freeing temporary buffers, enforcing a maximum string length (SfileadrL), handling different test_type values based on flag bits, skipping regex compilation for certain flags, and detailed error returns. These omissions result in incomplete coverage of critical semantics beyond the core.",
                "The summary claims the function compiles a regex from the given pattern string, stores it with configuration flags, and returns success or failure. While it is accurate that the function compiles a regex and stores it in a structure when certain conditions are met, it omits critical details on flag interpretation, conditional regex compilation, and the handling of allocation failures. The mention of storing 'configuration flags' is somewhat misleading, as the function sets a test_type value based on flag bits rather than directly storing flags. This is a minor inaccuracy (NOISE) but not a fatal misrepresentation of the primary purpose. The core description is broadly correct but lacks specificity and contains some vague phrasing, resulting in low informational gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Compiles a provided pattern string into a regex object, stores it with associated mode, and updates the target structure accordingly.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function compiles a provided string into a regex object, associates it with a mode determined by the flag, and updates the target structure, which aligns with the source code. However, it omits important conditional flows such as early exits on length checks, memory allocation failures, and the bypass of regex compilation entirely when certain flag values are set. Despite these omissions, the core claims made are accurate and aligned with the code\u2019s semantics, with no incorrect or contradictory statements.",
                "The summary correctly captures the core behavior of compiling a provided pattern into a regex and updating the target structure with mode information, matching the main semantic of the function. However, it omits important secondary details from the source such as validation of input length, allocation and freeing of temporary buffers, handling of multiple test_type values based on flag bits, conditional early return without regex compilation when flag&3==3, and error handling with return codes (-1, 0, 1). Coverage of these control flows and edge cases is lacking, resulting in only partial completeness.",
                "The summary correctly notes that the function compiles a pattern string into a regex object, stores it, and updates a structure with a mode. These details align with the source code\u2019s use of regcomp, storing the regex in t->arg2, and setting test_type based on the flag. However, the description is very high-level and omits important behaviors such as input validation, memory allocation failures, control flow for different flags, and early return when flag==3. There are no inaccurate claims, but the gain is low due to the generic phrasing and missing specifics."
            ]
        }
    }
}
{
    "source_code": "\nstatic void tg3_phy_toggle_apd(struct tg3 *tp, bool enable)\n{\n\tu32 reg;\n\n\tif (!tg3_flag(tp, 5705_PLUS) ||\n\t    (tg3_flag(tp, 5717_PLUS) &&\n\t     (tp->phy_flags & TG3_PHYFLG_MII_SERDES)))\n\t\treturn;\n\n\tif (tp->phy_flags & TG3_PHYFLG_IS_FET) {\n\t\ttg3_phy_fet_toggle_apd(tp, enable);\n\t\treturn;\n\t}\n\n\treg = MII_TG3_MISC_SHDW_WREN |\n\t      MII_TG3_MISC_SHDW_SCR5_SEL |\n\t      MII_TG3_MISC_SHDW_SCR5_LPED |\n\t      MII_TG3_MISC_SHDW_SCR5_DLPTLM |\n\t      MII_TG3_MISC_SHDW_SCR5_SDTL |\n\t      MII_TG3_MISC_SHDW_SCR5_C125OE;\n\tif (tg3_asic_rev(tp) != ASIC_REV_5784 || !enable)\n\t\treg |= MII_TG3_MISC_SHDW_SCR5_DLLAPD;\n\n\ttg3_writephy(tp, MII_TG3_MISC_SHDW, reg);\n\n\n\treg = MII_TG3_MISC_SHDW_WREN |\n\t      MII_TG3_MISC_SHDW_APD_SEL |\n\t      MII_TG3_MISC_SHDW_APD_WKTM_84MS;\n\tif (enable)\n\t\treg |= MII_TG3_MISC_SHDW_APD_ENABLE;\n\n\ttg3_writephy(tp, MII_TG3_MISC_SHDW, reg);\n}",
    "comment": "Toggles the APD feature of a PHY interface based on device flags and configurations, writing appropriate values to the hardware registers.",
    "prorec_sum": "Updates specific ATA port register fields to control flags and values based on device status and the provided command parameter.",
    "filter_prorec_sum": "Updates specific SATA PHY control registers to enable or disable features based on device flags and input, ensuring proper link configuration.",
    "prorec_aug_sum": "Updates specific PHY/MAC register fields based on status flags and input parameter to control link or media configuration on a network adapter.",
    "filter_prorec_aug_sum": "Updates specific PHY register bits based on link and management flags to control hardware behavior according to the given enable or disable parameter.",
    "work_score": {
        "prorec_aug": {
            "summary": "Updates specific PHY/MAC register fields based on status flags and input parameter to control link or media configuration on a network adapter.",
            "score": [
                0.5,
                0.3,
                0.5
            ],
            "reason": [
                "The summary claims the function updates specific PHY/MAC register fields to control link or media configuration. While it is true that the code writes to PHY registers based on flags and an input parameter, there is no evidence of MAC register updates, nor explicit link or media configuration control in the source. The actual behavior is toggling auto power down (APD) or related PHY settings. The claim is partially accurate (register writes based on flags and a parameter), but introduces incorrect elements, lowering overall accuracy.",
                "The summary correctly notes that the function updates PHY register fields based on flags and an input parameter, which is generally accurate. However, it fails to capture the core specific purpose \u2014 toggling Auto Power Down (APD) for the PHY depending on hardware revision and flags \u2014 and instead gives a vague reference to controlling link/media configuration. No mention is made of the APD-specific register constants, conditional hardware paths, or special handling for FET PHY, missing key secondary details such as early returns for certain revisions or PHY types.",
                "The summary makes a generic claim about updating PHY/MAC register fields to control link or media configuration, which loosely aligns with the code's behavior. However, it lacks specificity about the actual conditions checked (e.g., tg3_flag variants, PHYFLG types), the ASIC revision logic, and the exact register bit operations for toggling APD. The claim is SAFE but low-information, with minimal insight from the source code while avoiding outright inaccuracies. The worst failure mode is NOISE due to overly broad wording."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Updates specific PHY register bits based on link and management flags to control hardware behavior according to the given enable or disable parameter.",
            "score": [
                0.5,
                0.5,
                0.6
            ],
            "reason": [
                "The summary claims that the function updates specific PHY register bits based on link and management flags to control hardware behavior according to an enable/disable parameter. While it correctly notes that the function updates PHY register bits and uses the enable parameter to influence hardware behavior, it inaccurately generalizes the conditional logic as being based on 'link and management flags'. The source code actually uses specific tg3 flags, PHY flags, and ASIC revision checks, not general link flags. This mismatch reduces precision and makes the description partially inaccurate.",
                "The summary makes a generally accurate claim about updating PHY register bits based on flags and the enable parameter, which aligns with the function's core operation of toggling auto power down behavior for certain Broadcom PHYs. However, it does not clearly convey the specific domain purpose (controlling auto power down via shadow registers for supported PHY types) and omits key details such as early returns for certain hardware flags, special handling for FET PHY, ASIC revision checks, and the use of specific shadow register constants. Coverage of secondary semantics is weak.",
                "The summary makes a generic claim about updating PHY register bits based on link and management flags to control hardware behavior depending on enable/disable. While this is loosely aligned with the function\u2019s actual purpose, it is vague and omits key specifics: the early exit conditions tied to tg3_flag checks, special handling for FET PHY via a separate function, and the exact register constants used. There are no factual contradictions, but the statement is low\u2011info, offering only a broad SAFE claim without detailing domain\u2011specific semantics. Noise is minimal, and there is no FATAL error, but the positive gain is low."
            ]
        }
    }
}
{
    "source_code": "\nstatic void calc_mode_timings(int xres, int yres, int refresh,\n\t\t\t      struct fb_videomode *mode)\n{\n\tstruct fb_var_screeninfo *var;\n\n\tvar = kzalloc(sizeof(struct fb_var_screeninfo), GFP_KERNEL);\n\n\tif (var) {\n\t\tvar->xres = xres;\n\t\tvar->yres = yres;\n\t\tfb_get_mode(FB_VSYNCTIMINGS | FB_IGNOREMON,\n\t\t\t    refresh, var, NULL);\n\t\tmode->xres = xres;\n\t\tmode->yres = yres;\n\t\tmode->pixclock = var->pixclock;\n\t\tmode->refresh = refresh;\n\t\tmode->left_margin = var->left_margin;\n\t\tmode->right_margin = var->right_margin;\n\t\tmode->upper_margin = var->upper_margin;\n\t\tmode->lower_margin = var->lower_margin;\n\t\tmode->hsync_len = var->hsync_len;\n\t\tmode->vsync_len = var->vsync_len;\n\t\tmode->vmode = 0;\n\t\tmode->sync = 0;\n\t\tkfree(var);\n\t}\n}",
    "comment": "Calculates video mode timings based on resolution and refresh rate, populating the provided fb_videomode structure with these settings.",
    "prorec_sum": "Allocates and initializes a PCI bus-related data structure with provided parameters, updates the target structure fields, and finalizes the allocation.",
    "filter_prorec_sum": "Allocates and initializes a 160-byte structure with provided parameters, updates target memory fields, then finalizes and releases the allocated structure.",
    "prorec_aug_sum": "Allocates and initializes a 160-byte structure with provided parameters, updates related memory fields, and finalizes by releasing the allocated structure.",
    "filter_prorec_aug_sum": "Allocates and initializes a 160-byte structure with provided parameters, updates related fields in a target buffer, then releases the allocated structure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and initializes a 160-byte structure with provided parameters, updates related memory fields, and finalizes by releasing the allocated structure.",
            "score": [
                0.5,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function allocates a structure, initializes it with provided parameters, and frees it at the end, which matches the code's use of kzalloc, field assignments from arguments, and kfree. However, it inaccurately specifies the structure size as 160 bytes, which is not evident in the code, and uses vague language like 'updates related memory fields' instead of describing that it transfers fb_var_screeninfo values into the fb_videomode structure. This mix of accurate and imprecise claims results in roughly half to two-thirds accuracy.",
                "The summary notes allocation and freeing of a structure and populating fields, which aligns generically with the source code. However, it inaccurately specifies a hardcoded size of 160 bytes (not stated in code) and omits the core purpose: computing and filling framebuffer video mode timing parameters via fb_get_mode using provided resolution and refresh values. No mention is made of key domain-specific behavior such as use of fb_get_mode, copying of timing fields, or constants passed, so the core is not covered and secondary details are minimal.",
                "The summary contains a specific but incorrect claim that the function allocates a 160-byte structure, which is not stated or guaranteed in the source code and therefore contradicts its semantics. While it notes allocation, initialization with parameters, and freeing of the structure\u2014broadly matching the code\u2014it omits essential domain-specific details such as setting mode timings via fb_get_mode and exact fields updated. The worst failure mode is a FATAL error concerning the core allocation details, making the description unreliable for understanding the function\u2019s primary purpose."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates and initializes a 160-byte structure with provided parameters, updates related fields in a target buffer, then releases the allocated structure.",
            "score": [
                0.6,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains both accurate and inaccurate elements. It correctly states that a structure is allocated, initialized using provided parameters, updated in a target buffer (the mode struct), and freed. However, it inaccurately specifies the structure size as 160 bytes, which is not evident from the source code and could vary depending on platform and struct definition. Because this size detail is a factual claim about the code and is likely incorrect or unverifiable from the given snippet, the proportion of accurate claims falls into the mixed reliability range.",
                "The summary incorrectly specifies the allocated structure size as 160 bytes, which is not stated in the code and may not be correct for struct fb_var_screeninfo, making this claim inaccurate. While it correctly notes allocation, initialization with given parameters, updating fields in the target 'mode' structure, and freeing memory, it fails to mention the core purpose: calculating and populating framebuffer video mode timing parameters from resolution and refresh using fb_get_mode. Secondary semantics such as use of specific members, constants (FB_VSYNCTIMINGS | FB_IGNOREMON), and conditionally executing if allocation succeeds are missing.",
                "The summary claims a fixed 160-byte allocation size, which is inaccurate and contradicts the source code since the actual size of 'struct fb_var_screeninfo' is not given and could differ. While it correctly states allocation, initialization using provided parameters, updating fields in a target buffer, and releasing the allocated structure, the hardcoded size is a severe factual error directly related to the function's core memory operation, making this a FATAL issue."
            ]
        }
    }
}
{
    "source_code": "int img_collect_inos(IsoImage *image, IsoDir *dir, int flag)\n{\n    int ret, register_dir = 1;\n    IsoDirIter *iter = NULL;\n    IsoNode *node;\n    IsoDir *subdir;\n\n    if (dir == NULL)\n        dir = image->root;\n    if (image->used_inodes == NULL) {\n        image->used_inodes = calloc(ISO_USED_INODE_RANGE / 8, 1);\n        if (image->used_inodes == NULL)\n            return ISO_OUT_OF_MEM;\n    } else if(!(flag & 1)) {\n        memset(image->used_inodes, 0, ISO_USED_INODE_RANGE / 8);\n    } else {\n        register_dir = 0;\n    }\n    if (register_dir) {\n        node = (IsoNode *) dir;\n        ret = img_register_ino(image, node, 0);\n        if (ret < 0)\n            return ret;\n    }\n\n    ret = iso_dir_get_children(dir, &iter);\n    if (ret < 0)\n        return ret;\n    while (iso_dir_iter_next(iter, &node) == 1 ) {\n        ret = img_register_ino(image, node, 0);\n        if (ret < 0)\n            goto ex;\n        if (iso_node_get_type(node) == LIBISO_DIR) {\n            subdir = (IsoDir *) node;\n            ret = img_collect_inos(image, subdir, flag | 1);\n            if (ret < 0)\n                goto ex;\n        }\n    }\n    ret = 1;\nex:;\n    if (iter != NULL)\n        iso_dir_iter_free(iter);\n    return ret;\n}",
    "comment": "Registers inodes for an ISO image and its subdirectories, initializing used inode tracking if necessary.",
    "prorec_sum": "Recursively processes ISO9660 directory entries, allocating and resetting buffers, and traversing subdirectories while invoking helper routines for each entry.",
    "filter_prorec_sum": "Recursively processes ISO9660 directory entries, allocating and clearing buffers as needed, and traverses subdirectories while invoking directory entry handling routines.",
    "prorec_aug_sum": "Initializes a 32\u202fKB buffer in the image structure and recursively processes file or directory entries while preserving existing data when requested.",
    "filter_prorec_aug_sum": "Recursively processes ISO9660 directory entries, allocating or clearing a buffer, and invoking handlers for each subentry while tracking operation results.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes a 32\u202fKB buffer in the image structure and recursively processes file or directory entries while preserving existing data when requested.",
            "score": [
                0.5,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims a 32\u202fKB buffer is initialized, but the source code actually allocates ISO_USED_INODE_RANGE/8 bytes (size unspecified in the summary), making this detail inaccurate. It correctly notes recursive processing of directory entries, but the 'file entries' part is less precise as the code only handles directories and inodes. Preserving existing data when requested is accurate, corresponding to the flag logic that prevents memset. With one claim clearly wrong and others mostly correct, accuracy is around half.",
                "The summary partially aligns with the code but misses the core purpose: registering inodes from a directory structure into the image's used_inodes set by traversing recursively using img_register_ino. The claim about initializing a 32\u202fKB buffer is inaccurate \u2014 the allocated size is ISO_USED_INODE_RANGE/8 (not stated as 32\u202fKB in code). It also omits key semantics such as optional clearing of existing data, conditional registration of the starting directory, detailed recursion into subdirectories, and error handling. Although recursion over file/directory entries is mentioned, the fundamental task (collecting and registering inode usage) is not explicitly covered.",
                "The summary incorrectly states that a 32\u202fKB buffer is initialized; the code actually allocates ISO_USED_INODE_RANGE/8 bytes, whose value is not shown but is domain-specific and not explicitly 32\u202fKB. It also inaccurately characterizes the processing as handling both file and directory entries, whereas the code specifically iterates directory children and registers inode numbers, recursively descending into subdirectories. While it correctly notes that existing data may be preserved depending on a flag, the buffer size error is a FATAL issue affecting a key implementation detail (primary purpose related to allocation). This severe inaccuracy on a core detail, combined with the generic rest of the summary, gives little usable value."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Recursively processes ISO9660 directory entries, allocating or clearing a buffer, and invoking handlers for each subentry while tracking operation results.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary captures some accurate aspects of the function, such as recursively processing directory entries and handling a buffer allocation or clearing. However, it omits important specifics like the inode registration, conditional handling based on the flag, and exact iteration mechanisms, and uses vague phrasing like 'invoking handlers' that does not directly match the code. While most claims broadly align with the function's purpose, the lack of precise correspondence to explicit source code behaviors reduces accuracy.",
                "The summary captures the recursive processing of ISO9660 directory entries and mentions buffer allocation/clearing, which aligns with the code's creation or reset of the used_inodes array. However, it omits the core purpose of registering inodes for each directory and file, which is the primary domain-specific action in the function. Secondary behaviors such as error handling, conditional registration of the starting directory, iteration over children, and freeing the iterator are either absent or too vaguely described (e.g., 'invoking handlers' is not specific enough to describe inode registration).",
                "The summary contains mostly accurate but generic claims: it correctly notes that the function recursively processes directory entries and allocates or clears a buffer. It also mentions invoking handlers for each subentry, which loosely corresponds to img_register_ino, though the term 'handlers' is vague. It omits key specifics such as the tracking of used inode numbers and the flag logic controlling clearing vs preserving the inode buffer. No claims are outright false (no FATAL), but the information gain is low due to vague and underspecified language, with minor noise from imprecise 'handlers' phrasing."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nxmlFARegExecSaveInputString(xmlRegExecCtxtPtr exec, const xmlChar *value,\n\t                    void *data) {\n#ifdef DEBUG_PUSH\n    printf(\"saving value: %d:%s\\n\", exec->inputStackNr, value);\n#endif\n    if (exec->inputStackMax == 0) {\n\texec->inputStackMax = 4;\n\texec->inputStack = (xmlRegInputTokenPtr)\n\t    xmlMalloc(exec->inputStackMax * sizeof(xmlRegInputToken));\n\tif (exec->inputStack == NULL) {\n\t    xmlRegexpErrMemory(NULL, \"pushing input string\");\n\t    exec->inputStackMax = 0;\n\t    return;\n\t}\n    } else if (exec->inputStackNr + 1 >= exec->inputStackMax) {\n\txmlRegInputTokenPtr tmp;\n\n\texec->inputStackMax *= 2;\n\ttmp = (xmlRegInputTokenPtr) xmlRealloc(exec->inputStack,\n\t\t\texec->inputStackMax * sizeof(xmlRegInputToken));\n\tif (tmp == NULL) {\n\t    xmlRegexpErrMemory(NULL, \"pushing input string\");\n\t    exec->inputStackMax /= 2;\n\t    return;\n\t}\n\texec->inputStack = tmp;\n    }\n    exec->inputStack[exec->inputStackNr].value = xmlStrdup(value);\n    exec->inputStack[exec->inputStackNr].data = data;\n    exec->inputStackNr++;\n    exec->inputStack[exec->inputStackNr].value = NULL;\n    exec->inputStack[exec->inputStackNr].data = NULL;\n}",
    "comment": "Stores an input string and associated data in a dynamically expanding stack within the xmlRegExecCtxt structure.",
    "prorec_sum": "Adds a duplicated XML string and associated data to a dynamically resized array stored in the given context structure.",
    "filter_prorec_sum": "Adds a duplicated XML string and associated data to a dynamically resized array within the given structure.",
    "prorec_aug_sum": "Adds a duplicated XML string and associated metadata to a dynamically resized array within the parser context structure.",
    "filter_prorec_aug_sum": "Adds a duplicated XML string and associated data into a dynamically resized array within the given structure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Adds a duplicated XML string and associated metadata to a dynamically resized array within the parser context structure.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately states that the function duplicates an XML string (`xmlStrdup(value)`) and stores it with associated data in a dynamically resized array (`inputStack`) within the execution context structure (`exec`). These behaviors directly match the code, with no incorrect or irrelevant claims present, making all extracted claims correct and domain-relevant.",
                "The summary correctly states the core functionality of adding a duplicated XML string and its associated metadata to a dynamically resized array in the parser/execution context, which matches the function's purpose. However, it omits secondary but relevant implementation details from the code, such as the initial allocation with size 4, doubling logic on resize, explicit NULL assignments after insertion, and handling of memory allocation failures with appropriate error reporting.",
                "The summary correctly identifies that the function duplicates an XML string and stores it along with associated metadata into a dynamically resized array in the parser's execution context. This matches the source code's use of xmlStrdup for the string, data assignment, and the dynamic allocation logic adjusting inputStackMax and reallocating. There is no inaccurate or noisy content; the statement is concise and reflects the core behavior with high specificity, providing clear insight into the function's primary purpose and mechanism."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Adds a duplicated XML string and associated data into a dynamically resized array within the given structure.",
            "score": [
                0.9,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly describes the core behavior: the function duplicates an XML string, associates it with a data pointer, and stores it in a dynamically resized array within the provided context structure. There are no inaccurate claims; it omits minor details like initial allocation size or error handling, but these are non-critical for correctness. This leads to high alignment with the source code semantics.",
                "The summary accurately captures the core purpose of the function, which is to duplicate the provided XML string and associate data, storing them in a dynamically resized array within the execution context structure. This matches the source\u2019s main behavior of managing an input stack with possible allocation or reallocation. However, it omits secondary details such as debug printing under a compile-time flag, error handling when memory allocation fails, initialization when the stack is empty, and setting NULL terminators after insertion. These missing points reduce completeness despite the correct core coverage.",
                "The summary correctly captures the primary purpose of the function: it duplicates the provided XML string, associates it with a data pointer, and stores both in a dynamically resized array within the exec structure's input stack. These are accurate and specific core behavioral details from the source code with no inaccuracies or irrelevant noise, yielding high informational value."
            ]
        }
    }
}
{
    "source_code": "static void statPush(\n  sqlite3_context *context,\n  int argc,\n  sqlite3_value **argv\n){\n  int i;\n\n  /* The three function arguments */\n  Stat4Accum *p = (Stat4Accum*)sqlite3_value_blob(argv[0]);\n  int iChng = sqlite3_value_int(argv[1]);\n\n  UNUSED_PARAMETER( argc );\n  UNUSED_PARAMETER( context );\n  assert( p->nCol>0 );\n  assert( iChng<p->nCol );\n\n  if( p->nRow==0 ){\n    /* This is the first call to this function. Do initialization. */\n    for(i=0; i<p->nCol; i++) p->current.anEq[i] = 1;\n  }else{\n    /* Second and subsequent calls get processed here */\n    samplePushPrevious(p, iChng);\n\n    /* Update anDLt[], anLt[] and anEq[] to reflect the values that apply\n    ** to the current row of the index. */\n    for(i=0; i<iChng; i++){\n      p->current.anEq[i]++;\n    }\n    for(i=iChng; i<p->nCol; i++){\n      p->current.anDLt[i]++;\n#ifdef SQLITE_ENABLE_STAT3_OR_STAT4\n      p->current.anLt[i] += p->current.anEq[i];\n#endif\n      p->current.anEq[i] = 1;\n    }\n  }\n  p->nRow++;\n#ifdef SQLITE_ENABLE_STAT3_OR_STAT4\n  if( sqlite3_value_type(argv[2])==SQLITE_INTEGER ){\n    sampleSetRowidInt64(p->db, &p->current, sqlite3_value_int64(argv[2]));\n  }else{\n    sampleSetRowid(p->db, &p->current, sqlite3_value_bytes(argv[2]),\n                                       sqlite3_value_blob(argv[2]));\n  }\n  p->current.iHash = p->iPrn = p->iPrn*1103515245 + 12345;\n#endif\n\n#ifdef SQLITE_ENABLE_STAT4\n  {\n    tRowcnt nLt = p->current.anLt[p->nCol-1];\n\n    /* Check if this is to be a periodic sample. If so, add it. */\n    if( (nLt/p->nPSample)!=(nLt+1)/p->nPSample ){\n      p->current.isPSample = 1;\n      p->current.iCol = 0;\n      sampleInsert(p, &p->current, p->nCol-1);\n      p->current.isPSample = 0;\n    }\n\n    /* Update the aBest[] array. */\n    for(i=0; i<(p->nCol-1); i++){\n      p->current.iCol = i;\n      if( i>=iChng || sampleIsBetterPost(p, &p->current, &p->aBest[i]) ){\n        sampleCopy(p, &p->aBest[i], &p->current);\n      }\n    }\n  }\n#endif\n}",
    "comment": "Processes statistical data by updating counts and tracking samples based on input changes and row identifiers within a given dataset structure.",
    "prorec_sum": "Updates cache entry counters and flags based on provided index, initializing entries when empty and incrementing relevant ranges before returning the final index.",
    "filter_prorec_sum": "Updates indexed counters and flags within a cache entry structure based on lookup results, incrementing tracking fields and marking relevant positions as active.",
    "prorec_aug_sum": "Updates counters and flags in a list-like structure based on an index from input parameters, then increments the structure\u2019s primary operation count.",
    "filter_prorec_aug_sum": "Updates counters and flags in a data structure based on an input index, initializing entries if empty and incrementing usage tracking fields.",
    "work_score": {
        "prorec_aug": {
            "summary": "Updates counters and flags in a list-like structure based on an index from input parameters, then increments the structure\u2019s primary operation count.",
            "score": [
                0.5,
                0.3,
                0.5
            ],
            "reason": [
                "The summary vaguely describes updating counters and flags based on an index from input and incrementing a primary count, which partially aligns with the function's behavior of modifying anEq, anDLt, and possibly flags like isPSample. However, it omits important specifics such as initialization on first call, conditional branches, sampling logic, and handling of the third argument for row IDs. Only part of the described behavior matches the actual code, resulting in mixed accuracy with significant omissions.",
                "The summary gives a vague description of updating counters and flags in a structure and incrementing a primary count, which loosely matches the function\u2019s updating of anEq/anDLt/anLt arrays and nRow. However, it omits the specific core purpose of processing and recording statistical sample data for SQLite's STAT4 analysis, including first-call initialization, periodic sampling, updating best samples, and handling rowid input. The domain-specific semantics and key secondary behaviors like conditional STAT3/STAT4 branches, sample insertion, and comparison updates are entirely missing.",
                "The summary captures very generally that the function updates counters and a flag-like attribute based on an index from the input and increments a count. This loosely matches the code\u2019s iteration over columns, modifying arrays like anEq, anDLt, and setting flags like isPSample in certain conditions, and incrementing nRow. However, it omits most key details, including initialization behavior on the first call, the role of samplePushPrevious, conditional compilation blocks affecting behavior under STAT3/STAT4, and the specific periodic sampling and aBest array updates. While there are no explicit inaccuracies, the description is highly generic (SAFE) with low informational gain and much important behavior omitted, limiting its utility."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Updates counters and flags in a data structure based on an input index, initializing entries if empty and incrementing usage tracking fields.",
            "score": [
                0.5,
                0.3,
                0.5
            ],
            "reason": [
                "The summary captures the general essence of updating counters and flags based on an input index and includes initialization when empty, which aligns with the observed logic of initializing anEq[] and incrementing counters depending on iChng. However, it omits significant specific behaviors in the code, such as calls to samplePushPrevious, conditional updates under SQLITE_ENABLE_STAT3_OR_STAT4, handling of rowid values, hash updates, periodic sampling logic, and updates to aBest[]. These omissions reduce the specificity and completeness of the fact-based claims, making the alignment only partial.",
                "The summary describes generic counter and flag updates with initialization, which partially aligns with the code\u2019s behavior but omits the core primary purpose: managing and processing statistical samples for SQLite\u2019s STAT4 accumulation, including pushing previous samples, updating anDLt/anLt/anEq, handling rowid data, periodic sampling, and maintaining aBest[] entries. While the description of initialization and incrementing counters is accurate in a general sense, it lacks the necessary specificity and ignores most key secondary behaviors such as conditional compilation branches, sampling logic, and rowid handling.",
                "The summary contains one accurate but generic claim about updating counters and flags and initializing entries, which matches the code\u2019s role in incrementing and resetting anEq/anDLt arrays and initializing them on first call. However, it omits most of the specific and important behaviors in the function, such as handling periodic samples, updating aBest array, handling rowid via sampleSetRowid*, and distinguishing between first and subsequent calls with different processing. There are no false claims (no FATAL), but the lack of specificity means the gain is low and noise is minimal but the information is non-detailed."
            ]
        }
    }
}
{
    "source_code": "\nstatic u32\nacpi_ex_convert_to_ascii(u64 integer, u16 base, u8 *string, u8 data_width)\n{\n\tu64 digit;\n\tu32 i;\n\tu32 j;\n\tu32 k = 0;\n\tu32 hex_length;\n\tu32 decimal_length;\n\tu32 remainder;\n\tu8 supress_zeros;\n\n\tACPI_FUNCTION_ENTRY();\n\n\tswitch (base) {\n\tcase 10:\n\n\t\t/* Setup max length for the decimal number */\n\n\t\tswitch (data_width) {\n\t\tcase 1:\n\t\t\tdecimal_length = ACPI_MAX8_DECIMAL_DIGITS;\n\t\t\tbreak;\n\n\t\tcase 4:\n\t\t\tdecimal_length = ACPI_MAX32_DECIMAL_DIGITS;\n\t\t\tbreak;\n\n\t\tcase 8:\n\t\tdefault:\n\t\t\tdecimal_length = ACPI_MAX64_DECIMAL_DIGITS;\n\t\t\tbreak;\n\t\t}\n\n\t\tsupress_zeros = TRUE;\t/* No leading zeros */\n\t\tremainder = 0;\n\n\t\tfor (i = decimal_length; i > 0; i--) {\n\n\t\t\t/* Divide by nth factor of 10 */\n\n\t\t\tdigit = integer;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t(void)acpi_ut_short_divide(digit, 10, &digit,\n\t\t\t\t\t\t\t   &remainder);\n\t\t\t}\n\n\t\t\t/* Handle leading zeros */\n\n\t\t\tif (remainder != 0) {\n\t\t\t\tsupress_zeros = FALSE;\n\t\t\t}\n\n\t\t\tif (!supress_zeros) {\n\t\t\t\tstring[k] = (u8) (ACPI_ASCII_ZERO + remainder);\n\t\t\t\tk++;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase 16:\n\n\t\t/* hex_length: 2 ascii hex chars per data byte */\n\n\t\thex_length = ACPI_MUL_2(data_width);\n\t\tfor (i = 0, j = (hex_length - 1); i < hex_length; i++, j--) {\n\n\t\t\t/* Get one hex digit, most significant digits first */\n\n\t\t\tstring[k] =\n\t\t\t    (u8) acpi_ut_hex_to_ascii_char(integer,\n\t\t\t\t\t\t\t   ACPI_MUL_4(j));\n\t\t\tk++;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn (0);\n\t}\n\n\t/*\n\t * Since leading zeros are suppressed, we must check for the case where\n\t * the integer equals 0\n\t *\n\t * Finally, null terminate the string and return the length\n\t */\n\tif (!k) {\n\t\tstring[0] = ACPI_ASCII_ZERO;\n\t\tk = 1;\n\t}\n\n\tstring[k] = 0;\n\treturn ((u32) k);\n}",
    "comment": "Converts a given integer to its ASCII representation in either decimal or hexadecimal format based on specified parameters and returns the string length.",
    "prorec_sum": "Formats numeric data from the given source into a string buffer as decimal or hexadecimal based on input parameters and returns its length.",
    "filter_prorec_sum": "Generates a numeric string representation from input data, formatting either decimal digits or extracted bytes based on specified type and length parameters.",
    "prorec_aug_sum": "Converts an ACPI object\u2019s numeric data into a null\u2011terminated decimal or hexadecimal string representation based on the specified type and length.",
    "filter_prorec_aug_sum": "Formats data from a given source into a hexadecimal or decimal string representation based on input parameters and stores it in the output buffer.",
    "work_score": {
        "prorec_aug": {
            "summary": "Converts an ACPI object\u2019s numeric data into a null\u2011terminated decimal or hexadecimal string representation based on the specified type and length.",
            "score": [
                0.8,
                0.4,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function converts numeric data into a null\u2011terminated decimal or hexadecimal string and that the representation depends on the specified type (base) and length (data_width), both of which are directly reflected in the code. While it inaccurately refers to the input as an ACPI object rather than a raw integer value, the majority of the claim aligns well with the function's behavior, making it mostly accurate.",
                "The summary correctly captures the core operation: converting a numeric value to a null\u2011terminated decimal or hexadecimal string based on the specified length/base, which aligns with the function\u2019s primary purpose. However, it omits several secondary, behavior\u2011critical details present in the code, such as the handling of leading zeros suppression, special case for zero values, specific digit calculation loops, base restrictions (only 10 or 16 are supported), and return value semantics. Coverage of secondary points is weak despite core accuracy.",
                "The summary correctly captures the primary functionality of the function, which is converting numeric data into either decimal or hexadecimal ASCII string form with null termination based on the specified base and data width. It omits some implementation specifics (e.g., suppression of leading zeros in decimal, handling of zero case, restriction to base 10 or 16), but there are no contradictory or irrelevant claims, so there is no FATAL or overwhelming NOISE. The gain is moderate with a clear representation of the core behavior but lacking detailed GOLD-level specifics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Formats data from a given source into a hexadecimal or decimal string representation based on input parameters and stores it in the output buffer.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function formats numeric data into either hexadecimal or decimal string representations based on input parameters and writes it to the output buffer, which aligns with the code\u2019s behavior. It omits some specifics such as suppression of leading zeros in decimal mode and handling of zero values, but no claim contradicts the source code. All claims are accurate, though they are generic and low-detail.",
                "The summary correctly states that the function formats an input value into hexadecimal or decimal string form and writes it to the output buffer, which aligns with the core purpose of converting an integer to its ASCII representation in base 10 or 16. However, it omits notable secondary specifics such as suppression of leading zeros in decimal mode, handling data width to determine max length, null-terminating the string, returning its length, and special handling when the integer is zero. These omissions reduce coverage of critical behavior beyond the core purpose.",
                "The summary correctly states that the function formats data into hexadecimal or decimal strings depending on the input parameters and stores the result in the provided buffer, which matches the core functionality in the source code. However, it omits key specific details: the base is chosen from exactly 10 or 16, it processes integers with suppression of leading zeros in decimal form, treats zero specially, and returns the string length. There is no inaccurate or contradictory claim, but the description is generic and low\u2011info, offering minimal insight beyond the primary purpose."
            ]
        }
    }
}
{
    "source_code": "static void renameTriggerFunc(\n  sqlite3_context *context,\n  int NotUsed,\n  sqlite3_value **argv\n){\n  unsigned char const *zSql = sqlite3_value_text(argv[0]);\n  unsigned char const *zTableName = sqlite3_value_text(argv[1]);\n\n  int token;\n  Token tname;\n  int dist = 3;\n  unsigned char const *zCsr = zSql;\n  int len = 0;\n  char *zRet;\n  sqlite3 *db = sqlite3_context_db_handle(context);\n\n  UNUSED_PARAMETER(NotUsed);\n\n  /* The principle used to locate the table name in the CREATE TRIGGER \n  ** statement is that the table name is the first token that is immediately\n  ** preceded by either TK_ON or TK_DOT and immediately followed by one\n  ** of TK_WHEN, TK_BEGIN or TK_FOR.\n  */\n  if( zSql ){\n    do {\n\n      if( !*zCsr ){\n        /* Ran out of input before finding the table name. Return NULL. */\n        return;\n      }\n\n      /* Store the token that zCsr points to in tname. */\n      tname.z = (char*)zCsr;\n      tname.n = len;\n\n      /* Advance zCsr to the next token. Store that token type in 'token',\n      ** and its length in 'len' (to be used next iteration of this loop).\n      */\n      do {\n        zCsr += len;\n        len = sqlite3GetToken(zCsr, &token);\n      }while( token==TK_SPACE );\n      assert( len>0 );\n\n      /* Variable 'dist' stores the number of tokens read since the most\n      ** recent TK_DOT or TK_ON. This means that when a WHEN, FOR or BEGIN \n      ** token is read and 'dist' equals 2, the condition stated above\n      ** to be met.\n      **\n      ** Note that ON cannot be a database, table or column name, so\n      ** there is no need to worry about syntax like \n      ** \"CREATE TRIGGER ... ON ON.ON BEGIN ...\" etc.\n      */\n      dist++;\n      if( token==TK_DOT || token==TK_ON ){\n        dist = 0;\n      }\n    } while( dist!=2 || (token!=TK_WHEN && token!=TK_FOR && token!=TK_BEGIN) );\n\n    /* Variable tname now contains the token that is the old table-name\n    ** in the CREATE TRIGGER statement.\n    */\n    zRet = sqlite3MPrintf(db, \"%.*s\\\"%w\\\"%s\", (int)(((u8*)tname.z) - zSql),\n       zSql, zTableName, tname.z+tname.n);\n    sqlite3_result_text(context, zRet, -1, SQLITE_DYNAMIC);\n  }\n}",
    "comment": "Replaces the old table name in a CREATE TRIGGER SQL statement with a new table name provided as an argument.",
    "prorec_sum": "Parses a byte stream for specific opcode sequences and, upon matching, formats and dispatches a constructed string payload for further processing.",
    "filter_prorec_sum": "Parses a byte stream, detects specific control codes, and formats a quoted string with embedded data for further processing or dispatch.",
    "prorec_aug_sum": "Parses a byte sequence, checks token codes, and formats a labeled string with inserted data before dispatching it through a processing callback.",
    "filter_prorec_aug_sum": "Parses a byte sequence, detects specific token codes, and formats a quoted string with additional data for further processing.",
    "work_score": {
        "prorec_aug": {
            "summary": "Parses a byte sequence, checks token codes, and formats a labeled string with inserted data before dispatching it through a processing callback.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is overly generic and omits the specific domain semantics of locating and replacing the table name in a CREATE TRIGGER statement. While it is somewhat accurate that the function parses a byte sequence and processes tokens, it incorrectly generalizes the output stage as a generic 'processing callback' rather than SQLite's sqlite3_result_text. It also fails to mention key logic such as scanning for TK_ON/TK_DOT followed by TK_WHEN/TK_FOR/TK_BEGIN, making only about half of its claims accurate.",
                "The summary makes vague references to parsing a byte sequence, checking tokens, and formatting a string, which loosely aligns with the function looping over SQL tokens and building a result string. However, it fails to accurately capture the core primary purpose: finding and replacing the table name in a CREATE TRIGGER SQL statement based on specific token patterns (TK_ON/TK_DOT before and TK_WHEN/TK_FOR/TK_BEGIN after). It omits key domain semantics and specific logic, including the token distance condition, matching criteria, and returning the modified SQL, thus lacking both core coverage and key secondary details.",
                "The summary contains mostly vague and generic statements with little alignment to the actual semantics of the function. It does not mention the specific primary purpose of locating and replacing the old table name in a CREATE TRIGGER SQL statement. While it notes token checking and string formatting, these are described in an abstract way that misses critical details such as the conditions involving TK_ON, TK_DOT, TK_WHEN/TK_FOR/TK_BEGIN, or the use of sqlite3_result_text to set the output. The lack of specificity results in low gain and the presence of substantial noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Parses a byte sequence, detects specific token codes, and formats a quoted string with additional data for further processing.",
            "score": [
                0.5,
                0.2,
                0.5
            ],
            "reason": [
                "The summary makes vague references to parsing bytes, detecting tokens, and formatting a string, which loosely aligns with the code's behavior of scanning CREATE TRIGGER SQL text and using token codes to locate a table name before formatting and returning a modified SQL string. However, it omits the specific domain semantics of locating the old table name based on TK_ON/TK_DOT followed by TK_WHEN/TK_FOR/TK_BEGIN, and the function\u2019s purpose in renaming the table in the SQL statement. The generic phrasing reduces precision and misses key verifiable details, resulting in only partial accuracy.",
                "The summary generically describes parsing bytes and detecting tokens but fails to capture the core purpose of locating and replacing the old table name in a CREATE TRIGGER SQL statement based on specific token patterns (preceded by TK_ON/TK_DOT and followed by TK_WHEN/TK_FOR/TK_BEGIN). While 'detects specific token codes' is accurate as a low-information claim, the summary omits the SQL-domain context and the targeted string reconstruction with the new table name, resulting in no coverage of the core primary purpose and minimal secondary details.",
                "The summary is mostly generic and omits critical details of the function's purpose, namely that it parses a CREATE TRIGGER SQL statement to locate the old table name based on specific token patterns (ON/DOT followed by WHEN/FOR/BEGIN) and replaces it with a new quoted table name. While 'parses a byte sequence' and 'detects specific token codes' are accurate at a high level, they are low-information SAFE claims. The omission of the CREATE TRIGGER context and specific replacement operation significantly reduces usefulness. No factual inaccuracies are present, but the lack of specificity results in low gain."
            ]
        }
    }
}
{
    "source_code": "int blk_bio_map_sg(struct request_queue *q, struct bio *bio,\n\t\t   struct scatterlist *sglist)\n{\n\tstruct bio_vec *bvec, *bvprv;\n\tstruct scatterlist *sg;\n\tint nsegs, cluster;\n\tunsigned long i;\n\n\tnsegs = 0;\n\tcluster = blk_queue_cluster(q);\n\n\tbvprv = NULL;\n\tsg = NULL;\n\tbio_for_each_segment(bvec, bio, i) {\n\t\t__blk_segment_map_sg(q, bvec, sglist, &bvprv, &sg,\n\t\t\t\t     &nsegs, &cluster);\n\t} /* segments in bio */\n\n\tif (sg)\n\t\tsg_mark_end(sg);\n\n\tBUG_ON(bio->bi_phys_segments && nsegs > bio->bi_phys_segments);\n\treturn nsegs;\n}",
    "comment": "Maps segments of a block I/O bio to a scatter-gather list, updating the number of segments and handling physical segment constraints.",
    "prorec_sum": "Iterates over consecutive block entries, processes them via a helper, updates allocation flags, and enforces maximum block count constraints.",
    "filter_prorec_sum": "Iterates over consecutive filesystem block entries, processes them with a helper, updates status flags, and returns the count of successfully handled blocks.",
    "prorec_aug_sum": "Processes consecutive entries from a table, invokes a helper for each, updates flags, and validates the total processed count against a limit.",
    "filter_prorec_aug_sum": "Processes consecutive data chunks from a specified index, updating tracking variables and flags, and verifies the processed count does not exceed defined limits.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes consecutive entries from a table, invokes a helper for each, updates flags, and validates the total processed count against a limit.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary contains partially accurate elements \u2014 it correctly notes that a helper is invoked for each iteration and that there\u2019s a validation against a limit at the end. However, it inaccurately describes the data as a 'table' and refers to 'updating flags' which is not present in the source code, as the function iterates over bio segments and manages scatter-gather lists, not generic table entries or flags. This mix leads to less than full accuracy but more than half of the claims are aligned with the code.",
                "The summary makes generic claims about processing table entries, invoking a helper, updating flags, and validating counts. While 'invokes a helper for each' loosely aligns with calling __blk_segment_map_sg for each bio segment, the terms 'table' and 'flags' are inaccurate for this context, and there is no mention of scatterlist mapping\u2014the core purpose of mapping bio segments into a scatter-gather list. Thus, the core functionality is not covered, and most claims are misaligned with the actual domain semantics.",
                "The summary contains mostly inaccurate claims: it describes processing consecutive entries from a 'table' rather than iterating over bio segments, and omits key domain-specific detail about mapping scatterlists and clustering logic. While it mentions invoking a helper and validating a count against a limit, which loosely matches calling __blk_segment_map_sg and BUG_ON check, these are generic and low-information. The dominant mismatch (NOISE) undermines accuracy, and there are no specific GOLD details about the actual I/O or scatter-gather mapping performed."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes consecutive data chunks from a specified index, updating tracking variables and flags, and verifies the processed count does not exceed defined limits.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary claims the function processes consecutive data chunks from a specified index, updates tracking variables and flags, and verifies the processed count does not exceed limits. While the function does iterate over bio segments (akin to data chunks) and updates tracking variables like nsegs and cluster, there is no clear use of a 'specified index' beyond loop iteration, and no explicit 'flags' are involved\u2014only a call to sg_mark_end which is a structural marker. The verification of not exceeding limits matches the BUG_ON check. Overall, around half the claims are accurate but others are overly generic or slightly misleading regarding flags and index usage.",
                "The summary does not mention the core purpose of mapping a bio's segments into a scatter-gather list for a block I/O request queue, which is the central domain-specific behavior of the function. Instead, it gives a vague, generic description of processing data chunks and tracking variables, lacking specificity about scatter-gather mapping. While it loosely references iterating over data segments and enforcing limits, these points are too abstract and fail to directly align with the source code semantics.",
                "The summary's claims describe generic processing of consecutive data chunks from an index, updating variables/flags, and verifying counts against limits. While the 'verifies processed count does not exceed limits' loosely aligns with the BUG_ON check, the rest is largely inaccurate noise \u2014 the function iterates over bio segments, maps them to scatterlist entries, not arbitrary consecutive chunks from an index. No explicit FATAL misstatement of the primary purpose is present, but domain-specific details are omitted and replaced with vague placeholders, leading to high noise and low informational gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\ncleanup (void)\n{\n  if (close (STDIN_FILENO) < 0)\n    die (EXIT_FAILURE, errno, _(\"closing input file %s\"), quoteaf (input_file));\n\n  /* Don't remove this call to close, even though close_stdout\n     closes standard output.  This close is necessary when cleanup\n     is called as part of a signal handler.  */\n  if (close (STDOUT_FILENO) < 0)\n    die (EXIT_FAILURE, errno,\n         _(\"closing output file %s\"), quoteaf (output_file));\n}",
    "comment": "Cleans up temporary nodes by unlinking their associated names and resets the temporary head pointer to NULL.",
    "prorec_sum": "Handles specific signals by optionally logging, resetting timers, and sending them to a target process and process group using POSIX `kill` and `signal`.",
    "filter_prorec_sum": "Handles signal delivery to a process, optionally logging \u201csending signal %s to command %s\u201d, and triggering related cleanup and follow-up signals.",
    "prorec_aug_sum": "Handles signal delivery to a specified process, optionally logging the action, and sends additional stop signals unless certain signal types are specified.",
    "filter_prorec_aug_sum": "Handles signal dispatch to a process, optionally logging \u201csending signal %s to command %s\u201d, and manages follow\u2011up stop/continue signals based on global flags.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles signal delivery to a specified process, optionally logging the action, and sends additional stop signals unless certain signal types are specified.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims the function handles signal delivery, logs actions, and sends stop signals under certain conditions, but the source code only closes standard input and output file descriptors with error handling. None of the claims match the code's actual semantics, resulting in no accurate claims.",
                "The summary's claims about handling signal delivery, logging, and sending stop signals are unrelated to the source code, which simply closes standard input and output file descriptors with error handling. The core purpose of cleaning up by closing these file descriptors is entirely missing, so none of the fact-based claims align with the code.",
                "The summary is entirely inaccurate; the source code defines a cleanup function that closes standard input/output and exits on errors, with no handling of signals, process targeting, logging, or conditional stop signals. This is a severe FATAL error about the primary purpose, as the described behavior does not match the core action of the function."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Handles signal dispatch to a process, optionally logging \u201csending signal %s to command %s\u201d, and manages follow\u2011up stop/continue signals based on global flags.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes signal dispatch behavior, optional logging, and management of stop/continue signals, none of which appear in the provided source code. The actual code performs file descriptor closure for stdin and stdout with error handling, unrelated to signal handling or logging. All claims in the summary are inaccurate with respect to the source, resulting in 0% accurate claims.",
                "The summary makes claims about handling signal dispatch, logging, and managing stop/continue signals, none of which are present in the source code. The actual code simply closes STDIN and STDOUT, with error handling, as part of cleanup. The core purpose of closing these file descriptors is completely absent from the summary, and all claims are inaccurate regarding the source code semantics.",
                "The summary\u2019s claims about signal dispatch, logging, and managing stop/continue signals do not match the source code at all. The function only closes STDIN and STDOUT, handling potential errors, and does not send signals or perform related logging. This is a FATAL error on the primary purpose, making the summary unusable for understanding the actual code behavior."
            ]
        }
    }
}
{
    "source_code": "int schedule_on_each_cpu(work_func_t func)\n{\n\tint cpu;\n\tstruct work_struct __percpu *works;\n\n\tworks = alloc_percpu(struct work_struct);\n\tif (!works)\n\t\treturn -ENOMEM;\n\n\tget_online_cpus();\n\n\tfor_each_online_cpu(cpu) {\n\t\tstruct work_struct *work = per_cpu_ptr(works, cpu);\n\n\t\tINIT_WORK(work, func);\n\t\tschedule_work_on(cpu, work);\n\t}\n\n\tfor_each_online_cpu(cpu)\n\t\tflush_work(per_cpu_ptr(works, cpu));\n\n\tput_online_cpus();\n\tfree_percpu(works);\n\treturn 0;\n}",
    "comment": "Schedules a specified work function on each online CPU and waits for their completion before freeing allocated resources.",
    "prorec_sum": "Initializes per-CPU structures, iterates over all CPUs to configure data with provided parameters, then finalizes by cleaning up and freeing allocated memory.",
    "filter_prorec_sum": "Allocates a buffer and initializes per-IRQ data structures, processes them with provided parameters, then finalizes and frees allocated resources.",
    "prorec_aug_sum": "Iterates over registered objects, initializes and processes them with provided parameters, finalizes their state, and releases allocated resources.",
    "filter_prorec_aug_sum": "Allocates memory, iterates over indexed objects to initialize them with provided parameters, processes each, then finalizes and frees allocated resources.",
    "work_score": {
        "prorec_aug": {
            "summary": "Iterates over registered objects, initializes and processes them with provided parameters, finalizes their state, and releases allocated resources.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary gives a vague description about iterating over registered objects and processing them, but the source code specifically schedules a given work function on each online CPU, initializes work structures, flushes them, and releases resources. The summary fails to mention the CPU-specific scheduling or flushing semantics, replacing them with generic terms like 'registered objects' and 'finalizes their state', which do not align with the actual code behavior. Most claims are not targeted accurately to the code's domain semantics, resulting in low precision.",
                "The summary provides a vague and generic description that does not accurately reflect the core operation of scheduling and executing a given work function on each online CPU. Key specifics such as allocation of per-CPU work structures, scheduling using INIT_WORK and schedule_work_on, flushing work, and CPU iteration are missing. Although it mentions initialization, processing, and resource release, these are too general and omit the CPU-specific operations, resulting in the core purpose not being covered.",
                "The summary claims involve iterating over 'registered objects' with generic initialization and finalization, which is inaccurate since the source code iterates over online CPUs, initializes work structures with a provided function, schedules and flushes them, and frees allocated percpu resources. Core purpose (executing a work function on each CPU) is missed entirely, making this a FATAL error on the primary action. The statements are vague and do not convey specific, correct domain behavior beyond generic resource allocation and release."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates memory, iterates over indexed objects to initialize them with provided parameters, processes each, then finalizes and frees allocated resources.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary gives a generic outline of resource allocation, iteration, initialization, processing, and cleanup, which aligns broadly with the function\u2019s behavior. However, it omits critical domain-specific details such as operations being performed per CPU, use of `work_struct` and scheduling, and online CPU handling. While no claims are factually incorrect, the lack of specificity means the accuracy is limited to safe, generic statements rather than precise gold details.",
                "The summary provides a very generic description of allocating, initializing, processing, and freeing resources, but it omits the specific core purpose of scheduling a work function on each online CPU and waiting for completion. While the memory allocation and freeing for per-CPU structures are hinted at correctly, there is no mention of the CPU-specific iteration, scheduling mechanisms, flushing work, or error handling present in the source. The lack of core domain specificity results in coverage that is both vague and incomplete.",
                "The summary provides a generic description that loosely matches the code\u2019s sequence of actions but lacks specific, accurate domain details such as operating on all online CPUs, using INIT_WORK and schedule_work_on, and flushing work. While the broad actions of allocation, iteration, initialization, processing, and freeing are present and correct in a generic way (SAFE), the omission of the CPU-related semantics means no GOLD-level gain is delivered. There is no outright contradiction (no FATAL), but the description\u2019s low specificity makes the positive gain minimal and noise significant."
            ]
        }
    }
}
{
    "source_code": "\nstatic int put_compat_statfs(struct compat_statfs __user *ubuf, struct kstatfs *kbuf)\n{\n\t\n\tif (sizeof ubuf->f_blocks == 4) {\n\t\tif ((kbuf->f_blocks | kbuf->f_bfree | kbuf->f_bavail |\n\t\t     kbuf->f_bsize | kbuf->f_frsize) & 0xffffffff00000000ULL)\n\t\t\treturn -EOVERFLOW;\n\t\t/* f_files and f_ffree may be -1; it's okay\n\t\t * to stuff that into 32 bits */\n\t\tif (kbuf->f_files != 0xffffffffffffffffULL\n\t\t && (kbuf->f_files & 0xffffffff00000000ULL))\n\t\t\treturn -EOVERFLOW;\n\t\tif (kbuf->f_ffree != 0xffffffffffffffffULL\n\t\t && (kbuf->f_ffree & 0xffffffff00000000ULL))\n\t\t\treturn -EOVERFLOW;\n\t}\n\tif (!access_ok(VERIFY_WRITE, ubuf, sizeof(*ubuf)) ||\n\t    __put_user(kbuf->f_type, &ubuf->f_type) ||\n\t    __put_user(kbuf->f_bsize, &ubuf->f_bsize) ||\n\t    __put_user(kbuf->f_blocks, &ubuf->f_blocks) ||\n\t    __put_user(kbuf->f_bfree, &ubuf->f_bfree) ||\n\t    __put_user(kbuf->f_bavail, &ubuf->f_bavail) ||\n\t    __put_user(kbuf->f_files, &ubuf->f_files) ||\n\t    __put_user(kbuf->f_ffree, &ubuf->f_ffree) ||\n\t    __put_user(kbuf->f_namelen, &ubuf->f_namelen) ||\n\t    __put_user(kbuf->f_fsid.val[0], &ubuf->f_fsid.val[0]) ||\n\t    __put_user(kbuf->f_fsid.val[1], &ubuf->f_fsid.val[1]) ||\n\t    __put_user(kbuf->f_frsize, &ubuf->f_frsize) ||\n\t    __put_user(kbuf->f_flags, &ubuf->f_flags) ||\n\t    __clear_user(ubuf->f_spare, sizeof(ubuf->f_spare)))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
    "comment": "Validates and transfers filesystem statistics from kernel to user space, ensuring no overflow occurs for 32-bit fields.",
    "prorec_sum": "Validates 64-bit fields from a user-provided structure for 32-bit compliance, copies them into a destination array, and performs a final integrity check.",
    "filter_prorec_sum": "Validates 64-bit fields from a user-provided structure for 32-bit constraints, copies them into a destination buffer, and performs additional range checks.",
    "prorec_aug_sum": "Validates multiple 64-bit fields from a2 for 32-bit range, copies them into a1, and performs additional bounds and integrity checks before returning.",
    "filter_prorec_aug_sum": "Validates 64-bit fields for 32-bit range compliance, copies them into an output structure, and performs a final bounds check before returning success or error codes.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates multiple 64-bit fields from a2 for 32-bit range, copies them into a1, and performs additional bounds and integrity checks before returning.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function validates several 64-bit fields from the second parameter for 32-bit range and copies them into the first parameter, which aligns with the checks against 0xffffffff00000000ULL and the __put_user calls. However, the mention of 'additional bounds and integrity checks' is vague and not entirely accurate; the function specifically performs overflow checks, user-space access checks, and user memory clearance, not generic 'integrity' checks. Despite the vague wording, the majority of the claims match the observed implementation, making the accuracy high.",
                "The summary accurately states that the function validates several 64-bit fields in kbuf for 32-bit range, copies them into the compat struct ubuf, and performs additional integrity checks before returning. This covers the core purpose: converting and safely copying statfs data to a user-provided 32-bit compatible structure with overflow and access checks. However, it omits specifics about the EOVERFLOW conditions for particular fields, the allowance for -1 in f_files/f_ffree, and the exact failure return codes (EFAULT vs EOVERFLOW), so secondary coverage is partial but not comprehensive.",
                "The summary correctly states that the function validates several 64-bit fields from the second argument to ensure they fit within 32-bit values, and that it copies them into the first argument. This matches the code's checks for f_blocks, f_bfree, f_bavail, f_bsize, f_frsize, f_files, and f_ffree before writing to the user buffer via __put_user. The mention of 'additional bounds and integrity checks' is somewhat vague but generally aligns with the overflow checks and access_ok verification. There are no factually incorrect claims, but the wording is broad and lacks detail about the specific fields and error conditions, so the gain is moderate rather than high."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates 64-bit fields for 32-bit range compliance, copies them into an output structure, and performs a final bounds check before returning success or error codes.",
            "score": [
                0.8,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly identifies that the function validates 64-bit fields for 32-bit range compliance, transfers data into the output structure, and returns appropriate error codes, which matches the source logic. However, it inaccurately describes a 'final bounds check' before returning, as the concluding check is actually for write/access errors rather than bounds, making this part misleading. Most claims are accurate, but this misstatement reduces overall precision.",
                "The summary accurately captures the core purpose: ensuring 64-bit kstatfs values fit in 32-bit fields and copying them to the user-provided compat_statfs structure. However, it misrepresents some specifics, such as describing the initial overflow checks as a 'final bounds check', omitting the access_ok and __put_user sequence as part of a user-space write operation, and not mentioning the special handling of sentinel -1 values for f_files and f_ffree. Secondary behavior details like error return conditions (-EOVERFLOW and -EFAULT) are partially referenced but not fully contextualized.",
                "The summary correctly states that the function validates 64-bit fields for 32-bit compatibility and copies them into the output structure, which matches the code\u2019s overflow checks and __put_user calls. However, it inaccurately claims a 'final bounds check' before returning, which is not present; the final check is for write accessibility and copying errors, not bounds. This is a minor inaccuracy, with most content accurate and relevant, providing moderate detail about the primary purpose."
            ]
        }
    }
}
{
    "source_code": "\n\nsize_t ZSTD_compressEnd (ZSTD_CCtx* cctx,\n                         void* dst, size_t dstCapacity,\n                   const void* src, size_t srcSize)\n{\n    size_t endResult;\n    size_t const cSize = ZSTD_compressContinue_internal(cctx, dst, dstCapacity, src, srcSize, 1, 1);\n    if (ZSTD_isError(cSize)) return cSize;\n    endResult = ZSTD_writeEpilogue(cctx, (char*)dst + cSize, dstCapacity-cSize);\n    if (ZSTD_isError(endResult)) return endResult;\n    return cSize + endResult;\n}",
    "comment": "Compresses data using a continuation method, writes an epilogue, and returns the total compressed size or an error code if the process fails.",
    "prorec_sum": "Processes a data block with state-driven transformations, writing control values to the output and updating internal state before returning total bytes consumed.",
    "filter_prorec_sum": "Processes a data block with staged state transitions, writes control values, and appends an extra byte from a stored context before returning total bytes handled.",
    "prorec_aug_sum": "Processes a data block with state-dependent steps, writes control and optional values into the buffer, and returns the total bytes written or an error code.",
    "filter_prorec_aug_sum": "Processes a data block based on state flags, writing control values and optional byte, then returns processed length or specific error codes.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes a data block with state-dependent steps, writes control and optional values into the buffer, and returns the total bytes written or an error code.",
            "score": [
                0.5,
                0.3,
                0.5
            ],
            "reason": [
                "The summary claims the function processes a data block with state-dependent steps and writes control/optional values into the buffer. While it correctly implies sequential processing and returning total bytes or an error code, it introduces inaccurate notions of 'control and optional values' not present in the source code, which actually performs compression continuation followed by epilogue writing. The connection to control values is unfounded, so only a portion aligns with the actual implementation.",
                "The summary generically mentions processing a data block with state-dependent steps and returning total bytes written or an error, which loosely corresponds to combining compression output and epilogue writing. However, it fails to explicitly cover the core purpose of ending a ZSTD compression stream by calling ZSTD_compressContinue_internal with termination flags and then writing the epilogue. It omits key details such as the use of specific ZSTD functions, parameters like dstCapacity adjustments, and branching on error conditions for both compression and epilogue steps. While it hints at output and error behavior, the description is too vague and lacks domain-specific specifics from the source code.",
                "The summary contains mostly generic statements such as processing a data block and returning total bytes written, which loosely match the code but omit key details like the use of ZSTD_compressContinue_internal, ZSTD_writeEpilogue, and error checks. The mention of 'writes control and optional values' is vague and not supported by the source, making it noise. No severe factual contradictions are present, but the description provides low informational value and lacks specificity about the core compression and epilogue writing steps."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes a data block based on state flags, writing control values and optional byte, then returns processed length or specific error codes.",
            "score": [
                0.2,
                0.1,
                0.3
            ],
            "reason": [
                "The summary claims that the function processes a data block based on state flags, writes control values and an optional byte, and returns processed length or error codes. The source code shows that it calls compression continuation, checks for errors, writes an epilogue, and returns the sum or an error. The statements about state flags, control values, and optional byte are not present in the source, while only the return of processed length or error codes is loosely accurate. Overall, most claims are inaccurate with minimal alignment to actual code behavior.",
                "The summary's claims about processing a data block using state flags and writing control values/optional byte are inaccurate with respect to the source code, which actually continues compression, writes an epilogue, and handles error codes accordingly. The core purpose of finalizing a compression stream and calculating total compressed size is missing. The only tangentially relevant detail is returning processed length or error codes, which is generic and weak, with almost no accurate secondary information provided.",
                "The summary's claims about processing a data block based on state flags, writing control values, and optional bytes do not match the source code's primary behavior of finalizing compression by calling internal continuation and epilogue functions. These are unrelated to the actual semantics, making the claims NOISE and lacking alignment with core I/O or effects. No accurate, domain-specific details are present, resulting in negligible gain."
            ]
        }
    }
}
{
    "source_code": "void nfs_init_timeout_values(struct rpc_timeout *to, int proto,\n\t\t\t\t    unsigned int timeo, unsigned int retrans)\n{\n\tto->to_initval = timeo * HZ / 10;\n\tto->to_retries = retrans;\n\n\tswitch (proto) {\n\tcase XPRT_TRANSPORT_TCP:\n\tcase XPRT_TRANSPORT_RDMA:\n\t\tif (to->to_retries == 0)\n\t\t\tto->to_retries = NFS_DEF_TCP_RETRANS;\n\t\tif (to->to_initval == 0)\n\t\t\tto->to_initval = NFS_DEF_TCP_TIMEO * HZ / 10;\n\t\tif (to->to_initval > NFS_MAX_TCP_TIMEOUT)\n\t\t\tto->to_initval = NFS_MAX_TCP_TIMEOUT;\n\t\tto->to_increment = to->to_initval;\n\t\tto->to_maxval = to->to_initval + (to->to_increment * to->to_retries);\n\t\tif (to->to_maxval > NFS_MAX_TCP_TIMEOUT)\n\t\t\tto->to_maxval = NFS_MAX_TCP_TIMEOUT;\n\t\tif (to->to_maxval < to->to_initval)\n\t\t\tto->to_maxval = to->to_initval;\n\t\tto->to_exponential = 0;\n\t\tbreak;\n\tcase XPRT_TRANSPORT_UDP:\n\t\tif (to->to_retries == 0)\n\t\t\tto->to_retries = NFS_DEF_UDP_RETRANS;\n\t\tif (!to->to_initval)\n\t\t\tto->to_initval = NFS_DEF_UDP_TIMEO * HZ / 10;\n\t\tif (to->to_initval > NFS_MAX_UDP_TIMEOUT)\n\t\t\tto->to_initval = NFS_MAX_UDP_TIMEOUT;\n\t\tto->to_maxval = NFS_MAX_UDP_TIMEOUT;\n\t\tto->to_exponential = 1;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n}",
    "comment": "Initializes timeout values for NFS RPC transport depending on the protocol type, setting retries, initial timeout, and limits accordingly.",
    "prorec_sum": "Configures timing parameters and state fields in a structure based on input type, duration, and multiplier, enforcing bounds and defaults for specific modes.",
    "filter_prorec_sum": "Configures timing parameters and related fields for a lock operation based on input type, duration, and count, enforcing upper and default limits.",
    "prorec_aug_sum": "Configures timing parameters and related state fields based on input type and multiplier, enforcing bounds and defaults for subsequent operations.",
    "filter_prorec_aug_sum": "Configures timing parameters and limits in a structure based on operation type, rate, and count, applying defaults and caps for special conditions.",
    "work_score": {
        "prorec_aug": {
            "summary": "Configures timing parameters and related state fields based on input type and multiplier, enforcing bounds and defaults for subsequent operations.",
            "score": [
                0.9,
                0.2,
                0.5
            ],
            "reason": [
                "The summary makes a generic claim about configuring timing parameters, related state fields, enforcing bounds, and defaults, which aligns broadly with the function\u2019s behavior for different protocols. However, it lacks specific details about protocol-specific handling, exact field assignments, and conditions in the source code. The claim targets the code semantics but is high-level, thus accurate but low-information. With only one claim of this nature, the proportion of accurate statements is effectively 100%, though specificity is limited.",
                "The summary is generic and does not explicitly state the core purpose of initializing NFS RPC timeout values for TCP or UDP transports with protocol-specific defaults, bounds, and exponential behavior. While it correctly notes configuration of timing parameters and bounds, it omits key domain specifics such as the transport type handling, constants like NFS_DEF_TCP_RETRANS, and behavior differences between protocols. This leaves the core operation uncovered and secondary details minimal.",
                "The summary makes a single broad claim that the function sets timing parameters and state based on input type, applying bounds and defaults. This is generally accurate but highly generic, omitting specific behavioral details such as handling for TCP vs UDP, exponential backoff settings, and exact fields modified. There are no false or contradictory statements, but the vagueness limits its usefulness for understanding the function\u2019s core behavior. The worst failure mode is low-information SAFE claims with minimal net benefit."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Configures timing parameters and limits in a structure based on operation type, rate, and count, applying defaults and caps for special conditions.",
            "score": [
                0.8,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly captures the generic purpose of setting timing-related parameters based on a type and certain inputs, applying defaults and enforcing limits. However, it omits specific protocol distinctions (TCP vs UDP) and details like which fields are set or how increments and exponential behavior differ, making the claims mostly accurate but very high-level. There are no clear inaccuracies, but the lack of specificity reduces precision.",
                "The summary generically states that timing parameters and limits are configured based on type, rate, and count with defaults and caps, which loosely matches the function\u2019s role of initializing RPC timeout values for NFS based on protocol. However, it fails to explicitly cover the core purpose of setting timeout and retry parameters specifically for TCP, RDMA, or UDP transports with distinct logic, constants, and caps, thus missing key domain-specific details. Secondary behavior like exponential backoff, max value calculations, and BUG() handling is also omitted.",
                "The summary generically describes configuring timing parameters and applying defaults and limits, which aligns broadly with the code\u2019s behavior for different protocols. However, it omits important specifics such as handling of TCP vs UDP separately, exact use of retries and timeo, specific caps per protocol, and exponential vs fixed increments. There are no factually incorrect (FATAL) statements, but the claims are extremely generic (SAFE) with low informational value, resulting in low net benefit due to lack of detail."
            ]
        }
    }
}
{
    "source_code": "\nint\nfreadseek (FILE *fp, size_t offset)\n{\n  size_t total_buffered;\n  int fd;\n\n  if (offset == 0)\n    return 0;\n\n  /* Seek over the already read and buffered input as quickly as possible,\n     without doing any system calls.  */\n  total_buffered = freadahead (fp);\n  /* This loop is usually executed at most twice: once for ungetc buffer (if\n     present) and once for the main buffer.  */\n  while (total_buffered > 0)\n    {\n      size_t buffered;\n\n      if (freadptr (fp, &buffered) != NULL && buffered > 0)\n        {\n          size_t increment = (buffered < offset ? buffered : offset);\n\n          freadptrinc (fp, increment);\n          offset -= increment;\n          if (offset == 0)\n            return 0;\n          total_buffered -= increment;\n          if (total_buffered == 0)\n            break;\n        }\n      /* Read one byte.  If we were reading from the ungetc buffer, this\n         switches the stream back to the main buffer.  */\n      if (fgetc (fp) == EOF)\n        goto eof;\n      offset--;\n      if (offset == 0)\n        return 0;\n      total_buffered--;\n    }\n\n  /* Test whether the stream is seekable or not.  */\n  fd = fileno (fp);\n  if (fd >= 0 && lseek (fd, 0, SEEK_CUR) >= 0)\n    {\n      /* FP refers to a regular file.  fseek is most efficient in this case.  */\n      return fseeko (fp, offset, SEEK_CUR);\n    }\n  else\n    {\n      /* FP is a non-seekable stream, possibly not even referring to a file\n         descriptor.  Read OFFSET bytes explicitly and discard them.  */\n      char buf[4096];\n\n      do\n        {\n          size_t count = (sizeof (buf) < offset ? sizeof (buf) : offset);\n          if (fread (buf, 1, count, fp) < count)\n            goto eof;\n          offset -= count;\n        }\n      while (offset > 0);\n\n      return 0;\n   }\n\n eof:\n  /* EOF, or error before or while reading.  */\n  if (ferror (fp))\n    return EOF;\n  else\n    /* Encountered EOF.  */\n    return 0;\n}",
    "comment": "The function efficiently skips a specified number of bytes in a FILE stream, handling buffered input and seeking on regular files when possible.",
    "prorec_sum": "Reads and discards a specified number of bytes from a FILE stream using buffered or unbuffered methods until the count is exhausted or an error occurs.",
    "filter_prorec_sum": "Reads and discards a specified number of bytes from a FILE stream, using buffered, unbuffered, or seek-based methods depending on stream state.",
    "prorec_aug_sum": "Skips a specified number of bytes in a FILE stream using buffered reading, direct seeking, or unbuffered reads depending on stream capabilities.",
    "filter_prorec_aug_sum": "Reads and discards a specified number of bytes from a file stream, using buffered reads, single-byte reads, or seeks depending on stream state.",
    "work_score": {
        "prorec_aug": {
            "summary": "Skips a specified number of bytes in a FILE stream using buffered reading, direct seeking, or unbuffered reads depending on stream capabilities.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary states that the function skips a specified number of bytes using buffered reading, direct seeking, or unbuffered reads depending on stream capabilities. Each element accurately reflects the source code: the function iterates through buffered data, uses fseeko on seekable streams, and reads/discards data on non-seekable streams. No claims contradict the implementation, and all are relevant to the function\u2019s semantics.",
                "The summary accurately captures the core purpose of the function \u2014 skipping a specified offset in a FILE stream using different strategies depending on the stream's capabilities \u2014 which matches the main domain-specific operation in the code. It mentions buffered reading, direct seeking, and unbuffered reads, covering the main decision branches. However, it omits secondary important details such as handling of the ungetc buffer, EOF and error return behaviors, and explicit buffer sizes in unseekable streams, so coverage of secondary semantics is incomplete.",
                "The summary accurately captures the core purpose of the function \u2014 skipping a specified number of bytes in a FILE stream \u2014 and notes the three strategies employed: buffered reading, direct seeking, and unbuffered reads, which match the source code\u2019s logic paths. It omits minor implementation specifics such as handling ungetc buffers, EOF, and error states, but contains no inaccuracies or irrelevant noise. The claims are mostly safe with moderate specificity, providing a clear and correct high-level view without misleading details."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Reads and discards a specified number of bytes from a file stream, using buffered reads, single-byte reads, or seeks depending on stream state.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function reads and discards a specified number of bytes from a file stream. It correctly notes that the implementation may use buffered reads, single-byte reads, or seek operations, depending on the stream's state and capabilities, which matches the conditional logic in the code handling buffered data, switching buffers, using fseeko for regular files, or reading/discarding for non-seekable streams. All core claims are specific and align with the source code behavior.",
                "The summary correctly conveys the core purpose of the function \u2014 to skip/discard a specified number of bytes from a file stream \u2014 and mentions the use of buffering, single-byte reads, or seeking depending on stream state, which matches the code\u2019s logic for handling buffered data, seekable streams, and non-seekable streams. However, it omits important secondary details such as the EOF/error handling behavior and the distinction between ungetc buffer and main buffer. While the core is covered with good specificity, coverage of other key behaviors is limited.",
                "The summary correctly identifies the function\u2019s primary purpose of discarding a specified number of bytes from a file stream and notes it uses different strategies depending on stream state, matching the code\u2019s use of buffered reads, single-byte reads, and seeks. All elements are accurate and relevant to the implementation, with no evident inaccuracies or noise. However, while specific and correct, the description is fairly concise and omits some operational details like handling non-seekable streams via block reads or EOF/error behaviors, limiting the depth of insight."
            ]
        }
    }
}
{
    "source_code": "\nstatic Rconnection\nnewxzfile(const char *description, const char *mode, int type, int compress)\n{\n    Rconnection new;\n    new = (Rconnection) malloc(sizeof(struct Rconn));\n    if(!new) error(_(\"allocation of xzfile connection failed\"));\n    new->class = (char *) malloc(strlen(\"xzfile\") + 1);\n    if(!new->class) {\n\tfree(new);\n\terror(_(\"allocation of xzfile connection failed\"));\n\t/* for Solaris 12.5 */ new = NULL;\n    }\n    strcpy(new->class, \"xzfile\");\n    new->description = (char *) malloc(strlen(description) + 1);\n    if(!new->description) {\n\tfree(new->class); free(new);\n\terror(_(\"allocation of xzfile connection failed\"));\n\t/* for Solaris 12.5 */ new = NULL;\n    }\n    init_con(new, description, CE_NATIVE, mode);\n\n    new->canseek = FALSE;\n    new->open = &xzfile_open;\n    new->close = &xzfile_close;\n    new->vfprintf = &dummy_vfprintf;\n    new->fgetc_internal = &xzfile_fgetc_internal;\n    new->fgetc = &dummy_fgetc;\n    new->seek = &null_seek;\n    new->fflush = &null_fflush;\n    new->read = &xzfile_read;\n    new->write = &xzfile_write;\n    new->private = (void *) malloc(sizeof(struct xzfileconn));\n    memset(new->private, 0, sizeof(struct xzfileconn));\n    if(!new->private) {\n\tfree(new->description); free(new->class); free(new);\n\terror(_(\"allocation of xzfile connection failed\"));\n\t/* for Solaris 12.5 */ new = NULL;\n    }\n    ((Rxzfileconn) new->private)->type = type;\n    ((Rxzfileconn) new->private)->compress = compress;\n    return new;\n}",
    "comment": "Allocates and initializes a new xzfile connection, setting its properties and handling memory for class, description, and private data structures.",
    "prorec_sum": "Initializes and returns an xzfile connection object, allocating required buffers, setting handler function pointers, and storing provided parameters.",
    "filter_prorec_sum": "Initializes and returns an xzfile connection structure, allocating buffers and setting function pointers for I/O operations and configuration parameters.",
    "prorec_aug_sum": "Initializes and returns an xzfile connection structure, setting its handlers, storing parameters, and allocating buffers for subsequent compressed file operations.",
    "filter_prorec_aug_sum": "Creates and initializes an xzfile connection structure with associated callbacks, buffers, and parameters, reporting an error if memory allocation fails.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes and returns an xzfile connection structure, setting its handlers, storing parameters, and allocating buffers for subsequent compressed file operations.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function initializes and returns an xzfile connection, assigns various handler functions, stores parameters (description, type, compress), and allocates necessary memory for operation. These points are consistent with the source code, and there are no contradictory or irrelevant claims. All identified claims are accurate and supported by the implementation.",
                "The summary correctly identifies that the function initializes and returns an xzfile connection structure, sets its handlers, stores parameters, and allocates memory. These claims are accurate and reflect the core primary purpose of creating and preparing a new xzfile connection with specific function pointers and associated configuration. However, it omits secondary details such as the allocation error handling, exact fields like canseek, specific functions assigned for open/read/write, and initialization of the private structure with type and compress values. This reduces completeness beyond the core.",
                "The summary correctly states that the function initializes and returns an xzfile connection structure, sets its handlers, and stores parameters, which matches the code\u2019s allocation of the structure, assignment of function pointers, and parameter storage. However, it inaccurately claims that the function allocates buffers for subsequent compressed file operations \u2014 the code allocates memory for the connection structure and its internal data but not specific I/O buffers. This is a minor semantic inaccuracy (NOISE) rather than a severe FATAL error. Overall, accurate high-level description with one slightly misleading detail."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Creates and initializes an xzfile connection structure with associated callbacks, buffers, and parameters, reporting an error if memory allocation fails.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function creates and initializes an xzfile connection structure, assigns callbacks, sets parameters, and handles memory allocation failures with error reporting. While 'buffers' is mentioned in the summary, the source code does not explicitly allocate or manage additional buffers beyond structures, but this is a minor overgeneralization. Overall, the claims are correct and closely match the code's semantics with only slight imprecision.",
                "The summary accurately describes the core purpose\u2014creating and initializing an xzfile connection with callbacks and parameters, and handling allocation errors\u2014which matches the function's primary operation in the source code. However, it omits several important secondary details such as the specific fields set (class, description, private struct), initialization of canseek flag, explicit function pointers assigned, and constants like CE_NATIVE. This results in decent core coverage but only partial coverage of other critical semantics.",
                "The summary accurately conveys the primary purpose of the function \u2014 creating and initializing an xzfile connection with callbacks and parameters, and handling allocation failures. It correctly reflects the key elements seen in the code (initialization steps, setting of function pointers, error handling on memory allocation failure) without introducing incorrect or irrelevant information. The claim is specific enough to be useful with no apparent inaccuracies and minimal noise, though it is somewhat broad and omits finer details like the exact set of callbacks and structure field initializations."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_multifit_linear_applyW(const gsl_matrix * X,\n                           const gsl_vector * w,\n                           const gsl_vector * y,\n                           gsl_matrix * WX,\n                           gsl_vector * Wy)\n{\n  const size_t n = X->size1;\n  const size_t p = X->size2;\n\n  if (n != y->size)\n    {\n      GSL_ERROR(\"y vector does not match X\", GSL_EBADLEN);\n    }\n  else if (w != NULL && n != w->size)\n    {\n      GSL_ERROR(\"weight vector does not match X\", GSL_EBADLEN);\n    }\n  else if (n != WX->size1 || p != WX->size2)\n    {\n      GSL_ERROR(\"WX matrix dimensions do not match X\", GSL_EBADLEN);\n    }\n  else if (n != Wy->size)\n    {\n      GSL_ERROR(\"Wy vector must be length n\", GSL_EBADLEN);\n    }\n  else\n    {\n      size_t i;\n\n      /* copy WX = X; Wy = y if distinct pointers */\n      if (WX != X)\n        gsl_matrix_memcpy(WX, X);\n      if (Wy != y)\n        gsl_vector_memcpy(Wy, y);\n\n      if (w != NULL)\n        {\n          /* construct WX = sqrt(W) X and Wy = sqrt(W) y */\n          for (i = 0; i < n; ++i)\n            {\n              double wi = gsl_vector_get(w, i);\n              double swi;\n              gsl_vector_view row = gsl_matrix_row(WX, i);\n              double *yi = gsl_vector_ptr(Wy, i);\n\n              if (wi < 0.0)\n                wi = 0.0;\n\n              swi = sqrt(wi);\n              gsl_vector_scale(&row.vector, swi);\n              *yi *= swi;\n            }\n        }\n\n      return GSL_SUCCESS;\n    }\n}",
    "comment": "Applies weighted transformations to input matrix X and vector y, storing results in WX and Wy, respectively, while handling potential dimension mismatches.",
    "prorec_sum": "Validates dimensional consistency of input matrices/vectors and applies weight scaling to X and y for weighted linear regression fitting.",
    "filter_prorec_sum": "Validates matching dimensions of input vectors/matrices, then copies and applies weight scaling to X and y data for weighted linear regression.",
    "prorec_aug_sum": "Validates vector and matrix dimensions, then copies and applies weights to regression data by scaling rows and corresponding vector elements.",
    "filter_prorec_aug_sum": "Validates dimensions of input matrices/vectors and applies square root weight scaling to rows and corresponding vector elements for weighted linear regression.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates vector and matrix dimensions, then copies and applies weights to regression data by scaling rows and corresponding vector elements.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately reflects the function's core behavior: it first validates the dimensions of the input vectors and matrices, then copies data if needed, and applies weights by scaling rows in the matrix and corresponding elements in the vector. All these points are explicitly supported by the source code without introducing contradictions or irrelevant details, making the claims precise and consistent with the implementation.",
                "The summary correctly states that the function validates vector and matrix dimensions and applies weights by scaling rows and corresponding vector elements, which matches the core purpose of applying weights to regression data after dimension checks. It covers the primary operation and also mentions the copying step implicitly. However, secondary details like handling null weight vector, zeroing negative weights, and the return/error behavior are omitted, making the coverage incomplete.",
                "The summary contains accurate claims about the core function: it validates dimensions of input vectors and matrices, copies the data when needed, and applies weights by scaling rows and vector elements. These behaviors match the source code exactly and describe primary purpose and I/O semantics. There is no contradictory or irrelevant information, and although the gain is moderate due to brevity, it covers key operations with specificity."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates dimensions of input matrices/vectors and applies square root weight scaling to rows and corresponding vector elements for weighted linear regression.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary contains two key claims: that the function validates dimensions of input matrices/vectors, and that it applies square root weight scaling to rows and corresponding vector elements for weighted linear regression. Both are accurate based on the source code: the function performs multiple size checks with error returns and, when weights are provided, scales rows of WX and elements of Wy by the square root of non-negative weights. All claims precisely match the code's behavior, showing high accuracy.",
                "The summary accurately reflects the core primary purpose: checking matrix/vector dimensions and applying sqrt(weight) scaling for weighted linear regression. It also mentions both major aspects in the code: validation of dimensions and scaling of both rows and target vector elements. However, it leaves out some secondary details, such as handling NULL weight vectors (copying without scaling), clamping negative weights to zero, and returning specific error codes. This reduces completeness relative to the full set of critical behaviors.",
                "The summary correctly states that the function checks dimensions of its input matrices and vectors, and applies square root weight scaling to rows and vector elements, which matches the code's core logic for preparing data for weighted linear regression. All claims are accurate, specific to the function's domain, and target its primary purpose without introducing noise or contradictions. There is strong alignment with both the dimension-validation sequence and the weighted scaling implementation, offering high-value insight."
            ]
        }
    }
}
{
    "source_code": "\nstatic double InReal(R_inpstream_t stream)\n{\n    char word[128];\n    char buf[128];\n    double d;\n\n    switch (stream->type) {\n    case R_pstream_ascii_format:\n\tInWord(stream, word, sizeof(word));\n\tif(sscanf(word, \"%127s\", buf) != 1) error(_(\"read error\"));\n\tif (strcmp(buf, \"NA\") == 0)\n\t    return NA_REAL;\n\telse if (strcmp(buf, \"NaN\") == 0)\n\t    return R_NaN;\n\telse if (strcmp(buf, \"Inf\") == 0)\n\t    return R_PosInf;\n\telse if (strcmp(buf, \"-Inf\") == 0)\n\t    return R_NegInf;\n\telse\n\t    if(\n#ifdef Win32\n\t\ttrio_sscanf(buf, \"%lg\", &d)\n#else\n\t\tsscanf(buf, \"%lg\", &d)\n#endif\n\t\t!= 1) error(_(\"read error\"));\n\treturn d;\n    case R_pstream_binary_format:\n\tstream->InBytes(stream, &d, sizeof(double));\n\treturn d;\n    case R_pstream_xdr_format:\n\tstream->InBytes(stream, buf, R_XDR_DOUBLE_SIZE);\n\treturn R_XDRDecodeDouble(buf);\n    default:\n\treturn NA_REAL;\n    }\n}",
    "comment": "Reads a double value from a specified input stream format (ASCII, binary, or XDR) and handles special cases like NA, NaN, and infinity.",
    "prorec_sum": "Parses numeric or special string values from input, handles \u201cNA\u201d/\u201cNaN\u201d/\u201cInf\u201d cases, and raises an error if reading fails.",
    "filter_prorec_sum": "Parses numeric or special string values from input, handling \"NA\", \"NaN\", and infinities, and reports a read error on invalid data.",
    "prorec_aug_sum": "Parses numeric or special string values from input, handling NA/Inf cases, and invokes appropriate processing or error reporting based on a type code.",
    "filter_prorec_aug_sum": "Parses numeric or special string values from input, handles \u201cNA\u201d/\u201cNaN\u201d/\u201cInf\u201d cases, and reports a \u201cread error\u201d through R\u2019s error mechanism if invalid.",
    "work_score": {
        "prorec_aug": {
            "summary": "Parses numeric or special string values from input, handling NA/Inf cases, and invokes appropriate processing or error reporting based on a type code.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary accurately captures the core functionality of parsing numeric or special values (NA, Inf) and handling errors based on the stream type code, which aligns with the code\u2019s logic for ASCII, binary, and XDR formats. While it omits explicit mention of all special cases (e.g., NaN, -Inf) and certain implementation specifics, the majority of its claims are correct and code-targeted, with no clear inaccuracies.",
                "The summary correctly states that the function parses numeric and special string values, handles NA/Inf cases, and reports errors based on a type code, which matches the core purpose of reading a double from different stream formats and handling special tokens. However, it omits specificity about the three distinct stream types (ASCII, binary, XDR) and the exact processing for each, such as decoding XDR doubles or reading raw bytes for binary format, which are important secondary behaviors. The coverage of secondary details is limited and lacks the concrete domain wording of the primary action.",
                "The summary accurately captures the function\u2019s core purpose: it reads numeric or special values like NA and Inf from an input stream, handles them appropriately, and reports errors when parsing fails. It also notes that behavior depends on a type code, which aligns with the switch on stream->type. While accurate, the description is broad and omits specifics such as different parsing methods (ASCII, binary, XDR), the exact matching strings (NaN, -Inf), and the specific functions used. There are no inaccurate claims, but the gain is moderate because the detail level is low."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Parses numeric or special string values from input, handles \u201cNA\u201d/\u201cNaN\u201d/\u201cInf\u201d cases, and reports a \u201cread error\u201d through R\u2019s error mechanism if invalid.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function parses numeric or special string values and handles 'NA', 'NaN', and 'Inf' cases, which aligns with the source code. It also accurately mentions the use of R\u2019s error mechanism for invalid input. However, the summary omits handling of '-Inf' and the fact that there are multiple input formats (ascii, binary, xdr) handled differently. Despite these omissions, the majority of the described behavior matches the implementation, leading to high accuracy.",
                "The summary correctly captures the core function of parsing numeric or special string values from a stream and handling special cases like 'NA', 'NaN', and 'Inf'. It also accurately notes the use of R\u2019s error mechanism when invalid input occurs. However, it omits important secondary behaviors, such as support for multiple stream formats (ASCII, binary, XDR) and the distinct parsing method for each, as well as handling '-Inf' and numeric parsing in platform-specific ways. These omissions mean that while the core is covered, coverage of other key semantics is limited.",
                "The summary correctly states that the function parses numeric and special values (NA, NaN, Inf) from input and raises a read error if invalid, which matches the source. However, it omits key implementation details from the code, such as handling -Inf, supporting multiple input formats (ASCII, binary, XDR), and defaulting to NA_REAL for unknown types. While there are no inaccurate claims, the gain is low due to missing these specifics."
            ]
        }
    }
}
{
    "source_code": "dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,\n\t\t\t    unsigned long offset, size_t size,\n\t\t\t    enum dma_data_direction dir,\n\t\t\t    struct dma_attrs *attrs)\n{\n\tphys_addr_t map, phys = page_to_phys(page) + offset;\n\tdma_addr_t dev_addr = phys_to_dma(dev, phys);\n\n\tBUG_ON(dir == DMA_NONE);\n\t/*\n\t * If the address happens to be in the device's DMA window,\n\t * we can safely return the device addr and not worry about bounce\n\t * buffering it.\n\t */\n\tif (dma_capable(dev, dev_addr, size) && !swiotlb_force)\n\t\treturn dev_addr;\n\n\t/* Oh well, have to allocate and map a bounce buffer. */\n\tmap = map_single(dev, phys, size, dir);\n\tif (map == SWIOTLB_MAP_ERROR) {\n\t\tswiotlb_full(dev, size, dir, 1);\n\t\treturn phys_to_dma(dev, io_tlb_overflow_buffer);\n\t}\n\n\tdev_addr = phys_to_dma(dev, map);\n\n\t/* Ensure that the address returned is DMA'ble */\n\tif (!dma_capable(dev, dev_addr, size)) {\n\t\tswiotlb_tbl_unmap_single(dev, map, size, dir);\n\t\treturn phys_to_dma(dev, io_tlb_overflow_buffer);\n\t}\n\n\treturn dev_addr;\n}",
    "comment": "Maps a page of memory for DMA access, handling bounce buffers if the device cannot directly access the address.",
    "prorec_sum": "Maps a physical address range for DMA access, validates boundaries, and logs warnings if mapping fails or exceeds allowed memory limits.",
    "filter_prorec_sum": "Allocates or validates a DMA-accessible memory range, logging warnings for oversized regions and handling read, write, or random access types.",
    "prorec_aug_sum": "Validates and maps a given memory range for DMA access, logging warnings for unsafe read, write, or general access conditions.",
    "filter_prorec_aug_sum": "Validates and maps a DMA memory range, logging warnings for large random access patterns and handling errors or out-of-bounds conditions.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates and maps a given memory range for DMA access, logging warnings for unsafe read, write, or general access conditions.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains one main claim that the function validates and maps a memory range for DMA access, which is partially accurate since the code does check DMA capability and performs mapping. However, the claim that it logs warnings for unsafe read, write, or general access conditions is inaccurate \u2014 the code uses BUG_ON and error handling through bounce buffers, but no logging of warnings occurs. This makes the proportion of accurate content low, under 50%.",
                "The summary's main claim about validating and mapping memory for DMA access is only partially accurate\u2014it vaguely reflects the function's purpose but omits the core mechanism of mapping potentially non-DMA-capable physical pages either directly or via a bounce buffer, and handling failures. The mention of logging warnings for unsafe access is inaccurate, as the code calls error-handling routines without logging warnings, and does not specifically distinguish read/write/general conditions. Overall, the core domain action is missing in detail and most critical branches and side effects are not covered.",
                "The summary claims the function logs warnings for unsafe read, write, or general access, which is inaccurate because the code uses BUG_ON for invalid direction and handles bounce buffer allocation without any logging. While it does validate and map a memory range for DMA, the logging aspect is a severe factual error about the core side effects. This is a FATAL issue on the primary purpose side effects, making the description misleading despite the partial accuracy of the mapping validation claim."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates and maps a DMA memory range, logging warnings for large random access patterns and handling errors or out-of-bounds conditions.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains mostly inaccurate claims relative to the source code. While it correctly implies the function involves DMA mapping, it adds incorrect details about logging warnings for large random access patterns, which is not present. It also mentions handling out-of-bounds conditions in a generic way that does not reflect the actual error handling logic, which focuses on bounce buffer allocation and overflow scenarios. The high proportion of these unsupported statements results in low accuracy.",
                "The summary contains inaccuracies: it implies logging warnings for large random access patterns, which is not present in the code, and refers vaguely to 'out-of-bounds conditions' without reflecting the actual error handling and bounce buffer allocation logic. The core purpose\u2014mapping a page for DMA with swiotlb, returning device address directly if possible, or allocating/mapping a bounce buffer when needed\u2014is entirely missing. While the summary hints at validation and error handling generically, it omits critical domain-specific details like the swiotlb mechanism, dma_capable checks, and use of an overflow buffer.",
                "The summary's core claim about logging warnings for large random access patterns is not supported by the source code, making it a FATAL error regarding described behavior. Additionally, references to handling out-of-bounds conditions are inaccurate because the function does not perform range checks beyond 'dma_capable'. The only accurate portion is the generic statement that it handles mapping of a DMA memory range, which is low detail. The worst failure mode is a FATAL on described side effects, leading to untrustworthy documentation."
            ]
        }
    }
}
{
    "source_code": "\nasmlinkage int sys_modify_ldt(int func, void __user *ptr,\n\t\t\t      unsigned long bytecount)\n{\n\tint ret = -ENOSYS;\n\n\tswitch (func) {\n\tcase 0:\n\t\tret = read_ldt(ptr, bytecount);\n\t\tbreak;\n\tcase 1:\n\t\tret = write_ldt(ptr, bytecount, 1);\n\t\tbreak;\n\tcase 2:\n\t\tret = read_default_ldt(ptr, bytecount);\n\t\tbreak;\n\tcase 0x11:\n\t\tret = write_ldt(ptr, bytecount, 0);\n\t\tbreak;\n\t}\n\treturn ret;\n}",
    "comment": "The function modifies the local descriptor table (LDT) by reading or writing its entries based on the specified operation code.",
    "prorec_sum": "Handles different command types to transfer data from an internal buffer or directly to a target address, returning appropriate status or error codes.",
    "filter_prorec_sum": "Handles various command types to transfer or validate data buffers, including special cases for specific command IDs and staged memory copy operations.",
    "prorec_aug_sum": "Handles different command codes to transfer data between a buffer and a target address, returning success lengths or specific error codes.",
    "filter_prorec_aug_sum": "Handles different command codes to transfer data between a kernel buffer and a user address, enforcing size limits and returning status codes.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles different command codes to transfer data between a buffer and a target address, returning success lengths or specific error codes.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function handles different command codes, which aligns with the switch-case over `func` in the source code. However, it inaccurately describes the operations as transferring data between a buffer and a target address without reference to LDT-specific reads/writes, and incorrectly implies returning success lengths, which is not evident from the code. This mix of partial accuracy and misleading detail results in less than half of the claims being accurate.",
                "The summary is vague and generic, failing to identify the core purpose of the function, which is to read or write entries in the Local Descriptor Table depending on the 'func' argument. While it mentions handling different codes and data transfer, it omits the LDT-specific domain semantics and does not cover distinct operations like read_ldt, write_ldt with different flags, and read_default_ldt. No secondary details about specific cases, constants (0x11), or the returned error code initialization are included.",
                "The summary contains an inaccurate core claim: it describes transferring data between a buffer and a target address, which does not match the source code\u2019s actual behavior of reading and writing entries in the Local Descriptor Table based on function codes. This is a FATAL error affecting the primary purpose, as it misstates the domain semantics. While it mentions returning success lengths or error codes, that part is generic and safe. The severe mismatch on the main functionality renders the net benefit very low."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Handles different command codes to transfer data between a kernel buffer and a user address, enforcing size limits and returning status codes.",
            "score": [
                0.5,
                0.2,
                0.5
            ],
            "reason": [
                "The summary makes two distinct claims: that the function handles different command codes, and that it transfers data between a kernel buffer and a user address while enforcing size limits and returning status codes. The first claim is accurate, as the switch statement processes different func values and calls the corresponding read/write functions. However, the second claim is partially inaccurate: while data is passed to and from user space, the given code does not explicitly enforce size limits. The function does return status codes via 'ret'. Given this mix of correctness and inaccuracy, only part of the claims align with the source code.",
                "The summary omits the core purpose, which is to implement sys_modify_ldt to read or write Local Descriptor Table entries based on specific function codes. While it notes handling command codes generically, the 'transfer data between a kernel buffer and a user address' description is vague and not an accurate reflection of LDT-specific operations. It also incorrectly implies size limit enforcement, which is not visible in the provided code. No accurate domain-specific detail about reading/writing the LDT or the distinct handling of different func values is covered, leaving both the core action and key branches unaddressed.",
                "The summary correctly notes that different command codes trigger data transfer between kernel and user space, which aligns with the different read/write paths in the code. However, it inaccurately claims size limits are enforced, which is not evident in the provided source. The mention of returning status codes is generic and accurate but low-info. The main shortcoming is the inclusion of an incorrect size enforcement detail, which introduces noticeable noise while offering limited specific insight."
            ]
        }
    }
}
{
    "source_code": "\nstatic int usb_set_lpm_timeout(struct usb_device *udev,\n\t\tenum usb3_link_state state, int timeout)\n{\n\tint ret;\n\tint feature;\n\n\tswitch (state) {\n\tcase USB3_LPM_U1:\n\t\tfeature = USB_PORT_FEAT_U1_TIMEOUT;\n\t\tbreak;\n\tcase USB3_LPM_U2:\n\t\tfeature = USB_PORT_FEAT_U2_TIMEOUT;\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(&udev->dev, \"%s: Can't set timeout for non-U1 or U2 state.\\n\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (state == USB3_LPM_U1 && timeout > USB3_LPM_U1_MAX_TIMEOUT &&\n\t\t\ttimeout != USB3_LPM_DEVICE_INITIATED) {\n\t\tdev_warn(&udev->dev, \"Failed to set %s timeout to 0x%x, \"\n\t\t\t\t\"which is a reserved value.\\n\",\n\t\t\t\tusb3_lpm_names[state], timeout);\n\t\treturn -EINVAL;\n\t}\n\n\tret = set_port_feature(udev->parent,\n\t\t\tUSB_PORT_LPM_TIMEOUT(timeout) | udev->portnum,\n\t\t\tfeature);\n\tif (ret < 0) {\n\t\tdev_warn(&udev->dev, \"Failed to set %s timeout to 0x%x,\"\n\t\t\t\t\"error code %i\\n\", usb3_lpm_names[state],\n\t\t\t\ttimeout, ret);\n\t\treturn -EBUSY;\n\t}\n\tif (state == USB3_LPM_U1)\n\t\tudev->u1_params.timeout = timeout;\n\telse\n\t\tudev->u2_params.timeout = timeout;\n\treturn 0;\n}",
    "comment": "Sets the low power mode timeout for a USB device based on the specified USB 3.0 link state, validating the timeout value before applying it.",
    "prorec_sum": "Sets USB link power management timeout for U1 or U2 states, validating values and reporting errors when applying them to the device.",
    "filter_prorec_sum": "Sets USB port U1 or U2 low-power timeout values via control transfer, rejecting invalid states and reserved timing values with error logging.",
    "prorec_aug_sum": "Sets the USB device\u2019s U1 or U2 link power management timeout, validating values and reporting errors for unsupported states or reserved timings.",
    "filter_prorec_aug_sum": "Sets USB U1 or U2 power state timeout values and logs errors when given invalid or unsupported states or reserved timeout values.",
    "work_score": {
        "prorec_aug": {
            "summary": "Sets the USB device\u2019s U1 or U2 link power management timeout, validating values and reporting errors for unsupported states or reserved timings.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly identifies that the function sets the timeout for USB device U1 or U2 link power management states, validates certain values, and reports errors for unsupported states or reserved timings. These details align with the source code\u2019s logic for handling U1/U2 states, value checks, and error reporting, with no inaccuracies detected. All claims are accurate and relevant to the function\u2019s behavior.",
                "The summary correctly identifies the core purpose of setting the USB device\u2019s U1 or U2 link power management timeout, which matches the function\u2019s main domain action. It also notes validation of values and error reporting for unsupported states or reserved timings, aligning with the checks for non-U1/U2 states and reserved timeout values. However, it omits other significant secondary behaviors such as the distinct handling of EBUSY errors from set_port_feature, updating the device\u2019s u1_params/u2_params timeout fields, and specific constants used (like USB3_LPM_DEVICE_INITIATED). These omissions reduce completeness despite accurate core coverage.",
                "The summary correctly states that the function sets the USB device\u2019s U1 or U2 link power management timeout, performs validation on provided values, and reports errors for unsupported states (non-U1/U2) or reserved timings for U1. These claims align with the code\u2019s core behavior without introducing contradictions or irrelevant noise. However, the description is concise and omits some specifics such as the distinct handling of error codes (-EINVAL vs -EBUSY) and updating of internal timeout parameters, meaning the gain is moderate rather than high."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Sets USB U1 or U2 power state timeout values and logs errors when given invalid or unsupported states or reserved timeout values.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function sets timeout values for USB U1 and U2 power states and that it logs errors when provided with unsupported states or reserved timeout values. These points directly match the code's logic for handling valid states, rejecting unsupported ones, and checking for reserved timeout constraints. All claims are accurate and semantically aligned with the source code behavior.",
                "The summary accurately describes the core purpose of setting USB U1 or U2 link power management timeouts, which aligns with the function's main domain-specific operation. It also notes error logging for invalid states and reserved timeout values, covering some secondary semantics. However, it omits several important details such as the distinction between U1 and U2 maximum timeout checks, error codes returned for different failure cases, and the update of device-specific timeout parameters upon success.",
                "The summary accurately captures the primary purpose of setting USB U1 or U2 power state timeouts and notes error logging for invalid/unsupported states or reserved timeout values, both of which match the source code behavior. There are no inaccurate claims, and while the summary omits some details such as updating internal timeout parameters or differentiating between error codes (-EINVAL vs -EBUSY), the included facts are correct and focused. The gain is moderate due to being correct but relatively high-level."
            ]
        }
    }
}
{
    "source_code": "\nstatic struct rpc_cred *\nunx_create_cred(struct rpc_auth *auth, struct auth_cred *acred, int flags)\n{\n\tstruct unx_cred\t*cred;\n\tunsigned int groups = 0;\n\tunsigned int i;\n\n\tdprintk(\"RPC:       allocating UNIX cred for uid %d gid %d\\n\",\n\t\t\tfrom_kuid(&init_user_ns, acred->uid),\n\t\t\tfrom_kgid(&init_user_ns, acred->gid));\n\n\tif (!(cred = kmalloc(sizeof(*cred), GFP_NOFS)))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\trpcauth_init_cred(&cred->uc_base, acred, auth, &unix_credops);\n\tcred->uc_base.cr_flags = 1UL << RPCAUTH_CRED_UPTODATE;\n\n\tif (acred->group_info != NULL)\n\t\tgroups = acred->group_info->ngroups;\n\tif (groups > NFS_NGROUPS)\n\t\tgroups = NFS_NGROUPS;\n\n\tcred->uc_gid = acred->gid;\n\tfor (i = 0; i < groups; i++)\n\t\tcred->uc_gids[i] = GROUP_AT(acred->group_info, i);\n\tif (i < NFS_NGROUPS)\n\t\tcred->uc_gids[i] = INVALID_GID;\n\n\treturn &cred->uc_base;\n}",
    "comment": "Allocates and initializes a UNIX credential structure with user and group identifiers based on provided authentication credentials.",
    "prorec_sum": "Allocates and initializes a socket-like structure with request data, setting fixed fields and copying up to sixteen configuration integers from linked input structures.",
    "filter_prorec_sum": "Allocates and initializes a network socket structure, copying configuration data from the provided parameters with bounded array handling.",
    "prorec_aug_sum": "Allocates and initializes a structured object from input parameters, copies up to sixteen integer entries from a secondary structure, and sets default values when absent.",
    "filter_prorec_aug_sum": "Allocates and initializes a fixed-size structure, copies group-related integers from input data, and fills remaining entries with -1 when fewer than sixteen are provided.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and initializes a structured object from input parameters, copies up to sixteen integer entries from a secondary structure, and sets default values when absent.",
            "score": [
                0.6,
                0.3,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function allocates and initializes a structured object based on input parameters and sets default values when absent, which matches the allocation of `cred` and initialization via `rpcauth_init_cred`. However, the claim about copying up to sixteen integer entries is inaccurate because the code uses `NFS_NGROUPS` without specifying the number sixteen, and its actual value is not given in the source. This reduces claim accuracy, leading to mixed reliability.",
                "The summary accurately notes allocation and initialization of a structure from inputs, and that values are copied from a secondary structure with defaults when entries are absent. However, it omits the core domain purpose of creating an RPC UNIX credential, missing key specifics like handling UID, GID, group limits tied to NFS_NGROUPS, and use of rpcauth_init_cred. This means the main domain action is not covered, though some secondary behavior is described.",
                "The summary correctly captures the general allocation and initialization of a structure and mentions copying integer entries from a secondary structure with defaults when absent, which maps to copying group IDs and setting INVALID_GID if fewer than NFS_NGROUPS. However, it inaccurately specifies 'up to sixteen' entries, which contradicts the code's use of NFS_NGROUPS (a macro, not guaranteed to be 16). This is a specific semantic mismatch about a key loop limit, making it a FATAL error on a core detail (key input processing). Overall, the accurate parts are generic and low-info, but the fatal inaccuracy on numerical limit critically damages trust."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates and initializes a fixed-size structure, copies group-related integers from input data, and fills remaining entries with -1 when fewer than sixteen are provided.",
            "score": [
                0.9,
                0.3,
                0.2
            ],
            "reason": [
                "The summary correctly describes that the function allocates and initializes a structure, copies group-related values from the input, and fills remaining entries with an invalid marker when fewer than the maximum allowed groups are provided. The summary\u2019s reference to a fixed size and the sentinel value -1 aligns with the code\u2019s use of NFS_NGROUPS and INVALID_GID. While it omits some specifics such as setting uid/gid and flags, over 80% of its claims match the source code behavior accurately.",
                "The summary correctly notes the allocation and initialization of a structure, the copying of group-related values, and the use of a sentinel value when fewer than the maximum entries are provided. However, it omits the core primary purpose that the function creates and initializes a UNIX RPC credential, including setting flags and handling UID/GID from the input. It also misses constants like NFS_NGROUPS (rather than assuming a fixed sixteen), the initialization via rpcauth_init_cred, and error handling when allocation fails.",
                "The summary correctly states that the function allocates and initializes a fixed-size structure and copies group-related integers, and notes filling unused entries with -1 (INVALID_GID). However, it inaccurately fixes the limit to sixteen groups instead of using the actual NFS_NGROUPS constant from the code, which is a core I/O limit. This is a FATAL error affecting the primary behavior, as the group limit is misrepresented. The rest of the details are generic, with minimal specific insight beyond basic allocation and copying."
            ]
        }
    }
}
{
    "source_code": "\nvoid\nstatcmd (void)\n{\n  struct sockaddr_storage *sin;\n  unsigned char *a, *p;\n\n  lreply (211, \"%s FTP server status:\", hostname);\n  if (!no_version)\n    printf (\"     ftpd (%s) %s\\r\\n\", PACKAGE_NAME, PACKAGE_VERSION);\n  printf (\"     Connected to %s\", cred.remotehost);\n  (void) getnameinfo ((struct sockaddr *) &his_addr, his_addrlen,\n\t\t      addrstr, sizeof (addrstr), NULL, 0, NI_NUMERICHOST);\n  if (!isdigit (cred.remotehost[0]))\n    printf (\" (%s)\", addrstr);\n  printf (\"\\r\\n\");\n  printf (\"     Session timeout is %d seconds\\r\\n\", timeout);\n  if (cred.logged_in)\n    {\n      if (cred.guest)\n\tprintf (\"     Logged in anonymously\\r\\n\");\n      else\n\tprintf (\"     Logged in as %s\\r\\n\", cred.name);\n    }\n  else if (askpasswd)\n    printf (\"     Waiting for password\\r\\n\");\n  else\n    printf (\"     Waiting for user name\\r\\n\");\n  printf (\"     TYPE: %s\", typenames[type]);\n  if (type == TYPE_A || type == TYPE_E)\n    printf (\", FORM: %s\", formnames[form]);\n  if (type == TYPE_L)\n#ifdef CHAR_BIT\n    printf (\" %d\", CHAR_BIT);\n#else\n# if NBBY == 8\n    printf (\" %d\", NBBY);\n# else\n    printf (\" %d\", bytesize);\t/* need definition! */\n# endif\n#endif\n  printf (\"; STRUcture: %s; transfer MODE: %s\\r\\n\",\n\t  strunames[stru], modenames[stru_mode]);\n  if (data != -1)\n    printf (\"     Data connection open\\r\\n\");\n  else if (pdata != -1)\n    {\n      printf (\"     in Passive mode\");\n      sin = &pasv_addr;\n      goto printaddr;\n    }\n  else if (usedefault == 0)\n    {\n      printf (\"     PORT\");\n      sin = &data_dest;\n    printaddr:\n      a = (unsigned char *) & ((struct sockaddr_in *) sin)->sin_addr;\n      p = (unsigned char *) & ((struct sockaddr_in *) sin)->sin_port;\n#define UC(b) (((int) b) & 0xff)\n      printf (\" (%d,%d,%d,%d,%d,%d)\\r\\n\", UC (a[0]),\n\t      UC (a[1]), UC (a[2]), UC (a[3]), UC (p[0]), UC (p[1]));\n#undef UC\n    }\n  else\n    printf (\"     No data connection\\r\\n\");\n  reply (211, \"End of status\");\n}",
    "comment": "Displays the current status of the FTP server, including connection details, session timeout, user login status, data connection status, and transfer settings.",
    "prorec_sum": "Displays comprehensive FTP server status including connection info, session settings, login state, transfer parameters, and data connection details.",
    "filter_prorec_sum": "Outputs current FTP server and session status details, including connection info, login state, transfer settings, and data connection mode.",
    "prorec_aug_sum": "Displays the current FTP session status, including server info, login state, transfer settings, and data connection details, then ends with a status footer.",
    "filter_prorec_aug_sum": "Outputs a detailed FTP server status report including connection info, session parameters, login state, transfer settings, and data connection mode.",
    "work_score": {
        "prorec_aug": {
            "summary": "Displays the current FTP session status, including server info, login state, transfer settings, and data connection details, then ends with a status footer.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary accurately captures the core semantics of the function: it reports FTP session status, including server information, login state, transfer parameters, and data connection details, followed by a closing status message. All claims are correct and grounded in the source code behavior, with no extraneous or incorrect statements.",
                "The summary correctly identifies the function's core purpose: outputting the current FTP session status, and mentions accurate elements such as server info, login state, transfer settings, and data connection details. This covers the core domain action with sufficient specificity. However, it omits several secondary details present in the code, including the conditions for printing version info, how remote host numeric address and session timeout are displayed, distinctions between anonymous and named logins, the prompts for password or username, and specific passive/active connection address formatting. Coverage of secondary behavior-critical semantics is therefore incomplete.",
                "The summary correctly captures the primary purpose of the function \u2014 displaying FTP session status. It accurately mentions server info, login state, transfer settings, and data connection details, all of which are present in the code. It also notes that the output ends with a footer message, matching the final reply call. There is no factual inaccuracy or irrelevant noise, but the description is general and lacks deeper, specific details such as exact fields printed or conditional variations, resulting in only moderate informational gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Outputs a detailed FTP server status report including connection info, session parameters, login state, transfer settings, and data connection mode.",
            "score": [
                1.0,
                0.8,
                0.6
            ],
            "reason": [
                "The summary accurately reflects the function's behavior: it outputs an FTP server status including connection information, session parameters, login state, transfer settings, and data connection mode. All these elements match the source code, which uses various printf calls to display hostname, version info, login details, transfer type/structure/mode, and data connection state. No inaccuracies or irrelevant information are present, making all claims accurate.",
                "The summary accurately conveys the core purpose of the function: generating a detailed FTP server status report with specifics on connection info, session parameters, login state, transfer settings, and data connection mode. This matches the source code's primary domain action and covers major secondary semantics such as data connection states and transfer settings. However, it omits certain details like passive mode address printing, exact handling of username/password prompts, and formatting nuances, so coverage is strong but not exhaustive.",
                "The summary correctly states that the function outputs a detailed FTP server status report, covering connection information, session parameters, login state, transfer settings, and data connection mode \u2014 all of which align with the code\u2019s behavior. There are no inaccurate claims, but the description is broad and generic with low detail, providing SAFE-level accuracy without specific GOLD insights. Noise is minimal and accuracy is maintained, resulting in moderate gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic ssize_t snd_pcm_oss_write2(struct snd_pcm_substream *substream, const char *buf, size_t bytes, int in_kernel)\n{\n\tstruct snd_pcm_runtime *runtime = substream->runtime;\n\tsnd_pcm_sframes_t frames, frames1;\n#ifdef CONFIG_SND_PCM_OSS_PLUGINS\n\tif (runtime->oss.plugin_first) {\n\t\tstruct snd_pcm_plugin_channel *channels;\n\t\tsize_t oss_frame_bytes = (runtime->oss.plugin_first->src_width * runtime->oss.plugin_first->src_format.channels) / 8;\n\t\tif (!in_kernel) {\n\t\t\tif (copy_from_user(runtime->oss.buffer, (const char __force __user *)buf, bytes))\n\t\t\t\treturn -EFAULT;\n\t\t\tbuf = runtime->oss.buffer;\n\t\t}\n\t\tframes = bytes / oss_frame_bytes;\n\t\tframes1 = snd_pcm_plug_client_channels_buf(substream, (char *)buf, frames, &channels);\n\t\tif (frames1 < 0)\n\t\t\treturn frames1;\n\t\tframes1 = snd_pcm_plug_write_transfer(substream, channels, frames1);\n\t\tif (frames1 <= 0)\n\t\t\treturn frames1;\n\t\tbytes = frames1 * oss_frame_bytes;\n\t} else\n#endif\n\t{\n\t\tframes = bytes_to_frames(runtime, bytes);\n\t\tframes1 = snd_pcm_oss_write3(substream, buf, frames, in_kernel);\n\t\tif (frames1 <= 0)\n\t\t\treturn frames1;\n\t\tbytes = frames_to_bytes(runtime, frames1);\n\t}\n\treturn bytes;\n}",
    "comment": "Writes audio data from a buffer to a PCM substream, handling potential OSS plugin processing and user-kernel memory copying.",
    "prorec_sum": "Processes audio PCM substream write operations, handling buffer preparation, data copying, and frame size conversions depending on hardware configuration.",
    "filter_prorec_sum": "Processes and writes PCM audio data from a substream, handling both mmap-enabled and standard buffer copy modes with frame size adjustments.",
    "prorec_aug_sum": "Processes PCM substream data transfer, adjusting for hardware buffer size and invoking appropriate routines based on hardware state and provided parameters.",
    "filter_prorec_aug_sum": "Processes PCM substream data, adjusting frames based on hardware parameters, and delegates handling to appropriate routines depending on hardware configuration presence.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes PCM substream data transfer, adjusting for hardware buffer size and invoking appropriate routines based on hardware state and provided parameters.",
            "score": [
                0.5,
                0.3,
                0.5
            ],
            "reason": [
                "The summary makes a generic claim about processing PCM substream data and selecting routines based on state and parameters, which is somewhat aligned with the code\u2019s logic of branching between plugin handling and direct write depending on runtime state. However, it inaccurately introduces 'adjusting for hardware buffer size', which is not explicitly represented in the code. The description lacks specificity about key operations like 'copy_from_user', conversion between bytes and frames, and use of plugin-specific parameters. As such, only part of the claim is accurate, while some details are incorrect or overly vague.",
                "The summary vaguely describes processing a PCM substream and adjusting for hardware conditions but does not specifically cover the core purpose, which is handling OSS plugin or fallback paths, copying data from user space if needed, converting between bytes and frames, and invoking the appropriate write transfer or oss_write3 functions. Key behaviors such as conditional plugin processing, copy_from_user handling, and conversions are omitted, leaving only generic references to data transfer and hardware state.",
                "The summary gives a very generic description of processing PCM substream data and invoking routines based on state, which aligns broadly with the code\u2019s conditional paths and calls. However, it inaccurately adds the claim about adjusting for hardware buffer size, which is not explicitly reflected in the code\u2014the function uses buffer/frame conversions and plugins, not direct hardware buffer size adjustments. This is a minor semantic mismatch (NOISE) rather than a fatal error, but it reduces precision. The accurate parts are low\u2011info, providing little engineering insight."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes PCM substream data, adjusting frames based on hardware parameters, and delegates handling to appropriate routines depending on hardware configuration presence.",
            "score": [
                0.6,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function processes PCM substream data and delegates handling to different routines based on configuration, which matches the plugin-first conditional logic in the code. However, it inaccurately attributes frame adjustments specifically to hardware parameters, while the code shows adjustments based on plugin configurations and conversions between bytes and frames\u2014not explicitly hardware parameters. The overall description is generic and omits key details like user-space data copying and specific plugin handling, making only part of the claim set accurate.",
                "The summary correctly notes that the function processes PCM substream data and calls different routines depending on configuration, which matches the plugin vs non-plugin branch in the code. However, it does not cover the core purpose with sufficient specificity: the function\u2019s specific role is to write PCM data via OSS interface, including conversion between bytes and frames, optional copy from user buffer, plugin channel preparation, and transfer. Important details like handling in-kernel vs user space data, error returns from transfer calls, and frame-byte conversions are omitted, leaving coverage of secondary semantics weak.",
                "The summary makes two main claims: that the function processes PCM substream data and that it adjusts frames based on hardware parameters, delegating to the correct routine depending on configuration. The first claim is accurate and aligns with the code's handling of PCM substream processing. The second claim is partially inaccurate: the function bases its control flow on whether an OSS plugin is present, not directly on hardware parameters; also, 'hardware configuration' is a misleading term here. This is a mild semantic inaccuracy, not a severe FATAL, but it introduces noise. The accurate claim is generic and low-info, and with misleading specificity in the other claim, the positive gain is low."
            ]
        }
    }
}
{
    "source_code": "static int\nbackward_move_node_structure (WINDOW *window, int behaviour)\n{\n  if (window->node->flags & (N_IsInternal | N_IsManPage))\n    return 1;\n\n  switch (behaviour)\n    {\n    case IS_PageOnly:\n      info_error (\"%s\", msg_at_node_top);\n      return 1;\n\n    case IS_NextOnly:\n      return !info_handle_pointer (\"Prev\", window);\n      break;\n\n    case IS_Continuous:\n      if (window->node->up)\n        {\n          /* If up is the dir node, we are at the top node.\n             Don't do anything. */\n          if (!strncasecmp (window->node->up, \"(dir)\", strlen (\"(dir)\")))\n            {\n              info_error (\"%s\", _(\"No 'Prev' or 'Up' for this node within this document\"));\n              return 1;\n            }\n          /* If 'Prev' and 'Up' are the same, we are at the first node\n             of the 'Up' node's menu. Go to up node. */\n          else if (window->node->prev\n              && !strcmp(window->node->prev, window->node->up))\n            {\n              if (!info_handle_pointer (\"Up\", window))\n                return 1;\n            }\n          /* Otherwise, go to 'Prev' node and go down the last entry\n             in the menus as far as possible. */\n          else if (window->node->prev)\n            {\n              int starting_hist_index = window->hist_index;\n              if (!info_handle_pointer (\"Prev\", window))\n                return 1;\n              if (!(window->node->flags & N_IsIndex))\n                {\n                  while (1)\n                    {\n                      REFERENCE *entry = select_menu_digit (window, '0');\n                      if (!entry)\n                        break;\n                      if (!info_select_reference (window, entry))\n                        break;\n                    }\n                  /* Don't include intermediate nodes in the window's\n                     history.  */\n                  cleanup_history (window, starting_hist_index,\n                                   window->hist_index - 1);\n                }\n            }\n          else /* 'Up' but no 'Prev' */\n            {\n              if (!info_handle_pointer (\"Up\", window))\n                return 1;\n            }\n        }\n      else if (window->node->prev) /* 'Prev' but no 'Up' */\n        {\n          if (!info_handle_pointer (\"Prev\", window))\n            return 1;\n        }\n      else\n        {\n          info_error (\"%s\", _(\"No 'Prev' or 'Up' for this node within this document\"));\n          return 1;\n        }\n\n      break; /* case IS_Continuous: */\n    }\n  return 0;\n}",
    "comment": "Handles backward navigation in a document's node structure based on specified behavior, managing transitions to previous or upward nodes as necessary.",
    "prorec_sum": "Determines and executes navigation to \u201cPrev\u201d or \u201cUp\u201d nodes, handling directory markers and displaying an error if such navigation is unavailable.",
    "filter_prorec_sum": "Determines navigation availability and performs actions for \u201cPrev\u201d or \u201cUp\u201d document nodes, displaying an error message when neither is accessible.",
    "prorec_aug_sum": "Determines navigation availability for \u201cPrev\u201d or \u201cUp\u201d within a document, performing related actions or showing an error message when these links are absent.",
    "filter_prorec_aug_sum": "Determines navigation actions within a document, executing \u201cPrev\u201d or \u201cUp\u201d commands or showing an error when those links are unavailable.",
    "work_score": {
        "prorec_aug": {
            "summary": "Determines navigation availability for \u201cPrev\u201d or \u201cUp\u201d within a document, performing related actions or showing an error message when these links are absent.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function deals with navigation using 'Prev' and 'Up' links and shows an error when these are absent, which aligns with the core logic in the source code. However, it omits the distinction between different behaviours (IS_PageOnly, IS_NextOnly, IS_Continuous) and detailed handling paths such as when 'Up' is '(dir)' or when 'Prev' equals 'Up'. These missing specifics make the summary less precise and comprehensive, though it remains mostly accurate.",
                "The summary correctly identifies that the function checks for the presence of 'Prev' or 'Up' links and either navigates or shows an error if absent, which matches the core purpose of handling node navigation in different cases. However, it omits critical branching behaviors based on the 'behaviour' parameter (IS_PageOnly, IS_NextOnly, IS_Continuous), the handling of special node flags (N_IsInternal, N_IsManPage, N_IsIndex), and the multi-step process for Continuous mode (menu traversal, history cleanup). Coverage of secondary semantics like iteration through menus is missing, so while the core action is captured, detail and breadth are weak.",
                "The summary accurately captures the primary purpose of the function: checking for the availability of 'Prev' or 'Up' nodes and either navigating accordingly or displaying an error when unavailable. It omits detailed branching based on behaviour values (IS_PageOnly, IS_NextOnly, IS_Continuous) and specific fallback navigation logic, but contains no incorrect claims. The gain is low since the summary is broad and lacks key specifics, yet noise is minimal and there are no fatal inaccuracies."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Determines navigation actions within a document, executing \u201cPrev\u201d or \u201cUp\u201d commands or showing an error when those links are unavailable.",
            "score": [
                0.9,
                0.4,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function controls navigation within a document, executes 'Prev' or 'Up' commands, and shows an error when those links are unavailable, which aligns with the source code's branching logic for different behaviours. Although it omits specific cases like IS_PageOnly and detailed conditions for choosing 'Prev' vs 'Up', the claims made are accurate and free of contradictions.",
                "The summary accurately captures the core purpose of navigating within a document using 'Prev' or 'Up' links and handling errors when these links are absent, which aligns with the main domain-specific behavior in the source code. However, it omits important secondary details such as handling different behaviours (IS_PageOnly, IS_NextOnly, IS_Continuous), special cases like internal/manpage nodes, menu traversal, history cleanup, and index checks. The coverage of secondary semantics is weak despite correct core coverage.",
                "The summary accurately describes the primary purpose of the function: navigating within a document by following 'Prev' or 'Up' links and showing an error if unavailable. This matches the source code's core logic handling different navigation modes. There are no inaccuracies or irrelevant noise, but the summary is generic and omits specific branching behaviors (e.g., IS_PageOnly, IS_NextOnly, IS_Continuous cases) and edge cases handled in the code, so the gain is moderate rather than high."
            ]
        }
    }
}
{
    "source_code": "\nstatic void *\ndogleg_alloc (const void * params, const size_t n, const size_t p)\n{\n  dogleg_state_t *state;\n  \n  state = calloc(1, sizeof(dogleg_state_t));\n  if (state == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate dogleg state\", GSL_ENOMEM);\n    }\n\n  state->dx_gn = gsl_vector_alloc(p);\n  if (state->dx_gn == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for dx_gn\", GSL_ENOMEM);\n    }\n\n  state->dx_sd = gsl_vector_alloc(p);\n  if (state->dx_sd == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for dx_sd\", GSL_ENOMEM);\n    }\n\n  state->workp1 = gsl_vector_alloc(p);\n  if (state->workp1 == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for workp1\", GSL_ENOMEM);\n    }\n\n  state->workp2 = gsl_vector_alloc(p);\n  if (state->workp2 == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for workp2\", GSL_ENOMEM);\n    }\n\n  state->workn = gsl_vector_alloc(n);\n  if (state->workn == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for workn\", GSL_ENOMEM);\n    }\n\n  state->n = n;\n  state->p = p;\n  state->params = *(const gsl_multilarge_nlinear_parameters *) params;\n\n  return state;\n}",
    "comment": "Allocates memory for a dogleg optimization state and its associated vectors, initializing parameters for nonlinear optimization.",
    "prorec_sum": "Allocates and initializes a dogleg solver state structure with multiple GSL vectors, copying parameters and data from the provided source structure.",
    "filter_prorec_sum": "Allocates and initializes a GSL dogleg minimizer state structure with required working vectors, copying initial parameters from the provided source state.",
    "prorec_aug_sum": "Allocates and initializes a dogleg method state structure with multiple GSL vectors, copying initial parameters from the provided source structure.",
    "filter_prorec_aug_sum": "Allocates and initializes a GSL-based dogleg state structure with working vectors, copying parameters and initial data from an existing state.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and initializes a dogleg method state structure with multiple GSL vectors, copying initial parameters from the provided source structure.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function allocates and initializes a dogleg method state structure and several GSL vectors, and that it copies parameters from the provided structure. These details align with the code, which uses calloc and gsl_vector_alloc for allocations, and assigns parameters via a casted copy. All claims are accurate and directly supported by the source.",
                "The summary correctly identifies that the function allocates and initializes a dogleg state structure and copies parameters from the provided structure, which covers the core purpose. It also notes that multiple GSL vectors are allocated. However, it omits important secondary details such as the exact vector names, handling of both 'n' and 'p' dimensions, and explicit error handling for allocation failures, leaving coverage incomplete.",
                "The summary accurately states the primary purpose of the function: allocating and initializing a dogleg_state_t structure with multiple GSL vectors and copying parameters from the input. All claims are supported by the source code, with no false statements or irrelevant noise. While correct, the description is concise and lacks detailed specifics about error handling or the exact vectors allocated, so the informational gain is moderate rather than high."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates and initializes a GSL-based dogleg state structure with working vectors, copying parameters and initial data from an existing state.",
            "score": [
                0.5,
                0.4,
                0.4
            ],
            "reason": [
                "The summary correctly states that the function allocates and initializes a GSL-based dogleg state structure with working vectors and that it copies parameters. However, it inaccurately claims that initial data is copied from an existing state; in reality, the function initializes a new state and only copies parameters from the provided params struct, with no indication of copying initial data from another state. This makes about half of the claims accurate, and half inaccurate.",
                "The summary correctly states that the function allocates and initializes a GSL-based dogleg state structure with working vectors, and mentions copying parameters, which aligns with setting state->params from the passed-in params. However, it inaccurately claims copying initial data from an existing state, which does not occur in the source code. While the core purpose of allocating and initializing the dogleg state is covered, the incorrect extra detail lowers accuracy and there is little coverage of error handling or specifics about multiple vector allocations.",
                "The summary correctly states that the function allocates and initializes a GSL-based dogleg state with working vectors and copies parameters from the provided input, which matches the source code. However, it inaccurately claims that initial data is copied from an existing state \u2014 the function only copies parameters from a struct, not any existing state data. This is a factual error about the function's behavior. The misstatement impacts the description of the primary purpose moderately but does not entirely mislead about core allocation logic. Noise is minimal, but the incorrect 'initial data from existing state' element is the worst issue."
            ]
        }
    }
}
{
    "source_code": "\n\nngx_int_t\nngx_os_init(ngx_log_t *log)\n{\n    ngx_time_t  *tp;\n    ngx_uint_t   n;\n#if (NGX_HAVE_LEVEL1_DCACHE_LINESIZE)\n    long         size;\n#endif\n\n#if (NGX_HAVE_OS_SPECIFIC_INIT)\n    if (ngx_os_specific_init(log) != NGX_OK) {\n        return NGX_ERROR;\n    }\n#endif\n\n    if (ngx_init_setproctitle(log) != NGX_OK) {\n        return NGX_ERROR;\n    }\n\n    ngx_pagesize = getpagesize();\n    ngx_cacheline_size = NGX_CPU_CACHE_LINE;\n\n    for (n = ngx_pagesize; n >>= 1; ngx_pagesize_shift++) { /* void */ }\n\n#if (NGX_HAVE_SC_NPROCESSORS_ONLN)\n    if (ngx_ncpu == 0) {\n        ngx_ncpu = sysconf(_SC_NPROCESSORS_ONLN);\n    }\n#endif\n\n    if (ngx_ncpu < 1) {\n        ngx_ncpu = 1;\n    }\n\n#if (NGX_HAVE_LEVEL1_DCACHE_LINESIZE)\n    size = sysconf(_SC_LEVEL1_DCACHE_LINESIZE);\n    if (size > 0) {\n        ngx_cacheline_size = size;\n    }\n#endif\n\n    ngx_cpuinfo();\n\n    if (getrlimit(RLIMIT_NOFILE, &rlmt) == -1) {\n        ngx_log_error(NGX_LOG_ALERT, log, errno,\n                      \"getrlimit(RLIMIT_NOFILE) failed\");\n        return NGX_ERROR;\n    }\n\n    ngx_max_sockets = (ngx_int_t) rlmt.rlim_cur;\n\n#if (NGX_HAVE_INHERITED_NONBLOCK || NGX_HAVE_ACCEPT4)\n    ngx_inherited_nonblocking = 1;\n#else\n    ngx_inherited_nonblocking = 0;\n#endif\n\n    tp = ngx_timeofday();\n    srandom(((unsigned) ngx_pid << 16) ^ tp->sec ^ tp->msec);\n\n    return NGX_OK;\n}",
    "comment": "Initializes operating system parameters, retrieves CPU information, sets process title, and configures resource limits for a server application.",
    "prorec_sum": "Initializes OS-specific parameters, retrieves system page size, CPU and cache info, sets resource limits, and seeds the random number generator for Nginx.",
    "filter_prorec_sum": "Initializes OS-specific settings for Nginx, determines system page and cache parameters, retrieves resource limits, and seeds the random number generator.",
    "prorec_aug_sum": "Initializes OS-specific settings, detects CPU and memory parameters, configures resource limits, and seeds randomness for the Nginx runtime environment.",
    "filter_prorec_aug_sum": "Initializes Nginx OS-specific settings, determines CPU and memory parameters, configures resource limits, and seeds the random number generator.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes OS-specific settings, detects CPU and memory parameters, configures resource limits, and seeds randomness for the Nginx runtime environment.",
            "score": [
                1.0,
                0.8,
                0.6
            ],
            "reason": [
                "The summary captures multiple accurate behaviors from the source code: OS-specific initialization, CPU detection, page size (memory-related) configuration, resource limit setting via getrlimit, and randomness seeding using process and time data. All listed claims correspond directly to verifiable actions in the function, with no evident inaccuracies or irrelevant statements, indicating a strong match to the code semantics.",
                "The summary correctly captures the core purpose of performing OS-level initialization for Nginx, including setting CPU characteristics, memory/page parameters, resource limits, and randomness seeding. These align with the code\u2019s operations like getting page size, CPU cacheline size, number of CPUs, max sockets from getrlimit, and srandom. However, it omits certain secondary but behavior-relevant details, such as invoking ngx_os_specific_init, setting process title, safeguards for default CPU count, handling of RLIMIT_NOFILE failures, and enabling inherited nonblocking based on compile-time options. Coverage is good for the core and many secondary points, but not exhaustive.",
                "The summary correctly states the function initializes OS-specific settings, detects CPU parameters, configures resource limits, and seeds randomness, all of which are evident in the source code. The mention of memory parameters is slightly imprecise since the function primarily handles page size and cache line size rather than broader memory settings, but this is minor and not a fatal error. Overall, the claims are accurate but generic, offering limited specific detail about the functions called or exact values handled, resulting in low informational gain with minimal noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes Nginx OS-specific settings, determines CPU and memory parameters, configures resource limits, and seeds the random number generator.",
            "score": [
                1.0,
                0.7,
                0.8
            ],
            "reason": [
                "The summary contains accurate claims: it correctly notes OS-specific initialization, CPU parameter determination, setting of resource limits, and seeding of the random generator. Memory parameters are also addressed by setting page size and cache line size. All elements align with the source code behavior, with no inaccuracies or irrelevant statements.",
                "The summary correctly identifies the core purpose as initializing OS-specific settings, which aligns with the main function of ngx_os_init. It also accurately notes secondary actions: determining CPU parameters (via sysconf and related settings), memory parameters (page size, cache line size), configuring resource limits (getrlimit for max sockets), and seeding the random number generator. However, it omits certain secondary details like setting inherited non-blocking mode, calling ngx_cpuinfo, and handling failure cases for OS-specific init and setproctitle. Overall, the core is covered with several key secondary behaviors, but not all are mentioned.",
                "The summary accurately reflects the primary purpose and key operations in the code: it mentions initializing OS-specific settings (covers ngx_os_specific_init and ngx_init_setproctitle), determining CPU parameters (includes ngx_ncpu detection), memory parameters (pagesize and cacheline size), configuring resource limits (getrlimit for RLIMIT_NOFILE), and seeding the RNG (srandom with time and pid). All claims are verifiable against the source and there is no contradictory or irrelevant noise. The gains are moderate because the descriptions are correct but somewhat broad rather than deeply specific."
            ]
        }
    }
}
{
    "source_code": "static int tcp_match_skb_to_sack(struct sock *sk, struct sk_buff *skb,\n\t\t\t\t  u32 start_seq, u32 end_seq)\n{\n\tint err;\n\tbool in_sack;\n\tunsigned int pkt_len;\n\tunsigned int mss;\n\n\tin_sack = !after(start_seq, TCP_SKB_CB(skb)->seq) &&\n\t\t  !before(end_seq, TCP_SKB_CB(skb)->end_seq);\n\n\tif (tcp_skb_pcount(skb) > 1 && !in_sack &&\n\t    after(TCP_SKB_CB(skb)->end_seq, start_seq)) {\n\t\tmss = tcp_skb_mss(skb);\n\t\tin_sack = !after(start_seq, TCP_SKB_CB(skb)->seq);\n\n\t\tif (!in_sack) {\n\t\t\tpkt_len = start_seq - TCP_SKB_CB(skb)->seq;\n\t\t\tif (pkt_len < mss)\n\t\t\t\tpkt_len = mss;\n\t\t} else {\n\t\t\tpkt_len = end_seq - TCP_SKB_CB(skb)->seq;\n\t\t\tif (pkt_len < mss)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* Round if necessary so that SACKs cover only full MSSes\n\t\t * and/or the remaining small portion (if present)\n\t\t */\n\t\tif (pkt_len > mss) {\n\t\t\tunsigned int new_len = (pkt_len / mss) * mss;\n\t\t\tif (!in_sack && new_len < pkt_len) {\n\t\t\t\tnew_len += mss;\n\t\t\t\tif (new_len > skb->len)\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tpkt_len = new_len;\n\t\t}\n\t\terr = tcp_fragment(sk, skb, pkt_len, mss);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\treturn in_sack;\n}",
    "comment": "Determines if a TCP segment belongs to the SACK range and fragments it accordingly based on MSS and sequence numbers.",
    "prorec_sum": "Validates offsets against stored bounds and segment size, invoking a helper to process data when within range, else returning error or limit status.",
    "filter_prorec_sum": "Validates positional offsets against configured limits and segment sizes, invoking a helper to process within range or returning specific status codes otherwise.",
    "prorec_aug_sum": "Validates packet size against path MTU and invokes adjustment logic to handle fragmentation or transmission constraints based on route and offset parameters.",
    "filter_prorec_aug_sum": "Checks packet position against stored offsets and segment size, invoking a helper to process available data or returning specific error/status codes.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates packet size against path MTU and invokes adjustment logic to handle fragmentation or transmission constraints based on route and offset parameters.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims involve path MTU validation, route-based transmission constraints, and offset parameters, none of which are present in the source code. The actual function checks whether a TCP segment is within a SACK range, adjusts segment length to match MSS boundaries, and fragments if needed. As none of the summary's fact-based claims accurately describe the code's semantics, the proportion of accurate claims is 0%.",
                "The summary's claims about validating packet size against path MTU and handling fragmentation or transmission constraints based on route and offset parameters are inaccurate for the provided function. The actual function determines if a TCP segment sequence range is within a SACK range and conditionally fragments the skb based on MSS and sequence offsets, without reference to path MTU, routes, or generic transmission constraints. The core purpose of matching a TCP skb against SACK ranges and possible fragmentation aligned with MSS is not covered, and no accurate claims are present.",
                "The summary's claim that the function validates packet size against path MTU and uses route/offset parameters is inaccurate because the code handles SACK sequence matching within TCP, not path MTU checks or routing. This is a FATAL error on the primary purpose, as the core functionality is misrepresented. There are no accurate claims present, so the net benefit is negative."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Checks packet position against stored offsets and segment size, invoking a helper to process available data or returning specific error/status codes.",
            "score": [
                0.6,
                0.2,
                0.4
            ],
            "reason": [
                "The summary makes generic claims about checking packet positions, segment size, invoking a helper, and returning error/status codes, which loosely align with the code\u2019s operations. However, it omits key specifics such as the in_sack logic, conditional fragmentation based on MSS rounding, and the exact conditions for returning -EINVAL or 0. The claims are mostly accurate but overly generalized, missing significant domain-semantic details, resulting in moderate precision.",
                "The summary gives a generic description of checking packet positions and invoking a helper, but it fails to explicitly capture the core purpose: determining whether an skb falls within a SACK block and potentially fragmenting it to align with MSS/SACK boundaries. While 'checks packet position' is loosely related to sequence comparisons, it omits the SACK-specific logic, multi-packet handling, MSS alignment, and specific return semantics. Secondary behaviors like error handling via -EINVAL and conditional fragmentation are absent, leaving both core coverage and secondary detail weak.",
                "The summary makes a generic claim about checking packet position and segment size, which loosely aligns with the function's use of sequence comparisons and MSS values ([ACCURATE, SAFE]). However, it omits key specifics such as SACK inclusion logic, conditional fragmentation based on MSS rounding, and the exact role of tcp_fragment. The phrase 'process available data' is vague and introduces noise by not targeting the actual semantics, and error/status codes are mentioned generically without details. No FATAL errors occur, but the lack of specificity means the gain is low and noise is noticeable."
            ]
        }
    }
}
{
    "source_code": "static int o_save_ptr_helper(o_string *o, int n)\n{\n\tchar **list = (char**)o->data;\n\tint string_start;\n\tint string_len;\n\n\tif (!o->has_empty_slot) {\n\t\tstring_start = ((n + 0xf) & ~0xf) * sizeof(list[0]);\n\t\tstring_len = o->length - string_start;\n\t\tif (!(n & 0xf)) { /* 0, 0x10, 0x20...? */\n\t\t\tdebug_printf_list(\"list[%d]=%d string_start=%d (growing)\\n\", n, string_len, string_start);\n\t\t\t/* list[n] points to string_start, make space for 16 more pointers */\n\t\t\to->maxlen += 0x10 * sizeof(list[0]);\n\t\t\to->data = xrealloc(o->data, o->maxlen + 1);\n\t\t\tlist = (char**)o->data;\n\t\t\tmemmove(list + n + 0x10, list + n, string_len);\n\t\t\to->length += 0x10 * sizeof(list[0]);\n\t\t} else {\n\t\t\tdebug_printf_list(\"list[%d]=%d string_start=%d\\n\",\n\t\t\t\t\tn, string_len, string_start);\n\t\t}\n\t} else {\n\t\t/* We have empty slot at list[n], reuse without growth */\n\t\tstring_start = ((n+1 + 0xf) & ~0xf) * sizeof(list[0]); /* NB: n+1! */\n\t\tstring_len = o->length - string_start;\n\t\tdebug_printf_list(\"list[%d]=%d string_start=%d (empty slot)\\n\",\n\t\t\t\tn, string_len, string_start);\n\t\to->has_empty_slot = 0;\n\t}\n\to->has_quoted_part = 0;\n\tlist[n] = (char*)(uintptr_t)string_len;\n\treturn n + 1;\n}",
    "comment": "Reallocates string storage for a list, handles empty slots, and updates the length and state of the string data structure.",
    "prorec_sum": "Updates an entry in a table, allocating and initializing new storage when needed, then writes the computed offset and returns the next index.",
    "filter_prorec_sum": "Updates an entry in a structured memory table, allocating and initializing a new block when aligned conditions are met.",
    "prorec_aug_sum": "Updates an entry in a data structure, allocating and initializing a new block when needed, then stores the computed offset and advances the index.",
    "filter_prorec_aug_sum": "Updates an entry in a table, allocating and initializing a new block when needed, then stores a size-adjusted offset for the given index.",
    "work_score": {
        "prorec_aug": {
            "summary": "Updates an entry in a data structure, allocating and initializing a new block when needed, then stores the computed offset and advances the index.",
            "score": [
                0.9,
                0.3,
                0.5
            ],
            "reason": [
                "The summary captures the general behavior of updating an entry and allocating when needed, which aligns with the code\u2019s conditional growth of the list and reuse of empty slots. It correctly notes storing an offset and advancing the index. However, it omits specific details of pointer manipulation, empty slot handling, and offset calculation logic, making the claims largely generic and safe rather than detailed and domain-specific. The accuracy is high but the informativeness is limited.",
                "The summary vaguely describes updating a data structure and allocating a block, but it does not explicitly cover the core purpose of shifting a list of string pointers with potential growth in blocks of 16 elements and handling reuse when an empty slot exists. It omits key domain specifics like the pointer list structure, conditional growth logic, use of `memmove`, and updating structural metadata fields, providing only a generic description of allocation and index advancement.",
                "The summary captures the broad purpose of updating an entry and potentially allocating when needed, along with storing an offset and advancing an index. However, it omits important specifics such as the 16-entry growth increments, handling of 'has_empty_slot' without growth, the recalculation of string_start, shifting of existing pointers, and resetting of 'has_quoted_part'. While there are no contradictory inaccuracies (no FATAL), the description is overly generic and lacks the detailed, domain-specific behaviors visible in the code, resulting in low informational gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Updates an entry in a table, allocating and initializing a new block when needed, then stores a size-adjusted offset for the given index.",
            "score": [
                0.8,
                0.4,
                0.2
            ],
            "reason": [
                "The summary claims that the function updates a table entry, allocates and initializes a new block when needed, and stores a size-adjusted offset for the given index. The source code confirms that it updates an entry in a list, conditionally reallocates memory to grow capacity, and stores a calculated value into the list at the given index. However, 'initializing a new block' is somewhat misleading, as the code reallocates existing data rather than allocating and initializing a distinct new block. Overall, the claims are mostly accurate but include slight vagueness and minor imprecision in terminology.",
                "The summary\u2019s core claim about updating an entry in a table and conditionally allocating a new block loosely maps to the function\u2019s real operation of inserting a pointer into an array and reallocating memory when there\u2019s no empty slot every 16 entries. However, it omits critical domain-specific details such as the padding/alignment computation, specific handling of empty slots without growth, the debug logging, and the resetting of flags. It also generalizes \u2018allocating and initializing a new block\u2019 without capturing the actual pointer table shifting logic. While the core idea of conditional growth is touched, coverage of secondary and edge-case semantics is minimal.",
                "The summary contains a FATAL in describing the core purpose: the function does not store a 'size-adjusted offset', but actually stores the string length cast to a pointer at the given index. It also oversimplifies by calling the structure a 'table' and omitting critical behavior around handling the has_empty_slot flag and moving existing data to grow the list. While there is some slight alignment in mentioning reallocation when needed, this is outweighed by the incorrect characterization of the main action, leading to untrustworthiness for core semantics."
            ]
        }
    }
}
{
    "source_code": "\nvoid\ndatamash_ops_free ( struct datamash_ops* p )\n{\n  assert (p != NULL);                            /* LCOV_EXCL_LINE */\n  for (size_t i=0; i<p->num_grps; ++i)\n    free (p->grps[i].name);\n  free (p->grps);\n  p->grps = NULL;\n\n  #ifndef _STANDALONE_\n  for (size_t i=0; i<p->num_ops; ++i)\n    field_op_free (&p->ops[i]);\n  #endif\n\n  free (p->ops);\n  p->ops = NULL;\n\n  for  (size_t i=0; i<_fields_used; ++i) {\n    free (_fields[i].name);\n  }\n  free (_fields);\n  _fields = NULL;\n  _fields_alloc = 0;\n  _fields_used = 0;\n\n  free (_params);\n  _params_alloc = 0;\n  _params_used = 0;\n\n  free (p);\n}",
    "comment": "Frees allocated memory for operation groups, fields, parameters, and the datamash_ops structure while ensuring no memory leaks occur.",
    "prorec_sum": "Frees all dynamically allocated memory associated with an operation parser structure, including its internal arrays, related global buffers, and the structure itself.",
    "filter_prorec_sum": "Frees all allocated memory and resources associated with datamash operation structures and global state, then releases the main structure itself.",
    "prorec_aug_sum": "Frees all dynamically allocated memory associated with an operation parser structure and related global lists before releasing the structure itself.",
    "filter_prorec_aug_sum": "Frees all dynamically allocated operation data structures and related global buffers, then releases the main structure\u2019s memory.",
    "work_score": {
        "prorec_aug": {
            "summary": "Frees all dynamically allocated memory associated with an operation parser structure and related global lists before releasing the structure itself.",
            "score": [
                1.0,
                0.5,
                0.9
            ],
            "reason": [
                "The summary accurately describes that the function frees dynamically allocated memory tied to the provided structure and associated global data before freeing the structure itself. The code indeed releases memory for groups, operations (conditionally), global fields, parameters, and resets related counters before freeing 'p'. No contradicting or irrelevant claims are present, making all claims aligned with the source semantics.",
                "The summary correctly identifies that the function frees dynamically allocated memory for the operation parser structure and related global lists before freeing the structure itself, which matches the core purpose of releasing all allocated resources tied to the datamash_ops and associated globals. However, it provides only a high-level description without covering important secondary details such as nulling pointers, resetting counters, the conditional freeing of field operations, or the specific elements freed. This limits completeness despite accurate core coverage.",
                "The summary correctly states that the function frees dynamically allocated memory associated with a given structure (`struct datamash_ops*`) and also clears related global lists before freeing the structure. This matches the code, which frees group names, groups array, ops via `field_op_free` when applicable, ops array, global fields and field names, parameters, then the structure itself. The claim is accurate, specific to the code's behavior, and contains no irrelevant or incorrect information. Noise is minimal and there are no contradictory statements, offering a clear high-level but accurate overview."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Frees all dynamically allocated operation data structures and related global buffers, then releases the main structure\u2019s memory.",
            "score": [
                1.0,
                0.5,
                0.9
            ],
            "reason": [
                "The summary accurately describes the function's behavior: it frees dynamically allocated operation data structures, related global buffers, and finally the main structure's memory. This matches the source code, which iterates through group and field arrays, freeing names and arrays, resets related pointers and counters, frees parameter storage, and then frees the main struct. No inaccurate or irrelevant claims are present.",
                "The summary correctly describes the core action of releasing all dynamically allocated data structures, including operation and global buffers, and freeing the main structure, which matches the function\u2019s primary purpose. However, it lacks specific mention of the more detailed steps in the code, such as freeing group names, conditional freeing of field operations under _STANDALONE_, nulling pointers, and resetting allocation/usage counters. Coverage of these secondary behaviors is minimal.",
                "The summary accurately reflects the core behavior of the function: it frees all dynamically allocated structures tied to the struct (groups, ops) and related global buffers before freeing the struct itself. This matches the code, which deallocates group names, ops, global _fields, and _params. The claim is concise, fully correct, and directly describes the primary purpose without introducing inaccuracies or irrelevant noise."
            ]
        }
    }
}
{
    "source_code": "\nbfd_boolean\n_bfd_elf_maybe_strip_eh_frame_hdr (struct bfd_link_info *info)\n{\n  struct elf_link_hash_table *htab;\n  struct eh_frame_hdr_info *hdr_info;\n  struct bfd_link_hash_entry *bh = NULL;\n  struct elf_link_hash_entry *h;\n\n  htab = elf_hash_table (info);\n  hdr_info = &htab->eh_info;\n  if (hdr_info->hdr_sec == NULL)\n    return TRUE;\n\n  if (bfd_is_abs_section (hdr_info->hdr_sec->output_section)\n      || info->eh_frame_hdr_type == 0\n      || (info->eh_frame_hdr_type == DWARF2_EH_HDR\n\t  && !_bfd_elf_eh_frame_present (info))\n      || (info->eh_frame_hdr_type == COMPACT_EH_HDR\n\t  && !_bfd_elf_eh_frame_entry_present (info)))\n    {\n      hdr_info->hdr_sec->flags |= SEC_EXCLUDE;\n      hdr_info->hdr_sec = NULL;\n      return TRUE;\n    }\n\n  /* Add a hidden symbol so that systems without access to PHDRs can\n     find the table.  */\n  if (! (_bfd_generic_link_add_one_symbol\n\t (info, info->output_bfd, \"__GNU_EH_FRAME_HDR\", BSF_LOCAL,\n\t  hdr_info->hdr_sec, 0, NULL, FALSE, FALSE, &bh)))\n    return FALSE;\n\n  h = (struct elf_link_hash_entry *) bh;\n  h->def_regular = 1;\n  h->other = STV_HIDDEN;\n  get_elf_backend_data\n    (info->output_bfd)->elf_backend_hide_symbol (info, h, TRUE);\n\n  if (!hdr_info->frame_hdr_is_compact)\n    hdr_info->u.dwarf.table = TRUE;\n  return TRUE;\n}",
    "comment": "Modifies the header section flags and adds a hidden symbol if specific conditions for EH frame header presence are not met.",
    "prorec_sum": "Configures and registers the `__GNU_EH_FRAME_HDR` section for an object, adjusting related flags and state based on header bits and validation results.",
    "filter_prorec_sum": "Loads and processes the \"__GNU_EH_FRAME_HDR\" section if header flags permit, updating related structures and state, otherwise marks and clears the associated entry.",
    "prorec_aug_sum": "Processes ELF frame header data, updating related structures and flags, and marks dynamic section state based on specific byte flags and helper checks.",
    "filter_prorec_aug_sum": "Processes the `__GNU_EH_FRAME_HDR` section for a loaded object, updating related flags and invoking its handler based on header status bits.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes ELF frame header data, updating related structures and flags, and marks dynamic section state based on specific byte flags and helper checks.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary includes partially correct high-level statements, such as processing ELF frame header data, updating structures, and setting flags, which align with the function's role. However, it introduces inaccuracies: it mentions 'dynamic section state' and 'specific byte flags,' which are not present in the source code, and omits key accurate specifics like conditions under which the header is stripped or the addition of the hidden symbol. Around half of the claim components are accurate, but others are imprecise or misleading.",
                "The summary vaguely describes processing ELF frame header data but fails to capture the specific core purpose of conditionally stripping the .eh_frame_hdr section based on section type, header type, and presence checks. It incorrectly mentions marking dynamic section state based on byte flags, which is not present in the code. Aside from generic references to updating structures and flags, it omits key semantics such as adding a hidden symbol, hiding it via backend, and setting the DWARF table flag. The core domain action is not clearly covered and secondary details are missing or inaccurate.",
                "The summary contains mostly vague and partially incorrect claims. It suggests marking dynamic section state based on specific byte flags, but the source code deals with setting section exclusion flags, adding a hidden symbol, and updating a table flag\u2014there is no explicit use of 'specific byte flags' or a 'dynamic section state' concept. While it generically notes processing ELF frame header data and updating structures, these are broad SAFE claims with low informational value. The inaccurate reference to byte flags/section state introduces NOISE, and there are no detailed, accurate GOLD claims that directly capture the function's key conditional checks and symbol creation behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes the `__GNU_EH_FRAME_HDR` section for a loaded object, updating related flags and invoking its handler based on header status bits.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function processes the `__GNU_EH_FRAME_HDR` section for a loaded object and updates flags based on header status bits, which is inaccurate. The code does not process a loaded object's section in that sense; instead, it operates on an internal hdr_info structure in the link process, sometimes excluding the section entirely, conditionally adding a hidden symbol named `__GNU_EH_FRAME_HDR`. The mention of invoking its handler based on header status bits is unsupported \u2014 no such generic \"handler\" or bitmask logic appears in the source. The only accurate element is the name `__GNU_EH_FRAME_HDR`, but its role here is mischaracterized. Most of the claim set is inaccurate, leading to a low score.",
                "The summary's claim about processing the `__GNU_EH_FRAME_HDR` section and updating flags is only partially accurate because the code's core purpose is to conditionally strip an ELF .eh_frame_hdr section based on section type and presence of unwind info, or add a hidden symbol to locate it when kept. The summary mischaracterizes this as always processing the section for a loaded object and invoking a handler based on header status bits, which is not reflected in the source. It omits the conditional stripping logic, specific criteria checks, symbol addition, and hiding steps, thus failing to capture the core domain operation or important secondary behaviors.",
                "The summary's core claim about processing the `__GNU_EH_FRAME_HDR` section for a loaded object is inaccurate. The function does not process an already loaded object; it conditionally strips or adds the section during linking based on specific checks of header presence and type, not generic 'header status bits'. This is a FATAL error affecting the primary purpose, since the summary misstates the main operation\u2014from link-time conditional inclusion/exclusion and symbol creation to run-time handling. No other accurate, detailed claims are present, resulting in negligible benefit."
            ]
        }
    }
}
{
    "source_code": "static int\ngmp_stronglucas (const mpz_t x, mpz_t Qk)\n{\n  mp_bitcnt_t b0;\n  mpz_t V, n;\n  mp_limb_t maxD, D; /* The absolute value is stored. */\n  long Q;\n  mp_limb_t tl;\n\n  /* Test on the absolute value. */\n  mpz_roinit_normal_n (n, x->_mp_d, GMP_ABS (x->_mp_size));\n\n  assert (mpz_odd_p (n));\n  /* assert (mpz_gcd_ui (NULL, n, 6) == 1); */\n  if (mpz_root (Qk, n, 2))\n    return 0; /* A square is composite. */\n\n  /* Check Ds up to square root (in case, n is prime)\n     or avoid overflows */\n  maxD = (Qk->_mp_size == 1) ? Qk->_mp_d [0] - 1 : GMP_LIMB_MAX;\n\n  D = 3;\n  /* Search a D such that (D/n) = -1 in the sequence 5,-7,9,-11,.. */\n  /* For those Ds we have (D/n) = (n/|D|) */\n  do\n    {\n      if (D >= maxD)\n\treturn 1 + (D != GMP_LIMB_MAX); /* (1 + ! ~ D) */\n      D += 2;\n      tl = mpz_tdiv_ui (n, D);\n      if (tl == 0)\n\treturn 0;\n    }\n  while (gmp_jacobi_coprime (tl, D) == 1);\n\n  mpz_init (V);\n\n  /* n-(D/n) = n+1 = d*2^{b0}, with d = (n>>b0) | 1 */\n  b0 = mpz_scan0 (n, 0);\n\n  /* D= P^2 - 4Q; P = 1; Q = (1-D)/4 */\n  Q = (D & 2) ? (long) (D >> 2) + 1 : -(long) (D >> 2);\n\n  if (! gmp_lucas_mod (V, Qk, Q, b0, n))\t/* If Ud != 0 */\n    while (V->_mp_size != 0 && --b0 != 0)\t/* while Vk != 0 */\n      /* V <- V ^ 2 - 2Q^k */\n      /* Q^{2k} = (Q^k)^2 */\n      gmp_lucas_step_k_2k (V, Qk, n);\n\n  mpz_clear (V);\n  return (b0 != 0);\n}",
    "comment": "Determines if an odd integer is prime using the Lucas-Lehmer test and computes the Lucas sequence value based on specific parameters.",
    "prorec_sum": "Performs a strong Lucas primality test on a given large integer using mini-GMP routines to determine if it is prime.",
    "filter_prorec_sum": "Checks if a given large integer is an odd prime using a strong Lucas primality test implementation from the mini-GMP library.",
    "prorec_aug_sum": "Performs a strong Lucas probable prime test on a given odd number using mini-gmp functions and returns the primality result.",
    "filter_prorec_aug_sum": "Performs a strong Lucas primality test on a given odd multi-precision integer using mini-GMP functions and returns the result.",
    "work_score": {
        "prorec_aug": {
            "summary": "Performs a strong Lucas probable prime test on a given odd number using mini-gmp functions and returns the primality result.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary contains one main claim: the function performs a strong Lucas probable prime test using mini-gmp functions on an odd number and returns the primality result. This aligns with the source code, which indeed implements a strong Lucas test, uses GMP functions, asserts oddness, and returns an integer indicating primality or compositeness. Although the summary is high-level and omits specific algorithmic details (like handling squares or searching for 'D'), it is accurate in substance and free of contradictions.",
                "The summary correctly identifies the core purpose as performing a strong Lucas probable prime test on an odd number using mini-gmp functions, which matches the function's primary operation. However, it omits secondary details present in the code, such as handling perfect square detection, the specific search for a discriminant D with certain Jacobi properties, calculation of Q and Lucas sequences, and early return cases for compositeness. The coverage is thus limited to the primary purpose with no mention of important algorithmic steps or edge-case handling.",
                "The summary correctly identifies that the function implements a strong Lucas probable prime test on an odd number using mini-gmp functions and returns a primality-related result, which aligns with the code\u2019s primary purpose. There are no inaccurate (FATAL) claims or overwhelming unrelated content. However, the claim is generic and lacks detail about key steps (e.g., checks for squares, selection of D, Lucas sequence computations), so the gain is low despite being accurate."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Performs a strong Lucas primality test on a given odd multi-precision integer using mini-GMP functions and returns the result.",
            "score": [
                1.0,
                0.4,
                0.7
            ],
            "reason": [
                "The summary contains a single claim: that the function performs a strong Lucas primality test on an odd multi-precision integer using mini-GMP functions and returns the result. This matches the code, which implements a strong Lucas test (selecting D values, computing Q, using Lucas sequences) on an odd integer (`assert(mpz_odd_p(n))`) with mini-GMP calls (`mpz_`, `gmp_` functions) and returns an integer outcome. The claim is specific and correct, with no inaccuracies or irrelevant statements, so the proportion of accurate claims is 100%.",
                "The summary accurately states that the function performs a strong Lucas primality test on an odd multi-precision integer using mini-GMP functions, which matches the core purpose derived from the source code. However, it omits secondary critical details such as initial square check (`mpz_root`), search loop for appropriate D values, handling of special composite cases, Lucas sequence step logic, and conditions that terminate the test. Coverage is limited to the core domain task with no elaboration on important edge cases or internal computations.",
                "The summary correctly identifies that the function implements a strong Lucas primality test, specifically on odd multi-precision integers using mini-GMP functions, and returns a result indicating primality. This matches the code's primary purpose and I/O without introducing inaccuracies or irrelevant noise. However, the claim is fairly high-level and generic, omitting details such as the selection of parameter D, handling of perfect squares, and specific Lucas sequence steps, so the gain is moderate rather than high."
            ]
        }
    }
}
{
    "source_code": "\n\nint ec_GFp_simple_group_get_curve(const EC_GROUP *group, BIGNUM *p, BIGNUM *a, BIGNUM *b, BN_CTX *ctx)\n\t{\n\tint ret = 0;\n\tBN_CTX *new_ctx = NULL;\n\t\n\tif (p != NULL)\n\t\t{\n\t\tif (!BN_copy(p, &group->field)) return 0;\n\t\t}\n\n\tif (a != NULL || b != NULL)\n\t\t{\n\t\tif (group->meth->field_decode)\n\t\t\t{\n\t\t\tif (ctx == NULL)\n\t\t\t\t{\n\t\t\t\tctx = new_ctx = BN_CTX_new();\n\t\t\t\tif (ctx == NULL)\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\tif (a != NULL)\n\t\t\t\t{\n\t\t\t\tif (!group->meth->field_decode(group, a, &group->a, ctx)) goto err;\n\t\t\t\t}\n\t\t\tif (b != NULL)\n\t\t\t\t{\n\t\t\t\tif (!group->meth->field_decode(group, b, &group->b, ctx)) goto err;\n\t\t\t\t}\n\t\t\t}\n\t\telse\n\t\t\t{\n\t\t\tif (a != NULL)\n\t\t\t\t{\n\t\t\t\tif (!BN_copy(a, &group->a)) goto err;\n\t\t\t\t}\n\t\t\tif (b != NULL)\n\t\t\t\t{\n\t\t\t\tif (!BN_copy(b, &group->b)) goto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\n\tret = 1;\n\t\n err:\n\tif (new_ctx)\n\t\tBN_CTX_free(new_ctx);\n\treturn ret;\n\t}",
    "comment": "Retrieves the elliptic curve parameters (field, a, and b) from the specified EC_GROUP structure into provided BIGNUM variables.",
    "prorec_sum": "Retrieves the prime field curve parameters a, b, and p from an EC group, using BN_copy or group-specific methods with optional BN_CTX management.",
    "filter_prorec_sum": "Retrieves the elliptic curve parameters a, b, and field prime from a GFp group, using BN_copy or a method callback with optional BN_CTX.",
    "prorec_aug_sum": "Retrieves the curve parameters a, b, and field modulus from a GFp EC_GROUP, using BN_copy or method-specific operations with optional BN_CTX management.",
    "filter_prorec_aug_sum": "Retrieves the elliptic curve group parameters a, b, and field modulus into supplied BIGNUMs, using method-specific or direct BN_copy operations with optional BN_CTX.",
    "work_score": {
        "prorec_aug": {
            "summary": "Retrieves the curve parameters a, b, and field modulus from a GFp EC_GROUP, using BN_copy or method-specific operations with optional BN_CTX management.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately states that the function retrieves curve parameters a, b, and the field modulus from a GFp EC_GROUP, and correctly notes the use of BN_copy or method-specific operations along with optional BN_CTX management, all of which align with the source code. There are no contradictory or irrelevant claims, and all extracted facts match the function\u2019s semantics.",
                "The summary correctly identifies the core purpose of returning the field modulus and curve parameters a and b from an EC_GROUP and mentions the use of BN_copy or method-specific decoding as well as optional BN_CTX allocation, which aligns with the source code's core operation and error/branch handling at a high level. However, it omits finer details like conditional NULL checks for parameters, fallback to BN_copy when field_decode is absent, proper resource cleanup, and specific control flow for error handling, resulting in incomplete coverage of secondary behavior-critical semantics.",
                "The summary accurately identifies the function\u2019s purpose of retrieving curve parameters a, b, and the field modulus from an EC_GROUP. It correctly notes the use of BN_copy and method-specific operations, as well as optional BN_CTX management. There are no inaccurate claims or contradictions with the source code, and all key details are specific to the function\u2019s core behavior. The gain is high since the summary captures the main domain semantics clearly with low noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Retrieves the elliptic curve group parameters a, b, and field modulus into supplied BIGNUMs, using method-specific or direct BN_copy operations with optional BN_CTX.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately states that the function retrieves elliptic curve parameters a, b, and the field modulus into the provided BIGNUMs. It correctly notes the use of either method-specific decoding or direct BN_copy operations as seen in the code, and mentions the optional BN_CTX allocation, which matches the conditional creation and freeing of BN_CTX in the source. All claims directly align with the function\u2019s behavior and are specific to the code\u2019s semantics.",
                "The summary accurately states the core purpose: obtaining the elliptic curve group's field modulus and coefficients a and b into provided BIGNUMs using either method-specific decoding or BN_copy, and notes the optional BN_CTX use. This matches the code's core operation and mentions key implementation details. However, it omits secondary aspects such as allocation of a new BN_CTX when needed, error handling via early returns and 'goto err', and freeing of allocated BN_CTX, which are relevant to behavior-critical semantics.",
                "The summary correctly states the primary purpose of retrieving the elliptic curve group parameters a, b, and the field modulus into supplied BIGNUMs, and notes the conditional use of method-specific decoding or BN_copy, as seen in the source code. It also accurately mentions the optional BN_CTX, matching the code\u2019s creation of a new context if none is provided. There is no contradictory or irrelevant information, and the claims are both specific and semantically aligned with the function\u2019s core purpose, providing useful detail."
            ]
        }
    }
}
{
    "source_code": "\nvoid FAST_FUNC bb_perror_msg(const char *s, ...)\n{\n\tva_list p;\n\n\tva_start(p, s);\n\t/* Guard against \"<error message>: Success\" */\n\tbb_verror_msg(s, p, errno ? strerror(errno) : NULL);\n\tva_end(p);\n}",
    "comment": "Logs an error message along with the string representation of the current errno value, using a variable argument list for additional context.",
    "prorec_sum": "Packages input parameters and optional SIMD values, computes a derived value if configured, and forwards them to another routine for final processing.",
    "filter_prorec_sum": "Builds a parameter block from scalar and vector inputs, computes optional doubles via a helper, and forwards them to another processing routine.",
    "prorec_aug_sum": "Constructs parameter data from provided coordinates and calls a processing routine, optionally transforming vectors through an auxiliary computation if a global flag is set.",
    "filter_prorec_aug_sum": "Constructs parameter data from provided vectors and conditionally computes a double-based value before invoking a secondary processing routine with these arguments.",
    "work_score": {
        "prorec_aug": {
            "summary": "Constructs parameter data from provided coordinates and calls a processing routine, optionally transforming vectors through an auxiliary computation if a global flag is set.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes behavior related to handling coordinates, processing routines, vector transformations, and a global flag, none of which match the actual source code semantics. The function in the source code formats and passes variable arguments to an error message handler with specific logic around errno, entirely unrelated to the described claims. All claims are inaccurate.",
                "The summary's claims about constructing parameter data, processing coordinates, and transforming vectors have no relation to the source code, which handles formatting and printing an error message using a variadic argument list and errno handling. None of the claims are accurate, so the core purpose of reporting an error with contextual message is entirely missing.",
                "The summary's claims about constructing parameter data from coordinates, transforming vectors, and using a global flag do not match the source code, which initializes a variable argument list and calls an error message function. These are all inaccuracies that contradict the core function's purpose, making them FATAL errors regarding its primary behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Constructs parameter data from provided vectors and conditionally computes a double-based value before invoking a secondary processing routine with these arguments.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about constructing parameter data from vectors, computing a double-based value, and invoking a secondary routine do not match the source code's actual functionality, which deals with variadic arguments, formatting an error message, and handling errno. None of the claims reflect the domain-specific semantics of the function, resulting in zero accurate matches.",
                "The summary's claims about constructing parameter data from vectors, computing a double-based value, and invoking a secondary routine are entirely inaccurate relative to the source code, which initializes a va_list and calls bb_verror_msg to print an error message with strerror(errno) if errno is set. The core purpose of formatting and printing an error message while avoiding the 'Success' case is not covered at all, and the summary contains no accurate secondary details.",
                "The summary's claims about constructing parameter data from vectors, computing a double-based value, and invoking a secondary routine are entirely inaccurate compared to the source code, which formats and outputs an error message using variadic arguments and errno. This misrepresents the primary purpose and key I/O of the function, constituting a severe FATAL error that makes the summary unusable for understanding the code."
            ]
        }
    }
}
{
    "source_code": "int mls_import_netlbl_cat(struct context *context,\n\t\t\t  struct netlbl_lsm_secattr *secattr)\n{\n\tint rc;\n\n\tif (!policydb.mls_enabled)\n\t\treturn 0;\n\n\trc = ebitmap_netlbl_import(&context->range.level[0].cat,\n\t\t\t\t   secattr->attr.mls.cat);\n\tif (rc != 0)\n\t\tgoto import_netlbl_cat_failure;\n\n\trc = ebitmap_cpy(&context->range.level[1].cat,\n\t\t\t &context->range.level[0].cat);\n\tif (rc != 0)\n\t\tgoto import_netlbl_cat_failure;\n\n\treturn 0;\n\nimport_netlbl_cat_failure:\n\tebitmap_destroy(&context->range.level[0].cat);\n\tebitmap_destroy(&context->range.level[1].cat);\n\treturn rc;\n}",
    "comment": "Imports and copies the MLS category attributes into the context structure if MLS is enabled, handling errors by destroying allocated resources.",
    "prorec_sum": "Checks a global state and performs two geometry-related update operations on structures at given offsets, returning success if either update is executed.",
    "filter_prorec_sum": "Checks global initialization and performs two object-related update operations using provided parameters, returning a status code if either succeeds.",
    "prorec_aug_sum": "Processes two related data structures using multiple computation routines, updating them when certain conditions are met, and returns a status code indicating the operation result.",
    "filter_prorec_aug_sum": "Processes two related data structures with provided parameters, performing conditional sub-operations only if initial checks succeed, then returns the computed status code.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes two related data structures using multiple computation routines, updating them when certain conditions are met, and returns a status code indicating the operation result.",
            "score": [
                0.6,
                0.1,
                0.4
            ],
            "reason": [
                "The summary provides a vague and generic description that partially matches the code's behavior\u2014mentioning processing of two related data structures, conditional updates, and returning a status code. However, it lacks specificity about key domain semantics, such as the MLS policy check, the exact functions called for import and copy, and error handling with cleanup. While not incorrect, it is mostly boilerplate and misses distinguishing details, leading to only a moderately accurate representation of the function.",
                "The summary provides only vague, generic statements about processing data structures and returning a status. It does not accurately convey the core purpose of importing MLS category bitmaps from a netlabel security attribute into both levels of the context when MLS is enabled, nor does it specify the conditional checks, the use of ebitmap operations, or the cleanup on failure. The core functionality is entirely missing and there is minimal relevant secondary detail.",
                "The summary provides only a generic description of processing two data structures and returning a status code, which is SAFE but low-info. It omits key specific details from the source code such as the MLS policy check, importing category bitmap from secattr, copying between levels, and cleanup on failure. No FATAL inaccuracies are present, but the lack of specificity means the gain is very low. Noise is moderate due to vagueness."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes two related data structures with provided parameters, performing conditional sub-operations only if initial checks succeed, then returns the computed status code.",
            "score": [
                0.8,
                0.2,
                0.4
            ],
            "reason": [
                "The summary makes a few generic claims: it states that the function processes two related data structures, uses conditional logic, and returns a status code. These statements are broadly consistent with the source code, which operates on two category bitmaps in the context range levels, performs operations only if MLS is enabled, and returns an integer result. However, the claims are high-level and omit key specific behaviors such as importing netlabel categories, copying them, and cleaning up on failure. Despite lacking detail, the general control flow description aligns with the function, so most claims are accurate but generic.",
                "The summary is overly generic, failing to mention the specific core purpose of importing MLS category data from netlabel attributes into both levels of the context's range. While it notes conditional operations and status returns, it omits crucial domain-specific semantics such as the MLS policy check, duplication of category bitmaps, and cleanup on failure. No accurate claim covers the core domain action, resulting in poor alignment.",
                "The summary is overly generic, stating only that the function processes data structures with conditional steps and returns a status code. It fails to accurately capture key domain-specific behavior present in the source code, such as the MLS enablement check, use of ebitmap operations, and duplication of category bitmaps. No direct contradictions are present, but the lack of specific detail means the information gain is very low and noise is relatively high."
            ]
        }
    }
}
{
    "source_code": "\nvoid assert_pipe(struct drm_i915_private *dev_priv,\n\t\t enum pipe pipe, bool state)\n{\n\tint reg;\n\tu32 val;\n\tbool cur_state;\n\tenum transcoder cpu_transcoder = intel_pipe_to_cpu_transcoder(dev_priv,\n\t\t\t\t\t\t\t\t      pipe);\n\n\t/* if we need the pipe A quirk it must be always on */\n\tif (pipe == PIPE_A && dev_priv->quirks & QUIRK_PIPEA_FORCE)\n\t\tstate = true;\n\n\tif (!intel_using_power_well(dev_priv->dev) &&\n\t    cpu_transcoder != TRANSCODER_EDP) {\n\t\tcur_state = false;\n\t} else {\n\t\treg = PIPECONF(cpu_transcoder);\n\t\tval = I915_READ(reg);\n\t\tcur_state = !!(val & PIPECONF_ENABLE);\n\t}\n\n\tWARN(cur_state != state,\n\t     \"pipe %c assertion failure (expected %s, current %s)\\n\",\n\t     pipe_name(pipe), state_string(state), state_string(cur_state));\n}",
    "comment": "Asserts the state of a specified display pipe in the Intel graphics driver, ensuring it matches the expected enablement state.",
    "prorec_sum": "Checks an Intel GPU display pipe\u2019s enabled state and logs an assertion failure if it differs from the expected on/off configuration.",
    "filter_prorec_sum": "Checks an Intel GPU display pipe\u2019s state against expectations and logs an assertion failure with pipe ID and on/off status details.",
    "prorec_aug_sum": "Checks the expected on/off state of a display pipe and logs an assertion failure if the current hardware state does not match.",
    "filter_prorec_aug_sum": "Checks a GPU display pipe\u2019s expected on/off state against hardware status and logs an assertion failure if the states differ.",
    "work_score": {
        "prorec_aug": {
            "summary": "Checks the expected on/off state of a display pipe and logs an assertion failure if the current hardware state does not match.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary accurately captures the core function behavior: verifying the expected on/off state of a specific display pipe and issuing a warning when mismatched. It aligns with the source code\u2019s retrieval of the hardware state via register read, comparison with the expected state, and error logging through WARN. No contradictions or irrelevant statements are present, and the claim is specific and semantically correct.",
                "The summary accurately identifies that the function checks the expected versus current hardware state of a display pipe and logs a warning if they differ, matching the core purpose of asserting the pipe's state. However, it omits secondary details such as handling of PIPE_A quirks, power well conditions, use of the transcoder mapping, and specific register reads. These omissions reduce coverage of behavior-critical semantics.",
                "The summary correctly states the primary purpose: verifying if the current hardware state of a display pipe matches the expected state and logging an assertion failure if not. This aligns well with the source code, which reads the PIPECONF register, applies a PIPE_A quirk if needed, and uses WARN for mismatches. The claim is accurate, specific to the code's core function, and has minimal noise, but it omits some conditional details such as handling power wells and specific transcoders. Overall, it provides a clear, useful insight with no inaccuracies."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Checks a GPU display pipe\u2019s expected on/off state against hardware status and logs an assertion failure if the states differ.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly identifies that the function checks a GPU display pipe\u2019s expected state against the hardware and logs an assertion failure if they differ, which matches the core domain-semantic behavior in the source code. It omits implementation details like the quirk for PIPE_A and handling of the EDP transcoder, but these omissions do not contradict the code. Overall, the claims are accurate and relevant to the function\u2019s purpose with no incorrect statements.",
                "The summary captures the core purpose: verifying the GPU display pipe's expected state against actual hardware state and logging a warning if mismatched, which matches the function's main domain action. However, it omits secondary details such as the pipe A quirk forcing the state to true, handling based on power well usage, the check for EDP transcoder, and the precise mechanism for reading hardware registers. These missing points limit completeness but the essential behavior is correct.",
                "The summary accurately conveys the primary purpose: verifying a GPU display pipe\u2019s expected on/off state against the hardware register and logging an assertion if they differ. This matches the source code function\u2019s flow, including reading the PIPECONF register and comparing it to the desired state. There is no contradictory information or irrelevant noise, but the description is generic and omits details such as special handling for PIPE_A quirks or conditions related to power wells, which reduces the informational gain."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic int pcmcia_card_add(struct pcmcia_socket *s)\n{\n\tcistpl_longlink_mfc_t mfc;\n\tunsigned int no_funcs, i, no_chains;\n\tint ret = -EAGAIN;\n\n\tmutex_lock(&s->ops_mutex);\n\tif (!(s->resource_setup_done)) {\n\t\tdev_dbg(&s->dev,\n\t\t\t   \"no resources available, delaying card_add\\n\");\n\t\tmutex_unlock(&s->ops_mutex);\n\t\treturn -EAGAIN; /* try again, but later... */\n\t}\n\n\tif (pcmcia_validate_mem(s)) {\n\t\tdev_dbg(&s->dev, \"validating mem resources failed, \"\n\t\t       \"delaying card_add\\n\");\n\t\tmutex_unlock(&s->ops_mutex);\n\t\treturn -EAGAIN; /* try again, but later... */\n\t}\n\tmutex_unlock(&s->ops_mutex);\n\n\tret = pccard_validate_cis(s, &no_chains);\n\tif (ret || !no_chains) {\n\t\tdev_dbg(&s->dev, \"invalid CIS or invalid resources\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (!pccard_read_tuple(s, BIND_FN_ALL, CISTPL_LONGLINK_MFC, &mfc))\n\t\tno_funcs = mfc.nfn;\n\telse\n\t\tno_funcs = 1;\n\ts->functions = no_funcs;\n\n\tfor (i = 0; i < no_funcs; i++)\n\t\tpcmcia_device_add(s, i);\n\n\treturn ret;\n}",
    "comment": "Adds a PCMCIA card to the socket after validating resources and reading its function information from the card's CIS.",
    "prorec_sum": "Initializes and validates a hardware context, retrieves a count value, and iteratively performs device-specific operations for each enumerated unit.",
    "filter_prorec_sum": "Initializes device state, validates readiness, retrieves configuration data, and triggers operations for each configured unit using provided parameters.",
    "prorec_aug_sum": "Configures a device by validating state, reading parameters, and issuing initialization commands for each detected channel or endpoint.",
    "filter_prorec_aug_sum": "Configures and initiates device operations based on retrieved parameters, performing repeated command dispatches for each available unit and returning status codes on failure or completion.",
    "work_score": {
        "prorec_aug": {
            "summary": "Configures a device by validating state, reading parameters, and issuing initialization commands for each detected channel or endpoint.",
            "score": [
                0.3,
                0.4,
                0.2
            ],
            "reason": [
                "The summary makes generic statements about configuring a device, validating state, and initializing endpoints, but it omits key specifics from the source code such as handling EAGAIN for unavailable resources, checking CIS validity, determining the number of functions from a tuple read, and looping over functions with pcmcia_device_add. The term 'channel or endpoint' does not accurately reflect the code's concept of card functions. While the general idea of validation and initialization is correct, multiple details are either missing or inaccurately generalized, resulting in less than half of the claims being precise and verifiable against the source.",
                "The summary generally states that the function validates state, reads parameters, and initializes for each detected endpoint. This loosely maps to the code\u2019s steps of checking resource setup, validating memory, reading CIS tuples, and adding devices for each function. However, it omits the specific core purpose of adding PCMCIA card functions after CIS validation, uses incorrect domain terms (channels/endpoints instead of PCMCIA functions), and lacks detail on error handling, branches for resource unavailability, and use of constants. Core functionality is only vaguely implied, and domain specificity is missing.",
                "The summary\u2019s main claim is that the function configures a device by validating state, reading parameters, and issuing initialization commands for each detected channel or endpoint. The validation and parameter reading aspects align with the code\u2019s checks (resource setup, memory resource validation, CIS parsing), but the description of initializing 'each detected channel or endpoint' is inaccurate: the code handles functions of a PCMCIA card, not generic channels/endpoints. This is a semantic mismatch on the PRIMARY PURPOSE, introducing a FATAL error about what is being initialized. While some elements are accurate, the core misrepresentation of what is iterated over significantly undermines trust."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Configures and initiates device operations based on retrieved parameters, performing repeated command dispatches for each available unit and returning status codes on failure or completion.",
            "score": [
                0.2,
                0.2,
                0.3
            ],
            "reason": [
                "The summary omits key details such as resource validation checks, delayed retries via -EAGAIN, CIS validation, determination of the number of functions, and sequential addition of PCMICA devices. It introduces vague, generic notions like 'retrieved parameters' and 'repeated command dispatches' without accurately reflecting source-specific logic, leading to low alignment with code semantics.",
                "The summary vaguely describes configuring and initiating device operations with repeated command dispatches, but it does not accurately capture the core domain purpose of adding a PCMCIA card by validating resources, parsing its CIS, determining the number of functions, and adding each device. It omits critical specifics such as resource setup checks, memory validation, CIS validation, and the branching on number of functions, while introducing generic and potentially misleading notions like 'retrieved parameters' and 'command dispatches' that are not evident in the code.",
                "The summary is mostly inaccurate: it generically mentions configuring and initiating device operations and repeated command dispatches, but omits or misrepresents key semantics such as mutex locking, resource validation, CIS validation, setting the number of functions, and calling pcmcia_device_add per function. The phrase 'retrieved parameters' is vague and not clearly tied to the code's actual flow, and 'status codes on failure or completion' misses the specific return conditions (EAGAIN, ENODEV). This constitutes high NOISE with no GOLD-level specifics, resulting in very low net benefit."
            ]
        }
    }
}
{
    "source_code": "\nint cms_SignedData_final(CMS_ContentInfo *cms, BIO *chain)\n\t{\n\tSTACK_OF(CMS_SignerInfo) *sinfos;\n\tCMS_SignerInfo *si;\n\tint i;\n\tsinfos = CMS_get0_SignerInfos(cms);\n\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t{\n\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\tif (!cms_SignerInfo_content_sign(cms, si, chain))\n\t\t\treturn 0;\n\t\t}\n\tcms->d.signedData->encapContentInfo->partial = 0;\n\treturn 1;\n\t}",
    "comment": "Finalizes the signing process for all signer information in the CMS_ContentInfo structure by signing the content and marking it as complete.",
    "prorec_sum": "Finalizes signing for each CMS signer by completing digests, adding required signed attributes, generating signatures, and storing them in the signer information structures.",
    "filter_prorec_sum": "Finalizes CMS SignedData by processing each signer\u2019s digest context, adding required signed attributes, generating signatures, and storing them in the structure.",
    "prorec_aug_sum": "Generates and finalizes CMS signed-data signatures by processing each signer\u2019s digest, adding required attributes, and creating the final signature output.",
    "filter_prorec_aug_sum": "Finalizes CMS SignedData by computing digests or signatures for each signer and updating corresponding attributes, handling errors and freeing resources.",
    "work_score": {
        "prorec_aug": {
            "summary": "Generates and finalizes CMS signed-data signatures by processing each signer\u2019s digest, adding required attributes, and creating the final signature output.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary contains several domain-specific claims that are not evident in the source code. While it correctly implies that the function processes each signer and finalizes signed-data, it inaccurately specifies actions such as generating signatures, processing digests, and adding attributes, which are not shown in the implementation. Only the finalization aspect aligns with the code, resulting in less than half of the claims being accurate.",
                "The summary claims that the function processes each signer\u2019s digest, adds required attributes, and creates a final signature output. While this loosely aligns with signing operations, it omits the specific core purpose: iterating over all CMS_SignerInfo entries and invoking cms_SignerInfo_content_sign to complete signing, then marking the encapsulated content as non-partial. The mention of digest processing and attribute addition is not directly evidenced in the source, making parts of the summary inaccurate. The core is not explicitly covered, and secondary details are minimal and partly speculative.",
                "The summary claims the function processes each signer's digest, adds required attributes, and creates a final signature output. In the source, the function iterates over signer infos and calls cms_SignerInfo_content_sign, which may perform those tasks internally, but these specific actions are not visible in this code. The visible behavior is invoking that helper for each signer and setting 'partial' to 0. Thus, the claims about digest processing, attribute addition, and final signature generation are speculative and not grounded in the provided code, making them mostly NOISE. There is no FATAL contradiction, but the high proportion of unsubstantiated detail and low directly verifiable content leads to low net benefit."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Finalizes CMS SignedData by computing digests or signatures for each signer and updating corresponding attributes, handling errors and freeing resources.",
            "score": [
                0.7,
                0.3,
                0.5
            ],
            "reason": [
                "The summary claims that the function computes digests or signatures for each signer, which aligns with the call to cms_SignerInfo_content_sign in the source code. However, it also states that it updates corresponding attributes, which is partially accurate since it sets 'partial' to 0, but the description is more general than the actual code. The mention of handling errors is accurate as the function returns 0 upon failure. The claim about freeing resources is inaccurate because the code does not perform any resource deallocation. Most claims are accurate or safe, but there is at least one clear inaccuracy.",
                "The summary claims digest/signature computation and attribute updates, but the source code shows looping through signer infos and invoking cms_SignerInfo_content_sign without explicit digest computation or attribute management, and no resource freeing. The core purpose\u2014finalizing a CMS SignedData object by signing the content for each signer and marking it complete\u2014is only partially captured, with inaccuracies about freeing and attribute updates. The core is hinted at but not clearly or accurately stated, and secondary details are mostly incorrect.",
                "The summary's core claim that the function finalizes CMS SignedData is generally aligned with the source, but it specifies computing digests or signatures and updating attributes, which are not explicitly shown and thus are speculative. It also adds claims about freeing resources, which are unsupported in the provided code. The accurate part is that it loops over signer infos, calls a signing function, and marks the content as complete, but the inaccurate and speculative elements introduce noticeable noise without any severe contradiction of the primary purpose."
            ]
        }
    }
}
{
    "source_code": "static void tcp_set_skb_tso_segs(const struct sock *sk, struct sk_buff *skb,\n\t\t\t\t unsigned int mss_now)\n{\n\tif (skb->len <= mss_now || !sk_can_gso(sk) ||\n\t    skb->ip_summed == CHECKSUM_NONE) {\n\t\t/* Avoid the costly divide in the normal\n\t\t * non-TSO case.\n\t\t */\n\t\tskb_shinfo(skb)->gso_segs = 1;\n\t\tskb_shinfo(skb)->gso_size = 0;\n\t\tskb_shinfo(skb)->gso_type = 0;\n\t} else {\n\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss_now);\n\t\tskb_shinfo(skb)->gso_size = mss_now;\n\t\tskb_shinfo(skb)->gso_type = sk->sk_gso_type;\n\t}\n}",
    "comment": "Sets the TCP segmentation offload parameters for a socket buffer based on its length and the maximum segment size.",
    "prorec_sum": "Configures TCP segment header fields based on connection state and packet size, logging anomalies once, before finalizing length and identifier values.",
    "filter_prorec_sum": "Calculates and updates TCP output segment header fields based on connection state, segment size, and flags, with a one-time debug log on anomaly.",
    "prorec_aug_sum": "Updates TCP output header fields based on segment and connection state, logging anomalies once, to prepare acknowledgment or segment size information.",
    "filter_prorec_aug_sum": "Calculates and writes TCP segment count, size, and sequence fields into the packet buffer header based on connection state and provided parameters.",
    "work_score": {
        "prorec_aug": {
            "summary": "Updates TCP output header fields based on segment and connection state, logging anomalies once, to prepare acknowledgment or segment size information.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims that the function updates TCP output header fields based on segment and connection state, logs anomalies once, and prepares acknowledgment or segment size information. In the source, the function conditionally sets gso_segs, gso_size, and gso_type in skb based on MSS and TSO conditions\u2014this is about segmentation offload metadata, not general TCP header fields or acknowledgment preparation. There is no logging or anomaly detection in the code. All claims targeting semantics are inaccurate, resulting in no alignment.",
                "The summary's claim that the function updates TCP output header fields and logs anomalies is inaccurate, as the code does not handle headers or logging. The core purpose\u2014setting skb shinfo TSO segment parameters based on MSS, GSO capability, and checksum state\u2014is not mentioned at all. No accurate claims in the summary cover the core action or secondary behaviors like conditional assignments or constants used.",
                "The summary contains multiple inaccurate claims: it states that the function updates TCP output header fields, logs anomalies, and prepares acknowledgment information, none of which are present in the source code. The function instead sets GSO segment counts, size, and type based on conditions. These inaccuracies directly contradict the core purpose of the function, representing a severe FATAL error on the primary behavior. There are no accurate claims present, so the net benefit is essentially zero."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Calculates and writes TCP segment count, size, and sequence fields into the packet buffer header based on connection state and provided parameters.",
            "score": [
                0.7,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly notes that the function computes and writes TCP segment count and size based on parameters and connection state, aligning with the code that sets gso_segs and gso_size conditional on mss_now, skb length, and GSO capability. However, it inaccurately mentions setting sequence fields, which is not present in the source code, lowering claim accuracy. The majority of claims are accurate, but not all.",
                "The summary contains one main claim: that the function calculates and writes TCP segment count, size, and sequence fields into the packet buffer header based on connection state and provided parameters. The first part about calculating and writing segment count and size matches accurately with the code\u2019s setting of gso_segs and gso_size, but mentioning 'sequence fields' is inaccurate, as the code does not handle TCP sequence numbers. The core primary purpose\u2014setting gso_segs, gso_size, and gso_type for TCP segmentation depending on MSS, GSO capability, and checksum status\u2014is partially covered, but the wording is imprecise and omits critical elements like conditional logic for non-TSO cases and the setting of gso_type. Secondary behaviors such as skipping division for the non-TSO case and gso_type assignment are missing entirely.",
                "The summary correctly states that the function calculates and writes TCP segment count and size into the packet buffer header based on connection state and parameters, aligning with the code\u2019s logic for setting gso_segs, gso_size, and gso_type depending on conditions. However, the mention of 'sequence fields' is inaccurate, as the function does not handle TCP sequence numbers. This is a minor inaccuracy (NOISE), not a FATAL error, and the rest of the content is fairly generic with limited detail beyond the core behavior."
            ]
        }
    }
}
{
    "source_code": "\nSEXP attribute_hidden do_dynunload(SEXP call, SEXP op, SEXP args, SEXP env)\n{\n    char buf[2 * PATH_MAX];\n\n    checkArity(op,args);\n    if (!isString(CAR(args)) || LENGTH(CAR(args)) != 1)\n\terror(_(\"character argument expected\"));\n    GetFullDLLPath(call, buf, translateChar(STRING_ELT(CAR(args), 0)));\n    if(!DeleteDLL(buf))\n\terror(_(\"shared object '%s\\' was not loaded\"), buf);\n    return R_NilValue;\n}",
    "comment": "Unloads a shared object from memory by verifying the argument and deleting its associated DLL using the full path derived from the input.",
    "prorec_sum": "Validates a single character argument specifying a shared object name, loads it, and raises an error if the object is not found.",
    "filter_prorec_sum": "Validates a single string argument and reports an error if the specified shared object was not successfully loaded.",
    "prorec_aug_sum": "Loads a shared object by name from a character argument, invoking an internal loader and erroring if the object is not loaded.",
    "filter_prorec_aug_sum": "Validates a single string argument, translates it, and reports an error if the corresponding shared object is not loaded.",
    "work_score": {
        "prorec_aug": {
            "summary": "Loads a shared object by name from a character argument, invoking an internal loader and erroring if the object is not loaded.",
            "score": [
                0.1,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function 'loads a shared object', but the source code clearly performs the opposite\u2014it unloads a DLL via DeleteDLL. The mention of 'internal loader' is inaccurate, as the function calls a DLL path retrieval function and then attempts to delete it. The claim that it errors if the object is not loaded is a partial match but reversed in meaning, since it errors if the object was not loaded prior to unloading. Most details directly contradict the code's semantics, so the proportion of accurate claims is well below half.",
                "The summary incorrectly states that the function loads a shared object, while the source code clearly performs the opposite\u2014it unloads a DLL via DeleteDLL. The claim about taking a character argument is accurate, as is mentioning an error if the operation fails, but the core primary purpose (unloading a shared object by name after validating the argument) is not captured. Minimal secondary accurate details are present, but without the correct core action, coverage is very poor.",
                "The summary's core claim that the function loads a shared object is directly contradicted by the source code, which attempts to unload a DLL specified by a single-character argument. This is a severe factual error about the primary purpose (WHAT) of the function, making it unusable. There are no accurate, domain-specific details to offset this FATAL error."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates a single string argument, translates it, and reports an error if the corresponding shared object is not loaded.",
            "score": [
                0.9,
                0.3,
                0.8
            ],
            "reason": [
                "The summary correctly identifies that the function checks for a single string argument, translates it, and produces an error if the shared object is not loaded. These points align directly with the source code's logic: argument validation, translation using `translateChar`, and error reporting after `DeleteDLL` failure. No claims contradict the code, and all are relevant to its semantics, indicating high accuracy.",
                "The summary correctly notes the validation of a single string argument, translation of it, and reporting an error if the shared object is not loaded, which aligns with the source code. However, it omits the core purpose of unloading the shared object via DeleteDLL and returning R_NilValue. Without covering this domain-specific core operation, the coverage is incomplete, with only secondary steps described.",
                "The summary correctly captures key functional aspects: validation of a single string argument, translation of that argument, and error reporting when the shared object is not loaded. These are specific and match the source code behavior. There is no inaccurate or irrelevant noise, but while accurate, the description remains concise and omits some detail (e.g., full DLL path resolution and arity check). Overall, the summary provides useful, correct information with minimal noise."
            ]
        }
    }
}
{
    "source_code": "int audit_alloc(struct task_struct *tsk)\n{\n\tstruct audit_context *context;\n\tenum audit_state     state;\n\tchar *key = NULL;\n\n\tif (likely(!audit_ever_enabled))\n\t\treturn 0; /* Return if not auditing. */\n\n\tstate = audit_filter_task(tsk, &key);\n\tif (state == AUDIT_DISABLED)\n\t\treturn 0;\n\n\tif (!(context = audit_alloc_context(state))) {\n\t\tkfree(key);\n\t\taudit_log_lost(\"out of memory in audit_alloc\");\n\t\treturn -ENOMEM;\n\t}\n\tcontext->filterkey = key;\n\n\ttsk->audit_context  = context;\n\tset_tsk_thread_flag(tsk, TIF_SYSCALL_AUDIT);\n\treturn 0;\n}",
    "comment": "Allocates an audit context for a given task if auditing is enabled and filters the task based on its audit state.",
    "prorec_sum": "Allocates and initializes an audit data structure for the given object, setting type-specific fields and marking it with an audit flag.",
    "filter_prorec_sum": "Allocates and initializes an audit data structure for the given object, linking it to global lists and handling out-of-memory errors.",
    "prorec_aug_sum": "Allocates and initializes an audit data structure for the given task, linking it to global lists and marking the task with an audit flag.",
    "filter_prorec_aug_sum": "Allocates and initializes an audit record for the given context, linking it to global structures and handling memory exhaustion errors.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and initializes an audit data structure for the given task, linking it to global lists and marking the task with an audit flag.",
            "score": [
                0.3,
                0.4,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function allocates and initializes an audit-related structure for a task and marks it with an audit flag, which matches the code. However, it inaccurately claims that the structure is linked to global lists \u2014 there is no evidence in the source code of any insertion into global data structures. This results in a significant factual error, so less than half of the claims are accurate.",
                "The summary claims the function links the audit structure to global lists, which is inaccurate because the code does not perform any such linking\u2014it creates an audit context, sets a filter key, associates it with the task, and sets a syscall audit flag. While it correctly mentions allocation and marking the task with an audit flag, it omits key control flow such as early returns when auditing is disabled, handling of AUDIT_DISABLED state, out-of-memory errors, and logging lost events. The core purpose is partly covered but contains an incorrect detail and misses several critical behaviors.",
                "The summary correctly notes that the function allocates and initializes an audit structure for the given task and sets an audit-related flag, which aligns with the code. However, it inaccurately claims that it links the structure to global lists \u2014 there is no evidence of global list linkage in the implementation. This is a FATAL error affecting the primary purpose by asserting a core side effect not present in the code, making the description unreliable despite some accurate details."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates and initializes an audit record for the given context, linking it to global structures and handling memory exhaustion errors.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly mentions handling memory exhaustion errors, which matches the kfree/audit_log_lost path in the code. However, it inaccurately states that the function allocates and initializes an audit record, when the code actually allocates an audit context and links it to a specific task's audit_context, not to 'global structures'. The 'audit record' wording and 'global structures' claim are misleading, making only part of the statement accurate.",
                "The summary claims the function allocates and initializes an audit record and links it to global structures, but the code actually allocates an audit_context for a specific task, sets the filter key, updates the task\u2019s audit_context pointer, sets a thread flag, and exits early if auditing is disabled or if audit_filter_task returns AUDIT_DISABLED. The summary misrepresents the type of object involved and omits critical branching conditions, early returns, and the use of audit_filter_task. While it does mention memory exhaustion handling, the core domain-specific purpose is not accurately covered.",
                "The summary contains inaccuracies regarding the function's core purpose. It claims the function allocates and initializes an audit record and links it to global structures, but the code shows it allocates an audit_context for a given task_struct after checking audit state, not a generic audit record, and there is no linking to global structures beyond assigning the context to the task and setting a thread flag. The memory exhaustion handling part is accurate, but the primary purpose is misstated, making this a FATAL error on the core action."
            ]
        }
    }
}
{
    "source_code": "int Xorriso_register_matched_adr(struct XorrisO *xorriso,\n                                char *adr, int count_limit,\n                                int *filec, char **filev, off_t *mem, int flag)\n{\n int l;\n\n if(flag&1) {\n   (*filec)++;\n   l= strlen(adr)+1;\n   (*mem)+= sizeof(char *)+l;\n   if(l % sizeof(char *))\n     (*mem)+= sizeof(char *)-(l % sizeof(char *));\n } else {\n   if(*filec >= count_limit) {\n     sprintf(xorriso->info_text,\n         \"Number of matching files changed unexpectedly (> %d)\",\n         count_limit);\n     Xorriso_msgs_submit(xorriso, 0, xorriso->info_text, 0,\n                         (flag&2 ? \"FATAL\" : \"WARNING\"), 0);\n     return(flag&2 ? -1 : 0);\n   }\n   filev[*filec]= strdup(adr);\n   if(filev[*filec]==NULL) {\n     Xorriso_no_pattern_memory(xorriso, (off_t) (strlen(adr)+1), 0);\n     return(-1);\n   }\n   (*filec)++;\n }\n return(1);\n}",
    "comment": "Registers a matched address by updating file count, allocating memory for the address, and handling errors based on a specified flag.",
    "prorec_sum": "Adds a file path to a list, updates counters and memory alignment, and logs a warning or fatal error if expected count is exceeded.",
    "filter_prorec_sum": "Adds a matching filename to a list, updating counters and alignment, or logs a warning/fatal if the match count exceeds the expected limit.",
    "prorec_aug_sum": "Handles adding a matching filename to a list, updating counters and buffers, and issuing warnings or fatal errors if count limits are exceeded.",
    "filter_prorec_aug_sum": "Adds a matching file name to a list, updating counters and buffers, and logs warnings or fatal errors if count limits are exceeded.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles adding a matching filename to a list, updating counters and buffers, and issuing warnings or fatal errors if count limits are exceeded.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function adds a matching filename to a list, updates counters and memory usage, and issues warnings or fatal errors if the count limit is exceeded. These are directly verifiable and accurate from the code, including the count limit check and the messaging. No significant inaccuracies or unrelated information are present, making all claims accurate.",
                "The summary accurately captures the core purpose: adding a matching filename to a list and updating counters/buffers. It also includes the accurate condition of issuing warnings or fatal errors when the count limit is exceeded. However, it omits several secondary details such as the behavior when flag&1 is set (only size/memory calculation without adding), precise memory alignment adjustments, handling of memory allocation failures with a separate function, and the return values for different conditions. These omissions limit coverage of secondary behavior-critical semantics.",
                "The summary correctly captures the core behavior: it adds a matching filename to a list, updates counters and memory usage, and issues warnings or fatal errors when the count limit is exceeded. These are accurate reflections of the source code's primary purpose and error handling logic. There is no contradictory or irrelevant noise, and the claims are fairly specific to the function's semantics, providing clear value."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Adds a matching file name to a list, updating counters and buffers, and logs warnings or fatal errors if count limits are exceeded.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function adds a matching file name to a list, updates counters and buffers, and logs warnings or fatal errors when count limits are exceeded, all of which are supported by the code. While it omits some details such as specific behavior when the flag changes processing flow, all included claims are accurate to the function\u2019s semantics, resulting in a high accuracy proportion.",
                "The summary correctly states that the function adds a matching file name to a list, updates counters/buffers, and logs warnings or fatal errors when count limits are exceeded, aligning with the core behavior in the code. However, it omits important branches such as the flag-based memory calculation path, the distinction between warning and fatal modes when exceeding limits, and the handling of memory allocation failures. Coverage of secondary behaviors is minimal, making the description incomplete despite accurately capturing the primary purpose.",
                "The summary accurately captures the core behavior: adding a matching file name to a list, updating counters/memory buffers, and issuing warnings or fatal errors if the count limit is exceeded. All claims align with the source code without contradiction, and there is no noise. However, while correct, the description is somewhat generic and omits specific allocation details (pointer sizing, string duplication, memory calculation logic) that could enhance usefulness. This yields moderate gain without significant shortcomings."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\ngmbus_xfer_read(struct drm_i915_private *dev_priv, struct i2c_msg *msg,\n\t\tu32 gmbus1_index)\n{\n\tint reg_offset = dev_priv->gpio_mmio_base;\n\tu16 len = msg->len;\n\tu8 *buf = msg->buf;\n\n\tI915_WRITE(GMBUS1 + reg_offset,\n\t\t   gmbus1_index |\n\t\t   GMBUS_CYCLE_WAIT |\n\t\t   (len << GMBUS_BYTE_COUNT_SHIFT) |\n\t\t   (msg->addr << GMBUS_SLAVE_ADDR_SHIFT) |\n\t\t   GMBUS_SLAVE_READ | GMBUS_SW_RDY);\n\twhile (len) {\n\t\tint ret;\n\t\tu32 val, loop = 0;\n\n\t\tret = gmbus_wait_hw_status(dev_priv, GMBUS_HW_RDY,\n\t\t\t\t\t   GMBUS_HW_RDY_EN);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tval = I915_READ(GMBUS3 + reg_offset);\n\t\tdo {\n\t\t\t*buf++ = val & 0xff;\n\t\t\tval >>= 8;\n\t\t} while (--len && ++loop < 4);\n\t}\n\n\treturn 0;\n}",
    "comment": "Reads data from a GMBUS device into a buffer, handling timing and status checks during the transfer process.",
    "prorec_sum": "Transfers data blocks from a buffer to hardware registers in 256-byte chunks, invoking helper routines for writing and reading until all bytes are processed.",
    "filter_prorec_sum": "Transfers data blocks from a buffer to hardware registers in chunks, issuing commands and writing bytes with periodic status checks until complete.",
    "prorec_aug_sum": "Transfers data blocks from a buffer to hardware registers in fixed-size chunks, invoking lower-level routines to send and retrieve byte values.",
    "filter_prorec_aug_sum": "Transfers chunks of up to 256 bytes from a buffer to hardware registers, invoking helper calls for data output and synchronization until completion.",
    "work_score": {
        "prorec_aug": {
            "summary": "Transfers data blocks from a buffer to hardware registers in fixed-size chunks, invoking lower-level routines to send and retrieve byte values.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function transfers data from a buffer to hardware registers, which is inaccurate because the source code reads from hardware registers into a buffer. It also suggests the transfer direction is to hardware, contradicting the actual read operation. While it correctly implies chunked reading and calling lower-level routines, the core description of data flow direction is wrong, making less than half of the claims accurate.",
                "The summary inaccurately describes the direction of data transfer: the source code reads from hardware registers into a provided buffer, not from the buffer to hardware. This directly contradicts the core purpose of the function. The actual core operation is performing an I2C read transaction over GMBUS into msg->buf, handling up to four bytes per hardware-ready event and using gmbus_wait_hw_status for readiness. The summary neither captures this core purpose accurately nor mentions key behavior details like hardware readiness checks, use of GMBUS constants, or looping until all bytes are read.",
                "The summary incorrectly describes the data direction as transferring from a buffer to hardware registers, whereas the code reads bytes from hardware (GMBUS3 register) into a buffer. This is a FATAL error affecting the primary purpose. While it mentions chunked processing and lower-level routines, the core WHAT is wrong, making the description misleading and untrustworthy."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Transfers chunks of up to 256 bytes from a buffer to hardware registers, invoking helper calls for data output and synchronization until completion.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary inaccurately describes the direction and nature of the transfer. The source code performs a read operation from hardware (GMBUS3) into a buffer, not from a buffer to hardware registers, and processes data in up to 4-byte chunks, not 256-byte chunks. It also omits key details like setting up GMBUS1 with the read and address configuration. These errors mean less than half of the claims match the actual code semantics.",
                "The summary incorrectly describes the function as transferring data from a buffer to hardware registers for output, while the source code actually reads data from hardware (GMBUS) into a buffer for I2C messages. This misstates the core purpose and direction of data flow, so the core domain semantics are not covered. There is no mention of key constants, flags, or error handling in the loop, and the helper function gmbus_wait_hw_status is used for readiness checking, not generic synchronization as stated.",
                "The summary incorrectly describes the function as transferring data from a buffer to hardware registers for output, whereas the source code clearly reads data from hardware (GMBUS registers) into a buffer. This is a FATAL inaccuracy targeting the primary purpose of the function (core data direction), making the description unusable. There are no accurate claims to offset this major error."
            ]
        }
    }
}
{
    "source_code": "static void purge_old_ps_buffers(struct ieee80211_local *local)\n{\n\tint total = 0, purged = 0;\n\tstruct sk_buff *skb;\n\tstruct ieee80211_sub_if_data *sdata;\n\tstruct sta_info *sta;\n\n\tlist_for_each_entry_rcu(sdata, &local->interfaces, list) {\n\t\tstruct ps_data *ps;\n\n\t\tif (sdata->vif.type == NL80211_IFTYPE_AP)\n\t\t\tps = &sdata->u.ap.ps;\n\t\telse if (ieee80211_vif_is_mesh(&sdata->vif))\n\t\t\tps = &sdata->u.mesh.ps;\n\t\telse\n\t\t\tcontinue;\n\n\t\tskb = skb_dequeue(&ps->bc_buf);\n\t\tif (skb) {\n\t\t\tpurged++;\n\t\t\tdev_kfree_skb(skb);\n\t\t}\n\t\ttotal += skb_queue_len(&ps->bc_buf);\n\t}\n\n\t/*\n\t * Drop one frame from each station from the lowest-priority\n\t * AC that has frames at all.\n\t */\n\tlist_for_each_entry_rcu(sta, &local->sta_list, list) {\n\t\tint ac;\n\n\t\tfor (ac = IEEE80211_AC_BK; ac >= IEEE80211_AC_VO; ac--) {\n\t\t\tskb = skb_dequeue(&sta->ps_tx_buf[ac]);\n\t\t\ttotal += skb_queue_len(&sta->ps_tx_buf[ac]);\n\t\t\tif (skb) {\n\t\t\t\tpurged++;\n\t\t\t\tieee80211_free_txskb(&local->hw, skb);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tlocal->total_ps_buffered = total;\n\tps_dbg_hw(&local->hw, \"PS buffers full - purged %d frames\\n\", purged);\n}",
    "comment": "Purges old Power Save buffers from access points and stations, freeing memory and updating the total buffered frame count.",
    "prorec_sum": "Traverses two linked lists, processes selected entries with a helper routine, accumulates their counters, and stores the total into the object's data field.",
    "filter_prorec_sum": "Traverses two linked lists of objects, processes those with valid data using a helper routine, sums specific integer fields, and stores the accumulated total.",
    "prorec_aug_sum": "Aggregates specific node values from two linked lists, processes matching entries, and updates a total count field in the given data structure.",
    "filter_prorec_aug_sum": "Aggregates specific node metrics from two linked lists, processes matching entries, and stores the total count into the parent structure\u2019s field.",
    "work_score": {
        "prorec_aug": {
            "summary": "Aggregates specific node values from two linked lists, processes matching entries, and updates a total count field in the given data structure.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes generic aggregation of node values from linked lists and processing of matching entries, but the source code specifically purges old power-save buffers from AP and mesh interfaces, frees SKBs, updates a total count, and logs purged frames. The claims in the summary do not accurately reflect the code\u2019s domain-semantic behavior and omit key details like conditional interface handling, dequeue/free operations, and per-station buffer purging. All claims are either inaccurate or too generic to match the precise functionality.",
                "The summary's claims about aggregating node values from two linked lists and processing matching entries do not accurately describe the source code's domain-specific purpose, which is purging buffered power-save frames from AP/mesh interfaces and stations in an IEEE 802.11 local context. None of the claims cover the actual core behavior. There is a vague mention of updating a total count, which loosely aligns with updating total_ps_buffered, but the primary purging logic and domain semantics are entirely missing.",
                "The summary is inaccurate about the core function behavior: it describes aggregating node values from two linked lists and processing matching entries, which contradicts the actual code that iterates over interface and station lists to purge power-save buffers and update a total count. This is a severe mismatch on the primary purpose and key I/O, constituting a fatal error."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Aggregates specific node metrics from two linked lists, processes matching entries, and stores the total count into the parent structure\u2019s field.",
            "score": [
                0.3,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function aggregates specific node metrics from two linked lists, processes matching entries, and stores the total in a parent structure. While it is true that the code iterates over two linked lists and stores a total count in a struct field, the term 'specific node metrics' is vague and does not accurately describe that the metrics are buffer lengths. The claim about 'processing matching entries' is inaccurate, as the code processes all applicable entries, not only matches. Thus, only part of the summary correctly reflects the code, leading to less than half of the claims being accurate.",
                "The summary fails to capture the core purpose of purging power-save buffers for AP and mesh interfaces, and removing one frame from each station's lowest-priority access category. It offers a generic description of aggregating metrics and updating a field, which is inaccurate regarding the specific domain semantics of buffer management and frame deletion in the source code. No accurate claims align with the actual core operation, and key behavior such as dequeueing, freeing sk_buffs, handling different interface types, iterating stations, and logging purged frames is omitted.",
                "The summary claims aggregation of node metrics from two linked lists and storing the total into the parent structure\u2019s field, which loosely matches the code\u2019s high-level behavior of iterating over two lists, summing buffer lengths, and updating a total field. However, it omits critical specifics: the lists are of interfaces and stations, the processing involves selective dequeue and freeing of buffers, and it misrepresents the purpose as metric aggregation rather than buffer purging. This yields low informational value, and the primary purpose is inaccurately conveyed, making this a FATAL error affecting core semantics."
            ]
        }
    }
}
{
    "source_code": "\nstatic void mroute_netlink_event(struct mr_table *mrt, struct mfc_cache *mfc,\n\t\t\t\t int cmd)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct sk_buff *skb;\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(mroute_msgsize(mfc->mfc_parent >= MAXVIFS, mrt->maxvif),\n\t\t\tGFP_ATOMIC);\n\tif (skb == NULL)\n\t\tgoto errout;\n\n\terr = ipmr_fill_mroute(mrt, skb, 0, 0, mfc, cmd);\n\tif (err < 0)\n\t\tgoto errout;\n\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV4_MROUTE, NULL, GFP_ATOMIC);\n\treturn;\n\nerrout:\n\tkfree_skb(skb);\n\tif (err < 0)\n\t\trtnl_set_sk_err(net, RTNLGRP_IPV4_MROUTE, err);\n}",
    "comment": "Notifies the kernel about multicast route changes by creating and sending a netlink message based on the provided mfc_cache and command.",
    "prorec_sum": "Allocates and initializes a routing-related structure with provided parameters, handles errors by freeing resources, and reports status to the networking subsystem.",
    "filter_prorec_sum": "Allocates and initializes a network-related structure with provided parameters, handles errors by freeing resources, and reports status through a specified context.",
    "prorec_aug_sum": "Allocates and initializes a data structure with provided parameters, processes it, and handles cleanup and error reporting based on the operation\u2019s result.",
    "filter_prorec_aug_sum": "Allocates and initializes a data structure with provided parameters, invokes a setup routine, handles errors by cleanup, and signals the result to a managing context.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and initializes a data structure with provided parameters, processes it, and handles cleanup and error reporting based on the operation\u2019s result.",
            "score": [
                0.6,
                0.2,
                0.5
            ],
            "reason": [
                "The summary makes generic claims about allocation, initialization, processing, cleanup, and error reporting, which loosely match the code's structure. However, it omits key specifics such as use of netlink message creation (`nlmsg_new`), multicast routing context, and notification through `rtnl_notify`, and instead describes high-level behavior without domain-specific details. Most claims are broadly accurate but lack precision, resulting in moderate alignment.",
                "The summary is generic and omits the core purpose of sending a multicast routing netlink notification about a given multicast forwarding cache change, which is the key domain-specific action in the source. While it mentions allocation, processing, and cleanup, these are generic behaviors and do not capture the specific networking and netlink message semantics. No accurate claim reflects the core primary purpose, and there is minimal secondary detail.",
                "The summary gives a generic lifecycle description but omits specific and critical behaviors in the source code, such as using nlmsg_new for netlink message allocation, sending notifications via rtnl_notify, and signaling errors with rtnl_set_sk_err for the IPv4 multicast routing group. The claims are SAFE but very low\u2011info, with no FATAL inaccuracies, yet the vagueness means the engineer gains little domain\u2011specific insight."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates and initializes a data structure with provided parameters, invokes a setup routine, handles errors by cleanup, and signals the result to a managing context.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary captures some generic aspects of the code, such as allocation, initialization, invoking a routine, error handling with cleanup, and signalling results. However, it misses key domain-specific details: the function allocates an sk_buff via nlmsg_new with calculated size, fills it with multicast routing information using ipmr_fill_mroute, and sends notifications via rtnl_notify or rtnl_set_sk_err. The summary\u2019s terms like 'data structure', 'setup routine', and 'managing context' are vague and not directly verifiable against the source code\u2019s specific behavior. This leads to only partial accuracy.",
                "The summary provides only generic descriptions such as allocation, initialization, invoking a routine, cleanup, and signaling, without mentioning the core purpose of sending multicast routing events via netlink for IPv4. While these actions loosely align with the code flow, they omit the primary domain-specific behavior and critical details like use of rtnl_notify to RTNLGRP_IPV4_MROUTE, message sizing, and specific error handling via rtnl_set_sk_err. This results in the core purpose not being covered and very limited secondary coverage.",
                "The summary provides a generic outline of allocation, initialization, setup invocation, error cleanup, and signaling, which loosely matches the code\u2019s structure. However, it omits critical, specific details such as the use of netlink messaging, ipmr_fill_mroute, rtnl_notify, and rtnl_set_sk_err. These omissions make the claims too broad and low-information. There are no outright contradictions (no FATAL), but the lack of domain-specific accuracy yields only SAFE claims, resulting in low net benefit with noticeable noise."
            ]
        }
    }
}
{
    "source_code": "\nvoid inet_twdr_twkill_work(struct work_struct *work)\n{\n\tstruct inet_timewait_death_row *twdr =\n\t\tcontainer_of(work, struct inet_timewait_death_row, twkill_work);\n\tint i;\n\n\tBUILD_BUG_ON((INET_TWDR_TWKILL_SLOTS - 1) >\n\t\t\t(sizeof(twdr->thread_slots) * 8));\n\n\twhile (twdr->thread_slots) {\n\t\tspin_lock_bh(&twdr->death_lock);\n\t\tfor (i = 0; i < INET_TWDR_TWKILL_SLOTS; i++) {\n\t\t\tif (!(twdr->thread_slots & (1 << i)))\n\t\t\t\tcontinue;\n\n\t\t\twhile (inet_twdr_do_twkill_work(twdr, i) != 0) {\n\t\t\t\tif (need_resched()) {\n\t\t\t\t\tspin_unlock_bh(&twdr->death_lock);\n\t\t\t\t\tschedule();\n\t\t\t\t\tspin_lock_bh(&twdr->death_lock);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ttwdr->thread_slots &= ~(1 << i);\n\t\t}\n\t\tspin_unlock_bh(&twdr->death_lock);\n\t}\n}",
    "comment": "Processes and removes active threads from the timewait death row while managing concurrency using spin locks and checking for rescheduling needs.",
    "prorec_sum": "Processes and clears active bit flags by invoking associated handlers until no flags remain, repeatedly performing conditional operations based on status bits.",
    "filter_prorec_sum": "Processes pending flags for up to eight channels, invoking handlers until conditions clear, then updates the flag mask and repeats until all are serviced.",
    "prorec_aug_sum": "Processes up to eight flagged work items, repeatedly invoking handlers until completion, clearing processed flags, and looping until no pending tasks remain.",
    "filter_prorec_aug_sum": "Processes up to eight flagged entries by repeatedly invoking handler routines until completion and clearing processed flags in the given data structure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes up to eight flagged work items, repeatedly invoking handlers until completion, clearing processed flags, and looping until no pending tasks remain.",
            "score": [
                0.8,
                0.5,
                0.9
            ],
            "reason": [
                "The summary correctly describes looping over flagged work items, repeatedly invoking a handler until completion, clearing the flag, and continuing until no items remain, which aligns with the code's structure. However, it inaccurately states 'up to eight' items, since the actual limit is set by INET_TWDR_TWKILL_SLOTS, which is not explicitly fixed to eight in the code snippet. This is a minor inaccuracy, so most claims are correct but with a small factual error.",
                "The summary correctly describes the looping over flagged items, repeated invocation until completion, clearing flags, and finishing when no tasks remain, which matches the code's core purpose of processing timewait death row slots until all are cleared. However, it omits important specifics: the domain context of TCP timewait socket cleanup, the slot count constant from the code (INET_TWDR_TWKILL_SLOTS), the locking and rescheduling behavior, and the exact external function called for slot processing. Core purpose is covered but secondary behavior and domain specifics are lacking.",
                "The summary correctly captures core logic: iterating through flagged slots, repeatedly processing them until completion, clearing flags, and continuing until no pending items remain. The 'up to eight' detail matches INET_TWDR_TWKILL_SLOTS in the BUILD_BUG_ON constraint, indicating accurate specificity. No claims contradict the code, and noise is minimal, resulting in a strong alignment with the source semantics and clear description of primary purpose and key control flow."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes up to eight flagged entries by repeatedly invoking handler routines until completion and clearing processed flags in the given data structure.",
            "score": [
                0.6,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly captures the looped processing of flagged slots via handler routines and the clearing of processed flags in the data structure, aligning with the function's behavior. However, it inaccurately specifies a fixed limit of eight entries, which is not evident in the source code as the slot count depends on INET_TWDR_TWKILL_SLOTS. This introduces a notable error in one of the claims, reducing overall accuracy.",
                "The summary captures elements such as looping over flagged entries, invoking a handler until completion, and clearing flags, which are accurate with respect to the code\u2019s iteration over thread_slots bits, calling inet_twdr_do_twkill_work, and resetting bits. However, it does not clearly convey the core primary purpose of performing TCP time-wait socket cleanup within a death row structure, omitting key semantics like lock handling, scheduling when needed, and the context of network protocol cleanup. This results in partial coverage of the function's true purpose and limited secondary detail.",
                "The summary accurately describes the looped processing of flagged entries and clearing of flags, which matches the code's iteration over slot bits and calls to the handler function. However, it incorrectly states a fixed maximum of eight entries; the real maximum depends on INET_TWDR_TWKILL_SLOTS from compile-time constants, and is not evident as eight in the source. This numerical inaccuracy affects a specific implementation detail but does not alter the core purpose. The rest is correct but high level, providing limited insight into locking, scheduling, or slot bitmask operations. Noise is minimal and gain is low from mostly generic description."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic int unix_getname(struct socket *sock, struct sockaddr *uaddr, int *uaddr_len, int peer)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct unix_sock *u;\n\tDECLARE_SOCKADDR(struct sockaddr_un *, sunaddr, uaddr);\n\tint err = 0;\n\n\tif (peer) {\n\t\tsk = unix_peer_get(sk);\n\n\t\terr = -ENOTCONN;\n\t\tif (!sk)\n\t\t\tgoto out;\n\t\terr = 0;\n\t} else {\n\t\tsock_hold(sk);\n\t}\n\n\tu = unix_sk(sk);\n\tunix_state_lock(sk);\n\tif (!u->addr) {\n\t\tsunaddr->sun_family = AF_UNIX;\n\t\tsunaddr->sun_path[0] = 0;\n\t\t*uaddr_len = sizeof(short);\n\t} else {\n\t\tstruct unix_address *addr = u->addr;\n\n\t\t*uaddr_len = addr->len;\n\t\tmemcpy(sunaddr, addr->name, *uaddr_len);\n\t}\n\tunix_state_unlock(sk);\n\tsock_put(sk);\nout:\n\treturn err;\n}",
    "comment": "Retrieves the Unix socket's address or initializes it as empty if not connected, handling peer connections appropriately.",
    "prorec_sum": "Retrieves address data into a buffer, updates a reference count, and invokes cleanup when no longer referenced.",
    "filter_prorec_sum": "Retrieves address data from a socket structure, updates output parameters, and manages reference counts with locking and cleanup on zero references.",
    "prorec_aug_sum": "Retrieves an associated data entry, updates reference counters, copies its contents into the destination buffer, and performs cleanup when no longer referenced.",
    "filter_prorec_aug_sum": "Retrieves and writes structured data from an object, updating reference counts and invoking cleanup when no references remain.",
    "work_score": {
        "prorec_aug": {
            "summary": "Retrieves an associated data entry, updates reference counters, copies its contents into the destination buffer, and performs cleanup when no longer referenced.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary contains mostly inaccurate representations of the function's behavior. While it loosely suggests copying data into a destination buffer, it omits or misrepresents key semantics such as retrieving a socket's own or peer's address, handling AF_UNIX structure initialization, locking state, and returning an error if not connected. It incorrectly generalizes behavior to 'associated data entry' and 'cleanup when no longer referenced,' which are not precise to the source. Less than half of the claims are accurate, leading to a low score.",
                "The summary does not mention the core purpose of retrieving a UNIX socket address, including handling peer sockets, populating sockaddr_un with family and path data, and returning errors appropriately. While it generically notes retrieval, reference counting, copying to a buffer, and cleanup, these are vague and lack the domain-specific detail needed to identify the function\u2019s actual operation. No accurate claim in the summary covers the primary semantics or key branches in the source code.",
                "The summary contains mostly inaccurate and vague statements. The code specifically retrieves a UNIX socket name (or peer name), manages reference counts with sock_hold/sock_put, and copies address data into the provided sockaddr buffer with proper locking. The summary\u2019s phrase 'retrieves an associated data entry' is overly generic but loosely aligns, while 'updates reference counters' matches a safe detail. However, 'performs cleanup when no longer referenced' is misleading since the code just decrements references rather than explicit cleanup, and 'associated data entry' does not convey the function\u2019s primary purpose of retrieving socket address information. The worst issue is NOISE due to lack of primary purpose description and vague terms, while no outright fatal contradictions about core purpose exist."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Retrieves and writes structured data from an object, updating reference counts and invoking cleanup when no references remain.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes generic object data retrieval, reference count updates, and cleanup logic, but the source code specifically handles a UNIX domain socket address retrieval with conditional peer lookup, address copying, and locking. The summary does not capture these domain-specific behaviors and omits important details such as address family, memory copy, and error handling. Most claims are inaccurate because they don't match the code's actual functionality.",
                "The summary\u2019s claim about retrieving and writing structured data from an object and cleaning up when no references remain does not align with the actual function, which retrieves a local or peer UNIX socket address into a sockaddr structure, adjusts reference counts via sock_hold/sock_put, and handles cases with or without a bound address. The core purpose of retrieving a UNIX socket address is missing, and the described behavior is too generic and partially inaccurate about cleanup semantics.",
                "The summary ignores the primary purpose of the function, which is to obtain the local or peer address of a UNIX domain socket, populate the provided sockaddr structure, and update the length accordingly. Instead, it incorrectly focuses on generic notions of retrieving structured data, reference counting, and cleanup when no references remain\u2014concepts that are not explicitly implemented here. This constitutes a FATAL error about the core functionality, making the description untrustworthy."
            ]
        }
    }
}
{
    "source_code": "void sqlite3AddDefaultValue(Parse *pParse, ExprSpan *pSpan){\n  Table *p;\n  Column *pCol;\n  sqlite3 *db = pParse->db;\n  p = pParse->pNewTable;\n  if( p!=0 ){\n    pCol = &(p->aCol[p->nCol-1]);\n    if( !sqlite3ExprIsConstantOrFunction(pSpan->pExpr, db->init.busy) ){\n      sqlite3ErrorMsg(pParse, \"default value of column [%s] is not constant\",\n          pCol->zName);\n    }else{\n      /* A copy of pExpr is used instead of the original, as pExpr contains\n      ** tokens that point to volatile memory. The 'span' of the expression\n      ** is required by pragma table_info.\n      */\n      Expr x;\n      sqlite3ExprDelete(db, pCol->pDflt);\n      memset(&x, 0, sizeof(x));\n      x.op = TK_SPAN;\n      x.u.zToken = sqlite3DbStrNDup(db, (char*)pSpan->zStart,\n                                    (int)(pSpan->zEnd - pSpan->zStart));\n      x.pLeft = pSpan->pExpr;\n      x.flags = EP_Skip;\n      pCol->pDflt = sqlite3ExprDup(db, &x, EXPRDUP_REDUCE);\n      sqlite3DbFree(db, x.u.zToken);\n    }\n  }\n  sqlite3ExprDelete(db, pSpan->pExpr);\n}",
    "comment": "Validates and sets a default value for the last column of a new table, ensuring it is a constant expression before storing it.",
    "prorec_sum": "Sets a constant default value for a database column, creating and assigning the associated expression object, or reports an error if non-constant.",
    "filter_prorec_sum": "Updates a table column\u2019s default value when it is a constant, otherwise logs an error, and manages related memory references.",
    "prorec_aug_sum": "Validates a column\u2019s default value as constant, builds and assigns its data structure, and cleans up or reports an error if validation fails.",
    "filter_prorec_aug_sum": "Updates a table column\u2019s default value if it is constant, creating and attaching the necessary internal object, otherwise logs an error.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates a column\u2019s default value as constant, builds and assigns its data structure, and cleans up or reports an error if validation fails.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary contains three core claims: that the function validates whether a column\u2019s default value is constant, that it constructs and assigns the associated data structure, and that it either cleans up resources or reports an error when validation fails. All three are accurate per the source code: the constant check is done via sqlite3ExprIsConstantOrFunction, the data structure is built with TK_SPAN and assigned to pCol->pDflt, and either an error message is issued or cleanup occurs accordingly. No inaccuracies or irrelevant content are present.",
                "The summary accurately states that the function validates a column's default value as constant, assigns it if valid, and reports an error otherwise, which aligns with the core purpose of adding a default value to the last column of a new table after checking constancy. It also captures the cleanup aspect. However, it omits specifics like targeting the last added column, replacing any existing default, using a token span copy to avoid volatile references, and freeing resources after duplication. The coverage of core purpose is present but secondary details are limited.",
                "The summary captures the main purpose accurately: it validates the column's default value as constant, constructs the necessary expression data structure, assigns it to the column, and reports an error if validation fails. It also notes cleanup, which is supported by the final deletion of pSpan->pExpr. All claims are consistent with the source, with no factual errors or extraneous noise. The gain is moderate since the description is concise but omits some implementation details like the TK_SPAN wrapping and the specific memory handling."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Updates a table column\u2019s default value if it is constant, creating and attaching the necessary internal object, otherwise logs an error.",
            "score": [
                0.9,
                0.5,
                0.9
            ],
            "reason": [
                "The summary contains two main claims: (1) the function updates a column\u2019s default value if it is constant, and (2) it logs an error otherwise. Both align with the source code: the function checks if the expression is constant and, if so, duplicates and assigns it to the column's default, otherwise calls sqlite3ErrorMsg. The phrase 'creating and attaching the necessary internal object' is somewhat vague but reasonably reflects the creation and duplication of an Expr structure. Nearly all claims are accurate and grounded in the code.",
                "The summary accurately states that the function updates a table column's default value when it is constant and logs an error otherwise, which matches the core purpose of validating it is constant and setting the default expression for the most recently added column. However, it omits notable secondary details from the code, such as handling token spans for pragma output, copying expressions to avoid volatile memory issues, freeing previous defaults, and deleting the expression at the end. These omissions limit the completeness of coverage.",
                "The summary contains two atomic claims: (1) it updates a table column\u2019s default value if it is constant, and (2) it otherwise logs an error. Both are accurate per the code: the function checks if the expression is constant via sqlite3ExprIsConstantOrFunction, logs an error if not, and if constant, constructs a TK_SPAN expression and assigns it to the column's default. The description of 'creating and attaching the necessary internal object' matches the creation/duplication of the expression object. There is no contradictory or noisy content, and the claims are specific to the function's core behavior, yielding high gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void igmp_group_added(struct ip_mc_list *im)\n{\n\tstruct in_device *in_dev = im->interface;\n\n\tif (im->loaded == 0) {\n\t\tim->loaded = 1;\n\t\tip_mc_filter_add(in_dev, im->multiaddr);\n\t}\n\n#ifdef CONFIG_IP_MULTICAST\n\tif (im->multiaddr == IGMP_ALL_HOSTS)\n\t\treturn;\n\n\tif (in_dev->dead)\n\t\treturn;\n\tif (IGMP_V1_SEEN(in_dev) || IGMP_V2_SEEN(in_dev)) {\n\t\tspin_lock_bh(&im->lock);\n\t\tigmp_start_timer(im, IGMP_Initial_Report_Delay);\n\t\tspin_unlock_bh(&im->lock);\n\t\treturn;\n\t}\n\t/* else, v3 */\n\n\tim->crcount = in_dev->mr_qrv ? in_dev->mr_qrv :\n\t\tIGMP_Unsolicited_Report_Count;\n\tigmp_ifc_event(in_dev);\n#endif\n}",
    "comment": "The function processes the addition of an IGMP multicast group, initializing it and managing timers based on the interface's multicast version and state.",
    "prorec_sum": "Initializes a wireless station context if not already done, then updates or blocks its state based on connection flags and timing conditions.",
    "filter_prorec_sum": "Initializes a station context and updates its status or triggers wake/block actions based on connection flags and timing conditions.",
    "prorec_aug_sum": "Initializes state for a network device and conditionally triggers timestamp or mode updates based on its configuration flags and time-related checks.",
    "filter_prorec_aug_sum": "Initializes device state and conditionally triggers timer or status updates based on control fields and time comparisons within the associated device structure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes state for a network device and conditionally triggers timestamp or mode updates based on its configuration flags and time-related checks.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function initializes state for a network device and conditionally triggers timestamp or mode updates based on configuration flags and time-related checks. While the initialization part loosely matches the code's setting of `im->loaded` and adding an IP multicast filter, the mention of timestamp and time-related checks is inaccurate \u2014 the code instead handles IGMP protocol-specific logic like checking multicast address, device state (dead), IGMP version detection, and starting timers for reports. These are not generic 'timestamp' or 'mode' updates. Most semantic details are mismatched, so only a small portion is accurate.",
                "The summary claims the function initializes state for a network device and triggers timestamp or mode updates based on configuration flags and time checks, which does not match the actual semantics. The code specifically handles adding an IP multicast group to a device: it sets a loaded flag, adds a multicast filter, checks for special addresses and device state, and starts IGMP report timers or triggers interface change events. None of these domain-specific IGMP/multicast operations are mentioned, so the core purpose is entirely missed and the provided claims are inaccurate for the source.",
                "The summary's main claim about 'initializing state for a network device' is loosely aligned to the function's initial setup of the multicast group (setting im->loaded and adding filter), but it fails to correctly capture the primary purpose and behavior: joining an IGMP multicast group, handling IGMP host group conditions, and triggering IGMP timers/events. References to 'timestamp' or 'mode updates' and 'time-related checks' are inaccurate, as the code does not handle timestamps and only starts timers for IGMP reporting under specific protocol version checks. This introduces a FATAL error on the core purpose, making the description misleading about the actual network protocol logic."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes device state and conditionally triggers timer or status updates based on control fields and time comparisons within the associated device structure.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is vague and omits key specific behaviors present in the source code, such as checking and setting 'loaded', adding an IP multicast filter, handling the IGMP_ALL_HOSTS address, early returns on device 'dead' status, IGMP version checks, and configuring crcount with a fallback constant. It introduces 'time comparisons' which are not explicitly in the code. While it loosely reflects conditional state initialization and timer triggering, most specific functional semantics are missing or misrepresented, resulting in less than half of the claims being accurate.",
                "The summary does not accurately capture the core purpose of the function, which is to handle the addition of an IGMP group, update the loaded flag, add the multicast address filter, and then trigger specific IGMP report/timer actions depending on multicast group type and device state. The provided description is vague, referring generally to initializing device state and conditional timers/status updates without mentioning IGMP group handling, address filtering, or protocol/version-specific behavior, resulting in core coverage being absent and secondary details missing.",
                "The summary contains a vague, generic statement about initializing device state and conditionally triggering timer or status updates, but it fails to correctly or specifically describe the core logic in the source code. It omits key details such as checking and setting 'loaded', adding a multicast filter, early returns for IGMP_ALL_HOSTS and dead devices, detection of IGMP v1/v2 to start a timer, or setting 'crcount' and triggering 'igmp_ifc_event' for v3. There are no explicit factually incorrect statements (no FATAL), but the description is overly abstract and adds speculative concepts like 'time comparisons' not grounded in the code. The accuracy is low due to high noise from these generic and inaccurate abstractions, and the gain is minimal."
            ]
        }
    }
}
{
    "source_code": "static int shrink_dqcache_memory(struct shrinker *shrink,\n\t\t\t\t struct shrink_control *sc)\n{\n\tint nr = sc->nr_to_scan;\n\n\tif (nr) {\n\t\tspin_lock(&dq_list_lock);\n\t\tprune_dqcache(nr);\n\t\tspin_unlock(&dq_list_lock);\n\t}\n\treturn ((unsigned)\n\t\tpercpu_counter_read_positive(&dqstats.counter[DQST_FREE_DQUOTS])\n\t\t/100) * sysctl_vfs_cache_pressure;\n}",
    "comment": "Releases disk quota cache memory by pruning unused entries based on the specified number of entries to scan and adjusts the cache pressure accordingly.",
    "prorec_sum": "Releases and cleans up a set of linked resource objects under a lock, invoking their destructors, then returns a scaled usage metric value.",
    "filter_prorec_sum": "Cleans up and unlinks a set of linked structures, invokes their cleanup callbacks, and returns a scaled value based on a global counter.",
    "prorec_aug_sum": "Cleans up and unlinks a series of list entries, invoking associated destructors, then returns a scaled value based on a global counter.",
    "filter_prorec_aug_sum": "Cleans up and unlinks multiple linked structures, invokes their termination callbacks, then returns a scaled value based on a global 64\u2011bit counter.",
    "work_score": {
        "prorec_aug": {
            "summary": "Cleans up and unlinks a series of list entries, invoking associated destructors, then returns a scaled value based on a global counter.",
            "score": [
                0.5,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims that the function unlinks list entries and invokes destructors, which is inaccurate as the code uses prune_dqcache under a spinlock to free dqcache entries, not explicitly unlink lists or call destructors. The claim about returning a scaled value from a global counter is accurate. Given that only one of the two key claims matches the source code behavior, accuracy is around 50%, indicating mixed reliability.",
                "The summary's core claim about cleaning up and unlinking list entries with destructors is inaccurate; the function specifically prunes the dquot cache under a spinlock, not arbitrary list entries or destructor calls. While it correctly notes returning a scaled value based on a global counter, it fails to mention the core purpose of pruning quota caches and omits key details like lock usage, conditional execution when nr_to_scan is non-zero, and the role of sysctl_vfs_cache_pressure in scaling. The core domain-specific action is not covered accurately, so the score reflects that omission.",
                "The summary inaccurately describes the function as cleaning up and unlinking list entries with associated destructors, which is not reflected in the source code\u2014it prunes a quota cache under a lock. This is a FATAL error affecting the core purpose. The return value description is partially accurate, noting scaling of a global counter, but omits detail about the specific counter and multiplier. The worst failure mode is a FATAL on the primary purpose, rendering the summary misleading and untrustworthy despite minor correct elements."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Cleans up and unlinks multiple linked structures, invokes their termination callbacks, then returns a scaled value based on a global 64\u2011bit counter.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function unlinks multiple linked structures and invokes termination callbacks, but the source code shows it locks a cache list and prunes quota caches without explicit unlinking or callbacks, making these claims inaccurate. Only the part describing returning a scaled value from a global counter is accurate, resulting in less than half of the claims being correct.",
                "The summary incorrectly describes the core purpose: the function prunes the quota cache under a spinlock when nr_to_scan is nonzero and returns a scaled count of free dquots, but the summary mentions cleaning and unlinking multiple linked structures with termination callbacks, which is not in the source code. While it does correctly note returning a scaled value based on a global counter, it fails to capture and misrepresents the primary cache-pruning operation, making the overall coverage poor.",
                "The summary inaccurately describes the core logic: it claims the function cleans up and unlinks multiple linked structures and invokes termination callbacks, which is not present in the source code. The actual function locks a list, prunes dqcache entries, and returns a scaled counter value. The final return value description is partly accurate, but the primary purpose misstatement is a severe factual error about core behavior, making this a FATAL error. This critical inaccuracy overshadows any minor accurate detail."
            ]
        }
    }
}
{
    "source_code": "\nvoid BN_CTX_end(BN_CTX *ctx)\n\t{\n\tCTXDBG_ENTRY(\"BN_CTX_end\", ctx);\n\tif(ctx->err_stack)\n\t\tctx->err_stack--;\n\telse\n\t\t{\n\t\tunsigned int fp = BN_STACK_pop(&ctx->stack);\n\t\t/* Does this stack frame have anything to release? */\n\t\tif(fp < ctx->used)\n\t\t\tBN_POOL_release(&ctx->pool, ctx->used - fp);\n\t\tctx->used = fp;\n\t\t/* Unjam \"too_many\" in case \"get\" had failed */\n\t\tctx->too_many = 0;\n\t\t}\n\tCTXDBG_EXIT(ctx);\n\t}",
    "comment": "Releases resources associated with the BN_CTX structure, updating the used stack frame and resetting the too_many flag if necessary.",
    "prorec_sum": "Ends a big number context by restoring stack state, releasing allocated blocks, and updating depth and position tracking fields.",
    "filter_prorec_sum": "Releases temporary BIGNUM resources in a BN_CTX context, restoring stack and pool state after a scoped allocation ends.",
    "prorec_aug_sum": "Releases temporary big number variables and stack frames from a BN_CTX structure, restoring internal counters and linked context frames.",
    "filter_prorec_aug_sum": "Releases allocated big number context frames and restores internal state counters after nested usage.",
    "work_score": {
        "prorec_aug": {
            "summary": "Releases temporary big number variables and stack frames from a BN_CTX structure, restoring internal counters and linked context frames.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function releases temporary big number resources and restores internal counters, which matches the code's actions with BN_POOL_release, adjusting ctx->used, and resetting ctx->too_many. It also notes restoring context frames, which is reasonably inferred from BN_STACK_pop and frame pointer handling. All claims are consistent with the source code behavior, with no evident inaccuracies.",
                "The summary accurately states that this function releases temporary big number variables and stack frames within a BN_CTX context, and it notes restoring internal counters, which aligns with the code\u2019s updates to ctx->used and ctx->too_many. However, the mention of restoring linked context frames is imprecise and not directly represented in the code, and it omits the conditional logic for error stack handling, the use of BN_POOL_release when appropriate, and the decrement of err_stack. While the core purpose of releasing BN_CTX resources and resetting counters is covered, secondary details such as the conditional paths, specific variable behaviors, and debug entry/exit calls are missing.",
                "The summary correctly captures the core purpose of cleaning up temporary big number variables and stack frames from a BN_CTX, as well as restoring internal counters, which matches the code\u2019s release of pool entries, popping stack frames, and resetting used and too_many. There is minimal noise and no contradictions. However, the gain is modest since the claims are largely generic with limited technical detail from the source code\u2019s specific mechanics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Releases allocated big number context frames and restores internal state counters after nested usage.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly captures that the function releases allocated big number context frames and restores internal counters, which aligns with the code\u2019s BN_POOL_release call and updates to ctx->used and ctx->too_many. Although wording is slightly generic and omits specific conditions like err_stack decrement, the claims are consistent with the source code\u2019s purpose and domain semantics, resulting in very high accuracy.",
                "The summary correctly identifies that the function releases allocated big number context frames and restores internal state, which aligns with the core purpose of ending a BN_CTX stack frame and possibly releasing resources. However, it omits important specifics shown in the code, such as decrementing the error stack, conditionally releasing from the pool based on the frame pointer, resetting the 'too_many' flag, and the distinction between frames with and without errors. These missing details limit coverage of secondary behavior-critical semantics.",
                "The summary correctly captures the core purpose of the function: releasing allocated big number context frames and restoring internal state counters after nested usage. This matches the source code behavior where BN_CTX_end handles both error stack decrementing and releasing the pool with state reset. There is no contradictory claim (no FATAL), and no irrelevant noise; however, the statement is generic and omits specific details such as the conditionally decrementing err_stack or resetting too_many, limiting its informational gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic ssize_t\narray_size_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tsector_t sectors;\n\n\tif (strncmp(buf, \"default\", 7) == 0) {\n\t\tif (mddev->pers)\n\t\t\tsectors = mddev->pers->size(mddev, 0, 0);\n\t\telse\n\t\t\tsectors = mddev->array_sectors;\n\n\t\tmddev->external_size = 0;\n\t} else {\n\t\tif (strict_blocks_to_sectors(buf, &sectors) < 0)\n\t\t\treturn -EINVAL;\n\t\tif (mddev->pers && mddev->pers->size(mddev, 0, 0) < sectors)\n\t\t\treturn -E2BIG;\n\n\t\tmddev->external_size = 1;\n\t}\n\n\tmddev->array_sectors = sectors;\n\tif (mddev->pers) {\n\t\tset_capacity(mddev->gendisk, mddev->array_sectors);\n\t\trevalidate_disk(mddev->gendisk);\n\t}\n\treturn len;\n}",
    "comment": "Sets the array size for a storage device based on input, updating capacity and validating the disk if a specific size is provided.",
    "prorec_sum": "Configures a device\u2019s operational mode, default or parsed from input, validates capacity, updates internal state, and applies provided parameter values.",
    "filter_prorec_sum": "Sets a device\u2019s configuration value to \u201cdefault\u201d or a parsed custom setting, validates limits, updates state, and applies provided calibration parameters.",
    "prorec_aug_sum": "Sets a device parameter to either the default or a validated custom value and updates related structures with provided configuration data.",
    "filter_prorec_aug_sum": "Configures the target object's current profile to either \"default\" or a validated custom value and updates related parameters through a linked handler.",
    "work_score": {
        "prorec_aug": {
            "summary": "Sets a device parameter to either the default or a validated custom value and updates related structures with provided configuration data.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly captures that the function can set a parameter to a default or a validated custom value and that it updates related structures, which aligns with the code's logic of handling 'default' vs parsed values and updating array_sectors and disk capacity. However, it omits more specific behaviors, such as error handling with -EINVAL/-E2BIG and the exact nature of the parameter (array size in sectors), making it somewhat generic but still mostly accurate.",
                "The summary conveys that the function sets a parameter to a default or validated custom value and updates related structures, which loosely aligns with the core purpose of setting the RAID array size based on 'default' or parsed input and updating disk capacity. However, it omits the specific domain context (array size in sectors for an md device), lacks key secondary details like error handling for invalid input and oversizing (-EINVAL, -E2BIG), and the explicit updates to gendisk capacity and revalidation. The coverage of the core is vague and generic rather than matching the concrete domain semantics.",
                "The summary correctly captures the broad idea that the function sets a device parameter either to a default or a validated custom value and updates related structures, which aligns with the code\u2019s handling of 'default' or parsed input, validation via strict_blocks_to_sectors, and updating array_sectors, capacity, and revalidating the disk. However, the description is very generic and lacks specific details such as error conditions (-EINVAL, -E2BIG), the exact fields updated (external_size, array_sectors), and particular calls made to mddev->pers->size or set_capacity/revalidate_disk. There is no inaccurate or contradictory claim, but the gain is low due to the high-level abstraction."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Configures the target object's current profile to either \"default\" or a validated custom value and updates related parameters through a linked handler.",
            "score": [
                0.3,
                0.1,
                0.4
            ],
            "reason": [
                "The summary claims the function configures an object's profile to 'default' or a validated custom value, which loosely aligns with checking for the 'default' string or parsing a custom size. However, it inaccurately frames the operation as configuring a 'profile' rather than setting array size in sectors, and omits critical behaviors such as error returns for invalid input, updating external_size, and refreshing disk capacity. This results in significant semantic mismatch with the source code, with less than half of the claims being accurate.",
                "The summary vaguely describes configuring a profile to 'default' or a custom value but misrepresents the core purpose, which is setting the RAID array size based on input (either default from the personality's size or from a parsed value) and updating 'mddev' fields and disk capacity. It omits key specifics such as processing sector values, validating against maximum size (E2BIG), handling string parsing errors (EINVAL), updating 'external_size' flags, and calling set_capacity and revalidate_disk. The only partially accurate element is the branching on 'default' versus custom input, but terminology like 'current profile' and 'linked handler' is inaccurate for this domain, leading to no meaningful coverage of the core RAID size-setting behavior.",
                "The summary captures that the function supports a 'default' case or a custom value and updates related parameters, which aligns loosely with the code\u2019s conditional handling and subsequent updates to `array_sectors`. However, the description abstracts away key specifics: it refers inaccurately to configuring a 'current profile' and a 'linked handler', which are not present in the code (this is NOISE). The core behavior of manipulating `mddev->array_sectors`, `external_size`, and disk capacity is missing. There is no FATAL error about the primary purpose, but the vagueness and invented terminology reduce precision, making the net benefit low."
            ]
        }
    }
}
{
    "source_code": "void exit_itimers(struct signal_struct *sig)\n{\n\tstruct k_itimer *tmr;\n\n\twhile (!list_empty(&sig->posix_timers)) {\n\t\ttmr = list_entry(sig->posix_timers.next, struct k_itimer, list);\n\t\titimer_delete(tmr);\n\t}\n}",
    "comment": "Deletes all posix timers associated with the given signal structure by iterating through and removing each timer from the list.",
    "prorec_sum": "Removes and cleans up expired POSIX timers from a linked list, invoking appropriate callbacks or logging errors when timer handlers are missing.",
    "filter_prorec_sum": "Processes and removes expired POSIX timers from a linked list, invoking type-specific handlers and cleaning up associated resources.",
    "prorec_aug_sum": "Removes expired POSIX timers from a task\u2019s timer list, invoking their callbacks or cleanup routines as appropriate.",
    "filter_prorec_aug_sum": "Removes expired or invalid POSIX timer entries from a linked list and cleans up associated resources in kernel/posix-timers.c.",
    "work_score": {
        "prorec_aug": {
            "summary": "Removes expired POSIX timers from a task\u2019s timer list, invoking their callbacks or cleanup routines as appropriate.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims that the function removes expired POSIX timers and invokes their callbacks or cleanup routines. In reality, the code iterates through all timers in the signal_struct's posix_timers list and deletes them regardless of expiration status. There is no check for expiration and no explicit invocation of callbacks; only itimer_delete is called. Thus, the main claims about 'expired' timers and callback invocation are inaccurate, with only the generic mention of removing POSIX timers being partially correct.",
                "The summary asserts that the function removes expired POSIX timers and invokes their callbacks, which is inaccurate. The source code shows it iterates over all timers in a signal_struct's posix_timers list and calls itimer_delete, with no check for expiration and no explicit callback invocation. While the core action of removing POSIX timers from a list is touched upon, it is misrepresented by adding incorrect conditions and behavior, so the core primary purpose is not accurately covered.",
                "The summary incorrectly claims that the function removes expired POSIX timers and invokes callbacks, which contradicts the source code. The code actually iterates over all POSIX timers in the signal_struct and calls itimer_delete on each, without any check for expiration or explicit callback invocation. This is a FATAL error targeting the primary purpose, severely reducing trustworthiness. There are no clearly accurate, specific claims to provide positive gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Removes expired or invalid POSIX timer entries from a linked list and cleans up associated resources in kernel/posix-timers.c.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function removes expired or invalid POSIX timers, but the source code simply deletes all timers in the list regardless of their state, making the 'expired or invalid' detail inaccurate. It correctly notes removal from a linked list and cleanup of resources, aligning partially with the code\u2019s behavior. This results in a majority of claims being inaccurate, with only the generic removal and cleanup aspects matching.",
                "The summary claims removal of expired or invalid POSIX timer entries, which is inaccurate because the source code removes all timers in the posix_timers list regardless of their state. It does match some generic aspects, such as operating on a linked list and cleaning up resources, but fails to capture the core primary purpose: iterating through and deleting all POSIX timers associated with a signal_struct. Additionally, it omits specifics about the iteration loop and use of itimer_delete, providing weak secondary coverage.",
                "The summary claims that the function removes expired or invalid POSIX timer entries, which is inaccurate because the code deletes all timers in the linked list associated with the signal_struct, not specifically expired or invalid ones. This is a FATAL error targeting the primary purpose of the function (WHAT). While the mention of cleaning up resources is generally correct, the core semantics are misrepresented, resulting in severe negative impact."
            ]
        }
    }
}
{
    "source_code": "\nstatic int snd_pcm_unlink(struct snd_pcm_substream *substream)\n{\n\tstruct snd_pcm_substream *s;\n\tint res = 0;\n\n\tdown_write(&snd_pcm_link_rwsem);\n\twrite_lock_irq(&snd_pcm_link_rwlock);\n\tif (!snd_pcm_stream_linked(substream)) {\n\t\tres = -EALREADY;\n\t\tgoto _end;\n\t}\n\tlist_del(&substream->link_list);\n\tsubstream->group->count--;\n\tif (substream->group->count == 1) {\t/* detach the last stream, too */\n\t\tsnd_pcm_group_for_each_entry(s, substream) {\n\t\t\trelink_to_local(s);\n\t\t\tbreak;\n\t\t}\n\t\tkfree(substream->group);\n\t}\n\trelink_to_local(substream);\n       _end:\n\twrite_unlock_irq(&snd_pcm_link_rwlock);\n\tup_write(&snd_pcm_link_rwsem);\n\treturn res;\n}",
    "comment": "Unlinks a PCM substream from its group and releases resources if it was the last linked stream in the group.",
    "prorec_sum": "Removes an entry from a linked structure, updates related counters, reinitializes list links, and triggers further processing when only one item remains.",
    "filter_prorec_sum": "Removes an entry from a linked list, updates related queue counters, resets pointers, and triggers follow-up processing with provided parameters.",
    "prorec_aug_sum": "Removes and reinitializes a linked list entry from an audio device structure, updates related counters, and triggers subsequent audio stream handling operations.",
    "filter_prorec_aug_sum": "Removes and invalidates a linked substream structure, updates reference counters, triggers cleanup routines, and reinitializes its list pointers before returning a status code.",
    "work_score": {
        "prorec_aug": {
            "summary": "Removes and reinitializes a linked list entry from an audio device structure, updates related counters, and triggers subsequent audio stream handling operations.",
            "score": [
                0.9,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function removes a linked list entry, updates a related counter, and performs subsequent stream handling, which matches the code\u2019s deletion from `link_list`, decrementing `group->count`, and relinking operations. However, it omits key details like the initial check for an already unlinked stream returning -EALREADY and the conditional cleanup/free of the group when only one stream remains. Overall, the claims are accurate but somewhat generic and not fully comprehensive, with no factual inaccuracies.",
                "The summary contains some accurate elements such as removing a list entry, updating counters, and performing subsequent operations, which match parts of the code. However, it fails to explicitly convey the core purpose of unlinking an ALSA PCM substream from its group, including checks for already unlinked streams and special handling when only one stream remains. It also omits concurrency locking details and error handling. The description is vague about the domain (audio PCM substream unlinking) and secondary semantics like resource freeing, making coverage incomplete.",
                "The summary correctly notes removal from a linked list and updating counters, which matches the code\u2019s `list_del` and `group->count--` behaviors. However, it inaccurately describes the overall context as an 'audio device structure' and 'subsequent audio stream handling operations' without specifying the actual relinking to local streams or group deallocation logic. These vague phrases introduce noise and miss key specifics such as error return when already unlinked and the locking strategy. Noise is moderate, with only a few accurate claims of low informational gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Removes and invalidates a linked substream structure, updates reference counters, triggers cleanup routines, and reinitializes its list pointers before returning a status code.",
            "score": [
                0.9,
                0.4,
                0.7
            ],
            "reason": [
                "The summary's claims mostly match the function's behavior: it removes a linked substream from the list, decrements the group's counter, triggers cleanup (freeing the group when appropriate, relinking to local), and returns a status code. However, 'invalidates' is slightly vague and not explicitly reflected in the code, and 'reinitializes its list pointers' is an interpretive extension since the code calls relink_to_local but not an obvious generic list pointer reinitialization for all cases. Overall, well-aligned with minor overgeneralization.",
                "The summary\u2019s main claim about removing and invalidating a linked substream and updating counters is broadly accurate but misses the core primary purpose: unlinking an ALSA PCM substream from its linked group under appropriate locking. It omits the linked-state check that can return an error, the specific sequence of locks, and the conditional branch for detaching the last remaining stream and freeing its group. It also generalizes 'reinitializes its list pointers' without conveying the specific relink_to_local calls tied to domain semantics, leading to incomplete coverage of key control flow and side effects.",
                "The summary correctly reflects the primary purpose: unlinking a substream from a group (removing it from the list), updating the group's count, and performing cleanup (freeing the group if only one remains). The mention of returning a status code is accurate. However, 'invalidates' is vague and not explicitly indicated in the code, and 'reinitializes its list pointers' is somewhat misleading\u2014the function calls relink_to_local, which may reconfigure links but not a generic pointer reset. These are minor inaccuracies rather than fatal errors. Overall, the statement is mostly accurate with modest specificity, yielding moderate gain."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic ngx_int_t\nngx_http_chunked_header_filter(ngx_http_request_t *r)\n{\n    ngx_http_core_loc_conf_t       *clcf;\n    ngx_http_chunked_filter_ctx_t  *ctx;\n\n    if (r->headers_out.status == NGX_HTTP_NOT_MODIFIED\n        || r->headers_out.status == NGX_HTTP_NO_CONTENT\n        || r->headers_out.status < NGX_HTTP_OK\n        || r != r->main\n        || r->method == NGX_HTTP_HEAD)\n    {\n        return ngx_http_next_header_filter(r);\n    }\n\n    if (r->headers_out.content_length_n == -1\n        || r->expect_trailers)\n    {\n        clcf = ngx_http_get_module_loc_conf(r, ngx_http_core_module);\n\n        if (r->http_version >= NGX_HTTP_VERSION_11\n            && clcf->chunked_transfer_encoding)\n        {\n            if (r->expect_trailers) {\n                ngx_http_clear_content_length(r);\n            }\n\n            r->chunked = 1;\n\n            ctx = ngx_pcalloc(r->pool, sizeof(ngx_http_chunked_filter_ctx_t));\n            if (ctx == NULL) {\n                return NGX_ERROR;\n            }\n\n            ngx_http_set_ctx(r, ctx, ngx_http_chunked_filter_module);\n\n        } else if (r->headers_out.content_length_n == -1) {\n            r->keepalive = 0;\n        }\n    }\n\n    return ngx_http_next_header_filter(r);\n}",
    "comment": "The function processes HTTP responses to enable chunked transfer encoding when conditions regarding content length and HTTP version are met.",
    "prorec_sum": "Handles HTTP request state by checking connection and configuration flags, resetting or allocating chunked filter context, and returning a status indicator.",
    "filter_prorec_sum": "Handles HTTP request state checks and initializes the chunked filter context if conditions are met, otherwise resets related fields and returns immediately.",
    "prorec_aug_sum": "Handles HTTP request state checks, clears or resets related fields, and allocates chunked filter context when specific conditions on timers and flags are met.",
    "filter_prorec_aug_sum": "Manages HTTP request state for chunked transfer encoding, validating conditions and allocating filter context before enabling the chunked filter module.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles HTTP request state checks, clears or resets related fields, and allocates chunked filter context when specific conditions on timers and flags are met.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary makes vague references to HTTP request state checks and allocating a chunked filter context, which partially align with the function's logic of checking status codes, HTTP method, content length, and flags before enabling chunked transfer. However, it incorrectly mentions 'timers' \u2014 a concept absent from the source \u2014 and omits key specific conditions like HTTP version requirements, expect_trailers handling, and keepalive modification. These gaps and the inclusion of unrelated concepts reduce accuracy, resulting in mixed reliability.",
                "The summary is vague and introduces inaccuracies: it mentions 'conditions on timers' which are not present in the source, and omits the specific core purpose of determining whether to enable HTTP chunked transfer encoding based on status codes, content length, trailers, HTTP version, and configuration. While it notes clearing/resetting fields and allocating context, these are generic and not tied to the actual domain semantics. Critical branches, status checks, keepalive handling, and module context setting are not clearly covered.",
                "The summary contains significant inaccuracies. It incorrectly mentions 'timers' which are not present in the code and fails to identify the actual conditions, such as HTTP status checks, content length handling, HTTP version, and chunked transfer encoding flag. While it generically notes request state checks and context allocation, these are too vague and omit key specific conditions, constituting primarily NOISE with minimal accurate details. There is no FATAL error about primary purpose, but the inaccuracy and vagueness greatly reduce usefulness."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Manages HTTP request state for chunked transfer encoding, validating conditions and allocating filter context before enabling the chunked filter module.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly identifies that the function manages HTTP request state for chunked transfer encoding, checks certain conditions, and allocates filter context before enabling the chunked filter module. These elements accurately reflect the code's steps of validating headers/status, setting `r->chunked`, allocating and assigning context. However, it omits several key conditional details such as HTTP status exclusions, HTTP version checks, trailer expectations, and keepalive modifications, making it a high-level but generally accurate description rather than fully precise. Most claims are accurate but generic.",
                "The summary accurately captures the function\u2019s primary purpose of enabling chunked transfer encoding when conditions are met, and notes allocation of the filter context, aligning with the code\u2019s main domain action. However, it omits several important secondary behaviors: it does not mention that the function bypasses processing for specific HTTP status codes or HEAD requests, does not describe the handling for non-chunked cases (like disabling keepalive), nor the condition for clearing the content length when trailers are expected, and lacks coverage of HTTP version and config checks. Thus, while the core is covered, secondary coverage is limited.",
                "The summary captures the primary purpose of the function\u2014managing HTTP state for chunked transfer encoding\u2014and mentions key operations like validating conditions and allocating filter context before enabling the filter. These align with the source code's core logic: checking HTTP status and method, verifying content length and trailers, enabling chunked transfer, and creating context. While accurate, the description is broad and omits specific conditional cases and side effects (e.g., setting keepalive to 0 when content length is unknown and conditions for clearing content length). There is no clear inaccurate or noisy claim, but the gain is limited due to lack of detail."
            ]
        }
    }
}
{
    "source_code": "static int compute_partition_size(Ecma119Image *t, char *disk_path,\n                                  uint32_t *size, int flag)\n{\n    int ret, keep;\n    off_t num;\n    struct stat stbuf;\n    struct iso_interval_reader *ivr;\n    off_t byte_count;\n\n    if (flag & 1) {\n        ret = iso_interval_reader_new(t->image, disk_path,\n                                      &ivr, &byte_count, 0);\n        if (ret < 0)\n            return ret;\n        *size = (byte_count + BLOCK_SIZE - 1) / BLOCK_SIZE;\n        keep = iso_interval_reader_keep(t, ivr, 0);\n        iso_interval_reader_destroy(&ivr, 0);\n        if (keep < 0)\n            return keep;\n        return ISO_SUCCESS + (keep > 0);\n    }\n\n    *size = 0;\n    ret = stat(disk_path, &stbuf);\n    if (ret == -1)\n        return ISO_BAD_PARTITION_FILE;\n    if (! S_ISREG(stbuf.st_mode))\n        return ISO_BAD_PARTITION_FILE;\n    num = ((stbuf.st_size + 2047) / 2048);\n    if (num > 0x3fffffff || num == 0)\n        return ISO_BAD_PARTITION_FILE;\n    *size = num;\n    return ISO_SUCCESS;\n}",
    "comment": "Calculates the partition size from a disk path or an image based on a specified flag, ensuring valid file attributes and conditions.",
    "prorec_sum": "Determines a regular file\u2019s size in 2\u202fKB blocks using either a cached lookup or direct stat, returning error codes for invalid conditions.",
    "filter_prorec_sum": "Determines a file\u2019s block count from device or size data, using cached stat information when requested, and validates it is a regular file.",
    "prorec_aug_sum": "Retrieves file or device size in 2\u202fKB blocks after validating it is a regular file, returning specific error codes on failure conditions.",
    "filter_prorec_aug_sum": "Determines the file\u2019s size in 2\u202fKB blocks after validating its type, or retrieves equivalent size information via a filesystem-specific lookup.",
    "work_score": {
        "prorec_aug": {
            "summary": "Retrieves file or device size in 2\u202fKB blocks after validating it is a regular file, returning specific error codes on failure conditions.",
            "score": [
                0.7,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function validates the input is a regular file and computes its size in 2KB blocks, returning error codes for failure. However, it omits the alternate path when 'flag & 1' is set, where size computation uses iso_interval_reader logic instead of regular file stat. This introduces incompleteness, but the described behavior is accurate for one major code path.",
                "The summary accurately describes the branch that uses stat to validate a regular file and calculate its size in 2\u202fKB blocks with error codes, which is part of the core function purpose. However, it omits the other branch driven by the flag parameter that uses iso_interval_reader to compute the size in BLOCK_SIZE units, manage reader resources, and return different success codes. The coverage is therefore limited to part of the core logic and misses important conditional behavior and external interactions.",
                "The summary accurately states that the function retrieves a size in 2 KB blocks for regular files and has specific error codes for failures. However, it omits the important conditional branch when the flag bit is set, where size is computed from an interval reader for devices or disk paths, not only regular files. This omission means the description is incomplete but not directly contradictory to the code's primary purpose. The gain is low due to the missing details, but noise is minimal."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Determines the file\u2019s size in 2\u202fKB blocks after validating its type, or retrieves equivalent size information via a filesystem-specific lookup.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary contains two core claims: (1) it determines the file size in 2\u202fKB blocks after validating it is of the correct type, and (2) it alternatively retrieves equivalent size information via a filesystem-specific lookup. Both are accurate: in the non-flag branch, the code uses `stat` to ensure the path is a regular file and computes `*size` in units of 2048 bytes; in the flag & 1 branch, it uses `iso_interval_reader_new` to get `byte_count` and converts it to blocks, which is consistent with a filesystem/image-specific lookup. All claims match the source code behavior with no contradictions.",
                "The summary correctly captures the core purpose of computing a partition size in 2\u202fKB blocks and notes both the regular file validation path and the alternative reader-based lookup, aligning with the function\u2019s two branches. However, it omits important secondary details such as specific error conditions returned for invalid files or excessive sizes, and it does not mention the use of constants like BLOCK_SIZE or specific functions involved (stat, iso_interval_reader_keep/destroy). Coverage of secondary behavior-critical semantics is minimal beyond the core paths.",
                "The summary has one clear, fact-based claim: it either determines the file\u2019s size in 2KB blocks after validating that it is a regular file, or uses a filesystem-specific lookup to get equivalent size information. This is accurate: the code uses 2048-byte blocks after checking with stat() and S_ISREG, or invokes iso_interval_reader_new for partition sizes based on the disk path. There are no contradictions about core purpose, inputs, or outputs, and noise is minimal. The claim is moderately specific but could have noted additional validation steps and the conditions for different paths, so the gain is solid but not maximal."
            ]
        }
    }
}
{
    "source_code": "\nstruct timeval* dtls1_get_timeout(SSL *s, struct timeval* timeleft)\n\t{\n\tstruct timeval timenow;\n\n\t/* If no timeout is set, just return NULL */\n\tif (s->d1->next_timeout.tv_sec == 0 && s->d1->next_timeout.tv_usec == 0)\n\t\t{\n\t\treturn NULL;\n\t\t}\n\n\t/* Get current time */\n\tget_current_time(&timenow);\n\n\t/* If timer already expired, set remaining time to 0 */\n\tif (s->d1->next_timeout.tv_sec < timenow.tv_sec ||\n\t\t(s->d1->next_timeout.tv_sec == timenow.tv_sec &&\n\t\t s->d1->next_timeout.tv_usec <= timenow.tv_usec))\n\t\t{\n\t\tmemset(timeleft, 0, sizeof(struct timeval));\n\t\treturn timeleft;\n\t\t}\n\n\t/* Calculate time left until timer expires */\n\tmemcpy(timeleft, &(s->d1->next_timeout), sizeof(struct timeval));\n\ttimeleft->tv_sec -= timenow.tv_sec;\n\ttimeleft->tv_usec -= timenow.tv_usec;\n\tif (timeleft->tv_usec < 0)\n\t\t{\n\t\ttimeleft->tv_sec--;\n\t\ttimeleft->tv_usec += 1000000;\n\t\t}\n\n\t/* If remaining time is less than 15 ms, set it to 0\n\t * to prevent issues because of small devergences with\n\t * socket timeouts.\n\t */\n\tif (timeleft->tv_sec == 0 && timeleft->tv_usec < 15000)\n\t\t{\n\t\tmemset(timeleft, 0, sizeof(struct timeval));\n\t\t}\n\t\n\n\treturn timeleft;\n\t}",
    "comment": "Calculates the remaining timeout for a DTLS connection and returns a struct timeval with the time left until expiration.",
    "prorec_sum": "Calculates the remaining time before a DTLS event expires and returns zero when the deadline has passed or is within 15 milliseconds.",
    "filter_prorec_sum": "Calculates the remaining time until a DTLS handshake retransmission deadline and returns zero if expired or below a minimal threshold.",
    "prorec_aug_sum": "Calculates and returns the remaining time until a stored DTLS timer expires, or zero if the deadline has passed or is very close.",
    "filter_prorec_aug_sum": "Calculates and returns the remaining time until the DTLS retransmission timeout based on current time and stored expiry values.",
    "work_score": {
        "prorec_aug": {
            "summary": "Calculates and returns the remaining time until a stored DTLS timer expires, or zero if the deadline has passed or is very close.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly captures the key semantics of the function: it computes the remaining time until a stored DTLS timer expires, returns zero if the deadline has passed, and also handles the case when the expiry is very close. This aligns with the source code's logic, including the <15ms threshold behavior. No inaccurate claims were found, indicating full alignment with the implementation details.",
                "The summary accurately states the core behavior of computing and returning the remaining time until a stored DTLS timer expires, matching the function\u2019s main purpose. It also mentions returning zero if the deadline has passed or is very close, which aligns with the code's checks for expiration and the <15 ms adjustment. However, it omits secondary details such as handling when no timeout is set (NULL return), precise calculation logic including microsecond adjustments, and the explicit interaction with the timeval structure, resulting in incomplete secondary coverage.",
                "The summary accurately conveys the function\u2019s core purpose: determining and returning the time left until a DTLS timer expires, or zero if expired or within a small threshold. There are no contradictory claims or unrelated noise. While the phrasing is slightly less detailed than the source code (e.g., 15 ms threshold specified in the code is generalized as \u2018very close\u2019), the primary semantics and key I/O are correctly described, giving a net positive benefit."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Calculates and returns the remaining time until the DTLS retransmission timeout based on current time and stored expiry values.",
            "score": [
                1.0,
                0.5,
                0.7
            ],
            "reason": [
                "The summary makes a single fact-based claim that the function calculates and returns the remaining time until a DTLS retransmission timeout based on the current time and stored expiry values. This is accurate: the code checks the next_timeout, compares it with the current time, computes the remaining duration if not expired, and returns it, or NULL if unset. The claim aligns well with the function's semantics, covering both the purpose and basis of calculation without introducing inaccuracies.",
                "The summary accurately conveys the core purpose: computing and returning the remaining time until a DTLS retransmission timeout using current time and stored expiry values. This matches the main domain-specific functionality in the code. However, it omits important secondary details such as returning NULL when no timeout is set, setting the remaining time to zero if already expired, adjusting for negative microseconds, and the special handling for times less than 15ms. These omissions result in incomplete coverage of key behavior-critical semantics.",
                "The summary is concise and correctly states the primary purpose of the function: it calculates and returns the remaining time until a DTLS retransmission timeout using the current time and stored expiry values. This matches the code's logic for checking next_timeout, computing the difference, and returning NULL or updated timeval accordingly. There are no inaccurate or noisy claims, but the description is generic and lacks detail on edge cases like when no timeout is set, expired timers, microsecond adjustment, or small timeout normalization, which limits its information gain."
            ]
        }
    }
}
{
    "source_code": "static int mmc_get_leadin_text_al(struct burn_drive *d,\n                                  unsigned char **text_packs, int *alloc_len,\n                                  int flag)\n{\n\tstruct buffer *buf = NULL;\n\tstruct command *c = NULL;\n\tunsigned char *data;\n\tint ret, data_length;\n\n\t*text_packs = NULL;\n\n\tBURN_ALLOC_MEM(buf, struct buffer, 1);\n\tBURN_ALLOC_MEM(c, struct command, 1);\n\n\tscsi_init_command(c, MMC_GET_LEADTEXT, sizeof(MMC_GET_LEADTEXT));\n\tc->dxfer_len = *alloc_len;\n\tc->opcode[7]= (c->dxfer_len >> 8) & 0xff;\n\tc->opcode[8]= c->dxfer_len & 0xff;\n\tc->retry = 1;\n\tc->page = buf;\n\tc->page->bytes = 0;\n\tc->page->sectors = 0;\n\n\tc->dir = FROM_DRIVE;\n\td->issue_command(d, c);\n\tif (c->error)\n\t\t{ret = 0; goto ex;}\n\n\tdata = c->page->data;\t\n\tdata_length = (data[0] << 8) + data[1];\n\t*alloc_len = data_length + 2;\n\tif (*alloc_len >= 22 && !(flag & 1)) {\n\t\tBURN_ALLOC_MEM(*text_packs, unsigned char, *alloc_len - 4);\n\t\tmemcpy(*text_packs, data + 4, *alloc_len - 4);\n\t}\n\tret = 1;\t\nex:;\n\tBURN_FREE_MEM(c);\n\tBURN_FREE_MEM(buf);\n\treturn ret;\n}",
    "comment": "Retrieves lead-in text from a drive and allocates memory for the text if the conditions are met, returning success or failure.",
    "prorec_sum": "Allocates and initializes buffers, processes data through a callback, and optionally extracts a payload segment into output based on size and flag conditions.",
    "filter_prorec_sum": "Allocates buffers, invokes a callback to fill them, validates length, and copies resulting ISO9660 volume data into the provided output pointer.",
    "prorec_aug_sum": "Allocates buffers, invokes a callback to fill them, reads a length-prefixed payload, and optionally copies the payload data into a provided output buffer.",
    "filter_prorec_aug_sum": "Allocates buffers, invokes a callback to fill them, then extracts and optionally copies payload data based on header length and a control flag.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates buffers, invokes a callback to fill them, reads a length-prefixed payload, and optionally copies the payload data into a provided output buffer.",
            "score": [
                1.0,
                0.5,
                0.2
            ],
            "reason": [
                "The summary captures accurate semantics: it mentions buffer allocation (BURN_ALLOC_MEM), invoking a callback (d->issue_command) to fill them, reading a length-prefixed payload (data_length derived from first two bytes), and an optional copy into an output buffer when certain conditions are met. All claims align with the code, with no inaccuracies or unrelated content.",
                "The summary describes buffer allocation, invoking a function to fill them, reading a length-prefixed payload, and optional copying, which matches the core action of issuing an MMC_GET_LEADTEXT SCSI command to retrieve lead-in text data. However, it omits critical details such as the specific command being used, the condition involving 'alloc_len >= 22 && !(flag & 1)', handling of errors via 'c->error', and the source/direction of data transfer ('FROM_DRIVE'). Thus, while the core is covered in a generic way, secondary coverage is weak.",
                "The summary correctly notes buffer allocation, reading a length-prefixed payload, and conditional copying to an output buffer, which aligns with the function\u2019s logic. However, it inaccurately states that a 'callback' is invoked to fill buffers\u2014the code issues a SCSI command via a drive method, not a generic callback. This is a semantic mismatch targeting core behavior (how data is obtained), making it a FATAL error on the primary purpose. While other claims are accurate, this fundamental misrepresentation significantly reduces trustworthiness."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates buffers, invokes a callback to fill them, then extracts and optionally copies payload data based on header length and a control flag.",
            "score": [
                0.8,
                0.2,
                0.6
            ],
            "reason": [
                "The summary correctly notes buffer allocation, invoking a command to fill them, and conditionally copying payload data based on length and a flag, which matches the source code\u2019s behavior. However, it omits specific details such as how `alloc_len` is updated from the header, that the 'callback' is actually a device command (`issue_command`), and the explicit extraction of data length from the first two bytes. These omissions reduce precision but most claims are accurate.",
                "The summary generically describes buffer allocation, callback invocation, and optional data copying, but it does not identify the core domain purpose of retrieving lead-in text from a drive via an MMC command. While the described steps loosely match some mechanical aspects of the code, the domain-specific operation is completely omitted, and important details like the SCSI command setup, error handling, and conditional allocation logic are absent.",
                "The summary\u2019s claims are generally accurate: the function allocates buffers, issues a command to fill them, derives payload length from header bytes, and conditionally copies data based on a flag. There are no contradictions with the source code and no noise; however, the description is somewhat generic and omits specific details, such as the SCSI command setup, error handling, and exact header parsing offsets, which limits its informational value. The worst issue is low gain due to broad phrasing rather than incorrectness."
            ]
        }
    }
}
{
    "source_code": "\nstatic int mntns_install(struct nsproxy *nsproxy, void *ns)\n{\n\tstruct fs_struct *fs = current->fs;\n\tstruct mnt_namespace *mnt_ns = ns;\n\tstruct path root;\n\n\tif (!ns_capable(mnt_ns->user_ns, CAP_SYS_ADMIN) ||\n\t    !nsown_capable(CAP_SYS_CHROOT) ||\n\t    !nsown_capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tif (fs->users != 1)\n\t\treturn -EINVAL;\n\n\tget_mnt_ns(mnt_ns);\n\tput_mnt_ns(nsproxy->mnt_ns);\n\tnsproxy->mnt_ns = mnt_ns;\n\n\t/* Find the root */\n\troot.mnt    = &mnt_ns->root->mnt;\n\troot.dentry = mnt_ns->root->mnt.mnt_root;\n\tpath_get(&root);\n\twhile(d_mountpoint(root.dentry) && follow_down_one(&root))\n\t\t;\n\n\t/* Update the pwd and root */\n\tset_fs_pwd(fs, &root);\n\tset_fs_root(fs, &root);\n\n\tpath_put(&root);\n\treturn 0;\n}",
    "comment": "Validates permissions, checks filesystem usage, updates the mount namespace in the nsproxy, and sets the current process's root and working directory.",
    "prorec_sum": "Validates inode-related conditions before updating a file reference and performing subsequent filesystem operations on the associated directory entry.",
    "filter_prorec_sum": "Validates several conditions, updates a reference to a new object, and performs a series of linked data structure operations if the current state equals one.",
    "prorec_aug_sum": "Validates multiple conditions, updates a reference, processes data through several helper routines, and finalizes operations when a specific runtime flag equals one.",
    "filter_prorec_aug_sum": "Validates multiple conditions on input parameters, updates a shared pointer, and performs a sequence of synchronized operations on associated data structures.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates multiple conditions, updates a reference, processes data through several helper routines, and finalizes operations when a specific runtime flag equals one.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains mostly vague and generic descriptions that do not accurately reflect the source code's specific logic. It mentions 'runtime flag equals one,' which is inaccurate because the function checks permission capabilities and fs->users count, not a generic runtime flag. While 'updates a reference' and 'processes data through several helper routines' are partially true, the majority of claims lack specificity or correctness, resulting in a low proportion of accurate statements.",
                "The summary does not capture the core purpose of replacing the process's mount namespace and updating its root and working directory based on permission checks. Claims are generic and vague, omitting specific domain actions such as capability validation, reference counting for mount namespaces, and updating fs_struct paths. No accurate statement in the summary reflects the detailed semantics in the source code, leaving both the core function and secondary behaviors uncovered.",
                "The summary contains mostly inaccurate and generic statements. It omits the core purpose of the function\u2014installing a new mount namespace and updating the filesystem root/pwd\u2014and instead mentions a 'specific runtime flag equals one', which is not present in the source code, making this a FATAL error on the primary purpose. Other parts like 'processes data through several helper routines' are overly vague and do not provide specific verifiable details. Accurate content is minimal and low-info, so the net benefit is negligible."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates multiple conditions on input parameters, updates a shared pointer, and performs a sequence of synchronized operations on associated data structures.",
            "score": [
                0.6,
                0.1,
                0.4
            ],
            "reason": [
                "The summary contains generic statements that loosely match the code behavior, such as validating conditions and updating pointers, but it omits key specific behaviors in the source code like capability checks for specific privileges, reference count handling with get/put operations, mounting namespace root adjustment, and updating both the current working directory and root directory. The claims are broadly accurate but lack the specificity needed to fully reflect the function's semantics, making precision mixed but mostly correct.",
                "The summary offers only vague and generic descriptions such as validating conditions, updating a pointer, and operating on data structures, without accurately identifying the core function of installing a new mount namespace and updating the current process's root and working directory. This misses the specific permission checks, namespace reference handling, and root path adjustments present in the code, thus failing to cover the core purpose and omitting key behavioral details.",
                "The summary is largely generic and omits critical domain-specific details from the source code. It fails to mention key permission checks for specific capabilities, the handling of reference counts for mount namespaces, or the explicit updates to the process's root and working directory paths. While the statements about validating conditions, updating a pointer, and performing operations on data structures are broadly true, they are SAFE claims with low informational value and significant NOISE due to lack of precision. No FATAL inaccuracies are present, but the low specificity limits usefulness."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic void gen6_bsd_ring_write_tail(struct intel_ring_buffer *ring,\n\t\t\t\t     u32 value)\n{\n\tdrm_i915_private_t *dev_priv = ring->dev->dev_private;\n\n       /* Every tail move must follow the sequence below */\n\n\t/* Disable notification that the ring is IDLE. The GT\n\t * will then assume that it is busy and bring it out of rc6.\n\t */\n\tI915_WRITE(GEN6_BSD_SLEEP_PSMI_CONTROL,\n\t\t   _MASKED_BIT_ENABLE(GEN6_BSD_SLEEP_MSG_DISABLE));\n\n\t/* Clear the context id. Here be magic! */\n\tI915_WRITE64(GEN6_BSD_RNCID, 0x0);\n\n\t/* Wait for the ring not to be idle, i.e. for it to wake up. */\n\tif (wait_for((I915_READ(GEN6_BSD_SLEEP_PSMI_CONTROL) &\n\t\t      GEN6_BSD_SLEEP_INDICATOR) == 0,\n\t\t     50))\n\t\tDRM_ERROR(\"timed out waiting for the BSD ring to wake up\\n\");\n\n\t/* Now that the ring is fully powered up, update the tail */\n\tI915_WRITE_TAIL(ring, value);\n\tPOSTING_READ(RING_TAIL(ring->mmio_base));\n\n\t/* Let the ring send IDLE messages to the GT again,\n\t * and so let it sleep to conserve power when idle.\n\t */\n\tI915_WRITE(GEN6_BSD_SLEEP_PSMI_CONTROL,\n\t\t   _MASKED_BIT_DISABLE(GEN6_BSD_SLEEP_MSG_DISABLE));\n}",
    "comment": "Updates the tail of the BSD ring buffer after ensuring the ring is active and managing power-saving notifications.",
    "prorec_sum": "Writes commands to the BSD ring buffer and waits for it to become idle before issuing further GPU instructions.",
    "filter_prorec_sum": "Writes commands to the gen6 BSD hardware ring, waits for it to wake up with a timeout, then issues final control writes.",
    "prorec_aug_sum": "Writes commands to the BSD ring buffer and waits until it becomes ready, logging a timeout error if wake\u2011up does not occur.",
    "filter_prorec_aug_sum": "Writes commands to the Gen6 BSD ring buffer and waits for it to wake, timing out and logging an error if necessary.",
    "work_score": {
        "prorec_aug": {
            "summary": "Writes commands to the BSD ring buffer and waits until it becomes ready, logging a timeout error if wake\u2011up does not occur.",
            "score": [
                0.9,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly captures the core function behavior: writing to the BSD ring buffer, waiting for it to be ready, and logging a timeout if wake\u2011up fails. These claims align with the source code's sequence including the wait_for condition and DRM_ERROR handling. However, it omits details about the power management steps (disabling/enabling idle notifications, clearing context ID) and thus is incomplete but still factually accurate in the part it describes.",
                "The summary correctly states that the function writes commands to the BSD ring buffer, waits until it is ready, and logs a timeout on failure, which matches key operations in the code. However, it omits critical details of the core purpose, namely the specific sequence of disabling idle notifications, clearing context ID, powering up, writing the tail pointer, and re-enabling idle messages. These domain-specific steps are central to the function\u2019s role in safely updating the Gen6 BSD ring tail.",
                "The summary makes two main claims: that the function writes commands to the BSD ring buffer and that it waits until it becomes ready, logging a timeout if it fails to wake up. The waiting and timeout logging are accurate per the code. However, the 'writes commands' part is misleading \u2014 the function specifically updates the tail pointer of the BSD ring, not generic commands, which is a core action, making this a FATAL inaccuracy about the primary purpose. This severe inaccuracy on the core function behavior heavily undermines trust in the summary despite the accurate wait/error detail."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Writes commands to the Gen6 BSD ring buffer and waits for it to wake, timing out and logging an error if necessary.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary captures the essential actions of the function: sending commands to the Gen6 BSD ring buffer, waiting for it to wake, and handling a timeout with an error log. These align with the source code\u2019s sequence of writing to the ring tail after ensuring it is powered up and logging if the wake-up fails. Although the summary omits certain power management details, all stated claims are consistent with the code.",
                "The summary correctly states that the function writes to the Gen6 BSD ring buffer and waits for it to wake, including a timeout with error logging, which matches the code's core behavior. However, it omits key specifics such as disabling/enabling sleep message notifications, clearing the context ID, using POSTING_READ, and re-enabling idle message sending after updating the tail. These omissions mean the coverage of secondary, behavior-critical semantics is weak despite the core being captured.",
                "The summary correctly notes that the function writes to the Gen6 BSD ring buffer, waits for it to wake, and logs an error on timeout, which matches the core semantics in the source. However, it omits additional important steps such as disabling/enabling idle notifications, clearing the context ID, and updating the tail pointer, which reduces detail and gain. There are no inaccurate or contradictory claims, so the worst issue is missing details rather than misinformation."
            ]
        }
    }
}
{
    "source_code": "int ata_qc_complete_multiple(struct ata_port *ap, u32 qc_active)\n{\n\tint nr_done = 0;\n\tu32 done_mask;\n\n\tdone_mask = ap->qc_active ^ qc_active;\n\n\tif (unlikely(done_mask & qc_active)) {\n\t\tata_port_err(ap, \"illegal qc_active transition (%08x->%08x)\\n\",\n\t\t\t     ap->qc_active, qc_active);\n\t\treturn -EINVAL;\n\t}\n\n\twhile (done_mask) {\n\t\tstruct ata_queued_cmd *qc;\n\t\tunsigned int tag = __ffs(done_mask);\n\n\t\tqc = ata_qc_from_tag(ap, tag);\n\t\tif (qc) {\n\t\t\tata_qc_complete(qc);\n\t\t\tnr_done++;\n\t\t}\n\t\tdone_mask &= ~(1 << tag);\n\t}\n\n\treturn nr_done;\n}",
    "comment": "Processes and completes multiple ATA queued commands based on the active command status while checking for illegal state transitions.",
    "prorec_sum": "Validates and updates qc_active state bits, logging illegal transitions and invoking handlers for each newly activated bit in the ATA port structure.",
    "filter_prorec_sum": "Validates qc_active bit transitions, logs illegal changes, and processes newly activated bits by invoking related handlers.",
    "prorec_aug_sum": "Validates and processes changes to a qc_active bitmask, logging illegal transitions and invoking handlers for each newly activated queue command slot.",
    "filter_prorec_aug_sum": "Validates and processes changes in qc_active bitmask, logging illegal transitions and invoking handlers for newly activated ATA queued commands.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates and processes changes to a qc_active bitmask, logging illegal transitions and invoking handlers for each newly activated queue command slot.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary incorrectly states that the function handles 'newly activated queue command slots', whereas the source code processes commands that have been completed (bits that have changed from active to inactive). It correctly mentions validating a qc_active bitmask and logging illegal transitions, but the core behavior of completing queued commands is misrepresented. Only part of the description aligns with the actual semantics, resulting in low accuracy.",
                "The summary makes specific claims: it validates and processes changes to a qc_active bitmask, logs illegal transitions, and invokes handlers for each newly activated queue command slot. The first two points are accurate: the function compares the current and provided qc_active bitmasks, detects illegal transitions, and logs an error. However, the last point is inaccurate \u2014 the function calls ata_qc_complete for commands that have been completed (bits cleared) rather than newly activated. This misrepresentation of the core purpose means the summary does not correctly convey the function's primary role of completing finished queue commands, resulting in the core not being covered.",
                "The summary accurately notes that the function validates changes to the qc_active bitmask and logs illegal transitions, which matches the code's check using done_mask and error logging. However, it incorrectly claims that handlers are invoked for newly activated queue command slots. In the code, ata_qc_complete is called for commands that are being completed (bits cleared from ap->qc_active), not activated. This is a FATAL in describing the primary purpose regarding which commands are processed, significantly undermining trust."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates and processes changes in qc_active bitmask, logging illegal transitions and invoking handlers for newly activated ATA queued commands.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly mentions validation of qc_active bitmask changes and logging of illegal transitions, aligning with the code's behavior. However, it inaccurately describes the processing as invoking handlers for newly activated commands, whereas the function actually handles completed commands based on the difference mask. This is a key semantic error, making less than half of the claims accurate.",
                "The summary correctly identifies that the function processes changes in the qc_active bitmask and logs illegal transitions, but it inaccurately states that it handles newly activated commands. In the source code, the function actually completes commands that have become inactive, not activates new ones. This misrepresentation means the core purpose\u2014completing finished ATA queued commands\u2014is not accurately covered, and therefore the coverage of the core domain action is missing while minor secondary details are partially correct.",
                "The summary correctly states that the function validates and processes changes in the qc_active bitmask and logs illegal transitions, aligning with the code\u2019s XOR check and error logging on invalid transitions. However, it inaccurately describes the handler invocation as being for 'newly activated' commands, whereas the code actually completes tasks that have become inactive. This is a factual error about the core purpose (WHAT) and primary behavior, representing a severe inaccuracy in key I/O semantics."
            ]
        }
    }
}
{
    "source_code": "\nstatic bin_tree_t *\nparse_reg_exp (re_string_t *regexp, regex_t *preg, re_token_t *token,\n\t       reg_syntax_t syntax, Idx nest, reg_errcode_t *err)\n{\n  re_dfa_t *dfa = preg->buffer;\n  bin_tree_t *tree, *branch = NULL;\n  bitset_word_t initial_bkref_map = dfa->completed_bkref_map;\n  tree = parse_branch (regexp, preg, token, syntax, nest, err);\n  if (__glibc_unlikely (*err != REG_NOERROR && tree == NULL))\n    return NULL;\n\n  while (token->type == OP_ALT)\n    {\n      fetch_token (token, regexp, syntax | RE_CARET_ANCHORS_HERE);\n      if (token->type != OP_ALT && token->type != END_OF_RE\n\t  && (nest == 0 || token->type != OP_CLOSE_SUBEXP))\n\t{\n\t  bitset_word_t accumulated_bkref_map = dfa->completed_bkref_map;\n\t  dfa->completed_bkref_map = initial_bkref_map;\n\t  branch = parse_branch (regexp, preg, token, syntax, nest, err);\n\t  if (__glibc_unlikely (*err != REG_NOERROR && branch == NULL))\n\t    {\n\t      if (tree != NULL)\n\t\tpostorder (tree, free_tree, NULL);\n\t      return NULL;\n\t    }\n\t  dfa->completed_bkref_map |= accumulated_bkref_map;\n\t}\n      else\n\tbranch = NULL;\n      tree = create_tree (dfa, tree, branch, OP_ALT);\n      if (__glibc_unlikely (tree == NULL))\n\t{\n\t  *err = REG_ESPACE;\n\t  return NULL;\n\t}\n    }\n  return tree;\n}",
    "comment": "Parses a regular expression into a binary tree structure while managing alternative branches and backreference mapping.",
    "prorec_sum": "Processes repeated type\u201110 records by invoking subordinate handlers, temporarily adjusting a link\u2011state field, and merging their results into a cumulative linked structure.",
    "filter_prorec_sum": "Processes and merges link-related symbol data in a loop when a specific flag is set, handling errors and restoring state appropriately.",
    "prorec_aug_sum": "Processes input records with type 10 by repeatedly merging results from two retrieval calls, updating state fields, and handling error or cleanup conditions.",
    "filter_prorec_aug_sum": "Processes input records with type 10 by repeatedly merging parsed results and updating state, handling errors via cleanup and restoring section pointer values.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes input records with type 10 by repeatedly merging results from two retrieval calls, updating state fields, and handling error or cleanup conditions.",
            "score": [
                0.1,
                0.1,
                0.3
            ],
            "reason": [
                "The summary describes processing input records with type 10 and merging results from two retrieval calls, which does not correspond to the actual source code behavior. The source code is parsing a regular expression with alternation branches, managing backreference maps, and handling errors. None of the claims in the summary target the actual code semantics, making them inaccurate.",
                "The summary's claims about processing type 10 records, merging retrieval call results, and updating state fields do not match the source code, which parses a regular expression by combining branches separated by alternation operators, managing backreference maps, and handling parse errors and memory cleanup. None of the summary's claims are accurate, so the core purpose of regex branch parsing is not covered and no secondary details are correct.",
                "The summary contains entirely inaccurate claims unrelated to the source code. It describes processing input records of type 10, merging retrieval call results, and updating state fields, none of which occur in the provided function. The actual code parses a regular expression, handles alternation tokens, manages back-reference bitsets, and cleans up on errors. This mismatch represents severe NOISE with no accurate statements, yielding no usable insight."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes input records with type 10 by repeatedly merging parsed results and updating state, handling errors via cleanup and restoring section pointer values.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims are largely inaccurate. The code parses a regular expression by building an alternation (OP_ALT) tree from branches, updating the DFA's backreference map, and freeing resources on errors. The summary incorrectly refers to 'input records with type 10', 'merging parsed results', and 'restoring section pointer values', which do not match the source code semantics. Nearly all claims contradict the function's real behavior.",
                "The summary's claims about processing 'input records with type 10', merging parsed results, and restoring section pointers do not match the source code's actual purpose of parsing regular expression branches with alternation, managing back-reference maps, and handling memory cleanup on errors. The core purpose of building a syntax tree for regex alternations is not covered, and the summary instead introduces unrelated domain semantics.",
                "The summary's claims about processing 'input records with type 10', 'restoring section pointer values', and 'merging parsed results' do not match the source code, which parses regular expressions and handles alternation branches, error cleanup, and backreference maps. These are FATAL inaccuracies about the primary purpose and core logic. There are no accurate GOLD claims and almost all content is noise or wrong, making the summary untrustworthy."
            ]
        }
    }
}
{
    "source_code": "static int\nefivar_create_sysfs_entry(struct efivar_entry *new_var)\n{\n\tint i, short_name_size;\n\tchar *short_name;\n\tunsigned long variable_name_size;\n\tefi_char16_t *variable_name;\n\n\tvariable_name = new_var->var.VariableName;\n\tvariable_name_size = ucs2_strlen(variable_name) * sizeof(efi_char16_t);\n\n\t/*\n\t * Length of the variable bytes in ASCII, plus the '-' separator,\n\t * plus the GUID, plus trailing NUL\n\t */\n\tshort_name_size = variable_name_size / sizeof(efi_char16_t)\n\t\t\t\t+ 1 + EFI_VARIABLE_GUID_LEN + 1;\n\n\tshort_name = kzalloc(short_name_size, GFP_KERNEL);\n\n\tif (!short_name)\n\t\treturn 1;\n\n\t/* Convert Unicode to normal chars (assume top bits are 0),\n\t   ala UTF-8 */\n\tfor (i=0; i < (int)(variable_name_size / sizeof(efi_char16_t)); i++) {\n\t\tshort_name[i] = variable_name[i] & 0xFF;\n\t}\n\t/* This is ugly, but necessary to separate one vendor's\n\t   private variables from another's.         */\n\n\t*(short_name + strlen(short_name)) = '-';\n\tefi_guid_unparse(&new_var->var.VendorGuid,\n\t\t\t short_name + strlen(short_name));\n\n\tnew_var->kobj.kset = efivars_kset;\n\n\ti = kobject_init_and_add(&new_var->kobj, &efivar_ktype,\n\t\t\t\t   NULL, \"%s\", short_name);\n\tkfree(short_name);\n\tif (i)\n\t\treturn 1;\n\n\tkobject_uevent(&new_var->kobj, KOBJ_ADD);\n\tefivar_entry_add(new_var, &efivar_sysfs_list);\n\n\treturn 0;\n}",
    "comment": "Creates a sysfs entry for a new EFI variable by converting its Unicode name to ASCII and adding it to the kernel's object hierarchy.",
    "prorec_sum": "Formats a memory buffer with a \u201c%pUl\u201d identifier, updates device-specific pointers, and registers the prepared data structure for further processing.",
    "filter_prorec_sum": "Formats a string containing a GUID with the \"%pUl\" specifier, stores it in a buffer, and registers it into the object's data structure.",
    "prorec_aug_sum": "Allocates and formats a buffer with a device identifier, updates related state pointers, invokes registration routines, and finalizes associated device setup.",
    "filter_prorec_aug_sum": "Formats and sends a \"%pUl\" identifier to a hardware-related structure, updates associated pointers, and finalizes with a device-specific handler call.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and formats a buffer with a device identifier, updates related state pointers, invokes registration routines, and finalizes associated device setup.",
            "score": [
                0.8,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function allocates and formats a buffer (accurate: allocation of short_name and populating it with identifier-like data), updates state pointers (accurate: assigns new_var->kobj.kset), and invokes registration routines (accurate: kobject_init_and_add, kobject_uevent, efivar_entry_add). However, it mischaracterizes the formatted data as a generic 'device identifier' when the code specifically constructs a sysfs entry name from a variable name and GUID, and 'finalizes associated device setup' is vague and not directly stated in the code. Most claims are broadly correct but lack precision and have minor semantics drift.",
                "The summary\u2019s claims\u2014allocating/formatting a buffer, updating state pointers, invoking registration, and finalizing device setup\u2014are mostly generic and not specific to the actual core behavior of creating a sysfs entry for an EFI variable. While allocation and formatting vaguely match the code\u2019s conversion and buffer creation, key domain elements such as constructing a name from the variable name and GUID, initializing a kobject, emitting a uevent, and adding the entry to the EFI vars list are absent or misrepresented. The core purpose is not explicitly covered, and secondary behavior-critical details are missing.",
                "The summary vaguely captures that the function allocates and formats a buffer and updates state pointers, but it fails to specifically mention that the buffer is the sysfs entry name created from the EFI variable name and GUID. It mischaracterizes the context as a generic 'device' setup and registration rather than EFI variable sysfs entry creation, which is the primary purpose. This is a FATAL in the core WHAT, leading to a misleading interpretation of the function. Details about converting from UCS2, appending the GUID, and the specific sysfs mechanisms are omitted, and domain context is replaced with inaccurate terms."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Formats and sends a \"%pUl\" identifier to a hardware-related structure, updates associated pointers, and finalizes with a device-specific handler call.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary contains claims that do not match the function's actual behavior. The code builds a short name from a Unicode variable name and a GUID, initializes and adds a kobject, sends a uevent, and adds the entry to a sysfs list. The summary's claims about formatting and sending a \"%pUl\" identifier, updating hardware-related pointers, and calling a device-specific handler are unsupported by the source code. All claims are inaccurate, resulting in no alignment with the evaluation steps.",
                "The summary's claims about formatting and sending a '%pUl' identifier to a hardware structure, updating pointers, and invoking a device-specific handler do not match the source code's actual purpose of creating a sysfs entry for a UEFI variable by converting its Unicode name, appending its GUID, initializing a kobject, sending a uevent, and adding it to a list. The core operation is entirely missing, and all claims are inaccurate or irrelevant to the code semantics.",
                "The summary\u2019s claims are inaccurate: it asserts that the function formats and sends a \"%pUl\" identifier to a hardware-related structure, updates pointers, and calls a device-specific handler. In reality, the source code constructs a short_name string from a UEFI variable name and GUID, initializes a kobject, adds it to sysfs, sends a uevent, and adds it to a list. The summary does not target the actual semantics, making the entire description NOISE with no accurate claims. This is a case of overwhelming NOISE with no factual grounding in the code."
            ]
        }
    }
}
{
    "source_code": "\nvoid __cpuinit start_secondary(void)\n{\n\tunsigned int cpu;\n\tunsigned long thread_ptr;\n\n\t/*  Calculate thread_info pointer from stack pointer  */\n\t__asm__ __volatile__(\n\t\t\"%0 = SP;\\n\"\n\t\t: \"=r\" (thread_ptr)\n\t);\n\n\tthread_ptr = thread_ptr & ~(THREAD_SIZE-1);\n\n\t__asm__ __volatile__(\n\t\tQUOTED_THREADINFO_REG \" = %0;\\n\"\n\t\t:\n\t\t: \"r\" (thread_ptr)\n\t);\n\n\t/*  Set the memory struct  */\n\tatomic_inc(&init_mm.mm_count);\n\tcurrent->active_mm = &init_mm;\n\n\tcpu = smp_processor_id();\n\n\tsetup_irq(BASE_IPI_IRQ + cpu, &ipi_intdesc);\n\n\t/*  Register the clock_event dummy  */\n\tsetup_percpu_clockdev();\n\n\tprintk(KERN_INFO \"%s cpu %d\\n\", __func__, current_thread_info()->cpu);\n\n\tnotify_cpu_starting(cpu);\n\n\tset_cpu_online(cpu, true);\n\n\tlocal_irq_enable();\n\n\tcpu_startup_entry(CPUHP_ONLINE);\n}",
    "comment": "Initializes the secondary CPU by configuring memory management, enabling interrupts, and signaling readiness for operation within a multiprocessor environment.",
    "prorec_sum": "Initializes and synchronizes a secondary CPU during SMP startup, performing setup, waiting for readiness, and enabling interrupts before resuming execution.",
    "filter_prorec_sum": "Initializes and synchronizes a CPU during SMP startup, setting per\u2011CPU state, invoking init callbacks, and enabling it for scheduling.",
    "prorec_aug_sum": "Initializes and synchronizes a CPU during SMP startup, performing hardware setup, time initialization, memory mapping, and enabling interrupts before entering normal operation.",
    "filter_prorec_aug_sum": "Initializes a secondary CPU during SMP boot, synchronizing with startup flags, setting per\u2011CPU data, and enabling it for normal operation.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes and synchronizes a CPU during SMP startup, performing hardware setup, time initialization, memory mapping, and enabling interrupts before entering normal operation.",
            "score": [
                0.5,
                0.4,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function initializes a CPU during SMP startup, enables interrupts, and transitions into normal operation, matching the observed setup of CPU state, IRQ registration, and online status in the source. However, it inaccurately claims 'synchronizes' (no explicit synchronization logic is shown), 'time initialization' (only a dummy clock device is set up, not actual timekeeping), and 'memory mapping' (memory struct assignment occurs, but not mapping). These overgeneralizations reduce precision, with roughly half of the claims being accurate.",
                "The summary generically states that the function initializes and synchronizes a CPU, sets up hardware, time, memory, and interrupts before normal operation. While this loosely matches the core purpose of starting a secondary CPU in SMP, it lacks the specific domain actions reflected in the code such as calculating and storing the thread_info pointer from the stack, incrementing init_mm count, setting active_mm, registering a dummy clock device, and notifying CPU start. These specifics are not covered, making coverage of secondary behaviors weak despite core purpose being generally acknowledged.",
                "The summary correctly captures the high-level purpose of initializing and enabling a CPU in SMP startup, including interrupt enabling, but introduces inaccuracies: it claims time initialization and memory mapping occur, which are not present in the code. These are FATAL inaccuracies because they misstate core actions of the function and its primary purpose. The accurate part (CPU initialization and interrupt enable) is outweighed by the introduction of non-existent behaviors, resulting in the function being potentially misunderstood."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes a secondary CPU during SMP boot, synchronizing with startup flags, setting per\u2011CPU data, and enabling it for normal operation.",
            "score": [
                0.6,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function initializes a secondary CPU during SMP boot and enables it for normal operation, which aligns with the code's behavior of setting up per\u2011CPU structures and marking the CPU online. However, it inaccurately mentions 'synchronizing with startup flags,' which is not present in the code. Since roughly two out of three main claims are accurate, this places accuracy in the mixed\u2011reliability range.",
                "The summary correctly identifies that the function initializes a secondary CPU during SMP boot and brings it online, which aligns with the core operation in the source. However, it omits several key secondary behaviors such as calculating and setting the thread_info pointer, incrementing init_mm count, setting active_mm, configuring IRQs, registering a per-CPU clock device, printing startup info, sending CPU start notifications, and enabling local interrupts before entering the CPU startup loop. The claim about synchronizing with startup flags is not directly represented in the code and is therefore speculative.",
                "The summary correctly states that the function initializes a secondary CPU during SMP boot and enables it for operation, which matches the core behavior in the code. However, it inaccurately claims synchronization with startup flags, which is not evident in the implementation, and omits key specifics such as setting active_mm, configuring IRQs, and registering the clock device. This introduces some noise but no fatal errors on the primary purpose, and the accurate part is more generic than detailed, offering low informational gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic acpi_status acpi_dev_process_resource(struct acpi_resource *ares,\n\t\t\t\t\t     void *context)\n{\n\tstruct res_proc_context *c = context;\n\tstruct resource r;\n\tint i;\n\n\tif (c->preproc) {\n\t\tint ret;\n\n\t\tret = c->preproc(ares, c->preproc_data);\n\t\tif (ret < 0) {\n\t\t\tc->error = ret;\n\t\t\treturn AE_CTRL_TERMINATE;\n\t\t} else if (ret > 0) {\n\t\t\treturn AE_OK;\n\t\t}\n\t}\n\n\tmemset(&r, 0, sizeof(r));\n\n\tif (acpi_dev_resource_memory(ares, &r)\n\t    || acpi_dev_resource_io(ares, &r)\n\t    || acpi_dev_resource_address_space(ares, &r)\n\t    || acpi_dev_resource_ext_address_space(ares, &r))\n\t\treturn acpi_dev_new_resource_entry(&r, c);\n\n\tfor (i = 0; acpi_dev_resource_interrupt(ares, i, &r); i++) {\n\t\tacpi_status status;\n\n\t\tstatus = acpi_dev_new_resource_entry(&r, c);\n\t\tif (ACPI_FAILURE(status))\n\t\t\treturn status;\n\t}\n\n\treturn AE_OK;\n}",
    "comment": "Processes ACPI resources by calling preprocessing functions, handling memory, I/O, and address space resources, and creating new resource entries as needed.",
    "prorec_sum": "Processes hardware or ACPI data from the given structure, invoking resource-specific handlers and iterating elements to apply a standardized processing routine with error handling.",
    "filter_prorec_sum": "Processes hardware resource data from an input structure, invoking specific handlers and performing iterative operations to update the target structure with provided parameters.",
    "prorec_aug_sum": "Processes ACPI operand data by invoking region handlers or iterating field extraction routines, then dispatches results to a common evaluation function with provided parameters.",
    "filter_prorec_aug_sum": "Processes an ACPI operand by invoking its handler or iterating field elements, populating a local buffer, and executing a common evaluation routine.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes ACPI operand data by invoking region handlers or iterating field extraction routines, then dispatches results to a common evaluation function with provided parameters.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about invoking region handlers or iterating field extraction routines do not align with the source code, which instead processes resources through pre-processing, memory/IO/address space checks, and interrupt handling, then passes results to a resource entry function. There is little factual overlap, and most claims are inaccurate regarding actual function semantics.",
                "The summary's claims about invoking region handlers or iterating field extraction routines are inaccurate with respect to the source code, which instead processes ACPI resource structures, optionally calls a preprocessor, retrieves specific resource types (memory, I/O, address spaces, interrupts), and adds them via a resource entry function. The core purpose of extracting ACPI hardware resources and populating context is not described, so the main domain-specific semantics are missing, and there is no accurate coverage of side effects or condition handling.",
                "The summary is inaccurate about the core purpose: it claims the function processes ACPI operand data via region handlers or field extraction routines, but the code actually processes ACPI resource structures, optionally runs a preprocessor, extracts memory/IO/address/interrupt resources, and creates new resource entries. This is a FATAL error on the primary purpose (WHAT), as it misidentifies the function's main domain behavior and data flow. There are no accurate claims to offset this, resulting in zero net benefit."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes an ACPI operand by invoking its handler or iterating field elements, populating a local buffer, and executing a common evaluation routine.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function\u2019s behavior. The source code shows it processes ACPI resources by optionally running a preprocessor callback, zeroing a struct, checking for specific resource types, and adding entries. The summary\u2019s claims about invoking a handler, iterating field elements, and populating a local buffer for a common evaluation routine do not match the actual logic. None of the key claims are accurate to the implementation, resulting in a very low proportion of accurate statements.",
                "The summary's claims about invoking a handler, iterating field elements, and populating a local buffer do not accurately reflect the source, which processes ACPI resources via optional preprocessing, resource type extraction, and creating new resource entries. It misses the core purpose of handling ACPI resource structures and generating resource entries, and instead introduces unrelated terminology like 'operand' and 'common evaluation routine'. No accurate coverage of the core function's domain action or critical behaviors is present.",
                "The summary contains significant inaccuracies about the function's primary purpose. It incorrectly describes processing an ACPI operand, invoking its handler, iterating field elements, and executing a common evaluation routine, none of which match the source code. The actual function processes ACPI resources, optionally via a preprocessor, extracts specific resource types into a local struct, and stores them. This is a FATAL error on the core purpose, making the description misleading and untrustworthy. No accurate, code-specific claims are present to offset the failure."
            ]
        }
    }
}
{
    "source_code": "\nvoid native_play_dead(void)\n{\n\tplay_dead_common();\n\ttboot_shutdown(TB_SHUTDOWN_WFS);\n\n\tmwait_play_dead();\t/* Only returns on failure */\n\tif (cpuidle_play_dead())\n\t\thlt_play_dead();\n}",
    "comment": "Initiates a shutdown sequence and enters a low-power state, managing transitions based on CPU idle status and system power states.",
    "prorec_sum": "Initializes CPU idle monitoring using MONITOR/MWAIT instructions when specific hardware conditions are met, otherwise handles CPU bug checks and halts if critical errors occur.",
    "filter_prorec_sum": "Monitors a specific memory location using CPU MWAIT until triggered, then executes a handler, otherwise halts the processor under certain system state conditions.",
    "prorec_aug_sum": "Puts the CPU into a monitored low\u2011power idle state using MWAIT after cache flush, based on specific system and processor capability checks.",
    "filter_prorec_aug_sum": "Initializes CPU cache monitoring parameters and repeatedly enters low-power wait states until a wake condition occurs, then handles system halt on critical state.",
    "work_score": {
        "prorec_aug": {
            "summary": "Puts the CPU into a monitored low\u2011power idle state using MWAIT after cache flush, based on specific system and processor capability checks.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary introduces details not present in the source code, such as cache flushing and specific system/processor capability checks, which are unsupported by the function's implementation. The code sequence calls play_dead_common, tboot_shutdown, then mwait_play_dead, and conditionally cpuidle_play_dead or hlt_play_dead, without any explicit capability checks or cache flush steps being evident. As a result, most of the claims are inaccurate regarding source semantics.",
                "The summary does not accurately capture the core purpose of the function, which is to transition the CPU into a 'dead' state using a sequence of calls (play_dead_common, tboot_shutdown, mwait_play_dead, cpuidle_play_dead, hlt_play_dead) aimed at halting execution. It introduces inaccurate details about cache flushes and processor capability checks that are absent in the source code. No [ACCURATE] claims cover the actual execution flow or domain semantics, resulting in the core purpose being missed.",
                "The summary introduces an inaccurate and unverifiable claim about performing a cache flush, as well as system and processor capability checks, which are not present in the source code. The code directly invokes `mwait_play_dead` without explicit checks in this function and does not show a cache flush. This is a FATAL error targeting the primary purpose (what the function does before entering the low-power state). While the MWAIT low-power state part is roughly correct, the core description is misleading due to the fabricated preconditions."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes CPU cache monitoring parameters and repeatedly enters low-power wait states until a wake condition occurs, then handles system halt on critical state.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function initializes CPU cache monitoring parameters, repeatedly enters low-power wait states until a wake condition occurs, and handles system halt on a critical state. None of these details match the source code, which instead calls functions to perform a play-dead shutdown sequence with specific calls like tboot_shutdown, mwait_play_dead, cpuidle_play_dead, and hlt_play_dead. The claims misrepresent the function's purpose and behavior, resulting in 0% accurate statements.",
                "The summary's claims about initializing CPU cache monitoring parameters and handling wake conditions do not match the source code, which instead invokes functions to put the CPU into a dead state and handle shutdown. The description misses the core purpose of transitioning a CPU into a 'dead'/offline state via platform-specific calls, including fallbacks. No accurate claim covers the actual core operation, and there is no mention of the shutdown call or branching based on cpuidle_play_dead().",
                "The summary introduces NOISE by claiming the function initializes CPU cache monitoring parameters and waits for a wake condition, which is not reflected in the source code. The actual code calls play_dead_common, initiates tboot shutdown, and attempts various dead-state methods. There are no accurate GOLD details matching the primary purpose, and most statements misrepresent the core behavior. Worst failure mode is FATAL, as the incorrect description of primary purpose and core sequence makes it untrustworthy."
            ]
        }
    }
}
{
    "source_code": "static int apply_envelope(struct ml_effect_state *state, int value,\n\t\t\t  struct ff_envelope *envelope)\n{\n\tstruct ff_effect *effect = state->effect;\n\tunsigned long now = jiffies;\n\tint time_from_level;\n\tint time_of_envelope;\n\tint envelope_level;\n\tint difference;\n\n\tif (envelope->attack_length &&\n\t    time_before(now,\n\t\t\tstate->play_at + msecs_to_jiffies(envelope->attack_length))) {\n\t\tpr_debug(\"value = 0x%x, attack_level = 0x%x\\n\",\n\t\t\t value, envelope->attack_level);\n\t\ttime_from_level = jiffies_to_msecs(now - state->play_at);\n\t\ttime_of_envelope = envelope->attack_length;\n\t\tenvelope_level = min_t(u16, envelope->attack_level, 0x7fff);\n\n\t} else if (envelope->fade_length && effect->replay.length &&\n\t\t   time_after(now,\n\t\t\t      state->stop_at - msecs_to_jiffies(envelope->fade_length)) &&\n\t\t   time_before(now, state->stop_at)) {\n\t\ttime_from_level = jiffies_to_msecs(state->stop_at - now);\n\t\ttime_of_envelope = envelope->fade_length;\n\t\tenvelope_level = min_t(u16, envelope->fade_level, 0x7fff);\n\t} else\n\t\treturn value;\n\n\tdifference = abs(value) - envelope_level;\n\n\tpr_debug(\"difference = %d\\n\", difference);\n\tpr_debug(\"time_from_level = 0x%x\\n\", time_from_level);\n\tpr_debug(\"time_of_envelope = 0x%x\\n\", time_of_envelope);\n\n\tdifference = difference * time_from_level / time_of_envelope;\n\n\tpr_debug(\"difference = %d\\n\", difference);\n\n\treturn value < 0 ?\n\t\t-(difference + envelope_level) : (difference + envelope_level);\n}",
    "comment": "Adjusts the input value based on an attack or fade envelope, modifying the output according to the elapsed time and specified envelope levels.",
    "prorec_sum": "Adjusts an input value toward a target limit based on buffer occupancy thresholds and scaling factors from provided parameters.",
    "filter_prorec_sum": "Calculates and returns a rate-adjusted value based on input signal parameters, enforcing limits and bounds from current buffer and timing constraints.",
    "prorec_aug_sum": "Adjusts a signed input value based on threshold checks and scaling calculations using fields from two data structures and given 16\u2011bit parameters.",
    "filter_prorec_aug_sum": "Adjusts an input value proportionally based on threshold checks and scaling parameters retrieved from the provided data structure and measurement function.",
    "work_score": {
        "prorec_aug": {
            "summary": "Adjusts a signed input value based on threshold checks and scaling calculations using fields from two data structures and given 16\u2011bit parameters.",
            "score": [
                0.6,
                0.2,
                0.5
            ],
            "reason": [
                "The summary correctly identifies that the function adjusts a signed input value and uses fields from two data structures in its calculations, which matches the code\u2019s use of `state`, `effect`, and `envelope`. However, mentioning 'threshold checks' and 'scaling calculations' is accurate in a general sense but fails to reflect specific domain semantics such as attack/fade envelope timing conditions and 16-bit limiting behavior. The reference to 'given 16\u2011bit parameters' is somewhat accurate due to the `min_t(u16, ...)` use, but overall, the description is too generic and omits key temporal logic, leading to partially accurate coverage.",
                "The summary makes a very generic claim about adjusting a value based on thresholds and scaling, which loosely aligns with the code's math operations but fails to cover the core domain purpose: applying attack or fade envelope adjustments to an effect's value over time using timing logic from state and envelope parameters. It omits critical conditions involving play/stop times, envelope lengths, and attack/fade levels. While not factually wrong, it is too vague and misses both the specific core action and secondary semantics in the source such as the separate handling for attack and fade phases and debugging output.",
                "The summary correctly notes that the function adjusts a signed input value using fields from two data structures, but it is overly generic and misses key specifics such as handling of attack and fade phases, time-based envelope scaling, and debugging outputs. There are no inaccurate or contradictory claims, but the information provided is low\u2011value SAFE content with little detail, resulting in low net benefit due to omission of critical domain semantics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Adjusts an input value proportionally based on threshold checks and scaling parameters retrieved from the provided data structure and measurement function.",
            "score": [
                0.9,
                0.2,
                0.5
            ],
            "reason": [
                "The summary accurately conveys that the function modifies the input value proportionally based on certain checks and parameters from the provided structures, which aligns with the attack and fade envelope logic in the code. However, it is overly generic, omitting explicit details such as attack vs fade conditions, use of jiffies for timing, and how envelope_level is calculated. All claims are correct but low in specificity, making them SAFE rather than GOLD.",
                "The summary is vague and generic, failing to explicitly describe the core behavior of applying an attack or fade envelope based on timing in relation to the start/stop of an effect. While it hints at proportional adjustment and parameter use, it omits key domain specifics like handling of attack_length, fade_length, replay length, time comparisons, and envelope levels. This means the core purpose is not covered, and secondary details are minimal.",
                "The summary is overly generic and lacks precise alignment with the function's actual behavior. While it correctly conveys that the function adjusts a value based on conditions and parameters from input structures, it omits key specifics such as handling attack and fade phases, using time comparisons, and clamping levels. This makes it a SAFE but low-information statement with no direct inaccuracies. The worst issue is low gain due to missing core domain details rather than factual errors."
            ]
        }
    }
}
{
    "source_code": "\nvoid write_xattr(char *pathname, unsigned int xattr)\n{\n\tunsigned int count;\n\tstruct xattr_list *xattr_list;\n\tint i;\n\tstatic int nonsuper_error = FALSE;\n\tstatic int ignore_xattrs = FALSE;\n\tstatic int nospace_error = 0;\n\n\tif(ignore_xattrs || xattr == SQUASHFS_INVALID_XATTR ||\n\t\t\tsBlk.s.xattr_id_table_start == SQUASHFS_INVALID_BLK)\n\t\treturn;\n\n\txattr_list = get_xattr(xattr, &count, 1);\n\tif(xattr_list == NULL) {\n\t\tERROR(\"Failed to read xattrs for file %s\\n\", pathname);\n\t\treturn;\n\t}\n\n\tfor(i = 0; i < count; i++) {\n\t\tint prefix = xattr_list[i].type & SQUASHFS_XATTR_PREFIX_MASK;\n\n\t\tif(user_xattrs && prefix != SQUASHFS_XATTR_USER)\n\t\t\tcontinue;\n\n\t\tif(root_process || prefix == SQUASHFS_XATTR_USER) {\n\t\t\tint res = lsetxattr(pathname, xattr_list[i].full_name,\n\t\t\t\txattr_list[i].value, xattr_list[i].vsize, 0);\n\n\t\t\tif(res == -1) {\n\t\t\t\tif(errno == ENOTSUP) {\n\t\t\t\t\t/*\n\t\t\t\t\t * If the destination filesystem cannot\n\t\t\t\t\t * suppport xattrs, print error, and\n\t\t\t\t\t * disable xattr output as this error is\n\t\t\t\t\t * unlikely to go away, and printing\n\t\t\t\t\t * screenfulls of the same error message\n\t\t\t\t\t * is rather annoying\n\t\t\t\t\t */\n\t\t\t\t\tERROR(\"write_xattr: failed to write \"\n\t\t\t\t\t\t\"xattr %s for file %s because \" \n\t\t\t\t\t\t\"extended attributes are not \"\n\t\t\t\t\t\t\"supported by the destination \"\n\t\t\t\t\t\t\"filesystem\\n\",\n\t\t\t\t\t\txattr_list[i].full_name,\n\t\t\t\t\t\tpathname);\n\t\t\t\t\tERROR(\"Ignoring xattrs in \"\n\t\t\t\t\t\t\t\t\"filesystem\\n\");\n\t\t\t\t\tERROR(\"To avoid this error message, \"\n\t\t\t\t\t\t\"specify -no-xattrs\\n\");\n\t\t\t\t\tignore_xattrs = TRUE;\n\t\t\t\t} else if((errno == ENOSPC || errno == EDQUOT)\n\t\t\t\t\t\t&& nospace_error < NOSPACE_MAX) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Many filesystems like ext2/3/4 have\n\t\t\t\t\t * limits on the amount of xattr\n\t\t\t\t\t * data that can be stored per file\n\t\t\t\t\t * (typically one block or 4K), so\n\t\t\t\t\t * we shouldn't disable xattr ouput,\n\t\t\t\t\t * as the error may be restriced to one\n\t\t\t\t\t * file only.  If we get a lot of these\n\t\t\t\t\t * then suppress the error messsage\n\t\t\t\t\t */\n\t\t\t\t\tERROR(\"write_xattr: failed to write \"\n\t\t\t\t\t\t\"xattr %s for file %s because \" \n\t\t\t\t\t\t\"no extended attribute space \"\n\t\t\t\t\t\t\"remaining (per file or \"\n\t\t\t\t\t\t\"filesystem limit)\\n\",\n\t\t\t\t\t\txattr_list[i].full_name,\n\t\t\t\t\t\tpathname);\n\t\t\t\t\tif(++ nospace_error == NOSPACE_MAX)\n\t\t\t\t\t\tERROR(\"%d of these errors \"\n\t\t\t\t\t\t\t\"printed, further error \"\n\t\t\t\t\t\t\t\"messages of this type \"\n\t\t\t\t\t\t\t\"are suppressed!\\n\",\n\t\t\t\t\t\t\tNOSPACE_MAX);\n\t\t\t\t} else\n\t\t\t\t\tERROR(\"write_xattr: failed to write \"\n\t\t\t\t\t\t\"xattr %s for file %s because \"\n\t\t\t\t\t\t\"%s\\n\", xattr_list[i].full_name,\n\t\t\t\t\t\tpathname, strerror(errno));\n\t\t\t}\n\t\t} else if(nonsuper_error == FALSE) {\n\t\t\t/*\n\t\t\t * if extract user xattrs only then\n\t\t\t * error message is suppressed, if not\n\t\t\t * print error, and then suppress further error\n\t\t\t * messages to avoid possible screenfulls of the\n\t\t\t * same error message!\n\t\t\t */\n\t\t\tERROR(\"write_xattr: could not write xattr %s \"\n\t\t\t\t\t\"for file %s because you're not \"\n\t\t\t\t\t\"superuser!\\n\",\n\t\t\t\t\txattr_list[i].full_name, pathname);\n\t\t\tERROR(\"write_xattr: to avoid this error message, either\"\n\t\t\t\t\" specify -user-xattrs, -no-xattrs, or run as \"\n\t\t\t\t\"superuser!\\n\");\n\t\t\tERROR(\"Further error messages of this type are \"\n\t\t\t\t\"suppressed!\\n\");\n\t\t\tnonsuper_error = TRUE;\n\t\t}\n\t}\n\n\tfree_xattr(xattr_list, count);\n}",
    "comment": "Writes extended attributes to a specified file while handling errors for unsupported filesystems, space limitations, and non-superuser access.",
    "prorec_sum": "Sets multiple extended file attributes on the specified path from provided data and handles specific errno cases with retries or state flags.",
    "filter_prorec_sum": "Sets multiple extended file attributes on the given path from retrieved records, handling specific errno conditions and updating related global error state flags.",
    "prorec_aug_sum": "Sets extended file attributes on the given path from retrieved metadata, handling specific errno cases and updating related global error state flags.",
    "filter_prorec_aug_sum": "Sets extended file attributes from a descriptor onto the specified path, handling specific errno cases and maintaining related operation state flags.",
    "work_score": {
        "prorec_aug": {
            "summary": "Sets extended file attributes on the given path from retrieved metadata, handling specific errno cases and updating related global error state flags.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function sets extended file attributes on the given path using retrieved metadata, and that it handles specific errno cases while updating global error state flags. These points accurately reflect the code\u2019s behavior, which processes xattrs via lsetxattr, reacts to ENOTSUP, ENOSPC, EDQUOT, and other errors, and modifies flags like ignore_xattrs, nospace_error, and nonsuper_error. No contradictory or irrelevant claims are present, and all elements are grounded in the source code semantics.",
                "The summary correctly captures the core function of setting extended attributes from retrieved metadata, which matches the function's main purpose of applying xattrs to a file. It also notes handling of specific errno cases and updating global error flags, reflecting the code\u2019s logic for ENOTSUP, ENOSPC/EDQUOT, and superuser checks along with ignore_xattrs and nonsuper_error state. However, it omits key specifics such as selective application based on prefix and user_xattrs/root_process conditions, suppression of repeated errors, and details about NOSPACE_MAX behavior. Coverage of secondary points is present but lacks full breadth of the function\u2019s branching and filtering logic.",
                "The summary correctly identifies the function's core purpose of setting extended attributes on a given path from retrieved metadata and mentions handling specific error codes along with updating global state flags. These are accurate, domain-specific behaviors reflected in the code, with no contradictions or irrelevant noise present. However, the summary is somewhat broad and omits details such as conditional prefix checks, suppression of repetitive errors, and specific cases like ENOSPC handling limits, which would make it more informative."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Sets extended file attributes from a descriptor onto the specified path, handling specific errno cases and maintaining related operation state flags.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function sets extended attributes on a specified path and that it handles specific errno cases while tracking state flags. These points align with the code's main behavior: using lsetxattr to apply attributes, checking errno for ENOTSUP, ENOSPC, EDQUOT, and other errors, and updating ignore_xattrs, nospace_error, and nonsuper_error. However, the summary is generic and omits notable details such as filtering xattrs by prefix and user permissions, and the conditions under which the function returns early. Despite its brevity, most of its claims are accurate.",
                "The summary correctly identifies that the function applies extended attributes to a given path and that it handles specific errno cases while updating related state flags, aligning with the core behavior, which is writing xattrs from a descriptor to a file pathname. However, it lacks detail on important secondary aspects such as conditions for skipping attributes, restrictions based on user permissions, and suppression of repeated errors, so coverage of secondary semantics is incomplete.",
                "The summary correctly states that the function sets extended file attributes on a given path and handles specific errno cases with state flags, which matches the core logic in the source. However, it is generic and omits several important specific details, such as the conditional filtering of xattrs by type, suppression of repeated errors, and the cases for user vs superuser privileges. There are no inaccurate claims, but the coverage is shallow, yielding low informational value."
            ]
        }
    }
}
{
    "source_code": "static void __synchronize_srcu(struct srcu_struct *sp, int trycount)\n{\n\tstruct rcu_synchronize rcu;\n\tstruct rcu_head *head = &rcu.head;\n\tbool done = false;\n\n\trcu_lockdep_assert(!lock_is_held(&sp->dep_map) &&\n\t\t\t   !lock_is_held(&rcu_bh_lock_map) &&\n\t\t\t   !lock_is_held(&rcu_lock_map) &&\n\t\t\t   !lock_is_held(&rcu_sched_lock_map),\n\t\t\t   \"Illegal synchronize_srcu() in same-type SRCU (or RCU) read-side critical section\");\n\n\tmight_sleep();\n\tinit_completion(&rcu.completion);\n\n\thead->next = NULL;\n\thead->func = wakeme_after_rcu;\n\tspin_lock_irq(&sp->queue_lock);\n\tif (!sp->running) {\n\t\t/* steal the processing owner */\n\t\tsp->running = true;\n\t\trcu_batch_queue(&sp->batch_check0, head);\n\t\tspin_unlock_irq(&sp->queue_lock);\n\n\t\tsrcu_advance_batches(sp, trycount);\n\t\tif (!rcu_batch_empty(&sp->batch_done)) {\n\t\t\tBUG_ON(sp->batch_done.head != head);\n\t\t\trcu_batch_dequeue(&sp->batch_done);\n\t\t\tdone = true;\n\t\t}\n\t\t/* give the processing owner to work_struct */\n\t\tsrcu_reschedule(sp);\n\t} else {\n\t\trcu_batch_queue(&sp->batch_queue, head);\n\t\tspin_unlock_irq(&sp->queue_lock);\n\t}\n\n\tif (!done)\n\t\twait_for_completion(&rcu.completion);\n}",
    "comment": "Synchronizes SRCU processing by queuing a completion task and waiting for it to finish if not already done by the processing owner.",
    "prorec_sum": "Initializes lock-related state, updates linked list pointers, enables interrupts, and invokes further processing with provided parameters.",
    "filter_prorec_sum": "Initializes and links internal queue elements, enables interrupts, and dispatches processing of provided parameters within a locked synchronization context.",
    "prorec_aug_sum": "Initializes and links internal data structures, enables interrupts, and processes parameters before invoking a secondary handler for further execution.",
    "filter_prorec_aug_sum": "Initializes internal queue pointers, enables interrupts, and processes a hardware event with provided parameters before invoking the corresponding handler.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes and links internal data structures, enables interrupts, and processes parameters before invoking a secondary handler for further execution.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains vague and partially inaccurate claims. While it loosely references initialization and processing, it incorrectly asserts that interrupts are enabled, which is not supported by the source code (it uses spin_lock_irq but does not enable interrupts). No mention is made of the actual SRCU-specific synchronization, completion waiting, or handling of trycount, so most claims are generic or irrelevant. Less than half of the claims are accurate representations of the function's behavior.",
                "The summary's claims about initializing internal structures loosely match the code's setup of completion and RCU head, but references to enabling interrupts and processing parameters before calling a secondary handler are inaccurate or irrelevant to the actual SRCU synchronization process. It fails to identify the core purpose of waiting for an SRCU grace period via queuing the RCU head and advancing batches, instead offering vague and partially incorrect generalities with no coverage of branching, error checks, or synchronization details.",
                "The summary contains mostly inaccurate claims: it mentions enabling interrupts and invoking a secondary handler, neither of which are present in the source code. The summary fails to correctly identify the core purpose of the function, which is to synchronize SRCU by queuing work and waiting for completion, making this a FATAL error affecting the primary purpose. Accurate coverage of the SRCU-specific locking and queuing is missing, and noise overwhelms accuracy, resulting in very low utility."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes internal queue pointers, enables interrupts, and processes a hardware event with provided parameters before invoking the corresponding handler.",
            "score": [
                0.2,
                0.1,
                0.1
            ],
            "reason": [
                "The summary makes several claims \u2014 initialization of internal queue pointers, enabling interrupts, processing a hardware event, and invoking a handler \u2014 that do not align with the source code. The function does initialize queue-related pointers and set a callback, but it does not enable interrupts (it manipulates spin locks with IRQ flags) and it does not handle hardware events; it manages SRCU synchronization logic. Most claims are inaccurate with respect to the code\u2019s semantics.",
                "The summary's claims about initializing queue pointers and enabling interrupts are partially tangential at best, but its statements about processing a hardware event and invoking a handler are inaccurate with respect to the code, which actually synchronizes SRCU by queueing a callback and waiting for batch completion with concurrency checks. The core primary purpose\u2014ensuring all SRCU read-side critical sections complete before proceeding\u2014is not mentioned, and the given description misrepresents the domain semantics entirely with unrelated hardware processing language.",
                "The summary contains entirely inaccurate claims about the code\u2019s semantics. It states that the function enables interrupts, processes a hardware event, and invokes a handler with provided parameters, none of which occur in the source. The actual code deals with SRCU synchronization: setting up an RCU completion, queuing work, advancing batches, and waiting, with no hardware events or enabling interrupts. This constitutes a severe FATAL error on the primary purpose of the function, making the description unusable."
            ]
        }
    }
}
{
    "source_code": "\nint kernel_ident_mapping_init(struct x86_mapping_info *info, pgd_t *pgd_page,\n\t\t\t      unsigned long addr, unsigned long end)\n{\n\tunsigned long next;\n\tint result;\n\tint off = info->kernel_mapping ? pgd_index(__PAGE_OFFSET) : 0;\n\n\tfor (; addr < end; addr = next) {\n\t\tpgd_t *pgd = pgd_page + pgd_index(addr) + off;\n\t\tpud_t *pud;\n\n\t\tnext = (addr & PGDIR_MASK) + PGDIR_SIZE;\n\t\tif (next > end)\n\t\t\tnext = end;\n\n\t\tif (pgd_present(*pgd)) {\n\t\t\tpud = pud_offset(pgd, 0);\n\t\t\tresult = ident_pud_init(info, pud, addr, next);\n\t\t\tif (result)\n\t\t\t\treturn result;\n\t\t\tcontinue;\n\t\t}\n\n\t\tpud = (pud_t *)info->alloc_pgt_page(info->context);\n\t\tif (!pud)\n\t\t\treturn -ENOMEM;\n\t\tresult = ident_pud_init(info, pud, addr, next);\n\t\tif (result)\n\t\t\treturn result;\n\t\tset_pgd(pgd, __pgd(__pa(pud) | _KERNPG_TABLE));\n\t}\n\n\treturn 0;\n}",
    "comment": "Initializes kernel identity mapping by setting up page entries in the page global directory for the specified address range, allocating pages as needed.",
    "prorec_sum": "Maps a virtual address range to physical pages in an IOMMU domain, allocating and setting page table entries as required.",
    "filter_prorec_sum": "Maps a virtual address range to physical memory in an IOMMU page table, allocating and linking page table entries when absent.",
    "prorec_aug_sum": "Traverses a virtual address range, allocating and linking page table entries as needed, and delegates processing of each mapped segment to a helper function.",
    "filter_prorec_aug_sum": "Traverses a range of virtual addresses, allocating and mapping missing page table entries, and recursively processing already present mappings.",
    "work_score": {
        "prorec_aug": {
            "summary": "Traverses a virtual address range, allocating and linking page table entries as needed, and delegates processing of each mapped segment to a helper function.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary contains two key claims: that the function traverses a virtual address range and that it allocates and links page table entries as needed, delegating segment processing to a helper function. Both claims align with the source code: the loop walks through addresses from 'addr' to 'end', allocates new 'pud' pages when necessary, links them via 'set_pgd', and calls 'ident_pud_init' for each segment. No inaccurate or irrelevant statements are present, so the claims are highly precise and correct.",
                "The summary correctly states that the function traverses a virtual address range, allocates page table entries when necessary, and calls a helper for each segment, which aligns with the code\u2019s loop over addr to end, allocation when pgd not present, and calls to ident_pud_init. This covers the core purpose of initializing identity mappings in the page table. However, it omits key secondary details such as the handling of kernel_mapping offset, the specific levels of the page table (PGD/PUD), return-on-error behavior, and setting PGD entries with proper flags, which reduces completeness.",
                "The summary contains a single accurate GOLD claim: it correctly states that the function iterates over a virtual address range, allocates and links page table entries when necessary, and uses a helper to process each segment. This matches the code, where the loop progresses through the address space, allocates PUD pages if missing, links them into the PGD, and calls ident_pud_init. There is no inaccurate or noisy claim, but the description is somewhat generic and omits notable details such as the offset adjustment based on kernel_mapping and the error handling. The worst failure mode is absent (no FATAL), and the gain is moderate due to correct but not highly detailed coverage."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Traverses a range of virtual addresses, allocating and mapping missing page table entries, and recursively processing already present mappings.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary contains two main claims: that the function traverses a range of virtual addresses and that it allocates/mapping missing page table entries while recursively processing already present mappings. Both claims align with the source code: the loop advances from `addr` to `end` confirming traversal, and the code checks for present entries, processes them via `ident_pud_init`, or allocates new ones when absent. All extracted claims are accurate and correspond to the function\u2019s actual behavior.",
                "The summary accurately captures the core purpose: iterating over a virtual address range to allocate missing page tables and process existing ones, which matches the function\u2019s loop over addresses, handling present pgd entries and allocating new ones. However, it omits several secondary, behavior-critical details from the source code such as indexing offset for kernel mapping, calculation of 'next' using PGDIR_MASK/PGDIR_SIZE, early returns on allocation failure (-ENOMEM), and the final setting of pgd entries with specific flags. These omissions reduce coverage of important semantics.",
                "The summary accurately states the primary purpose of the function: iterating over a virtual address range, allocating missing page table levels, and handling already present mappings by invoking a recursive initializer. This aligns with the source code, which loops through addresses, checks for existing pgd entries, allocates new pud pages when missing, and calls ident_pud_init for both present and newly allocated entries. There is no contradictory or irrelevant information, and the claim is specific to the function's semantics, giving clear insight into its behavior."
            ]
        }
    }
}
{
    "source_code": "\nstatic reg_errcode_t\n__attribute_warn_unused_result__\nregister_state (const re_dfa_t *dfa, re_dfastate_t *newstate,\n\t\tre_hashval_t hash)\n{\n  struct re_state_table_entry *spot;\n  reg_errcode_t err;\n  Idx i;\n\n  newstate->hash = hash;\n  err = re_node_set_alloc (&newstate->non_eps_nodes, newstate->nodes.nelem);\n  if (BE (err != REG_NOERROR, 0))\n    return REG_ESPACE;\n  for (i = 0; i < newstate->nodes.nelem; i++)\n    {\n      Idx elem = newstate->nodes.elems[i];\n      if (!IS_EPSILON_NODE (dfa->nodes[elem].type))\n\tif (! re_node_set_insert_last (&newstate->non_eps_nodes, elem))\n\t  return REG_ESPACE;\n    }\n\n  spot = dfa->state_table + (hash & dfa->state_hash_mask);\n  if (BE (spot->alloc <= spot->num, 0))\n    {\n      Idx new_alloc = 2 * spot->num + 2;\n      re_dfastate_t **new_array = re_realloc (spot->array, re_dfastate_t *,\n\t\t\t\t\t      new_alloc);\n      if (BE (new_array == NULL, 0))\n\treturn REG_ESPACE;\n      spot->array = new_array;\n      spot->alloc = new_alloc;\n    }\n  spot->array[spot->num++] = newstate;\n  return REG_NOERROR;\n}",
    "comment": "Registers a new DFA state in the state table, allocating memory as needed and populating non-epsilon nodes.",
    "prorec_sum": "Allocates and initializes a data structure, validates its elements, and appends it into a dynamically resized list within a container object.",
    "filter_prorec_sum": "Allocates and initializes an entry structure, validates referenced elements, and appends it into a dynamically resized list within the primary data container.",
    "prorec_aug_sum": "Initializes a data structure, allocates memory for its elements, validates them, and inserts the structure into a dynamically managed list indexed by a mask.",
    "filter_prorec_aug_sum": "Allocates and initializes an entry structure, validates referenced elements, and appends it into a dynamically resized list within the given container.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes a data structure, allocates memory for its elements, validates them, and inserts the structure into a dynamically managed list indexed by a mask.",
            "score": [
                0.6,
                0.3,
                0.6
            ],
            "reason": [
                "The summary captures some general aspects of the function, such as initialization, memory allocation, validation, and insertion into a masked index list. However, these claims are generic and omit key specifics from the source code, like filtering non-epsilon nodes, handling allocation failures with specific error codes, and expanding the table when full. Most statements are accurate in a broad sense but lack the detailed domain semantics, resulting in moderate precision.",
                "The summary identifies generic steps like initializing a structure, allocating memory, validating elements, and inserting into a list indexed by a mask, which loosely align with actions in the source code. However, it fails to cover the core primary purpose of registering a DFA state into a state table with specific handling for non-epsilon nodes and capacity expansion. The omissions of domain-specific semantics and error handling result in incomplete coverage of critical behaviors.",
                "The summary contains mostly accurate but very generic claims. It correctly conveys that the function initializes part of a structure, allocates memory for elements, validates/filter them, and inserts into a data structure indexed by a hash mask. However, it omits specific details such as handling non-epsilon nodes, returning error codes, and dynamic resizing of the state table array. There are no factually inaccurate or contradictory claims, but the content is low-information, offering little domain-specific insight. The worst failure mode is low gain due to vagueness, not factual errors."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates and initializes an entry structure, validates referenced elements, and appends it into a dynamically resized list within the given container.",
            "score": [
                0.5,
                0.3,
                0.6
            ],
            "reason": [
                "The summary captures some generic aspects like allocation, initialization, and appending to a resizable list, which align loosely with the code's dynamic allocation of nodes and array resizing. However, it omits critical domain-specific details such as handling non-epsilon nodes, hash-based placement in the state table, error handling with REG_ESPACE, and exact structure types. The claims are mostly generic and partially accurate, with several omissions of key semantics, leading to mixed reliability.",
                "The summary provides a generic description of allocation, initialization, validation, and dynamic list insertion, which loosely corresponds to allocating a non-epsilon node set, ensuring space, and inserting a state into the DFA\u2019s table. However, it does not specifically cover the core primary purpose of registering a DFA state keyed by a hash into the DFA\u2019s state table, omitting critical domain-specific details such as the DFA context, hash-based indexing, and error handling paths. Thus, while some secondary actions like allocation and resizing are touched, the most distinguishing semantics are absent.",
                "The summary captures the general flow \u2014 allocation, initialization, validation of elements, and appending to a resizable collection \u2014 which matches the function's behavior of allocating the non-epsilon nodes set, checking elements, and inserting into a dynamically resized table array. However, it is very generic and omits key domain-specific details such as the DFA state registration context, the use of the hash for placement, and memory error handling. There are no contradictory or irrelevant statements (no FATAL or overwhelming NOISE), but the gain is low due to lack of specificity."
            ]
        }
    }
}
{
    "source_code": "\napr_fileperms_t apr_unix_mode2perms(mode_t mode)\n{\n    apr_fileperms_t perms = 0;\n\n    if (mode & S_ISUID)\n        perms |= APR_USETID;\n    if (mode & S_IRUSR)\n        perms |= APR_UREAD;\n    if (mode & S_IWUSR)\n        perms |= APR_UWRITE;\n    if (mode & S_IXUSR)\n        perms |= APR_UEXECUTE;\n\n    if (mode & S_ISGID)\n        perms |= APR_GSETID;\n    if (mode & S_IRGRP)\n        perms |= APR_GREAD;\n    if (mode & S_IWGRP)\n        perms |= APR_GWRITE;\n    if (mode & S_IXGRP)\n        perms |= APR_GEXECUTE;\n\n#ifdef S_ISVTX\n    if (mode & S_ISVTX)\n        perms |= APR_WSTICKY;\n#endif\n    if (mode & S_IROTH)\n        perms |= APR_WREAD;\n    if (mode & S_IWOTH)\n        perms |= APR_WWRITE;\n    if (mode & S_IXOTH)\n        perms |= APR_WEXECUTE;\n\n    return perms;\n}",
    "comment": "Converts a Unix file mode into an APR file permissions representation by checking user, group, and others' read, write, and execute bits.",
    "prorec_sum": "Converts a Unix file mode bitmask into an APR permission bitfield representing read, write, execute, and special mode flags.",
    "filter_prorec_sum": "Converts a Unix file mode bitmask into a corresponding APR permission bitfield representation.",
    "prorec_aug_sum": "Converts a Unix file mode bitmask into an APR-style permission flag representation.",
    "filter_prorec_aug_sum": "Converts a Unix file mode bitmask into an APR-style permission bitfield encoding owner, group, and other read, write, execute, and special bits.",
    "work_score": {
        "prorec_aug": {
            "summary": "Converts a Unix file mode bitmask into an APR-style permission flag representation.",
            "score": [
                1.0,
                0.4,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function converts a Unix file mode bitmask into an APR-style permission flag representation, which matches the source code's logic. This is an accurate, high-level description of the function's semantics, with no contradictory or irrelevant claims. Although it is generic and does not detail the specific flags, it is factually consistent with the implementation, resulting in all claims being accurate.",
                "The summary accurately states the core purpose of the function, which is converting a Unix file mode bitmask to APR-style permission flags. This matches the function's domain-specific operation. However, it omits secondary behavior-critical details such as specific flag mappings for user/group/other permissions, handling of special bits like setuid, setgid, and sticky bit, and constants used. Thus, while the core is covered, coverage of secondary details is minimal.",
                "The summary accurately states the primary purpose of the function: translating a Unix file mode bitmask into an APR permission flag set. This matches the code's logic, which checks specific mode bits and maps them to corresponding APR constants. The claim is correct but generic, providing low detail about specific flags handled. There are no inaccuracies or noise, and while the gain is limited, it is still a clear and accurate description of the core functionality."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Converts a Unix file mode bitmask into an APR-style permission bitfield encoding owner, group, and other read, write, execute, and special bits.",
            "score": [
                1.0,
                0.5,
                0.9
            ],
            "reason": [
                "The summary correctly describes the function as converting a Unix file mode bitmask into an APR permission bitfield and notes inclusion of owner, group, and other read, write, execute, and special bits. This matches the implementation, which maps mode_t flags (including setuid, setgid, sticky) to corresponding APR constants. All claims are accurate and directly relevant to the code\u2019s semantics.",
                "The summary accurately describes the core behavior by stating that the function converts a Unix file mode bitmask into an APR permission bitfield, including owner, group, other permissions, and special bits. This matches the core purpose of mapping mode_t flags to apr_fileperms_t constants for read, write, execute, and special flags. However, it lacks detailed coverage of specific flags (e.g., S_ISUID, S_ISGID, S_ISVTX) and their corresponding APR constants, so secondary detail is minimal.",
                "The summary correctly describes the core functionality: translating a Unix mode bitmask into an APR-defined permission bitfield covering owner, group, and other read/write/execute permissions, as well as special bits like setuid, setgid, and sticky. This is an accurate GOLD-level claim with no contradictions or irrelevant noise. While concise and lacking in exhaustive detail of each mapping, it fully captures the primary purpose with minimal noise, yielding high net benefit."
            ]
        }
    }
}
{
    "source_code": "\nstatic int check_policy(X509_STORE_CTX *ctx)\n\t{\n\tint ret;\n\tif (ctx->parent)\n\t\treturn 1;\n\tret = X509_policy_check(&ctx->tree, &ctx->explicit_policy, ctx->chain,\n\t\t\t\tctx->param->policies, ctx->param->flags);\n\tif (ret == 0)\n\t\t{\n\t\tX509err(X509_F_CHECK_POLICY,ERR_R_MALLOC_FAILURE);\n\t\treturn 0;\n\t\t}\n\t/* Invalid or inconsistent extensions */\n\tif (ret == -1)\n\t\t{\n\t\t/* Locate certificates with bad extensions and notify\n\t\t * callback.\n\t\t */\n\t\tX509 *x;\n\t\tint i;\n\t\tfor (i = 1; i < sk_X509_num(ctx->chain); i++)\n\t\t\t{\n\t\t\tx = sk_X509_value(ctx->chain, i);\n\t\t\tif (!(x->ex_flags & EXFLAG_INVALID_POLICY))\n\t\t\t\tcontinue;\n\t\t\tctx->current_cert = x;\n\t\t\tctx->error = X509_V_ERR_INVALID_POLICY_EXTENSION;\n\t\t\tif(!ctx->verify_cb(0, ctx))\n\t\t\t\treturn 0;\n\t\t\t}\n\t\treturn 1;\n\t\t}\n\tif (ret == -2)\n\t\t{\n\t\tctx->current_cert = NULL;\n\t\tctx->error = X509_V_ERR_NO_EXPLICIT_POLICY;\n\t\treturn ctx->verify_cb(0, ctx);\n\t\t}\n\n\tif (ctx->param->flags & X509_V_FLAG_NOTIFY_POLICY)\n\t\t{\n\t\tctx->current_cert = NULL;\n\t\tctx->error = X509_V_OK;\n\t\tif (!ctx->verify_cb(2, ctx))\n\t\t\treturn 0;\n\t\t}\n\n\treturn 1;\n\t}",
    "comment": "Validates X509 certificate policies, checks for invalid extensions, and invokes a callback for policy notifications or errors during the verification process.",
    "prorec_sum": "Checks X.509 certificate policies using `X509_policy_check` and triggers appropriate error handling or callbacks based on the validation result.",
    "filter_prorec_sum": "Performs X.509 certificate policy checking and invokes configured callbacks to handle compliance, violations, or errors during verification.",
    "prorec_aug_sum": "Checks X.509 certificate policies and invokes a callback to handle specific policy violations or errors during SSL certificate verification.",
    "filter_prorec_aug_sum": "Validates X.509 certificate policies via `X509_policy_check` and triggers appropriate error handling or callbacks based on the check result.",
    "work_score": {
        "prorec_aug": {
            "summary": "Checks X.509 certificate policies and invokes a callback to handle specific policy violations or errors during SSL certificate verification.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary captures the general purpose of the function\u2014checking X.509 certificate policies and invoking a callback for policy violations\u2014which is consistent with the source code. However, it omits specific and verifiable details like handling explicit policy absence, invalid policy extensions, and the early return when ctx->parent is set. Most of the claims are accurate but generic, with no contradictory or false statements, resulting in high accuracy but low specificity.",
                "The summary accurately states that the function checks X.509 certificate policies and calls a callback for policy violations or errors, which matches the core purpose of invoking X509_policy_check and handling specific return cases with verify_cb. However, it lacks detail on key secondary behaviors, such as early return when ctx->parent is set, explicit handling of different return values (-1, -2, 0) with specific error codes, and the notification behavior when X509_V_FLAG_NOTIFY_POLICY is set. This makes coverage of secondary semantics incomplete.",
                "The summary correctly states that the function checks X.509 certificate policies and calls a callback for handling certain policy errors, which matches the core logic in the source code: calling X509_policy_check, detecting specific return values (-1 for invalid policies, -2 for no explicit policy), and invoking ctx->verify_cb. However, it inaccurately frames the context as 'SSL certificate verification' rather than general X.509 validation, which is a mild overreach but not a severe FATAL. The claim covers the primary purpose with fair specificity, and noise is minimal, making this moderately accurate but not deeply detailed."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates X.509 certificate policies via `X509_policy_check` and triggers appropriate error handling or callbacks based on the check result.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function calls `X509_policy_check` to validate X.509 certificate policies and that it handles errors or triggers callbacks based on the result. This aligns with the source code, which processes return values from `X509_policy_check` and invokes error handling or `verify_cb` callbacks accordingly. No inaccuracies or irrelevant claims are present, making it a precise reflection of the core semantics.",
                "The summary accurately captures the core purpose of the function \u2014 validating X.509 certificate policies using `X509_policy_check` and invoking corresponding error handling or callbacks based on results. This matches the source code's primary operation and main control flow. However, it omits key secondary details like early return when `ctx->parent` exists, handling specific return codes (-1 and -2) with targeted error codes, iteration over certificates with invalid policy extensions, and notify policy flag behavior. Coverage of the core is strong but secondary behavior is underrepresented.",
                "The summary captures the primary purpose accurately: the function checks X.509 certificate policies using `X509_policy_check` and responds with errors or callbacks depending on the result. This aligns with the code's main logic flow and key decision branches. There is no contradictory or irrelevant noise, and while the claim is concise and generic (SAFE), it still conveys the core semantics correctly. However, it lacks detailed specifics on error codes, flag handling, or the conditions checked, so the gain is moderate rather than high."
            ]
        }
    }
}
{
    "source_code": "void\nmpz_rootrem (mpz_t x, mpz_t r, const mpz_t y, unsigned long z)\n{\n  int sgn;\n  mpz_t t, u;\n\n  sgn = y->_mp_size < 0;\n  if ((~z & sgn) != 0)\n    gmp_die (\"mpz_rootrem: Negative argument, with even root.\");\n  if (z == 0)\n    gmp_die (\"mpz_rootrem: Zeroth root.\");\n\n  if (mpz_cmpabs_ui (y, 1) <= 0) {\n    if (x)\n      mpz_set (x, y);\n    if (r)\n      r->_mp_size = 0;\n    return;\n  }\n\n  mpz_init (u);\n  mpz_init (t);\n  mpz_setbit (t, mpz_sizeinbase (y, 2) / z + 1);\n\n  if (z == 2) /* simplify sqrt loop: z-1 == 1 */\n    do {\n      mpz_swap (u, t);\t\t\t/* u = x */\n      mpz_tdiv_q (t, y, u);\t\t/* t = y/x */\n      mpz_add (t, t, u);\t\t/* t = y/x + x */\n      mpz_tdiv_q_2exp (t, t, 1);\t/* x'= (y/x + x)/2 */\n    } while (mpz_cmpabs (t, u) < 0);\t/* |x'| < |x| */\n  else /* z != 2 */ {\n    mpz_t v;\n\n    mpz_init (v);\n    if (sgn)\n      mpz_neg (t, t);\n\n    do {\n      mpz_swap (u, t);\t\t\t/* u = x */\n      mpz_pow_ui (t, u, z - 1);\t\t/* t = x^(z-1) */\n      mpz_tdiv_q (t, y, t);\t\t/* t = y/x^(z-1) */\n      mpz_mul_ui (v, u, z - 1);\t\t/* v = x*(z-1) */\n      mpz_add (t, t, v);\t\t/* t = y/x^(z-1) + x*(z-1) */\n      mpz_tdiv_q_ui (t, t, z);\t\t/* x'=(y/x^(z-1) + x*(z-1))/z */\n    } while (mpz_cmpabs (t, u) < 0);\t/* |x'| < |x| */\n\n    mpz_clear (v);\n  }\n\n  if (r) {\n    mpz_pow_ui (t, u, z);\n    mpz_sub (r, y, t);\n  }\n  if (x)\n    mpz_swap (x, u);\n  mpz_clear (u);\n  mpz_clear (t);\n}",
    "comment": "Computes the nth root and remainder of a multi-precision integer, handling special cases for negative and zero values.",
    "prorec_sum": "Computes the integer a4\u2011th root of a given big integer and optionally returns the remainder and root, rejecting invalid or negative inputs.",
    "filter_prorec_sum": "Computes the integer n\u2011th root of a large number and optionally returns the remainder, rejecting invalid negative or zero\u2011root inputs.",
    "prorec_aug_sum": "Computes the integer nth root of a large number and optionally returns the remainder, rejecting invalid zero or even\u2011root negative inputs.",
    "filter_prorec_aug_sum": "Computes the integer n\u2011th root of a large number, with optional remainder output, rejecting invalid root values or negative inputs for even roots.",
    "work_score": {
        "prorec_aug": {
            "summary": "Computes the integer nth root of a large number and optionally returns the remainder, rejecting invalid zero or even\u2011root negative inputs.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary contains two main claims: (1) the function computes the integer nth root of a large number and optionally returns the remainder, and (2) it rejects invalid inputs such as zero root or even roots of negative numbers. Both claims are accurate per the source code: the implementation computes the nth root using different loops for square root vs other roots, optionally calculates the remainder if 'r' is provided, and explicitly checks for z == 0 or negative arguments with even z. All extracted claims are correct and domain-relevant.",
                "The summary correctly identifies the core purpose of computing the integer nth root of a large number with an optional remainder and notes the rejection of zero root and even root of a negative number, which matches the function\u2019s primary domain effect and key error checks. However, it omits secondary but relevant details such as early return for |y| \u2264 1, separate handling for square root versus higher roots, use of iteration until convergence, and the final computation of remainder via subtraction. These omissions reduce completeness, though the core is well covered.",
                "The summary correctly describes the primary purpose as computing the integer nth root of a large number and optionally producing the remainder, matching the code's core logic. It also accurately notes rejection of zeroth root and negative inputs when the root is even. There are no inaccurate claims, and the points are specific to the code\u2019s semantics. While the description is concise, it captures the essential functionality with clear, low-noise accuracy, giving moderate to high net benefit."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Computes the integer n\u2011th root of a large number, with optional remainder output, rejecting invalid root values or negative inputs for even roots.",
            "score": [
                1.0,
                0.5,
                0.9
            ],
            "reason": [
                "The summary accurately captures the function's core purpose of computing the integer n\u2011th root of a large number, optionally producing a remainder, and correctly notes rejection of invalid root values (zeroth root) and negative inputs for even roots. All stated claims are directly supported by the source code semantics, with no contradictions or irrelevant information, resulting in high precision.",
                "The summary correctly identifies the core purpose as computing the integer n\u2011th root and optionally providing the remainder, and it also mentions rejection of invalid root values (z == 0) and of negative inputs for even roots, matching the error checks in the code. However, it omits secondary behavior-critical details such as handling of |y| <= 1 as a special case, the iterative method used for z == 2 versus other z, sign adjustments for odd roots, and precise management of output variables. Thus, while the core is covered with some error handling, the coverage of other semantics is limited.",
                "The summary correctly captures the primary purpose of the function \u2014 computing the integer n\u2011th root of a large number and optionally returning the remainder \u2014 and notes the rejection of invalid roots (zero) and negative inputs for even roots, which matches the source code checks. All claims are accurate, domain\u2011specific, and concise, with no evident noise or contradictions. While the summary is high\u2011level, it covers key I/O and constraints directly from the implementation."
            ]
        }
    }
}
{
    "source_code": "\nint\nmutil_parse_field_map (const char *map, mu_assoc_t *passoc_tab, int *perr)\n{\n  int rc;\n  int i;\n  struct mu_wordsplit ws;\n  mu_assoc_t assoc_tab = NULL;\n\n  ws.ws_delim = \":\";\n  if (mu_wordsplit (map, &ws, MU_WRDSF_DEFFLAGS|MU_WRDSF_DELIM))\n    {\n      mu_error (_(\"cannot split line `%s': %s\"), map,\n\t\tmu_wordsplit_strerror (&ws));\n      return errno;\n    }\n\n  for (i = 0; i < ws.ws_wordc; i++)\n    {\n      char *tok = ws.ws_wordv[i];\n      char *p = strchr (tok, '=');\n      char *pptr;\n      \n      if (!p)\n\t{\n\t  rc = EINVAL;\n\t  break;\n\t}\n      if (!assoc_tab)\n\t{\n\t  rc = mu_assoc_create (&assoc_tab, 0);\n\t  if (rc)\n\t    break;\n\t  mu_assoc_set_destroy_item (assoc_tab, mu_list_free_item);\n\t  *passoc_tab = assoc_tab;\n\t}\n      *p++ = 0;\n      pptr = strdup (p);\n      if (!pptr)\n\t{\n\t  rc = errno;\n\t  break;\n\t}\n      rc = mu_assoc_install (assoc_tab, tok, pptr);\n      if (rc)\n\t{\n\t  free (p);\n\t  break;\n\t}\n    }\n\n  mu_wordsplit_free (&ws);\n  if (rc && perr)\n    *perr = i;\n  return rc;\n}",
    "comment": "Parses a colon-delimited string into a key-value association table, handling errors for malformed entries and memory allocation failures.",
    "prorec_sum": "Parses a colon-separated string of key=value pairs into an associative map, handling errors and returning the index of any malformed entry.",
    "filter_prorec_sum": "Parses a colon-delimited string of key=value pairs into an associative map, reporting errors on malformed entries or memory allocation failure.",
    "prorec_aug_sum": "Parses a colon-separated line into key-value pairs, storing them in an association object and reporting errors on invalid or memory allocation failures.",
    "filter_prorec_aug_sum": "Parses a colon-separated field map string into a key-value association, handling errors and storing the map in the provided output pointer.",
    "work_score": {
        "prorec_aug": {
            "summary": "Parses a colon-separated line into key-value pairs, storing them in an association object and reporting errors on invalid or memory allocation failures.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly captures the function's primary purpose: splitting a colon-separated string into key-value pairs, storing them in an association object, and handling errors for invalid formats or allocation failures. These statements directly describe the code\u2019s behavior and match the implementation details, with no evident inaccuracies or unrelated claims. All extracted claims are accurate and verifiable against the source code.",
                "The summary accurately states that the function parses a colon-separated string into key-value pairs and stores them in an association object, which matches the core functionality of creating and populating a mu_assoc_t from parsed tokens. It also notes error reporting for invalid format and memory allocation failures, which aligns with the code's handling of missing '=' separators, allocation errors, and reporting the error index via perr. However, it omits some secondary details such as mu_wordsplit error handling specifics, freeing resources, and setting the destroy item callback. Coverage of secondary behaviors is decent but not complete.",
                "The summary accurately captures the core functionality: splitting a colon-separated string, processing each token into key-value pairs, inserting them into an association table, and handling errors such as invalid format or memory allocation failures. These are specific, verifiable, and match the source code's logic, with no inaccuracies or irrelevant noise present. While correct, the description is concise and lacks detail on some implementation specifics, so the gain is moderate rather than extensive."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Parses a colon-separated field map string into a key-value association, handling errors and storing the map in the provided output pointer.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function parses a colon-separated field map string and converts it into key-value pairs stored in an output pointer, which matches the code's use of `ws.ws_delim = \":\"` and `mu_assoc_install`. It also notes error handling, consistent with checks on `mu_wordsplit`, `strdup`, and `mu_assoc_create`. All claims are accurate and grounded in the source code behavior, with no contradictory or irrelevant statements.",
                "The summary accurately captures the core behavior of parsing a colon-separated string into key-value associations and placing the result in the provided output pointer, which matches the function's primary purpose. It also notes error handling, aligning with the code's error checks and return codes. However, it omits many specific secondary behaviors, such as the use of 'mu_wordsplit' with specific delimiters and flags, handling of malformed entries without '=', lazy creation of the association table, specific error reporting via 'perr', memory allocation/failure handling, and freeing resources.",
                "The summary makes an accurate claim that the function parses a colon-separated field map string into key-value associations and handles errors, which aligns with the source code's use of mu_wordsplit with ':' delimiter, splitting tokens on '=', and installing them in an assoc_tab. It also correctly states that the association is stored in the provided output pointer. There are no inaccurate or noisy claims; however, the description is generic and lacks specific details such as error handling mechanics, initialization steps, or memory allocation, leading to only modest informational gain."
            ]
        }
    }
}
{
    "source_code": "static int\nxmlRelaxNGRegisterTypeLibrary(const xmlChar * namespace, void *data,\n                              xmlRelaxNGTypeHave have,\n                              xmlRelaxNGTypeCheck check,\n                              xmlRelaxNGTypeCompare comp,\n                              xmlRelaxNGFacetCheck facet,\n                              xmlRelaxNGTypeFree freef)\n{\n    xmlRelaxNGTypeLibraryPtr lib;\n    int ret;\n\n    if ((xmlRelaxNGRegisteredTypes == NULL) || (namespace == NULL) ||\n        (check == NULL) || (comp == NULL))\n        return (-1);\n    if (xmlHashLookup(xmlRelaxNGRegisteredTypes, namespace) != NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"Relax-NG types library '%s' already registered\\n\",\n                        namespace);\n        return (-1);\n    }\n    lib =\n        (xmlRelaxNGTypeLibraryPtr)\n        xmlMalloc(sizeof(xmlRelaxNGTypeLibrary));\n    if (lib == NULL) {\n        xmlRngVErrMemory(NULL, \"adding types library\\n\");\n        return (-1);\n    }\n    memset(lib, 0, sizeof(xmlRelaxNGTypeLibrary));\n    lib->namespace = xmlStrdup(namespace);\n    lib->data = data;\n    lib->have = have;\n    lib->comp = comp;\n    lib->check = check;\n    lib->facet = facet;\n    lib->freef = freef;\n    ret = xmlHashAddEntry(xmlRelaxNGRegisteredTypes, namespace, lib);\n    if (ret < 0) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"Relax-NG types library failed to register '%s'\\n\",\n                        namespace);\n        xmlRelaxNGFreeTypeLibrary(lib, namespace);\n        return (-1);\n    }\n    return (0);\n}",
    "comment": "Registers a new Relax-NG types library with a given namespace and associated functions in the xmlRelaxNGRegisteredTypes hash table.",
    "prorec_sum": "Registers a new Relax-NG types library in a global XML hash table, allocating and storing its associated callbacks, with error reporting on duplicates or failures.",
    "filter_prorec_sum": "Registers a new Relax-NG types library in a global hash, allocating and storing its callbacks, and reports errors if it already exists or registration fails.",
    "prorec_aug_sum": "Registers a new Relax-NG types library in an XML hash table, allocating and storing its metadata, and reports errors if already registered or on failure.",
    "filter_prorec_aug_sum": "Registers a new Relax-NG types library in a global XML hash, reporting errors if the library is already registered or registration fails.",
    "work_score": {
        "prorec_aug": {
            "summary": "Registers a new Relax-NG types library in an XML hash table, allocating and storing its metadata, and reports errors if already registered or on failure.",
            "score": [
                1.0,
                0.8,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function registers a new Relax-NG types library, uses an XML hash table to store it, allocates and stores its metadata, and reports errors in cases where the library is already registered or the registration fails. All claims in the summary match the behavior seen in the source code, with no contradictory or irrelevant details, making the description precise and aligned with function semantics.",
                "The summary correctly captures the core purpose of registering a new Relax-NG types library in an XML hash table and includes key metadata allocation and storage actions along with error reporting for duplicates and failures. This matches the source code's primary purpose and covers secondary semantics such as precondition checks and duplicate detection, though it omits specifics like null pointer checks and memory error handling details, leaving some branches uncovered.",
                "The summary accurately captures the core purpose of registering a new Relax-NG types library in the XML hash table, including allocation of metadata and error reporting when already registered or on failure. It omits details about specific null pointer argument checks and the freeing of allocated structures on registration failure, but these are minor omissions. There are no inaccurate or misleading claims, and noise is minimal, with the content focusing on the function's primary behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Registers a new Relax-NG types library in a global XML hash, reporting errors if the library is already registered or registration fails.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary captures the core function behavior: adding a new Relax-NG types library to a global XML hash and handling two key error cases\u2014already registered and failed registration\u2014which directly match the code's checks and error reporting. It omits some lower-level details such as null parameter checks, memory allocation, and assignment of structure fields, but these omissions do not introduce inaccuracies. All stated claims align with the source code, making the description highly accurate overall.",
                "The summary correctly states the core operation of registering a Relax-NG types library in a global XML hash and includes two key error conditions: already registered and registration failure, which matches the source code behavior. However, it omits several secondary details such as the required non-NULL parameters, memory allocation and initialization steps, specific function pointer assignments, and additional error handling for memory allocation failure. These omissions limit coverage of other critical semantics beyond the core purpose.",
                "The summary correctly captures the primary purpose of the function \u2014 registering a new Relax-NG types library in a global XML hash \u2014 and accurately notes error reporting if the library is already registered or registration fails. There are no incorrect claims; the statements are specific to the code\u2019s semantics and align with observed behavior. However, the summary is concise and omits detailed parameter requirements and internal allocation steps, providing moderate but not comprehensive insight."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nevhttp_read_header(struct evhttp_connection *evcon,\n\t\t   struct evhttp_request *req)\n{\n\tenum message_read_status res;\n\tevutil_socket_t fd = evcon->fd;\n\n\tres = evhttp_parse_headers_(req, bufferevent_get_input(evcon->bufev));\n\tif (res == DATA_CORRUPTED || res == DATA_TOO_LONG) {\n\t\t/* Error while reading, terminate */\n\t\tevent_debug((\"%s: bad header lines on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, EV_SOCK_ARG(fd)));\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\treturn;\n\t} else if (res == MORE_DATA_EXPECTED) {\n\t\t/* Need more header lines */\n\t\treturn;\n\t}\n\n\t/* Callback can shut down connection with negative return value */\n\tif (req->header_cb != NULL) {\n\t\tif ((*req->header_cb)(req, req->cb_arg) < 0) {\n\t\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_EOF);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Done reading headers, do the real work */\n\tswitch (req->kind) {\n\tcase EVHTTP_REQUEST:\n\t\tevent_debug((\"%s: checking for post data on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, EV_SOCK_ARG(fd)));\n\t\tevhttp_get_body(evcon, req);\n\t\t/* note the request may have been freed in evhttp_get_body */\n\t\tbreak;\n\n\tcase EVHTTP_RESPONSE:\n\t\t/* Start over if we got a 100 Continue response. */\n\t\tif (req->response_code == 100) {\n\t\t\tstruct evbuffer *output = bufferevent_get_output(evcon->bufev);\n\t\t\tevbuffer_add_buffer(output, req->output_buffer);\n\t\t\tevhttp_start_write_(evcon);\n\t\t\treturn;\n\t\t}\n\t\tif (!evhttp_response_needs_body(req)) {\n\t\t\tevent_debug((\"%s: skipping body for code %d\\n\",\n\t\t\t\t\t__func__, req->response_code));\n\t\t\tevhttp_connection_done(evcon);\n\t\t} else {\n\t\t\tevent_debug((\"%s: start of read body for %s on \"\n\t\t\t\tEV_SOCK_FMT\"\\n\",\n\t\t\t\t__func__, req->remote_host, EV_SOCK_ARG(fd)));\n\t\t\tevhttp_get_body(evcon, req);\n\t\t\t/* note the request may have been freed in\n\t\t\t * evhttp_get_body */\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tevent_warnx(\"%s: bad header on \"EV_SOCK_FMT, __func__,\n\t\t    EV_SOCK_ARG(fd));\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\tbreak;\n\t}\n\t/* request may have been freed above */\n}",
    "comment": "Processes incoming HTTP headers, validates them, invokes a callback if present, and handles the request or response body based on the type and status.",
    "prorec_sum": "Parses HTTP headers from a bufferevent, handles status-specific logic, and manages connection failure or response writing based on parsing results.",
    "filter_prorec_sum": "Parses HTTP headers from a bufferevent, handles status-specific responses, and triggers appropriate connection failure or subsequent write operations.",
    "prorec_aug_sum": "Processes HTTP headers from a bufferevent, handles specific status codes, and manages connection failure or transition to response writing as appropriate.",
    "filter_prorec_aug_sum": "Processes HTTP headers from a buffered event, handles connection failures, and manages response writing based on status codes with optional debug logging.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes HTTP headers from a bufferevent, handles specific status codes, and manages connection failure or transition to response writing as appropriate.",
            "score": [
                0.8,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly notes that the function processes HTTP headers from a bufferevent and that it handles status codes and connection failure or response writing, which aligns with the code's flow for different `res` values and `req->kind` cases. However, it omits key specifics such as handling corrupted/too-long headers, invoking a header callback, managing 100 Continue responses, and body skipping logic, resulting in a partial but generally correct depiction. Most claims are accurate but lack detail.",
                "The summary correctly states that the function processes HTTP headers from a bufferevent and handles certain status codes, aligning with the code\u2019s header parsing and flow control logic. However, it does not explicitly capture the core primary purpose with domain-specific detail \u2014 namely, parsing HTTP request/response headers, checking conditions for corrupted or incomplete data, invoking optional callbacks, and branching into reading the body, skipping it, or resending buffers for '100 Continue' responses. It omits key secondary behaviors such as handling EVHTTP_REQUEST vs. EVHTTP_RESPONSE cases, triggering evhttp_get_body, and edge-case handling based on response_code.",
                "The summary accurately captures the core behavior: reading HTTP headers from a bufferevent, handling conditions based on parse status, managing connection failure, and transitioning appropriately to body reading or response writing. No contradictory (FATAL) claims are present, and noise is minimal. While the description is correct, it is somewhat high-level and omits specifics like handling '100 Continue' or different request kinds, which limits the depth of insight."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes HTTP headers from a buffered event, handles connection failures, and manages response writing based on status codes with optional debug logging.",
            "score": [
                0.8,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function processes HTTP headers from a buffered event and handles connection failures, which matches the code's use of evhttp_parse_headers_ and evhttp_connection_fail_. It also notes response writing based on status codes, consistent with the handling of 100 Continue and skipping bodies for certain status codes, and observes optional debug logging, which is present. However, it omits significant behaviors such as handling MORE_DATA_EXPECTED, invoking header callbacks, distinguishing request vs. response paths, and body processing logic. While accurate for what it covers, the summary is incomplete, so accuracy is above 80% but not exhaustive.",
                "The summary correctly notes handling of HTTP headers from a buffered event, managing connection failures, and writing responses based on status codes, all of which match the code. However, it only covers the core purpose in a generic way without detailing critical specifics such as parsing outcome branches (DATA_CORRUPTED, MORE_DATA_EXPECTED), invocation of optional header callbacks, handling EVHTTP_REQUEST vs EVHTTP_RESPONSE, 100 Continue special case, skipping bodies when unnecessary, or differentiating request kinds. Secondary behavior and edge cases are mostly absent.",
                "The summary captures some correct, high-level aspects such as processing HTTP headers, handling connection failures, and managing responses based on status codes with debug logging, which are accurate but broad SAFE claims. However, it omits key specifics like handling different message read statuses, invoking a header callback that can terminate the connection, the special case for 100 Continue, and the distinction between request and response kinds. There are no FATAL inaccuracies targeting the primary purpose, but the lack of detail means high-noise, low-gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nset_level_indent(const char *str)\n{\n     long n;\n     const char *p;\n     char *q;\n     \n     n = strtol(str, &q, 0);\n     if (*q == 0 && n > 0) {\n\t  char *s = xmalloc(n+1);\n\t  memset(s, ' ', n-1);\n\t  s[n-1] = 0;\n\t  level_indent[0] = level_indent[1] = s;\n\t  return;\n     }\n     \n     p = str;\n     while (*p != '=') {\n\t  if (*p == 0)\n\t       error(EX_USAGE, 0, _(\"level-indent syntax\"));\n\t  p++;\n     }\n     ++p;\n    \n     switch (find_option_type(level_indent_optype, str, p - str - 1)) {\n     case LEVEL_BEGIN:\n\t  parse_level_string(p, &level_begin);\n\t  break;\n     case LEVEL_INDENT0:\n\t  parse_level_string(p, &level_indent[0]);\n\t  break;\n     case LEVEL_INDENT1:\n\t  parse_level_string(p, &level_indent[1]);\n\t  break;\n     case LEVEL_END0:\n\t  parse_level_string(p, &level_end[0]);\n\t  break;\n     case LEVEL_END1:\n\t  parse_level_string(p, &level_end[1]);\n\t  break;\n     default:\n\t  error(EX_USAGE, 0, _(\"unknown level indent option: %s\"), str);\n     }\n}",
    "comment": "Sets the level indentation based on a string input, allocating space for indentation or parsing specific level configuration options.",
    "prorec_sum": "Parses a level-indent option string or numeric value and configures corresponding indentation settings, reporting errors for invalid or unknown options.",
    "filter_prorec_sum": "Parses a level-indent specification string, validating syntax, and updates global indent style or whitespace padding based on numeric or named options.",
    "prorec_aug_sum": "Parses a level indent specification from a string, validates its format, and updates corresponding global indentation style or spacing settings.",
    "filter_prorec_aug_sum": "Parses a level-indent option or numeric value and sets corresponding global indentation strings, reporting errors for invalid syntax or unknown options.",
    "work_score": {
        "prorec_aug": {
            "summary": "Parses a level indent specification from a string, validates its format, and updates corresponding global indentation style or spacing settings.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly conveys the high-level behavior: parsing a level indent specification from a string, validating it, and updating global indentation settings. These actions align with the code\u2019s logic, which uses strtol for numeric spacing, checks syntax, handles errors, and updates global arrays for indentation or level markers. The description is generic but accurate; no contradictions or irrelevant information are present.",
                "The summary correctly states that the function parses a level indent specification from a string, validates its format, and updates global indentation settings, which aligns with the core purpose of interpreting and applying indentation configuration from input. It covers the main domain action and mentions validation and updating of global settings, matching code behavior. However, it lacks detail on key secondary semantics such as handling numeric lengths via strtol and memory allocation, parsing different option types via find_option_type, branching for specific level indentation arrays, and error handling for unrecognized formats. These omissions reduce completeness.",
                "The summary accurately captures the core function: parsing a level indent specification from a string, checking validity, and updating global indentation/spacing-related settings. It omits some specifics such as handling numeric input to allocate spaces or parsing named options via a switch, but these omissions are not contradictory. There is no incorrect claim (no FATAL), and noise is minimal, though the description is somewhat generic without detailing the branching logic or exact updates, leading to modest gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Parses a level-indent option or numeric value and sets corresponding global indentation strings, reporting errors for invalid syntax or unknown options.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary states that the function parses either a numeric value or a level-indent option and sets the corresponding global indentation strings, and it reports errors for invalid syntax or unknown options. These details are all directly supported by the source code: the numeric parsing via strtol and allocation of spaces, the option parsing via find_option_type and parse_level_string calls for specific globals, and error calls for syntax and unknown options. All claims accurately reflect the code's semantics with no contradictions or irrelevant content.",
                "The summary correctly identifies that the function handles both numeric and option-based level-indent inputs, sets global indentation strings, and reports errors for invalid syntax or unknown options. This matches the core purpose of parsing a level-indent specification and updating indentation settings. It also includes secondary details about error reporting. However, it omits more granular coverage such as allocation and initialization of spaces for numeric input, handling of multiple specific option types, and branching for different LEVEL_* cases. Thus, while the core is covered with reasonable specificity, secondary detail coverage is moderate rather than exhaustive.",
                "The summary correctly states that the function parses either a numeric value or a level-indent option and updates corresponding global indentation strings, while reporting errors for syntax issues or unknown options. These claims are accurate to the source code\u2019s primary purpose and key side effects, with no contradictory statements or irrelevant noise. The description is concise but provides clear insight into the core behavior, making it highly aligned with the evaluation steps."
            ]
        }
    }
}
{
    "source_code": "\n\nvoid *\nngx_http_map_find(ngx_http_request_t *r, ngx_http_map_t *map, ngx_str_t *match)\n{\n    void        *value;\n    u_char      *low;\n    size_t       len;\n    ngx_uint_t   key;\n\n    len = match->len;\n\n    if (len) {\n        low = ngx_pnalloc(r->pool, len);\n        if (low == NULL) {\n            return NULL;\n        }\n\n    } else {\n        low = NULL;\n    }\n\n    key = ngx_hash_strlow(low, match->data, len);\n\n    value = ngx_hash_find_combined(&map->hash, key, low, len);\n    if (value) {\n        return value;\n    }\n\n#if (NGX_PCRE)\n\n    if (len && map->nregex) {\n        ngx_int_t              n;\n        ngx_uint_t             i;\n        ngx_http_map_regex_t  *reg;\n\n        reg = map->regex;\n\n        for (i = 0; i < map->nregex; i++) {\n\n            n = ngx_http_regex_exec(r, reg[i].regex, match);\n\n            if (n == NGX_OK) {\n                return reg[i].value;\n            }\n\n            if (n == NGX_DECLINED) {\n                continue;\n            }\n\n            /* NGX_ERROR */\n\n            return NULL;\n        }\n    }\n\n#endif\n\n    return NULL;\n}",
    "comment": "Finds a corresponding value in a hash map or regex patterns for a given string in an HTTP request.",
    "prorec_sum": "Finds a matching value in an HTTP map using lowercase hashing, and falls back to evaluating configured regular expressions if no hash match is found.",
    "filter_prorec_sum": "Finds a lowercase-hashed map entry by string key, falling back to regex pattern matching when no direct hash match is found.",
    "prorec_aug_sum": "Looks up an HTTP map entry by lowercase-hashed key, falling back to matching configured regular expressions when no direct hash match is found.",
    "filter_prorec_aug_sum": "Finds a value in a combined hash by lowercase key, falling back to regex matching if no direct hash entry is found.",
    "work_score": {
        "prorec_aug": {
            "summary": "Looks up an HTTP map entry by lowercase-hashed key, falling back to matching configured regular expressions when no direct hash match is found.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function looks up an HTTP map entry using a lowercase-hashed key and falls back to configured regex matches when no direct hash match is found. These behaviors are explicitly reflected in the source code: the function uses `ngx_hash_strlow` to compute the lowercase-hashed key, searches with `ngx_hash_find_combined`, and if not found, iterates through regex entries when `map->nregex` is nonzero. No inaccuracies or unrelated claims are present, indicating a high proportion of accurate, domain-specific statements.",
                "The summary accurately states that the function looks up an HTTP map entry by a lowercase-hashed key and falls back to matching configured regular expressions when no hash match is found, which is the core purpose of the code. However, it omits secondary but relevant details such as allocation of lowercase buffer only when length > 0, returning NULL on allocation failure or regex execution error, handling of empty input, and the requirement of PCRE support for regex matching. These omissions reduce completeness of coverage.",
                "The summary accurately captures the primary purpose: performing a lowercase hash lookup in the HTTP map and falling back to regex matching if no hash match is found. This aligns with the source code's sequence of computing a lowercase version of the match string, using ngx_hash_find_combined, and then iterating over regex patterns when needed. There are no inaccuracies or extraneous noise; the claim is concise, specific, and directly supported by the code, offering good insight into the function's behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Finds a value in a combined hash by lowercase key, falling back to regex matching if no direct hash entry is found.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function looks up a value in a combined hash using a lowercase key and falls back to regex matching if no direct entry is found. This matches the code\u2019s logic: `ngx_hash_strlow` is used for lowercase key generation, `ngx_hash_find_combined` performs the hash search, and regex matching is attempted if the hash lookup fails and regex patterns exist. No significant inaccuracies were found, and the summary is both specific and aligned with the function\u2019s behavior.",
                "The summary accurately describes the core purpose of looking up a value in a combined hash using a lowercased key and falling back to regex matching when no hash entry is found, aligning with the function\u2019s main domain operation. It omits secondary details such as allocation from the request pool, returning NULL on memory allocation failure or regex errors, handling of the NGX_DECLINED case, and the condition that regex fallback happens only if regex entries exist. This makes the core coverage strong but secondary coverage limited.",
                "The summary accurately states the primary function behavior: it performs a lowercase-based key lookup in a combined hash and, if not found, attempts regex matching. This matches the source code's sequence of lowering the key, calling ngx_hash_find_combined, and falling back to regex via ngx_http_regex_exec. There are no inaccurate statements or irrelevant noise; however, the description is concise and offers only moderate detail beyond the core logic, so the gain is solid but not extensive."
            ]
        }
    }
}
{
    "source_code": "\n\nngx_int_t\nngx_http_request_body_save_filter(ngx_http_request_t *r, ngx_chain_t *in)\n{\n    ngx_buf_t                 *b;\n    ngx_chain_t               *cl;\n    ngx_http_request_body_t   *rb;\n\n    rb = r->request_body;\n\n#if (NGX_DEBUG)\n\n#if 0\n    for (cl = rb->bufs; cl; cl = cl->next) {\n        ngx_log_debug7(NGX_LOG_DEBUG_EVENT, r->connection->log, 0,\n                       \"http body old buf t:%d f:%d %p, pos %p, size: %z \"\n                       \"file: %O, size: %O\",\n                       cl->buf->temporary, cl->buf->in_file,\n                       cl->buf->start, cl->buf->pos,\n                       cl->buf->last - cl->buf->pos,\n                       cl->buf->file_pos,\n                       cl->buf->file_last - cl->buf->file_pos);\n    }\n#endif\n\n    for (cl = in; cl; cl = cl->next) {\n        ngx_log_debug7(NGX_LOG_DEBUG_EVENT, r->connection->log, 0,\n                       \"http body new buf t:%d f:%d %p, pos %p, size: %z \"\n                       \"file: %O, size: %O\",\n                       cl->buf->temporary, cl->buf->in_file,\n                       cl->buf->start, cl->buf->pos,\n                       cl->buf->last - cl->buf->pos,\n                       cl->buf->file_pos,\n                       cl->buf->file_last - cl->buf->file_pos);\n    }\n\n#endif\n\n    /* TODO: coalesce neighbouring buffers */\n\n    if (ngx_chain_add_copy(r->pool, &rb->bufs, in) != NGX_OK) {\n        return NGX_HTTP_INTERNAL_SERVER_ERROR;\n    }\n\n    if (r->request_body_no_buffering) {\n        return NGX_OK;\n    }\n\n    if (rb->rest > 0) {\n\n        if (rb->buf && rb->buf->last == rb->buf->end\n            && ngx_http_write_request_body(r) != NGX_OK)\n        {\n            return NGX_HTTP_INTERNAL_SERVER_ERROR;\n        }\n\n        return NGX_OK;\n    }\n\n    /* rb->rest == 0 */\n\n    if (rb->temp_file || r->request_body_in_file_only) {\n\n        if (ngx_http_write_request_body(r) != NGX_OK) {\n            return NGX_HTTP_INTERNAL_SERVER_ERROR;\n        }\n\n        if (rb->temp_file->file.offset != 0) {\n\n            cl = ngx_chain_get_free_buf(r->pool, &rb->free);\n            if (cl == NULL) {\n                return NGX_HTTP_INTERNAL_SERVER_ERROR;\n            }\n\n            b = cl->buf;\n\n            ngx_memzero(b, sizeof(ngx_buf_t));\n\n            b->in_file = 1;\n            b->file_last = rb->temp_file->file.offset;\n            b->file = &rb->temp_file->file;\n\n            rb->bufs = cl;\n        }\n    }\n\n    return NGX_OK;\n}",
    "comment": "Saves the request body data by copying buffers and managing temporary files for further processing in an NGINX HTTP request.",
    "prorec_sum": "Appends incoming request body buffers to storage and finalizes processing, allocating a new buffer if needed, otherwise returning an error status.",
    "filter_prorec_sum": "Saves incoming HTTP request body data into a buffer chain, flushing or allocating buffers as needed and returning errors on failure.",
    "prorec_aug_sum": "Appends incoming request body data to the buffer chain and manages buffer reuse, returning HTTP 500 on copy or processing failures.",
    "filter_prorec_aug_sum": "Buffers and chains incoming HTTP request body data, invoking further processing when thresholds are met and allocating a free buffer for remaining content.",
    "work_score": {
        "prorec_aug": {
            "summary": "Appends incoming request body data to the buffer chain and manages buffer reuse, returning HTTP 500 on copy or processing failures.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function appends incoming request body data to the existing buffer chain and that it returns HTTP 500 on failures during copying or processing, both of which are supported by the code. However, it inaccurately states 'manages buffer reuse' as a general behavior; while the code may obtain a free buffer in a specific scenario, buffer reuse is not an overarching function behavior. Overall, the majority of claims are accurate, with only a minor overgeneralization.",
                "The summary correctly describes appending incoming request body data to the existing buffer chain and mentions returning HTTP 500 on copy or processing failures, which aligns with core semantics of adding copies via ngx_chain_add_copy and error handling. However, it omits important conditional flows such as handling the no-buffering flag, writing request bodies when rb->rest > 0 or when stored in a temp file, and reinitializing buffers for file-only cases. These missing branches and side effects reduce coverage of secondary key points.",
                "The summary correctly states that the function appends incoming request body data to the buffer chain and returns HTTP 500 on copy or processing failures, which aligns with the code's use of ngx_chain_add_copy and various NGX_HTTP_INTERNAL_SERVER_ERROR returns. However, it inaccurately claims that the function manages buffer reuse; while the code manipulates buffers and may allocate a new one when writing to a temp file, explicit reuse management is not a primary or evident behavior. Despite this slight overstatement, there are no severe inaccuracies about the core purpose or key I/O, and most of the summary is accurate but broad, providing only limited additional insight."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Buffers and chains incoming HTTP request body data, invoking further processing when thresholds are met and allocating a free buffer for remaining content.",
            "score": [
                0.6,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly notes that the function handles incoming HTTP request body data and manages buffers/chains, which aligns with the code\u2019s use of `ngx_chain_add_copy` and buffer allocation from `ngx_chain_get_free_buf`. However, the mention of 'invoking further processing when thresholds are met' is vague and does not clearly reflect the specific conditions in the code, such as checks for `rb->rest`, `request_body_no_buffering`, or file-related operations. The description leaves out important domain-specific behaviors like writing to temporary files, handling `request_body_in_file_only`, and returning error codes, leading to only partial accuracy.",
                "The summary partially captures the core purpose by noting buffering/chaining of incoming HTTP request body data, which aligns with adding incoming chain buffers to the request body buffers. However, it is vague about the specific core behavior, which involves saving incoming buffers to rb->bufs and conditionally writing to a temporary file. It omits multiple critical secondary details from the code, such as handling the no-buffering flag, rest > 0 logic, invocation of ngx_http_write_request_body(), error handling, and temp file buffer allocation when certain flags are set. The phrasing around 'thresholds are met' is imprecise and does not directly map to the 'rest' and buffering conditions in the source.",
                "The summary contains mostly accurate but somewhat generic claims. It correctly states that the function deals with buffering and chaining incoming HTTP request body data and triggers further processing when certain conditions are met (e.g., buffer full, rest == 0). It also mentions allocating a free buffer for remaining content, which aligns with the temp_file handling. However, the description omits other important details like request_body_no_buffering handling, temporary file writes, and error return paths. There are no outright contradictions (no FATAL), but the gain is modest due to the generic wording and lack of full specificity, leading to low net benefit."
            ]
        }
    }
}
{
    "source_code": "\nint __init APIC_init_uniprocessor(void)\n{\n\tif (disable_apic) {\n\t\tpr_info(\"Apic disabled\\n\");\n\t\treturn -1;\n\t}\n#ifdef CONFIG_X86_64\n\tif (!cpu_has_apic) {\n\t\tdisable_apic = 1;\n\t\tpr_info(\"Apic disabled by BIOS\\n\");\n\t\treturn -1;\n\t}\n#else\n\tif (!smp_found_config && !cpu_has_apic)\n\t\treturn -1;\n\n\t/*\n\t * Complain if the BIOS pretends there is one.\n\t */\n\tif (!cpu_has_apic &&\n\t    APIC_INTEGRATED(apic_version[boot_cpu_physical_apicid])) {\n\t\tpr_err(\"BIOS bug, local APIC 0x%x not detected!...\\n\",\n\t\t\tboot_cpu_physical_apicid);\n\t\treturn -1;\n\t}\n#endif\n\n\tdefault_setup_apic_routing();\n\n\tverify_local_APIC();\n\tconnect_bsp_APIC();\n\n#ifdef CONFIG_X86_64\n\tapic_write(APIC_ID, SET_APIC_ID(boot_cpu_physical_apicid));\n#else\n\t/*\n\t * Hack: In case of kdump, after a crash, kernel might be booting\n\t * on a cpu with non-zero lapic id. But boot_cpu_physical_apicid\n\t * might be zero if read from MP tables. Get it from LAPIC.\n\t */\n# ifdef CONFIG_CRASH_DUMP\n\tboot_cpu_physical_apicid = read_apic_id();\n# endif\n#endif\n\tphysid_set_mask_of_physid(boot_cpu_physical_apicid, &phys_cpu_present_map);\n\tsetup_local_APIC();\n\n#ifdef CONFIG_X86_IO_APIC\n\t/*\n\t * Now enable IO-APICs, actually call clear_IO_APIC\n\t * We need clear_IO_APIC before enabling error vector\n\t */\n\tif (!skip_ioapic_setup && nr_ioapics)\n\t\tenable_IO_APIC();\n#endif\n\n\tbsp_end_local_APIC_setup();\n\n#ifdef CONFIG_X86_IO_APIC\n\tif (smp_found_config && !skip_ioapic_setup && nr_ioapics)\n\t\tsetup_IO_APIC();\n\telse {\n\t\tnr_ioapics = 0;\n\t}\n#endif\n\n\tx86_init.timers.setup_percpu_clockev();\n\treturn 0;\n}",
    "comment": "Initializes the local APIC for uniprocessor systems, verifying configuration and enabling IO-APICs as necessary for proper operation.",
    "prorec_sum": "Initializes ACPI-related hardware state, clears and updates a 1024-entry table, and invokes multiple platform callbacks based on specific configuration flags.",
    "filter_prorec_sum": "Handles ACPI initialization by processing system tables, updating related data structures, and invoking hardware-specific setup routines based on configuration flags.",
    "prorec_aug_sum": "Initializes CPU-related data structures, configures interrupt handling, and updates global state based on hardware flags and initialization conditions.",
    "filter_prorec_aug_sum": "Initializes interrupt-related data structures, sets bit flags, and triggers hardware setup routines based on system state and configuration flags.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes CPU-related data structures, configures interrupt handling, and updates global state based on hardware flags and initialization conditions.",
            "score": [
                0.5,
                0.4,
                0.5
            ],
            "reason": [
                "The summary makes broad, generic claims about CPU initialization, interrupt setup, and global state updates, which loosely align with the overall function's purpose. However, it omits many specific conditional checks and hardware-related operations from the source code, such as APIC disable handling, BIOS bug detection, and IO-APIC setup. While the few claims present are broadly accurate, they lack precise, verifiable detail tied to the actual semantics, resulting in low informational value and limited coverage.",
                "The summary makes generic statements about CPU initialization and interrupt handling but does not specifically capture the function\u2019s core purpose of initializing the uniprocessor APIC, including detailed hardware checks, BIOS conditions, and stepwise APIC/IO-APIC setup. While the claims are broadly accurate, they omit key domain-specific details and conditions that distinguish this code from generic initialization routines, resulting in incomplete coverage of critical behaviors.",
                "The summary contains only broad, generic claims about CPU initialization, interrupt handling, and global state updates without specifying the detailed hardware checks, APIC setup sequences, or conditional branches present in the source code. All statements are accurate in a general sense (SAFE) but provide low informational value and lack specificity. No incorrect or contradictory claims are present, so there is no FATAL error, but the gain is minimal due to high-level vagueness."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes interrupt-related data structures, sets bit flags, and triggers hardware setup routines based on system state and configuration flags.",
            "score": [
                0.3,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is overly generic and misses specific behaviors in the source code such as early returns when APIC is disabled, BIOS checks, APIC ID setup, and IO-APIC initialization. While it loosely matches the idea of hardware setup based on configuration, it inaccurately mentions 'sets bit flags' which is not clearly present, and omits many detailed actions. Less than half of the claims are accurate, making the precision low.",
                "The summary provides only a generic description of initialization tasks and hardware setup, without specifically identifying the function\u2019s core purpose: initializing the local APIC for a uniprocessor system with conditional handling for disabled states, BIOS configuration, IO-APIC setup, and error scenarios. While broadly accurate in tone, it fails to capture any domain-specific detail about APIC routing, verification, or configuration branches, nor does it mention key secondary behaviors like error logging, IO-APIC enabling, or crash dump handling. This leaves the core uncovered and secondary coverage minimal.",
                "The summary provides only a vague, generic description of initialization without specifying the primary purpose (uniprocessor APIC setup) or key conditional behaviors present in the code. The claims about initializing interrupt-related data structures and hardware setup are broadly SAFE but low-info, omitting detailed steps such as APIC disabling checks, IO-APIC enabling/setup, and LAPIC ID handling. There are no FATAL inaccuracies, but the lack of specificity means the gain is minimal and noise from generic phrasing is noticeable."
            ]
        }
    }
}
{
    "source_code": "\nstatic int asn1_template_ex_d2i(ASN1_VALUE **val,\n\t\t\t\tconst unsigned char **in, long inlen,\n\t\t\t\tconst ASN1_TEMPLATE *tt, char opt,\n\t\t\t\t\t\t\tASN1_TLC *ctx)\n\t{\n\tint flags, aclass;\n\tint ret;\n\tlong len;\n\tconst unsigned char *p, *q;\n\tchar exp_eoc;\n\tif (!val)\n\t\treturn 0;\n\tflags = tt->flags;\n\taclass = flags & ASN1_TFLG_TAG_CLASS;\n\n\tp = *in;\n\n\t/* Check if EXPLICIT tag expected */\n\tif (flags & ASN1_TFLG_EXPTAG)\n\t\t{\n\t\tchar cst;\n\t\t/* Need to work out amount of data available to the inner\n\t\t * content and where it starts: so read in EXPLICIT header to\n\t\t * get the info.\n\t\t */\n\t\tret = asn1_check_tlen(&len, NULL, NULL, &exp_eoc, &cst,\n\t\t\t\t\t&p, inlen, tt->tag, aclass, opt, ctx);\n\t\tq = p;\n\t\tif (!ret)\n\t\t\t{\n\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tERR_R_NESTED_ASN1_ERROR);\n\t\t\treturn 0;\n\t\t\t}\n\t\telse if (ret == -1)\n\t\t\treturn -1;\n\t\tif (!cst)\n\t\t\t{\n\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tASN1_R_EXPLICIT_TAG_NOT_CONSTRUCTED);\n\t\t\treturn 0;\n\t\t\t}\n\t\t/* We've found the field so it can't be OPTIONAL now */\n\t\tret = asn1_template_noexp_d2i(val, &p, len, tt, 0, ctx);\n\t\tif (!ret)\n\t\t\t{\n\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tERR_R_NESTED_ASN1_ERROR);\n\t\t\treturn 0;\n\t\t\t}\n\t\t/* We read the field in OK so update length */\n\t\tlen -= p - q;\n\t\tif (exp_eoc)\n\t\t\t{\n\t\t\t/* If NDEF we must have an EOC here */\n\t\t\tif (!asn1_check_eoc(&p, len))\n\t\t\t\t{\n\t\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\t\tASN1_R_MISSING_EOC);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\telse\n\t\t\t{\n\t\t\t/* Otherwise we must hit the EXPLICIT tag end or its\n\t\t\t * an error */\n\t\t\tif (len)\n\t\t\t\t{\n\t\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tASN1_R_EXPLICIT_LENGTH_MISMATCH);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse \n\t\t\treturn asn1_template_noexp_d2i(val, in, inlen,\n\t\t\t\t\t\t\t\ttt, opt, ctx);\n\n\t*in = p;\n\treturn 1;\n\n\terr:\n\tASN1_template_free(val, tt);\n\treturn 0;\n\t}",
    "comment": "Parses an ASN.1 encoded structure, handling explicit tags and validating length, while managing errors and memory for the decoded value.",
    "prorec_sum": "Parses ASN.1 encoded data with optional tag handling, validates structure, updates buffer position, and reports errors using OpenSSL\u2019s ASN.1 routines.",
    "filter_prorec_sum": "Decodes ASN.1 data with optional indefinite-length handling, validates content, updates the input pointer, and reports detailed errors on format violations.",
    "prorec_aug_sum": "Decodes an ASN.1 template with optional indefinite-length support, validates structure integrity, advances input pointer, and reports detailed errors on failure.",
    "filter_prorec_aug_sum": "Decodes ASN.1 template data with indefinite length handling, validates structure, updates parsing position, and reports detailed errors on failure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Decodes an ASN.1 template with optional indefinite-length support, validates structure integrity, advances input pointer, and reports detailed errors on failure.",
            "score": [
                0.9,
                0.5,
                0.9
            ],
            "reason": [
                "The summary correctly notes that the function decodes an ASN.1 template, checks for structure integrity, advances the input pointer, and reports detailed errors, all of which are evident in the code via the EXPLICIT tag handling, length checks, error calls, and pointer updates. However, the mention of 'optional indefinite-length support' is misleading \u2014 while the code handles indefinite length via exp_eoc and EOC checks, the term 'optional' here might incorrectly imply a configurable feature, which isn't explicitly present. Overall, most claims are accurate with a minor overgeneralization.",
                "The summary correctly notes that the function decodes an ASN.1 template, advances the input pointer, and reports errors, which aligns with the code's behavior. However, it omits the core specificity that the function handles explicit tagging versus non-explicit cases, including checks for constructed type, length mismatches, and end-of-content markers. The mention of optional indefinite-length support is not clearly grounded in the source logic, making it somewhat imprecise. Secondary coverage is thin and lacks details on branching conditions and specific error scenarios.",
                "The summary correctly notes that the function decodes an ASN.1 template, validates structure integrity, advances the input pointer, and reports detailed errors on failure, all of which align with the source code's logic. The mention of optional indefinite-length support is accurate, as the code handles indefinite-length encoding through exp_eoc/EOC checks. The claims are specific and relevant, with no inaccuracies or extraneous noise, providing high-value insight into the function\u2019s core behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Decodes ASN.1 template data with indefinite length handling, validates structure, updates parsing position, and reports detailed errors on failure.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary captures accurate high-level behavior: it describes decoding ASN.1 template data, handling indefinite length (via exp_eoc and EOC checks), validating structure, updating the parsing pointer, and reporting detailed errors. These actions are present in the source code, with no contradictory claims or irrelevant noise. While the summary is generic and omits specifics like EXPLICIT tag handling, its claims align strongly with the code's semantics.",
                "The summary correctly notes that the function decodes ASN.1 template data, validates structure, updates the parsing position, and reports detailed errors, which aligns with the source code's core purpose and behavior. However, it omits critical specifics, such as handling of explicit versus non-explicit tags, construction checks, error conditions for length mismatches and missing EOC, and branching to different decoding paths. These details are important for complete coverage of the function\u2019s behavior, so coverage of secondary information is only moderate.",
                "The summary accurately conveys that the function decodes ASN.1 template data, validates structure, updates the input pointer, and reports detailed errors, which match the primary purpose and behavior in the source code. However, it omits significant details such as conditional explicit tag handling, optional field behavior, and the distinction between EXPLICIT and non-EXPLICIT parsing paths. There are no inaccurate claims, but the coverage is somewhat generic, limiting informational gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic psmouse_ret_t cypress_protocol_handler(struct psmouse *psmouse)\n{\n\tstruct cytp_data *cytp = psmouse->private;\n\n\tif (psmouse->pktcnt >= cytp->pkt_size) {\n\t\tcypress_process_packet(psmouse, 0);\n\t\treturn PSMOUSE_FULL_PACKET;\n\t}\n\n\treturn cypress_validate_byte(psmouse);\n}",
    "comment": "Handles packet processing for a Cypress device, validating bytes and triggering full packet processing when the expected packet size is reached.",
    "prorec_sum": "Adjusts a hardware control field based on status bytes and flags, or triggers a fallback routine when conditions invalidate the current sequence.",
    "filter_prorec_sum": "Adjusts device configuration based on status flags and counters, or invokes a reset routine when conditions are not met.",
    "prorec_aug_sum": "Updates a device state counter and conditionally modifies configuration flags or triggers a reset based on control byte and status field conditions.",
    "filter_prorec_aug_sum": "Updates a hardware control field based on device status flags and counters, or triggers a fallback handler when conditions are not met.",
    "work_score": {
        "prorec_aug": {
            "summary": "Updates a device state counter and conditionally modifies configuration flags or triggers a reset based on control byte and status field conditions.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about updating a device state counter, modifying configuration flags, or triggering a reset do not match the source code, which processes packets when a packet count exceeds a threshold and otherwise validates a byte. None of the described behaviors appear in the provided function, making all claims inaccurate.",
                "The summary's claims about updating a device state counter and modifying configuration flags or triggering a reset do not match the source code. The function checks if the accumulated packet count meets the required packet size, processes the packet if so, or otherwise validates the current byte. There is no evidence in the code of updating counters beyond reading pktcnt, altering configuration flags, or triggering resets. The core purpose of handling Cypress protocol packets is entirely missing, making the content inaccurate and failing to cover the main semantics.",
                "The summary's claims about updating a device state counter and modifying configuration flags or triggering a reset are inaccurate and do not reflect the source code behavior. The actual function checks if the packet count meets or exceeds a packet size threshold, processes the packet, and returns a specific status, otherwise it validates a byte. These mismatched claims are FATAL as they misstate the core purpose and logic of the function, making the summary misleading and unusable."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Updates a hardware control field based on device status flags and counters, or triggers a fallback handler when conditions are not met.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function updates a hardware control field based on status flags and counters, and triggers a fallback handler when conditions are not met. The source code, however, does not update any hardware control field; instead, it checks if the packet count meets a threshold, then processes a packet and returns a constant, or otherwise calls a validation function. Both major elements of the summary (hardware control field update, fallback handler logic) are inaccurate, resulting in no factually accurate claims.",
                "The summary does not accurately reflect the source code\u2019s core purpose, which is handling Cypress touchpad protocol packets: if enough bytes have been received (pktcnt >= pkt_size), it processes the packet and returns a specific constant, otherwise it validates the next byte. The claims about updating hardware control fields and triggering fallback handlers are unsupported by the code, making them inaccurate noise. No accurate claim covers the core operation or other key behaviors present in the function.",
                "The summary contains a FATAL inaccuracy about the primary purpose: it claims the function updates a hardware control field based on device status flags and counters, which is not reflected in the source code. The actual code checks if a packet counter meets the packet size threshold, processes the packet if so, and otherwise validates the byte. There is no hardware control field update or explicit device status flag usage. This misrepresentation of core semantics severely compromises trust, and while the fallback notion loosely matches the 'else' behavior, the dominant inaccuracy is about the core action."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\ninfo_signal_proc (int sig)\n{\n  signal_info *old_signal_handler = NULL;\n\n#if !defined (HAVE_SIGACTION)\n  /* best effort: first increment this counter and later block signals */\n  if (term_conf_busy)\n    return;\n  term_conf_busy++;\n#if defined (HAVE_SIGPROCMASK)\n    {\n      sigset_t nvar, ovar;\n      sigemptyset (&nvar);\n      mask_termsig (&nvar);\n      sigprocmask (SIG_BLOCK, &nvar, &ovar);\n    }\n#endif /* HAVE_SIGPROCMASK */\n#endif /* !HAVE_SIGACTION */\n  switch (sig)\n    {\n#if defined (SIGTSTP)\n    case SIGTSTP:\n    case SIGTTOU:\n    case SIGTTIN:\n#endif\n#if defined (SIGQUIT)\n    case SIGQUIT:\n#endif\n#if defined (SIGINT)\n    case SIGINT:\n#endif\n#if defined (SIGTERM)\n    case SIGTERM:\n#endif\n      {\n#if defined (SIGTSTP)\n        if (sig == SIGTSTP)\n          old_signal_handler = &old_TSTP;\n        if (sig == SIGTTOU)\n          old_signal_handler = &old_TTOU;\n        if (sig == SIGTTIN)\n          old_signal_handler = &old_TTIN;\n#endif /* SIGTSTP */\n#if defined (SIGQUIT)\n        if (sig == SIGQUIT)\n          old_signal_handler = &old_QUIT;\n#endif /* SIGQUIT */\n#if defined (SIGINT)\n        if (sig == SIGINT)\n          old_signal_handler = &old_INT;\n#endif /* SIGINT */\n#if defined (SIGTERM)\n        if (sig == SIGTERM)\n          old_signal_handler = &old_TERM;\n#endif /* SIGTERM */\n\n        /* For stop signals, restore the terminal IO, leave the cursor\n           at the bottom of the window, and stop us. */\n        terminal_goto_xy (0, screenheight - 1);\n        terminal_clear_to_eol ();\n        fflush (stdout);\n        terminal_unprep_terminal ();\n\trestore_termsig (sig, old_signal_handler);\n\tUNBLOCK_SIGNAL (sig);\n\tkill (getpid (), sig);\n\n        /* The program is returning now.  Restore our signal handler,\n           turn on terminal handling, redraw the screen, and place the\n           cursor where it belongs. */\n        terminal_prep_terminal ();\n\tset_termsig (sig, old_signal_handler);\n\t/* window size might be changed while sleeping */\n\treset_info_window_sizes ();\n      }\n      break;\n\n#if defined (SIGWINCH) || defined (SIGUSR1)\n#ifdef SIGWINCH\n    case SIGWINCH:\n#endif\n#ifdef SIGUSR1\n    case SIGUSR1:\n#endif\n      {\n\t/* Turn off terminal IO, tell our parent that the window has changed,\n\t   then reinitialize the terminal and rebuild our windows. */\n#ifdef SIGWINCH\n\tif (sig == SIGWINCH)\n\t  old_signal_handler = &old_WINCH;\n#endif\n#ifdef SIGUSR1\n\tif (sig == SIGUSR1)\n\t  old_signal_handler = &old_USR1;\n#endif\n\n        /* This seems risky: what if we receive a (real) signal before\n           the next line is reached? */\n#if 0\n\trestore_termsig (sig, old_signal_handler);\n\tkill (getpid (), sig);\n#endif\n\n\t/* After our old signal handler returns... */\n\tset_termsig (sig, old_signal_handler); /* needless? */\n\n        if (sigwinch_block_count != 0)\n          abort ();\n\n        /* Avoid any of the code unblocking the signal too early.  This\n           should set the variable to 1 because we shouldn't be here if\n           sigwinch_block_count > 0. */\n        sigwinch_block_count++;\n\n\treset_info_window_sizes ();\n\n        sigwinch_block_count--;\n        /* Don't unblock the signal until after we've finished. */\n\tUNBLOCK_SIGNAL (sig);\n      }\n      break;\n#endif /* SIGWINCH || SIGUSR1 */\n    }\n#if !defined (HAVE_SIGACTION)\n  /* at this time it is safer to perform unblock after decrement */\n  term_conf_busy--;\n#if defined (HAVE_SIGPROCMASK)\n    {\n      sigset_t nvar, ovar;\n      sigemptyset (&nvar);\n      mask_termsig (&nvar);\n      sigprocmask (SIG_UNBLOCK, &nvar, &ovar);\n    }\n#endif /* HAVE_SIGPROCMASK */\n#endif /* !HAVE_SIGACTION */\n}",
    "comment": "Handles various signals by restoring terminal settings, blocking signals during critical sections, and managing terminal window size changes.",
    "prorec_sum": "Handles specific signals by temporarily swapping handlers, masking the signal, sending it to the process, restoring handlers, and performing associated cleanup routines.",
    "filter_prorec_sum": "Handles specific signals by temporarily swapping sigaction handlers, delivering the signal to itself, and restoring the original handler configuration.",
    "prorec_aug_sum": "Handles specific signals by temporarily replacing their handlers, triggering the signal for self-delivery, and then restoring the original signal actions and masks.",
    "filter_prorec_aug_sum": "Handles specific signals by temporarily swapping handlers, flushing state, sending the signal to itself, then restoring the original signal actions.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles specific signals by temporarily replacing their handlers, triggering the signal for self-delivery, and then restoring the original signal actions and masks.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly notes that the function handles specific signals and that it triggers the same signal for self-delivery (via kill) after making changes, but it inaccurately generalizes behavior. It omits that the restoration of original handlers and masks occurs separately for different signals, with additional terminal state handling and window resizing logic included, and that not all cases involve triggering the signal. This makes the central claim only partially aligned with the code.",
                "The summary correctly notes that the function handles specific signals and involves replacing/restoring handlers, which matches code behavior. However, it omits the core primary purpose: managing terminal state and window sizes across different signals (stop, quit, interrupt, terminate, window change, user signal). It also fails to mention key secondary actions such as terminal I/O restoration, cursor positioning, blocking/unblocking signals safely with sigprocmask, and handling sigwinch_block_count. Thus, while partially accurate, it lacks coverage of the main domain action and most critical side effects.",
                "The summary omits key details on how the function actually handles different signals (e.g., SIGTSTP, SIGQUIT, SIGINT, SIGTERM, SIGWINCH, SIGUSR1) and the significant terminal state manipulations, but the core claim\u2014that it temporarily replaces handlers, delivers the signal to itself, and restores original handlers and masks\u2014is accurate for the stop-signal handling path. There are no outright contradictions (no FATAL), but the description is overly generic and misses important context such as terminal preparation/restoration and conditional signal blocking, resulting in low gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Handles specific signals by temporarily swapping handlers, flushing state, sending the signal to itself, then restoring the original signal actions.",
            "score": [
                0.9,
                0.4,
                0.7
            ],
            "reason": [
                "The summary accurately states that the function handles specific signals, temporarily changes handlers, flushes state, sends the signal to itself, and then restores the original handlers. These steps align with the code's behavior for SIGTSTP, SIGTTOU, SIGTTIN, SIGQUIT, SIGINT, and SIGTERM, and partially for SIGWINCH/SIGUSR1 except for the self-signal step, which is omitted there. Although it omits some signal-specific details and conditional compilation aspects, there are no incorrect claims, and most described actions are verifiable in the source.",
                "The summary correctly states that the function handles certain signals, temporarily changes handlers, sends the signal to itself, and restores the original handlers, which matches the core mechanism in the code. However, it omits critical domain-specific details such as differentiating behaviors for stop signals vs. window change signals, terminal state manipulations, screen redraws, and handling of sigwinch_block_count. This results in the core being covered but secondary behavior coverage being weak.",
                "The summary correctly captures that the function handles signals, changes handlers temporarily, and later restores them, which aligns with the code. However, it omits important specifics such as the differentiated behavior for stop signals versus window-change signals, the terminal state management, and conditional compilation branches. The description of flushing state and sending the signal to itself is accurate for stop signals but not universally applicable to all cases. Overall, noise is minimal and there is moderate gain from the accurate core description, but the lack of detailed coverage limits usefulness."
            ]
        }
    }
}
{
    "source_code": "int ENGINE_add(ENGINE *e)\n\t{\n\tint to_return = 1;\n\tif(e == NULL)\n\t\t{\n\t\tENGINEerr(ENGINE_F_ENGINE_ADD,\n\t\t\tERR_R_PASSED_NULL_PARAMETER);\n\t\treturn 0;\n\t\t}\n\tif((e->id == NULL) || (e->name == NULL))\n\t\t{\n\t\tENGINEerr(ENGINE_F_ENGINE_ADD,\n\t\t\tENGINE_R_ID_OR_NAME_MISSING);\n\t\t}\n\tCRYPTO_w_lock(CRYPTO_LOCK_ENGINE);\n\tif(!engine_list_add(e))\n\t\t{\n\t\tENGINEerr(ENGINE_F_ENGINE_ADD,\n\t\t\tENGINE_R_INTERNAL_LIST_ERROR);\n\t\tto_return = 0;\n\t\t}\n\tCRYPTO_w_unlock(CRYPTO_LOCK_ENGINE);\n\treturn to_return;\n\t}",
    "comment": "Adds an ENGINE structure to a list after validating its parameters and managing thread safety with locks.",
    "prorec_sum": "Registers a new ENGINE into the global engine list with duplicate checks, error reporting, and linked-list management under locking.",
    "filter_prorec_sum": "Registers a new ENGINE structure into the global engine list with duplicate checks, error reporting, and thread\u2011safe list updates.",
    "prorec_aug_sum": "Registers a new ENGINE into OpenSSL\u2019s global linked list, ensuring uniqueness, updating linkage pointers, and reporting detailed errors under locking.",
    "filter_prorec_aug_sum": "Registers a new ENGINE structure into the global linked list with locking, validating identifiers, and reporting errors for duplicates or invalid inputs.",
    "work_score": {
        "prorec_aug": {
            "summary": "Registers a new ENGINE into OpenSSL\u2019s global linked list, ensuring uniqueness, updating linkage pointers, and reporting detailed errors under locking.",
            "score": [
                0.5,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function registers a new ENGINE into OpenSSL\u2019s global list and reports errors under locking, which aligns with the code\u2019s use of CRYPTO_w_lock/unlock and ENGINEerr calls. However, it inaccurately adds claims about ensuring uniqueness and updating linkage pointers, which are not explicitly supported by the source code. As a result, the proportion of accurate claims is mixed, with some correct core behavior descriptions but also unsupported details.",
                "The summary correctly notes that the function registers a new ENGINE into a global list with locking and error reporting, which matches the core purpose and key behaviors in the source code. However, it inaccurately adds specifics about ensuring uniqueness and updating linkage pointers that are not evident from the code, and it omits explicit mention of input validation for null parameters and missing ID/name. Overall, core coverage is present but secondary coverage is incomplete with some speculative details.",
                "The summary correctly states that the function registers a new ENGINE into OpenSSL\u2019s global list and reports errors under locking, which matches the source code. However, it inaccurately claims uniqueness enforcement and updating of linkage pointers\u2014these are not indicated in the code, as the only related operation is calling `engine_list_add(e)` with no visible pointer manipulation or explicit uniqueness check. These are domain-semantic inaccuracies about the core process, making them FATAL issues for the primary purpose."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Registers a new ENGINE structure into the global linked list with locking, validating identifiers, and reporting errors for duplicates or invalid inputs.",
            "score": [
                0.6,
                0.6,
                0.2
            ],
            "reason": [
                "The summary correctly mentions registering an ENGINE structure into a global list, use of locking, and validation of identifiers, which match the code. However, it inaccurately claims that the function reports errors for duplicates, a behavior not present in the source code. This introduces a significant incorrect domain-specific detail, reducing accuracy to a mixed level overall.",
                "The summary accurately captures the core purpose of adding an ENGINE structure to a global list along with locking and validation of identifiers, aligning with the source code's domain-specific behavior. It also notes error reporting for invalid inputs, which is present in the code. However, it incorrectly states that errors are specifically for duplicates \u2014 the code reports an internal list error without explicit duplicate detection. Secondary coverage is moderate, touching on locking and error handling but missing details such as specific error types/constants and handling of NULL parameters versus missing IDs/names separately.",
                "The summary correctly notes that the function registers an ENGINE in a global list, uses locking, validates null parameters/identifiers, and reports errors for invalid inputs, which aligns with the code. However, it inaccurately claims error reporting for duplicates, which the source code does not explicitly check; failures are due to internal list errors, not duplicate detection. This is a FATAL in describing the primary purpose's conditions, reducing trustworthiness. Positive gain is limited due to this core semantic error despite some accurate details."
            ]
        }
    }
}
{
    "source_code": "\nstatic int inet6_addr_del(struct net *net, int ifindex, const struct in6_addr *pfx,\n\t\t\t  unsigned int plen)\n{\n\tstruct inet6_ifaddr *ifp;\n\tstruct inet6_dev *idev;\n\tstruct net_device *dev;\n\n\tif (plen > 128)\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tif ((idev = __in6_dev_get(dev)) == NULL)\n\t\treturn -ENXIO;\n\n\tread_lock_bh(&idev->lock);\n\tlist_for_each_entry(ifp, &idev->addr_list, if_list) {\n\t\tif (ifp->prefix_len == plen &&\n\t\t    ipv6_addr_equal(pfx, &ifp->addr)) {\n\t\t\tin6_ifa_hold(ifp);\n\t\t\tread_unlock_bh(&idev->lock);\n\n\t\t\tipv6_del_addr(ifp);\n\n\t\t\t/* If the last address is deleted administratively,\n\t\t\t   disable IPv6 on this interface.\n\t\t\t */\n\t\t\tif (list_empty(&idev->addr_list))\n\t\t\t\taddrconf_ifdown(idev->dev, 1);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tread_unlock_bh(&idev->lock);\n\treturn -EADDRNOTAVAIL;\n}",
    "comment": "Removes an IPv6 address from a network interface and disables IPv6 if it becomes the last address.",
    "prorec_sum": "Searches a socket\u2019s connection list for a matching endpoint by address and ID, updates its reference count, and triggers related handler routines.",
    "filter_prorec_sum": "Searches a socket\u2019s bound address list for a matching entry by length and identifier, updates reference counts, and triggers associated connection handling callbacks.",
    "prorec_aug_sum": "Searches for a matching entry by identifier and key, updates related metrics, and triggers further processing with provided parameters if found.",
    "filter_prorec_aug_sum": "Searches a multicast source list for a matching entry by address and key, updates related counters, and triggers associated processing callbacks.",
    "work_score": {
        "prorec_aug": {
            "summary": "Searches for a matching entry by identifier and key, updates related metrics, and triggers further processing with provided parameters if found.",
            "score": [
                0.3,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function searches by identifier and key, updates metrics, and triggers further processing with provided parameters. While the function does search for a matching IPv6 address (identifier/key analogy) and triggers further processing (address deletion) if found, it does not update any metrics, and the phrase 'provided parameters' is vague. Most claims are either inaccurate or too generic, with only the search and conditional processing parts aligning with the code. This results in less than half of the claims being accurate.",
                "The summary does not cover the core primary purpose of removing a specific IPv6 address from a network interface based on prefix and length, nor does it mention any of the error conditions, address list traversal, or disabling IPv6 when last address is removed. Instead, it incorrectly describes searching by identifier and key, updating metrics, and triggering further processing \u2014 behaviors not present in the source. This represents a direct semantic mismatch with no accurate claims about the code.",
                "The summary's claims about \"updating related metrics\" and \"triggering further processing\" do not align with the code's actual behavior of removing an IPv6 address, possibly disabling IPv6 on the interface, and returning appropriate error codes. The described search criteria (identifier and key) are also overly generic and miss the core purpose of address deletion. These are FATAL inaccuracies regarding the primary purpose and key side effect of the function, making the depiction untrustworthy. There are no accurate, domain-specific details present to offset the errors."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Searches a multicast source list for a matching entry by address and key, updates related counters, and triggers associated processing callbacks.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary's claims about searching a multicast source list, matching by address and key, updating counters, and triggering callbacks do not reflect the actual function behavior in the source code, which deletes an IPv6 address from an interface if it matches prefix length and address, handling errors and interface shutdown. All claims are unrelated to the code's semantics, resulting in no accurate alignment.",
                "The summary describes searching a multicast source list, updating counters, and triggering callbacks, which does not align with the source code's primary purpose of deleting an IPv6 address from an interface based on prefix length and address match, handling errors, and potentially disabling IPv6 on the interface. No accurate claims from the summary reflect the core domain action, and all described behavior is unrelated to the actual function semantics.",
                "The summary claims the function searches a multicast source list, matches by address and key, updates counters, and triggers callbacks. The source code actually deletes an IPv6 address from an interface based on prefix length, handles errors, and potentially brings the interface down if no addresses remain. All claims in the summary misrepresent the core purpose and I/O of the function, amounting to a severe FATAL error on the primary purpose, making the description entirely untrustworthy."
            ]
        }
    }
}
{
    "source_code": "\nstatic char *\nstyle_sheet_mixed_new (const uchar * ancestors)\n{\n  struct style_sheet *sheet, *ancestor;\n  char *ancestor_key, *key, *cp;\n  char *ancestors_keys;\n  struct darray *ancestors_array;\n\n  /* It cannot be longer than ancestors_keys. */\n  key = ALLOCA (char, ustrlen (ancestors) + 1);\n  astrcpy (ancestors_keys, ancestors);\n\n  /* Create the darray of ancestors keys, and build the final key. */\n  ancestors_array = ancestors_new ();\n  ancestor_key = strtok (ancestors_keys, MIXED_SHEET_SEP);\n  da_append (ancestors_array, ancestor_key);\n  ancestor = get_style_sheet (ancestor_key);\n  cp = stpcpy (key, ancestor->key);\n\n  while ((ancestor_key = strtok (NULL, MIXED_SHEET_SEP)))\n    {\n      da_append (ancestors_array, ancestor_key);\n      ancestor = get_style_sheet (ancestor_key);\n      *cp++ =',';\n      cp = stpcpy (cp, ancestor->key);\n    }\n  *cp = '\\0';\n  key = xstrdup (key);\n\n  /* Create the style sheet. */\n  message (msg_sheet,\n\t   (stderr, \"Creating a mixed style sheet \\\"%s\\\"\\n\", key));\n  /* Its name is its key. */\n  sheet = new_style_sheet ((uchar *) key);\n  sheet->key = strdup (key);\n  da_concat (sheet->ancestors, ancestors_array);\n  da_erase (ancestors_array);\n  style_sheet_finalize (sheet);\n\n  return key;\n}",
    "comment": "Creates a new style sheet by concatenating keys from ancestor style sheets, storing them in a darray, and finalizing the new sheet.",
    "prorec_sum": "Parses a comma- or semicolon-separated list of ancestor style sheets, registers each, builds a combined name, and creates the corresponding mixed style sheet entry.",
    "filter_prorec_sum": "Parses a comma or semicolon separated list of style sheet names, registers them as \u201cAncestors,\u201d and creates a combined mixed style sheet entry.",
    "prorec_aug_sum": "Parses a comma- or semicolon-separated list of ancestor stylesheets, registers them, and creates a combined \u201cmixed style sheet\u201d entry with associated metadata.",
    "filter_prorec_aug_sum": "Parses a comma- or semicolon-separated list of stylesheet names, registers them as \"Ancestors\", and creates a combined mixed stylesheet entry.",
    "work_score": {
        "prorec_aug": {
            "summary": "Parses a comma- or semicolon-separated list of ancestor stylesheets, registers them, and creates a combined \u201cmixed style sheet\u201d entry with associated metadata.",
            "score": [
                0.8,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly describes that the function processes a list of ancestor stylesheets and creates a mixed style sheet with associated metadata, aligning with the code's splitting of ancestors, lookup of style sheets, and creation/registration of a new sheet. However, it inaccurately specifies 'comma- or semicolon-separated' while the code uses the MIXED_SHEET_SEP constant, and the separator type is not explicitly confirmed in the source. This is a minor inaccuracy in otherwise faithful coverage of functionality, so most claims are accurate.",
                "The summary accurately describes parsing a separated list of ancestor stylesheets and the creation of a mixed style sheet, which matches the core purpose of the function. However, it omits several important behavioral details from the source code, such as building a unique key from ancestor keys, explicit message logging, memory allocation steps, use of specific separators defined in MIXED_SHEET_SEP, and finalization steps like concatenating and erasing the ancestor array. These omissions reduce coverage of secondary behavior-critical semantics.",
                "The summary correctly identifies that the function processes a list of ancestor stylesheets and creates a mixed style sheet. However, it inaccurately specifies 'comma- or semicolon-separated' input; the actual separator is defined by MIXED_SHEET_SEP, which is not explicitly stated as either of those and could differ. Aside from this minor inaccuracy, the rest of the description\u2014registering ancestors, creating a combined sheet, and associating metadata\u2014is consistent with the code. The error about separator type is noise rather than a severe fatal issue, and the gain from accuracy is moderate due to the clear statement of primary purpose."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Parses a comma- or semicolon-separated list of stylesheet names, registers them as \"Ancestors\", and creates a combined mixed stylesheet entry.",
            "score": [
                0.8,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly notes that the function creates a combined mixed stylesheet entry from a list of ancestor stylesheet names, which matches the code's behavior of building a key from ancestor styles and creating a new style sheet. However, it inaccurately specifies 'comma- or semicolon-separated' lists, whereas the actual delimiter is defined by MIXED_SHEET_SEP and not directly shown as comma or semicolon. Aside from this delimiter detail, the rest of the description aligns with the code, making most claims accurate.",
                "The summary accurately conveys that the function takes a separator-delimited list of style sheet names, processes them as ancestors, and creates a combined mixed style sheet. This aligns with the code's core purpose of building a composite style_sheet object from ancestor keys. However, it omits several important behavioral details: use of a dynamic array to store ancestor keys, lookup of ancestor style sheets to build a derived key, logging a creation message, duplicating strings for the key, concatenating ancestor arrays into the new sheet, and finalizing the sheet. The omission of these specifics means secondary coverage is limited.",
                "The summary claims the function parses a comma- or semicolon-separated list of stylesheet names, registers them as 'Ancestors', and creates a combined mixed stylesheet entry. The source code indeed splits an input string using MIXED_SHEET_SEP as a delimiter (likely comma) and builds an array of ancestor stylesheets, appending each fetched style sheet's key to form a combined key. It then creates a new style sheet and sets its ancestors. While 'registers them as \"Ancestors\"' is slightly interpretive, it aligns with `da_append` and `da_concat` operations. There are no factually incorrect statements or major noise, and the summary captures the primary purpose concisely, though with moderate specificity rather than deep detail."
            ]
        }
    }
}
{
    "source_code": "EXPORT BITCODE_H\ndwg_find_tablehandle (Dwg_Data *restrict dwg, const char *restrict name,\n                      const char *restrict table)\n{\n  BITCODE_BL i, num_entries = 0;\n  BITCODE_H ctrl = NULL, *hdlv = NULL;\n  Dwg_Object *obj;\n  Dwg_Object_APPID_CONTROL *_obj; // just some random generic type\n  Dwg_Header_Variables *vars = &dwg->header_vars;\n\n  if (!dwg || !name || !table)\n    return NULL;\n  // look for the _CONTROL table, and search for name in all entries\n  ctrl = dwg_ctrl_table (dwg, table);\n  if (strEQc (table, \"LTYPE\"))\n    {\n      if (strEQc (name, \"BYLAYER\") || strEQc (name, \"ByLayer\"))\n        {\n          if (vars->LTYPE_BYLAYER)\n            return vars->LTYPE_BYLAYER;\n        }\n      else if (strEQc (name, \"BYBLOCK\") || strEQc (name, \"ByBlock\"))\n        {\n          if (vars->LTYPE_BYBLOCK)\n            return vars->LTYPE_BYBLOCK;\n        }\n      else if (strEQc (name, \"CONTINUOUS\") || strEQc (name, \"Continuous\"))\n        {\n          if (vars->LTYPE_CONTINUOUS)\n            return vars->LTYPE_CONTINUOUS;\n        }\n    }\n  if (!ctrl)\n    { // TODO: silently search table_control. header_vars can be empty\n      LOG_TRACE (\"dwg_find_tablehandle: Empty header_vars table %s\\n\", table);\n      return NULL;\n    }\n  obj = dwg_resolve_handle (dwg, ctrl->absolute_ref);\n  if (!obj)\n    {\n      LOG_TRACE (\"dwg_find_tablehandle: Could not resolve table %s\\n\", table);\n      return NULL;\n    }\n  if (obj->type == DWG_TYPE_DICTIONARY)\n    return dwg_find_dicthandle_objname (dwg, ctrl, name);\n  if (!dwg_obj_is_control (obj))\n    {\n      LOG_ERROR (\"dwg_find_tablehandle: Could not resolve CONTROL object %s \"\n                 \"for table %s\",\n                 obj->name, table);\n      return NULL;\n    }\n  _obj = obj->tio.object->tio.APPID_CONTROL; // just random type\n  dwg_dynapi_entity_value (_obj, obj->name, \"num_entries\", &num_entries, NULL);\n  if (!num_entries)\n    return NULL;\n  dwg_dynapi_entity_value (_obj, obj->name, \"entries\", &hdlv, NULL);\n  if (!hdlv)\n    return NULL;\n  for (i = 0; i < num_entries; i++)\n    {\n      char *hdlname;\n      Dwg_Object *hobj;\n      Dwg_Object_APPID *_o;\n      int isnew = 0;\n      bool ok;\n\n      if (!hdlv[i])\n        continue;\n      hobj = dwg_resolve_handle (dwg, hdlv[i]->absolute_ref);\n      if (!hobj || !hobj->tio.object || !hobj->tio.object->tio.APPID)\n        continue;\n      _o = hobj->tio.object->tio.APPID;\n      ok = dwg_dynapi_entity_utf8text (_o, hobj->name, \"name\", &hdlname, &isnew, NULL);\n      LOG_HANDLE (\" %s.%s[%d] => %s.name: %s\\n\", obj->name, \"entries\", i,\n                  hobj->name, hdlname ? hdlname : \"NULL\");\n      if (ok && hdlname && (strEQ (name, hdlname) || !strcasecmp (name, hdlname)))\n        {\n          if (isnew)\n            free (hdlname);\n          return hdlv[i];\n        }\n      if (ok && isnew && hdlname)\n        free (hdlname);\n    }\n\n  return NULL;\n}",
    "comment": "Retrieves a handle for a specified named entry in a given table from a DWG file's control structure.",
    "prorec_sum": "Retrieves a DWG table handle by name, with special cases for common linetypes, resolving related handles and reporting errors when lookup fails.",
    "filter_prorec_sum": "Retrieves a specific DWG table entry handle by table and entry name, with special handling for common LTYPE names and error reporting.",
    "prorec_aug_sum": "Retrieves a specific CAD table handle from a DWG structure by matching table and entry names, with special handling for common linetype constants.",
    "filter_prorec_aug_sum": "Retrieves a DWG table handle for a specified table and entry name, with special handling for predefined LTYPE entries and error reporting.",
    "work_score": {
        "prorec_aug": {
            "summary": "Retrieves a specific CAD table handle from a DWG structure by matching table and entry names, with special handling for common linetype constants.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function retrieves a table handle from a DWG structure by matching table and entry names, which aligns with the code's logic of searching through control tables and entries. It also accurately notes the special handling for common linetype constants ('BYLAYER', 'BYBLOCK', 'CONTINUOUS') found in the source. While the wording is somewhat general, all key described behaviors are present in the code, making the claims specific and accurate.",
                "The summary accurately states that the function retrieves a CAD table handle from a DWG structure by matching table and entry names, which matches the core domain action. It also correctly notes special handling for common linetype constants (BYLAYER, BYBLOCK, CONTINUOUS). However, it omits numerous secondary details such as null checks on inputs, handling when the control table is absent or not resolvable, dictionary-type lookups, the iteration over entries with name matching using case-insensitive comparison, logging behavior, and early returns on missing data. Coverage of the core is solid, but secondary behavior coverage is minimal.",
                "The summary accurately captures the core purpose of the function \u2014 retrieving a specific CAD table handle from a DWG structure by matching table and entry names \u2014 and mentions the special handling for common linetype constants (BYLAYER, BYBLOCK, CONTINUOUS), which is explicitly implemented in the code. It omits details such as dictionary table handling, control object checks, and error logging, but these are secondary to the primary purpose. There are no inaccurate claims, and the claim is specific enough to be directly supported by the code."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Retrieves a DWG table handle for a specified table and entry name, with special handling for predefined LTYPE entries and error reporting.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function retrieves a DWG table handle for a given table and entry name, matches the code\u2019s special casing for LTYPE predefined entries, and mentions error reporting via log calls. These are all supported by the source, and there are no inaccurate or misleading claims, making the content fully aligned with the code's behavior.",
                "The summary correctly captures the core purpose: locating and returning a DWG table handle for a given table and entry name, including special-case handling for LTYPE variants. It also notes error reporting, which aligns with logging observed in the code. However, it omits important secondary behaviors, such as using control objects, resolving handles, checking dictionary types, iterating over entries, and handling null cases and specific header variables. This results in incomplete coverage of the function\u2019s behavior-critical semantics.",
                "The summary correctly states the primary purpose of the function: retrieving a DWG table handle for a given table and entry name, and notes the special case handling for predefined LTYPE entries as seen in the code. It also includes error reporting, which matches multiple LOG_TRACE/LOG_ERROR calls present. These claims are accurate, specific to the function's core semantics, and there is no contradicting information or excessive irrelevant content, providing good positive gain."
            ]
        }
    }
}
{
    "source_code": "static void\nPerform_Justification(FIELD *field, WINDOW *win)\n{\n  FIELD_CELL *bp;\n  int len;\n\n  bp = (Field_Has_Option(field, O_NO_LEFT_STRIP)\n\t? field->buf\n\t: Get_Start_Of_Data(field->buf, Buffer_Length(field)));\n  len = (int)(After_End_Of_Data(field->buf, Buffer_Length(field)) - bp);\n\n  if (len > 0)\n    {\n      int col = 0;\n\n      assert(win && (field->drows == 1));\n\n      if (field->cols - len >= 0)\n\tswitch (field->just)\n\t  {\n\t  case JUSTIFY_LEFT:\n\t    break;\n\t  case JUSTIFY_CENTER:\n\t    col = (field->cols - len) / 2;\n\t    break;\n\t  case JUSTIFY_RIGHT:\n\t    col = field->cols - len;\n\t    break;\n\t  default:\n\t    break;\n\t  }\n\n      wmove(win, 0, col);\n      myADDNSTR(win, bp, len);\n    }\n}",
    "comment": "Justifies the contents of a field within a window by aligning text based on specified justification (left, center, right) and current field length.",
    "prorec_sum": "Trims leading and trailing space characters from a fixed-size byte buffer segment and writes the cleaned data into the destination buffer.",
    "filter_prorec_sum": "Trims leading and trailing space characters from a buffer segment and writes the resulting content into the destination with padding if needed.",
    "prorec_aug_sum": "Trims leading and trailing spaces from a data buffer and writes the trimmed segment into the destination with adjusted length handling.",
    "filter_prorec_aug_sum": "Trims leading and trailing space characters from a fixed-size byte buffer and writes the resulting segment to the specified output.",
    "work_score": {
        "prorec_aug": {
            "summary": "Trims leading and trailing spaces from a data buffer and writes the trimmed segment into the destination with adjusted length handling.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims both leading and trailing spaces are trimmed, but the source code shows only conditional leading space trimming based on the O_NO_LEFT_STRIP option; trailing spaces are not removed. The description of adjusted length handling is partially accurate in referencing length calculation before output, but omits key details such as justification handling (left, center, right) and positioning before writing to the window. The majority of its claims about trimming are inaccurate relative to the code.",
                "The summary claims the function trims both leading and trailing spaces from a buffer and writes the trimmed data, but the code only conditionally skips leading spaces based on the O_NO_LEFT_STRIP option and determines length up to the end of the data without explicit trailing trim logic. It entirely omits the core purpose of performing text justification (left, center, right) in a single-row field window before writing, which is central to the function's domain behavior. No mention is made of justification cases, column calculation, or window positioning, meaning the core is not covered and the included claim is partially inaccurate.",
                "The summary claims the function trims both leading and trailing spaces, but the code only optionally strips leading spaces depending on O_NO_LEFT_STRIP and determines the segment end via After_End_Of_Data without explicit trailing space trimming. This is a FATAL in describing the primary purpose of the function, as it misstates the core behavior. The summary also omits the justification logic and placement into the window, which are key outputs. Limited accurate detail reduces net benefit to near zero."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Trims leading and trailing space characters from a fixed-size byte buffer and writes the resulting segment to the specified output.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary incorrectly states that the function trims both leading and trailing spaces from a fixed-size byte buffer. The source code optionally skips leading spaces based on a field option, but trailing spaces are not clearly trimmed; instead, 'After_End_Of_Data' marks the end of non-space data without explicitly trimming. The summary also omits key details like justification handling and cursor positioning. Most claims are inaccurate or overly generic, with less than half aligning with the code behavior.",
                "The summary incorrectly describes trimming both leading and trailing spaces from a byte buffer, while the source code only conditionally strips leading spaces based on the O_NO_LEFT_STRIP option and determines the end of data without explicit trailing space trimming. It omits the core purpose of justifying text within a single-row field based on the justification setting (left, center, right) and writing to a window, which is critical domain behavior. Only a generic mention of writing to output is present, with no accurate reflection of justification logic or other key semantics.",
                "The summary inaccurately states that the function trims both leading and trailing spaces. In reality, leading spaces are conditionally skipped only if the O_NO_LEFT_STRIP option is not set, and trailing spaces are not explicitly trimmed\u2014end position is determined semantically via After_End_Of_Data. This is a FATAL error about the primary purpose and I/O behavior. No accurate, high-value specifics are given, so net benefit is near zero."
            ]
        }
    }
}
{
    "source_code": "\nvoid acpi_ut_mutex_terminate(void)\n{\n\tu32 i;\n\n\tACPI_FUNCTION_TRACE(ut_mutex_terminate);\n\n\t/* Delete each predefined mutex object */\n\n\tfor (i = 0; i < ACPI_NUM_MUTEX; i++) {\n\t\tacpi_ut_delete_mutex(i);\n\t}\n\n\tacpi_os_delete_mutex(acpi_gbl_osi_mutex);\n\n\t/* Delete the spinlocks */\n\n\tacpi_os_delete_lock(acpi_gbl_gpe_lock);\n\tacpi_os_delete_lock(acpi_gbl_hardware_lock);\n\tacpi_os_delete_lock(acpi_gbl_reference_count_lock);\n\n\t/* Delete the reader/writer lock */\n\n\tacpi_ut_delete_rw_lock(&acpi_gbl_namespace_rw_lock);\n\treturn_VOID;\n}",
    "comment": "Terminates and deletes all predefined mutex objects, spinlocks, and a reader/writer lock to clean up synchronization mechanisms.",
    "prorec_sum": "Processes and clears multiple stored context entries, then updates related structures before finalizing with a consolidated display or graphics state update.",
    "filter_prorec_sum": "Processes and resets multiple hardware state entries, then updates additional registers before finalizing via a consolidated state commit routine.",
    "prorec_aug_sum": "Processes and clears stored entries, updates related global data blocks, and performs final aggregated calculations using provided parameters.",
    "filter_prorec_aug_sum": "Processes and resets multiple global data entries, then performs sequential operations on remaining entries before returning a final computed result.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes and clears stored entries, updates related global data blocks, and performs final aggregated calculations using provided parameters.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about processing stored entries, updating global data blocks, and performing aggregated calculations do not match the source code, which strictly deletes mutex objects, spinlocks, and a reader/writer lock without performing calculations or updating data blocks. All claims are inaccurate, resulting in no alignment.",
                "The summary makes generic claims about processing entries, updating global data, and performing calculations, none of which match the source code's core function of deleting ACPI-related mutexes, spinlocks, and locks during termination. There is no accurate claim that covers or even approximates the function's actual purpose, and no secondary relevant details from the code are present.",
                "The summary\u2019s claims \u2014 processing and clearing stored entries, updating global data blocks, and performing final aggregated calculations using provided parameters \u2014 do not match the source code, which deletes mutexes, spinlocks, and a reader/writer lock. These are severe [FATAL] inaccuracies about the primary purpose and core behavior of the function, making the description unusable for understanding the code."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes and resets multiple global data entries, then performs sequential operations on remaining entries before returning a final computed result.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains several inaccurate claims: it states that the function processes and resets multiple global data entries and returns a final computed result, which contradicts the source code. The code instead deletes predefined mutex objects, locks, and a reader/writer lock, and does not compute or return a result. None of the claims specifically describe the actual deletion operations, making the proportion of accurate claims below 50%.",
                "The summary\u2019s claims about processing and resetting global data entries and computing a final result are inaccurate relative to the source code. The function\u2019s core purpose is to delete predefined ACPI mutexes, spinlocks, and a reader/writer lock during termination, which is not described. No accurate, specific domain actions from the code are reflected in the summary, and the stated sequence and final computation are unsupported by the source code.",
                "The summary is inaccurate: it describes processing and resetting global data entries, sequential operations, and a final computed result, none of which align with the source code. The function merely deletes various mutexes, spinlocks, and a reader/writer lock, with no computation or result output. This is a FATAL error affecting the primary purpose, making the summary unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic bool\ndigest_file (const char *filename, int *binary, unsigned char *bin_result,\n             bool *missing)\n{\n  FILE *fp;\n  int err;\n  bool is_stdin = STREQ (filename, \"-\");\n\n  *missing = false;\n\n  if (is_stdin)\n    {\n      have_read_stdin = true;\n      fp = stdin;\n      if (O_BINARY && *binary)\n        {\n          if (*binary < 0)\n            *binary = ! isatty (STDIN_FILENO);\n          if (*binary)\n            xset_binary_mode (STDIN_FILENO, O_BINARY);\n        }\n    }\n  else\n    {\n      fp = fopen (filename, (O_BINARY && *binary ? \"rb\" : \"r\"));\n      if (fp == NULL)\n        {\n          if (ignore_missing && errno == ENOENT)\n            {\n              *missing = true;\n              return true;\n            }\n          error (0, errno, \"%s\", quotef (filename));\n          return false;\n        }\n    }\n\n  fadvise (fp, FADVISE_SEQUENTIAL);\n\n#if HASH_ALGO_BLAKE2\n  err = DIGEST_STREAM (fp, bin_result, b2_length / 8);\n#else\n  err = DIGEST_STREAM (fp, bin_result);\n#endif\n  if (err)\n    {\n      error (0, errno, \"%s\", quotef (filename));\n      if (fp != stdin)\n        fclose (fp);\n      return false;\n    }\n\n  if (!is_stdin && fclose (fp) != 0)\n    {\n      error (0, errno, \"%s\", quotef (filename));\n      return false;\n    }\n\n  return true;\n}",
    "comment": "Calculates a digest of the specified file or standard input, handling binary mode and error management for file operations.",
    "prorec_sum": "Opens the specified file or standard input, validates readability, handles errors, and sets a flag if the file is missing.",
    "filter_prorec_sum": "Opens the specified file or standard input, prepares it for reading, and reports errors with detailed messages, setting a flag if missing.",
    "prorec_aug_sum": "Opens the specified file or standard input, checks for readability, reports errors via errno, and sets a flag if the file is missing.",
    "filter_prorec_aug_sum": "Opens the specified file or standard input for reading, reports errors via stderr, and sets a flag if the file is missing.",
    "work_score": {
        "prorec_aug": {
            "summary": "Opens the specified file or standard input, checks for readability, reports errors via errno, and sets a flag if the file is missing.",
            "score": [
                0.9,
                0.2,
                0.7
            ],
            "reason": [
                "The summary captures key behaviors such as opening a specified file or standard input, handling missing files by setting a flag, and reporting errors using errno, all of which align with the source code\u2019s logic. However, the phrase 'checks for readability' is somewhat vague and could be misleading, as the function primarily opens the file and processes data rather than performing an explicit readability check. Overall, most claims are accurate with minor imprecision.",
                "The summary accurately notes that the function can open a specified file or standard input, and that it sets a missing flag in certain conditions. However, it inaccurately claims a check for readability (which the code does not explicitly perform) and omits the core purpose: computing a file's digest/hash and writing it to the provided result buffer. It also misses other key behaviors such as handling binary mode, sequential read advice, detailed error handling paths, and closing the file pointer. Since the core purpose is not covered and only limited secondary info is provided, the alignment is low.",
                "The summary contains mostly accurate claims: it correctly states that the function opens a specified file or stdin, sets a missing flag when the file is absent, and reports errors using errno. However, the wording 'checks for readability' is vague and could mislead since the code attempts to open and process the file rather than explicitly performing a separate readability check. Overall, the claims align with the code's primary purpose, with no fatal errors and minimal noise, but the gain is modest due to low specificity and lack of detail on binary mode handling or digest computation."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Opens the specified file or standard input for reading, reports errors via stderr, and sets a flag if the file is missing.",
            "score": [
                1.0,
                0.3,
                0.6
            ],
            "reason": [
                "The summary contains three atomic claims: (1) opens the specified file or standard input for reading, (2) reports errors via stderr, and (3) sets a flag if the file is missing. All three are supported by the source code: the function conditionally opens stdin or a file, calls error() to report problems, and sets *missing when a file is not found with ignore_missing enabled. This yields full alignment with the source code.",
                "The summary correctly states that the function opens a file or standard input, reports errors, and sets a missing flag, which matches several accurate behaviors in the code. However, it omits the core primary purpose of computing a digest of the file contents into a binary result and does not mention key secondary details such as handling binary mode settings, using fadvise for sequential access, special handling for stdin, or specific error conditions. This results in significant undercoverage of core and secondary semantics.",
                "The summary makes three clear claims: (1) opens the specified file or standard input for reading, (2) reports errors via stderr, and (3) sets a flag if the file is missing. All three are accurate based on the source code \u2014 the function opens either the given file or stdin, calls `error` to report issues to stderr, and sets `*missing = true` when appropriate. The claims are correct but fairly generic, offering low detail on the digest computation or binary mode handling. There is no noise or fatal inaccuracy, but gain is modest due to limited specificity."
            ]
        }
    }
}
{
    "source_code": "static noinline_for_stack\nvoid ext4_mb_simple_scan_group(struct ext4_allocation_context *ac,\n\t\t\t\t\tstruct ext4_buddy *e4b)\n{\n\tstruct super_block *sb = ac->ac_sb;\n\tstruct ext4_group_info *grp = e4b->bd_info;\n\tvoid *buddy;\n\tint i;\n\tint k;\n\tint max;\n\n\tBUG_ON(ac->ac_2order <= 0);\n\tfor (i = ac->ac_2order; i <= sb->s_blocksize_bits + 1; i++) {\n\t\tif (grp->bb_counters[i] == 0)\n\t\t\tcontinue;\n\n\t\tbuddy = mb_find_buddy(e4b, i, &max);\n\t\tBUG_ON(buddy == NULL);\n\n\t\tk = mb_find_next_zero_bit(buddy, max, 0);\n\t\tBUG_ON(k >= max);\n\n\t\tac->ac_found++;\n\n\t\tac->ac_b_ex.fe_len = 1 << i;\n\t\tac->ac_b_ex.fe_start = k << i;\n\t\tac->ac_b_ex.fe_group = e4b->bd_group;\n\n\t\text4_mb_use_best_found(ac, e4b);\n\n\t\tBUG_ON(ac->ac_b_ex.fe_len != ac->ac_g_ex.fe_len);\n\n\t\tif (EXT4_SB(sb)->s_mb_stats)\n\t\t\tatomic_inc(&EXT4_SB(sb)->s_bal_2orders);\n\n\t\tbreak;\n\t}\n}",
    "comment": "Scans the buddy system for free blocks, updates allocation context, and records statistics for memory management in an ext4 filesystem.",
    "prorec_sum": "Updates inode block mapping state by selecting the next valid extent, adjusting related counters and cache fields, and triggering integrity checks with BUG() on errors.",
    "filter_prorec_sum": "Validates and processes an ext4 extent entry, updating inode preallocation metadata and counters, and ensures consistency through cache updates and sanity checks.",
    "prorec_aug_sum": "Updates filesystem group descriptor data for a specific block group, validating parameters, adjusting inode state, and incrementing usage counters when conditions are met.",
    "filter_prorec_aug_sum": "Updates inode group allocation state by selecting the next available block group, computing block offsets, and synchronizing metadata with the ext4 filesystem structures.",
    "work_score": {
        "prorec_aug": {
            "summary": "Updates filesystem group descriptor data for a specific block group, validating parameters, adjusting inode state, and incrementing usage counters when conditions are met.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes updating filesystem group descriptor data, validating parameters, and adjusting inode state, but the source code does not update group descriptor structures directly nor modify inode state. It scans for a suitable free block region within a group using counters, sets allocation context fields, and increments statistics. Only the mention of incrementing usage counters aligns with the code. Most claims misrepresent the function's behavior, resulting in a low proportion of accurate statements.",
                "The summary does not accurately capture the core purpose, which is scanning a block group to find a suitable free extent of a given order and update the allocation context. It inaccurately describes updating filesystem group descriptors and adjusting inode state, which are not performed here. Some mention of incrementing usage counters aligns partially with the EXT4_SB stat counter increment, but overall most claims are inaccurate or unrelated to the code's actual function.",
                "The summary contains multiple inaccurate claims: it states the function updates filesystem group descriptor data, adjusts inode state, and increments usage counters when conditions are met. In reality, the function scans buddy structures for a suitable free block extent, sets allocation context fields, and may increment a block allocator statistic. There is no explicit update of group descriptor data or inode state in the code. The only partially accurate element is the mention of incrementing usage counters, which corresponds to a statistic counter. The inaccuracies are FATAL since they misrepresent the primary purpose and core side effects, making the summary misleading."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Updates inode group allocation state by selecting the next available block group, computing block offsets, and synchronizing metadata with the ext4 filesystem structures.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary makes several domain-specific claims, such as updating inode group allocation state, selecting the next available block group, and synchronizing metadata. However, the source code does not update inode-level structures; it operates on an ext4 allocation context and buddy group info to find and use the best block extent. The concept of 'next available block group' is not directly reflected in the loop logic, which scans for a suitable order rather than switching groups. Metadata synchronization is vague and not explicitly performed here. Most claims target code behavior but misrepresent it, resulting in low accuracy.",
                "The summary fails to cover the core purpose, which is scanning an ext4 group starting from a specific order to find and allocate the best matching free block using buddy bitmaps. While it mentions selecting a block group and computing offsets, these are generic and do not capture the buddy bitmap search or the specific allocation logic. There is also no coverage of critical checks (BUG_ON), use of ext4_mb_use_best_found, or updating statistics, leading to very incomplete and inaccurate representation of the function\u2019s semantics.",
                "The summary makes several domain-semantic claims about inode group allocation and metadata synchronization that do not match the source code. The function does not operate on inodes or select a new block group; instead, it scans the buddy bitmap in a given ext4 group to find available blocks and updates the allocation context accordingly. These mismatches are FATAL on the primary purpose, as they misrepresent the core action. No accurate GOLD claims are present, and the inaccuracies target the key 'what' of the function, making the net benefit unusable."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_linalg_cholesky_scale_apply(gsl_matrix * A, const gsl_vector * S)\n{\n  const size_t M = A->size1;\n  const size_t N = A->size2;\n\n  if (M != N)\n    {\n      GSL_ERROR(\"A is not a square matrix\", GSL_ENOTSQR);\n    }\n  else if (N != S->size)\n    {\n      GSL_ERROR(\"S must have length N\", GSL_EBADLEN);\n    }\n  else\n    {\n      size_t i, j;\n\n      /* compute: A <- diag(S) A diag(S) using lower triangle */\n      for (j = 0; j < N; ++j)\n        {\n          double sj = gsl_vector_get(S, j);\n\n          for (i = j; i < N; ++i)\n            {\n              double si = gsl_vector_get(S, i);\n              double *Aij = gsl_matrix_ptr(A, i, j);\n              *Aij *= si * sj;\n            }\n        }\n\n      return GSL_SUCCESS;\n    }\n}",
    "comment": "Scales the elements of square matrix A by the elements of vector S using diagonal multiplication in a Cholesky decomposition context.",
    "prorec_sum": "Validates matrix dimensions and scales a Cholesky factorization in-place using the provided diagonal scaling vector, reporting errors for mismatched sizes.",
    "filter_prorec_sum": "Validates matrix and scale vector dimensions, then applies element-wise scaling to a Cholesky factor matrix using the provided scale values.",
    "prorec_aug_sum": "Scales a Cholesky-decomposed square matrix by a matching-length vector, validating dimensions and reporting errors for invalid shapes.",
    "filter_prorec_aug_sum": "Validates matrix dimensions and scales a Cholesky-decomposed square matrix by a vector S, reporting dimension mismatches via gsl_error.",
    "work_score": {
        "prorec_aug": {
            "summary": "Scales a Cholesky-decomposed square matrix by a matching-length vector, validating dimensions and reporting errors for invalid shapes.",
            "score": [
                0.3,
                0.6,
                0.2
            ],
            "reason": [
                "The summary correctly notes scaling of a square matrix by a vector and validation of dimensions, which matches the code's operations and error checks for non-square matrices or mismatched vector length. However, it inaccurately states that the matrix is 'Cholesky-decomposed', which is not indicated in the function\u2014this is a semantic error targeting the code behavior. Given that one of the few claims is inaccurate, the proportion of accurate claims is below half.",
                "The summary correctly notes that the function scales a square matrix using a vector of matching length and validates dimensions, returning errors for mismatches. These are accurate reflections of the code's shape checks and scaling logic. However, it omits the core specificity that the scaling is performed as diag(S) * A * diag(S) using the lower triangle elements of the matrix. Missing these implementation details and constants reduces completeness, but the core purpose is essentially covered.",
                "The summary accurately notes that the function scales a square matrix by a vector and validates dimensions, returning errors for invalid shapes. However, it incorrectly claims the matrix is Cholesky-decomposed, which is not enforced by the code. This is a FATAL in describing the primary purpose since no Cholesky decomposition check or requirement exists. While some accurate details remain, the core description is misleading about the input's nature."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates matrix dimensions and scales a Cholesky-decomposed square matrix by a vector S, reporting dimension mismatches via gsl_error.",
            "score": [
                0.6,
                0.8,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function validates matrix dimensions and performs scaling of a square matrix by a vector S, and that it reports dimension mismatches via gsl_error. However, it inaccurately claims that the function operates on a Cholesky-decomposed matrix\u2014this is not evident in the code, which simply scales a matrix without performing or assuming a Cholesky decomposition. This inaccuracy affects one of the key specific claims, leading to mixed accuracy overall.",
                "The summary correctly mentions validation of matrix dimensions, requirement for a square matrix, the scaling operation using vector S, and reporting errors via gsl_error, which aligns with the code's checks for matrix squareness, vector length, and the diag(S) A diag(S) scaling using lower triangle. It conveys the core purpose of scaling a square matrix by vector S after dimension checks, though it adds 'Cholesky-decomposed' which is not explicitly stated in the code, making that part slightly inaccurate. Secondary details like exact error conditions and operation specifics are mostly present.",
                "The summary correctly notes that the function validates matrix dimensions and reports mismatches using gsl_error, and that scaling is done via vector S. However, it inaccurately specifies that the matrix is 'Cholesky-decomposed', which is not indicated or verified in the source code, making this a FATAL error about the primary purpose. This mischaracterization reduces trust in the summary despite some accurate elements."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\nfb_mmap(struct file *file, struct vm_area_struct * vma)\n{\n\tstruct fb_info *info = file_fb_info(file);\n\tstruct fb_ops *fb;\n\tunsigned long mmio_pgoff;\n\tunsigned long start;\n\tu32 len;\n\n\tif (!info)\n\t\treturn -ENODEV;\n\tfb = info->fbops;\n\tif (!fb)\n\t\treturn -ENODEV;\n\tmutex_lock(&info->mm_lock);\n\tif (fb->fb_mmap) {\n\t\tint res;\n\t\tres = fb->fb_mmap(info, vma);\n\t\tmutex_unlock(&info->mm_lock);\n\t\treturn res;\n\t}\n\n\t/*\n\t * Ugh. This can be either the frame buffer mapping, or\n\t * if pgoff points past it, the mmio mapping.\n\t */\n\tstart = info->fix.smem_start;\n\tlen = info->fix.smem_len;\n\tmmio_pgoff = PAGE_ALIGN((start & ~PAGE_MASK) + len) >> PAGE_SHIFT;\n\tif (vma->vm_pgoff >= mmio_pgoff) {\n\t\tif (info->var.accel_flags) {\n\t\t\tmutex_unlock(&info->mm_lock);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tvma->vm_pgoff -= mmio_pgoff;\n\t\tstart = info->fix.mmio_start;\n\t\tlen = info->fix.mmio_len;\n\t}\n\tmutex_unlock(&info->mm_lock);\n\n\tvma->vm_page_prot = vm_get_page_prot(vma->vm_flags);\n\tfb_pgprotect(file, vma, start);\n\n\treturn vm_iomap_memory(vma, start, len);\n}",
    "comment": "Maps the framebuffer or MMIO memory region into the process's address space based on the provided virtual memory area structure.",
    "prorec_sum": "Validates a block device context, adjusts buffer allocation, and initiates a data transfer based on current device state and request parameters.",
    "filter_prorec_sum": "Validates device state, adjusts memory counters, and executes a device-specific operation using provided parameters and function pointers.",
    "prorec_aug_sum": "Validates a context\u2019s mapped region, adjusts resource counters, and invokes a handler or performs a fallback operation to complete the mapping request.",
    "filter_prorec_aug_sum": "Validates a memory object handle, adjusts allocation counters, and invokes either a custom or default routine to map the specified region.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates a context\u2019s mapped region, adjusts resource counters, and invokes a handler or performs a fallback operation to complete the mapping request.",
            "score": [
                0.3,
                0.2,
                0.4
            ],
            "reason": [
                "The summary makes vague claims about validating a context\u2019s mapped region, adjusting resource counters, and invoking a handler or fallback. The 'invokes a handler or fallback' loosely matches the code's fb->fb_mmap call or MMIO mapping logic, and 'validates mapping region' can be interpreted as checking offsets and lengths. However, there is no evidence in the code of adjusting resource counters, making that claim inaccurate. The overall description is too generic, omitting key specifics about framebuffer, memory mapping, mutex locking, and error returns. Less than half of the claims are accurate.",
                "The summary does not explicitly cover the core purpose of mapping framebuffer or MMIO memory into a process\u2019s virtual address space. While it generically mentions validating a mapped region and invoking a handler or fallback, it lacks the specific domain action of framebuffer mmap handling. There is no reference to the distinction between framebuffer and MMIO mapping, conditional handling for drivers with a custom fb_mmap function, or the error cases present in the code. The claims are vague and generic, missing the core and most secondary details.",
                "The summary contains mostly inaccurate and overly generic claims. It incorrectly states that the function validates a context\u2019s mapped region and adjusts resource counters, neither of which is explicit in the source code. The actual function checks for fb_info and fb_ops validity, optionally delegates to a driver-specific mmap handler, and otherwise sets up mappings for framebuffer or mmio memory. The mention of a fallback operation is vaguely aligned with the branch when fb->fb_mmap is absent, but the rest is misleading. The worst failure mode is NOISE, as most described actions don\u2019t match the code\u2019s actual logic, and the gains are minimal due to low specificity and inaccuracy."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates a memory object handle, adjusts allocation counters, and invokes either a custom or default routine to map the specified region.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims validation of a memory object handle and adjustment of allocation counters, but the source code validates a framebuffer info structure and associated operations without modifying allocation counters. While it correctly notes invoking either a custom or default mapping routine, most of the description is inaccurate relative to actual code semantics, resulting in less than half of the claims being accurate.",
                "The summary does not accurately capture the core purpose of mapping framebuffer or MMIO memory based on conditions in the source code. It incorrectly introduces unrelated concepts like 'memory object handle' and 'allocation counters' that are not present, missing domain-specific details such as handling fb_ops->fb_mmap, differentiating between framebuffer and mmio mapping based on vm_pgoff, and locking/unlocking. This results in core purpose not being covered and the inclusion of inaccurate claims.",
                "The summary contains multiple inaccuracies relative to the source code. It incorrectly claims that the function validates a memory object handle (the code validates fb_info and fb_ops, not a generic memory object handle) and adjusts allocation counters (no such counters are manipulated). The description of invoking a custom or default routine to map a region partially aligns\u2014there is a call to a custom fb_mmap if present, otherwise default logic\u2014but the WHAT is substantially wrong regarding key input/output roles, constituting a FATAL error on primary purpose. Few if any accurate claims are present, and the inaccuracies undermine trustworthiness."
            ]
        }
    }
}
{
    "source_code": "static void vt_disallocate_all(void)\n{\n\tstruct vc_data *vc[MAX_NR_CONSOLES];\n\tint i;\n\n\tconsole_lock();\n\tfor (i = 1; i < MAX_NR_CONSOLES; i++)\n\t\tif (!VT_BUSY(i))\n\t\t\tvc[i] = vc_deallocate(i);\n\t\telse\n\t\t\tvc[i] = NULL;\n\tconsole_unlock();\n\n\tfor (i = 1; i < MAX_NR_CONSOLES; i++) {\n\t\tif (vc[i] && i >= MIN_NR_CONSOLES) {\n\t\t\ttty_port_destroy(&vc[i]->port);\n\t\t\tkfree(vc[i]);\n\t\t}\n\t}\n}",
    "comment": "Deallocates all virtual consoles that are not busy, destroying associated tty ports and freeing memory for those consoles.",
    "prorec_sum": "Iterates over 62 stored entries, filtering and initializing active ones, then processes each through two geometry-related update routines using provided parameters.",
    "filter_prorec_sum": "Iterates through indexed hardware-related entries, clearing or initializing them based on status, then processes each initialized entry with two sequential computational and handling routines.",
    "prorec_aug_sum": "Iterates through device entries, skips inactive ones, processes active entries, and invokes two routines with provided parameters for each processed entry.",
    "filter_prorec_aug_sum": "Iterates through device entries, skips inactive ones, processes active entries, and applies two computation routines using provided double-precision parameters.",
    "work_score": {
        "prorec_aug": {
            "summary": "Iterates through device entries, skips inactive ones, processes active entries, and invokes two routines with provided parameters for each processed entry.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary misrepresents the code: it claims active entries are processed, whereas the function deallocates inactive consoles, sets pointers to NULL for busy consoles, and then frees resources for specific inactive entries. The described 'two routines with provided parameters' is too generic and ignores actual functions and conditions in the code, leading to multiple inaccurate claims with very limited accurate correspondence.",
                "The summary misrepresents the code's logic: in the source, the function iterates from index 1 to MAX_NR_CONSOLES, deallocating consoles that are not busy, and later destroying and freeing them if they exist and meet a minimum index. The summary incorrectly says it skips inactive ones and processes active entries, which is the opposite of the actual condition, and omits specifics like MIN_NR_CONSOLES check, locking, and memory freeing. This means the core purpose\u2014disallocating all unused virtual consoles\u2014is not captured.",
                "The summary contains multiple inaccuracies: it inverts the active/inactive logic, claiming inactive entries are skipped and active ones are processed, whereas the code processes inactive consoles (via vc_deallocate) and skips busy ones. It also misstates call patterns, omitting details like the two-phase processing and use of console_lock/unlock, and incorrectly implies parameters are provided externally. This is a FATAL error on the primary purpose (processing criteria) of the function, making it untrustworthy. There is very little accurate content remaining beyond generic iteration language."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Iterates through device entries, skips inactive ones, processes active entries, and applies two computation routines using provided double-precision parameters.",
            "score": [
                0.2,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about iterating through device entries, skipping inactive ones, and processing active ones align partially with the source code's loop structure and conditional handling based on VT_BUSY. However, references to double-precision parameters and computation routines are entirely unrelated to the function's actual behavior, which deals with console data structures, locking, deallocation, and freeing memory. Most claims are inaccurate regarding the source code semantics.",
                "The summary's claims about iterating through device entries, processing active entries, and applying computation routines with double-precision parameters are inaccurate with respect to the source code. The function actually iterates through virtual console instances, skips busy ones, deallocates inactive ones, destroys TTY ports, and frees memory\u2014no double-precision parameters or computation routines are involved. The core purpose of deallocating virtual consoles is entirely missing, and there is no accurate coverage of the key semantics.",
                "The summary claims iteration over device entries, skipping inactive ones, processing active entries, and applying two computation routines with double-precision parameters. In the source code, the function iterates over console indices, skips busy ones, deallocates inactive consoles, then destroys ports and frees memory. There is no handling of double-precision parameters or computation routines, and the active/inactive logic is inverted relative to the summary. This is a severe FATAL error on the primary purpose and core behavior, making the description unusable."
            ]
        }
    }
}
{
    "source_code": "\nvoid FAST_FUNC bb_herror_msg(const char *s, ...)\n{\n\tva_list p;\n\n\tva_start(p, s);\n\tbb_verror_msg(s, p, hstrerror(h_errno));\n\tva_end(p);\n}",
    "comment": "Formats and displays an error message using a variable argument list and the current error description from `hstrerror(h_errno)`.",
    "prorec_sum": "Prepares structured parameters and vector data, then invokes a downstream routine to process them with retrieved configuration and floating\u2011point values.",
    "filter_prorec_sum": "Prepares structured parameters and floating\u2011point values before invoking a downstream routine to process data with retrieved configuration and formatting context.",
    "prorec_aug_sum": "Prepares structured parameter data and forwards multiple 128-bit vector and floating-point values to a downstream processing routine for further handling.",
    "filter_prorec_aug_sum": "Prepares vector and scalar parameters, retrieves configuration data, and invokes a processing routine to handle structured output based on the provided inputs.",
    "work_score": {
        "prorec_aug": {
            "summary": "Prepares structured parameter data and forwards multiple 128-bit vector and floating-point values to a downstream processing routine for further handling.",
            "score": [
                0.0,
                0.1,
                0.0
            ],
            "reason": [
                "The summary\u2019s claims about handling 128-bit vector and floating-point values are unrelated to the actual source code, which deals with preparing a variable argument list and passing an error string to another function. None of the claims accurately reflect the function\u2019s true domain behavior, resulting in zero alignment with the evaluation steps.",
                "The summary\u2019s claims describe handling 128-bit vector and floating-point values for downstream processing, which is unrelated to the source code\u2019s actual function of formatting and forwarding an error message using `hstrerror` and `bb_verror_msg`. The core purpose of propagating an error message with strerror-like resolution of `h_errno` is not covered at all, and all claims are inaccurate as they refer to unrelated data types and behavior.",
                "The summary's claims about preparing structured parameter data and forwarding multiple 128-bit vector and floating-point values are completely unrelated to the source code, which handles variable arguments and passes an error message along with an h_errno-derived string to another function. All claims are NOISE, with no accurate domain-relevant content, resulting in no positive gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Prepares vector and scalar parameters, retrieves configuration data, and invokes a processing routine to handle structured output based on the provided inputs.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary's claims about preparing vector and scalar parameters, retrieving configuration data, and handling structured output do not match the actual function, which only processes variadic arguments and calls an error logging routine with a network error string. All claims are unrelated to the code's real semantics, resulting in no accurate statements.",
                "The summary does not reflect the core purpose of the function, which is to format and output an error message related to the current h_errno using bb_verror_msg. None of its claims match the source code's semantics, instead referencing preparation of parameters, configuration retrieval, and structured output handling, which are unrelated. This results in no coverage of the core operation or any secondary details.",
                "The summary's claims about preparing vector/scalar parameters, retrieving configuration data, and handling structured output do not match the source code, which formats and displays an error message using hstrerror and varargs. All claims are inaccurate (NOISE) with no accurate alignment to the function's actual purpose. The noise overwhelms (no factual alignment), and there is no gain for understanding the code."
            ]
        }
    }
}
{
    "source_code": "int sysfs_merge_group(struct kobject *kobj,\n\t\t       const struct attribute_group *grp)\n{\n\tstruct sysfs_dirent *dir_sd;\n\tint error = 0;\n\tstruct attribute *const *attr;\n\tint i;\n\n\tdir_sd = sysfs_get_dirent(kobj->sd, NULL, grp->name);\n\tif (!dir_sd)\n\t\treturn -ENOENT;\n\n\tfor ((i = 0, attr = grp->attrs); *attr && !error; (++i, ++attr))\n\t\terror = sysfs_add_file(dir_sd, *attr, SYSFS_KOBJ_ATTR);\n\tif (error) {\n\t\twhile (--i >= 0)\n\t\t\tsysfs_hash_and_remove(dir_sd, NULL, (*--attr)->name);\n\t}\n\tsysfs_put(dir_sd);\n\n\treturn error;\n}",
    "comment": "Merges a specified attribute group into a kobject's sysfs directory, adding attributes and handling errors by removing any added attributes on failure.",
    "prorec_sum": "Traverses and processes a list of filesystem-related entries, performing conditional updates and cleanup, and returns a status code for the last processed entry.",
    "filter_prorec_sum": "Processes a list of inode extended attributes, updating entries as needed, and releases resources with reference counting before returning success or error status.",
    "prorec_aug_sum": "Initializes an object, iterates linked entries performing conditional operations, and releases resources, returning a status code indicating the first successful operation.",
    "filter_prorec_aug_sum": "Processes a list of objects by invoking comparison and cleanup routines, returning a status code, and freeing resources using reference counting.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes an object, iterates linked entries performing conditional operations, and releases resources, returning a status code indicating the first successful operation.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains mostly inaccurate claims: the function does not initialize an object, it iterates over an array of attributes rather than linked entries, and it returns an error code for the first failure, not success. While it does release resources and return a status code, more than half of the claims contradict the source code\u2019s behavior.",
                "The summary fails to capture the core purpose of merging an attribute group into a sysfs directory. It inaccurately describes the return value as indicating the first successful operation, whereas the function returns an error code or zero. It also omits essential semantics such as checking for the directory's existence, adding files, handling errors by removing added entries, and interacting with sysfs internals. The description is vague ('initializes an object' and 'conditional operations') and does not reflect the specific domain behavior found in the source code.",
                "The summary contains a major factual inaccuracy: it states the function returns a status code indicating the first successful operation, but in reality it returns 0 on success or an error code on the first failure. This is a FATAL error about the function\u2019s core output contract. Other claims, like 'initializes an object' and 'releases resources,' are vague and inaccurate: the code retrieves an existing sysfs dirent rather than initializing an object, and the iteration is over an array not 'linked entries'. These issues mean the summary misrepresents key behavior and offers little accurate, specific detail."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes a list of objects by invoking comparison and cleanup routines, returning a status code, and freeing resources using reference counting.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function processes a list of objects using comparison routines and reference-counted cleanup, which does not align with the source code. The actual code retrieves a sysfs directory entry, iterates over a list of attributes, adds files, removes them on error, and calls sysfs_put for cleanup. There is no comparison routine or generic object list processing as described; the claim about reference counting is partially accurate only due to sysfs_put usage. Most claims are inaccurate, leading to low alignment.",
                "The summary does not correctly identify the core purpose of merging an attribute group into an existing sysfs directory for a given kobject. Instead, it inaccurately describes generic processing of objects with comparison routines, which is not present in the source. There is no [ACCURATE] claim that matches the function\u2019s actual domain-specific behavior, and coverage of secondary details such as adding files, error rollback, and reference counting (sysfs_put) is absent or misstated.",
                "The summary contains mostly inaccurate claims about the function's semantics. It describes processing a list of objects with comparison routines, which is not reflected in the source; the code actually iterates over attribute pointers, adding them to a sysfs directory and removing them if errors occur. 'Comparison routines' and 'reference counting' are misleading; only sysfs_put handles refcounting, but in a specific sysfs context. There is no object comparison logic present. These errors target the core purpose, making them FATAL to understanding. Accurate detail about returning a status code is too generic to salvage net benefit."
            ]
        }
    }
}
{
    "source_code": "static int __kprobes write_mem(unsigned long val, unsigned long ea, int nb,\n\t\t\t       struct pt_regs *regs)\n{\n\tif (!address_ok(regs, ea, nb))\n\t\treturn -EFAULT;\n\tif ((ea & (nb - 1)) == 0)\n\t\treturn write_mem_aligned(val, ea, nb);\n\treturn write_mem_unaligned(val, ea, nb, regs);\n}",
    "comment": "Writes specified bytes from a buffer to a target object's memory section, logging the operation if enabled.",
    "prorec_sum": "Reads data in page-aligned chunks from a mapped memory region into a buffer, updating the offset and enforcing address range limits.",
    "filter_prorec_sum": "Reads data in page-aligned chunks from a source into memory, updating the offset and aborting if allocation or read fails.",
    "prorec_aug_sum": "Copies data in page-aligned chunks from a source address to a destination memory range, updating the offset and enforcing hardware address limits.",
    "filter_prorec_aug_sum": "Copies data in page-aligned chunks from a source buffer into a destination memory range, updating the offset pointer and enforcing address limit checks.",
    "work_score": {
        "prorec_aug": {
            "summary": "Copies data in page-aligned chunks from a source address to a destination memory range, updating the offset and enforcing hardware address limits.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function copies data in page-aligned chunks from a source to a destination and enforces hardware address limits, but the source code shows it simply writes a given value to a specified address with alignment checks and address validation, not performing chunked copying or updating offsets. All claims are inaccurate as they misrepresent the function\u2019s purpose and behavior.",
                "The summary's main claim about copying page-aligned chunks from a source to a destination and updating offsets does not align with the core purpose of the function, which is to write a given value to a target memory address only if it is a valid address, delegating to either aligned or unaligned write routines. There is no mention of the address validity check, alignment calculation, or branching into specific write functions, and the described behavior of copying page-aligned chunks and enforcing hardware limits is inaccurate for the given code.",
                "The summary\u2019s claims about copying data in page-aligned chunks, using a source/destination memory range, updating offsets, and enforcing hardware address limits are inaccurate relative to the source code. The function actually writes a value to a specified effective address with size checks and alignment handling, not copying between ranges. These are FATAL errors on the primary purpose and key I/O behavior, making the description misleading and unusable."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Copies data in page-aligned chunks from a source buffer into a destination memory range, updating the offset pointer and enforcing address limit checks.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains multiple inaccurate claims. It describes copying data in page-aligned chunks from a source buffer to a destination range and updating an offset pointer\u2014none of which are reflected in the source code. The actual function writes a single value to memory, checks address validity, and delegates to aligned or unaligned write helpers without any explicit page alignment or buffer copying. Only the mention of enforcing an address limit check roughly corresponds to the address_ok call. Most claims target semantics but contradict the implementation, resulting in under 50% accuracy.",
                "The summary describes copying page-aligned chunks from a source buffer, updating an offset pointer, and enforcing address limit checks, which does not match the source code. The function instead validates an address range using `address_ok`, then delegates to either `write_mem_aligned` or `write_mem_unaligned` based on alignment. The core purpose of writing a value to memory with alignment handling is missing, and the provided details about page alignment and buffer copying are inaccurate relative to the code.",
                "The summary makes several semantic claims about copying data from a source buffer to a destination in page-aligned chunks, updating an offset pointer, and enforcing address limit checks. None of these align with the actual source code behavior, which writes a given value to a specified address, first validating the address and choosing between aligned and unaligned write functions. The core purpose and I/O in the summary are incorrect, making these FATAL inaccuracies about the primary function behavior."
            ]
        }
    }
}
{
    "source_code": "\nstatic int __init i8042_create_aux_port(int idx)\n{\n\tstruct serio *serio;\n\tint port_no = idx < 0 ? I8042_AUX_PORT_NO : I8042_MUX_PORT_NO + idx;\n\tstruct i8042_port *port = &i8042_ports[port_no];\n\n\tserio = kzalloc(sizeof(struct serio), GFP_KERNEL);\n\tif (!serio)\n\t\treturn -ENOMEM;\n\n\tserio->id.type\t\t= SERIO_8042;\n\tserio->write\t\t= i8042_aux_write;\n\tserio->start\t\t= i8042_start;\n\tserio->stop\t\t= i8042_stop;\n\tserio->port_data\t= port;\n\tserio->dev.parent\t= &i8042_platform_device->dev;\n\tif (idx < 0) {\n\t\tstrlcpy(serio->name, \"i8042 AUX port\", sizeof(serio->name));\n\t\tstrlcpy(serio->phys, I8042_AUX_PHYS_DESC, sizeof(serio->phys));\n\t\tserio->close = i8042_port_close;\n\t} else {\n\t\tsnprintf(serio->name, sizeof(serio->name), \"i8042 AUX%d port\", idx);\n\t\tsnprintf(serio->phys, sizeof(serio->phys), I8042_MUX_PHYS_DESC, idx + 1);\n\t}\n\n\tport->serio = serio;\n\tport->mux = idx;\n\tport->irq = I8042_AUX_IRQ;\n\n\treturn 0;\n}",
    "comment": "Initializes an i8042 auxiliary port, allocating a serio structure and configuring it for communication with the specified input device.",
    "prorec_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) port device, assigning handlers, naming paths, and updating global controller state arrays.",
    "filter_prorec_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) serio port with appropriate handlers and device names based on the provided port index.",
    "prorec_aug_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) serio port structure with appropriate handlers, names, and global table entries based on the port index.",
    "filter_prorec_aug_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) port device, assigning handlers, identifiers, and storing it in global controller structures.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes and registers an i8042 AUX (PS/2 mouse) serio port structure with appropriate handlers, names, and global table entries based on the port index.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function initializes an i8042 AUX serio port structure and sets appropriate handlers, names, and table entries depending on the index, which matches the code parts setting type, write/start/stop handlers, name/phys fields conditionally, and storing into the global port array. However, it inaccurately claims the port is 'registered', which is not present in the code \u2014 there is only initialization and assignment to structures, no registration call. This keeps most claims accurate but includes a notable semantic overreach.",
                "The summary accurately reflects the function's core purpose of initializing an i8042 AUX serio port structure with handlers, names, and entries based on the index, which matches the code's primary behavior. However, it incorrectly includes 'registers', which the function does not perform, and omits certain secondary details like allocation failure handling, setting parent device, configuring mux/IRQ, and differences between AUX and MUX naming/physical descriptors. This limits completeness despite core coverage.",
                "The summary correctly states the function initializes an i8042 AUX serio port structure, assigns handlers, names, and entries based on index. These are accurate to the code, which sets up the 'serio' structure fields, chooses names depending on idx, and updates the global i8042_ports table. No false or irrelevant claims are present, but the description is broad and omits specifics on memory allocation, parent device linking, and exact fields set, resulting in low informational gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes and registers an i8042 AUX (PS/2 mouse) port device, assigning handlers, identifiers, and storing it in global controller structures.",
            "score": [
                0.8,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function initializes an i8042 AUX port device and assigns handlers and identifiers, and it also stores the port in global structures, which is evident from the serio field setups and assignments to the i8042_ports array. However, it inaccurately claims that the function registers the device \u2014 there is no registration logic in the code (e.g., no call to serio_register_port or similar). This makes most of the claims accurate except for the registration part, resulting in slightly less than full precision.",
                "The summary accurately notes initialization of an i8042 AUX port device, assignment of handlers, and storage in global controller structures, aligning with the code\u2019s setup of a serio struct, linking it to i8042_ports, and configuring handlers and IDs. However, it incorrectly claims the port is 'registered', which is not present in the function\u2014it only allocates, initializes, and stores the serio object without calling any registration routine. The core purpose (initialize an i8042 AUX port structure and associate it with controller data) is covered, but secondary details like conditional naming for primary auxiliary vs. multiplexed port, error handling on allocation failure, and setting constants (IRQ, mux index) are missing or glossed over.",
                "The summary claims the function registers the AUX port device, but the source code only allocates, initializes, and assigns handlers and data structures\u2014it does not perform registration. The initialization, handler assignment, and storing in global structures are accurate GOLD claims. The single inaccurate element is the mention of registration, which is a FATAL error regarding the primary purpose as it misstates what the function does at its core."
            ]
        }
    }
}
{
    "source_code": "long keyctl_keyring_unlink(key_serial_t id, key_serial_t ringid)\n{\n\tkey_ref_t keyring_ref, key_ref;\n\tlong ret;\n\n\tkeyring_ref = lookup_user_key(ringid, 0, KEY_WRITE);\n\tif (IS_ERR(keyring_ref)) {\n\t\tret = PTR_ERR(keyring_ref);\n\t\tgoto error;\n\t}\n\n\tkey_ref = lookup_user_key(id, KEY_LOOKUP_FOR_UNLINK, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = PTR_ERR(key_ref);\n\t\tgoto error2;\n\t}\n\n\tret = key_unlink(key_ref_to_ptr(keyring_ref), key_ref_to_ptr(key_ref));\n\n\tkey_ref_put(key_ref);\nerror2:\n\tkey_ref_put(keyring_ref);\nerror:\n\treturn ret;\n}",
    "comment": "Unlinks a key from a specified keyring after verifying the existence of both the key and the keyring.",
    "prorec_sum": "Allocates two memory pages for cryptographic operations, processes them with provided parameters, and returns a result or an allocation pointer.",
    "filter_prorec_sum": "Allocates two memory pages for cryptographic processing, performs computations on them using provided double parameters, and returns the final processed page reference.",
    "prorec_aug_sum": "Processes two memory-mapped objects by applying computation functions with given double parameters and returns a status or updated reference address.",
    "filter_prorec_aug_sum": "Processes two numeric handles, performs linked operations using provided floating-point parameters, updates both resources, and returns the final resulting handle value.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes two memory-mapped objects by applying computation functions with given double parameters and returns a status or updated reference address.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims that the function processes memory-mapped objects with computation functions and double parameters, returning a status or updated reference. None of these details match the source code, which actually manipulates keyrings and keys through lookup and unlink operations without memory mapping or double parameters. All claims are inaccurate, resulting in no alignment with the function's domain-specific behavior.",
                "The summary's claims about processing two memory-mapped objects with computation functions and double parameters are entirely inaccurate relative to the source code, which actually looks up two keys, unlinks one from a keyring, and handles reference counting and error checks. The core purpose of unlinking a key from a keyring is not covered, and there is no mention of critical secondary behaviors like key lookup modes, error handling, or resource release.",
                "The summary is entirely inaccurate: it describes processing of memory-mapped objects with double parameters, which is unrelated to the actual code. The function in the source handles unlinking a key from a keyring via kernel key management, using key lookups, unlink operation, and returning a status code. This mismatch is a severe FATAL error affecting the primary purpose and I/O description, making the summary untrustworthy."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes two numeric handles, performs linked operations using provided floating-point parameters, updates both resources, and returns the final resulting handle value.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains multiple inaccurate claims: it describes processing 'numeric handles' and 'floating-point parameters', updating both resources, and returning a handle value, none of which aligns with the function's actual semantics. The code deals with key serial numbers, key lookup and unlink operations, and returns a long status code. None of the claims in the summary accurately represent the domain-specific behavior present in the source code, resulting in very low accuracy.",
                "The summary's claims about numeric handles and floating-point parameters are inaccurate, as the source code deals with key_serial_t identifiers for keys and keyrings, not floating-point parameters. It also fails to capture the core purpose, which is to look up a keyring and a key by ID and unlink the key from the keyring. No accurate claims cover the actual domain-specific action or error handling present in the code.",
                "The summary contains multiple inaccurate claims about the function's behavior. It describes 'numeric handles' used with 'floating-point parameters', 'updates both resources', and 'returns the final resulting handle value', none of which match the source code. The code actually operates on keyring and key IDs (likely integer types), performs lookups with specific access rights, unlinks a key from a keyring, and returns a long status/error code. These mismatches are severe FATAL errors affecting the primary purpose and key I/O, leaving no accurate or useful information."
            ]
        }
    }
}
{
    "source_code": "\nbool ssh2_common_filter_queue(PacketProtocolLayer *ppl)\n{\n    static const char *const ssh2_disconnect_reasons[] = {\n        NULL,\n        \"host not allowed to connect\",\n        \"protocol error\",\n        \"key exchange failed\",\n        \"host authentication failed\",\n        \"MAC error\",\n        \"compression error\",\n        \"service not available\",\n        \"protocol version not supported\",\n        \"host key not verifiable\",\n        \"connection lost\",\n        \"by application\",\n        \"too many connections\",\n        \"auth cancelled by user\",\n        \"no more auth methods available\",\n        \"illegal user name\",\n    };\n\n    PktIn *pktin;\n    ptrlen msg;\n    int reason;\n\n    while ((pktin = pq_peek(ppl->in_pq)) != NULL) {\n        switch (pktin->type) {\n          case SSH2_MSG_DISCONNECT:\n            reason = get_uint32(pktin);\n            msg = get_string(pktin);\n\n            ssh_remote_error(\n                ppl->ssh, \"Remote side sent disconnect message\\n\"\n                \"type %d (%s):\\n\\\"%.*s\\\"\", reason,\n                ((reason > 0 && reason < lenof(ssh2_disconnect_reasons)) ?\n                 ssh2_disconnect_reasons[reason] : \"unknown\"),\n                PTRLEN_PRINTF(msg));\n            /* don't try to pop the queue, because we've been freed! */\n            return true;               /* indicate that we've been freed */\n\n          case SSH2_MSG_DEBUG:\n            /* XXX maybe we should actually take notice of the return value */\n            get_bool(pktin);\n            msg = get_string(pktin);\n            ppl_logevent(\"Remote debug message: %.*s\", PTRLEN_PRINTF(msg));\n            pq_pop(ppl->in_pq);\n            break;\n\n          case SSH2_MSG_IGNORE:\n            /* Do nothing, because we're ignoring it! Duhh. */\n            pq_pop(ppl->in_pq);\n            break;\n\n          default:\n            return false;\n        }\n    }\n\n    return false;\n}",
    "comment": "Processes incoming SSH2 packets, handling disconnect messages, debug messages, and ignores messages, while managing packet queue operations.",
    "prorec_sum": "Processes incoming messages from a connection, dispatching type\u2011specific handlers and invoking callbacks to handle control or command data until no more messages remain.",
    "filter_prorec_sum": "Processes successive command responses from an SSH-related connection context, handling specific message types and invoking appropriate callbacks for type\u20111 and type\u20114 events.",
    "prorec_aug_sum": "Processes event codes from a session handler, executing specific callbacks for recognized codes and terminating on unhandled or null events.",
    "filter_prorec_aug_sum": "Processes command codes from an input handler, executing associated actions or callbacks until no more commands are available.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes event codes from a session handler, executing specific callbacks for recognized codes and terminating on unhandled or null events.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary inaccurately describes the function's behavior. It mentions processing event codes from a session handler and terminating on null events, but the source code shows it handles specific SSH2 message types (DISCONNECT, DEBUG, IGNORE) from a packet queue, logs or ignores them accordingly, and returns true or false based on the message type. There is no generic 'session handler' or 'callbacks' abstraction, and no special handling of 'null events' as described. The majority of claims are not aligned with the actual code semantics, resulting in low accuracy.",
                "The summary describes generic event code processing with callbacks and termination on unhandled events, but it fails to mention the core purpose of handling specific SSH2 message types such as DISCONNECT, DEBUG, and IGNORE, nor does it reflect the error logging, queue manipulation, or the disconnect reason mapping present in the code. It is overly abstract, missing the concrete domain wording and key secondary behaviors tied to SSH protocol handling.",
                "The summary incorrectly describes the function as processing event codes from a session handler with callbacks and terminating on unhandled or null events. In the source, the function processes specific SSH2 message types from an input packet queue, logs or handles disconnects, debug, and ignore messages, and returns based on the outcome. The mention of 'callbacks' is inaccurate, and the 'null events' concept does not match the code. This is a FATAL error affecting the primary purpose description, leaving no accurate claims of the core logic."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes command codes from an input handler, executing associated actions or callbacks until no more commands are available.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function processes command codes from an input handler and executes associated actions or callbacks until no more commands are available. While the source code does loop over incoming packets and processes them based on type, there is no explicit concept of 'command codes' or 'callbacks' in the implementation. The actual function handles specific SSH2 message types with concrete actions like logging errors, ignoring certain messages, and returning early on disconnects, not generic command execution. The claim is too generic, misses key SSH-specific details, and introduces inaccurate terminology, resulting in a low proportion of accurate statements.",
                "The summary provides a vague description of processing commands from an input handler but does not accurately capture the core domain-specific purpose of handling specific SSH2 message types (DISCONNECT, DEBUG, IGNORE), logging events, reporting remote errors, and managing the input packet queue. It misses concrete protocol context, specific actions per message type, and side effects such as returning true when disconnected. The core purpose is therefore not covered, and there is minimal accurate secondary detail.",
                "The summary claims that the function processes command codes from an input handler and executes associated actions or callbacks until no more commands are available. While it loosely resembles the loop over packet types, it is inaccurate because the function specifically handles SSH2 protocol message types (DISCONNECT, DEBUG, IGNORE), not generic command codes, and its behavior includes logging, error reporting, and queue handling based on message type. The conflation of packet processing with generic command execution is a semantic mismatch targeting code behavior (FATAL) related to the primary purpose."
            ]
        }
    }
}
{
    "source_code": "\nint __net_init fib4_rules_init(struct net *net)\n{\n\tint err;\n\tstruct fib_rules_ops *ops;\n\n\tops = fib_rules_register(&fib4_rules_ops_template, net);\n\tif (IS_ERR(ops))\n\t\treturn PTR_ERR(ops);\n\n\terr = fib_default_rules_init(ops);\n\tif (err < 0)\n\t\tgoto fail;\n\tnet->ipv4.rules_ops = ops;\n\tnet->ipv4.fib_has_custom_rules = false;\n\treturn 0;\n\nfail:\n\t/* also cleans all rules already added */\n\tfib_rules_unregister(ops);\n\treturn err;\n}",
    "comment": "Initializes IPv4 fib rules for a specified network, registering operations and setting default rules, or cleaning up on failure.",
    "prorec_sum": "Initializes a socket-related structure and performs three configuration steps, cleaning up and returning an error if any step fails.",
    "filter_prorec_sum": "Initializes a socket-related structure with multiple configuration steps, aborting on failure, and stores it in the given context structure.",
    "prorec_aug_sum": "Initializes a network-related structure with multiple configuration steps and stores it in the given context, cleaning up if any initialization stage fails.",
    "filter_prorec_aug_sum": "Initializes a network-related structure with multiple configuration calls, cleans up on error, and stores the result pointer into the given context object.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes a network-related structure with multiple configuration steps and stores it in the given context, cleaning up if any initialization stage fails.",
            "score": [
                0.9,
                0.2,
                0.5
            ],
            "reason": [
                "The summary correctly describes that the function performs initialization, involves multiple steps, stores the result in the provided context (`net`), and includes cleanup on failure, all of which align with the source code\u2019s behavior. Although it is generic and lacks specifics like `fib_rules_register` or `fib_default_rules_init`, the core semantics are accurate and no incorrect claims are present.",
                "The summary conveys a generic idea of initializing a structure with cleanup on failure, which is somewhat accurate but lacks the specific core purpose of registering IPv4 FIB rules and setting default rules for a given network namespace. This omission means the domain-specific operation is not covered, and secondary behaviors such as the exact calls to fib_rules_register/fib_default_rules_init, the setting of fib_has_custom_rules, and the specific error handling via goto fail are not described. The phrasing is too generic to reflect the distinctive functionality present in the source.",
                "The summary contains mostly generic statements about initialization and cleanup, which are accurate but low-information and do not capture specific domain details such as the use of fib_rules_register, fib_default_rules_init, or setting ipv4-specific fields. There are no contradictory or irrelevant claims, but the lack of specificity limits its usefulness. The worst failure mode is low informational gain due to broad SAFE claims."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes a network-related structure with multiple configuration calls, cleans up on error, and stores the result pointer into the given context object.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary contains three main claims: initialization of a network-related structure, cleanup on error, and storing a result pointer into the given context. All three are supported by the code: the function calls registration and initialization functions for IPv4 rules (initialization), invokes cleanup via fib_rules_unregister on failure (cleanup), and assigns the registered ops pointer to net->ipv4.rules_ops (storing result). The description is abstract but aligns well with the code behavior, with no inaccuracies found.",
                "The summary makes accurate but generic claims about initialization, cleanup on error, and storing a pointer to a context object, which generally align with the code's structure. However, it does not specifically capture the core purpose of registering IPv4 FIB rules and initializing default rules, which is the distinctive domain action in the source code. Secondary details such as setting fib_has_custom_rules to false are also omitted.",
                "The summary correctly identifies that the function initializes a network-related structure, invokes multiple configuration calls, performs cleanup on error, and stores a pointer in the context object. These are all accurate, verifiable behaviors from the source code. However, the description is quite generic, missing specific details such as the exact operations (fib_rules_register, fib_default_rules_init), the context being the 'net->ipv4' structure, and the setting of 'fib_has_custom_rules' to false. No inaccurate or contradictory claims are present, but the level of detail is limited, which reduces the overall gain."
            ]
        }
    }
}
{
    "source_code": "static int whereLoopCheaperProperSubset(\n  const WhereLoop *pX,       /* First WhereLoop to compare */\n  const WhereLoop *pY        /* Compare against this WhereLoop */\n){\n  int i, j;\n  if( pX->nLTerm-pX->nSkip >= pY->nLTerm-pY->nSkip ){\n    return 0; /* X is not a subset of Y */\n  }\n  if( pY->nSkip > pX->nSkip ) return 0;\n  if( pX->rRun >= pY->rRun ){\n    if( pX->rRun > pY->rRun ) return 0;    /* X costs more than Y */\n    if( pX->nOut > pY->nOut ) return 0;    /* X costs more than Y */\n  }\n  for(i=pX->nLTerm-1; i>=0; i--){\n    if( pX->aLTerm[i]==0 ) continue;\n    for(j=pY->nLTerm-1; j>=0; j--){\n      if( pY->aLTerm[j]==pX->aLTerm[i] ) break;\n    }\n    if( j<0 ) return 0;  /* X not a subset of Y since term X[i] not used by Y */\n  }\n  return 1;  /* All conditions meet */\n}",
    "comment": "Determines if WhereLoop `pX` is a proper subset of WhereLoop `pY` based on terms, costs, and skip values.",
    "prorec_sum": "Checks positional bounds and verifies matching 64\u2011bit entries between two indexed arrays, returning success only if all compared elements satisfy the match criteria.",
    "filter_prorec_sum": "Checks coordinate and index ranges, then validates corresponding entries in two arrays for equality before confirming a sequential match.",
    "prorec_aug_sum": "Checks positional bounds and verifies that corresponding entries in two indexed 2D data arrays match across a specified rectangular region.",
    "filter_prorec_aug_sum": "Checks positional bounds and verifies matching 64\u2011bit entries between two arrays, returning success if all compared elements satisfy the match criteria.",
    "work_score": {
        "prorec_aug": {
            "summary": "Checks positional bounds and verifies that corresponding entries in two indexed 2D data arrays match across a specified rectangular region.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary describes checking positional bounds and matching entries in 2D arrays over a rectangular region, which is unrelated to the actual function. The source code compares properties of two WhereLoop structures to determine if one is a cheaper proper subset of the other. All claims in the summary are inaccurate because they target semantics that do not exist in the code.",
                "The summary claims the function checks positional bounds and matches entries in 2D arrays over a region, which does not align with the source code's actual operation of comparing two WhereLoop structures to determine if one is a cheaper proper subset of the other based on term matches and cost metrics. The stated action is completely unrelated to the core purpose, and no accurate claims cover the primary semantic or any secondary details.",
                "The summary claims the function checks positional bounds and matches entries in two indexed 2D data arrays over a rectangular region, but the source code actually compares two WhereLoop structures for subset relationships and cost metrics. This is a completely different operation, constituting a severe factual error about the primary purpose (FATAL) and making the summary unusable. No accurate claims are present."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Checks positional bounds and verifies matching 64\u2011bit entries between two arrays, returning success if all compared elements satisfy the match criteria.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function checks positional bounds and compares 64-bit entries between two arrays, but the source code actually compares properties of two WhereLoop structures, including term counts, skip counts, run costs, and matching term pointers. There is no indication of 64-bit entries nor generic array bounds checks. All claims in the summary misrepresent the actual semantics, resulting in no accurate claims.",
                "The summary focuses on positional bounds and matching 64\u2011bit array entries, which misrepresents the core purpose of determining if one WhereLoop is a cheaper proper subset of another using term counts, skip values, run cost, output count, and membership checks. The actual comparison is not about generic 64\u2011bit array entries but about specific struct fields and logical subset criteria. This means the core domain-specific purpose is entirely missing and the described behavior is inaccurate.",
                "The summary claims the function checks positional bounds and matches 64-bit entries between two arrays, which is inaccurate and constitutes FATAL errors regarding the core purpose. The actual function compares two WhereLoop structures to determine if the first is a cheaper proper subset of the second using multiple conditions on fields like nLTerm, nSkip, rRun, nOut, and shared aLTerm elements. There is no mention of WhereLoop subset logic in the summary, and the focus on 64-bit array element comparison is not present in the code, severely misrepresenting the primary functionality."
            ]
        }
    }
}
{
    "source_code": "\nacpi_status acpi_ut_mutex_initialize(void)\n{\n\tu32 i;\n\tacpi_status status;\n\n\tACPI_FUNCTION_TRACE(ut_mutex_initialize);\n\n\t/* Create each of the predefined mutex objects */\n\n\tfor (i = 0; i < ACPI_NUM_MUTEX; i++) {\n\t\tstatus = acpi_ut_create_mutex(i);\n\t\tif (ACPI_FAILURE(status)) {\n\t\t\treturn_ACPI_STATUS(status);\n\t\t}\n\t}\n\n\t/* Create the spinlocks for use at interrupt level or for speed */\n\n\tstatus = acpi_os_create_lock (&acpi_gbl_gpe_lock);\n\tif (ACPI_FAILURE (status)) {\n\t\treturn_ACPI_STATUS (status);\n\t}\n\n\tstatus = acpi_os_create_lock (&acpi_gbl_hardware_lock);\n\tif (ACPI_FAILURE (status)) {\n\t\treturn_ACPI_STATUS (status);\n\t}\n\n\tstatus = acpi_os_create_lock(&acpi_gbl_reference_count_lock);\n\tif (ACPI_FAILURE(status)) {\n\t\treturn_ACPI_STATUS(status);\n\t}\n\n\t/* Mutex for _OSI support */\n\n\tstatus = acpi_os_create_mutex(&acpi_gbl_osi_mutex);\n\tif (ACPI_FAILURE(status)) {\n\t\treturn_ACPI_STATUS(status);\n\t}\n\n\t/* Create the reader/writer lock for namespace access */\n\n\tstatus = acpi_ut_create_rw_lock(&acpi_gbl_namespace_rw_lock);\n\treturn_ACPI_STATUS(status);\n}",
    "comment": "Initializes predefined mutexes and locks for synchronization, including mutexes for _OSI support and a reader/writer lock for namespace access.",
    "prorec_sum": "Iterates over a table of region descriptors, allocates and initializes buffers for each, and invokes setup routines for final region configuration.",
    "filter_prorec_sum": "Initializes or allocates multiple EFI-related data structures and invokes setup routines until successful, returning an error code if allocation or initialization fails.",
    "prorec_aug_sum": "Allocates and initializes multiple data buffers, iterating through a table array and invoking helper routines until successful or returning an error code.",
    "filter_prorec_aug_sum": "Initializes or allocates multiple data structures sequentially and invokes a setup routine, returning an error code if any allocation or initialization fails.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and initializes multiple data buffers, iterating through a table array and invoking helper routines until successful or returning an error code.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains claims about allocating and initializing multiple data buffers and iterating through a table array, which are inaccurate given the source code. The function actually creates mutexes, locks, and a reader/writer lock, not data buffers. While it does iterate over an index to create mutexes and returns on failure, most claims misrepresent the domain semantics. The proportion of accurate claims is well below half.",
                "The summary\u2019s primary claim that the function allocates and initializes data buffers by iterating through a table array is inaccurate relative to the source code, which instead initializes predefined mutexes and various locks. There is no mention of buffers or table arrays in the code, and the summary fails to capture the core purpose of setting up synchronization primitives with error handling. No accurate claims align with the core domain action, and no secondary details are correct.",
                "The summary inaccurately describes the function's primary purpose. The code initializes mutexes and locks, but the summary claims it allocates and initializes multiple data buffers and iterates through a table array, which is unrelated to the actual implementation. This is a severe FATAL error concerning the core action (WHAT) of the function, making the description misleading and unusable despite no accurate claims being present."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes or allocates multiple data structures sequentially and invokes a setup routine, returning an error code if any allocation or initialization fails.",
            "score": [
                0.8,
                0.2,
                0.5
            ],
            "reason": [
                "The summary correctly captures the sequential initialization of multiple resources and the behavior of returning on failure, which matches the looped mutex creation and subsequent lock/mutex/rw lock creations in the source code. However, it inaccurately describes these as 'data structures' rather than synchronization primitives (mutexes, locks), making it imprecise in terms of domain semantics. Despite this, most of the content is accurate and relevant to the code's behavior, with only minor terminology issues.",
                "The summary fails to capture the core domain-specific purpose, which is initializing ACPI mutexes, spinlocks, and related synchronization primitives for ACPI operations. Instead, it uses vague terms like 'multiple data structures' and 'setup routine' with no mention of locks or ACPI. While it does generally capture the control flow of sequential initialization and early return on failure, this is generic and omits the concrete operations and resources involved, as well as the types of locks and their usage purposes.",
                "The summary correctly notes sequential initialization and error handling, which matches the loop creating mutexes and the checks returning status. However, it inaccurately generalizes the operation as initializing or allocating multiple data structures, ignoring the specific creation of mutexes, spinlocks, and locks, which are synchronization primitives. This generalization is noise rather than a fatal error, as it does not contradict the core semantics but omits important specificity. The accurate part is low-gain due to being generic, and noise is noticeable from the overly broad 'data structures' phrasing with no mention of concurrency constructs."
            ]
        }
    }
}
{
    "source_code": "void __key_link(struct key *keyring, struct key *key,\n\t\tunsigned long *_prealloc)\n{\n\tstruct keyring_list *klist, *nklist;\n\tstruct key *discard;\n\n\tnklist = (struct keyring_list *)(*_prealloc & ~KEY_LINK_FIXQUOTA);\n\t*_prealloc = 0;\n\n\tkenter(\"%d,%d,%p\", keyring->serial, key->serial, nklist);\n\n\tklist = rcu_dereference_locked_keyring(keyring);\n\n\tatomic_inc(&key->usage);\n\tkeyring->last_used_at = key->last_used_at =\n\t\tcurrent_kernel_time().tv_sec;\n\n\t/* there's a matching key we can displace or an empty slot in a newly\n\t * allocated list we can fill */\n\tif (nklist) {\n\t\tkdebug(\"reissue %hu/%hu/%hu\",\n\t\t       nklist->delkey, nklist->nkeys, nklist->maxkeys);\n\n\t\tRCU_INIT_POINTER(nklist->keys[nklist->delkey], key);\n\n\t\trcu_assign_pointer(keyring->payload.subscriptions, nklist);\n\n\t\t/* dispose of the old keyring list and, if there was one, the\n\t\t * displaced key */\n\t\tif (klist) {\n\t\t\tkdebug(\"dispose %hu/%hu/%hu\",\n\t\t\t       klist->delkey, klist->nkeys, klist->maxkeys);\n\t\t\tcall_rcu(&klist->rcu, keyring_unlink_rcu_disposal);\n\t\t}\n\t} else if (klist->delkey < klist->nkeys) {\n\t\tkdebug(\"replace %hu/%hu/%hu\",\n\t\t       klist->delkey, klist->nkeys, klist->maxkeys);\n\n\t\tdiscard = rcu_dereference_protected(\n\t\t\tklist->keys[klist->delkey],\n\t\t\trwsem_is_locked(&keyring->sem));\n\t\trcu_assign_pointer(klist->keys[klist->delkey], key);\n\t\t/* The garbage collector will take care of RCU\n\t\t * synchronisation */\n\t\tkey_put(discard);\n\t} else {\n\t\t/* there's sufficient slack space to append directly */\n\t\tkdebug(\"append %hu/%hu/%hu\",\n\t\t       klist->delkey, klist->nkeys, klist->maxkeys);\n\n\t\tRCU_INIT_POINTER(klist->keys[klist->delkey], key);\n\t\tsmp_wmb();\n\t\tklist->nkeys++;\n\t}\n}",
    "comment": "Links a key to a keyring, replacing an existing key if necessary, while managing memory and usage references appropriately.",
    "prorec_sum": "Links a dentry to an inode, updates reference counts, and integrates it into its parent\u2019s child list with initialization callbacks.",
    "filter_prorec_sum": "Links a dentry with its inode, updates parent directory structures, and initializes related context and accounting information for filesystem operations.",
    "prorec_aug_sum": "Updates linked object references and counters, creating a new handle and inserting it into an existing structure or initializing a new entry with provided parameters.",
    "filter_prorec_aug_sum": "Links a new object into an existing structure, updating references and counters, and invokes appropriate callbacks or initialization for replacement or insertion.",
    "work_score": {
        "prorec_aug": {
            "summary": "Updates linked object references and counters, creating a new handle and inserting it into an existing structure or initializing a new entry with provided parameters.",
            "score": [
                0.5,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains very generic statements that loosely relate to the code's purpose but fail to accurately capture the specific function semantics, such as the conditional logic for replacing, appending, or reissuing keys in a keyring structure. It mentions updating references and counters, which is correct but overly vague, and incorrectly frames the action as 'creating a new handle' without clarifying the real operations on RCU-protected key lists. The majority of claims are safe but generic, with limited domain-specific alignment.",
                "The summary is vague and misses the specific core purpose of linking a key into a keyring, potentially by replacing an existing one, appending, or initializing a new keyring list with RCU-safe operations. While it hints at updating references and counters, it lacks any explicit mention of keyrings, replacement, conditional append, or disposal behavior seen in the source. No accurate claim matches the code\u2019s primary domain semantics, leading to omission of critical branch handling and external interactions.",
                "The summary is vague and omits critical specifics of the function's behavior, such as conditional replacement, appending within a keyring list, manipulating RCU pointers, and handling displaced keys. It also inaccurately mentions 'creating a new handle,' which does not occur in the code, making this a misleading statement about the core purpose. The lack of detail and presence of this FATAL in describing the primary action severely reduces trustworthiness."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Links a new object into an existing structure, updating references and counters, and invokes appropriate callbacks or initialization for replacement or insertion.",
            "score": [
                0.8,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly captures that the function links a new key into an existing keyring, updates reference counters, and handles insertion or replacement logic, which aligns with the code\u2019s branching for nklist, replacement, and append scenarios. However, it omits key specifics such as the use of RCU pointer operations, time updates, and precise disposal handling. The claims are generally accurate but lack domain-specific detail from the source code, making them generic rather than highly specific.",
                "The summary correctly notes that the function links a new object into an existing structure and updates references and counters, which matches the core purpose of linking a key into a keyring list. However, it is generic and omits crucial specifics like handling a preallocated list, replacing a displaced key, appending with slack space, and the exact RCU-based disposal mechanism used. Coverage of branch-specific behavior and key constants in the source code is missing, making the description incomplete despite capturing the core action.",
                "The summary gives a generic description of linking an object into a structure and updating references/counters, which aligns broadly with the code's behavior but lacks specific detail. It omits core specifics such as the conditional handling for preallocated list, replacement vs append scenarios, use of RCU for pointer assignment, and disposal of displaced keys. No claims are outright incorrect, so there is no fatal error, but the gain is low because the description is vague and misses key semantics. Noise is minimal, but the summary does not meaningfully accelerate understanding."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic void\nngx_http_upstream_keepalive_close_handler(ngx_event_t *ev)\n{\n    ngx_http_upstream_keepalive_srv_conf_t  *conf;\n    ngx_http_upstream_keepalive_cache_t     *item;\n\n    int                n;\n    char               buf[1];\n    ngx_connection_t  *c;\n\n    ngx_log_debug0(NGX_LOG_DEBUG_HTTP, ev->log, 0,\n                   \"keepalive close handler\");\n\n    c = ev->data;\n\n    if (c->close || c->read->timedout) {\n        goto close;\n    }\n\n    n = recv(c->fd, buf, 1, MSG_PEEK);\n\n    if (n == -1 && ngx_socket_errno == NGX_EAGAIN) {\n        ev->ready = 0;\n\n        if (ngx_handle_read_event(c->read, 0) != NGX_OK) {\n            goto close;\n        }\n\n        return;\n    }\n\nclose:\n\n    item = c->data;\n    conf = item->conf;\n\n    ngx_http_upstream_keepalive_close(c);\n\n    ngx_queue_remove(&item->queue);\n    ngx_queue_insert_head(&conf->free, &item->queue);\n}",
    "comment": "Closes an upstream keepalive connection, handling read timeouts and queue management for connection reuse.",
    "prorec_sum": "Closes an Nginx connection when error or read event occurs, releasing its memory pool and unlinking it from active connection lists.",
    "filter_prorec_sum": "Closes an HTTP connection when socket or event conditions occur, cleans up its memory pool, and removes it from linked connection lists.",
    "prorec_aug_sum": "Closes a network connection and cleans up associated resources when a read event indicates closure, error, or specific connection state flags.",
    "filter_prorec_aug_sum": "Handles upstream connection closure by checking socket/read event conditions, destroying its memory pool, closing the connection, and unlinking it from peer management lists.",
    "work_score": {
        "prorec_aug": {
            "summary": "Closes a network connection and cleans up associated resources when a read event indicates closure, error, or specific connection state flags.",
            "score": [
                0.6,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly captures that the function closes a network connection and cleans up resources, which aligns with the code's behavior of invoking a close function and updating queues. However, it omits specific logic details such as handling of `timedout` flags, the `recv` check with `MSG_PEEK`, and the conditional path involving `ngx_handle_read_event`, and it generalizes 'error' without explicitly tying it to actual code conditions. Overall, most of the claims are accurate but somewhat generic, representing more than half but not near-total precision.",
                "The summary correctly identifies that the function closes a network connection and cleans up resources on certain conditions, aligning with the core action in the source code. However, it lacks the specific domain context of handling upstream keepalive connections in NGINX, omits key operational details such as checking for timed-out reads, peeking data with MSG_PEEK, re-registering read events when EAGAIN is encountered, and the queue manipulation to manage the free list. Secondary behaviors and edge cases are underrepresented, resulting in incomplete coverage.",
                "The summary correctly captures the primary purpose of closing a network connection and cleaning up resources, aligning with the code's behavior of closing when certain conditions are met (close flag, timeout, or read event status). While it is accurate, it is broad and lacks detail about the specific checks performed (such as MSG_PEEK usage to detect readiness) and the reuse of the keepalive cache queue, which limits informativeness. There is no contradictory or irrelevant noise, but the gain is moderate due to the generic phrasing."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Handles upstream connection closure by checking socket/read event conditions, destroying its memory pool, closing the connection, and unlinking it from peer management lists.",
            "score": [
                0.7,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function handles upstream connection closure by checking socket/read event conditions and removing it from management lists, matching the code's logic of checking `c->close` or timeout and removing the item from the queue. However, it inaccurately claims that the function destroys its memory pool, which is not seen in the source code. Most claims are accurate, but this false detail reduces precision.",
                "The summary covers the core purpose, which is handling upstream connection closure based on socket/read event conditions and updating management lists, aligning with the code's checks for close/timedout conditions, socket peek, and re-queueing the connection item. However, it inaccurately claims destruction of the memory pool, which does not occur in the source, and omits important secondary details such as the non-blocking MSG_PEEK read, EAGAIN handling, resetting event readiness, and the reinsertion into the free list. These omissions and one incorrect element reduce the completeness and accuracy of the coverage.",
                "The summary contains an inaccurate claim about destroying the memory pool, which is not present in the source code, making it a FATAL error on core side effects. While it correctly notes that the handler checks socket/read conditions and closes the connection, it incorrectly adds steps about memory pool destruction and \"peer management lists\" instead of the actual upstream keepalive queue handling. This severe semantic mismatch on key cleanup behavior renders the description unreliable despite minor accurate elements."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nshow_arch (FILE *stream, int ext, int check)\n{\n  static char message[] = MESSAGE_TEMPLATE;\n  char *start = message + 27;\n  char *p;\n  int size = sizeof (MESSAGE_TEMPLATE);\n  int left;\n  const char *name;\n  int len;\n  unsigned int j;\n\n  p = start;\n  left = size - (start - message);\n  for (j = 0; j < ARRAY_SIZE (cpu_arch); j++)\n    {\n      /* Should it be skipped?  */\n      if (cpu_arch [j].skip)\n\tcontinue;\n\n      name = cpu_arch [j].name;\n      len = cpu_arch [j].len;\n      if (*name == '.')\n\t{\n\t  /* It is an extension.  Skip if we aren't asked to show it.  */\n\t  if (ext)\n\t    {\n\t      name++;\n\t      len--;\n\t    }\n\t  else\n\t    continue;\n\t}\n      else if (ext)\n\t{\n\t  /* It is an processor.  Skip if we show only extension.  */\n\t  continue;\n\t}\n      else if (check && ! cpu_arch[j].flags.bitfield.cpui386)\n\t{\n\t  /* It is an impossible processor - skip.  */\n\t  continue;\n\t}\n\n      p = output_message (stream, p, message, start, &left, name, len);\n    }\n\n  /* Display disabled extensions.  */\n  if (ext)\n    for (j = 0; j < ARRAY_SIZE (cpu_noarch); j++)\n      {\n\tname = cpu_noarch [j].name;\n\tlen = cpu_noarch [j].len;\n\tp = output_message (stream, p, message, start, &left, name,\n\t\t\t    len);\n      }\n\n  *p = '\\0';\n  fprintf (stream, \"%s\\n\", message);\n}",
    "comment": "Outputs architecture information to a specified stream, including enabled processors and disabled extensions, based on provided flags and conditions.",
    "prorec_sum": "Generates a formatted string from predefined name fragments and writes it to the given stream, appending an extra set when the second flag is set.",
    "filter_prorec_sum": "Formats and writes a composed filename string to the output stream based on directory entries, flags, and specified formatting rules.",
    "prorec_aug_sum": "Generates a formatted string from predefined entries based on flags and writes it with a newline to the specified output stream.",
    "filter_prorec_aug_sum": "Generates and prints a formatted version information string to the given stream based on conditionally included predefined text segments.",
    "work_score": {
        "prorec_aug": {
            "summary": "Generates a formatted string from predefined entries based on flags and writes it with a newline to the specified output stream.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function produces a formatted string from predefined entries and writes it with a newline to the provided output stream, which aligns with the observed use of `output_message` and `fprintf`. However, it omits key specifics about conditional filtering based on `ext`, `check`, and architecture arrays, resulting in a partially accurate but overly generic description. Most of the (few) claims are accurate but low-detail, so the precision proportion is high despite low recall.",
                "The summary correctly notes that the function builds a formatted string from predefined entries and outputs it with a newline, which aligns with the core purpose of iterating CPU architecture/extension lists and formatting them based on flags. However, it omits key specifics such as handling of extension vs processor types, skipping based on flags and conditions, and inclusion of disabled extensions. These omissions limit coverage of secondary behavior-critical details.",
                "The summary correctly describes that the function produces a formatted string from predefined entries depending on certain flags and writes it to the given output stream, which matches the code's logic involving cpu_arch and cpu_noarch arrays and conditions on ext and check flags. While the description is accurate for the primary purpose, it is quite generic and omits more specific details such as how extensions, processors, and disabled extensions are selectively included. There is no contradictory or irrelevant information, so there are no FATAL or NOISE issues, but the gain is low due to lack of detail."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Generates and prints a formatted version information string to the given stream based on conditionally included predefined text segments.",
            "score": [
                0.2,
                0.3,
                0.2
            ],
            "reason": [
                "The summary vaguely describes generating and printing a formatted string but omits key specifics from the code, such as iterating through cpu_arch and cpu_noarch arrays, applying skip logic based on extension, processor checks, and flags. The single high-level claim is only partially accurate and mostly generic, failing to capture the actual domain-semantic behavior. This results in a low proportion of accurate, specific claims.",
                "The summary correctly notes that the function outputs a formatted string to a stream, aligning with the fprintf behavior, but it fails to capture the core purpose of iterating through CPU architecture arrays, filtering entries based on flags and conditions (extensions, processors, skip flags), and assembling the message accordingly. It omits key branching and selection logic that defines the function\u2019s domain semantics, covering only a broad output description.",
                "The summary gives a generic and somewhat misleading description, focusing on 'version information' and 'predefined text segments' without reflecting the actual core purpose of iterating over cpu_arch and cpu_noarch entries and conditionally appending names based on ext and check flags. This mismatch in the primary purpose counts as a FATAL error, as it misrepresents the function\u2019s domain semantics and output. The gain from accurate content is minimal due to its vagueness and incorrect framing."
            ]
        }
    }
}
{
    "source_code": "\nstatic boolean ReadICCProfile(j_decompress_ptr jpeg_info)\n{\n  char\n    magick[12];\n\n  ErrorManager\n    *error_manager;\n\n  Image\n    *image;\n\n  long\n    length;\n\n  register long\n    i;\n\n  unsigned char\n    *profile;\n\n  /*\n    Determine length of color profile.\n  */\n  length=(long) GetCharacter(jpeg_info) << 8;\n  length+=(long) GetCharacter(jpeg_info);\n  length-=2;\n  if (length <= 14)\n    {\n      while (--length >= 0)\n        (void) GetCharacter(jpeg_info);\n      return(True);\n    }\n  for (i=0; i < 12; i++)\n    magick[i]=GetCharacter(jpeg_info);\n  if (LocaleCompare(magick,\"ICC_PROFILE\") != 0)\n    {\n      /*\n        Not a ICC profile, return.\n      */\n      for (i=0; i < length-12; i++)\n        (void) GetCharacter(jpeg_info);\n      return(True);\n    }\n  (void) GetCharacter(jpeg_info);  /* id */\n  (void) GetCharacter(jpeg_info);  /* markers */\n  length-=14;\n  error_manager=(ErrorManager *) jpeg_info->client_data;\n  image=error_manager->image;\n\n  /*\n    Read color profile.\n  */\n  profile=error_manager->buffer;\n\n  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"ICC profile chunk: %ld bytes\",\n    length);\n\n  for (i=0 ; i < length; i++)\n   profile[i]=GetCharacter(jpeg_info);\n\n  (void) AppendImageProfile(image,\"ICM\",profile,length);\n\n  return(True);\n}",
    "comment": "Reads an ICC color profile from JPEG data, storing it in an image's buffer if the profile is valid.",
    "prorec_sum": "Reads JPEG segment bytes, detects an \u201cICC_PROFILE\u201d marker, and if found extracts and stores the embedded ICC color profile data.",
    "filter_prorec_sum": "Processes a JPEG ICC_PROFILE segment, reading its bytes and storing the ICM data into the image structure for further handling.",
    "prorec_aug_sum": "Parses JPEG segment data to detect and process embedded ICC color profiles, storing profile bytes and invoking ICM handling for valid profiles.",
    "filter_prorec_aug_sum": "Processes JPEG data to detect an \"ICC_PROFILE\" marker and, if found, reads and stores the associated ICM profile into image structures.",
    "work_score": {
        "prorec_aug": {
            "summary": "Parses JPEG segment data to detect and process embedded ICC color profiles, storing profile bytes and invoking ICM handling for valid profiles.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary contains two main claims: that the function parses JPEG segment data to detect and process embedded ICC color profiles, and that it stores the profile bytes and invokes ICM handling for valid profiles. Both claims align closely with the source code behavior \u2014 it reads segment data, checks for ICC_PROFILE marker, stores bytes into a buffer, and calls AppendImageProfile with 'ICM'. The claims are accurate and specific to the function's semantics, with no evident inaccuracies or irrelevant content.",
                "The summary correctly identifies that the function parses JPEG segment data, detects embedded ICC profiles, and processes valid ones by storing bytes and invoking ICM handling, which matches the core purpose of reading and appending an ICC color profile to the image. However, it omits secondary details such as the length checks, handling of non-ICC segments, logging of the profile chunk, and retrieval of data from the error_manager buffer, resulting in incomplete coverage of behavior-critical semantics.",
                "The summary accurately captures the core behavior: reading JPEG segment data, checking for 'ICC_PROFILE', storing bytes in a buffer, and adding an ICM profile for valid data. There are no incorrect claims and noise is minimal. The description is concise but specific enough to convey the primary purpose, providing a solid gain with high alignment to the code semantics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes JPEG data to detect an \"ICC_PROFILE\" marker and, if found, reads and stores the associated ICM profile into image structures.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly identifies that the function processes JPEG data, checks for an \"ICC_PROFILE\" marker, and if found, reads and stores the profile into image structures. These correspond to the code's actual steps: checking the marker string, reading the profile bytes, and appending them to the image with the ICM tag. There are no incorrect or irrelevant claims, and the description is concise and aligned with the function's domain semantics.",
                "The summary correctly states that the function detects an \"ICC_PROFILE\" marker in JPEG data and reads/stores the associated ICM profile into image structures, which matches the core purpose in the source code. However, it omits secondary details such as the initial length calculation and threshold check, handling when the marker is not present, reading the id and markers bytes, logging the ICC profile chunk size, and the use of specific buffers from the error manager. These missing aspects reduce completeness beyond the core coverage.",
                "The summary correctly identifies that the function processes JPEG data to detect an 'ICC_PROFILE' marker and, if present, reads and stores the associated ICM profile into image structures. This matches the core logic in the source code, which reads the marker bytes, verifies the 'ICC_PROFILE' string, retrieves the profile data, and appends it to the image. There are no inaccurate or noisy claims, and the description covers the primary purpose succinctly, though without deep detail such as handling non-profile cases or intermediate ID/marker bytes. Overall, it is specific and accurate with low noise and moderate informational value."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_permutation_linear_to_canonical (gsl_permutation * q,\n                                     const gsl_permutation * p)\n{\n  const size_t n = p->size;\n  size_t i, k, s;\n  size_t t = n;\n\n  const size_t *const pp = p->data;\n  size_t *const qq = q->data;\n\n  if (q->size != p->size)\n    {\n      GSL_ERROR (\"size of q does not match size of p\", GSL_EINVAL);\n    }\n\n  for (i = 0; i < n; i++)\n    {\n\n      k = pp[i];\n      s = 1;\n\n      while (k > i)\n        {\n          k = pp[k];\n          s++;\n        }\n\n      if (k < i)\n        continue;\n\n      /* Now have k == i, i.e the least in its cycle, and s == cycle length */\n\n      t -= s;\n\n      qq[t] = i;\n\n      k = pp[i];\n      s = 1;\n\n      while (k > i)\n        {\n          qq[t + s] = k;\n          k = pp[k];\n          s++;\n        }\n\n      if (t == 0)\n        break;\n    }\n\n  return GSL_SUCCESS;\n}",
    "comment": "Converts a given permutation `p` into its canonical form and stores the result in `q`.",
    "prorec_sum": "Converts a linear permutation array into canonical cycle form, validating equal sizes and reporting an error if permutations differ in length.",
    "filter_prorec_sum": "Converts a linear permutation representation into canonical cycle form, validating matching sizes and reporting an error if dimensions differ.",
    "prorec_aug_sum": "Converts a linear permutation into its canonical cycle form, storing cycles sequentially and reporting an error if permutation sizes differ.",
    "filter_prorec_aug_sum": "Converts a linear permutation into canonical cycle form, validating matching sizes and reporting an error if the permutation lengths differ.",
    "work_score": {
        "prorec_aug": {
            "summary": "Converts a linear permutation into its canonical cycle form, storing cycles sequentially and reporting an error if permutation sizes differ.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary contains two main claims: that the function converts a linear permutation into its canonical cycle form and that it reports an error if permutation sizes differ. The error reporting claim is accurate, reflecting the check and GSL_ERROR behavior in the code. The cycle conversion description is generally accurate\u2014it does transform the linear permutation into a canonical cycle representation, storing elements of each cycle sequentially\u2014but the summary omits specifics such as the reverse ordering logic with 't' and the precise placement of cycle starts. Overall, both claims align with the function's semantics, with minor missing detail but no contradictions.",
                "The summary correctly identifies the core purpose as converting a linear permutation into canonical cycle form and includes the specific behavior of reporting an error when sizes differ, both of which match the source code. However, it omits secondary details such as how cycles are identified (finding the least element in each cycle), the ordering logic with variable 't', breaking early when t reaches zero, and the specific GSL error and success codes used. This limits coverage of other behavior-critical semantics.",
                "The summary correctly states that the function reports an error if permutation sizes differ and that it converts a permutation into a canonical cycle form, which aligns with the code\u2019s algorithm for processing cycles and ordering them in q. These are accurate, fact-based claims about the core behavior. There is no contradictory or irrelevant information, and noise is minimal. The claims are moderately specific, targeting the primary purpose and a key side effect, but lack deeper technical detail such as the ordering logic and cycle detection steps, limiting the gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Converts a linear permutation into canonical cycle form, validating matching sizes and reporting an error if the permutation lengths differ.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function converts a linear permutation into a canonical cycle form and checks that q and p have matching sizes, reporting an error otherwise. Both claims target the actual semantics in the source code and align accurately, resulting in a high proportion of accurate claims with no evident inaccuracies.",
                "The summary correctly identifies the core purpose of converting a linear permutation into canonical cycle form and notes the size validation with error reporting, which matches the source code. However, it lacks coverage of important secondary semantics such as the specific handling of permutation cycles, the decrement of t, iteration mechanics, and how elements are assigned in the canonical form. These omissions reduce completeness despite accurate core coverage.",
                "The summary accurately states the primary purpose of converting a linear permutation to canonical cycle form and the size validation with an error if sizes differ. These are correct and directly based on the source code. There is no contradictory or irrelevant information, but the description is somewhat generic and lacks specific details about how the canonical form is constructed, limiting its informative value."
            ]
        }
    }
}
{
    "source_code": "\nstatic int slave_update(struct link_slave *slave)\n{\n\tstruct snd_ctl_elem_value *uctl;\n\tint err, ch;\n\n\tuctl = kmalloc(sizeof(*uctl), GFP_KERNEL);\n\tif (!uctl)\n\t\treturn -ENOMEM;\n\tuctl->id = slave->slave.id;\n\terr = slave->slave.get(&slave->slave, uctl);\n\tfor (ch = 0; ch < slave->info.count; ch++)\n\t\tslave->vals[ch] = uctl->value.integer.value[ch];\n\tkfree(uctl);\n\treturn 0;\n}",
    "comment": "Updates the values of a slave device by retrieving its current control element values and storing them in the slave's array.",
    "prorec_sum": "Initializes a newly allocated structure with state from the given context and invokes further processing on it using provided double parameters.",
    "filter_prorec_sum": "Allocates and initializes a structure with data from the given context, invokes a callback, updates fields, and performs additional setup operations.",
    "prorec_aug_sum": "Allocates and populates a 72\u2011byte structure from a1\u2019s fields, invokes its callback, updates state fields, and performs further initialization with provided doubles.",
    "filter_prorec_aug_sum": "Allocates and initializes a target structure with parameters from the source object, invokes its setup callback, updates state fields, and finalizes configuration.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and populates a 72\u2011byte structure from a1\u2019s fields, invokes its callback, updates state fields, and performs further initialization with provided doubles.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains multiple inaccurate claims. It incorrectly specifies a fixed 72-byte structure size, references 'a1\u2019s fields' rather than the actual 'slave' struct, mentions invocation of its callback in a generic way without matching the actual function signature, and adds non-existent behavior about 'further initialization with provided doubles'. Only the part about allocating a structure, invoking a callback, and updating state fields loosely matches the source, making most claims misaligned with the code semantics.",
                "The summary's claims about a fixed 72-byte size, usage of 'a1's fields, and handling doubles are inaccurate and not supported by the source code. The function actually allocates a snd_ctl_elem_value structure with kmalloc, copies an ID, invokes a get callback, updates integer value arrays, and frees the structure. The summary fails to capture the core purpose of updating the slave's vals from retrieved integer data, and contains multiple incorrect details rather than accurate coverage of secondary behaviors.",
                "The summary contains multiple inaccuracies about the function's behavior. It claims a fixed size of 72 bytes, mentions a1\u2019s fields, and refers to doubles and further initialization, none of which are present in the source code. The actual code allocates memory for a snd_ctl_elem_value struct, copies an ID from the slave struct, calls a get callback, updates integer values for each channel, and frees the allocation. These errors directly misrepresent the primary purpose and key data handling, constituting a severe FATAL issue on core semantics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Allocates and initializes a target structure with parameters from the source object, invokes its setup callback, updates state fields, and finalizes configuration.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as invoking a 'setup callback' and 'finalizing configuration,' which are not present in the source code. It omits accurate specifics such as using kmalloc to allocate memory, copying an ID from the slave struct, calling the get method, updating vals from uctl, and freeing the allocated memory. Only the generic notions of allocation, initialization, invoking a callback, and updating fields partially align, resulting in less than half of the claims being accurate.",
                "The summary generically describes allocation, initialization, callback invocation, and state updates, but it fails to accurately capture the specific core purpose of retrieving control element values from a link_slave via its get method and copying them into vals. It uses vague terms like 'setup callback' and 'finalizes configuration' that don't match the actual domain semantics, and omits details like channel iteration, memory freeing, and error handling. Thus, the core domain action is not covered and secondary key points are also missing.",
                "The summary claims an allocation and initialization with parameters from the source object, a setup callback invocation, state updates, and configuration finalization. In the source code, the function allocates a control element value structure, sets its id from the slave object, calls a get callback, copies integer values into the slave's vals array, then frees the structure. The wording 'setup callback' and 'finalizes configuration' are inaccurate for the actual semantics, as the callback is a getter and no configuration finalization occurs. These are FATAL inaccuracies related to the primary purpose and core side effects, making the description misleading despite mentioning allocation and state updates correctly."
            ]
        }
    }
}
{
    "source_code": "\n\f\nint\nalias_cb(enum grecs_callback_command cmd,\n\t grecs_locus_t *locus,\n\t void *varptr,\n\t grecs_value_t *value,\n\t void *cb_data)\n{\n    char **argv;\n    int argc;\n    int i;\n\n    if (cmd != grecs_callback_set_value) {\n\tgrecs_error(locus, 0, _(\"Unexpected block statement\"));\n\treturn 1;\n    }\n    if (value->type != GRECS_TYPE_ARRAY) {\n\tgrecs_error(locus, 0, _(\"Not enough arguments for alias\"));\n\treturn 1;\n    }\n    argc = value->v.arg.c - 1;\n    argv = xcalloc(argc + 1, sizeof(argv[0]));\n    for (i = 0; i < argc; i++) {\n\tif (value->v.arg.v[i+1]->type != GRECS_TYPE_STRING) {\n\t    grecs_error(locus, 0, _(\"argument %d has wrong type\"), i+1);\n\t    return 1;\n\t}\n\targv[i] = xstrdup(value->v.arg.v[i+1]->v.string);\n    }\n    argv[i] = NULL;\n    return alias_install(value->v.arg.v[0]->v.string, argc, argv, locus);\n}",
    "comment": "Processes a callback to set an alias by checking argument types and installing the alias with provided string parameters.",
    "prorec_sum": "Validates alias command arguments, converts them to strings, and invokes a handler with the alias name and processed argument list.",
    "filter_prorec_sum": "Validates alias arguments, converts them to strings, and invokes a command handler, reporting errors for unexpected blocks or incorrect argument types.",
    "prorec_aug_sum": "Validates alias block arguments, reports errors for wrong types or counts, builds an argument list, and invokes the alias execution routine.",
    "filter_prorec_aug_sum": "Validates alias command arguments, converts them to strings, and invokes the alias creation routine, reporting specific errors for unexpected blocks or wrong argument types.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates alias block arguments, reports errors for wrong types or counts, builds an argument list, and invokes the alias execution routine.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly describes that the function validates alias block arguments, checks for wrong types or insufficient argument counts, constructs an argument list, and calls another routine. All these claims align with the source code: it verifies the callback command, confirms array type, enforces string type for each argument, allocates and populates argv, and then calls alias_install. There are no inaccurate or irrelevant claims, and all points are grounded in the function's actual behavior.",
                "The summary accurately notes validation of alias block arguments, error reporting for wrong types or counts, creation of an argument list, and calling a routine to execute the alias, which aligns with the core purpose of installing an alias from configuration input. It covers the core primary purpose with reasonable specificity and touches on secondary behaviors like type checking and argument count validation, but omits finer details such as the specific command check, handling for non-array values, memory allocation with xcalloc/xstrdup, and the exact interaction with alias_install including passing the locus.",
                "The summary accurately reflects the core behavior: checking alias block argument count and types, constructing an argument list from strings, and invoking a routine (alias_install) to execute/install the alias. No contradictory or irrelevant claims are present, and all points match the source code logic. While the claims are correct and cover the primary purpose, they are somewhat high-level and generic without detailing specifics like skipping the first argument when building the list, thus offering moderate rather than deep insight."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates alias command arguments, converts them to strings, and invokes the alias creation routine, reporting specific errors for unexpected blocks or wrong argument types.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately describes the function\u2019s behavior: it checks for unexpected block statements, validates that arguments are passed as an array, ensures elements are strings, converts them, and calls the alias creation routine. All these points match the source code without introducing incorrect or irrelevant claims, indicating a high proportion of accurate statements.",
                "The summary correctly identifies that the function validates alias command arguments, converts them to strings, calls an alias creation routine, and reports errors for unexpected blocks or wrong argument types. This covers the core purpose of validating and installing an alias from provided arguments and includes secondary details such as error handling and type checking. However, it omits some specifics like ensuring the first argument is the alias name and handling 'not enough arguments' cases, making coverage decent but not exhaustive.",
                "The summary accurately reflects the function\u2019s main behavior: it checks for correct command type and argument type, converts arguments to strings, and calls the alias creation routine while reporting specific errors. All claims are supported by the source code and are specific to its semantics, with no contradictory or irrelevant statements. The description includes the primary purpose, key validation steps, and error handling, offering high informational value with no noise."
            ]
        }
    }
}
{
    "source_code": "static int\nis_hidden_fd(struct redirtab *rp, int fd)\n{\n\tint i;\n\tstruct parsefile *pf;\n\n\tif (fd == -1)\n\t\treturn 0;\n\t/* Check open scripts' fds */\n\tpf = g_parsefile;\n\twhile (pf) {\n\t\t/* We skip pf_fd == 0 case because of the following case:\n\t\t * $ ash  # running ash interactively\n\t\t * $ . ./script.sh\n\t\t * and in script.sh: \"exec 9>&0\".\n\t\t * Even though top-level pf_fd _is_ 0,\n\t\t * it's still ok to use it: \"read\" builtin uses it,\n\t\t * why should we cripple \"exec\" builtin?\n\t\t */\n\t\tif (pf->pf_fd > 0 && fd == pf->pf_fd) {\n\t\t\treturn 1;\n\t\t}\n\t\tpf = pf->prev;\n\t}\n\n\tif (!rp)\n\t\treturn 0;\n\t/* Check saved fds of redirects */\n\tfd |= COPYFD_RESTORE;\n\tfor (i = 0; i < rp->pair_count; i++) {\n\t\tif (rp->two_fd[i].copy == fd) {\n\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}",
    "comment": "Checks if a file descriptor is already in use by open scripts or saved redirects in the given redirection table.",
    "prorec_sum": "Checks if the given identifier matches a valid entry in a global list or a flagged record within the specified structure.",
    "filter_prorec_sum": "Checks whether the given integer identifier matches an entry in a global list or a flagged ID within the specified object's array.",
    "prorec_aug_sum": "Checks whether the given integer identifier exists in a global linked list or in an array within the specified structure.",
    "filter_prorec_aug_sum": "Checks whether the specified integer identifier exists in a global linked list or in the given object's stored ID array.",
    "work_score": {
        "prorec_aug": {
            "summary": "Checks whether the given integer identifier exists in a global linked list or in an array within the specified structure.",
            "score": [
                0.7,
                0.6,
                0.4
            ],
            "reason": [
                "The summary correctly notes that the function checks for the identifier in two locations: a global linked list (via g_parsefile traversal) and an array within a provided structure (rp->two_fd). However, it omits important specifics such as skipping pf_fd == 0, the integer being a file descriptor, and the special bitwise operation with COPYFD_RESTORE before array comparison. While the core structural behavior is captured, detail loss and lack of precise domain terminology reduce accuracy.",
                "The summary correctly identifies the core operation of verifying whether a given identifier (file descriptor) appears in two data sources\u2014a global linked list (the parsefile chain) or an array within a provided structure (the redirtab's two_fd array). This aligns with the function's purpose of checking if a file descriptor is 'hidden'. However, it omits essential behavioral conditions, such as the special handling when fd == -1, the skipping of pf_fd == 0 cases, and the COPYFD_RESTORE flag manipulation, reducing completeness in secondary semantics coverage.",
                "The summary provides a very generic description that omits critical domain semantics of the function. It inaccurately generalizes the check as looking for an integer identifier in a linked list or array, without mentioning that the identifier is specifically a file descriptor, that certain fd values (such as -1 or 0) are treated specially, or that the linked list is of parsefile structures and the array is part of a redirect table. This results in low informational value and introduces noise by failing to capture key behaviors and conditions central to the function\u2019s primary purpose. No outright contradiction exists, but the lack of core details makes it weak and unhelpful."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Checks whether the specified integer identifier exists in a global linked list or in the given object's stored ID array.",
            "score": [
                0.2,
                0.4,
                0.2
            ],
            "reason": [
                "The summary's claims are inaccurate because the function does not generically check for an integer identifier in a linked list or stored ID array. Instead, it specifically checks if a file descriptor matches one in a global parsefile chain with pf_fd > 0 or in the redirtab's saved file descriptor pairs after modifying with COPYFD_RESTORE. The described 'linked list' and 'stored ID array' mappings misrepresent the code's domain-specific file descriptor handling, making the majority of claims incorrect.",
                "The summary correctly notes that the function checks for the existence of an identifier in a global linked list or a given object's stored array, which aligns with the code's traversal of the global parsefile chain and rp->two_fd array. However, it omits critical domain semantics: the identifier is a file descriptor, there is a special case exclusion for fd == -1 and pf_fd == 0, and the check involves a COPYFD_RESTORE bitwise operation. These omissions mean the core purpose of determining if a file descriptor is hidden in open scripts or redirects is only vaguely captured.",
                "The summary contains an inaccurate core claim: it describes checking for an integer identifier in a global linked list or an object's stored ID array, which does not match the source code's actual semantics. The function checks whether a file descriptor matches those in a global parsefile chain (with special handling for fd 0) or in a redirect table's saved descriptors, not a generic linked list or ID array. This misrepresentation is a FATAL error on the primary purpose, making the description misleading and untrustworthy."
            ]
        }
    }
}
{
    "source_code": "\nvoid ironlake_edp_panel_off(struct intel_dp *intel_dp)\n{\n\tstruct drm_device *dev = intel_dp_to_dev(intel_dp);\n\tstruct drm_i915_private *dev_priv = dev->dev_private;\n\tu32 pp;\n\tu32 pp_ctrl_reg;\n\n\tif (!is_edp(intel_dp))\n\t\treturn;\n\n\tDRM_DEBUG_KMS(\"Turn eDP power off\\n\");\n\n\tWARN(!intel_dp->want_panel_vdd, \"Need VDD to turn off panel\\n\");\n\n\tpp = ironlake_get_pp_control(intel_dp);\n\t/* We need to switch off panel power _and_ force vdd, for otherwise some\n\t * panels get very unhappy and cease to work. */\n\tpp &= ~(POWER_TARGET_ON | EDP_FORCE_VDD | PANEL_POWER_RESET | EDP_BLC_ENABLE);\n\n\tpp_ctrl_reg = IS_VALLEYVIEW(dev) ? PIPEA_PP_CONTROL : PCH_PP_CONTROL;\n\n\tI915_WRITE(pp_ctrl_reg, pp);\n\tPOSTING_READ(pp_ctrl_reg);\n\n\tintel_dp->want_panel_vdd = false;\n\n\tironlake_wait_panel_off(intel_dp);\n}",
    "comment": "Turns off eDP panel power by modifying control registers and ensuring no VDD is supplied, preventing panel damage during shutdown.",
    "prorec_sum": "Turns off the Ironlake eDP panel, logs the action, ensures required power conditions, updates hardware state, and waits for the panel power-off delay.",
    "filter_prorec_sum": "Turns off the Ironlake eDP panel, logs status, updates power control registers, clears VDD state, and waits for panel power-down timing.",
    "prorec_aug_sum": "Turns off an Ironlake eDP panel, logs status messages, manages VDD power state, and waits for required panel power-off timing.",
    "filter_prorec_aug_sum": "Turns off the Ironlake eDP panel power, logs the action, resets power flags, and waits for the panel power-off duration.",
    "work_score": {
        "prorec_aug": {
            "summary": "Turns off an Ironlake eDP panel, logs status messages, manages VDD power state, and waits for required panel power-off timing.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary captures the main functional intent: turning off an Ironlake eDP panel, logging status messages via DRM_DEBUG_KMS, managing the VDD power state, and waiting for the panel to power off. All these points are directly supported by the source code's sequence of actions. No contradictory or irrelevant claims are present, and the summary maintains accurate domain semantics.",
                "The summary correctly identifies the core function of turning off an Ironlake eDP panel, which aligns with the primary domain-specific action in the source code. It also mentions logging and managing the VDD state, and waiting for panel-off timing, all of which are accurately reflected in the implementation. However, it omits secondary technical specifics such as the conditional check for eDP type, the WARN on missing VDD, the clearing of specific control bits (POWER_TARGET_ON, EDP_FORCE_VDD, etc.), selection of control register based on platform, and actual hardware register writes and reads. These are important behavior-critical semantics not covered, so secondary coverage remains moderate.",
                "The summary accurately states the primary function of turning off an Ironlake eDP panel, includes mention of logging status messages, correctly notes management of the VDD power state, and references waiting for the panel power-off timing. All claims match the source code behavior without contradictions. The points are largely generic and safe, with minimal specific detail beyond the core actions, giving low informational gain but no false or noisy claims."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Turns off the Ironlake eDP panel power, logs the action, resets power flags, and waits for the panel power-off duration.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly describes the function's purpose of turning off the Ironlake eDP panel power, mentions logging the action, resetting power-related flags, and waiting for the power-off procedure. All these points align with the code\u2019s logic, including the logging via DRM_DEBUG_KMS, clearing specific power control bits, and calling ironlake_wait_panel_off. No inaccuracies or irrelevant claims are present, indicating high precision.",
                "The summary correctly identifies the core operation as turning off the Ironlake eDP panel power, which matches the primary purpose in the source. It also notes logging the action, resetting power flags, and waiting for panel power-off, which are accurate secondary behaviors. However, it omits important details such as the initial check for eDP type, the WARN invocation if VDD is missing, the specific registers used depending on the platform, and clearing multiple specific power bits. These missing elements reduce coverage of behavior-critical semantics.",
                "The summary accurately captures the primary purpose \u2014 turning off Ironlake eDP panel power \u2014 and mentions logging and waiting for the panel power-off duration, both present in the code. It also correctly notes resetting power flags, matching the bitmask operations clearing POWER_TARGET_ON, EDP_FORCE_VDD, PANEL_POWER_RESET, and EDP_BLC_ENABLE. No contradictory or irrelevant claims are present, but the description is somewhat generic and lacks specific details such as the functional check for eDP, the VDD requirement warning, and hardware-specific control register selection. This yields moderate gain with negligible noise."
            ]
        }
    }
}
{
    "source_code": "\nstatic void die_if_script(unsigned lineno, const char *fmt, ...)\n{\n\tva_list p;\n\n#if HUSH_DEBUG >= 2\n\tbb_error_msg(\"hush.c:%u\", lineno);\n#endif\n\tva_start(p, fmt);\n\tbb_verror_msg(fmt, p, NULL);\n\tva_end(p);\n\tif (!G_interactive_fd)\n\t\txfunc_die();\n}",
    "comment": "Logs an error message with the line number and format specified, then terminates the program if not in interactive mode.",
    "prorec_sum": "Processes a byte input with multiple double parameters and forwards them to a helper function, invoking a secondary routine if a status flag is unset.",
    "filter_prorec_sum": "Formats and sends multiple double-precision values with optional vector data to a processing routine, then triggers a secondary operation if no prior result exists.",
    "prorec_aug_sum": "Packages input parameters into a structured array, forwards them with floating-point vectors for processing, and triggers a secondary handler if no result is set.",
    "filter_prorec_aug_sum": "Prepares a structured argument block with optional vector data and invokes helper routines, returning a status code from a shared configuration variable.",
    "work_score": {
        "prorec_aug": {
            "summary": "Packages input parameters into a structured array, forwards them with floating-point vectors for processing, and triggers a secondary handler if no result is set.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about packaging parameters into a structured array, using floating\u2011point vectors, and triggering a secondary handler if no result is set do not align with the source code. The function in the source code initializes a va_list, formats and outputs an error message, and calls a termination function based on a condition. None of the claims accurately describe this behavior, resulting in no accurate claims.",
                "The summary's claims about packaging parameters into arrays, forwarding floating-point vectors, and triggering a handler on missing results are unrelated to the actual source code, which formats and logs an error with variable arguments and terminates if not in interactive mode. No accurate claim matches the core primary purpose, and all provided details are incorrect relative to the code's semantics.",
                "The summary's claims are entirely inaccurate relative to the source code. The function does not package parameters into a structured array, work with floating-point vectors, or trigger a secondary handler based on a missing result. Instead, it logs an error message, formats it using variadic arguments, and conditionally terminates the process. These mismatches represent severe FATAL errors about the primary purpose and key side effects, making the description unusable."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Prepares a structured argument block with optional vector data and invokes helper routines, returning a status code from a shared configuration variable.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary's claims about preparing a structured argument block, handling optional vector data, and returning a status code from a shared configuration variable do not match the source code, which constructs a va_list from variable arguments, prints error messages, and conditionally calls a termination function. None of the claims accurately describe the function's actual domain-semantic behavior.",
                "The summary does not match the source code's semantics at all. The function in the source handles error reporting for the hush shell, optionally logs debugging info, formats a message with variable arguments, and terminates the process if not running interactively. The summary incorrectly describes preparing a structured argument block, using optional vector data, and returning a status code from a shared configuration variable\u2014none of which occur in the code. This means the core purpose is completely missed and all stated claims are inaccurate.",
                "The summary's claims about preparing a structured argument block, handling optional vector data, and returning a status code from a shared configuration variable are completely unrelated to the source code, which formats and outputs an error message and terminates based on an interactive flag. All extracted claims are NOISE, with no accurate reflection of the function's actual domain behavior, resulting in zero net benefit."
            ]
        }
    }
}
{
    "source_code": "\nasmlinkage long compat_sys_getdents64(unsigned int fd,\n\t\tstruct linux_dirent64 __user * dirent, unsigned int count)\n{\n\tstruct fd f;\n\tstruct linux_dirent64 __user * lastdirent;\n\tstruct compat_getdents_callback64 buf;\n\tint error;\n\n\tif (!access_ok(VERIFY_WRITE, dirent, count))\n\t\treturn -EFAULT;\n\n\tf = fdget(fd);\n\tif (!f.file)\n\t\treturn -EBADF;\n\n\tbuf.current_dir = dirent;\n\tbuf.previous = NULL;\n\tbuf.count = count;\n\tbuf.error = 0;\n\n\terror = vfs_readdir(f.file, compat_filldir64, &buf);\n\tif (error >= 0)\n\t\terror = buf.error;\n\tlastdirent = buf.previous;\n\tif (lastdirent) {\n\t\ttypeof(lastdirent->d_off) d_off = f.file->f_pos;\n\t\tif (__put_user_unaligned(d_off, &lastdirent->d_off))\n\t\t\terror = -EFAULT;\n\t\telse\n\t\t\terror = count - buf.count;\n\t}\n\tfdput(f);\n\treturn error;\n}",
    "comment": "Retrieves directory entries from a file descriptor and populates a user-provided buffer with the results, handling errors and offsets.",
    "prorec_sum": "Allocates space in a file at the specified offset and length, invoking a callback for associated operations when conditions are met.",
    "filter_prorec_sum": "Allocates space in a file at the specified offset and length, invoking callbacks and updating state based on operation results.",
    "prorec_aug_sum": "Handles a futex operation by initializing state, invoking a callback, and optionally performing additional processing based on arguments and operation results.",
    "filter_prorec_aug_sum": "Handles a futex operation by preparing parameters, invoking a handler, adjusting result codes, and optionally performing additional processing based on provided timing and control arguments.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles a futex operation by initializing state, invoking a callback, and optionally performing additional processing based on arguments and operation results.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary incorrectly describes handling a futex operation, which is unrelated to the provided source code. The function in the source deals with reading directory entries using getdents64 for compatibility mode. None of the claims in the summary align with the domain-specific semantics of the source, resulting in 0% accurate statements.",
                "The summary incorrectly describes the function as handling a futex operation, which is unrelated to the actual source code. The code implements compat_sys_getdents64, performing a directory entries read for a file descriptor with validation, vfs_readdir invocation, and finalizing offsets. This mismatch means the core purpose is not covered, and no accurate secondary details are present.",
                "The summary incorrectly describes the function as handling a futex operation, which contradicts the source code's core purpose of reading directory entries via compat_sys_getdents64. This is a severe factual error on the primary purpose, misidentifying both the domain and I/O behavior, making the description unusable. No accurate, domain-specific claims are present to offset this error, and all details in the summary are unrelated noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Handles a futex operation by preparing parameters, invoking a handler, adjusting result codes, and optionally performing additional processing based on provided timing and control arguments.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary describes behavior related to futex operations, parameters, timing, and control arguments, which is entirely unrelated to the provided source code that implements a compat_sys_getdents64 function for reading directory entries. None of the claims align with the domain-semantic behavior of the actual function, resulting in 0% accurate claims.",
                "The summary's core claim about handling a futex operation is completely inaccurate, as the source code implements a compat_sys_getdents64 function that reads directory entries from a file descriptor. None of the claims match the core primary purpose of filling user-provided linux_dirent64 structures via vfs_readdir and handling access checks and error codes. There is no accurate coverage of the main domain-specific action or secondary behaviors like access_ok checks, fd retrieval, or updating d_off.",
                "The summary is entirely inaccurate, describing a futex operation with timing and control arguments, while the source code implements compat_sys_getdents64 to read directory entries from a file descriptor in a 64-bit compatibility context. This is a FATAL error on the primary purpose of the function, making the description unusable for understanding or working with the code."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_multilarge_nlinear_eval_df(const CBLAS_TRANSPOSE_t TransJ,\n                               const gsl_vector *x,\n                               const gsl_vector *f,\n                               const gsl_vector *u,\n                               const gsl_vector *swts,\n                               const double h,\n                               const gsl_multilarge_nlinear_fdtype fdtype,\n                               gsl_multilarge_nlinear_fdf *fdf,\n                               gsl_vector *v,\n                               gsl_matrix *JTJ,\n                               gsl_vector *work)\n{\n  const size_t n = fdf->n;\n  const size_t p = fdf->p;\n\n  if (u != NULL && ((TransJ == CblasNoTrans && u->size != p) ||\n                    (TransJ == CblasTrans && u->size != n)))\n    {\n      GSL_ERROR(\"u vector has wrong size\", GSL_EBADLEN);\n    }\n  else if (v != NULL && ((TransJ == CblasNoTrans && v->size != n) ||\n                         (TransJ == CblasTrans && v->size != p)))\n    {\n      GSL_ERROR(\"v vector has wrong size\", GSL_EBADLEN);\n    }\n  else if (JTJ != NULL && ((JTJ->size1 != p) || (JTJ->size2 != p)))\n    {\n      GSL_ERROR(\"JTJ matrix has wrong size\", GSL_EBADLEN);\n    }\n  else\n    {\n      int status;\n\n      if (fdf->df)\n        {\n          /* call user-supplied function */\n          status = ((*((fdf)->df)) (TransJ, x, u, fdf->params, v, JTJ));\n\n          if (v)\n            ++(fdf->nevaldfu);\n\n          if (JTJ)\n            ++(fdf->nevaldf2);\n        }\n      else\n        {\n#if 0\n          /* use finite difference Jacobian approximation */\n          status = gsl_multilarge_nlinear_df(h, fdtype, x, swts, fdf, f, df, work);\n#endif\n        }\n\n      return status;\n    }\n}",
    "comment": "Evaluates the Jacobian or its finite difference approximation for a nonlinear optimization problem, checking vector and matrix sizes for validity.",
    "prorec_sum": "Validates input vector and matrix dimensions for a nonlinear large-scale evaluation, reporting size errors before invoking the model\u2019s derivative function.",
    "filter_prorec_sum": "Validates vector and matrix dimensions for nonlinear evaluation, reports size errors, and calls the appropriate evaluation routine while updating call counters.",
    "prorec_aug_sum": "Validates vector and matrix dimensions for a nonlinear large-scale GSL solver before invoking its derivative evaluation callback.",
    "filter_prorec_aug_sum": "Validates vector and matrix dimensions for nonlinear large-scale evaluation, reporting size errors, then calls the model\u2019s derivative evaluation callback.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates vector and matrix dimensions for a nonlinear large-scale GSL solver before invoking its derivative evaluation callback.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary accurately states that the function validates vector and matrix dimensions before calling a derivative evaluation callback. This matches the code, which checks sizes of 'u', 'v', and 'JTJ' based on 'TransJ' and 'fdf->n/p', and then calls 'fdf->df' if available. The claim is specific, fact-based, and grounded in actual source semantics, with no inaccuracies detected.",
                "The summary accurately describes the dimension checks for vectors and matrices and the invocation of the derivative evaluation callback, which is the core purpose of the function. However, it omits secondary details such as the conditional behavior based on TransJ, the specific error handling with GSL_ERROR for wrong sizes, the tracking of evaluation counters (nevaldfu, nevaldf2), and the alternative finite difference Jacobian path when df is not provided. Coverage of these additional key semantics is weak.",
                "The summary accurately captures the primary purpose of the function: it performs dimension validation on input vectors and matrices before calling the derivative evaluation callback defined in the 'fdf' struct. There are no contradictory or irrelevant claims, but the description is generic and omits specifics like handling of TransJ for size checks, conditions for different parameters, and incrementing evaluation counters. The gain is low due to the lack of detail, though noise is minimal."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates vector and matrix dimensions for nonlinear large-scale evaluation, reporting size errors, then calls the model\u2019s derivative evaluation callback.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately captures the core semantics: the function checks vector and matrix dimensions and reports size errors, then invokes the derivative evaluation callback if defined. These details directly match the source code's validation logic and callback call, with no contradictions or irrelevant claims present.",
                "The summary correctly captures the core purpose of the function: checking input vector/matrix dimensions and reporting errors, then invoking the derivative evaluation callback. These details align with the source code\u2019s key steps. However, it omits secondary behavior such as handling different transpose modes, distinguishing between u, v, and JTJ size checks, incrementing evaluation counters after successful calls, and the conditional fallback to finite difference computation (though disabled here). This makes coverage of secondary semantics incomplete.",
                "The summary accurately captures the dimension validation for vectors and matrices and the error reporting, as well as the invocation of the derivative callback when available. These are core aspects of the source code\u2019s behavior. No incorrect or irrelevant claims are present, and the description is concise with low noise, though it omits some minor details such as conditional increments of counters and the handling of the absence of a derivative function. Overall, the claims are accurate but offer moderate detail."
            ]
        }
    }
}
{
    "source_code": "\nvoid\njitter_hash_table_add (struct jitter_hash_table *t,\n                       const union jitter_word key,\n                       const union jitter_word value,\n                       jitter_hash_function f)\n{\n  /* We only enlarge the table (when it's getting too full) on add, and never\n     shrink it. */\n  if (jitter_hash_table_overfull (t))\n    jitter_hash_table_enlarge (t, f);\n\n  t->binding_no ++;\n  jitter_uint bucket_index = f (key) % t->bucket_no;\n\n  /* Find the bucket; make it if needed. */\n  struct jitter_hash_bucket *b = t->buckets [bucket_index];\n  if (b == NULL)\n    {\n      b = jitter_xmalloc (sizeof (struct jitter_hash_bucket));\n      b->allocated_binding_no = INITIAL_BINDING_NO_PER_BUCKET;\n      b->used_binding_no = 0;\n      b->bindings\n        = jitter_xmalloc (sizeof (struct jitter_hash_binding)\n                          * INITIAL_BINDING_NO_PER_BUCKET);\n      t->buckets [bucket_index] = b;\n    }\n\n  /* Find the binding where we need to write within the bucket; make place and\n     reallocate if needed. */\n  if (b->used_binding_no == b->allocated_binding_no)\n    {\n      //printf (\"enlarging the %i-th bucket: %li to %li\\n\", (int)bucket_index, (long)b->allocated_binding_no, (long)(b->allocated_binding_no * 2));\n\n      b->bindings = jitter_xrealloc (b->bindings,\n                                     sizeof (struct jitter_hash_binding)\n                                     * (b->allocated_binding_no *= 2));\n    }\n  struct jitter_hash_binding *bi = b->bindings + (b->used_binding_no ++);\n  bi->key = key;\n  bi->value = value;\n}",
    "comment": "Adds a key-value pair to a jitter hash table, reallocating bucket space if necessary, while ensuring the table size increases when overfull.",
    "prorec_sum": "Inserts a key\u2013value pair into a hash table, allocating or expanding buckets as needed and handling hash collisions via per-bucket dynamic arrays.",
    "filter_prorec_sum": "Inserts a key\u2013value pair into a hash table, allocating and growing bucket storage as needed to maintain capacity.",
    "prorec_aug_sum": "Inserts a key\u2013value pair into a hash table, allocating or expanding bucket storage when needed and storing the key with its associated data.",
    "filter_prorec_aug_sum": "Inserts a key\u2013value pair into a hash table, allocating or expanding bucket arrays as needed based on load factor and bucket capacity.",
    "work_score": {
        "prorec_aug": {
            "summary": "Inserts a key\u2013value pair into a hash table, allocating or expanding bucket storage when needed and storing the key with its associated data.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function inserts a key\u2013value pair into a hash table, allocates or expands bucket storage when needed, and stores the key with its associated data. These are accurate and verifiable behaviors from the source code. Although it omits certain details like enlarging the table when overfull and not shrinking it, the claims present are all accurate, making the proportion of accurate claims very high.",
                "The summary correctly states that the function inserts a key\u2013value pair into a hash table and handles allocation or expansion of bucket storage when needed, matching the core domain purpose. It omits secondary details such as the pre-insertion check for table overfull condition and possible enlargement of the entire table, the specific use of a hash function to locate the proper bucket, initialization of new buckets with a fixed initial binding capacity, and the doubling of bucket capacity on reallocation. These omissions reduce completeness of coverage of other behavior-critical semantics.",
                "The summary correctly identifies the core purpose of the function as inserting a key\u2013value pair into a hash table and mentions allocation or expansion of bucket storage as needed, which aligns with the source code. It omits the specific detail that the table may be enlarged when overfull and that bucket reallocation occurs when bindings are full, but these omissions do not contradict the code. The claim is accurate but generic, offering low informational gain with minimal noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Inserts a key\u2013value pair into a hash table, allocating or expanding bucket arrays as needed based on load factor and bucket capacity.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function inserts a key\u2013value pair into a hash table and that it allocates or expands bucket arrays as needed, which matches the code\u2019s logic of enlarging the table when overfull and reallocating buckets when capacity is reached. However, the mention of 'load factor' slightly overgeneralizes the trigger condition since the code explicitly checks for 'overfull' rather than computing a load factor, making the claim mostly accurate but not perfectly precise.",
                "The summary accurately identifies the core purpose: adding a key\u2013value pair to a hash table, and it correctly notes allocation or expansion of buckets when needed. This aligns with the source code\u2019s logic of enlarging the table if overfull and reallocating bucket storage when capacity is reached. However, it omits secondary specifics such as the exact trigger for table enlargement (only on add, never shrinking), incrementing the binding count, and the calculation of the bucket index using the provided hash function. As a result, coverage of secondary behavior-critical details is partial.",
                "The summary correctly states that the function inserts a key\u2013value pair into a hash table and expands bucket arrays when needed, which matches the code\u2019s behavior of allocating new buckets if null and reallocating when full. It also captures that expansion happens based on load factor (via `jitter_hash_table_overfull`) before insertion. No inaccurate claims are present; all points are concise and relevant. However, the description is somewhat generic and lacks detail about the specific allocation sizes, non-shrinking policy, or hash index calculation, limiting its informational gain."
            ]
        }
    }
}
{
    "source_code": "\n\nvoid generate_file_priorities(struct dir_info *dir, int priority,\n\tstruct stat *buf)\n{\n\tstruct dir_ent *dir_ent = dir->list;\n\n\tpriority = get_priority(dir->pathname, buf, priority);\n\n\tfor(; dir_ent; dir_ent = dir_ent->next) {\n\t\tstruct stat *buf = &dir_ent->inode->buf;\n\t\tif(dir_ent->inode->root_entry)\n\t\t\tcontinue;\n\n\t\tswitch(buf->st_mode & S_IFMT) {\n\t\t\tcase S_IFREG:\n\t\t\t\tadd_priority_list(dir_ent,\n\t\t\t\t\tget_priority(pathname(dir_ent), buf,\n\t\t\t\t\tpriority));\n\t\t\t\tbreak;\n\t\t\tcase S_IFDIR:\n\t\t\t\tgenerate_file_priorities(dir_ent->dir,\n\t\t\t\t\tpriority, buf);\n\t\t\t\tbreak;\n\t\t}\n\t}\n}",
    "comment": "Recursively assigns priority values to regular files and directories within a specified directory structure based on their pathnames and inode information.",
    "prorec_sum": "Traverses a hierarchical file or link list, matching entries by identifiers, and processes them recursively or via a handler based on type flags.",
    "filter_prorec_sum": "Traverses linked file structures to propagate or update link-related identifiers, invoking child processing and handling special types via auxiliary lookup and operations.",
    "prorec_aug_sum": "Traverses a hierarchical structure to locate matching entries by identifiers, updating or processing linked nodes based on type-specific conditions.",
    "filter_prorec_aug_sum": "Traverses hierarchical data structures to match entries by identifiers and invokes appropriate processing routines based on node type flags and stored lookup values.",
    "work_score": {
        "prorec_aug": {
            "summary": "Traverses a hierarchical structure to locate matching entries by identifiers, updating or processing linked nodes based on type-specific conditions.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary is largely inaccurate because it describes locating entries by identifiers, which is not reflected in the function; the code iterates through directory entries and processes them according to file type, updating priorities. While it correctly notes traversal of a hierarchical structure and type-specific conditions, it omits the distinction between files and directories via S_IFREG/S_IFDIR and misrepresents the criteria for processing as identifier matching rather than type or priority logic. Only a small proportion of claims align correctly with the code.",
                "The summary does not correctly capture the core behavior of iterating directory entries to assign priorities based on file type. It inaccurately describes 'locating matching entries by identifiers', which is not reflected in the source code, and omits the primary purpose of updating priorities for files and recursing into subdirectories. It also lacks coverage of specific branching logic for regular files and directories, making it incomplete and misaligned with the source semantics.",
                "The summary inaccurately describes the function's primary purpose: the source code does not locate entries by identifiers, but rather iterates through directory entries in a hierarchical structure to assign priorities based on file type. This is a FATAL error affecting the core domain action. There are no specific, accurate GOLD claims\u2014only vague and misleading descriptions\u2014so the net benefit is very low."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Traverses hierarchical data structures to match entries by identifiers and invokes appropriate processing routines based on node type flags and stored lookup values.",
            "score": [
                0.2,
                0.3,
                0.3
            ],
            "reason": [
                "The summary contains mostly inaccurate claims relative to the source code. While the code does traverse a hierarchical structure and processes nodes based on type flags (`S_IFREG`, `S_IFDIR`), it does not match entries by identifiers or use stored lookup values as described. Instead, it applies priority calculations and invokes file or directory-specific routines. The proportion of accurate claims is below half, indicating low alignment with the actual semantics.",
                "The summary generically mentions traversal and processing based on type flags, which loosely aligns with the function\u2019s iteration over directory entries and switch on file type. However, it omits the core purpose of generating and assigning file priorities via get_priority and add_priority_list, and lacks mention of recursion into subdirectories or skipping root entries. Key side effects and external interactions from the source code are missing, resulting in incomplete coverage.",
                "The summary is largely inaccurate: it describes matching entries by identifiers and using stored lookup values, which are not present in the source code. The actual function traverses a directory list, checks root entry flags, determines item type via st_mode, and applies priority logic or recursion. This mismatch constitutes NOISE that overwhelms any accurate element, and there are no specific GOLD details aligned with the core domain behavior. Worst failure mode is NOISE, with very low positive gain from accuracy."
            ]
        }
    }
}
{
    "source_code": "void ZSTDMT_compressChunk(void* jobDescription)\n{\n    ZSTDMT_jobDescription* const job = (ZSTDMT_jobDescription*)jobDescription;\n    const void* const src = (const char*)job->srcStart + job->dictSize;\n    buffer_t const dstBuff = job->dstBuff;\n    DEBUGLOG(3, \"job (first:%u) (last:%u) : dictSize %u, srcSize %u\", job->firstChunk, job->lastChunk, (U32)job->dictSize, (U32)job->srcSize);\n    if (job->cdict) {\n        size_t const initError = ZSTD_compressBegin_usingCDict(job->cctx, job->cdict, job->fullFrameSize);\n        if (job->cdict) DEBUGLOG(3, \"using CDict \");\n        if (ZSTD_isError(initError)) { job->cSize = initError; goto _endJob; }\n    } else {\n        size_t const initError = ZSTD_compressBegin_advanced(job->cctx, job->srcStart, job->dictSize, job->params, job->fullFrameSize);\n        if (ZSTD_isError(initError)) { job->cSize = initError; goto _endJob; }\n        ZSTD_setCCtxParameter(job->cctx, ZSTD_p_forceWindow, 1);\n    }\n    if (!job->firstChunk) {  /* flush frame header */\n        size_t const hSize = ZSTD_compressContinue(job->cctx, dstBuff.start, dstBuff.size, src, 0);\n        if (ZSTD_isError(hSize)) { job->cSize = hSize; goto _endJob; }\n        ZSTD_invalidateRepCodes(job->cctx);\n    }\n\n    DEBUGLOG(4, \"Compressing : \");\n    DEBUG_PRINTHEX(4, job->srcStart, 12);\n    job->cSize = (job->lastChunk) ?   /* last chunk signal */\n                 ZSTD_compressEnd     (job->cctx, dstBuff.start, dstBuff.size, src, job->srcSize) :\n                 ZSTD_compressContinue(job->cctx, dstBuff.start, dstBuff.size, src, job->srcSize);\n    DEBUGLOG(3, \"compressed %u bytes into %u bytes   (first:%u) (last:%u)\", (unsigned)job->srcSize, (unsigned)job->cSize, job->firstChunk, job->lastChunk);\n\n_endJob:\n    PTHREAD_MUTEX_LOCK(job->jobCompleted_mutex);\n    job->jobCompleted = 1;\n    job->jobScanned = 0;\n    pthread_cond_signal(job->jobCompleted_cond);\n    pthread_mutex_unlock(job->jobCompleted_mutex);\n}",
    "comment": "Compresses data chunks using a context or dictionary, managing the compression state and signaling job completion through condition variables.",
    "prorec_sum": "Opens or reopens a B-tree cursor for a specified table segment, selecting creation or retrieval path based on existing handles and configuration flags.",
    "filter_prorec_sum": "Creates or reuses a B-tree cursor for a specified table or index and marks the cursor as active for subsequent operations.",
    "prorec_aug_sum": "Constructs or retrieves an internal resource handle using stored parameters, selecting creation or lookup paths, and updates state indicators upon successful acquisition.",
    "filter_prorec_aug_sum": "Initializes or retrieves an object handle using provided parameters and updates related state fields based on the success of creation or lookup operations.",
    "work_score": {
        "prorec_aug": {
            "summary": "Constructs or retrieves an internal resource handle using stored parameters, selecting creation or lookup paths, and updates state indicators upon successful acquisition.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about constructing or retrieving an internal resource handle, choosing creation or lookup paths, and updating state indicators do not accurately describe the source code, which performs chunk compression using either a preloaded dictionary or specified parameters, handles errors, and signals job completion. None of the claims match the actual compression and synchronization logic, resulting in a purely inaccurate mapping.",
                "The summary describes generic resource handle acquisition and state updates, which does not align with the source code's specific purpose of compressing a chunk of data in a multi-threaded ZSTD context with conditional initialization paths, processing first/last chunks, handling errors, and signaling job completion. It misses the core compression semantics entirely and provides no accurate domain-specific details from the code.",
                "The summary is entirely inaccurate regarding the source code\u2019s semantics. The function does not construct or retrieve a generic internal resource handle via creation/lookup paths; it specifically performs chunk compression using either a prepared dictionary or advanced compression setup, writes output to a buffer, and signals job completion. The described behavior is noise unrelated to the actual primary purpose and key I/O, making it unusable for understanding the function."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes or retrieves an object handle using provided parameters and updates related state fields based on the success of creation or lookup operations.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary makes vague, generic claims about initializing or retrieving an object handle and updating state based on success, which do not align with the specific compression logic, conditional branching, and mutex signaling present in the source code. None of the claims directly or accurately describe the function\u2019s domain-semantic behavior, resulting in 0% accurate claims.",
                "The summary makes a generic claim about initializing or retrieving an object handle and updating state fields, which does not match the specific domain semantics of compressing a chunk with Zstandard multi-threading, handling initialization with or without a prepared dictionary, processing first/last chunk cases, and signaling job completion. The core purpose of performing chunk compression is completely absent, and no other accurate details from the source are covered.",
                "The summary's claim about initializing or retrieving an object handle via creation or lookup does not match the source code's primary purpose, which is compressing a data chunk in a multithreaded context using ZSTD compression functions. The function sets up compression based on a dictionary, processes chunks, and signals job completion. The provided description is generic, inaccurate regarding the core domain semantics, and omits key I/O behavior, constituting a severe FATAL error on the primary purpose."
            ]
        }
    }
}
{
    "source_code": "\nSEXP attribute_hidden do_Rhome(SEXP call, SEXP op, SEXP args, SEXP rho)\n{\n    char *path;\n    checkArity(op, args);\n    if (!(path = R_HomeDir()))\n\terror(_(\"unable to determine R home location\"));\n    return mkString(path);\n}",
    "comment": "Returns the R home directory path as a string after verifying the function's arity and checking if the path can be determined.",
    "prorec_sum": "Returns a single-element character vector containing R\u2019s home directory path, raising an error if the home location cannot be determined.",
    "filter_prorec_sum": "Returns a character vector containing the R home directory path, raising an error if the location cannot be determined.",
    "prorec_aug_sum": "Creates a single-element character vector containing the R home directory path, raising an error if the location cannot be determined.",
    "filter_prorec_aug_sum": "Creates a character vector containing the R home directory path, returning an error if the home location cannot be determined.",
    "work_score": {
        "prorec_aug": {
            "summary": "Creates a single-element character vector containing the R home directory path, raising an error if the location cannot be determined.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function returns a single-element character vector containing the R home directory path and that it raises an error if the location cannot be determined. Both claims match the source code\u2019s behavior exactly, indicating high precision and alignment.",
                "The summary accurately describes the function\u2019s core purpose: creating a character vector containing the R home directory path and raising an error if it cannot be determined. This matches the source code\u2019s logic involving R_HomeDir(), error handling, and mkString(). However, it omits secondary details such as the checkArity call, which enforces argument count, thereby missing some behavioral specifics.",
                "The summary accurately states the core behavior: the function creates a character vector containing the R home directory path and raises an error if it cannot be determined. These are specific and verifiable claims directly reflected in the source code, with no inaccuracies or irrelevant noise present. The detail about single-element output and error condition provides clear insight into the function's primary purpose."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Creates a character vector containing the R home directory path, returning an error if the home location cannot be determined.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary states that the function creates a character vector containing the R home directory path and returns an error if it cannot be determined. Both claims are accurate based on the source code: the function calls R_HomeDir() to retrieve the path, raises an error when the result is null, and returns mkString(path) as a character vector. There are no incorrect or irrelevant statements in the summary, making all claims accurate.",
                "The summary correctly identifies the core purpose as creating and returning a string with the R home directory path and notes the error if the path cannot be determined, matching the source code's semantics. It misses minor secondary details such as the explicit argument arity check before determining the path, but overall accurately captures the primary domain-specific operation.",
                "The summary correctly states that the function returns a character vector containing the R home directory path and that it raises an error if the path cannot be determined. These details match the source code's use of `mkString(path)` and `error()` when `R_HomeDir()` fails, making all claims accurate and specific to the code. There is no noise or contradictory information, and the claims convey the function's primary purpose and key behavior clearly."
            ]
        }
    }
}
{
    "source_code": "int snd_hda_mixer_amp_volume_get(struct snd_kcontrol *kcontrol,\n\t\t\t\t struct snd_ctl_elem_value *ucontrol)\n{\n\tstruct hda_codec *codec = snd_kcontrol_chip(kcontrol);\n\thda_nid_t nid = get_amp_nid(kcontrol);\n\tint chs = get_amp_channels(kcontrol);\n\tint dir = get_amp_direction(kcontrol);\n\tint idx = get_amp_index(kcontrol);\n\tunsigned int ofs = get_amp_offset(kcontrol);\n\tlong *valp = ucontrol->value.integer.value;\n\n\tif (chs & 1)\n\t\t*valp++ = read_amp_value(codec, nid, 0, dir, idx, ofs);\n\tif (chs & 2)\n\t\t*valp = read_amp_value(codec, nid, 1, dir, idx, ofs);\n\treturn 0;\n}",
    "comment": "Retrieves and stores the volume values for specified audio channels from a sound codec's amplifier settings into the provided control element structure.",
    "prorec_sum": "Computes adjusted audio control values from codec registers and writes them to output slots based on specific flag and bitfield conditions.",
    "filter_prorec_sum": "Computes adjusted values from codec registers and updates output buffer fields based on specific control bits and a helper processing routine.",
    "prorec_aug_sum": "Computes adjusted values from codec configuration bits using a helper routine and stores them into specific offsets within the provided output structure.",
    "filter_prorec_aug_sum": "Updates codec-related output registers based on specific control bits, calculating values via a helper function and applying range limits before storing.",
    "work_score": {
        "prorec_aug": {
            "summary": "Computes adjusted values from codec configuration bits using a helper routine and stores them into specific offsets within the provided output structure.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary inaccurately describes the function as computing adjusted values from codec configuration bits and storing them at specific offsets, which does not align with the actual code. The code reads amplifier values from the codec for selected channels using helper functions and writes them into the provided control structure. No direct mention of configuration bits or offset-specific storage semantics exists in the implementation, making nearly all claims incorrect.",
                "The summary fails to convey the core purpose of reading amplifier volume levels from the codec for specific channels using helper functions and populating them into the provided control element structure. Instead, it inaccurately describes 'computing adjusted values from codec configuration bits', which does not match the actual read operations from hardware amp parameters. No accurate claim covers the core domain operation, and there is no mention of the channel-specific branching or helper routines to retrieve values.",
                "The summary claims that the function computes adjusted values from codec configuration bits and stores them into specific offsets in the provided structure. In reality, the source code reads raw amplifier values for specific channels from the codec using helper functions and writes them sequentially into the output structure. The mention of 'adjusted values' and 'configuration bits' is inaccurate and misrepresents the core purpose, which is to read and return amp values for channels. This is a FATAL error affecting the PRIMARY PURPOSE, leaving no reliable understanding of the function's main behavior."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Updates codec-related output registers based on specific control bits, calculating values via a helper function and applying range limits before storing.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as updating codec-related output registers and applying range limits, which is not present in the source code. The source code reads amplifier values from the codec into the control structure based on channel bits and does not modify registers or enforce range limits. This means the factual alignment is very low, with most claims being inaccurate.",
                "The summary misrepresents the function\u2019s core behavior. The source code reads amplifier volume values from the codec for specified channels using helper functions, without updating output registers or applying range limits. It omits the actual core purpose of retrieving and populating volume values based on channel bits, and instead incorrectly describes an update process. No accurate claims cover the core domain semantics, leading to a failure to meet the evaluation criteria.",
                "The summary claims the function updates codec-related output registers and applies range limits before storing, which is inaccurate. The source code shows it reads amplifier values from the codec via helper functions and writes them into ucontrol, with no output register updates or range limiting. This is a FATAL error on the primary purpose, making the summary misleading and unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic struct demangle_component *\nd_make_comp (struct d_info *di, enum demangle_component_type type,\n             struct demangle_component *left,\n             struct demangle_component *right)\n{\n  struct demangle_component *p;\n\n  /* We check for errors here.  A typical error would be a NULL return\n     from a subroutine.  We catch those here, and return NULL\n     upward.  */\n  switch (type)\n    {\n      /* These types require two parameters.  */\n    case DEMANGLE_COMPONENT_QUAL_NAME:\n    case DEMANGLE_COMPONENT_LOCAL_NAME:\n    case DEMANGLE_COMPONENT_TYPED_NAME:\n    case DEMANGLE_COMPONENT_TAGGED_NAME:\n    case DEMANGLE_COMPONENT_TEMPLATE:\n    case DEMANGLE_COMPONENT_CONSTRUCTION_VTABLE:\n    case DEMANGLE_COMPONENT_VENDOR_TYPE_QUAL:\n    case DEMANGLE_COMPONENT_PTRMEM_TYPE:\n    case DEMANGLE_COMPONENT_UNARY:\n    case DEMANGLE_COMPONENT_BINARY:\n    case DEMANGLE_COMPONENT_BINARY_ARGS:\n    case DEMANGLE_COMPONENT_TRINARY:\n    case DEMANGLE_COMPONENT_TRINARY_ARG1:\n    case DEMANGLE_COMPONENT_LITERAL:\n    case DEMANGLE_COMPONENT_LITERAL_NEG:\n    case DEMANGLE_COMPONENT_COMPOUND_NAME:\n    case DEMANGLE_COMPONENT_VECTOR_TYPE:\n    case DEMANGLE_COMPONENT_CLONE:\n      if (left == NULL || right == NULL)\n\treturn NULL;\n      break;\n\n      /* These types only require one parameter.  */\n    case DEMANGLE_COMPONENT_VTABLE:\n    case DEMANGLE_COMPONENT_VTT:\n    case DEMANGLE_COMPONENT_TYPEINFO:\n    case DEMANGLE_COMPONENT_TYPEINFO_NAME:\n    case DEMANGLE_COMPONENT_TYPEINFO_FN:\n    case DEMANGLE_COMPONENT_THUNK:\n    case DEMANGLE_COMPONENT_VIRTUAL_THUNK:\n    case DEMANGLE_COMPONENT_COVARIANT_THUNK:\n    case DEMANGLE_COMPONENT_JAVA_CLASS:\n    case DEMANGLE_COMPONENT_GUARD:\n    case DEMANGLE_COMPONENT_TLS_INIT:\n    case DEMANGLE_COMPONENT_TLS_WRAPPER:\n    case DEMANGLE_COMPONENT_REFTEMP:\n    case DEMANGLE_COMPONENT_HIDDEN_ALIAS:\n    case DEMANGLE_COMPONENT_TRANSACTION_CLONE:\n    case DEMANGLE_COMPONENT_NONTRANSACTION_CLONE:\n    case DEMANGLE_COMPONENT_POINTER:\n    case DEMANGLE_COMPONENT_REFERENCE:\n    case DEMANGLE_COMPONENT_RVALUE_REFERENCE:\n    case DEMANGLE_COMPONENT_COMPLEX:\n    case DEMANGLE_COMPONENT_IMAGINARY:\n    case DEMANGLE_COMPONENT_VENDOR_TYPE:\n    case DEMANGLE_COMPONENT_CAST:\n    case DEMANGLE_COMPONENT_CONVERSION:\n    case DEMANGLE_COMPONENT_JAVA_RESOURCE:\n    case DEMANGLE_COMPONENT_DECLTYPE:\n    case DEMANGLE_COMPONENT_PACK_EXPANSION:\n    case DEMANGLE_COMPONENT_GLOBAL_CONSTRUCTORS:\n    case DEMANGLE_COMPONENT_GLOBAL_DESTRUCTORS:\n    case DEMANGLE_COMPONENT_NULLARY:\n    case DEMANGLE_COMPONENT_TRINARY_ARG2:\n      if (left == NULL)\n\treturn NULL;\n      break;\n\n      /* This needs a right parameter, but the left parameter can be\n\t empty.  */\n    case DEMANGLE_COMPONENT_ARRAY_TYPE:\n    case DEMANGLE_COMPONENT_INITIALIZER_LIST:\n      if (right == NULL)\n\treturn NULL;\n      break;\n\n      /* These are allowed to have no parameters--in some cases they\n\t will be filled in later.  */\n    case DEMANGLE_COMPONENT_FUNCTION_TYPE:\n    case DEMANGLE_COMPONENT_RESTRICT:\n    case DEMANGLE_COMPONENT_VOLATILE:\n    case DEMANGLE_COMPONENT_CONST:\n    case DEMANGLE_COMPONENT_ARGLIST:\n    case DEMANGLE_COMPONENT_TEMPLATE_ARGLIST:\n    FNQUAL_COMPONENT_CASE:\n      break;\n\n      /* Other types should not be seen here.  */\n    default:\n      return NULL;\n    }\n\n  p = d_make_empty (di);\n  if (p != NULL)\n    {\n      p->type = type;\n      p->u.s_binary.left = left;\n      p->u.s_binary.right = right;\n    }\n  return p;\n}",
    "comment": "Constructs a demangle component by validating parameters based on type and initializing its properties, returning NULL for errors or invalid types.",
    "prorec_sum": "Adds an entry with specified type and parameters to a bounded array if the type and nonzero arguments satisfy required conditions.",
    "filter_prorec_sum": "Appends a new entry with given type and parameters to a bounded list within the structure if case-specific non\u2011null conditions are satisfied.",
    "prorec_aug_sum": "Appends a new entry with specified type and parameters to an internal list if conditions based on the type code and arguments are met.",
    "filter_prorec_aug_sum": "Adds an entry with given type and parameters to a bounded list if the type and arguments satisfy specific switch-case acceptance conditions.",
    "work_score": {
        "prorec_aug": {
            "summary": "Appends a new entry with specified type and parameters to an internal list if conditions based on the type code and arguments are met.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary is mostly inaccurate: it claims the function appends a new entry to an internal list, but the source code shows it constructs and returns a single `demangle_component` struct without maintaining any list. While it correctly notes conditions based on type and arguments are checked, the core behavior described in the summary contradicts the actual semantics. Only a small portion of the summary aligns with the code, resulting in low accuracy.",
                "The summary inaccurately describes the core purpose as appending an entry to a list, while the code creates and initializes a demangle_component struct based on type-specific parameter checks. It fails to convey the domain-specific goal of constructing this component and omits critical details such as different parameter requirements for various types, error handling via NULL returns, and the use of d_make_empty for allocation. The core operation is not covered, and secondary behaviors are missing.",
                "The summary inaccurately describes the function as appending to an internal list, which is not supported by the source code. The actual code creates and returns a new 'demangle_component' struct if arguments meet specific null-check conditions, with no list manipulation present. This is a FATAL error targeting the primary purpose, making the summary misleading despite partially noting conditional behavior based on type and arguments."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Adds an entry with given type and parameters to a bounded list if the type and arguments satisfy specific switch-case acceptance conditions.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains an inaccurate claim that the function adds an entry to a bounded list, whereas the source code shows it allocates and initializes a demangle_component without operating on any bounded list. While the mention of type and parameter validation via switch-case is correct, the core described action does not match the code\u2019s actual behavior. This results in less than half of the claims being accurate.",
                "The summary is inaccurate because it misrepresents the core purpose: the function constructs and returns a demangle_component object with given type and child components after parameter validation, not adding an entry to a bounded list. While it mentions acceptance conditions via switch-case, the reference to a bounded list is unsupported by the source code, and the core demangle-related creation is missing. There is little accurate coverage of other critical behaviors like NULL checks for different parameter requirements or the return of NULL on invalid type or parameters.",
                "The summary inaccurately describes the function as adding an entry to a bounded list, which is not reflected in the source code. The code constructs and returns a demangle_component if certain parameter conditions are met, without any list manipulation. This is a FATAL error about the primary purpose, misrepresenting the core action. No highly specific, accurate claims remain to provide useful insight, so the net benefit is essentially zero."
            ]
        }
    }
}
{
    "source_code": "static enum mu_filter_result\n_c_escape_decoder (void *xd MU_ARG_UNUSED,\n\t\t   enum mu_filter_command cmd,\n\t\t   struct mu_filter_io *iobuf)\n{\n  size_t i, j;\n  const unsigned char *iptr;\n  size_t isize;\n  char *optr;\n  size_t osize;\n  \n  switch (cmd)\n    {\n    case mu_filter_init:\n    case mu_filter_done:\n      return mu_filter_ok;\n    default:\n      break;\n    }\n  \n  iptr = (const unsigned char *) iobuf->input;\n  isize = iobuf->isize;\n  optr = iobuf->output;\n  osize = iobuf->osize;\n\n  for (i = j = 0; i < isize && j < osize; i++)\n    {\n      unsigned char c = *iptr++;\n      if (c == '\\\\')\n\t{\n\t  int x;\n\t  if (i + 1 == isize)\n\t    break;\n\t  c = *iptr++;\n\t  i++;\n\t  x = mu_wordsplit_c_unquote_char (c);\n\t  optr[j++] = (x == -1) ? c : x;\n\t}\n      else\n\toptr[j++] = c;\n    }\n\n  iobuf->isize = i;\n  iobuf->osize = j;\n  return mu_filter_ok;\n}",
    "comment": "Decodes escape sequences in the input buffer by replacing backslash-prefixed characters with their unquoted equivalents, storing results in the output buffer.",
    "prorec_sum": "Processes an input byte sequence, handling backslash escape sequences via character unquoting, and writes the resulting bytes into an output buffer.",
    "filter_prorec_sum": "Processes an input byte sequence, handling backslash escape sequences via `mu_wordsplit_c_unquote_char`, and writes the unescaped result to the output buffer.",
    "prorec_aug_sum": "Processes an input byte stream, decoding backslash escape sequences into characters and writing the result into an output buffer with updated position counters.",
    "filter_prorec_aug_sum": "Processes an input byte stream, decoding backslash escape sequences into unquoted characters and writing the result into the output buffer.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes an input byte stream, decoding backslash escape sequences into characters and writing the result into an output buffer with updated position counters.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately reflects the function's behavior: it iterates over the input byte stream, interprets backslash escape sequences using a decoding routine, writes the output to the buffer, and updates the buffer position counters. There are no contradictory or irrelevant claims; all details match the source code's semantics, indicating very high precision.",
                "The summary correctly captures the core purpose of decoding backslash escape sequences from an input stream into an output buffer, which matches the function\u2019s main loop and use of mu_wordsplit_c_unquote_char. It also notes the update of position counters, reflecting iobuf->isize and iobuf->osize assignments. However, it omits secondary details such as handling of specific mu_filter_command cases (init, done returning early), the break on incomplete escape at end of input, and constraints from output buffer size limits, so coverage of secondary semantics is moderate but incomplete.",
                "The summary correctly captures the primary purpose of the function: it reads an input byte stream, decodes backslash escape sequences into corresponding characters, writes them to the output buffer, and updates position counters. This is a specific and accurate description of the core domain behavior with no contradictory or irrelevant claims, resulting in high gain from accurate information and negligible noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes an input byte stream, decoding backslash escape sequences into unquoted characters and writing the result into the output buffer.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately captures the core behavior of the function: it reads an input byte stream, identifies backslash escape sequences, replaces them with their unquoted character equivalents using a helper, and writes the decoded data into the output buffer. There are no extraneous or incorrect claims; the description maps directly to observable logic in the code, including the loop processing and transformation. All claims pertain to source code semantics and are correct.",
                "The summary accurately states the core purpose of decoding backslash escape sequences into their unquoted form and writing them to the output buffer, matching the function's main loop behavior. It covers the primary domain-specific action in sufficient detail. However, it omits secondary details such as the handling of mu_filter_init and mu_filter_done commands, the break condition when a trailing backslash is found, limits imposed by buffer sizes, and the update of input/output sizes in the iobuf structure.",
                "The summary correctly captures the core purpose of the function: decoding backslash escape sequences from the input stream using a character unquoting routine and writing the processed output to the buffer. This is an accurate reflection of the source code\u2019s behavior, including the primary purpose and key I/O semantics. There is no incorrect or irrelevant information, and the claim is specific enough to provide value without noise."
            ]
        }
    }
}
{
    "source_code": "int\nevutil_read_file_(const char *filename, char **content_out, size_t *len_out,\n    int is_binary)\n{\n\tint fd, r;\n\tstruct stat st;\n\tchar *mem;\n\tsize_t read_so_far=0;\n\tint mode = O_RDONLY;\n\n\tEVUTIL_ASSERT(content_out);\n\tEVUTIL_ASSERT(len_out);\n\t*content_out = NULL;\n\t*len_out = 0;\n\n#ifdef O_BINARY\n\tif (is_binary)\n\t\tmode |= O_BINARY;\n#endif\n\n\tfd = evutil_open_closeonexec_(filename, mode, 0);\n\tif (fd < 0)\n\t\treturn -1;\n\tif (fstat(fd, &st) || st.st_size < 0 ||\n\t    st.st_size > EV_SSIZE_MAX-1 ) {\n\t\tclose(fd);\n\t\treturn -2;\n\t}\n\tmem = mm_malloc((size_t)st.st_size + 1);\n\tif (!mem) {\n\t\tclose(fd);\n\t\treturn -2;\n\t}\n\tread_so_far = 0;\n#ifdef _WIN32\n#define N_TO_READ(x) ((x) > INT_MAX) ? INT_MAX : ((int)(x))\n#else\n#define N_TO_READ(x) (x)\n#endif\n\twhile ((r = read(fd, mem+read_so_far, N_TO_READ(st.st_size - read_so_far))) > 0) {\n\t\tread_so_far += r;\n\t\tif (read_so_far >= (size_t)st.st_size)\n\t\t\tbreak;\n\t\tEVUTIL_ASSERT(read_so_far < (size_t)st.st_size);\n\t}\n\tclose(fd);\n\tif (r < 0) {\n\t\tmm_free(mem);\n\t\treturn -2;\n\t}\n\tmem[read_so_far] = 0;\n\n\t*len_out = read_so_far;\n\t*content_out = mem;\n\treturn 0;\n}",
    "comment": "Reads the contents of a specified file into a dynamically allocated buffer, returning the length and handling binary mode if specified.",
    "prorec_sum": "Reads the entire contents of a file into a newly allocated null-terminated buffer, returning its size and handling errors appropriately.",
    "filter_prorec_sum": "Reads the entire contents of a file into a newly allocated, null-terminated buffer and returns its address and length via output parameters.",
    "prorec_aug_sum": "Reads the entire contents of a file into a newly allocated null\u2011terminated buffer, returning its size and handling file or memory errors.",
    "filter_prorec_aug_sum": "Reads the entire contents of a file into a newly allocated, null\u2011terminated buffer and returns its pointer and length via output parameters.",
    "work_score": {
        "prorec_aug": {
            "summary": "Reads the entire contents of a file into a newly allocated null\u2011terminated buffer, returning its size and handling file or memory errors.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function reads the file contents into a newly allocated null-terminated buffer, returns the size, and handles errors related to file operations or memory allocation. These are all accurate and directly supported by the code, with no contradictory or irrelevant claims present. All claims are precise and align with the function's semantics, yielding high accuracy.",
                "The summary accurately captures the core purpose of the function \u2014 reading the full file contents into a newly allocated null\u2011terminated buffer and returning its size \u2014 and notes error handling for file and memory operations. This directly aligns with the function\u2019s primary behavior in the source code. However, it omits several secondary details, such as binary mode handling with O_BINARY, specific file size validation limits, the use of platform\u2011dependent read limits, and explicit cleanup steps on error. The coverage of the core is strong, but secondary coverage is only moderate.",
                "The summary correctly states that the function reads the entire contents of a file into a newly allocated null\u2011terminated buffer, returns its size, and handles file or memory errors. These are accurate reflections of the code's core behavior and error handling logic. The claims are specific and domain-relevant with no inaccuracies or noise. Positive gain is high due to precise coverage of the primary purpose and key I/O behavior, with low noise and no contradictions."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Reads the entire contents of a file into a newly allocated, null\u2011terminated buffer and returns its pointer and length via output parameters.",
            "score": [
                0.9,
                0.4,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function reads the entire file into a newly allocated buffer, null-terminates it, and provides both pointer and length via output parameters, all of which match the source code\u2019s behavior. It omits minor details such as binary mode handling, error codes, and allocation size checks, but these omissions do not contradict or misrepresent the code. The single claim is precise and aligns well with the implementation.",
                "The summary accurately captures the core purpose of the function: reading an entire file into a newly allocated, null\u2011terminated buffer and returning its pointer and length via output parameters. This matches the function's main domain\u2011specific effect. However, it omits important secondary details from the source code, such as handling of binary mode flags, size and allocation checks, error return values, platform\u2011specific read limits, and cleanup on failure. The coverage of secondary behavior is minimal, making it incomplete beyond the core.",
                "The summary accurately states the primary purpose of the function: it reads the entire file into a newly allocated, null\u2011terminated buffer and provides both the pointer and the length via output parameters. This matches the source code\u2019s behavior, including the allocation, null\u2011termination, and setting of both output values. There is no contradictory or irrelevant information (no FATAL or excessive NOISE), but the description is somewhat generic without mentioning specific error handling or binary mode considerations, making the gain modest rather than high."
            ]
        }
    }
}
{
    "source_code": "\nstatic int disk_status(struct dm_dirty_log *log, status_type_t status,\n\t\t       char *result, unsigned int maxlen)\n{\n\tint sz = 0;\n\tstruct log_c *lc = log->context;\n\n\tswitch(status) {\n\tcase STATUSTYPE_INFO:\n\t\tDMEMIT(\"3 %s %s %c\", log->type->name, lc->log_dev->name,\n\t\t       lc->log_dev_flush_failed ? 'F' :\n\t\t       lc->log_dev_failed ? 'D' :\n\t\t       'A');\n\t\tbreak;\n\n\tcase STATUSTYPE_TABLE:\n\t\tDMEMIT(\"%s %u %s %u \", log->type->name,\n\t\t       lc->sync == DEFAULTSYNC ? 2 : 3, lc->log_dev->name,\n\t\t       lc->region_size);\n\t\tDMEMIT_SYNC;\n\t}\n\n\treturn sz;\n}",
    "comment": "Generates and emits status information for a dirty log based on the provided status type, including device name and synchronization details.",
    "prorec_sum": "Formats and writes synchronization or status information into a buffer based on provided parameters and internal structure fields.",
    "filter_prorec_sum": "Formats and writes synchronization or status command strings with device-specific fields into a provided buffer based on mode and internal state flags.",
    "prorec_aug_sum": "Formats and writes connection or device status information, including sync state or mode indicator, into the provided output buffer based on input parameters.",
    "filter_prorec_aug_sum": "Formats and writes synchronization or status command strings into a buffer based on mode and object state fields.",
    "work_score": {
        "prorec_aug": {
            "summary": "Formats and writes connection or device status information, including sync state or mode indicator, into the provided output buffer based on input parameters.",
            "score": [
                0.9,
                0.2,
                0.5
            ],
            "reason": [
                "The summary correctly identifies that the function formats and writes device status information (via DMEMIT) into an output buffer and that the output varies with input parameters. It slightly generalizes by mentioning 'connection or device' and 'sync state or mode indicator' rather than explicitly describing the specific status types and flags in the code, but all factual claims align with the function\u2019s behavior. High alignment with minor generic wording earns a near-perfect assessment.",
                "The summary gives a vague and partly inaccurate description, referring to 'connection' which is not present in the source code. It does not specifically identify the core action of emitting disk or log device status via DMEMIT based on STATUSTYPE_INFO or STATUSTYPE_TABLE, including specific indicators such as 'F', 'D', or 'A', and sync values. The core purpose\u2014formatting and outputting the log device's status depending on the status type\u2014is not explicitly covered, and no secondary implementation details (like conditions, constants, or external interactions) are mentioned.",
                "The summary is generally accurate in describing that the function formats and writes status information to an output buffer based on parameters. However, it is somewhat vague, using generic terms like 'connection or device status' and 'sync state or mode indicator' without specifying the precise conditions or values from the code (e.g., the type name, device name, specific status characters 'F', 'D', 'A', region size). There are no outright contradictions (no FATAL), but the lack of detail means it provides only low informational gain and minimal alignment with the actual code semantics."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Formats and writes synchronization or status command strings into a buffer based on mode and object state fields.",
            "score": [
                0.8,
                0.2,
                0.6
            ],
            "reason": [
                "The summary correctly describes that the function formats and writes status information into a buffer depending on mode (status type) and object state. It reflects the use of different formatting for STATUSTYPE_INFO and STATUSTYPE_TABLE. However, it omits certain specifics such as the exact output format and returned value, making it slightly generic but still accurate in essence.",
                "The summary provides a generic description of formatting and writing status/synchronization strings but does not accurately capture the core purpose of the function, which is to emit specific disk log status information in two distinct formats (INFO and TABLE) including device names, failure indicators, sync values, and region size. While the summary touches on mode-based string formatting, it misses critical domain-specific details such as the conditional failure character output and the inclusion of region size, thus the core purpose is not covered.",
                "The summary correctly captures the high-level behavior that the function formats and writes status information into a buffer based on a mode and object state fields, which aligns broadly with the switch on `status` and the DMEMIT calls. However, it is very generic, omitting specific details such as the exact modes (`STATUSTYPE_INFO` and `STATUSTYPE_TABLE`), the particular fields used (`log->type->name`, `lc->log_dev->name`, failure flags, `region_size`), and the precise format of the output. There are no inaccurate claims, but the lack of specific, verifiable detail means the gain is low."
            ]
        }
    }
}
{
    "source_code": "int\nrl_insert_text (const char *string)\n{\n  register int i, l;\n\n  l = (string && *string) ? strlen (string) : 0;\n  if (l == 0)\n    return 0;\n\n  if (rl_end + l >= rl_line_buffer_len)\n    rl_extend_line_buffer (rl_end + l);\n\n  for (i = rl_end; i >= rl_point; i--)\n    rl_line_buffer[i + l] = rl_line_buffer[i];\n\n  strncpy (rl_line_buffer + rl_point, string, l);\n\n  /* Remember how to undo this if we aren't undoing something. */\n  if (_rl_doing_an_undo == 0)\n    {\n      /* If possible and desirable, concatenate the undos. */\n      if ((l == 1) &&\n\t  rl_undo_list &&\n\t  (rl_undo_list->what == UNDO_INSERT) &&\n\t  (rl_undo_list->end == rl_point) &&\n\t  (rl_undo_list->end - rl_undo_list->start < 20))\n\trl_undo_list->end++;\n      else\n\trl_add_undo (UNDO_INSERT, rl_point, rl_point + l, (char *)NULL);\n    }\n  rl_point += l;\n  rl_end += l;\n  rl_line_buffer[rl_end] = '\\0';\n  return l;\n}",
    "comment": "Inserts a given string into a line buffer at a specified point, adjusting the buffer and managing undo operations accordingly.",
    "prorec_sum": "Inserts the given text into the readline buffer at the cursor position, shifting existing text, updating cursor/end indexes, and managing undo information.",
    "filter_prorec_sum": "Inserts the given text into the readline buffer at the cursor position, shifting existing content and recording undo information if enabled.",
    "prorec_aug_sum": "Inserts the given text at the current cursor position in the readline buffer, shifting existing contents and updating undo history and buffer metadata.",
    "filter_prorec_aug_sum": "Inserts the given text into the readline buffer at the current cursor position, shifting existing content and updating undo history and buffer length.",
    "work_score": {
        "prorec_aug": {
            "summary": "Inserts the given text at the current cursor position in the readline buffer, shifting existing contents and updating undo history and buffer metadata.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary accurately describes the function's core behavior: inserting text at the current cursor position, shifting existing contents, and updating both undo history and buffer metadata. These points match the code's sequence of operations such as buffer extension, shifting data using a loop, strncpy insertion, undo logic, and position updates. No incorrect or irrelevant claims are present, and all claims directly map to explicit code behavior.",
                "The summary correctly states the core purpose \u2014 inserting text at the current cursor position in the readline buffer and shifting existing contents \u2014 which matches the source code's primary function. It also notes updating undo history and buffer metadata, which aligns with the code's undo list handling and pointer updates. However, it omits mention of important secondary behaviors, such as buffer length checks, calling rl_extend_line_buffer when necessary, conditional concatenation of undo for single-character inserts, and returning the length inserted. Thus, while the core is covered, secondary detail coverage is limited.",
                "The summary accurately captures the primary purpose of the function (inserting text at the cursor position in the readline buffer) and mentions core behaviors such as shifting existing contents, updating undo history, and buffer metadata. All these claims align with the source code\u2019s logic (loop shifting data, undo-handling conditionals, buffer length and null terminator updates). There are no inaccurate or noisy claims, and the description is specific enough to be useful, though it could include more detail on edge-case handling and conditions for undo concatenation."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Inserts the given text into the readline buffer at the current cursor position, shifting existing content and updating undo history and buffer length.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately describes the function's behavior: it inserts the string at the current cursor position, shifts existing content, updates undo history, and adjusts buffer length. All claims align with the source code semantics, with no incorrect or irrelevant statements.",
                "The summary accurately captures the core functionality: inserting text into the readline buffer at the current cursor position and shifting existing content, which matches the main domain-specific action. It also mentions updating undo history and buffer length, covering key secondary behaviors like buffer resizing and undo tracking. However, it omits specifics such as handling empty strings, detailed undo concatenation conditions, pointer/index updates, and null termination, leading to only partial coverage of secondary semantics.",
                "The summary accurately describes the primary purpose of inserting text into the readline buffer at the current cursor position, mentioning shifting content, undo history updates, and buffer resizing \u2014 all present in the source code. Claims are precise and verifiable, with no inaccurate or irrelevant noise, yielding high gain from specific GOLD-level coverage of the function\u2019s core behavior."
            ]
        }
    }
}
{
    "source_code": "\nstatic int restore(struct ks *ks, char x[])\n{     int j, k, z;\n      z = ks->c0;\n      for (j = 1, k = 0; j <= ks->orig_n; j++)\n      {  if (ks->x[j] & 0x10)\n         {  k++;\n            xassert(k <= ks->n);\n            xassert(x[k] == 0 || x[k] == 1);\n            if (ks->x[j] & 1)\n               ks->x[j] = 1 - x[k];\n            else\n               ks->x[j] = x[k];\n            if (x[k])\n               z += ks->c[k];\n         }\n      }\n      xassert(k == ks->n);\n      return z;\n}",
    "comment": "Restores values in the `ks->x` array based on conditions and updates a sum `z` based on corresponding values from the `x` array.",
    "prorec_sum": "Iterates over flagged items in a structure, validates associated binary values, flips bits if needed, updates sum accordingly, and returns the total.",
    "filter_prorec_sum": "Updates item flags and accumulates a total value from selected binary entries, enforcing consistency checks on selection count and boolean state.",
    "prorec_aug_sum": "Validates and updates a set of binary flags in a structure based on input values, enforcing constraints, and accumulates a corresponding weighted sum.",
    "filter_prorec_aug_sum": "Validates and updates knapsack solution variables, enforcing binary constraints and summing selected item weights before returning the total weight.",
    "work_score": {
        "prorec_aug": {
            "summary": "Validates and updates a set of binary flags in a structure based on input values, enforcing constraints, and accumulates a corresponding weighted sum.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly captures that the function updates binary flags in the structure based on input values, enforces constraints using assertions, and accumulates a weighted sum, all of which align with the source code semantics. While it does not mention specific control flow details (such as iterating over ks->orig_n or conditionally inverting values), the core behavioral claims are accurate and domain-relevant, yielding a high proportion of accurate statements.",
                "The summary accurately reflects the core purpose: iterating over fields in a structure, validating them as binary flags, updating according to input, and accumulating a weighted sum. The constraints enforced via assertions are covered, and the accumulation of ks->c values matches the weighted sum mention. While the wording is a bit abstract, it still captures the domain-specific update-and-sum operation effectively. Secondary details like the use of bitmask checks, conditional inversion of values, and final assertion are not included, which limits completeness.",
                "The summary correctly captures the core purpose of the function: it processes binary flag values (via checking the bits in ks->x[j]), enforces constraints through assertions, updates the structure\u2019s flags accordingly, and accumulates a weighted sum (stored in z). No contradictory or irrelevant claims are present, and while the description is accurate, it remains generic and lacks specific details such as the inversion logic when a certain bit is set. The absence of noise or FATAL issues results in a positive but moderate benefit."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Validates and updates knapsack solution variables, enforcing binary constraints and summing selected item weights before returning the total weight.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function updates solution-related variables (ks->x array), ensures binary constraints on x[k], and accumulates a sum (z) representing total contribution of selected items. It aligns closely with the code behavior of validating bits and summing values. A minor shortcoming is the term 'knapsack' and 'weights' are inferred from naming and not explicit in code, but overall correspondence exceeds 80% accuracy.",
                "The summary correctly identifies that the function validates binary constraints on solution variables and updates them, also noting the summation of selected item weights before returning the total. This covers the core purpose from the source code, which is restoring and validating the knapsack solution while computing the total weight. However, it omits secondary details such as the exact condition checks on ks->x[j] using bitwise flags, the handling of value inversion when a flag is set, and the precise use of assertions to ensure consistency. These omissions reduce completeness in covering critical branches and constants from the code.",
                "The summary accurately reflects the core behavior of the function by noting that it validates variables with binary constraints and computes a sum, which matches the assertions and weight accumulation in the code. It avoids any incorrect claims and the description of updating solution variables and returning total weight is consistent with the loop logic and return statement. The claim is somewhat generic (SAFE) and lacks deeper specifics such as the conditional flipping of values or exact data structures, but there is no noise or fatal error."
            ]
        }
    }
}
{
    "source_code": "\nconst ProtobufCFieldDescriptor *\nprotobuf_c_message_descriptor_get_field_by_name(const ProtobufCMessageDescriptor *desc,\n\t\t\t\t\t\tconst char *name)\n{\n\tunsigned start = 0;\n\tunsigned count;\n\tconst ProtobufCFieldDescriptor *field;\n\n\tif (desc == NULL || desc->fields_sorted_by_name == NULL)\n\t\treturn NULL;\n\n\tcount = desc->n_fields;\n\n\twhile (count > 1) {\n\t\tunsigned mid = start + count / 2;\n\t\tint rv;\n\t\tfield = desc->fields + desc->fields_sorted_by_name[mid];\n\t\trv = strcmp(field->name, name);\n\t\tif (rv == 0)\n\t\t\treturn field;\n\t\telse if (rv < 0) {\n\t\t\tcount = start + count - (mid + 1);\n\t\t\tstart = mid + 1;\n\t\t} else\n\t\t\tcount = mid - start;\n\t}\n\tif (count == 0)\n\t\treturn NULL;\n\tfield = desc->fields + desc->fields_sorted_by_name[start];\n\tif (strcmp(field->name, name) == 0)\n\t\treturn field;\n\treturn NULL;\n}",
    "comment": "Retrieves the field descriptor with a matching name from a sorted list of fields in a ProtobufC message descriptor.",
    "prorec_sum": "Searches an indexed array for an entry meeting criteria and returns a pointer to its associated 72\u2011byte structure, or zero if none match.",
    "filter_prorec_sum": "Searches an index array for the first entry with a zero status code and returns a pointer to its associated 72\u2011byte structure.",
    "prorec_aug_sum": "Performs a binary search over an index array to locate and return the associated 72-byte entry with a zero key field.",
    "filter_prorec_aug_sum": "Performs a binary search over an index array to locate and return the matching 72\u2011byte entry when its key multiplied by nine equals zero.",
    "work_score": {
        "prorec_aug": {
            "summary": "Performs a binary search over an index array to locate and return the associated 72-byte entry with a zero key field.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function returns a 72-byte entry with a zero key field, which is not supported by the source code. The code performs a binary search on an index array of field descriptors by comparing field names, but there is no mention of 72-byte entries or zero key fields. Only the binary search aspect is accurate, making less than half of the claims correct.",
                "The summary claims the function searches for a 72-byte entry with a zero key field, which is inaccurate since the code performs a binary search on a name-sorted index of field descriptors in a ProtobufCMessageDescriptor, returning the matching field by name. It does not reference or indicate the core purpose of looking up a field descriptor by name, and no accurate claim matches the actual domain semantics. Secondary details are also incorrect, leading to no coverage of the core functionality.",
                "The summary claims the function returns a 72-byte entry with a zero key field, which is not reflected in the source code; this is a severe factual error about the primary purpose and output. While it is correct that a search over an index array is performed, the binary search is for matching a field name string and returns a ProtobufCFieldDescriptor pointer, not a fixed-size entry or one with a zero key. This incorrectness directly contradicts the core I/O behavior, making the description unreliable despite minimal accurate detail."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Performs a binary search over an index array to locate and return the matching 72\u2011byte entry when its key multiplied by nine equals zero.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary inaccurately describes the function\u2019s semantics. The source code performs a binary search over a sorted array of field descriptors by name and returns the matching field or NULL. The summary\u2019s claim about a \u201c72\u2011byte entry\u201d and \u201ckey multiplied by nine equals zero\u201d does not correspond to any code behavior, making all extracted claims incorrect and unrelated to the actual implementation.",
                "The summary incorrectly describes the core logic by introducing details like a '72\u2011byte entry' and 'key multiplied by nine equals zero' that do not exist in the source code. The actual function performs a binary search over an index array of field names in a Protobuf message descriptor and returns the matching field if the name matches, otherwise returns NULL. The stated behavior in the summary contradicts the code and fails to cover the core purpose or other critical semantics such as NULL checks and string comparisons.",
                "The summary contains a severe inaccuracy about the core purpose: it claims the function searches for a '72\u2011byte entry when its key multiplied by nine equals zero', which does not align with the actual binary search comparing field names in the source code. This is a FATAL error on the primary purpose of the function. There are no accurate claims, resulting in zero useful information and rendering the summary misleading."
            ]
        }
    }
}
{
    "source_code": "\nvoid\npkl_asm_for (pkl_asm pasm, pkl_ast_node head)\n{\n  pkl_asm_pushlevel (pasm, PKL_ASM_ENV_FOR_LOOP);\n\n  pasm->level->node1 = ASTREF (head);\n  pasm->level->label1 = pvm_program_fresh_label (pasm->program);\n  pasm->level->label2 = pvm_program_fresh_label (pasm->program);\n  pasm->level->label3 = pvm_program_fresh_label (pasm->program);\n  pasm->level->continue_label = pvm_program_fresh_label (pasm->program);\n  pasm->level->break_label = pvm_program_fresh_label (pasm->program);\n\n  if (head)\n    pkl_asm_insn (pasm, PKL_INSN_PUSHF, 0);\n}",
    "comment": "Initializes a for loop's environment in the assembly context, assigning labels and pushing the loop node if a valid head is provided.",
    "prorec_sum": "Initializes a node\u2019s metadata fields from a related object and triggers an additional processing step when a secondary reference is provided.",
    "filter_prorec_sum": "Initializes a node\u2019s fields from repeated computed values, links it to a given object, updates counters, and triggers a follow\u2011up processing routine.",
    "prorec_aug_sum": "Initializes a data structure with repeated computed values, links it to an optional object, and triggers further processing if that object is present.",
    "filter_prorec_aug_sum": "Initializes a data structure with repeated identifier values from a related object, links it to a secondary object, and triggers further processing if present.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes a data structure with repeated computed values, links it to an optional object, and triggers further processing if that object is present.",
            "score": [
                0.3,
                0.2,
                0.3
            ],
            "reason": [
                "The summary gives a vague and generalized description of 'initializes a data structure' and 'links to an optional object', which loosely matches the function's initialization of loop state and conditional instruction emission if head is present. However, it omits specific key semantics such as creating multiple distinct fresh labels for loop control, pushing the FOR_LOOP environment level, and storing AST references. The claim about 'repeated computed values' is misleading since the code generates different labels, not repeated identical values. This results in less than half of the claims being accurate.",
                "The summary does not capture the core purpose of setting up assembler state for a 'for' loop with multiple fresh labels and environment level push. Its phrasing about 'data structure with repeated computed values' is vague and does not mention labels, loop control, or the specific handling of continue/break. While it loosely refers to linking with an optional object and conditional processing, these are generic and fail to accurately convey the concrete domain semantics in the source code.",
                "The summary incorrectly generalizes the function's actions, missing core semantics such as setting up a for-loop environment by pushing a level with specific labels for loop control (continue, break) and associating with an AST node. The description of 'repeated computed values' and 'optional object' is vague and does not clearly map to the actual label initialization or the AST node usage in the source, resulting in substantial noise. No highly specific, accurate claims are present, making the net benefit very low."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes a data structure with repeated identifier values from a related object, links it to a secondary object, and triggers further processing if present.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function initializes a data structure with repeated identifier values from a related object and links it to a secondary object, but the source code shows it sets specific labels and references for a 'for' loop in an assembler context, not repeated identifiers nor a generic link to a secondary object. The description is vague and misses key domain semantics, making its alignment with the source low. Almost none of the claims are accurate in representing the actual code behavior.",
                "The summary fails to capture the core purpose of setting up a FOR loop environment in the assembler, including assigning multiple fresh labels for loop control (start, end, continue, break) and storing the loop AST node. It instead describes vague generic actions like initializing a data structure and linking to another object, which do not match the domain-specific semantics of the source. No accurate coverage of the core behavior or other key details is provided.",
                "The summary contains mostly inaccurate claims: it vaguely refers to initializing a data structure with repeated identifier values and linking to a secondary object, which does not accurately capture the function's actual behavior of setting up loop environment labels and storing a reference to the AST node. The triggering of further processing is only loosely related to the conditional instruction execution when `head` is present. These mismatches target core semantics of the function (primary purpose), making them FATAL errors for understanding the code. There is no specific or accurate description of the loop label setup, resulting in negative net benefit."
            ]
        }
    }
}
{
    "source_code": "BITCODE_BL\ndwg_object_polyline_2d_get_numpoints (const dwg_object *restrict obj,\n                                      int *restrict error)\n{\n  if (obj && obj->type == DWG_TYPE_POLYLINE_2D)\n    {\n      BITCODE_BL num_points = 0;\n      Dwg_Data *dwg = obj->parent;\n      Dwg_Entity_POLYLINE_2D *_obj = obj->tio.entity->tio.POLYLINE_2D;\n      Dwg_Entity_VERTEX_2D *vertex;\n      *error = 0;\n\n      if (dwg->header.version >= R_2004)\n        return obj->tio.entity->tio.POLYLINE_2D->num_owned;\n      // iterate over first_vertex - last_vertex\n      else if (dwg->header.version >= R_13)\n        {\n          Dwg_Object *vobj = dwg_ref_object (dwg, _obj->first_vertex);\n          Dwg_Object *vlast = dwg_ref_object (dwg, _obj->last_vertex);\n          if (!vobj)\n            *error = 1;\n          else\n            {\n              do\n                {\n                  if ((vertex = dwg_object_to_VERTEX_2D (vobj)))\n                    {\n                      num_points++;\n                    }\n                  else\n                    {\n                      *error = 1; // return not all vertices, but some\n                    }\n                }\n              while ((vobj = dwg_next_object (vobj)) && vobj != vlast);\n            }\n        }\n      else // <r13: iterate over vertices until seqend\n        {\n          Dwg_Object *vobj;\n          while ((vobj = dwg_next_object (obj))\n                 && vobj->type != DWG_TYPE_SEQEND)\n            {\n              if ((vertex = dwg_object_to_VERTEX_2D (vobj)))\n                num_points++;\n              else\n                *error = 1; // return not all vertices, but some\n            }\n        }\n      return num_points;\n    }\n  else\n    {\n      LOG_ERROR (\"%s: empty or wrong arg\", __FUNCTION__)\n      *error = 1;\n      return 0L;\n    }\n}",
    "comment": "Counts the number of 2D vertices in a polyline object based on DWG version and returns the count or an error code.",
    "prorec_sum": "Counts the number of 2D vertex objects in a polyline entity, returning an error flag if invalid types or object structure are encountered.",
    "filter_prorec_sum": "Counts the number of 2D vertex objects in a polyline entity, validating object types and reporting errors for invalid input or structure.",
    "prorec_aug_sum": "Retrieves the number of 2D vertex points in a DWG polyline object and reports an error status if the object is invalid.",
    "filter_prorec_aug_sum": "Counts the number of 2D vertex objects in a polyline entity, returning errors for invalid input or non-vertex elements.",
    "work_score": {
        "prorec_aug": {
            "summary": "Retrieves the number of 2D vertex points in a DWG polyline object and reports an error status if the object is invalid.",
            "score": [
                0.9,
                0.5,
                0.5
            ],
            "reason": [
                "The summary captures the core purpose of the function\u2014retrieving the number of 2D vertex points from a DWG polyline and indicating an error if the object is invalid\u2014which is directly supported by the source code. However, it omits important conditional behaviors based on the DWG version and specific iteration logic when counting vertices. Despite this lack of detail, the single claim present is accurate, resulting in high precision but low completeness in coverage.",
                "The summary accurately identifies that the function retrieves the number of 2D vertex points and can report an error if the object is invalid, which covers the core purpose. However, it omits important secondary details from the code, such as handling different DWG versions, iteration logic for vertices, partial error reporting when some vertices are invalid, and use of specific object fields. This lack of coverage on error nuances and branching reduces completeness.",
                "The summary captures the primary purpose of the function accurately by stating it retrieves the number of 2D vertex points in a DWG polyline object and notes error reporting if the object is invalid. However, it omits key version-dependent behaviors, iteration methods, and partial error statuses when some vertices cannot be converted. There are no factual inaccuracies, but the information gain is low due to the lack of detail, making the net benefit limited."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Counts the number of 2D vertex objects in a polyline entity, returning errors for invalid input or non-vertex elements.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function counts 2D vertex objects in a polyline entity and returns an error for invalid input or non-vertex elements, which aligns with the code logic for handling null/incorrect object types and vertices that fail conversion. However, it omits important specifics such as conditions based on DWG version and different counting methods used for R_2004, R_13, and earlier formats. Despite these omissions, the claims are accurate and relevant to the code\u2019s semantics, with no incorrect statements present.",
                "The summary correctly identifies the core action as counting 2D vertex objects in a polyline entity and notes errors for invalid input or non-vertex elements, which matches the function\u2019s purpose. However, it omits important secondary details such as handling based on DWG version ranges (R_2004, R_13, <R_13), iteration logic using first and last vertex references, use of seqend termination, and nuances of partial vertex counts with error setting. This limits coverage of critical behavior beyond the core purpose.",
                "The summary correctly states that the function counts 2D vertex objects in a polyline and flags errors for invalid input or non-vertex elements, aligning with the main loop logic and error handling for wrong arguments or missing vertices. However, it omits the conditional behavior based on DWG version (R_2004, R_13, pre-R_13) and specific counting approaches, meaning the information gain is low. There are no inaccurate claims, but the lack of version-dependent detail reduces its utility."
            ]
        }
    }
}
{
    "source_code": "int ed_main(int argc UNUSED_PARAM, char **argv)\n{\n\tINIT_G();\n\n\tbufSize = INITBUF_SIZE;\n\tbufBase = xmalloc(bufSize);\n\tbufPtr = bufBase;\n\tlines.next = &lines;\n\tlines.prev = &lines;\n\n\tif (argv[1]) {\n\t\tfileName = xstrdup(argv[1]);\n\t\tif (!readLines(fileName, 1)) {\n\t\t\treturn EXIT_SUCCESS;\n\t\t}\n\t\tif (lastNum)\n\t\t\tsetCurNum(1);\n\t\tdirty = FALSE;\n\t}\n\n\tdoCommands();\n\treturn EXIT_SUCCESS;\n}",
    "comment": "Initializes a buffer, reads lines from a specified file if provided, and then executes commands in a loop.",
    "prorec_sum": "Initializes a data structure with provided parameters, links related resources, validates them, and performs final setup or cleanup before returning.",
    "filter_prorec_sum": "Initializes a data structure with provided parameters, performs conditional validation and processing, and finalizes state updates before exiting.",
    "prorec_aug_sum": "Initializes and configures a 1024\u2011byte structure with service data, validates it, invokes setup routines, and finalizes state based on provided parameters.",
    "filter_prorec_aug_sum": "Initializes a 1024\u2011byte structure, sets up internal buffers and pointers from provided parameters, validates a resource, and finalizes with a cleanup call.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes and configures a 1024\u2011byte structure with service data, validates it, invokes setup routines, and finalizes state based on provided parameters.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function initializes a 1024\u2011byte structure, validates it, and invokes setup routines. The source code shows buffer initialization using INITBUF_SIZE (value not specified as 1024) and use of malloc, but there is no explicit 1024-byte structure or validation logic. The mention of configuring service data and finalizing state based on parameters also does not match the code\u2019s actions, which load a file if provided and execute commands. Most claims target semantics but contradict the actual operations, resulting in low accuracy.",
                "The summary describes generic initialization and configuration of a 1024\u2011byte structure with service data, validation, and setup, which does not match the specific core purpose of ed_main: initializing global buffers and doubly linked list state, optionally loading a file into memory, setting current line number and dirty flag, then running 'doCommands'. The core domain action around file reading and command execution is missing, and several details in the summary (1024\u2011byte, service data, validation) are inaccurate or irrelevant to the actual code.",
                "The summary contains several inaccurate claims about the core behavior: it incorrectly states that a 1024-byte structure is initialized and validated, and mentions 'service data' and validation which are not present in the code. The actual code allocates a buffer based on INITBUF_SIZE, sets up doubly-linked list pointers, optionally loads a file, and processes commands. These inaccuracies directly misrepresent the primary purpose and key I/O behavior, making the description misleading. No accurate core-domain claims are present, resulting in a severe FATAL failure mode."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes a 1024\u2011byte structure, sets up internal buffers and pointers from provided parameters, validates a resource, and finalizes with a cleanup call.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains multiple inaccuracies: it claims a 1024-byte structure initialization, which is not supported by the code (bufSize comes from INITBUF_SIZE, but the value is not stated as 1024 here), describes validation of a resource without matching the specific readLines logic, and mentions a cleanup call that does not occur. While buffer allocation and pointer setup are accurate, more than half of the claims misrepresent the source code, reducing alignment with evaluation steps.",
                "The summary incorrectly states that a 1024-byte structure is initialized and mentions resource validation and cleanup calls that do not exist in the source code. It misses the core purpose, which is to initialize editor state, optionally read and set up a file's contents, and then execute editing commands. No accurate claim covers this primary behavior, and most statements are inaccurate regarding actual buffer size, operations, and the execution of commands.",
                "The summary contains several inaccuracies about the code's behavior. It claims initialization of a 1024\u2011byte structure, but the code sets bufSize to INITBUF_SIZE (a constant whose value is not shown) and allocates memory via xmalloc without specifying a structure of that size. It mentions validation of a resource and finalizing with a cleanup call, but instead the code conditionally reads lines from a file, sets pointers and flags, then executes commands and returns. There are no explicit cleanup calls. These mismatches are FATAL because they misstate the primary purpose and I/O behavior, leading to a misleading understanding of the function. Accurate details are minimal and generic, offering little positive gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nmpn_dcpi1_bdiv_q_n (mp_ptr qp,\n\t\t    mp_ptr np, mp_srcptr dp, mp_size_t n,\n\t\t    mp_limb_t dinv, mp_ptr tp)\n{\n  while (ABOVE_THRESHOLD (n, DC_BDIV_Q_THRESHOLD))\n    {\n      mp_size_t lo, hi;\n      mp_limb_t cy;\n\n      lo = n >> 1;\t\t\t/* floor(n/2) */\n      hi = n - lo;\t\t\t/* ceil(n/2) */\n\n      cy = mpn_dcpi1_bdiv_qr_n (qp, np, dp, lo, dinv, tp);\n\n      mpn_mullo_n (tp, qp, dp + hi, lo);\n      mpn_add_n (np + hi, np + hi, tp, lo);\n\n      if (lo < hi)\n\t{\n\t  cy += mpn_addmul_1 (np + lo, qp, lo, dp[lo]);\n\t  np[n - 1] += cy;\n\t}\n      qp += lo;\n      np += lo;\n      n -= lo;\n    }\n  mpn_sbpi1_bdiv_q (qp, np, n, dp, n, dinv);\n}",
    "comment": "Divides a multi-precision number by another using a divide-and-conquer approach, updating quotient and remainder for large input sizes.",
    "prorec_sum": "Performs large integer division using GMP\u2019s divide-and-conquer and base-case algorithms, updating partial results with multiplication and addition steps.",
    "filter_prorec_sum": "Performs multi-precision division using divide-and-conquer and small-block algorithms with GMP low-level `mpn` functions.",
    "prorec_aug_sum": "Performs multi-precision division using divide-and-conquer and schoolbook algorithms, producing the quotient from high and low parts of large integer operands.",
    "filter_prorec_aug_sum": "Performs multi-limb division using divide-and-conquer algorithms and GMP low-level routines, yielding the quotient from large integer operands.",
    "work_score": {
        "prorec_aug": {
            "summary": "Performs multi-precision division using divide-and-conquer and schoolbook algorithms, producing the quotient from high and low parts of large integer operands.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary accurately reflects the function's purpose: it processes large integer division using a divide-and-conquer loop when above a threshold, then uses a schoolbook division method. The mention of producing the quotient from high and low parts aligns with splitting 'n' into 'lo' and 'hi' for processing. There are no contradictory or irrelevant claims, and all points in the summary match the source code semantics.",
                "The summary accurately identifies that the function performs multi-precision division using a mix of divide-and-conquer and schoolbook algorithms, which matches the core purpose inferred from the source code. It specifies that the quotient is derived from high and low parts of large integer operands, aligning with the code's splitting into lo and hi segments. However, it omits critical secondary behaviors such as threshold-based looping, handling carry operations, adjustments when lo < hi, and the specific functions called for multiplication, addition, and final schoolbook division step. These omissions limit coverage breadth.",
                "The summary correctly identifies that the function performs multi-precision division using divide-and-conquer and schoolbook algorithms, which matches the source\u2019s use of loops with ABOVE_THRESHOLD and a final call to mpn_sbpi1_bdiv_q. It also correctly notes that the function produces a quotient. However, the claim about 'high and low parts of large integer operands' is generic and loosely tied to the lo/hi splitting in the code, without precise detail of their role. No fatal inaccuracies are present, but the explanation is broad and offers limited specific insight beyond generic algorithm names."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Performs multi-limb division using divide-and-conquer algorithms and GMP low-level routines, yielding the quotient from large integer operands.",
            "score": [
                1.0,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function performs multi-limb division using a divide-and-conquer approach and GMP low-level routines, and that it produces a quotient from large integer operands, all of which are consistent with the source code\u2019s operations (including threshold-based splitting, recursive calls, and final call to sbpi1 division). This alignment indicates all claims are accurate and specific to the code\u2019s semantics.",
                "The summary correctly identifies that the function performs multi-limb division with a divide-and-conquer approach using GMP low-level routines, which aligns with the core purpose of iteratively dividing large integers using specific limb-based operations to produce a quotient. However, it lacks mention of critical secondary behaviors such as the threshold check (ABOVE_THRESHOLD), recursive structure, use of specific helper functions (mpn_dcpi1_bdiv_qr_n, mpn_mullo_n, mpn_add_n, mpn_addmul_1), handling of carry values, and the final fallback to mpn_sbpi1_bdiv_q. Thus, while the core is covered, the coverage of other key details is minimal.",
                "The summary correctly identifies that the function performs multi-limb division and uses GMP low-level routines with a divide-and-conquer approach, which matches the looping and splitting logic in the source code. It accurately notes that the quotient is produced from large integer operands. However, the description is quite generic and lacks specific operational details such as the use of threshold checks, recursive calls to `mpn_dcpi1_bdiv_qr_n`, and subsequent calls to functions like `mpn_mullo_n` and `mpn_add_n`. There are no inaccurate or contradictory statements, but the informational gain is low due to the absence of finer technical points, making the net benefit moderate."
            ]
        }
    }
}
{
    "source_code": "\nstatic int create_dir(struct kobject *kobj, struct sysfs_dirent *parent_sd,\n\tenum kobj_ns_type type, const void *ns, const char *name,\n\tstruct sysfs_dirent **p_sd)\n{\n\tumode_t mode = S_IFDIR| S_IRWXU | S_IRUGO | S_IXUGO;\n\tstruct sysfs_addrm_cxt acxt;\n\tstruct sysfs_dirent *sd;\n\tint rc;\n\n\t/* allocate */\n\tsd = sysfs_new_dirent(name, mode, SYSFS_DIR);\n\tif (!sd)\n\t\treturn -ENOMEM;\n\n\tsd->s_flags |= (type << SYSFS_NS_TYPE_SHIFT);\n\tsd->s_ns = ns;\n\tsd->s_dir.kobj = kobj;\n\n\t/* link in */\n\tsysfs_addrm_start(&acxt, parent_sd);\n\trc = sysfs_add_one(&acxt, sd);\n\tsysfs_addrm_finish(&acxt);\n\n\tif (rc == 0)\n\t\t*p_sd = sd;\n\telse\n\t\tsysfs_put(sd);\n\n\treturn rc;\n}",
    "comment": "Creates a directory entry in a configuration filesystem, ensuring it does not already exist and managing reference counts for the parent directory.",
    "prorec_sum": "Allocates and initializes a filesystem-related structure with provided parameters, invokes setup routines, and returns it through an output pointer or cleans up on failure.",
    "filter_prorec_sum": "Allocates and initializes a structure with provided parameters, invokes two setup routines, and either returns it via output pointer or cleans it up on error.",
    "prorec_aug_sum": "Allocates and initializes a filesystem structure with provided parameters, performs setup routines, and returns it via output pointer or an error code.",
    "filter_prorec_aug_sum": "Initializes a new structure with provided parameters, links it to inputs, performs setup routines, and returns it or cleans up on failure.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and initializes a filesystem structure with provided parameters, performs setup routines, and returns it via output pointer or an error code.",
            "score": [
                0.9,
                0.3,
                0.6
            ],
            "reason": [
                "The summary correctly describes the allocation and initialization of a filesystem-related structure with given parameters, the execution of setup routines, and returning it via an output pointer or an error code, all of which align with the source code's sequence: creating a sysfs_dirent, setting its fields, linking it, and conditionally returning it. While it is somewhat generic and lacks some domain-specific details like sysfs context handling or mode flags, the claims are accurate and match the code's behavior without contradictions.",
                "The summary correctly notes allocation, initialization, and returning via output pointer or an error code, which are accurate generalities. However, it fails to cover the core purpose of creating and linking a sysfs directory entry with specific flags, namespace, and kobject association. No mention is made of linking into the parent directory context or the cleanup on failure, meaning critical domain-specific behavior is omitted.",
                "The summary captures the core purpose accurately: allocation and initialization of a filesystem-related structure using provided parameters, performing setup, and returning either via output pointer or error code. It omits some specifics like setting permissions/mode, namespace type, and linking into the parent via sysfs routines, but there are no contradictory or irrelevant claims. The claims are generic and safe, offering low informational gain without fatal inaccuracies. Noise is minimal, so net benefit is modest but positive."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes a new structure with provided parameters, links it to inputs, performs setup routines, and returns it or cleans up on failure.",
            "score": [
                0.7,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly identifies that the function creates a structure, initializes it with the provided parameters, links it, and handles cleanup on failure\u2014matching the allocation and linking behavior in the code. However, it oversimplifies by saying the function 'returns it', while in reality it only stores the pointer in an output parameter and returns a status code. This minor inaccuracy slightly lowers alignment despite generally accurate core claims.",
                "The summary correctly captures the high-level flow\u2014allocation/initialization, linking into input structures, and cleanup on failure\u2014aligning with the core behavior of creating and adding a sysfs directory entry. However, it omits the core domain detail that this function specifically creates a sysfs directory (not just a generic structure), and lacks mention of namespace type, permissions, and use of helper functions like sysfs_addrm_start/add_one/finish, so coverage of secondary semantics is only moderate.",
                "The summary captures the general flow of the function\u2014initializing a structure with parameters, linking to inputs, performing setup, and returning or cleaning up on failure\u2014which is broadly accurate. However, it is entirely generic, lacking specific details like the use of sysfs_dirent, the mode setup, namespace type shifting, or the sysfs_addrm operations. There are no false claims, but the low-information nature means most content is SAFE with minimal GOLD detail, resulting in low net benefit without overwhelming noise."
            ]
        }
    }
}
{
    "source_code": "acpi_status acpi_unload_parent_table(acpi_handle object)\n{\n\tstruct acpi_namespace_node *node =\n\t    ACPI_CAST_PTR(struct acpi_namespace_node, object);\n\tacpi_status status = AE_NOT_EXIST;\n\tacpi_owner_id owner_id;\n\tu32 i;\n\n\tACPI_FUNCTION_TRACE(acpi_unload_parent_table);\n\n\t/* Parameter validation */\n\n\tif (!object) {\n\t\treturn_ACPI_STATUS(AE_BAD_PARAMETER);\n\t}\n\n\t/*\n\t * The node owner_id is currently the same as the parent table ID.\n\t * However, this could change in the future.\n\t */\n\towner_id = node->owner_id;\n\tif (!owner_id) {\n\n\t\t/* owner_id==0 means DSDT is the owner. DSDT cannot be unloaded */\n\n\t\treturn_ACPI_STATUS(AE_TYPE);\n\t}\n\n\t/* Must acquire the interpreter lock during this operation */\n\n\tstatus = acpi_ut_acquire_mutex(ACPI_MTX_INTERPRETER);\n\tif (ACPI_FAILURE(status)) {\n\t\treturn_ACPI_STATUS(status);\n\t}\n\n\t/* Find the table in the global table list */\n\n\tfor (i = 0; i < acpi_gbl_root_table_list.current_table_count; i++) {\n\t\tif (owner_id != acpi_gbl_root_table_list.tables[i].owner_id) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Allow unload of SSDT and OEMx tables only. Do not allow unload\n\t\t * of the DSDT. No other types of tables should get here, since\n\t\t * only these types can contain AML and thus are the only types\n\t\t * that can create namespace objects.\n\t\t */\n\t\tif (ACPI_COMPARE_NAME\n\t\t    (acpi_gbl_root_table_list.tables[i].signature.ascii,\n\t\t     ACPI_SIG_DSDT)) {\n\t\t\tstatus = AE_TYPE;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Ensure the table is actually loaded */\n\n\t\tif (!acpi_tb_is_table_loaded(i)) {\n\t\t\tstatus = AE_NOT_EXIST;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Invoke table handler if present */\n\n\t\tif (acpi_gbl_table_handler) {\n\t\t\t(void)acpi_gbl_table_handler(ACPI_TABLE_EVENT_UNLOAD,\n\t\t\t\t\t\t     acpi_gbl_root_table_list.\n\t\t\t\t\t\t     tables[i].pointer,\n\t\t\t\t\t\t     acpi_gbl_table_handler_context);\n\t\t}\n\n\t\t/*\n\t\t * Delete all namespace objects owned by this table. Note that\n\t\t * these objects can appear anywhere in the namespace by virtue\n\t\t * of the AML \"Scope\" operator. Thus, we need to track ownership\n\t\t * by an ID, not simply a position within the hierarchy.\n\t\t */\n\t\tstatus = acpi_tb_delete_namespace_by_owner(i);\n\t\tif (ACPI_FAILURE(status)) {\n\t\t\tbreak;\n\t\t}\n\n\t\tstatus = acpi_tb_release_owner_id(i);\n\t\tacpi_tb_set_table_loaded_flag(i, FALSE);\n\t\tbreak;\n\t}\n\n\t(void)acpi_ut_release_mutex(ACPI_MTX_INTERPRETER);\n\treturn_ACPI_STATUS(status);\n}",
    "comment": "Unloads ACPI tables by deleting namespace objects and calling the table handler, ensuring conditions to prevent unloading the DSDT are met.",
    "prorec_sum": "Processes an ACPI table entry matching a specific identifier, invoking related handlers and executing associated operations with provided parameters.",
    "filter_prorec_sum": "Processes an ACPI table entry matching a given identifier and executes linked handler functions with specified parameters.",
    "prorec_aug_sum": "Processes an attribute identified by a key byte in a global table, optionally invoking callbacks and updating related data before final cleanup.",
    "filter_prorec_aug_sum": "Removes an extended attribute from a VXFS inode by matching its identifier, invoking callbacks, and updating related metadata structures.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes an attribute identified by a key byte in a global table, optionally invoking callbacks and updating related data before final cleanup.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims are inaccurate: it describes processing an attribute keyed by a byte in a global table and optional callbacks/cleanup, which does not match the source code. The function actually unloads a parent ACPI table for a given handle, validates parameters, checks table type and load state, possibly calls a handler, deletes namespace objects, and updates owner-related flags. None of these semantics are conveyed correctly in the summary, resulting in 0% accurate claims.",
                "The summary's claim that it processes an attribute identified by a key byte in a global table is inaccurate; the function actually unloads a parent ACPI table by owner_id, with specific restrictions for certain table types, mutex handling, namespace object deletion, and table state updates. The described callbacks and cleanup in the summary are vaguely related but lack correct domain specificity, and the core purpose of unloading an ACPI table is entirely missing.",
                "The summary\u2019s claims about processing an attribute identified by a key byte in a global table and performing optional callbacks and cleanup are inaccurate with respect to the source code\u2019s primary purpose. The function actually unloads a parent ACPI table based on the owner ID, with specific restrictions for certain table types and explicit mutex locking and namespace object deletion. The mismatch affects the core domain action, making this a severe FATAL error. There are no accurate, specific claims to provide positive gain, resulting in negligible net benefit."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Removes an extended attribute from a VXFS inode by matching its identifier, invoking callbacks, and updating related metadata structures.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary describes removing an extended attribute from a VXFS inode, which is unrelated to the source code\u2019s ACPI table unloading functionality. All fact-based claims in the summary are inaccurate because they target a completely different domain and do not reflect the code\u2019s behavior of unloading ACPI tables by owner ID, invoking table handlers, and updating namespace objects. There are no accurate claims present.",
                "The summary describes removing an extended attribute from a VXFS inode, which is unrelated to the source code's actual purpose of unloading a parent ACPI table for a given namespace node, with checks for table type, ownership, interpreter locking, invoking table handler, and cleaning up namespace objects. The core functionality and all critical semantics are entirely missing, and the claims are inaccurate with respect to the source code.",
                "The summary is entirely inaccurate: it describes removing an extended attribute from a VXFS inode, which has no relation to the function's actual purpose of unloading an ACPI parent table by owner ID, validating parameters, acquiring a mutex, checking table type and load state, invoking unload handlers, and deleting associated namespace objects. This is a severe FATAL error about the core domain action and I/O, making the response unusable."
            ]
        }
    }
}
{
    "source_code": "int\n_rl_dispatch_callback (_rl_keyseq_cxt *cxt)\n{\n  int nkey, r;\n\n  /* For now */\n  /* The first time this context is used, we want to read input and dispatch\n     on it.  When traversing the chain of contexts back `up', we want to use\n     the value from the next context down.  We're simulating recursion using\n     a chain of contexts. */\n  if ((cxt->flags & KSEQ_DISPATCHED) == 0)\n    {\n      nkey = _rl_subseq_getchar (cxt->okey);\n      if (nkey < 0)\n\t{\n\t  _rl_abort_internal ();\n\t  return -1;\n\t}\n      r = _rl_dispatch_subseq (nkey, cxt->dmap, cxt->subseq_arg);\n      cxt->flags |= KSEQ_DISPATCHED;\n    }\n  else\n    r = cxt->childval;\n\n  /* For now */\n  if (r != -3)\t/* don't do this if we indicate there will be other matches */\n    r = _rl_subseq_result (r, cxt->oldmap, cxt->okey, (cxt->flags & KSEQ_SUBSEQ));\n\n  RL_CHECK_SIGNALS ();\n  /* We only treat values < 0 specially to simulate recursion. */\n  if (r >= 0 || (r == -1 && (cxt->flags & KSEQ_SUBSEQ) == 0))\t/* success! or failure! */\n    {\n      _rl_keyseq_chain_dispose ();\n      RL_UNSETSTATE (RL_STATE_MULTIKEY);\n      return r;\n    }\n\n  if (r != -3)\t\t\t/* magic value that says we added to the chain */\n    _rl_kscxt = cxt->ocxt;\n  if (_rl_kscxt)\n    _rl_kscxt->childval = r;\n  if (r != -3)\n    _rl_keyseq_cxt_dispose (cxt);\n\n  return r;\n}",
    "comment": "Handles key sequence input and dispatches actions based on the context, managing recursion through context chaining and returning results based on input validity.",
    "prorec_sum": "Processes a readline key input sequence, dispatches it to the appropriate handler, manages signal interruptions, and cleans up the key sequence context state.",
    "filter_prorec_sum": "Processes a readline key dispatch, executing associated actions, handling special return codes, and cleaning up or updating context while managing caught signals.",
    "prorec_aug_sum": "Handles a readline key sequence by dispatching its callback, processing results, managing signal handling, and freeing associated key sequence context structures.",
    "filter_prorec_aug_sum": "Processes a readline callback by dispatching subsequences, handling signals, managing context cleanup, and returning the resulting status code.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles a readline key sequence by dispatching its callback, processing results, managing signal handling, and freeing associated key sequence context structures.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function handles a readline key sequence, dispatches callbacks, processes results, manages signal handling, and disposes of key sequence context structures. These points align with the source code: it reads input, dispatches subsequences, processes the result, checks signals, and disposes context structures. All claims are accurate and reflect the code's domain semantics with no contradictory or irrelevant elements.",
                "The summary correctly identifies that the function deals with readline key sequences, dispatching a callback, processing results, handling signals, and freeing context structures, which aligns with the core purpose of reading a key, dispatching it, and managing state and memory. However, it omits important specifics such as the conditional recursion simulation via context chains, special handling for magic values like -3, abort conditions on negative keys, and state flags management, resulting in incomplete coverage of key behavior-critical semantics.",
                "The summary correctly captures the core purpose of the function \u2014 handling a readline key sequence via dispatch, result processing, signal handling, and cleanup \u2014 all of which are evident in the source code. It omits lower-level specifics such as conditional recursion simulation, special handling for return values like -3, and flag manipulations, but these are not misrepresented. There is no inaccurate or contradictory claim, though the information gain is low due to broad and generic phrasing rather than detailed GOLD-level insights. Noise is minimal and accuracy is high."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Processes a readline callback by dispatching subsequences, handling signals, managing context cleanup, and returning the resulting status code.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function processes a readline callback, dispatches subsequences, handles signals, manages context cleanup, and returns a status code\u2014all of which align with the source code. While the description is high-level and generic, it accurately reflects the core behavior without introducing inaccuracies, resulting in all claims being accurate.",
                "The summary correctly identifies that the function processes a readline callback, dispatches subsequences, handles signals, cleans up contexts, and returns a status code, which aligns with the core purpose of reading a key, dispatching via subsequence logic, and managing cleanup. However, it lacks specific domain details present in the code such as handling recursion via context chains, conditional behavior based on special return values like -3, and aborting on input errors. As a result, while the core is covered, important secondary semantics including error handling and branching cases are missing.",
                "The summary accurately captures the primary purpose of the function: processing a readline callback through subsequence dispatch, signal handling, context cleanup, and returning a status code. These elements correspond to actual behaviors in the code. However, the summary is generic and lacks specific details such as the conditions for reading input versus using child context values, handling special return codes like -3, and recursion simulation via context chains. The claims are accurate but low-info, resulting in limited positive gain with no significant noise or fatal inaccuracies."
            ]
        }
    }
}
{
    "source_code": "int burn_drive_obtain_scsi_adr(char *path,\n\t\t\t       int *bus_no, int *host_no, int *channel_no,\n\t\t\t       int *target_no, int *lun_no)\n{\n\tint ret, i;\n\tchar *adr = NULL;\n\n\tBURN_ALLOC_MEM(adr, char, BURN_DRIVE_ADR_LEN);\n\n\t/* open drives cannot be inquired by sg_obtain_scsi_adr() */\n\tfor (i = 0; i < drivetop + 1; i++) {\n\t\tif (drive_array[i].global_index < 0)\n\tcontinue;\n\t\tret = burn_drive_d_get_adr(&(drive_array[i]),adr);\n\t\tif (ret < 0)\n\t\t\t{ret = 1; goto ex;}\n\t\tif (ret == 0)\n\tcontinue;\n\t\tif (strcmp(adr, path) == 0) {\n\t\t\t*host_no = drive_array[i].host;\n\t\t\t*channel_no = drive_array[i].channel;\n\t\t\t*target_no = drive_array[i].id;\n\t\t\t*lun_no = drive_array[i].lun;\n\t\t\t*bus_no = drive_array[i].bus_no;\n\t\t\tif (*host_no < 0 || *channel_no < 0 ||\n\t\t\t    *target_no < 0 || *lun_no < 0)\n\t\t\t\t{ret = 0; goto ex;}\n\t\t\t{ret = 1; goto ex;}\n\t\t}\n\t}\n\n\tret = sg_obtain_scsi_adr(path, bus_no, host_no, channel_no,\n\t\t\t\t target_no, lun_no);\nex:;\n\tBURN_FREE_MEM(adr);\n\treturn ret;\n}",
    "comment": "Retrieves the SCSI address information for a specified drive path, utilizing both local and SCSI inquiry methods.",
    "prorec_sum": "Searches for a matching file entry by name in an ISO9660 directory structure and returns associated metadata through output parameters.",
    "filter_prorec_sum": "Searches an ISO9660 directory for a matching filename and returns its associated extent and metadata if found, otherwise falls back to alternative lookup.",
    "prorec_aug_sum": "Searches for a matching device entry by name, retrieves its stored parameters into provided variables, or delegates retrieval to an alternate routine if not found.",
    "filter_prorec_aug_sum": "Searches stored device entries for a matching name and returns associated parameters, or falls back to an alternate retrieval routine if none match.",
    "work_score": {
        "prorec_aug": {
            "summary": "Searches for a matching device entry by name, retrieves its stored parameters into provided variables, or delegates retrieval to an alternate routine if not found.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function searches for a matching device and stores its parameters into provided variables, which aligns with the loop and assignments in the code. It also accurately notes the delegation to an alternate routine (`sg_obtain_scsi_adr`) when the device is not found. These are specific and verifiable behaviors seen in the source. There are no contradictory or irrelevant claims in the summary, and all statements target the code's functionality.",
                "The summary correctly states that the function searches for a matching device entry by name and assigns parameters to provided variables, and that it calls another routine if not found, which matches the core purpose of obtaining SCSI address parameters. However, it omits key secondary details from the code, such as memory allocation and freeing, handling of open drives, specific negative value checks for parameters, and the early exit conditions. Coverage of core purpose is solid, but secondary semantics are sparse.",
                "The summary correctly captures the core behavior: iterating through device entries by a given path, retrieving SCSI parameters into the provided pointers, and falling back to an alternate routine if not found. These are accurate, domain-specific points matching the source code\u2019s primary purpose and I/O behavior. There is minimal noise and no inaccurate claims, and while the description is somewhat high-level, it covers key aspects well without contradiction."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Searches stored device entries for a matching name and returns associated parameters, or falls back to an alternate retrieval routine if none match.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly captures the function\u2019s process of searching through existing drive entries for a match and returning associated parameters, and notes the fallback to another retrieval routine when no match is found. These statements align with the source code\u2019s loop checking drive_array entries, comparing adr to path, and the final call to sg_obtain_scsi_adr. All claims are accurate and reflect the semantic behavior of the function without introducing errors or irrelevant information.",
                "The summary correctly captures the core by stating that the function searches stored device entries for a matching name (matching the PATH string comparison against drive_array) and returns associated parameters, and notes the fallback to an alternate retrieval routine (sg_obtain_scsi_adr). However, it omits critical secondary details such as memory allocation/freeing, handling of open drives, specific conditions for setting ret values, and validation of retrieved parameters where negative values lead to a different return path. These omissions limit coverage of behavior-critical semantics.",
                "The summary correctly captures the primary purpose: iterating through stored drives to find one matching the given path and returning associated parameters, and describes the fallback to an alternate retrieval function if no match is found. These are accurate, domain-specific behaviors present in the source code. There is no evidence of incorrect semantics or excessive noise; however, the description is somewhat generic, omitting specifics such as parameter names and validation checks, which limits the informational gain."
            ]
        }
    }
}
{
    "source_code": "\nint\ncontext_init (char *str)\n{\n  mem_init ();\n  context = mem_alloc (sizeof (struct context));\n  context->num_pat = expr_init (str);\n  if (!context->num_pat)\n    return 0;\n\n  context->tmp = mem_alloc (sizeof (struct line) - sizeof (char[4])\n      + opt.context + 1);\n\n  if (!opt.out_quiet)\n    {\n      register int i, j, occurrences;\n      struct line **line;\n\n      context->lines = mem_alloc (context->num_pat\n\t  * sizeof (struct line **));\n      occurrences = opt.occurrences ? opt.occurrences : 1;\n\n      for (i = 0; i < context->num_pat; i++)\n\t{\n\t  line = mem_alloc (occurrences * sizeof (struct line *));\n\t  for (j = 0; j < occurrences; j++)\n\t    line[j] = mem_alloc (sizeof (struct line) - sizeof (char[4])\n\t\t+ opt.context + 1);\n\n\t  context->lines[i] = line;\n\t}\n    }\n\n  return context->num_pat;\n}",
    "comment": "Initializes the context structure, allocating memory for patterns and lines based on given input and options, and returns the number of patterns.",
    "prorec_sum": "Allocates and initializes nested field-related data structures based on input parameters and global configuration values.",
    "filter_prorec_sum": "Initializes a global field structure, allocates required buffers, and sets up nested arrays based on the provided parameter count and configuration flags.",
    "prorec_aug_sum": "Initializes a primary data structure and allocates nested arrays for each entry based on configuration flags and size parameters.",
    "filter_prorec_aug_sum": "Initializes global data structures by allocating and linking multiple memory blocks based on the given parameter and configuration flags.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes a primary data structure and allocates nested arrays for each entry based on configuration flags and size parameters.",
            "score": [
                0.8,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function initializes a main structure and allocates nested arrays according to configuration parameters, which matches the code's use of mem_alloc for context, tmp, and lines arrays based on opt flags and sizes. However, it omits key specifics such as the initialization of patterns via expr_init, the conditional allocation depending on opt.out_quiet, and the return value logic. While the claims made are accurate, they are generic and miss several distinguishing details, reducing precision.",
                "The summary notes initialization of a data structure and allocation of nested arrays based on configuration, which is accurate but vague. It does not specify the core domain purpose of setting up a 'context' with patterns parsed from the input string, thus missing the explicit link between expr_init(str) and the allocation logic. While the allocation details are roughly covered, important secondary elements like conditional allocation when 'opt.out_quiet' is false, use of 'opt.occurrences', and the return of num_pat are omitted.",
                "The summary captures the general idea of initializing a main structure and allocating nested arrays, which aligns with the function's behavior. However, it lacks specifics such as the initialization of `context->num_pat` via `expr_init(str)`, conditionals based on `opt.out_quiet`, and allocation sizes using `opt.context` and `opt.occurrences`. The claims are accurate but generic, providing minimal actionable detail, and there is no inaccurate or contradictory information. The worst failure mode is low gain due to excessive generality."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes global data structures by allocating and linking multiple memory blocks based on the given parameter and configuration flags.",
            "score": [
                0.8,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly captures the general purpose of the function\u2014initializing global data structures and allocating memory based on the input parameter and configuration flags. However, it omits specific and verifiable details from the source such as the call to `expr_init`, conditional memory allocations depending on `opt.out_quiet`, and returning `context->num_pat`. While it is broadly accurate, it is mostly generic boilerplate, lacking the high-specificity domain semantics present in the source code.",
                "The summary correctly reflects that the function initializes and allocates multiple memory blocks based on a parameter and configuration flags, which aligns with the source code's actions. However, it lacks the specific core purpose: setting up the global 'context' structure with pattern data from expr_init(str) and optionally preparing lines arrays depending on opt.out_quiet. No mention is made of the pattern count, conditional allocations, or error handling branch, resulting in very limited secondary detail coverage despite the core being generically referenced.",
                "The summary correctly captures that the function initializes global data structures and allocates memory based on an input parameter and configuration flags, aligning with the code's use of mem_init, mem_alloc, and opt values. However, it is very generic, omitting specific details such as allocation of the 'context' struct, initialization of num_pat via expr_init, and conditional allocation of 'lines' based on out_quiet and occurrences. No inaccurate or contradictory claims are present, but the gain is low due to lack of precision and omission of notable logic, making the net benefit limited."
            ]
        }
    }
}
{
    "source_code": "\n\nu_char *\nngx_proxy_protocol_write(ngx_connection_t *c, u_char *buf, u_char *last)\n{\n    ngx_uint_t  port, lport;\n\n    if (last - buf < NGX_PROXY_PROTOCOL_MAX_HEADER) {\n        return NULL;\n    }\n\n    if (ngx_connection_local_sockaddr(c, NULL, 0) != NGX_OK) {\n        return NULL;\n    }\n\n    switch (c->sockaddr->sa_family) {\n\n    case AF_INET:\n        buf = ngx_cpymem(buf, \"PROXY TCP4 \", sizeof(\"PROXY TCP4 \") - 1);\n        break;\n\n#if (NGX_HAVE_INET6)\n    case AF_INET6:\n        buf = ngx_cpymem(buf, \"PROXY TCP6 \", sizeof(\"PROXY TCP6 \") - 1);\n        break;\n#endif\n\n    default:\n        return ngx_cpymem(buf, \"PROXY UNKNOWN\" CRLF,\n                          sizeof(\"PROXY UNKNOWN\" CRLF) - 1);\n    }\n\n    buf += ngx_sock_ntop(c->sockaddr, c->socklen, buf, last - buf, 0);\n\n    *buf++ = ' ';\n\n    buf += ngx_sock_ntop(c->local_sockaddr, c->local_socklen, buf, last - buf,\n                         0);\n\n    port = ngx_inet_get_port(c->sockaddr);\n    lport = ngx_inet_get_port(c->local_sockaddr);\n\n    return ngx_slprintf(buf, last, \" %ui %ui\" CRLF, port, lport);\n}",
    "comment": "Constructs and writes a PROXY protocol header, including client and server IP addresses and ports, to the provided buffer.",
    "prorec_sum": "Formats and writes a PROXY protocol line with source and destination addresses and ports into the provided buffer.",
    "filter_prorec_sum": "Formats and writes a PROXY protocol line with source and destination addresses and ports for TCP4, TCP6, or unknown connections.",
    "prorec_aug_sum": "Constructs and writes a PROXY protocol header with source and destination IP addresses and ports into the provided buffer.",
    "filter_prorec_aug_sum": "Constructs and writes a PROXY protocol header with source and destination IP addresses and ports for TCP4, TCP6, or UNKNOWN connections.",
    "work_score": {
        "prorec_aug": {
            "summary": "Constructs and writes a PROXY protocol header with source and destination IP addresses and ports into the provided buffer.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function constructs and writes a PROXY protocol header including source and destination IP addresses and ports into the buffer, which matches the code's behavior using ngx_cpymem, ngx_sock_ntop, and ngx_slprintf. It omits minor details such as handling IPv4, IPv6, or 'UNKNOWN' types and buffer space checks but these do not contradict the code, making the claim highly accurate overall.",
                "The summary accurately captures the core purpose of constructing and writing a PROXY protocol header containing source and destination IPs and ports, which aligns with the function's primary behavior in the code. However, it omits secondary details such as handling buffer size limits, possible early returns on errors, conditional handling for IPv4 vs IPv6 vs unknown families, and use of helper functions for address formatting. These omissions mean the coverage of critical secondary semantics is incomplete.",
                "The summary accurately captures the core purpose of the function: it writes a PROXY protocol header containing source and destination IP addresses and ports into a buffer. This directly reflects the code's behavior, which builds the header based on the connection's socket family and populates it with both remote and local addresses and ports. There is no contradictory or irrelevant information, though the description is somewhat generic and lacks mention of conditions like buffer size and handling unknown families. The gain is moderate due to correct but broad coverage and minimal noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Constructs and writes a PROXY protocol header with source and destination IP addresses and ports for TCP4, TCP6, or UNKNOWN connections.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function constructs a PROXY protocol header including source and destination IP addresses and ports and supports TCP4, TCP6, and UNKNOWN families. These details align with the code\u2019s logic involving ngx_cpymem for labeled prefixes, ngx_sock_ntop for addresses, and ngx_inet_get_port for ports. All claims are accurate and grounded in the source.",
                "The summary accurately states that the function constructs and writes a PROXY protocol header with source and destination IP addresses and ports for TCP4, TCP6, or UNKNOWN connections, which matches the core purpose of the code. However, it omits important secondary semantics such as buffer size checks, handling errors from obtaining the local socket address, and the specific formatting logic using ngx_cpymem and ngx_slprintf. These omissions mean key behavioral details are missing, reducing completeness.",
                "The summary accurately states the primary purpose: constructing and writing a PROXY protocol header including source and destination IP addresses and ports. It correctly identifies TCP4, TCP6, and UNKNOWN as possible connection types according to the code. There is no conflicting or irrelevant information (NOISE) or inaccurate detail (FATAL). The claim is specific to the core semantics, offering high gain without notable shortcomings."
            ]
        }
    }
}
{
    "source_code": "\nint ext4_write_inline_data_end(struct inode *inode, loff_t pos, unsigned len,\n\t\t\t       unsigned copied, struct page *page)\n{\n\tint ret;\n\tvoid *kaddr;\n\tstruct ext4_iloc iloc;\n\n\tif (unlikely(copied < len)) {\n\t\tif (!PageUptodate(page)) {\n\t\t\tcopied = 0;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = ext4_get_inode_loc(inode, &iloc);\n\tif (ret) {\n\t\text4_std_error(inode->i_sb, ret);\n\t\tcopied = 0;\n\t\tgoto out;\n\t}\n\n\tdown_write(&EXT4_I(inode)->xattr_sem);\n\tBUG_ON(!ext4_has_inline_data(inode));\n\n\tkaddr = kmap_atomic(page);\n\text4_write_inline_data(inode, &iloc, kaddr, pos, len);\n\tkunmap_atomic(kaddr);\n\tSetPageUptodate(page);\n\t/* clear page dirty so that writepages wouldn't work for us. */\n\tClearPageDirty(page);\n\n\tup_write(&EXT4_I(inode)->xattr_sem);\n\tbrelse(iloc.bh);\nout:\n\treturn copied;\n}",
    "comment": "Writes inline data to the inode's page, marking it as up-to-date and clearing its dirty state after successfully copying the specified length.",
    "prorec_sum": "Finalizes writing inline data in an ext4 inode, ensuring journal access, updating buffer states, and handling errors through kernel bug checks.",
    "filter_prorec_sum": "Finalizes an ext4 inline data write operation, updating journal access, buffer state, and related metadata with error logging and synchronization.",
    "prorec_aug_sum": "Handles completion of ext4 inline data writes by validating conditions, performing block operations, updating flags, and finalizing with optional follow-up processing.",
    "filter_prorec_aug_sum": "Handles completion of ext4 inline data write operations, updating flags, invoking end I/O processing, and logging errors when conditions are met.",
    "work_score": {
        "prorec_aug": {
            "summary": "Handles completion of ext4 inline data writes by validating conditions, performing block operations, updating flags, and finalizing with optional follow-up processing.",
            "score": [
                0.5,
                0.2,
                0.5
            ],
            "reason": [
                "The summary makes only generic statements about handling completion, validating conditions, performing block operations, and updating flags, which are broadly accurate but lack specificity tied to the function's actual sequence of operations in the code. It omits key details such as handling partial copies, checking page uptodate status, obtaining inode location, using locks, and final cleanup steps. While nothing is factually wrong, the low informational content means the accuracy present is mostly boilerplate rather than precise domain-semantic claims.",
                "The summary offers vague and generic descriptions like 'validating conditions' and 'performing block operations' without explicitly stating the core purpose of completing an inline data write for an ext4 inode. It fails to mention specific domain actions such as retrieving inode location, locking/unlocking xattr_sem, mapping/unmapping the page, writing inline data, updating page state flags, and handling errors. While the wording alludes to finalizing a write, the lack of precise ext4 inline data semantics means the core purpose is not adequately covered and secondary behaviors are mostly omitted.",
                "The summary contains mostly generic and broad statements like 'validating conditions', 'performing block operations', and 'updating flags' without specifying the actual behaviors from the code such as calling ext4_get_inode_loc, using kmap_atomic/kunmap_atomic, or clearing page dirty state. There are no explicit incorrect (FATAL) claims, but the language is abstract and omits key domain-specific details, resulting in low informational gain. The worst failure mode is NOISE due to vagueness rather than contradiction."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Handles completion of ext4 inline data write operations, updating flags, invoking end I/O processing, and logging errors when conditions are met.",
            "score": [
                0.5,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly identifies that the function handles completion of ext4 inline data write operations and logs errors, which are accurate and supported by the code. However, it inaccurately mentions 'invoking end I/O processing', which is not present in the implementation, and omits specific details such as mapping the page, writing inline data, and clearing the dirty flag. This mix results in only partial accuracy of the claims.",
                "The summary correctly identifies that the function finalizes inline data write operations and updates state flags, aligning with the core operation of writing inline data in ext4. However, it inaccurately mentions end I/O processing and logging errors, which the code does not perform directly. It omits important specifics such as acquiring the xattr semaphore, mapping/unmapping the page, handling the inline data branch conditions, and managing the page\u2019s dirty state and error cleanup. The core purpose is covered, but secondary behaviors are only partially represented.",
                "The summary correctly notes handling completion of ext4 inline data writes and logging errors, which aligns with the function\u2019s core. However, it inaccurately claims 'invoking end I/O processing', which is not present in the code, and omits key specifics such as mapping the page, writing inline data via ext4_write_inline_data, and clearing dirty flags. The inaccuracies introduce moderate noise but do not fatally misstate the primary purpose, resulting in low net benefit from mostly generic claims."
            ]
        }
    }
}
{
    "source_code": "void luaS_resize(lua_State* L, int newsize) {\n  int i;\n  stringtable* tb = &G(L)->strt; // global string table\n  if (newsize > tb->size) { /* grow table if needed */\n    luaM_reallocvector(L, tb->hash, tb->size, newsize, TString*);\n    for (i = tb->size; i < newsize; i++)\n      // open hash table, tb->hash is the pointer for linked list\n      tb->hash[i] = NULL;\n  }\n  for (i = 0; i < tb->size; i++) { /* rehash */\n    TString* p = tb->hash[i];\n    tb->hash[i] = NULL;\n    while (p) { /* for each node in the list */\n      TString* hnext = p->u.hnext; /* save next */\n      unsigned int h = lmod(p->hash, newsize); /* new position */\n      p->u.hnext = tb->hash[h]; /* chain it */\n      tb->hash[h] = p;\n      p = hnext;\n    }\n  }\n  if (newsize < tb->size) { /* shrink table if needed */\n    /* vanishing slice should be empty */\n    lua_assert(tb->hash[newsize] == NULL && tb->hash[tb->size - 1] == NULL);\n    luaM_reallocvector(L, tb->hash, tb->size, newsize, TString*);\n  }\n  tb->size = newsize;\n}",
    "comment": "Resizes the global string table, rehashes existing strings, and reallocates memory based on the new size provided.",
    "prorec_sum": "Resizes a hash table\u2019s bucket array and rehashes all entries to match the new capacity specified by the parameter.",
    "filter_prorec_sum": "Resizes and rehashes a hash table\u2019s bucket array to the specified size, clearing entries and redistributing existing nodes based on updated index masking.",
    "prorec_aug_sum": "Resizes a hash table's bucket array and rehashes its linked entries to match the new size.",
    "filter_prorec_aug_sum": "Resizes a hash table\u2019s bucket array to the specified size and reassigns existing linked-list entries into new buckets based on updated indexing.",
    "work_score": {
        "prorec_aug": {
            "summary": "Resizes a hash table's bucket array and rehashes its linked entries to match the new size.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function resizes the hash table's bucket array and rehashes its linked entries to fit the new size, which is directly reflected in the source code's growth, shrink, and rehash logic. There are no contradictory or irrelevant claims, and all details are accurate though somewhat general, covering the core behavior of the function without errors.",
                "The summary accurately describes the core purpose: resizing the string table's bucket array and rehashing linked entries to fit the new size. This directly matches the function's domain behavior in the source code. However, it omits secondary details such as handling both growth and shrink scenarios, initializing new buckets to NULL when growing, performing assertions before shrinking, and the specifics of reallocation and pointer chaining. These omissions reduce coverage of behavior-critical semantics.",
                "The summary accurately captures the primary purpose of the function, which is to resize the hash table and rehash its entries to fit the new bucket count. There is no contradictory or irrelevant information, and the claim is semantically consistent with the source code logic, including both growing and shrinking scenarios. The detail level is moderate, giving a clear core operation but lacking specifics about initialization, linked list handling, and assertion checks, thus providing limited engineering insight while avoiding noise."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Resizes a hash table\u2019s bucket array to the specified size and reassigns existing linked-list entries into new buckets based on updated indexing.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function resizes a hash table\u2019s bucket array and reassigns linked-list entries into new buckets based on updated indexing, which aligns with the source code\u2019s behavior of growing/shrinking the string table and rehashing entries. It omits some implementation specifics, such as handling empty slices when shrinking, but these omissions do not make the statement inaccurate. The claims present are domain-accurate and specific to the function\u2019s semantics, resulting in a very high proportion of accurate claims.",
                "The summary accurately describes the core functional behavior of resizing the string table\u2019s bucket array and rehashing linked-list entries into new buckets, matching the source code\u2019s primary purpose. However, it omits secondary details such as handling distinct grow and shrink cases, initializing new buckets to NULL, asserting emptiness when shrinking, and using Lua-specific memory reallocation functions. This leads to incomplete coverage of behavior-critical semantics beyond the core action.",
                "The summary correctly states the core function purpose of resizing the hash table\u2019s bucket array and reassigning entries according to updated indices, which matches the code\u2019s grow/shrink and rehash logic. It omits some specifics like handling both growth and shrink conditions, memory reallocation, and null-initialization of new buckets, but contains no inaccuracies or irrelevant noise. The gain is moderate as it captures the main semantics without fine details."
            ]
        }
    }
}
{
    "source_code": "\nint ssl3_get_req_cert_type(SSL *s, unsigned char *p)\n\t{\n\tint ret=0;\n\tunsigned long alg_k;\n\n\talg_k = s->s3->tmp.new_cipher->algorithm_mkey;\n\n#ifndef OPENSSL_NO_GOST\n\tif (s->version >= TLS1_VERSION)\n\t\t{\n\t\tif (alg_k & SSL_kGOST)\n\t\t\t{\n\t\t\tp[ret++]=TLS_CT_GOST94_SIGN;\n\t\t\tp[ret++]=TLS_CT_GOST01_SIGN;\n\t\t\treturn(ret);\n\t\t\t}\n\t\t}\n#endif\n\n#ifndef OPENSSL_NO_DH\n\tif (alg_k & (SSL_kDHr|SSL_kEDH))\n\t\t{\n#  ifndef OPENSSL_NO_RSA\n\t\tp[ret++]=SSL3_CT_RSA_FIXED_DH;\n#  endif\n#  ifndef OPENSSL_NO_DSA\n\t\tp[ret++]=SSL3_CT_DSS_FIXED_DH;\n#  endif\n\t\t}\n\tif ((s->version == SSL3_VERSION) &&\n\t\t(alg_k & (SSL_kEDH|SSL_kDHd|SSL_kDHr)))\n\t\t{\n#  ifndef OPENSSL_NO_RSA\n\t\tp[ret++]=SSL3_CT_RSA_EPHEMERAL_DH;\n#  endif\n#  ifndef OPENSSL_NO_DSA\n\t\tp[ret++]=SSL3_CT_DSS_EPHEMERAL_DH;\n#  endif\n\t\t}\n#endif /* !OPENSSL_NO_DH */\n#ifndef OPENSSL_NO_RSA\n\tp[ret++]=SSL3_CT_RSA_SIGN;\n#endif\n#ifndef OPENSSL_NO_DSA\n\tp[ret++]=SSL3_CT_DSS_SIGN;\n#endif\n#ifndef OPENSSL_NO_ECDH\n\tif ((alg_k & (SSL_kECDHr|SSL_kECDHe)) && (s->version >= TLS1_VERSION))\n\t\t{\n\t\tp[ret++]=TLS_CT_RSA_FIXED_ECDH;\n\t\tp[ret++]=TLS_CT_ECDSA_FIXED_ECDH;\n\t\t}\n#endif\n\n#ifndef OPENSSL_NO_ECDSA\n\t/* ECDSA certs can be used with RSA cipher suites as well \n\t * so we don't need to check for SSL_kECDH or SSL_kEECDH\n\t */\n\tif (s->version >= TLS1_VERSION)\n\t\t{\n\t\tp[ret++]=TLS_CT_ECDSA_SIGN;\n\t\t}\n#endif\t\n\treturn(ret);\n\t}",
    "comment": "Determines and populates the required certificate types based on the SSL connection's cipher algorithms and version.",
    "prorec_sum": "Generates the SSL/TLS requested certificate types list based on protocol version and capability flags, returning the number of types added.",
    "filter_prorec_sum": "Generates the SSLv3/TLS client certificate type list based on connection version and capability flags.",
    "prorec_aug_sum": "Constructs the SSLv3 certificate request type list based on the connection version and bitmask flags, and returns the number of types added.",
    "filter_prorec_aug_sum": "Constructs a list of acceptable SSL certificate type codes based on protocol version and capability flags, returning the count of generated entries.",
    "work_score": {
        "prorec_aug": {
            "summary": "Constructs the SSLv3 certificate request type list based on the connection version and bitmask flags, and returns the number of types added.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function builds a certificate type list according to the connection version and bitmask flags, and returns the number of types added. These claims align with the source code, which branches logic on 's->version' and 'alg_k' flags, populates 'p' with certificate types, and returns 'ret'. There are no inaccurate or irrelevant claims, indicating high precision.",
                "The summary correctly states that the function builds a certificate request type list depending on the SSL/TLS version and algorithm bitmask, and returns the count, which is the core semantic of the source code. However, it omits secondary details such as specific handling for GOST, DH, RSA, DSA, ECDH, and ECDSA, as well as conditional compilation and version checks tied to these algorithms, so coverage of important branches and constants is weak.",
                "The summary correctly captures the primary purpose of the function\u2014building a certificate request type list based on version and algorithm flags and returning its count. This aligns with the source code's logic, which appends specific certificate types to the list depending on version checks and algorithm bitmask conditions. The claim is accurate, domain-specific, and free of noise, though relatively concise without detailing the specific types added, so the gain is moderate rather than maximal."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Constructs a list of acceptable SSL certificate type codes based on protocol version and capability flags, returning the count of generated entries.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary accurately states that the function constructs a list of acceptable SSL certificate type codes using protocol version and capability flags, and returns the count of entries. These behaviors match the source code, which iterates over various algorithm and version checks to populate the array `p` and then returns `ret`. There are no incorrect or irrelevant claims, and all statements are directly supported by the code.",
                "The summary accurately captures the core purpose of selecting SSL certificate type codes based on protocol version and algorithm flags, and returning the count. This aligns with the source code\u2019s main function of populating the output array with appropriate certificate type constants depending on version and supported key exchange/cipher algorithms. However, it omits secondary details such as specific handling for GOST, DH, RSA, DSA, and ECDSA, as well as the conditional compilation controls present in the code, making its coverage of secondary behavior incomplete.",
                "The summary accurately captures the primary purpose of the function: generating a list of SSL certificate type codes based on protocol version and capability flags, and returning the count. This aligns well with the source code\u2019s logic, which conditionally appends certificate type codes according to version and supported algorithms before returning the total. There is no inaccurate or noisy claim, though the description is general and lacks specific details such as the use of GOST, DH, RSA, DSA, and ECDH flags, which limits the informational gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void e1000_get_wol(struct net_device *netdev,\n\t\t\t  struct ethtool_wolinfo *wol)\n{\n\tstruct e1000_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\twol->supported = WAKE_UCAST | WAKE_MCAST |\n\t                 WAKE_BCAST | WAKE_MAGIC;\n\twol->wolopts = 0;\n\n\t/* this function will set ->supported = 0 and return 1 if wol is not\n\t * supported by this hardware\n\t */\n\tif (e1000_wol_exclusion(adapter, wol) ||\n\t    !device_can_wakeup(&adapter->pdev->dev))\n\t\treturn;\n\n\t/* apply any specific unsupported masks here */\n\tswitch (hw->device_id) {\n\tcase E1000_DEV_ID_82546GB_QUAD_COPPER_KSP3:\n\t\t/* KSP3 does not support UCAST wake-ups */\n\t\twol->supported &= ~WAKE_UCAST;\n\n\t\tif (adapter->wol & E1000_WUFC_EX)\n\t\t\te_err(drv, \"Interface does not support directed \"\n\t\t\t      \"(unicast) frame wake-up packets\\n\");\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (adapter->wol & E1000_WUFC_EX)\n\t\twol->wolopts |= WAKE_UCAST;\n\tif (adapter->wol & E1000_WUFC_MC)\n\t\twol->wolopts |= WAKE_MCAST;\n\tif (adapter->wol & E1000_WUFC_BC)\n\t\twol->wolopts |= WAKE_BCAST;\n\tif (adapter->wol & E1000_WUFC_MAG)\n\t\twol->wolopts |= WAKE_MAGIC;\n}",
    "comment": "Configures wake-on-LAN options for the network device based on adapter capabilities and supported wake-up frame types.",
    "prorec_sum": "Configures wake-up capability flags in the target structure based on device status bits and logs if unicast frame wake-up is unsupported.",
    "filter_prorec_sum": "Configures wake-up capability flags in an output structure based on interface power management settings and hardware support for directed frame reception.",
    "prorec_aug_sum": "Configures wake-up packet capabilities in a network interface, enabling flags for unicast, multicast, and broadcast wake support based on hardware and configuration status.",
    "filter_prorec_aug_sum": "Configures wake-up capabilities in the provided structure based on device flags, logging if directed unicast frame wake-up is unsupported.",
    "work_score": {
        "prorec_aug": {
            "summary": "Configures wake-up packet capabilities in a network interface, enabling flags for unicast, multicast, and broadcast wake support based on hardware and configuration status.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly notes that the function configures wake-up capabilities and mentions unicast, multicast, and broadcast wake support based on hardware/configuration, which aligns with the code's logic. However, it omits specific details such as magic packet support, conditional hardware exclusions (like for device ID E1000_DEV_ID_82546GB_QUAD_COPPER_KSP3), and the distinction between supported flags and wolopts assignment. Despite these omissions, the included claims are accurate, covering more than 80% of the key behavior at a high level.",
                "The summary correctly identifies the general function of configuring wake-up packet capabilities and mentions unicast, multicast, and broadcast support, which aligns with the code's behavior. However, it omits key aspects: magic packet support is missing, the conditional exclusion of unicast for specific hardware (device_id check) is not covered, and the possibility of disabling all WOL if hardware does not support it is absent. These omissions weaken coverage of critical secondary details.",
                "The summary correctly states that the function configures wake-up packet capabilities and that it enables flags for unicast, multicast, and broadcast wake support based on hardware and configuration. However, it omits mention of magic packet support, a capability set early in the code, and does not clarify the exclusion behavior or hardware-specific masking (e.g., removal of unicast support for certain device IDs). These omissions reduce its specificity, but there are no contradictory or completely irrelevant claims. The main shortcoming is low detail rather than inaccuracy."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Configures wake-up capabilities in the provided structure based on device flags, logging if directed unicast frame wake-up is unsupported.",
            "score": [
                0.6,
                0.5,
                0.9
            ],
            "reason": [
                "The summary correctly captures that the function sets wake-up capability fields based on device-specific flags and mentions the logging of unicast wake-up unsupported situations, both of which are evident in the code. However, it omits key details like the initial setting of all supported wake types, the conditional exclusion based on hardware capability (`e1000_wol_exclusion` and `device_can_wakeup`), and handling of individual wake option bits. The claims that are present are accurate but incomplete, leading to moderate coverage of the function's behavior.",
                "The summary accurately mentions configuring wake-up capabilities based on device flags and logging when directed unicast wake-up is unsupported, which matches key details from the code. However, it omits the core purpose that the function specifically populates the ethtool_wolinfo structure with supported and enabled wake-on-LAN options, handling hardware capability checks, device-specific exclusions, and mapping adapter flags to wolopts. Important aspects like supported wake types (unicast, multicast, broadcast, magic), hardware exclusion checks, and the conditional clearing of capabilities are missing, weakening coverage of secondary critical semantics.",
                "The summary correctly identifies that the function populates a wake-on-LAN (WoL) info structure based on hardware/device flags and mentions the logged warning for unsupported directed (unicast) frame wake-ups. It captures the primary purpose and key side behavior accurately without introducing irrelevant or incorrect information. The claims are both specific and verifiable from the code with no evident noise or omission of major behavior."
            ]
        }
    }
}
{
    "source_code": "\nint intel_pmu_setup_lbr_filter(struct perf_event *event)\n{\n\tint ret = 0;\n\n\t/*\n\t * no LBR on this PMU\n\t */\n\tif (!x86_pmu.lbr_nr)\n\t\treturn -EOPNOTSUPP;\n\n\t/*\n\t * setup SW LBR filter\n\t */\n\tret = intel_pmu_setup_sw_lbr_filter(event);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * setup HW LBR filter, if any\n\t */\n\tif (x86_pmu.lbr_sel_map)\n\t\tret = intel_pmu_setup_hw_lbr_filter(event);\n\n\treturn ret;\n}",
    "comment": "Configures both software and hardware LBR filters for a performance event if LBR support is available on the PMU.",
    "prorec_sum": "Configures device state flags from a structure field and updates related masks, returning errors if prerequisites or mappings are invalid.",
    "filter_prorec_sum": "Configures device control flags from a context structure and applies a resource mask based on enabled feature bits, returning specific error codes if unsupported.",
    "prorec_aug_sum": "Configures CPU-related flags from a task structure\u2019s field and updates global masks, returning errors if prerequisites or mappings are invalid.",
    "filter_prorec_aug_sum": "Configures CPU-related flags in a task structure and updates global masks based on enabled feature bits, returning errors for invalid or unsupported configurations.",
    "work_score": {
        "prorec_aug": {
            "summary": "Configures CPU-related flags from a task structure\u2019s field and updates global masks, returning errors if prerequisites or mappings are invalid.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes configuring CPU flags and global masks from a task structure, which does not match the actual function's semantics. The source code sets up software and hardware LBR filters for a performance event, returning specific errors if unsupported, while the summary's claims are unrelated to LBR setup. All claims are inaccurate, leading to complete misalignment.",
                "The summary's claims about configuring CPU-related flags from a task structure and updating global masks do not align with the source code, which performs setup of software and hardware Last Branch Record (LBR) filters for a perf_event, returning errors if LBR is unsupported or filter setup fails. The core purpose of setting up LBR filters is entirely missing, and none of the claims accurately reflect the observed behavior, leading to no coverage of primary or secondary semantics.",
                "The summary\u2019s claims about configuring CPU-related flags from a task structure and updating global masks do not match the source code, which sets up software and hardware LBR filters for performance monitoring based on PMU capabilities. This is a FATAL inaccuracy affecting the primary purpose and core functionality description, making the summary misleading and unusable."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Configures CPU-related flags in a task structure and updates global masks based on enabled feature bits, returning errors for invalid or unsupported configurations.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary describes configuring CPU-related flags in a task structure and updating global masks based on feature bits, which does not match the source code's actual behavior of setting up software and hardware LBR filters for a performance event and returning errors based on PMU capabilities. None of the claims are accurate to the code's semantics, indicating a complete mismatch.",
                "The summary's claims about configuring CPU flags and updating global masks do not align with the source code, which sets up software and hardware Last Branch Record filters for a performance monitoring event and returns specific errors when unsupported. The core domain purpose of LBR filter setup is missing entirely, and all claims are inaccurate as they describe unrelated behavior.",
                "The summary describes configuring CPU flags in a task structure and updating global masks, which is unrelated to the actual function. The source code sets up software and hardware Last Branch Record (LBR) filters for performance events, returning errors if unsupported or on failure. All claims in the summary are NOISE and do not target the code\u2019s actual purpose, with no accurate points present. The worst failure mode is overwhelming NOISE with zero alignment to the core semantics."
            ]
        }
    }
}
{
    "source_code": "\nstatic int __init dquot_init(void)\n{\n\tint i, ret;\n\tunsigned long nr_hash, order;\n\n\tprintk(KERN_NOTICE \"VFS: Disk quotas %s\\n\", __DQUOT_VERSION__);\n\n\tregister_sysctl_table(sys_table);\n\n\tdquot_cachep = kmem_cache_create(\"dquot\",\n\t\t\tsizeof(struct dquot), sizeof(unsigned long) * 4,\n\t\t\t(SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|\n\t\t\t\tSLAB_MEM_SPREAD|SLAB_PANIC),\n\t\t\tNULL);\n\n\torder = 0;\n\tdquot_hash = (struct hlist_head *)__get_free_pages(GFP_ATOMIC, order);\n\tif (!dquot_hash)\n\t\tpanic(\"Cannot create dquot hash table\");\n\n\tfor (i = 0; i < _DQST_DQSTAT_LAST; i++) {\n\t\tret = percpu_counter_init(&dqstats.counter[i], 0);\n\t\tif (ret)\n\t\t\tpanic(\"Cannot create dquot stat counters\");\n\t}\n\n\t/* Find power-of-two hlist_heads which can fit into allocation */\n\tnr_hash = (1UL << order) * PAGE_SIZE / sizeof(struct hlist_head);\n\tdq_hash_bits = 0;\n\tdo {\n\t\tdq_hash_bits++;\n\t} while (nr_hash >> dq_hash_bits);\n\tdq_hash_bits--;\n\n\tnr_hash = 1UL << dq_hash_bits;\n\tdq_hash_mask = nr_hash - 1;\n\tfor (i = 0; i < nr_hash; i++)\n\t\tINIT_HLIST_HEAD(dquot_hash + i);\n\n\tprintk(\"Dquot-cache hash table entries: %ld (order %ld, %ld bytes)\\n\",\n\t\t\tnr_hash, order, (PAGE_SIZE << order));\n\n\tregister_shrinker(&dqcache_shrinker);\n\n\treturn 0;\n}",
    "comment": "Initializes the disk quota subsystem by creating a cache, allocating a hash table, and setting up statistical counters.",
    "prorec_sum": "Initializes quota management by creating the dquot cache, hash table, and associated statistics counters, then logs their configuration.",
    "filter_prorec_sum": "Initializes the dquot subsystem by creating its hash table, setting up stat counters, and logging cache table configuration.",
    "prorec_aug_sum": "Initializes the dquot subsystem by creating its hash table, allocating stat counters, and logging cache parameters for quota management.",
    "filter_prorec_aug_sum": "Initializes the dquot subsystem by allocating a hash table, setting up stat counters, clearing entries, and logging cache table details.",
    "work_score": {
        "prorec_aug": {
            "summary": "Initializes the dquot subsystem by creating its hash table, allocating stat counters, and logging cache parameters for quota management.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly conveys the main behaviors: initializing the dquot subsystem, creating its hash table, allocating stat counters, and logging cache parameters. All these actions are explicitly present in the source code, with no contradictions or irrelevant claims, reflecting accurate coverage of the function's domain semantics.",
                "The summary correctly states the function initializes the dquot subsystem, creates a hash table, allocates stat counters, and logs parameters, which matches the core domain purpose of setting up disk quota data structures. However, it omits key secondary details from the code, such as sysctl table registration, specific kmem cache creation for dquot objects, panic handling on allocation failures, initializing hash heads, and registering the shrinker. Coverage of secondary behaviors is therefore limited.",
                "The summary correctly captures the primary purpose of the function: it initializes the disk quota subsystem. It accurately mentions creation of a hash table, allocation of stat counters, and logging, all of which are present in the source code. While it omits some specific implementation details like cache creation via kmem_cache_create, sysctl registration, and shrinker registration, there are no inaccurate or contradictory claims. The claims are largely generic and lack deeper specifics, limiting the positive gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes the dquot subsystem by allocating a hash table, setting up stat counters, clearing entries, and logging cache table details.",
            "score": [
                0.8,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies initialization of the dquot subsystem, allocation of a hash table, setup of stat counters, and logging of cache table details, all of which are supported by the source code. However, the claim about 'clearing entries' is inaccurate \u2014 the code initializes hash list heads but does not explicitly clear existing data entries. Most other claims align well with the source, so the majority are accurate.",
                "The summary accurately states the core purpose of initializing the dquot subsystem, which aligns with the source code\u2019s main operation of setting up memory structures for disk quota management. It correctly mentions allocating a hash table, initializing stat counters, and logging cache table details, covering the core initialization functionality. However, it omits other critical behaviors from the source such as sysctl registration, creation of the kmem cache with specific flags, panic handling on allocation failures, computation of hash bits/mask, initializing each hash list head, and registering a shrinker. These omissions make the coverage of secondary details incomplete.",
                "The summary correctly mentions initialization of the dquot subsystem, allocation of a hash table, setup of stat counters, and logging of cache table details, which are consistent with the source code. However, it inaccurately describes 'clearing entries'\u2014the code initializes hash list heads rather than clearing existing entries\u2014making this a minor semantic error, but not a FATAL on the primary purpose. The claims are mostly accurate but lack deeper detail on the multiple specific steps in initialization, offering only modest informational value."
            ]
        }
    }
}
{
    "source_code": "static int netlbl_unlabel_list(struct sk_buff *skb, struct genl_info *info)\n{\n\tint ret_val = -EINVAL;\n\tstruct sk_buff *ans_skb;\n\tvoid *data;\n\n\tans_skb = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\n\tif (ans_skb == NULL)\n\t\tgoto list_failure;\n\tdata = genlmsg_put_reply(ans_skb, info, &netlbl_unlabel_gnl_family,\n\t\t\t\t 0, NLBL_UNLABEL_C_LIST);\n\tif (data == NULL) {\n\t\tret_val = -ENOMEM;\n\t\tgoto list_failure;\n\t}\n\n\tret_val = nla_put_u8(ans_skb,\n\t\t\t     NLBL_UNLABEL_A_ACPTFLG,\n\t\t\t     netlabel_unlabel_acceptflg);\n\tif (ret_val != 0)\n\t\tgoto list_failure;\n\n\tgenlmsg_end(ans_skb, data);\n\treturn genlmsg_reply(ans_skb, info);\n\nlist_failure:\n\tkfree_skb(ans_skb);\n\treturn ret_val;\n}",
    "comment": "Generates and replies with a netlabel unlabeling response containing an acceptance flag in a netlink message or returns an error.",
    "prorec_sum": "Initializes a network-related structure, configures parameters, and dispatches it through a lower-level transmission routine, returning success or an error code.",
    "filter_prorec_sum": "Initializes a network-related object, configures it with provided parameters, and performs a follow-up operation, returning success or an error code.",
    "prorec_aug_sum": "Allocates and initializes a network-related structure, configures it with provided parameters, then commits it to a connection table, handling errors appropriately.",
    "filter_prorec_aug_sum": "Initializes a network-related object, configures it with provided parameters, updates metadata, and invokes a follow-up operation, returning errors or success accordingly.",
    "work_score": {
        "prorec_aug": {
            "summary": "Allocates and initializes a network-related structure, configures it with provided parameters, then commits it to a connection table, handling errors appropriately.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function allocates and initializes a network-related structure and commits it to a connection table, but the source code shows it creates a netlink message, adds a flag, and sends a reply without interacting with any connection table. While it accurately notes allocation and error handling, most claims about configuration with provided parameters and committing to a connection table are unsupported or inaccurate, resulting in less than half of the claims being correct.",
                "The summary\u2019s claims about allocating and initializing a network-related structure and committing it to a connection table do not match the source code\u2019s core purpose, which is to build and send a generic netlink reply containing the netlabel unlabel accept flag. The summary omits this primary functionality and misstates the target of initialization and the destination, indicating inaccurate coverage of core semantics and secondary behaviors. Error handling is mentioned but context is wrong.",
                "The summary's main claims\u2014that the function allocates and initializes a network-related structure, configures it with provided parameters, and commits it to a connection table\u2014are inaccurate. The source code actually allocates a netlink message buffer, populates it with specific reply data (accept flag), and sends it back via generic netlink, with error handling. There is no connection table involvement, and 'provided parameters' are not used for configuration in the stated way. This represents a severe FATAL error on the primary purpose of the function, making the description misleading and untrustworthy."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Initializes a network-related object, configures it with provided parameters, updates metadata, and invokes a follow-up operation, returning errors or success accordingly.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary offers a very generic description without accurately reflecting the specific contract of the function in the source code. It omits key domain-specific details such as creating a netlink message, adding an accept flag attribute, managing memory on failure, and sending a reply. Most claims are vague and nonspecific, providing little verifiable alignment with the code\u2019s actual semantics, making the proportion of accurate claims very low.",
                "The summary is vague and generic, failing to convey the specific core purpose of the function, which is to construct and send a generic netlink reply containing the unlabel accept flag for netlabel unlabel list requests. While it correctly implies some initialization and operation with possible errors, it does not accurately describe the domain semantics, omits key details such as message construction, attribute addition, and reply sending, and does not cover any error branch handling specifics. As a result, the core purpose is not covered and secondary behavioral coverage is minimal.",
                "The summary contains mostly generic and vague statements that do not match the specific semantics of the function. The function constructs a netlink message with details from netlabel_unlabel_acceptflg and replies to a request, but the summary's claims about configuring with provided parameters, updating metadata, and invoking a follow-up operation are high-level and not explicitly supported. These are NOISE rather than domain-specific GOLD accuracy, with no clear factual contradiction but also no detailed, verifiable insight into the core purpose. Noise dominates, and gain is very low."
            ]
        }
    }
}
{
    "source_code": "\nvoid\nS_SET_EXTERNAL (symbolS *s)\n{\n  if (LOCAL_SYMBOL_CHECK (s))\n    s = local_symbol_convert ((struct local_symbol *) s);\n  if ((s->bsym->flags & BSF_WEAK) != 0)\n    {\n      /* Let .weak override .global.  */\n      return;\n    }\n  if (s->bsym->flags & BSF_SECTION_SYM)\n    {\n      /* Do not reassign section symbols.  */\n      as_warn (_(\"section symbols are already global\"));\n      return;\n    }\n#ifndef TC_GLOBAL_REGISTER_SYMBOL_OK\n  if (S_GET_SEGMENT (s) == reg_section)\n    {\n      as_bad (\"can't make register symbol `%s' global\",\n\t      S_GET_NAME (s));\n      return;\n    }\n#endif\n  s->bsym->flags |= BSF_GLOBAL;\n  s->bsym->flags &= ~(BSF_LOCAL | BSF_WEAK);\n\n#ifdef TE_PE\n  if (! an_external_name && S_GET_NAME(s)[0] != '.')\n    an_external_name = S_GET_NAME (s);\n#endif\n}",
    "comment": "Sets a symbol as global, overriding weak and local flags while preventing reassignment of section or register symbols.",
    "prorec_sum": "Marks a section symbol as global unless it is already global or a register symbol, issuing corresponding error messages when prohibited.",
    "filter_prorec_sum": "Marks a section symbol as global unless it is already global or is a register symbol, issuing appropriate error messages when invalid.",
    "prorec_aug_sum": "Marks a section symbol as global unless it is already global or a register symbol, issuing translated error messages when those conditions prevent changes.",
    "filter_prorec_aug_sum": "Marks a section symbol as global unless it is already global or a restricted register symbol, returning appropriate error messages when disallowed.",
    "work_score": {
        "prorec_aug": {
            "summary": "Marks a section symbol as global unless it is already global or a register symbol, issuing translated error messages when those conditions prevent changes.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary captures that the function makes a symbol global unless certain conditions prevent changes, but it inaccurately describes those conditions. It omits the check for weak symbols (which block global assignment), misrepresents the section symbol case as 'already global' instead of issuing a warning without necessarily being global, and ignores the LOCAL_SYMBOL_CHECK conversion. The description of error reporting is partially correct for register symbols but overgeneralizes to 'translated error messages'. Less than half of the claims align precisely with the source code's semantics.",
                "The summary incorrectly identifies the function as marking a section symbol as global, whereas the source code explicitly avoids reassigning section symbols and instead warns if they are already global. It omits the core purpose of marking a non-weak, non-section, non-register symbol as global. It also fails to mention handling of weak symbols, conversion of local symbols, and the TE_PE external name assignment. The translated error message reference is generally accurate for the register symbol case, but overall the core domain action is missing and some details are wrong.",
                "The summary misrepresents core behavior: it claims the function marks a section symbol as global, but the source code specifically avoids reassigning section symbols and instead issues a warning. This is a FATAL error on the primary purpose and core logic, as the function's actual role is to set a symbol as global unless weak, section, or register conditions block it. While the summary correctly mentions register symbols and error/warning messages, the incorrect handling of section symbols severely undermines trustworthiness."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Marks a section symbol as global unless it is already global or a restricted register symbol, returning appropriate error messages when disallowed.",
            "score": [
                0.2,
                0.3,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function\u2019s behavior. The code marks a symbol as global unless it is weak, a section symbol, or a register symbol, with specific warnings/errors for section and register symbols. The summary omits the weak symbol check and misstates the section symbol logic by claiming it applies only if not already global, which is not reflected in the source. This results in multiple inaccuracies, with less than half of the claims aligning to the code\u2019s actual semantics.",
                "The summary partially captures the core by indicating the function marks symbols as global and notes restrictions for register symbols, but it misstates key conditions: the code operates on generic symbols, not specifically 'section symbols', and has exceptions for weak and section symbols with distinct handling not mentioned here. It omits secondary behaviors such as conversion of local symbols, the precedence of .weak over .global, issuance of warnings for section symbols, conditional handling for TE_PE, and flag adjustments. The inaccuracies and missing details reduce alignment with the source.",
                "The summary correctly states that the function marks a symbol as global unless it meets certain conditions and mentions restricted register symbols, but it inaccurately claims that section symbols are marked as global if not already global. In the code, section symbols are never reassigned and instead trigger a warning, indicating a core semantic error about handling section symbols. This is a FATAL error impacting the description of the primary purpose."
            ]
        }
    }
}
{
    "source_code": "\nint FAST_FUNC ll_addr_a2n(unsigned char *lladdr, int len, char *arg)\n{\n\tint i;\n\n\tif (strchr(arg, '.')) {\n\t\tinet_prefix pfx;\n\t\tif (get_addr_1(&pfx, arg, AF_INET)) {\n\t\t\tbb_error_msg(\"\\\"%s\\\" is invalid lladdr\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tif (len < 4) {\n\t\t\treturn -1;\n\t\t}\n\t\tmemcpy(lladdr, pfx.data, 4);\n\t\treturn 4;\n\t}\n\n\tfor (i = 0; i < len; i++) {\n\t\tint temp;\n\t\tchar *cp = strchr(arg, ':');\n\t\tif (cp) {\n\t\t\t*cp = 0;\n\t\t\tcp++;\n\t\t}\n\t\tif (sscanf(arg, \"%x\", &temp) != 1 || (temp < 0 || temp > 255)) {\n\t\t\tbb_error_msg(\"\\\"%s\\\" is invalid lladdr\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tlladdr[i] = temp;\n\t\tif (!cp) {\n\t\t\tbreak;\n\t\t}\n\t\targ = cp;\n\t}\n\treturn i+1;\n}",
    "comment": "Converts a string representation of a link-layer address to its binary format, supporting both IPv4 addresses and hexadecimal notation.",
    "prorec_sum": "Parses and validates a link-layer address string, storing its bytes into the provided buffer and reporting an error if the format is invalid.",
    "filter_prorec_sum": "Parses and validates a textual link-layer address, storing its bytes into the provided buffer or reporting an invalid address error.",
    "prorec_aug_sum": "Parses and validates a MAC address string, storing its bytes into the provided buffer and returning the number of parsed components or an error.",
    "filter_prorec_aug_sum": "Parses a string-formatted link-layer address into bytes, validating each segment and reporting an error if the format or values are invalid.",
    "work_score": {
        "prorec_aug": {
            "summary": "Parses and validates a MAC address string, storing its bytes into the provided buffer and returning the number of parsed components or an error.",
            "score": [
                0.5,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function parses and validates an address string, stores bytes in the provided buffer, and returns the count or an error. However, it inaccurately specifies that it is specifically a MAC address, whereas the source code also supports parsing IPv4 addresses when dots are present. This mislabeling means not all claims are accurate, with only some reflecting the actual logic implemented.",
                "The summary correctly states that the function parses and validates an address string, stores the bytes into a buffer, and returns a count or error, which aligns with the core behavior. However, it inaccurately constrains the domain to MAC addresses only, while the source code handles both IPv4 dotted-quad and colon-separated byte formats. It omits important secondary details such as the IPv4 prefix parsing branch, checks for buffer length, and error conditions for invalid formats or byte ranges. Coverage of the core is partial due to the domain mislabeling and lack of IP handling in the description.",
                "The summary claims the function parses and validates a MAC address string, but the code handles both IPv4 addresses (when '.' is present) and colon-delimited byte sequences, not strictly MAC addresses. This is a factual inaccuracy about the primary purpose, misrepresenting the domain semantics and core behavior. Although the rest of the description\u2014storing bytes in the buffer and returning count or error\u2014is correct, the core misclassification of address type is a severe FATAL error on the primary purpose, making the description unreliable."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Parses a string-formatted link-layer address into bytes, validating each segment and reporting an error if the format or values are invalid.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function parses a string-formatted link-layer address into bytes, validates each segment, and reports an error for invalid formats or values. This aligns with the code's handling of both dotted decimal (IPv4-like) and colon-separated hex formats, including range checks and error reporting. It accurately reflects the semantics without introducing incorrect information, covering more than 80% of the actual behavior.",
                "The summary accurately conveys that the function parses a string-formatted link-layer address into bytes and validates segments, matching the core purpose of converting textual link-layer addresses into a byte array with error reporting on invalid inputs. However, it omits key secondary behaviors from the source code such as handling IPv4 notation by detecting dots, using specific parsing logic for hex-separated bytes, enforcing minimum length for IPv4, and returning specific lengths. These omissions limit coverage of behavior-critical details.",
                "The summary correctly states the function parses a string-formatted link-layer address into bytes, validates each segment, and reports errors on invalid input, which matches the code's handling of both dot-separated IPv4-style and colon-separated hex formats. The claim is accurate, but it is broad and generic with low informational detail, offering no specifics about the alternate IPv4 parsing path, length constraints, or return values. No inaccuracies or noise are present, yielding low net benefit from primarily SAFE claims."
            ]
        }
    }
}
{
    "source_code": "\nstatic void __activate_page(struct page *page, struct lruvec *lruvec,\n\t\t\t    void *arg)\n{\n\tif (PageLRU(page) && !PageActive(page) && !PageUnevictable(page)) {\n\t\tint file = page_is_file_cache(page);\n\t\tint lru = page_lru_base_type(page);\n\n\t\tdel_page_from_lru_list(page, lruvec, lru);\n\t\tSetPageActive(page);\n\t\tlru += LRU_ACTIVE;\n\t\tadd_page_to_lru_list(page, lruvec, lru);\n\n\t\t__count_vm_event(PGACTIVATE);\n\t\tupdate_page_reclaim_stat(lruvec, file, 1);\n\t}\n}",
    "comment": "Activates a page by removing it from the LRU list and updating its status if it is inactive and eligible for activation.",
    "prorec_sum": "Links a memory group to a zone, updates related list pointers and counters, and marks the object as inserted with specific flags.",
    "filter_prorec_sum": "Re-links a memory cgroup\u2019s zone statistics structures, updates relevant counters, and marks the zone as active based on specific status flags.",
    "prorec_aug_sum": "Processes a flagged object\u2019s linked-list reassignment, updates related counters, and marks it active within a resource management structure.",
    "filter_prorec_aug_sum": "Transitions an object from one linked list to another, updates related counters, and marks it with a status flag for subsequent processing.",
    "work_score": {
        "prorec_aug": {
            "summary": "Processes a flagged object\u2019s linked-list reassignment, updates related counters, and marks it active within a resource management structure.",
            "score": [
                0.8,
                0.4,
                0.5
            ],
            "reason": [
                "The summary captures that the function marks an object active, reassigns it in a list, and updates counters, which aligns with the code that changes page state, moves it between LRU lists, and increments VM events. However, the description is abstract and lacks specific domain terms like 'page', 'LRU', and the exact activation conditions, reducing precision. Despite this, the claims made are broadly accurate about the function\u2019s behavior.",
                "The summary generically describes list reassignment, counter updates, and marking active, which loosely matches the function\u2019s behavior of moving a page between LRU lists, setting it active, and updating stats. However, it fails to accurately capture the core purpose with domain-specific wording (page activation in kernel LRU structures) and omits critical conditions such as checks for PageLRU, PageActive, and PageUnevictable, as well as the distinction between file and anonymous pages. The coverage of secondary details is minimal, with no mention of specific events or reclaim statistics beyond vague phrasing.",
                "The summary contains mostly generic statements about object re-linking, marking active, and updating counters, which loosely match the code\u2019s behavior but lack domain-specific accuracy about memory pages and LRU lists. There are no outright false claims (no FATAL), but the description is vague, abstracting away critical details like page cache type and unevictable checks. The gain is low as it offers minimal insight beyond generic resource management concepts, and noise is noticeable due to absence of precise terminology tied to the function\u2019s purpose."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Transitions an object from one linked list to another, updates related counters, and marks it with a status flag for subsequent processing.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary generically describes moving an object between linked lists, updating counters, and marking it with a status flag, which aligns loosely with the function\u2019s actual behavior of moving a page between LRU lists, setting it active, and updating stats. However, it omits key semantic conditions (PageLRU check, not active, not unevictable) and specific memory-management context, making the claims too generic. While broadly correct, the lack of specificity reduces precision, resulting in mixed reliability.",
                "The summary correctly notes a transition between lists, counter updates, and a status flag, which aligns generally with the code's behavior. However, it fails to cover the core primary purpose of activating a page in the LRU list only when certain conditions are met, including checks for PageLRU, PageActive, and PageUnevictable, and the distinction between file and non-file cache pages. The wording is vague, missing key domain specifics such as LRU list types, active status setting, and page reclaim statistics, resulting in incomplete coverage.",
                "The summary captures the broad idea of moving an item between lists, setting a flag, and updating counters, which loosely matches the code\u2019s actions. However, details like the LRU-specific page handling, the exact activation logic, and conditional checks are omitted, making the description generic and low-info. There are no outright contradictions, and noise is moderate but the gain is limited due to lack of specificity on core domain semantics."
            ]
        }
    }
}
{
    "source_code": "\nstatic void unix_sock_destructor(struct sock *sk)\n{\n\tstruct unix_sock *u = unix_sk(sk);\n\n\tskb_queue_purge(&sk->sk_receive_queue);\n\n\tWARN_ON(atomic_read(&sk->sk_wmem_alloc));\n\tWARN_ON(!sk_unhashed(sk));\n\tWARN_ON(sk->sk_socket);\n\tif (!sock_flag(sk, SOCK_DEAD)) {\n\t\tprintk(KERN_INFO \"Attempt to release alive unix socket: %p\\n\", sk);\n\t\treturn;\n\t}\n\n\tif (u->addr)\n\t\tunix_release_addr(u->addr);\n\n\tatomic_long_dec(&unix_nr_socks);\n\tlocal_bh_disable();\n\tsock_prot_inuse_add(sock_net(sk), sk->sk_prot, -1);\n\tlocal_bh_enable();\n#ifdef UNIX_REFCNT_DEBUG\n\tprintk(KERN_DEBUG \"UNIX %p is destroyed, %ld are still alive.\\n\", sk,\n\t\tatomic_long_read(&unix_nr_socks));\n#endif\n}",
    "comment": "Destroys a Unix socket, purging its receive queue and decrementing the count of active sockets if the socket is marked as dead.",
    "prorec_sum": "Closes an AF_UNIX socket, logging state details, releasing associated resources, and decrementing reference counters before final cleanup operations.",
    "filter_prorec_sum": "Closes a UNIX domain socket, logging state checks, releasing associated resources, and decrementing reference counters before final cleanup.",
    "prorec_aug_sum": "Finalizes and logs UNIX socket state, updates reference counters, releases associated resources, and performs connection teardown if specific flags and conditions are met.",
    "filter_prorec_aug_sum": "Logs AF_UNIX socket state transitions, updates reference counters, and releases associated resources during socket teardown or cleanup.",
    "work_score": {
        "prorec_aug": {
            "summary": "Finalizes and logs UNIX socket state, updates reference counters, releases associated resources, and performs connection teardown if specific flags and conditions are met.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly notes finalizing a UNIX socket, logging state, updating reference counters, and releasing resources, which align with actions in the code such as decrementing unix_nr_socks and releasing u->addr. However, it introduces an inaccurate claim about performing connection teardown based on flags and conditions\u2014the code only exits early for alive sockets and does not perform a teardown sequence beyond resource release. This reduces overall precision, with roughly 75% of claims being accurate.",
                "The summary contains some accurate elements, such as releasing resources, updating reference counters, and logging, which match parts of the code. However, it fails to explicitly cover the core primary purpose: destructing a UNIX socket by purging its receive queue, ensuring it is marked dead, releasing its bound address, and decrementing global counters. The mention of 'connection teardown' is inaccurate since the code does not handle connection shutdown; rather, it manages cleanup and checks for active sockets. Coverage of branch handling and specific safety checks (WARN_ON, SOCK_DEAD) is missing.",
                "The summary correctly notes releasing resources, updating counters, and logging, which align with the code. However, it inaccurately states that the function performs 'connection teardown,' which is not evident in the source; the code purges queues, releases addresses, and decrements counters but does not close or tear down connections. This is a mild inaccuracy (NOISE), not a severe FATAL, and most claims are generic rather than highly specific, providing low informational gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Logs AF_UNIX socket state transitions, updates reference counters, and releases associated resources during socket teardown or cleanup.",
            "score": [
                0.9,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly notes that the function releases resources and updates reference counters, which matches the code's behavior of purging the receive queue, releasing the address, decrementing counters, and updating protocol usage counts. It also mentions logging socket state, which is partially accurate since the code logs specific destruction-related events, though not general state transitions. Overall, most claims align with the source code semantics, with only slight overgeneralization on logging specifics.",
                "The summary captures that the function logs certain socket information, updates counters, and releases resources, which aligns with the code's logging, counter decrement, and address release. However, it fails to specifically convey the core purpose: destructing a unix_sock including purging the receive queue, performing sanity checks, and ensuring proper state before cleanup. The description about 'state transitions' is somewhat vague and doesn't match the detailed precondition checks, thus only partially covering the core with limited secondary details.",
                "The summary correctly notes that the function releases associated resources and updates reference counters, which matches the code's behavior of purging queues, releasing addresses, and decrementing counters. However, it inaccurately claims to log AF_UNIX socket state transitions; the code only logs a specific warning when attempting to release a live socket and optional destruction info under a debug flag, not general state transitions. This is a semantic mismatch, but as it does not contradict the primary purpose of socket cleanup, it is classified as NOISE rather than a fatal error. Noise slightly outweighs precise details, and the accurate claims are relatively generic."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\n_nullstream_ctl (struct _mu_stream *str, int code, int opcode, void *arg)\n{\n  struct _mu_nullstream *np = (struct _mu_nullstream *)str;\n\n  if (code != MU_IOCTL_NULLSTREAM)\n    /* Only this code is supported */\n    return ENOSYS;\n  switch (opcode)\n    {\n    case MU_IOCTL_NULLSTREAM_SET_PATTERN:\n      if (!arg)\n\t_nullstream_free_pattern (np);\n      else\n\t{\n\t  struct mu_nullstream_pattern *pat = arg;\n\t  char *p;\n\t  \n\t  p = malloc (pat->size);\n\t  if (!p)\n\t    return ENOMEM;\n\t  memcpy (p, pat->pattern, pat->size);\n\t  _nullstream_free_pattern (np);\n\t  np->pattern = p;\n\t  np->patsize = pat->size;\n\t}\n      break;\n\n    case MU_IOCTL_NULLSTREAM_SET_PATCLASS:\n      if (!arg)\n\treturn EINVAL;\n      else\n\t{\n\t  char buf[256];\n\t  int cnt = 0, i;\n\t  int class = *(int*)arg;\n\t  char *p;\n\t  \n\t  for (i = 0; i < 256; i++)\n\t    {\n\t      if (mu_c_is_class (i, class))\n\t\tbuf[cnt++] = i;\n\t    }\n\n\t  p = malloc (cnt);\n\t  if (!p)\n\t    return ENOMEM;\n\t  memcpy (p, buf, cnt);\n\t  _nullstream_free_pattern (np);\n\t  np->pattern = p;\n\t  np->patsize = cnt;\n\t}\n      break;\n\t  \n    case MU_IOCTL_NULLSTREAM_SETSIZE:\n      if (!arg)\n\treturn EINVAL;\n      else\n\treturn _nullstream_truncate (str, *(mu_off_t*)arg);\n      break;\n\n    case MU_IOCTL_NULLSTREAM_CLRSIZE:\n      np->mode &= ~MU_NULLSTREAM_SIZE;\n      np->base.size = NULL;\n      break;\n      \n    default:\n      return ENOSYS;\n    }\n  return 0;\n}",
    "comment": "Handles control operations for a nullstream, including setting patterns, pattern classes, and managing size-related functionalities.",
    "prorec_sum": "Configures a path object\u2019s internal byte list or attributes based on mode, allocating and copying data, clearing flags, or delegating to helper functions.",
    "filter_prorec_sum": "Configures a path object\u2019s internal byte list or size settings based on mode, allocating and copying data or clearing fields as instructed.",
    "prorec_aug_sum": "Configures a data structure\u2019s byte list or related parameters based on mode, allocating and copying memory as needed, and resetting fields when required.",
    "filter_prorec_aug_sum": "Configures a data structure\u2019s byte filter or content buffer based on mode, allocating and copying data accordingly, and resets related state fields.",
    "work_score": {
        "prorec_aug": {
            "summary": "Configures a data structure\u2019s byte list or related parameters based on mode, allocating and copying memory as needed, and resetting fields when required.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is vague and omits many specific control codes and behaviors in the source, such as handling MU_IOCTL_NULLSTREAM_SET_PATTERN, MU_IOCTL_NULLSTREAM_SET_PATCLASS, MU_IOCTL_NULLSTREAM_SETSIZE, and MU_IOCTL_NULLSTREAM_CLRSIZE, as well as the error handling for unsupported codes or null arguments. While it generically captures that memory is allocated, copied, and fields reset, it lacks the precise, domain-specific details evident in the function, making most claims generic and low-info rather than highly accurate representations of the function's semantics.",
                "The summary offers a vague description of configuring a data structure and memory operations but fails to accurately identify the core domain purpose of handling nullstream control codes (MU_IOCTL_NULLSTREAM_*). It omits the specificity of responding to different opcodes for setting patterns, pattern classes, truncating size, and clearing size, as well as the associated error handling. While memory allocation and field resetting are mentioned, these are generic and do not capture the unique semantics or primary intent of the function.",
                "The summary is overly vague and does not accurately capture the function\u2019s primary purpose or specific IOCTL command handling. It fails to mention that the function specifically responds to MU_IOCTL_NULLSTREAM commands with distinct opcodes for setting patterns, pattern classes, size, or clearing size, and how it returns specific error codes for unsupported codes or invalid arguments. While it generically references memory allocation and resetting fields, these are generic SAFE claims and offer low informational value. The lack of precise, domain-specific details means the noise outweighs the gain."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Configures a data structure\u2019s byte filter or content buffer based on mode, allocating and copying data accordingly, and resets related state fields.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is overly generic and fails to capture specific, verifiable behaviors from the source code. Key operations such as handling different ioctl opcodes, setting patterns from either provided data or character classes, truncating stream size, clearing size flags, and returning specific error codes for unsupported operations are omitted. The claim about configuring a byte filter or content buffer is loosely related but lacks precise alignment with the detailed mode-specific logic in the function, resulting in a low proportion of accurate claims.",
                "The summary vaguely describes configuring a data structure with a byte filter or buffer, but it does not mention the function's core domain purpose of handling specific MU_IOCTL_NULLSTREAM control operations. It omits key details such as supported opcodes for setting a pattern from supplied data, generating a pattern from a character class, adjusting or clearing stream size, and handling errors like ENOSYS, ENOMEM, and EINVAL. The description lacks specificity tied to the source code semantics, providing only generic behavior that could apply to many unrelated functions.",
                "The summary is overly generic and does not accurately capture the specific semantics of the source code. It omits key details such as handling different opcodes (e.g., setting a pattern from a provided structure, generating a pattern from character classes, truncating size, clearing size), as well as the explicit error returns for unsupported codes or null arguments. While mentioning allocation and copying is partially accurate, the use of vague terms like \u2018mode\u2019 and \u2018byte filter\u2019 does not align precisely with the function\u2019s domain behavior. This results in predominantly noise with very low informational gain and no fatal contradiction."
            ]
        }
    }
}
{
    "source_code": "\nstatic int des_ede_cfb64_cipher(EVP_CIPHER_CTX *ctx, unsigned char *out,\n\t\t\t      const unsigned char *in, size_t inl)\n{\n\twhile (inl>=EVP_MAXCHUNK)\n\t\t{\n\t\tDES_ede3_cfb64_encrypt(in, out, (long)EVP_MAXCHUNK, \n\t\t\t       &data(ctx)->ks1, &data(ctx)->ks2, &data(ctx)->ks3,\n\t\t\t       (DES_cblock *)ctx->iv, &ctx->num, ctx->encrypt);\n\t\tinl-=EVP_MAXCHUNK;\n\t\tin +=EVP_MAXCHUNK;\n\t\tout+=EVP_MAXCHUNK;\n\t\t}\n\tif (inl)\n\t\tDES_ede3_cfb64_encrypt(in, out, (long)inl,\n\t\t\t       &data(ctx)->ks1, &data(ctx)->ks2, &data(ctx)->ks3,\n                               (DES_cblock *)ctx->iv, &ctx->num, ctx->encrypt);\n\treturn 1;\n}",
    "comment": "Encrypts input data using Triple DES in CFB64 mode, processing it in chunks of EVP_MAXCHUNK size.",
    "prorec_sum": "Encrypts a large input buffer using 3DES in CFB64 mode, processing huge chunks iteratively and handling any remaining bytes in a final call.",
    "filter_prorec_sum": "Encrypts data in large chunks using triple DES in CFB64 mode, handling oversized input by processing sequential 2^62\u2011byte segments before the remainder.",
    "prorec_aug_sum": "Encrypts data of arbitrary length using 3DES in CFB64 mode, processing extremely large inputs in 2^62\u2011byte chunks before handling any remaining bytes.",
    "filter_prorec_aug_sum": "Encrypts data using 3DES in CFB64 mode, processing extremely large buffers in 2^62\u2011byte chunks before handling any remaining bytes.",
    "work_score": {
        "prorec_aug": {
            "summary": "Encrypts data of arbitrary length using 3DES in CFB64 mode, processing extremely large inputs in 2^62\u2011byte chunks before handling any remaining bytes.",
            "score": [
                0.5,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly identifies that the function performs encryption using 3DES in CFB64 mode and can process data of arbitrary length, aligning with the code's use of DES_ede3_cfb64_encrypt in a loop for chunks and remaining bytes. However, it inaccurately claims that the chunk size is 2^62 bytes, whereas the code uses EVP_MAXCHUNK, which is much smaller and not specified as 2^62 bytes. This incorrect chunk size detail reduces accuracy, making roughly half of the summary accurate.",
                "The summary correctly states that the function encrypts data using 3DES in CFB64 mode and handles arbitrary length input, which matches the core domain purpose observed in the code. It also notes chunked processing for large inputs, though the code uses EVP_MAXCHUNK (about 2^31) rather than 2^62 bytes, making that part inaccurate. The rest of the description omits other details such as the use of multiple key schedules, updating IV and num state, and returning a fixed success value. Core purpose coverage is strong but secondary coverage is limited and contains a notable inaccuracy in chunk size.",
                "The summary correctly identifies that the function uses 3DES in CFB64 mode and processes data in large chunks before handling remaining bytes, which aligns with the code. However, it inaccurately states the chunk size as 2^62 bytes, while the code clearly uses EVP_MAXCHUNK as the fixed chunk size (not defined as 2^62 bytes here). This is a severe factual error affecting the description of key I/O behavior, making it a FATAL error on a core aspect."
            ]
        },
        "filter_prorec_aug": {
            "summary": "Encrypts data using 3DES in CFB64 mode, processing extremely large buffers in 2^62\u2011byte chunks before handling any remaining bytes.",
            "score": [
                0.3,
                0.6,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function encrypts data using 3DES in CFB64 mode and handles remaining bytes after processing full chunks, which aligns with the code. However, it inaccurately describes the chunk size as 2^62 bytes, while the code uses EVP_MAXCHUNK (a much smaller value), making this a major semantic error. This results in less than half of the claims being accurate.",
                "The summary correctly identifies the core purpose as encrypting data using 3DES in CFB64 mode, matching the function's primary operation from the source code. It also notes the chunked processing of large buffers and the handling of remaining bytes, which reflects the loop over EVP_MAXCHUNK and the final partial encryption. However, it inaccurately specifies '2^62\u2011byte chunks' instead of the constant EVP_MAXCHUNK used in the code, and it omits mention of keys, IV, and the encryption/decryption direction flag, leaving secondary coverage incomplete.",
                "The summary correctly identifies that the function encrypts data using 3DES in CFB64 mode, which matches the calls to DES_ede3_cfb64_encrypt with ks1, ks2, ks3 and ctx->encrypt. However, it inaccurately claims that it processes extremely large buffers in 2^62\u2011byte chunks; the source code processes data in EVP_MAXCHUNK units, not 2^62 bytes, making this a severe factual error about the core data processing behavior. This constitutes a FATAL error targeting the primary purpose, greatly reducing trust in the summary despite the accurate encryption mode detail."
            ]
        }
    }
}
