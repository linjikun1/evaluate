{
    "source_code": "\nstatic void *\nxpalloc (void *pa, ptrdiff_t *nitems, ptrdiff_t nitems_incr_min,\n\t ptrdiff_t nitems_max, ptrdiff_t item_size)\n{\n  ptrdiff_t n0 = *nitems;\n\n  /* The approximate size to use for initial small allocation\n     requests.  This is the largest \"small\" request for the GNU C\n     library malloc.  */\n  enum { DEFAULT_MXFAST = 64 * sizeof (size_t) / 4 };\n\n  /* If the array is tiny, grow it to about (but no greater than)\n     DEFAULT_MXFAST bytes.  Otherwise, grow it by about 50%.\n     Adjust the growth according to three constraints: NITEMS_INCR_MIN,\n     NITEMS_MAX, and what the C language can represent safely.  */\n\n  ptrdiff_t n, nbytes;\n  if (INT_ADD_WRAPV (n0, n0 >> 1, &n))\n    n = PTRDIFF_MAX;\n  if (0 <= nitems_max && nitems_max < n)\n    n = nitems_max;\n\n  ptrdiff_t adjusted_nbytes\n    = ((INT_MULTIPLY_WRAPV (n, item_size, &nbytes) || SIZE_MAX < nbytes)\n       ? MIN (PTRDIFF_MAX, SIZE_MAX)\n       : nbytes < DEFAULT_MXFAST ? DEFAULT_MXFAST : 0);\n  if (adjusted_nbytes)\n    {\n      n = adjusted_nbytes / item_size;\n      nbytes = adjusted_nbytes - adjusted_nbytes % item_size;\n    }\n\n  if (! pa)\n    *nitems = 0;\n  if (n - n0 < nitems_incr_min\n      && (INT_ADD_WRAPV (n0, nitems_incr_min, &n)\n\t  || (0 <= nitems_max && nitems_max < n)\n\t  || INT_MULTIPLY_WRAPV (n, item_size, &nbytes)))\n    xalloc_die ();\n  pa = xrealloc (pa, nbytes);\n  *nitems = n;\n  return pa;\n}",
    "comment": "Allocates or reallocates memory for an array based on its current size, growth constraints, and item size, ensuring safe memory usage.",
    "prorec_sum": "Resizes a buffer\u2019s allocation size by growing it safely within limits, preventing integer overflow, and ensuring a minimum capacity before proceeding with further operations.",
    "filter_prorec_sum": "Resizes a memory buffer by growing its allocation size with overflow and limit checks, then allocates or adjusts it accordingly.",
    "prorec_aug_sum": "Resizes a memory buffer by increasing its element count with overflow and maximum size checks, then allocates or reallocates storage accordingly.",
    "filter_prorec_aug_sum": "Resizes a memory buffer, enforcing overflow checks and alignment, and invokes allocation routines when capacity needs to increase beyond the current size.",
    "work_score": {
        "prorec": {
            "summary": "Resizes a buffer\u2019s allocation size by growing it safely within limits, preventing integer overflow, and ensuring a minimum capacity before proceeding with further operations.",
            "score": [
                1.0,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly describes that the function resizes a buffer's allocation size, enforces growth limits, prevents integer overflow, and ensures a minimum capacity before further operations. These claims align with the source code\u2019s logic, which checks for integer overflow, applies minimum increments, and enforces maximum growth constraints. All claims target the code\u2019s semantics accurately, with no inaccuracies detected.",
                "The summary correctly identifies that the function grows an existing allocation with safety checks against integer overflow and enforces minimum capacity constraints, which matches the core purpose of safely resizing an array buffer within defined limits. However, it omits several important secondary details from the source code, such as the specific growth strategy (50% increase or DEFAULT_MXFAST threshold for small allocations), handling of NULL input pointers, maximum items constraint, and the use of `xalloc_die` for allocation failures. This results in adequate core coverage but weak coverage of critical secondary semantics.",
                "The summary accurately identifies that the function resizes an allocation, applies safety checks to prevent integer overflow, and respects a minimum capacity constraint. These are core behaviors present in the source code. However, it omits several specific constraints, such as growth strategy for small vs. large arrays, enforcement of maximum capacity, and the use of DEFAULT_MXFAST thresholds. The missing details reduce the completeness but do not introduce inaccuracies, making this low-noise and moderately informative."
            ]
        },
        "filter_prorec": {
            "summary": "Resizes a memory buffer by growing its allocation size with overflow and limit checks, then allocates or adjusts it accordingly.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function resizes a memory buffer and applies overflow and limit checks before allocation, which matches the code's use of INT_ADD_WRAPV/INT_MULTIPLY_WRAPV and max constraints. However, it omits several specific semantics such as the initial size growth logic (DEFAULT_MXFAST for small arrays, 50% for larger), handling of nitems_incr_min, and resetting *nitems when pa is NULL. Despite these omissions, the claims made are accurate and relevant to the source code, with no contradictions.",
                "The summary correctly identifies the function\u2019s core purpose of resizing a memory buffer with overflow and limit checks, which matches the code\u2019s behavior of growing allocation size based on constraints and using xrealloc. However, it is vague and omits several domain-specific details present in the source, such as the DEFAULT_MXFAST threshold, growth by approximately 50% for larger arrays, adjustment based on minimum increments and maximum limits, handling of NULL pointers, and error termination via xalloc_die. Secondary coverage of critical branches and constants is poor, limiting completeness.",
                "The summary captures the primary purpose of the function, which is to resize a memory buffer while performing overflow and limit checks before reallocating. This aligns with the code\u2019s behavior of calculating a new size, checking constraints, and calling xrealloc. However, the description is generic and omits specific logic such as initial small allocation adjustment to DEFAULT_MXFAST, minimum increment enforcement, and handling of allocation failures via xalloc_die. No FATAL inaccuracies are present, but the lack of detail limits the gain."
            ]
        }
    }
}
{
    "source_code": "\nint\nmu_get_host_name (char **host)\n{\n  char *hostname = NULL;\n  size_t size = 0;\n  char *p;\n\n  while (1)\n    {\n      if (size == 0)\n\t{\n\t  size = MAXHOSTNAMELEN;\n\t  p = malloc (size);\n\t}\n      else\n\t{\n\t  size_t ns = size * 2;\n\t  if (ns < size)\n\t    {\n\t      free (hostname);\n\t      return ENOMEM;\n\t    }\n\t  size = ns;\n\t  p = realloc (hostname, size);\n\t}\n      if (!p)\n\t{\n\t  free (hostname);\n\t  return ENOMEM;\n\t}\n      hostname = p;\n      hostname[size - 1] = 0;\n      if (gethostname (hostname, size - 1) == 0)\n\t{\n\t  if (!hostname[size - 1])\n\t    break;\n\t}\n      else if (errno != 0 && errno != ENAMETOOLONG && errno != EINVAL\n\t       && errno != ENOMEM)\n\t{\n\t  int rc = errno;\n\t  free (hostname);\n\t  return rc;\n\t}\n    }\n\n  /* Try to return fully qualified host name */\n  if (!strchr (hostname, '.'))\n    {\n      struct hostent *hp = gethostbyname (hostname);\n      if (hp)\n\t{\n\t  size_t len = strlen (hp->h_name);\n\t  if (size < len + 1)\n\t    {\n\t      p = realloc (hostname, len + 1);\n\t      if (!p)\n\t\t{\n\t\t  free (hostname);\n\t\t  return ENOMEM;\n\t\t}\n\t      hostname = p;\n\t    }\n\t  strcpy (hostname, hp->h_name);\n\t}\n    }\n  \n  *host = hostname;\n  return 0;\n}",
    "comment": "Retrieves the host name of the machine, expanding the buffer as needed, and attempts to return the fully qualified host name if not present.",
    "prorec_sum": "Retrieves the system's host name, expanding the buffer as needed and resolving the fully qualified name if no domain is present.",
    "filter_prorec_sum": "Retrieves the local host name, expanding buffer if needed, and resolves it to a fully qualified name when missing a domain.",
    "prorec_aug_sum": "Retrieves the local host name, expanding buffer as needed, and resolves it to a fully qualified domain name if missing a dot.",
    "filter_prorec_aug_sum": "Retrieves the local host name, expanding buffer as needed, and resolves it to a fully qualified name if no domain is present.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves the system's host name, expanding the buffer as needed and resolving the fully qualified name if no domain is present.",
            "score": [
                1.0,
                0.8,
                0.8
            ],
            "reason": [
                "The summary contains two key claims: retrieving the system's host name and expanding the buffer as needed, and resolving the fully qualified name if no domain is present. Both are accurate according to the source code, which uses gethostname with dynamic buffer resizing and calls gethostbyname when no '.' is found in the hostname. There are no inaccuracies or irrelevant statements.",
                "The summary accurately states that the function retrieves the system's host name, handles buffer expansion, and attempts to resolve it to a fully qualified domain name if no domain is present, which matches the core purpose and key secondary details from the source code. It omits mention of specific error handling scenarios, memory allocation failures, and the return of error codes, so while coverage is good, it is not complete.",
                "The summary correctly describes the primary purpose of retrieving the system's host name, notes buffer expansion, and adds detail on resolving the fully qualified name when no domain is present. All claims align with the source code behavior with no inaccuracies or irrelevant noise. However, the gain is moderate, as the description is accurate but concise and lacks further specifics such as error handling paths or the iterative resizing logic conditions."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves the local host name, expanding buffer if needed, and resolves it to a fully qualified name when missing a domain.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary contains two atomic claims: (1) the function retrieves the local host name, and (2) it expands the buffer as needed and resolves to a fully qualified name if no domain is present. Both claims match the source code\u2019s behavior: the code uses gethostname with dynamic buffer resizing until it fits, and later uses gethostbyname to add the domain if missing. There are no inaccuracies or irrelevant statements, indicating high precision in describing the function\u2019s semantics.",
                "The summary accurately captures the core purpose of obtaining the local host name and expanding the buffer as needed, as well as resolving it to a fully qualified name when the domain is missing, which matches the source code's main functionality. However, it omits several important secondary details, such as handling specific errors like ENOMEM and other errno values, the loop retry logic for gethostname, and memory allocation strategies. This results in a good representation of the core but incomplete coverage of secondary behavior-critical semantics.",
                "The summary contains two specific claims: (1) it retrieves the local host name, and (2) it resolves to a fully qualified name when missing a domain. Both are accurate according to the source code, which allocates and expands a buffer as needed, uses gethostname, and optionally calls gethostbyname to add a domain. The buffer expansion detail is correctly included. There is no evidence of contradictory or irrelevant content, noise is minimal, and the claims align with the core purpose and I/O of the function, providing clear, high-value insights."
            ]
        }
    }
}
{
    "source_code": "static int do_sysinfo(struct sysinfo *info)\n{\n\tunsigned long mem_total, sav_total;\n\tunsigned int mem_unit, bitcount;\n\tstruct timespec tp;\n\n\tmemset(info, 0, sizeof(struct sysinfo));\n\n\tktime_get_ts(&tp);\n\tmonotonic_to_bootbased(&tp);\n\tinfo->uptime = tp.tv_sec + (tp.tv_nsec ? 1 : 0);\n\n\tget_avenrun(info->loads, 0, SI_LOAD_SHIFT - FSHIFT);\n\n\tinfo->procs = nr_threads;\n\n\tsi_meminfo(info);\n\tsi_swapinfo(info);\n\n\t/*\n\t * If the sum of all the available memory (i.e. ram + swap)\n\t * is less than can be stored in a 32 bit unsigned long then\n\t * we can be binary compatible with 2.2.x kernels.  If not,\n\t * well, in that case 2.2.x was broken anyways...\n\t *\n\t *  -Erik Andersen <andersee@debian.org>\n\t */\n\n\tmem_total = info->totalram + info->totalswap;\n\tif (mem_total < info->totalram || mem_total < info->totalswap)\n\t\tgoto out;\n\tbitcount = 0;\n\tmem_unit = info->mem_unit;\n\twhile (mem_unit > 1) {\n\t\tbitcount++;\n\t\tmem_unit >>= 1;\n\t\tsav_total = mem_total;\n\t\tmem_total <<= 1;\n\t\tif (mem_total < sav_total)\n\t\t\tgoto out;\n\t}\n\n\t/*\n\t * If mem_total did not overflow, multiply all memory values by\n\t * info->mem_unit and set it to 1.  This leaves things compatible\n\t * with 2.2.x, and also retains compatibility with earlier 2.4.x\n\t * kernels...\n\t */\n\n\tinfo->mem_unit = 1;\n\tinfo->totalram <<= bitcount;\n\tinfo->freeram <<= bitcount;\n\tinfo->sharedram <<= bitcount;\n\tinfo->bufferram <<= bitcount;\n\tinfo->totalswap <<= bitcount;\n\tinfo->freeswap <<= bitcount;\n\tinfo->totalhigh <<= bitcount;\n\tinfo->freehigh <<= bitcount;\n\nout:\n\treturn 0;\n}",
    "comment": "Populates the `sysinfo` structure with system uptime, load averages, process count, and adjusted memory and swap information, ensuring compatibility with older kernels.",
    "prorec_sum": "Initializes a 0x70-byte structure, populates fields via helper routines, and scales multiple size-related members based on calculated capacity thresholds.",
    "filter_prorec_sum": "Initializes a 0x70-byte structure with computed size fields and scales multiple capacity values based on aggregate limits before finalizing setup.",
    "prorec_aug_sum": "Initializes and scales multiple 64\u2011bit timing or counter fields in a data structure based on aggregated values and a scaling factor constraint.",
    "filter_prorec_aug_sum": "Initializes a 0x70-byte structure with timing and size parameters, then scales multiple fields to align memory or resource allocation thresholds.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a 0x70-byte structure, populates fields via helper routines, and scales multiple size-related members based on calculated capacity thresholds.",
            "score": [
                0.7,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly notes that the function zero-initializes a struct and populates its fields using helper routines, and that it scales several size-related members based on computed thresholds, which matches the code\u2019s use of memset, si_meminfo, si_swapinfo, and bit-shifting of memory-related fields. However, the claim of initializing a 0x70-byte structure is inaccurate because the struct size is not specified or implied in the source code, reducing overall accuracy.",
                "The summary accurately notes that the function initializes a structure and fills fields using helper routines, as well as scaling size-related members, which matches the code\u2019s initialization of sysinfo, population via ktime_get_ts, get_avenrun, si_meminfo, si_swapinfo, and subsequent bit-shift scaling. However, it omits the core purpose of reporting system statistics such as uptime, load averages, process count, and memory/swap info, and does not mention important semantics like conversion to boot-based time or overflow checks, resulting in incomplete coverage.",
                "The summary correctly notes that the function initializes a structure and fills fields using helper routines, as well as scales memory-related members based on capacity calculations, which matches the code's calls to memset, helper functions, and bit-shift scaling of memory fields. However, it inaccurately specifies the exact structure size as 0x70 bytes, which is not verifiable from the source snippet and is a low-value generic detail. There are no severe contradictory claims affecting the core purpose, but the claim about structure size is noise and reduces specificity, with the rest of the summary providing only moderate insight."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a 0x70-byte structure with computed size fields and scales multiple capacity values based on aggregate limits before finalizing setup.",
            "score": [
                0.6,
                0.3,
                0.4
            ],
            "reason": [
                "The summary correctly states that the function initializes a structure and scales capacity values based on certain limits, which aligns with the code's memset, memory calculations, and scaling logic. However, the claim about a '0x70-byte structure' is inaccurate because the code initializes the structure based on sizeof(struct sysinfo), not a fixed 0x70 size. This reduces precision but the majority of the description reflects actual behavior from the source code.",
                "The summary correctly notes initialization of a structure and scaling of capacity values, which aligns with the code\u2019s memset and bit-shift operations. However, it fails to clearly cover the core purpose of gathering and populating system information such as uptime, load averages, process count, and memory/swap stats, as seen in the calls to ktime_get_ts, get_avenrun, si_meminfo, and si_swapinfo. Key behavior-critical details like overflow checks, compatibility logic, and the role of mem_unit are omitted, resulting in incomplete coverage.",
                "The summary contains an inaccurate claim about initializing a \"0x70-byte\" structure, which is not derived from the source code as the struct size isn't specified there. It also vaguely describes \"computed size fields\" and \"scales multiple capacity values based on aggregate limits\" without mentioning crucial, specific behaviors present in the code such as uptime setting, load averages, process count, or the mem_unit bit-shift scaling logic. This makes the description low in domain-specific accuracy, with the key inaccuracy being unrelated to the primary purpose but still misleading. Overall, the noise outweighs the accurate content, and the gain is very low."
            ]
        }
    }
}
{
    "source_code": "int drm_markbufs(struct drm_device *dev, void *data,\n\t\t struct drm_file *file_priv)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf_desc *request = data;\n\tint order;\n\tstruct drm_buf_entry *entry;\n\n\tif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\n\t\treturn -EINVAL;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tDRM_DEBUG(\"%d, %d, %d\\n\",\n\t\t  request->size, request->low_mark, request->high_mark);\n\torder = drm_order(request->size);\n\tif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\n\t\treturn -EINVAL;\n\tentry = &dma->bufs[order];\n\n\tif (request->low_mark < 0 || request->low_mark > entry->buf_count)\n\t\treturn -EINVAL;\n\tif (request->high_mark < 0 || request->high_mark > entry->buf_count)\n\t\treturn -EINVAL;\n\n\tentry->freelist.low_mark = request->low_mark;\n\tentry->freelist.high_mark = request->high_mark;\n\n\treturn 0;\n}",
    "comment": "Configures buffer management parameters, including size and free list thresholds, for a Direct Rendering Manager (DRM) device's DMA buffers.",
    "prorec_sum": "Validates DRM buffer parameters and updates buffer metadata entries after confirming alignment, size constraints, and device state readiness.",
    "filter_prorec_sum": "Validates DRM buffer parameters and updates specific buffer state fields after ensuring proper alignment, range limits, and feature enablement.",
    "prorec_aug_sum": "Validates DRM buffer parameters and updates buffer indices in the device structure, returning errors for misaligned sizes or out\u2011of\u2011range values.",
    "filter_prorec_aug_sum": "Validates DRM buffer parameters and updates ring buffer metadata for the given device context, returning errors on invalid sizes or indices.",
    "work_score": {
        "prorec": {
            "summary": "Validates DRM buffer parameters and updates buffer metadata entries after confirming alignment, size constraints, and device state readiness.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly conveys that the function validates DRM buffer parameters and updates buffer metadata, aligning with checks for device DMA capability, size constraints via order bounds, and updating freelist marks. It omits some specific details like exact error conditions and parameter limit checks but does not introduce inaccuracies. Nearly all claims are accurate and relevant to the source code semantics.",
                "The summary correctly notes that the function validates DRM buffer parameters and updates buffer metadata, which matches the core purpose of setting freelist low/high marks in a specific buffer entry after checks. However, it omits key specifics such as the feature check for DRIVER_HAVE_DMA, null dma check, detailed bounds on size/order, and explicit low/high mark range validations. Coverage of the core is present but secondary behavior coverage is thin, with vague wording about constraints and readiness instead of detailed conditions.",
                "The summary correctly identifies that the function validates DRM buffer parameters and updates metadata entries, aligning with the code's checks on device DMA state, buffer size order, and low/high mark constraints. It omits some specifics such as the explicit range checks for buffer counts and the retrieval of the buffer entry by calculated order, but there are no inaccurate or contradictory claims. The claims are broadly accurate but phrased in generic terms, providing low informational gain."
            ]
        },
        "filter_prorec": {
            "summary": "Validates DRM buffer parameters and updates specific buffer state fields after ensuring proper alignment, range limits, and feature enablement.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly captures the core function behavior: it validates buffer parameters (size, low_mark, high_mark), checks feature enablement (DRIVER_HAVE_DMA), and updates specific buffer state fields (freelist marks). However, the mention of 'proper alignment' is not explicitly reflected in the source code; while it calculates an 'order' based on size, no direct alignment check is implemented. Overall, the majority of claims are accurate, with only a minor misstatement about alignment.",
                "The summary correctly captures the core purpose: verifying DRM buffer parameters (size, low/high marks) and updating freelist state after checks for feature availability and valid ranges. It aligns with the source code's validation of DRIVER_HAVE_DMA, presence of dma, order bounds, and low/high mark limits, followed by setting freelist marks. However, it omits more granular details such as the specific order calculation, explicit range constants (DRM_MIN_ORDER/DRM_MAX_ORDER), and separate error conditions, limiting coverage of secondary semantics.",
                "The summary accurately captures the function's primary purpose of validating DRM buffer parameters and updating specific buffer state fields. It correctly notes checks for feature enablement and range limits, aligning with the source code\u2019s validations of DMA capability, size order bounds, and low/high marks. However, the mention of 'proper alignment' is vague and slightly misleading, as the code uses drm_order for size checks rather than explicit memory alignment logic. Despite this minor inaccuracy, there is no severe contradiction, and the claims are mostly precise and relevant, offering moderate informational value."
            ]
        }
    }
}
{
    "source_code": "\nstatic const char* findlocal(lua_State* L, CallInfo* ci, int n, StkId* pos) {\n  const char* name = NULL;\n  StkId base;\n  if (isLua(ci)) {\n    if (n < 0) /* access to vararg values? */\n      return findvararg(ci, -n, pos);\n    else {\n      base = ci->u.l.base;\n      name = luaF_getlocalname(ci_func(ci)->p, n, currentpc(ci));\n    }\n  } else\n    base = ci->func + 1;\n  if (name == NULL) { /* no 'standard' name? */\n    StkId limit = (ci == L->ci) ? L->top : ci->next->func;\n    if (limit - base >= n && n > 0) /* is 'n' inside 'ci' stack? */\n      name = \"(*temporary)\"; /* generic name for any valid slot */\n    else\n      return NULL; /* no name */\n  }\n  *pos = base + (n - 1);\n  return name;\n}",
    "comment": "Retrieves the local variable name from a Lua function's call frame or returns a generic name for temporary slots if no name exists.",
    "prorec_sum": "Retrieves a specific argument or temporary variable from a parser\u2019s stack and returns its descriptive name, storing its memory address in the provided pointer.",
    "filter_prorec_sum": "Retrieves a function argument or temporary value index and returns its label while storing the corresponding memory location pointer.",
    "prorec_aug_sum": "Retrieves a specific argument or temporary value from a data frame and returns its descriptor string while updating the provided pointer.",
    "filter_prorec_aug_sum": "Retrieves a function argument or temporary value reference by index and returns its descriptive label along with its memory location.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves a specific argument or temporary variable from a parser\u2019s stack and returns its descriptive name, storing its memory address in the provided pointer.",
            "score": [
                0.7,
                0.5,
                0.2
            ],
            "reason": [
                "The summary claims that the function retrieves an argument or temporary variable from a parser\u2019s stack, returns its descriptive name, and stores its memory address in a provided pointer. The source code shows it operates on a Lua call stack, determining variable names (or a placeholder for temporary ones) and setting the position pointer. While the concept of retrieving and naming stack variables matches, mentioning a 'parser\u2019s stack' is inaccurate\u2014this is a Lua VM call stack, not a parser. The majority of the claims\u2014retrieving arguments, returning descriptive names, storing positions\u2014are accurate, but the parser reference is a notable inaccuracy.",
                "The summary captures the core purpose of identifying and returning the name of a local variable or temporary in a function's call stack and storing its position, which matches the source code's behavior of finding a local or vararg variable. However, it inaccurately frames the context as a 'parser\u2019s stack' rather than Lua's call stack and omits key secondary details such as handling varargs when n<0, the generic '(*temporary)' naming when no explicit name, and returning NULL in certain conditions. Coverage of error/edge cases and constants is missing, leading to incomplete secondary behavior capture.",
                "The summary contains an inaccurate core claim by describing retrieval from a 'parser\u2019s stack', whereas the code operates on Lua call stack frames via CallInfo and StkId. This misstates the primary purpose and domain context. While it correctly notes that a name is returned and a position pointer updated, the mischaracterization of the stack type directly impacts understanding of the function\u2019s core behavior, making this a severe FATAL error on the primary purpose."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves a function argument or temporary value index and returns its label while storing the corresponding memory location pointer.",
            "score": [
                0.6,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly notes that the function retrieves a value and returns its label, and that it stores the related memory location pointer, which aligns with the code setting *pos and returning a name string. However, it inaccurately generalizes the source code behavior to only 'function arguments or temporary values', omitting other possibilities in the code such as vararg access, and makes the retrieval sound unconditional without the conditional logic present. This limits precision, though the majority of the described behavior remains accurate.",
                "The summary correctly mentions retrieving a value and returning its label while storing a pointer, which matches the code's behavior of returning a local variable name and setting its position. However, it omits the core purpose's specificity: identifying a local or vararg variable name from a CallInfo in Lua, including fallback to a generic name for valid slots. No mention is made of handling varargs, base stack positions, or the conditional logic for name resolution, which are critical behaviors in the source code.",
                "The summary claims the function retrieves a function argument or temporary value index and returns its label while storing the corresponding memory location pointer. While it captures the broad idea of returning a label and storing a pointer, it omits key conditions from the source code, such as handling varargs when n < 0, the distinction between Lua and non-Lua CallInfo, and the fallback to a generic '(*temporary)' label when no standard name is found. These omissions result in oversimplification but no outright contradiction, making the claim mostly safe but low in informational value. Noise from missing important control flows reduces utility."
            ]
        }
    }
}
{
    "source_code": "  \nvoid\nmu_ident_stat (mu_stream_t str)\n{\n  size_t count, i;\n  mu_iterator_t itr;\n  \n  mu_stream_printf (str, \"BEGIN IDENT STAT\\n\");\n\n  mu_assoc_count (nametab, &count);\n  mu_stream_printf (str, \"N=%zu\\n\", count);\n\n  if (count > 0)\n    {\n      int rc = mu_assoc_get_iterator (nametab, &itr);\n      if (rc)\n\tmu_stream_printf (str, \"mu_assoc_get_iterator: %s\\n\",\n\t\t\t  mu_strerror (rc));\n      else\n\t{\n\t  i = 0;\n\t  for (mu_iterator_first (itr); !mu_iterator_is_done (itr);\n\t       mu_iterator_next (itr), i++)\n\t    {\n\t      const char *key;\n\t      struct mu_ident_ref *ref;\n\t      \n\t      mu_iterator_current_kv (itr,\n\t\t\t\t      (const void **)&key, (void **)&ref);  \n\t      mu_stream_printf (str, \"%04zu: %s: %zu\\n\", i, key, ref->count);\n\t    }\n\t}\n      mu_iterator_destroy (&itr);\n    }\n  mu_stream_printf (str, \"END IDENT STAT\\n\");\n}",
    "comment": "Outputs the count and details of identifiers from a name table to a specified stream, including key-value pairs and their associated counts.",
    "prorec_sum": "Outputs association statistics, iterating over key-value pairs to print each entry\u2019s index, key, and value between BEGIN and END IDENT STAT markers.",
    "filter_prorec_sum": "Outputs identification statistics by counting entries in an association, iterating key-value pairs, and printing formatted results to the provided stream.",
    "prorec_aug_sum": "Outputs identification statistics by counting and iterating over entries in an association, printing each key-value pair and summary markers to a provided stream.",
    "filter_prorec_aug_sum": "Outputs identification statistics by counting entries in an association and listing each key with its value to the provided stream.",
    "work_score": {
        "prorec": {
            "summary": "Outputs association statistics, iterating over key-value pairs to print each entry\u2019s index, key, and value between BEGIN and END IDENT STAT markers.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly describes that the function outputs association statistics, iterates over key-value pairs, and prints the index, key, and associated value between BEGIN and END IDENT STAT markers. It aligns with the source code\u2019s use of iteration over nametab entries and mu_stream_printf calls, with no contradictory or irrelevant claims. All claims are accurate and grounded in the function\u2019s behavior.",
                "The summary accurately states that the function outputs association statistics, iterates over key-value pairs, and prints each entry's index and key between BEGIN and END IDENT STAT markers, which matches the core purpose of iterating through nametab entries and printing their count and details. However, it omits important secondary details present in the source code such as printing the total count, handling cases with zero entries, managing iterator creation errors, and including the ref->count in the output. Coverage of core is good, but secondary coverage is limited.",
                "The summary correctly describes the function\u2019s primary purpose of outputting association statistics, including iterating over key-value pairs and printing the index, key, and related value between BEGIN and END IDENT STAT markers. The description matches the source code\u2019s behavior without introducing inaccuracies, but the term \u2018value\u2019 is somewhat generic compared to the actual \u2018ref->count\u2019 printed. The claim is accurate with low informational gain since it omits details such as printing the count of associations and handling possible iterator retrieval errors."
            ]
        },
        "filter_prorec": {
            "summary": "Outputs identification statistics by counting entries in an association, iterating key-value pairs, and printing formatted results to the provided stream.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function counts entries in an association, iterates over key-value pairs, and prints formatted results to a provided stream. These are all specific and verifiable behaviors evident from the code, with no contradictions or irrelevant information. The description omits some minor details like error handling messages, but this does not significantly affect accuracy since the core semantics are correct.",
                "The summary correctly describes the core purpose of the function as outputting identification statistics by counting entries, iterating key-value pairs, and printing results to a stream, which matches the source code's logic. It covers the core domain action (counting from nametab and printing formatted data) but omits secondary details such as printing header/footer markers, handling the empty count case, the iterator acquisition error handling, and destroying the iterator. These omissions reduce completeness of coverage.",
                "The summary accurately reflects the core behavior: it outputs identification statistics by counting entries in `nametab`, iterating over key-value pairs, and printing formatted results to the provided stream. All claims target actual code semantics with no contradictions or irrelevant noise. The description covers the primary purpose and key I/O clearly, though it omits minor details like error handling and specific formatting tokens, resulting in slightly reduced informational depth but still high gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\nnfs3_proc_link(struct inode *inode, struct inode *dir, struct qstr *name)\n{\n\tstruct nfs3_linkargs\targ = {\n\t\t.fromfh\t\t= NFS_FH(inode),\n\t\t.tofh\t\t= NFS_FH(dir),\n\t\t.toname\t\t= name->name,\n\t\t.tolen\t\t= name->len\n\t};\n\tstruct nfs3_linkres\tres;\n\tstruct rpc_message msg = {\n\t\t.rpc_proc\t= &nfs3_procedures[NFS3PROC_LINK],\n\t\t.rpc_argp\t= &arg,\n\t\t.rpc_resp\t= &res,\n\t};\n\tint status = -ENOMEM;\n\n\tdprintk(\"NFS call  link %s\\n\", name->name);\n\tres.fattr = nfs_alloc_fattr();\n\tres.dir_attr = nfs_alloc_fattr();\n\tif (res.fattr == NULL || res.dir_attr == NULL)\n\t\tgoto out;\n\n\tstatus = rpc_call_sync(NFS_CLIENT(inode), &msg, 0);\n\tnfs_post_op_update_inode(dir, res.dir_attr);\n\tnfs_post_op_update_inode(inode, res.fattr);\nout:\n\tnfs_free_fattr(res.dir_attr);\n\tnfs_free_fattr(res.fattr);\n\tdprintk(\"NFS reply link: %d\\n\", status);\n\treturn status;\n}",
    "comment": "Links a source inode to a target directory inode with a specified name using an NFS procedure and updates their attributes.",
    "prorec_sum": "Generates two data structures from input parameters, processes them through helper routines, and returns an operation status code.",
    "filter_prorec_sum": "Constructs two data structures from given parameters, processes them through storage-related operations, and returns a status code indicating success or resource error.",
    "prorec_aug_sum": "Constructs two attribute structures from provided parameters, updates them in the server context, invokes RPC handling, and returns the resulting status code.",
    "filter_prorec_aug_sum": "Prepares two data structures from input parameters, performs an operation on them via a server object, and cleans up before returning a status code.",
    "work_score": {
        "prorec": {
            "summary": "Generates two data structures from input parameters, processes them through helper routines, and returns an operation status code.",
            "score": [
                0.6,
                0.1,
                0.5
            ],
            "reason": [
                "The summary captures a generic notion that the function creates data structures, uses helper routines, and returns a status code, which matches the code flow in a broad sense. However, it omits key domain-specific details such as the use of NFS filehandles, the rpc_call_sync operation, and specific attributes updates, making it low-information and generic. While not factually wrong, most claims are safe but lack precision, with no inaccurate statements present.",
                "The summary provides only generic statements about creating data structures, using helper routines, and returning a status code, without accurately capturing the specific domain action of performing an NFSv3 link between an inode and a directory entry. It misses the core purpose and omits behavior-critical details such as RPC call usage, attribute allocation and freeing, and post-operation inode updates. Coverage is minimal and lacks specificity aligned with the source code\u2019s semantics.",
                "The summary contains mostly generic claims, stating that two data structures are generated from inputs, processed via helpers, and an operation status code is returned. While these are broadly accurate, they lack specificity about the function's primary purpose\u2014creating an NFSv3 link via RPC\u2014and omit key I/O details such as attribute allocation, the RPC procedure used, and updating inode metadata. There are no contradictory (FATAL) elements, but the gain is low due to minimal domain-specific insight and high reliance on generic phrasing."
            ]
        },
        "filter_prorec": {
            "summary": "Constructs two data structures from given parameters, processes them through storage-related operations, and returns a status code indicating success or resource error.",
            "score": [
                0.6,
                0.2,
                0.5
            ],
            "reason": [
                "The summary correctly notes that the function builds two data structures from parameters and returns a status code reflecting the outcome, which aligns with the source code's creation of `nfs3_linkargs` and `rpc_message` and its return of `status` after resource checks. However, it mislabels the operations as generic 'storage-related' without specifying the clear NFS link RPC call, and omits key post-operation inode updates and attribute allocations. As a result, while most claims are broadly accurate, they lack precise semantic detail from the code.",
                "The summary makes vague claims about constructing data structures, performing storage-related operations, and returning a status code, but it does not accurately capture the specific core purpose of performing an NFSv3 link operation between inodes via RPC. While the mentioned resource error loosely matches the -ENOMEM branch, the summary omits crucial domain-specific details such as the use of NFS file handles, the actual RPC procedure invoked, and the inode attribute updates, resulting in the core purpose not being covered and very limited secondary information.",
                "The summary correctly notes that the function constructs data structures from parameters and returns a status code, which aligns with the code. However, it is overly generic and lacks specific, distinguishing details about the NFS link operation, RPC call, and inode updates. There are no contradictory claims (no FATAL), but most of the content qualifies as low-information SAFE statements, with minimal positive gain and some vague abstraction that omits core domain semantics. The worst failure mode here is NOISE due to the lack of specificity, making the net benefit low."
            ]
        }
    }
}
{
    "source_code": "static void tsc_refine_calibration_work(struct work_struct *work)\n{\n\tstatic u64 tsc_start = -1, ref_start;\n\tstatic int hpet;\n\tu64 tsc_stop, ref_stop, delta;\n\tunsigned long freq;\n\n\t/* Don't bother refining TSC on unstable systems */\n\tif (check_tsc_unstable())\n\t\tgoto out;\n\n\t/*\n\t * Since the work is started early in boot, we may be\n\t * delayed the first time we expire. So set the workqueue\n\t * again once we know timers are working.\n\t */\n\tif (tsc_start == -1) {\n\t\t/*\n\t\t * Only set hpet once, to avoid mixing hardware\n\t\t * if the hpet becomes enabled later.\n\t\t */\n\t\thpet = is_hpet_enabled();\n\t\tschedule_delayed_work(&tsc_irqwork, HZ);\n\t\ttsc_start = tsc_read_refs(&ref_start, hpet);\n\t\treturn;\n\t}\n\n\ttsc_stop = tsc_read_refs(&ref_stop, hpet);\n\n\t/* hpet or pmtimer available ? */\n\tif (ref_start == ref_stop)\n\t\tgoto out;\n\n\t/* Check, whether the sampling was disturbed by an SMI */\n\tif (tsc_start == ULLONG_MAX || tsc_stop == ULLONG_MAX)\n\t\tgoto out;\n\n\tdelta = tsc_stop - tsc_start;\n\tdelta *= 1000000LL;\n\tif (hpet)\n\t\tfreq = calc_hpet_ref(delta, ref_start, ref_stop);\n\telse\n\t\tfreq = calc_pmtimer_ref(delta, ref_start, ref_stop);\n\n\t/* Make sure we're within 1% */\n\tif (abs(tsc_khz - freq) > tsc_khz/100)\n\t\tgoto out;\n\n\ttsc_khz = freq;\n\tpr_info(\"Refined TSC clocksource calibration: %lu.%03lu MHz\\n\",\n\t\t(unsigned long)tsc_khz / 1000,\n\t\t(unsigned long)tsc_khz % 1000);\n\nout:\n\tclocksource_register_khz(&clocksource_tsc, tsc_khz);\n}",
    "comment": "Refines TSC clocksource calibration by measuring timer frequencies and adjusting the TSC frequency if within 1% accuracy after initial readings.",
    "prorec_sum": "Computes and updates a CPU timing calibration value using hardware cycle counters, converting elapsed ticks into microseconds for scheduler timekeeping.",
    "filter_prorec_sum": "Calculates CPU time measurement using hardware or software clock sources, updates stored timing values, and triggers reporting if deviation exceeds threshold.",
    "prorec_aug_sum": "Computes elapsed time between high\u2011resolution counter reads to update and return a calibrated clock rate value in microseconds.",
    "filter_prorec_aug_sum": "Computes and updates a clock calibration value using TSC and stored timestamps, then returns the result through the kernel clock event interface.",
    "work_score": {
        "prorec": {
            "summary": "Computes and updates a CPU timing calibration value using hardware cycle counters, converting elapsed ticks into microseconds for scheduler timekeeping.",
            "score": [
                0.8,
                0.2,
                0.5
            ],
            "reason": [
                "The summary claims the function computes and updates a CPU timing calibration value using hardware cycle counters, which aligns with the code's refinement of the TSC clocksource frequency using either HPET or PM timer references. However, the mention of converting elapsed ticks into microseconds for scheduler timekeeping is inaccurate, as the code scales delta in microseconds for frequency calculation but does not explicitly tie it to scheduler timekeeping. Overall, most of the claim matches the source semantics, with a minor inaccuracy.",
                "The summary states a generic computation and update of a CPU timing calibration using hardware counters, but the source code\u2019s core purpose is specifically refining the TSC clocksource calibration using HPET or PM timer references during early boot, ensuring accuracy within 1% before registering the clocksource. The key domain details\u2014refinement process, use of HPET/pmtimer references, boot-time scheduling, and stability checks\u2014are missing, so the core is not covered and secondary behavior is absent.",
                "The summary claims the function computes and updates a CPU timing calibration value using hardware cycle counters and converts elapsed ticks into microseconds for scheduler timekeeping. While the code does perform TSC frequency refinement with hardware timers, the microseconds conversion and scheduler timekeeping purpose are not explicit in the source. The primary purpose is to refine and register the TSC clocksource frequency, not directly handle scheduler timekeeping. This introduces noise by overstating the intended use. No fatal contradictions to the core logic are present, but the information gain is low due to vague and slightly misaligned framing."
            ]
        },
        "filter_prorec": {
            "summary": "Calculates CPU time measurement using hardware or software clock sources, updates stored timing values, and triggers reporting if deviation exceeds threshold.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains partially accurate elements: it correctly indicates the use of hardware or software clock sources and updating stored timing values, which aligns with usage of HPET/pmtimer and updating tsc_khz. However, it inaccurately states that reporting is triggered if deviation exceeds threshold; in the code, output is logged only when within 1% deviation, and deviation exceeding the threshold leads to skipping refinement. The claim about calculating CPU time measurement is generic and does not precisely match the TSC calibration specifics. Overall, fewer than half of the claims are accurate.",
                "The summary incorrectly frames the core purpose as generic CPU time measurement and deviation reporting, which does not match the source code\u2019s specific function of refining TSC clocksource calibration using HPET or PM timer after initial boot and updating tsc_khz within a tolerance. The actual core \u2014 conditional calibration steps, handling unstable TSC, initial scheduling, reference comparison, and registering the clocksource \u2014 is missing. Secondary details such as handling SMI disturbance, 1% tolerance check, and specific hardware sources are also absent.",
                "The summary contains mostly inaccurate claims: it states the function calculates CPU time measurement in general terms, updates stored timing values, and triggers reporting if deviation exceeds a threshold. In reality, the code refines TSC calibration using HPET or PM timer references, conditionally updates `tsc_khz` only if deviation is within 1%, and registers the clocksource; there is no reporting triggered when deviation exceeds a threshold. The inaccuracies affect the primary purpose since the summary misrepresents the conditions and effect of deviation handling, making it misleading for understanding the function's semantics. The correct parts are generic and low-info, providing minimal gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic int pci_pm_poweroff(struct device *dev)\n{\n\tstruct pci_dev *pci_dev = to_pci_dev(dev);\n\tconst struct dev_pm_ops *pm = dev->driver ? dev->driver->pm : NULL;\n\n\tif (pci_has_legacy_pm_support(pci_dev))\n\t\treturn pci_legacy_suspend(dev, PMSG_HIBERNATE);\n\n\tif (!pm) {\n\t\tpci_pm_default_suspend(pci_dev);\n\t\tgoto Fixup;\n\t}\n\n\tpci_dev->state_saved = false;\n\tif (pm->poweroff) {\n\t\tint error;\n\n\t\terror = pm->poweroff(dev);\n\t\tsuspend_report_result(pm->poweroff, error);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n Fixup:\n\tpci_fixup_device(pci_fixup_suspend, pci_dev);\n\n\treturn 0;\n}",
    "comment": "Handles the power-off process for PCI devices, utilizing legacy support or device-specific power management operations, and fixes up device state afterward.",
    "prorec_sum": "Manages PCI device power-off by checking conditions, invoking device-specific callbacks, and performing fallback shutdown if no suitable handler is available.",
    "filter_prorec_sum": "Handles PCI device power-off by checking conditions, invoking optional callbacks, and issuing fallback or alternative actions based on power management checks.",
    "prorec_aug_sum": "Handles PCI device power-off by checking hardware conditions, invoking callbacks, and performing shutdown or reinitialization procedures as necessary.",
    "filter_prorec_aug_sum": "Handles PCI device power management by checking conditions, invoking shutdown callbacks, and performing a \"pci_pm_poweroff\" sequence when appropriate.",
    "work_score": {
        "prorec": {
            "summary": "Manages PCI device power-off by checking conditions, invoking device-specific callbacks, and performing fallback shutdown if no suitable handler is available.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly reflects the code's behavior by noting that it manages PCI device power-off, evaluates conditions, uses device-specific callbacks, and falls back when no handler is present. These claims align well with the code's conditional checks, invocation of pm->poweroff, and fallback paths, with no evident inaccuracies.",
                "The summary correctly states that the function powers off PCI devices using condition checks, optional device-specific callbacks, and fallbacks, which aligns with the core behavior of invoking appropriate suspend/poweroff paths and applying fixups. However, it lacks specific domain details such as handling legacy PM support, calling pci_pm_default_suspend, using pm->poweroff with error handling and suspend_report_result, and invoking pci_fixup_device. This results in coverage of the primary purpose but very limited coverage of key secondary behaviors and logic branches.",
                "The summary accurately states the primary purpose: managing PCI device power-off, conditional logic through device-specific callbacks, and fallback if no handler is available. These align with the source code's checks for legacy PM support, driver PM ops, and default suspend path. There are no inaccurate or irrelevant claims, but the description is generic and lacks specifics on key functions, arguments, and flow. The gain is low due to minimal detail despite accuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Handles PCI device power-off by checking conditions, invoking optional callbacks, and issuing fallback or alternative actions based on power management checks.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly reflects the core behavior: checking conditions, using optional driver callbacks, and fallback actions based on power management support. These statements align with the function\u2019s actual sequence\u2014legacy support check, default suspend fallback when no PM ops, invoking the poweroff callback if present, and performing device fixups. The claims are accurate but somewhat generic, lacking mention of specific branch conditions or concrete function names, making them low-info but still correct.",
                "The summary provides a generic description of checking conditions, optional callbacks, and fallbacks, but it fails to state the core action: powering off a PCI device with specific handling for legacy PM support, default suspend when no PM ops, invoking driver-provided poweroff, reporting results, and performing suspend fixups. While accurate at a high level, it lacks the explicit and distinctive details that capture the core domain semantics and omits error handling, constants like PMSG_HIBERNATE, and specific function calls used.",
                "The summary correctly notes that the function handles PCI device power-off, performs conditional checks, calls optional callbacks, and uses fallback or alternative actions based on power management conditions. These claims align with the source code\u2019s logic and flow, but they are generic and lack specific details such as the legacy PM support check, use of default suspend, or the Fixup routine. There are no inaccurate or contradictory statements, but the gain is low due to minimal technical specificity. Noise is minimal, with content remaining relevant to the function."
            ]
        }
    }
}
{
    "source_code": "static void drm_cleanup_buf_error(struct drm_device * dev,\n\t\t\t\t  struct drm_buf_entry * entry)\n{\n\tint i;\n\n\tif (entry->seg_count) {\n\t\tfor (i = 0; i < entry->seg_count; i++) {\n\t\t\tif (entry->seglist[i]) {\n\t\t\t\tdrm_pci_free(dev, entry->seglist[i]);\n\t\t\t}\n\t\t}\n\t\tkfree(entry->seglist);\n\n\t\tentry->seg_count = 0;\n\t}\n\n\tif (entry->buf_count) {\n\t\tfor (i = 0; i < entry->buf_count; i++) {\n\t\t\tkfree(entry->buflist[i].dev_private);\n\t\t}\n\t\tkfree(entry->buflist);\n\n\t\tentry->buf_count = 0;\n\t}\n}",
    "comment": "Cleans up allocated buffer memory and frees associated resources in a DRM device's buffer entry structure.",
    "prorec_sum": "Processes and clears entries from two linked lists or arrays, invoking a specified handler on each element before resetting their counters.",
    "filter_prorec_sum": "Processes and releases pending and queued node structures, invoking cleanup routines for each before resetting their associated counters.",
    "prorec_aug_sum": "Processes and resets GPU-related data structures by iterating queued entries and invoking a rendering update routine with provided parameters.",
    "filter_prorec_aug_sum": "Processes and clears queued and secondary entries from a graphics-related structure, invoking a rendering or update routine for each with provided parameters.",
    "work_score": {
        "prorec": {
            "summary": "Processes and clears entries from two linked lists or arrays, invoking a specified handler on each element before resetting their counters.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as processing linked lists or arrays and invoking a handler on each element, which does not match the source code. The code operates on two arrays in a struct, freeing allocated memory (via drm_pci_free and kfree) and resetting counters, but there is no generic 'specified handler' nor linked list processing. The claim thus misrepresents core semantics, resulting in a low proportion of accurate statements.",
                "The summary misrepresents the core function behavior: the source code specifically frees allocated DRM buffer memory using `drm_pci_free` and `kfree` for segments and buffers before resetting counts, whereas the summary generically refers to processing entries in 'linked lists or arrays' with a 'specified handler'. This fails to mention the core domain purpose of cleaning up and deallocating resources to handle buffer errors. No accurate claim matches the specific memory cleanup operation, and secondary details such as freeing both segment and buffer lists, conditional loops based on counts, and resetting counters are either inaccurately generalized or omitted.",
                "The summary incorrectly describes the data structures as 'linked lists', which contradicts the source code showing operations on arrays (seglist and buflist). This is a FATAL error affecting the primary purpose since it misrepresents the core data handling. While it generically notes iterating over elements and resetting counters, it omits specific behaviors like freeing memory via drm_pci_free and kfree. The summary's vague 'invoking a specified handler' fails to accurately reflect these explicit functions, and the noise outweighs any accurate content."
            ]
        },
        "filter_prorec": {
            "summary": "Processes and releases pending and queued node structures, invoking cleanup routines for each before resetting their associated counters.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes processing and releasing 'pending and queued node structures', which is unrelated to the actual source code operations. The function specifically frees allocated segment and buffer memory for a DRM device using drm_pci_free and kfree, and resets counters, but there is no mention of 'node structures' or 'cleanup routines' beyond these memory deallocations. The claims in the summary are therefore mostly inaccurate in targeting the actual semantics, with little factual alignment.",
                "The summary uses vague terms like 'pending and queued node structures' that do not match the specific domain semantics of freeing DRM buffer entry segment and buffer lists. It fails to mention the core purpose of releasing allocated PCI memory and freeing associated private data before resetting counters. No accurate claim covers the actual core operation, and secondary details such as the specific use of drm_pci_free, kfree, iteration logic, and conditional checks are missing.",
                "The summary describes processing and releasing 'pending and queued node structures' with cleanup routines, which does not match the source code's actual behavior of freeing DRM buffer segments and buffer lists using specific memory deallocation calls and resetting counters. This is a FATAL inaccuracy about the primary purpose and key side effects, as the summary misrepresents both the domain objects and actions. There are no accurate claims providing useful insight into the actual function semantics."
            ]
        }
    }
}
{
    "source_code": "int Xorriso_register_node_target(struct XorrisO *xorriso, int node_idx,\n                                 char *disk_path, int flag)\n{\n int l;\n\n if(xorriso->node_targets_availmem == 0)\n   return(2);\n if(xorriso->hln_targets == NULL || node_idx < 0 ||\n    node_idx >= xorriso->hln_count)\n   return(0);\n if(xorriso->hln_targets[node_idx] != NULL) {\n   xorriso->node_targets_availmem+= strlen(xorriso->hln_targets[node_idx]) +1;\n   free(xorriso->hln_targets[node_idx]);\n }\n l= strlen(disk_path);\n if(xorriso->node_targets_availmem <= l + 1) {\n   sprintf(xorriso->info_text,\n \"Hardlink target buffer exceeds -temp_mem_limit. Hardlinks may get divided.\");\n   Xorriso_msgs_submit(xorriso, 0, xorriso->info_text, 0, \"FAILURE\", 0);\n   xorriso->node_targets_availmem= 0;\n   return(0);\n }\n xorriso->hln_targets[node_idx]= strdup(disk_path);\n if(xorriso->hln_targets[node_idx] == NULL) {\n   Xorriso_no_malloc_memory(xorriso, NULL, 0);\n   return(-1);\n }\n xorriso->node_targets_availmem-= (l + 1);\n return(1);\n}",
    "comment": "Registers a hardlink target for a specified node index in the Xorriso structure, managing memory and error handling accordingly.",
    "prorec_sum": "Updates a string entry in an indexed array within a filesystem structure, freeing old data, enforcing size limits, and reporting failure if constraints are exceeded.",
    "filter_prorec_sum": "Updates a string entry in a bounded array, adjusting remaining capacity, and reports failure if the new string exceeds the available space.",
    "prorec_aug_sum": "Updates a specified string entry in an array, adjusting remaining capacity and reporting failure if the new string exceeds the allowed buffer size.",
    "filter_prorec_aug_sum": "Updates a specified string entry in a tracked list, adjusting remaining capacity and reporting failure if the new string exceeds the available buffer space.",
    "work_score": {
        "prorec": {
            "summary": "Updates a string entry in an indexed array within a filesystem structure, freeing old data, enforcing size limits, and reporting failure if constraints are exceeded.",
            "score": [
                0.9,
                0.3,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function updates a string entry in an indexed array, frees old data, enforces size limits, and reports failures when constraints are exceeded. These elements match the code\u2019s behavior with memory limit checks, freeing previous entries, and reporting errors via messages. However, the summary omits certain specifics, such as the early returns when memory is unavailable or index bounds fail, and doesn\u2019t mention the exact nature of return values, making it slightly incomplete.",
                "The summary correctly notes updating a string in an indexed array, freeing old data, enforcing size limits, and failure reporting, which aligns with the source code\u2019s array update and memory limit checks. However, it omits the core domain purpose of registering a hardlink target for a specified node index within the Xorriso context, thus failing to cover the primary operation. Secondary behaviors such as specific return codes and different error conditions are not mentioned.",
                "The summary correctly captures the core purpose: updating a string in an indexed array, freeing old data, enforcing size limits, and reporting failures when exceeded. These points align with the code\u2019s logic for replacing hln_targets entries, checking available memory, and issuing failure messages. However, it omits specific details on varied return codes (2, 0, -1, 1) depending on conditions, and does not mention some validation (e.g., index bounds, null checks). Overall, it is accurate with low noise but provides only moderate detail."
            ]
        },
        "filter_prorec": {
            "summary": "Updates a string entry in a bounded array, adjusting remaining capacity, and reports failure if the new string exceeds the available space.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary accurately reflects the core behavior of the function: it updates a string entry in an array, tracks remaining capacity, and reports a failure when the new string exceeds available memory. It omits some details such as specific return codes and conditional validation, but these omissions do not contradict the source. The claims are domain-relevant and correct, with more than 80% accuracy.",
                "The summary correctly notes updating a string entry in a bounded array and adjusting capacity, as well as failing when space is insufficient, which aligns with the core action of registering a hardlink target path with memory limit checks. However, it omits key domain-specific details like hardlink targets, specific return codes, freeing prior entries, emitting failure messages, and handling memory allocation errors, resulting in incomplete coverage of critical behaviors.",
                "The summary correctly notes that the function updates a string entry and adjusts capacity, and that it reports failure if the new string exceeds available space. These are accurate reflections of the code\u2019s behavior. However, it omits several key details such as the specific array being `hln_targets`, handling of freeing old entries, the multiple distinct return codes (2, 0, -1, 1), and checks on index validity and NULL pointers before updating. The omissions reduce its informational value, but there are no clear inaccuracies or contradictions, and noise is minimal."
            ]
        }
    }
}
{
    "source_code": "\nstatic const char *\nget_symbol_index_type (Filedata * filedata, unsigned int type)\n{\n  static char buff[32];\n\n  switch (type)\n    {\n    case SHN_UNDEF:\treturn \"UND\";\n    case SHN_ABS:\treturn \"ABS\";\n    case SHN_COMMON:\treturn \"COM\";\n    default:\n      if (type == SHN_IA_64_ANSI_COMMON\n\t  && filedata->file_header.e_machine == EM_IA_64\n\t  && filedata->file_header.e_ident[EI_OSABI] == ELFOSABI_HPUX)\n\treturn \"ANSI_COM\";\n      else if ((filedata->file_header.e_machine == EM_X86_64\n\t\t|| filedata->file_header.e_machine == EM_L1OM\n\t\t|| filedata->file_header.e_machine == EM_K1OM)\n\t       && type == SHN_X86_64_LCOMMON)\n\treturn \"LARGE_COM\";\n      else if ((type == SHN_MIPS_SCOMMON\n\t\t&& filedata->file_header.e_machine == EM_MIPS)\n\t       || (type == SHN_TIC6X_SCOMMON\n\t\t   && filedata->file_header.e_machine == EM_TI_C6000))\n\treturn \"SCOM\";\n      else if (type == SHN_MIPS_SUNDEFINED\n\t       && filedata->file_header.e_machine == EM_MIPS)\n\treturn \"SUND\";\n      else if (type >= SHN_LOPROC && type <= SHN_HIPROC)\n\tsprintf (buff, \"PRC[0x%04x]\", type & 0xffff);\n      else if (type >= SHN_LOOS && type <= SHN_HIOS)\n\tsprintf (buff, \"OS [0x%04x]\", type & 0xffff);\n      else if (type >= SHN_LORESERVE)\n\tsprintf (buff, \"RSV[0x%04x]\", type & 0xffff);\n      else if (type >= filedata->file_header.e_shnum)\n\tsprintf (buff, _(\"bad section index[%3d]\"), type);\n      else\n\tsprintf (buff, \"%3d\", type);\n      break;\n    }\n\n  return buff;\n}",
    "comment": "Returns a string representation of a symbol index type based on the provided type and file header information.",
    "prorec_sum": "Returns a descriptive string label or formatted code representing a section type based on the given numeric identifier and header field values.",
    "filter_prorec_sum": "Returns a descriptive string label for a given section code based on specific numeric values, structural fields, and predefined formatting rules.",
    "prorec_aug_sum": "Returns a descriptive string label for a given section or communication code based on numeric identifiers and contextual header field values.",
    "filter_prorec_aug_sum": "Maps a numeric section or type code to a corresponding identifier string or formatted label based on specific value and field checks.",
    "work_score": {
        "prorec": {
            "summary": "Returns a descriptive string label or formatted code representing a section type based on the given numeric identifier and header field values.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly conveys that the function returns a descriptive string or formatted code depending on a numeric identifier and certain header field values. This matches the source code\u2019s behavior where various constants and conditions determine the returned string. However, it is generic and lacks mention of specific cases or labels used, reducing the informational value but remaining accurate overall.",
                "The summary correctly states that the function returns a descriptive string based on a numeric identifier and header field values, which matches the code\u2019s purpose. However, it does not specify the detailed core logic of mapping specific section type constants (e.g., SHN_UNDEF, SHN_ABS) to labels or handling particular machine and OSABI conditions. This omission means the core domain behavior is only vaguely covered, and no secondary behaviors like formatted output for ranges, error indications, or machine-specific constants are mentioned.",
                "The summary is generically accurate, stating that the function returns a label or formatted code based on the numeric identifier and header fields. It correctly reflects the core purpose without contradicting the code. However, it is low-information, lacking the specific mappings and detailed conditions present in the source, and contains no noise or fatal errors. The worst failure mode is low gain due to broad, generic phrasing that provides limited engineering value."
            ]
        },
        "filter_prorec": {
            "summary": "Returns a descriptive string label for a given section code based on specific numeric values, structural fields, and predefined formatting rules.",
            "score": [
                0.9,
                0.2,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function returns a descriptive string label based on the section code, using specific values from the code and formatting rules, which matches the source implementation. However, it is generic and omits important specific mappings (e.g., 'UND', 'ABS', 'COM', ANSI_COM for IA-64 HPUX) and conditional logic tied to machine types and OSABI, so while accurate, it lacks detail. This makes it a safe but low-information summary with no inaccuracies.",
                "The summary captures the general idea that the function returns a descriptive string based on numeric values and formatting rules, but it is too vague. It does not explicitly mention the core purpose of mapping ELF special section index types to specific labels according to type constants and machine/OSABI conditions, which is central to the function. No accurate claim directly reflects these domain-specific mappings, so the core is not covered.",
                "The summary is broadly correct in stating that the function returns a descriptive string based on numeric type values and certain structural fields, which matches the code's switch cases and formatting with sprintf. However, the claim is generic and lacks specific details on the exact conditions and labels (e.g., 'UND', 'ABS', 'COM', machine-specific cases), offering only low informational value. There are no inaccurate contradictions, but the gain is limited due to absence of precise mappings present in the source code."
            ]
        }
    }
}
{
    "source_code": "\nvoid *\nFcompile (char *pattern, idx_t size, reg_syntax_t ignored, bool exact)\n{\n  kwset_t kwset;\n  char *buf = NULL;\n  idx_t bufalloc = 0;\n\n  kwset = kwsinit (true);\n\n  char const *p = pattern;\n  do\n    {\n      char const *sep = rawmemchr (p, '\\n');\n      idx_t len = sep - p;\n\n      if (match_lines)\n        {\n          if (eolbyte == '\\n' && pattern < p)\n            p--;\n          else\n            {\n              if (bufalloc < len + 2)\n                {\n                  free (buf);\n                  bufalloc = len;\n                  buf = xpalloc (NULL, &bufalloc, 2, -1, 1);\n                  buf[0] = eolbyte;\n                }\n              memcpy (buf + 1, p, len);\n              buf[len + 1] = eolbyte;\n              p = buf;\n            }\n          len += 2;\n        }\n      kwsincr (kwset, p, len);\n\n      p = sep + 1;\n    }\n  while (p <= pattern + size);\n\n  free (buf);\n\n  idx_t words = kwswords (kwset);\n  kwsprep (kwset);\n\n  struct kwsearch *kwsearch = xmalloc (sizeof *kwsearch);\n  kwsearch->kwset = kwset;\n  kwsearch->words = words;\n  kwsearch->pattern = pattern;\n  kwsearch->size = size;\n  kwsearch->re = NULL;\n  return kwsearch;\n}",
    "comment": "Processes a pattern string, initializes a keyword set, and returns a structure containing the keyword set and its associated properties.",
    "prorec_sum": "Processes an obstack buffer line by line, conditionally modifies line endings, stores them in a new obstack, and returns related buffer references.",
    "filter_prorec_sum": "Processes an obstack by splitting at newline characters, optionally modifying lines, and returns a structure containing the processed and original data.",
    "prorec_aug_sum": "Processes an obstack buffer line by line, conditionally modifies line endings, stores them in a new obstack, and returns related buffer references.",
    "filter_prorec_aug_sum": "Processes newline-delimited data from two obstack buffers, conditionally modifies line endings, and returns a structure containing aggregated and original buffer references.",
    "work_score": {
        "prorec": {
            "summary": "Processes an obstack buffer line by line, conditionally modifies line endings, stores them in a new obstack, and returns related buffer references.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary makes several claims that are inaccurate when compared to the source code. It asserts processing of an obstack buffer and returning obstack-related references, but the function operates on a `pattern` string using `kwset` functions, not on an obstack, and returns a `kwsearch` struct. While it correctly notes line-by-line processing and conditional modification of line endings, the majority of claims misrepresent the data structures and operations, resulting in low alignment with the source.",
                "The summary incorrectly describes processing an obstack buffer and returning obstack references, which is not present in the source code. The function actually initializes a keyword set, processes the input pattern line by line possibly adjusting end-of-line bytes, adds each line into the kwset, prepares it, and returns a kwsearch structure. The core purpose of compiling patterns into a prepared keyword set is missing, and none of the claims align accurately with the code\u2019s domain semantics.",
                "The summary is dominated by inaccurate claims: it incorrectly describes processing an obstack buffer, storing lines in a new obstack, and returning buffer references, none of which occur in the source. The actual function works with a keyword set, manipulates line endings based on flags, and builds a search structure. These are core semantic mismatches on the primary purpose and key I/O, making the output misleading and untrustworthy."
            ]
        },
        "filter_prorec": {
            "summary": "Processes an obstack by splitting at newline characters, optionally modifying lines, and returns a structure containing the processed and original data.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly states that the function processes an obstack, while the source code handles a pattern string using a kwset for keyword searching. The claim about splitting at newline characters is partially accurate, but the context is misrepresented. Additionally, the summary mentions returning both processed and original data, which is misleading since it returns a kwsearch struct without storing modified lines in that struct. Most claims fail to match the code's actual semantics, resulting in very low accuracy.",
                "The summary is inaccurate because it describes processing an obstack, which is not present in the source code, and does not capture the core purpose of compiling a keyword set from a pattern split at newlines. It also omits the actual domain-specific functionality of handling match_lines adjustments, preparing the keyword set, and returning a search structure. The core behavior is missing and the provided details are incorrect, leading to poor alignment.",
                "The summary is inaccurate: it claims the function processes an obstack, but the source code does not involve obstacks at all\u2014it operates on a string pattern, splitting at newline characters, optionally adding eolbyte to lines if match_lines is set, and building a kwset for search. This is a FATAL error related to the primary purpose, since it misstates the data structure being processed, which is core to understanding the function. There is minimal accurate content; the splitting at newline characters is correct, but misleading context and incorrect data structure overwhelm it."
            ]
        }
    }
}
{
    "source_code": "bool pm_wakeup_pending(void)\n{\n\tunsigned long flags;\n\tbool ret = false;\n\n\tspin_lock_irqsave(&events_lock, flags);\n\tif (events_check_enabled) {\n\t\tunsigned int cnt, inpr;\n\n\t\tsplit_counters(&cnt, &inpr);\n\t\tret = (cnt != saved_count || inpr > 0);\n\t\tevents_check_enabled = !ret;\n\t}\n\tspin_unlock_irqrestore(&events_lock, flags);\n\n\tif (ret)\n\t\tprint_active_wakeup_sources();\n\n\treturn ret;\n}",
    "comment": "Checks if a wakeup event is pending by comparing counters and prints active wakeup sources if there is a pending event.",
    "prorec_sum": "Checks a hardware unlock status flag, updates it, and triggers follow\u2011up actions on eligible devices in a linked list based on specific conditions.",
    "filter_prorec_sum": "Checks a hardware unlock status and, if successful, iterates registered devices to trigger specific actions on flagged or most recent entries.",
    "prorec_aug_sum": "Checks a global state flag and triggers specific callbacks for CPU idle devices, selecting one based on activity status and timestamp.",
    "filter_prorec_aug_sum": "Checks a global status flag, updates related data structures, and triggers callbacks for active or most recent entries before returning a success indicator.",
    "work_score": {
        "prorec": {
            "summary": "Checks a hardware unlock status flag, updates it, and triggers follow\u2011up actions on eligible devices in a linked list based on specific conditions.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's main claims about checking a hardware unlock status flag, updating it, and triggering actions on eligible devices in a linked list do not match the source code behavior. The function actually locks an events_lock, checks event counter values if events_check_enabled, updates that flag accordingly, optionally prints active wakeup sources, and returns a boolean indicating pending wakeup. None of the summary's claims accurately reflect these details, resulting in 0% accurate claims.",
                "The summary does not capture the core purpose of determining whether there are pending power management wakeup events by checking event counters under a spinlock and updating the check flag. Instead, it inaccurately describes checking a hardware unlock status and triggering actions on linked list devices, which contradicts the source code behavior. No accurate claims cover the core domain operation or other key behaviors such as spinlock usage, counter comparison, flag update, conditional printing, or return value semantics.",
                "The summary contains a main claim that the function checks a hardware unlock status flag, updates it, and triggers follow-up actions on eligible devices in a linked list. This is inaccurate because the source code does not reference any hardware unlock flag or linked list of devices; instead it checks event counters under a spinlock and possibly prints active wakeup sources. The key claim contradicts the primary purpose, making it a severe semantic error (FATAL) on core functionality. There are no accurate domain-specific details to offset this, resulting in unusable output."
            ]
        },
        "filter_prorec": {
            "summary": "Checks a hardware unlock status and, if successful, iterates registered devices to trigger specific actions on flagged or most recent entries.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary makes claims about checking hardware unlock status and iterating over registered devices to trigger actions on flagged or recent entries, none of which match the actual function semantics. The source code deals with spin locks, checking event counters, and potentially printing active wakeup sources; there is no hardware unlock status or device iteration. All claims are inaccurate, resulting in low alignment with the evaluation steps.",
                "The summary incorrectly describes the function as checking hardware unlock status and iterating over registered devices, which is not reflected in the source code. The actual function checks if a power management wakeup is pending by evaluating event counters under a spinlock, then conditionally printing active wakeup sources. No claims in the summary align with the core purpose or secondary details from the code, resulting in complete mismatch.",
                "The summary is inaccurate about the core purpose: it claims the function checks a hardware unlock status and iterates devices, which contradicts the code that checks pending wakeup events and conditionally prints active sources using counters under a spinlock. This is a severe FATAL error on the primary purpose and key side effects, making the description misleading and unusable."
            ]
        }
    }
}
{
    "source_code": "\nstruct local_symbol *\nlocal_symbol_make (const char *name, segT section, valueT val, fragS *frag)\n{\n  const char *name_copy;\n  struct local_symbol *ret;\n\n  ++local_symbol_count;\n\n  name_copy = save_symbol_name (name);\n\n  ret = (struct local_symbol *) obstack_alloc (&notes, sizeof *ret);\n  ret->lsy_flags.sy_local_symbol = 1;\n  ret->lsy_flags.sy_resolved = 0;\n  ret->lsy_name = name_copy;\n  ret->lsy_section = section;\n  local_symbol_set_frag (ret, frag);\n  ret->lsy_value = val;\n\n  hash_jam (local_hash, name_copy, (void *) ret);\n\n  return ret;\n}",
    "comment": "Creates and initializes a local symbol structure, copying its name, setting properties, and storing it in a hash table.",
    "prorec_sum": "Allocates space in an obstack for a new object, stores provided fields, updates control flags, and registers it with a global table.",
    "filter_prorec_sum": "Allocates space in an obstack for a new object, stores provided parameters into it, and registers it through a handler function.",
    "prorec_aug_sum": "Allocates a new 40-byte object in an obstack, stores provided parameters, updates alignment and chunk pointers, and registers it via a callback.",
    "filter_prorec_aug_sum": "Allocates and initializes a new obstack object with supplied parameters and string data, then registers it using a dedicated handler function.",
    "work_score": {
        "prorec": {
            "summary": "Allocates space in an obstack for a new object, stores provided fields, updates control flags, and registers it with a global table.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function allocates space in an obstack for a new local_symbol object, stores the provided fields (name, section, value), updates control flags (sy_local_symbol and sy_resolved), and registers it with a global table via hash_jam. All claims are directly supported by the source code, with no inaccuracies present, indicating high alignment with the function's domain semantics.",
                "The summary accurately notes memory allocation via obstack, storing provided fields, updating control flags, and registering in a global table, which matches the source code. However, it fails to cover the core primary purpose with domain-specific specificity\u2014creating and initializing a local_symbol structure, including copying the symbol name, setting section, frag, and value, and inserting into a hash table. Several critical details, such as name copying and frag linkage, are omitted, resulting in incomplete secondary coverage.",
                "The summary contains several accurate generic statements: allocation in an obstack, storing provided fields, updating flags, and registering in a global table. These match the source code's creation of a local_symbol in an obstack, assignment of values from parameters, setting flags, and inserting into a hash table. However, all claims are SAFE and generic, with no specific details on parameter names, the exact flags, or the hash function used. No inaccurate or contradictory claims are present, but the informational gain is low."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates space in an obstack for a new object, stores provided parameters into it, and registers it through a handler function.",
            "score": [
                0.9,
                0.3,
                0.5
            ],
            "reason": [
                "The summary contains accurate but generic claims: it correctly notes allocation via obstack, assignment of provided parameters, and registration via a handler function, which aligns with `obstack_alloc`, storing `name`, `section`, `val`, and `frag`, and calling `hash_jam`. However, the description omits specific details such as setting flags and incrementing the symbol count, making it a broad rather than fully precise characterization. All claims are accurate but low-info, resulting in high proportion of ACCURATE but generic statements.",
                "The summary accurately notes allocation in an obstack, storing parameters, and a registration step, but it fails to cover the core primary purpose: creating and initializing a local_symbol struct with specific fields and behaviors (local flag, resolved flag, section, fragment, value) and inserting it into a hash table keyed by a saved copy of the name. It omits key implementation details like incrementing a counter, copying the symbol name, and setting flags, which are critical to the function\u2019s semantics.",
                "The summary makes a single broad claim: allocation in an obstack, storing parameters, and registering via a handler function. These map loosely to the code, which uses obstack_alloc, assigns fields from parameters, and calls hash_jam. However, the description lacks specificity about the domain semantics (creating a local_symbol, setting flags), omits key steps like incrementing the counter and copying the name, and does not misstate the primary purpose. The inaccuracy level is low (no FATAL), but the claim is generic SAFE with minimal detail, reducing gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\ngss_pipe_release(struct inode *inode)\n{\n\tstruct net *net = inode->i_sb->s_fs_info;\n\tstruct rpc_pipe *pipe = RPC_I(inode)->pipe;\n\tstruct gss_upcall_msg *gss_msg;\n\nrestart:\n\tspin_lock(&pipe->lock);\n\tlist_for_each_entry(gss_msg, &pipe->in_downcall, list) {\n\n\t\tif (!list_empty(&gss_msg->msg.list))\n\t\t\tcontinue;\n\t\tgss_msg->msg.errno = -EPIPE;\n\t\tatomic_inc(&gss_msg->count);\n\t\t__gss_unhash_msg(gss_msg);\n\t\tspin_unlock(&pipe->lock);\n\t\tgss_release_msg(gss_msg);\n\t\tgoto restart;\n\t}\n\tspin_unlock(&pipe->lock);\n\n\tput_pipe_version(net);\n}",
    "comment": "Releases GSS upcall messages in a pipe by unhashing and incrementing the error count for empty message lists before freeing resources.",
    "prorec_sum": "Iterates through a linked list of objects, updates their state, invokes two processing callbacks with given parameters, and finalizes with a cleanup operation.",
    "filter_prorec_sum": "Iterates through and updates linked queue entries with new parameters, invoking specified callbacks, then finalizes processing via a related control structure.",
    "prorec_aug_sum": "Iterates over and updates linked service entries, applies numeric adjustments, triggers two processing callbacks, then finalizes using a secondary service pointer.",
    "filter_prorec_aug_sum": "Iterates through a linked list of structures, updates fields, invokes two processing callbacks with numeric parameters, and finalizes by calling a service-related function.",
    "work_score": {
        "prorec": {
            "summary": "Iterates through a linked list of objects, updates their state, invokes two processing callbacks with given parameters, and finalizes with a cleanup operation.",
            "score": [
                0.3,
                0.2,
                0.4
            ],
            "reason": [
                "The summary accurately captures that the function iterates through a list and updates object state, but it inaccurately describes the actions as 'invokes two processing callbacks with given parameters,' which does not match the source code. The functions called in the code are specific cleanup and release operations, not generic processing callbacks, and parameters are not passed in the way described. The final cleanup is mentioned correctly but generically. Overall, fewer than half the claims align precisely with the code's actual semantics.",
                "The summary gives a vague and generic description of iterating through a list, updating state, calling callbacks, and cleanup, but it fails to identify the core purpose of releasing GSS upcall messages in an RPC pipe when they have no pending data and signalling errors. It omits specific domain semantics like the use of spin locks, the restart loop, error setting to -EPIPE, unhashing and releasing messages, and calling put_pipe_version at the end. This means the primary purpose is not covered and secondary behaviors are largely missing.",
                "The summary provides only a vague description without capturing specific semantics of the function, such as setting errno to -EPIPE, incrementing a count, unhashing and releasing messages, and handling lock/unlock cycles. It inaccurately generalizes actions as 'invokes two processing callbacks' and 'cleanup operation' without matching actual function names or parameters in the code. This is mostly NOISE with no GOLD-level detail, resulting in low net benefit."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates through and updates linked queue entries with new parameters, invoking specified callbacks, then finalizes processing via a related control structure.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is overly generic and does not accurately reflect the specific behavior in the source code, which processes gss_upcall_msg structures by setting an error code, incrementing a counter, unhashing, releasing messages, and looping until done before updating the pipe version. The description of 'updating linked queue entries with new parameters' and 'invoking callbacks' is vague and mismatched to the actual operations. Most claims do not target the code's true semantics, resulting in low accuracy.",
                "The summary fails to capture the core purpose, which is to release pending GSS upcall messages from a pipe by marking them with an error, unhashing and releasing them, then decrementing pipe version. The claims are generic about iterating and updating entries, invoking callbacks, and finalizing via a control structure, which neither specifies GSS messages nor reflects the error marking, restart loop, lock handling, or pipe version release. Core functionality and critical secondary details are missing, making the coverage poor.",
                "The summary is mostly inaccurate and vague. It claims the function updates linked queue entries with new parameters and invokes unspecified callbacks, but the source code shows it iterating over a list of downcall messages, setting an error code, adjusting a reference count, unhashing the message, and releasing it. There is no mention of generic 'new parameters' or arbitrary callbacks. The reference to finalizing via a related control structure is also unclear and does not map directly to the code's behavior of calling put_pipe_version. These are NOISE statements that do not capture the core purpose or I/O of the function, resulting in low gain from the accurate parts."
            ]
        }
    }
}
{
    "source_code": "void FAST_FUNC add_to_ino_dev_hashtable(const struct stat *statbuf, const char *name)\n{\n\tint i;\n\tino_dev_hashtable_bucket_t *bucket;\n\n\tif (!name)\n\t\tname = \"\";\n\tbucket = xmalloc(sizeof(ino_dev_hashtable_bucket_t) + strlen(name));\n\tbucket->ino = statbuf->st_ino;\n\tbucket->dev = statbuf->st_dev;\n\tbucket->isdir = !!S_ISDIR(statbuf->st_mode);\n\tstrcpy(bucket->name, name);\n\n\tif (!ino_dev_hashtable)\n\t\tino_dev_hashtable = xzalloc(HASH_SIZE * sizeof(*ino_dev_hashtable));\n\n\ti = hash_inode(statbuf->st_ino);\n\tbucket->next = ino_dev_hashtable[i];\n\tino_dev_hashtable[i] = bucket;\n}",
    "comment": "Adds a new entry to the inode-device hashtable using the provided stat structure and name, allocating memory for the bucket dynamically.",
    "prorec_sum": "Creates and links a new file entry from given parameters, handling symlink identification and inserting it into a global hash table.",
    "filter_prorec_sum": "Creates a new file entry structure using provided metadata and inserts it into a hash table, initializing fields and symlink-related attributes.",
    "prorec_aug_sum": "Allocates and links a new entry into a hash table, initializing fields from input parameters and copying identifier data from the provided source.",
    "filter_prorec_aug_sum": "Creates and links a new structure for the given key, initializes its fields from input data, and stores it in a global hash table.",
    "work_score": {
        "prorec": {
            "summary": "Creates and links a new file entry from given parameters, handling symlink identification and inserting it into a global hash table.",
            "score": [
                0.5,
                0.2,
                0.2
            ],
            "reason": [
                "The summary\u2019s claim about creating and linking a new file entry with given parameters is broadly accurate regarding allocating a bucket, setting inode/device, and linking into a global hash table. However, it incorrectly states that the function handles symlink identification\u2014source code only identifies directories via `S_ISDIR` and does not check for symlinks. This makes one of the major claims inaccurate, resulting in mixed reliability with less than full precision.",
                "The summary incorrectly claims symlink identification, while the source code checks if the entry is a directory. It does not accurately state the core purpose, which is to allocate and populate a hash table bucket keyed by inode and device from a stat structure and name. The global hash insertion is mentioned, but the domain-specific behavior of using inode/device from statbuf and handling directory status is missing or wrong. Secondary details like memory allocation and empty name fallback are also omitted.",
                "The summary makes a FATAL error by claiming symlink identification, which is not present in the source code; the function only checks if the path is a directory using S_ISDIR. While it correctly notes insertion into a global hash table from given parameters, the primary purpose is misrepresented, harming trustworthiness. Positive gain is low due to minimal accurate detail and the severe inaccuracy on core behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Creates a new file entry structure using provided metadata and inserts it into a hash table, initializing fields and symlink-related attributes.",
            "score": [
                0.6,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly describes creating a structure from provided metadata and inserting it into a hash table, aligning with the code\u2019s allocation, field initialization, and insertion logic. However, it inaccurately mentions symlink-related attributes, which are not present in the source code. This results in a mix of accurate and inaccurate claims, with the incorrect symlink detail lowering overall precision.",
                "The summary correctly states that a structure is created from provided metadata and inserted into a hash table, which matches the core purpose of populating fields from stat data and adding the bucket to ino_dev_hashtable. However, it inaccurately mentions symlink-related attributes, which are not handled in the code, and omits important specifics such as determining directory status, handling empty name defaults, allocating hash table if null, and using inode-based hashing. The coverage of secondary behavior is weak and contains an incorrect detail, reducing alignment with evaluation steps.",
                "The summary correctly notes that the function creates a new entry from provided metadata and inserts it into a hash table, which matches the code\u2019s core purpose. However, it inaccurately states that symlink-related attributes are initialized\u2014there is no handling of symlinks in the source code, only inode, device, directory flag, and name. This is a specific contradiction regarding a semantic detail, but it does not affect the primary purpose or core I/O, making it a non-fatal inaccuracy. The rest of the summary is generic and low in detail, with little high-gain information present."
            ]
        }
    }
}
{
    "source_code": "int loadkmap_main(int argc UNUSED_PARAM, char **argv)\n{\n\tstruct kbentry ke;\n\tint i, j, fd;\n\tuint16_t ibuff[NR_KEYS];\n/*\tconst char *tty_name = CURRENT_TTY; */\n\tRESERVE_CONFIG_BUFFER(flags, MAX_NR_KEYMAPS);\n\n\t/* When user accidentally runs \"loadkmap FILE\"\n\t * instead of \"loadkmap <FILE\", we end up waiting for input from tty.\n\t * Let's prevent it: */\n\tif (argv[1])\n\t\tbb_show_usage();\n/* bb_warn_ignoring_args(argv[1]); */\n\n\tfd = get_console_fd_or_die();\n/* or maybe:\n\topt = getopt32(argv, \"C:\", &tty_name);\n\tfd = xopen_nonblocking(tty_name);\n*/\n\n\txread(STDIN_FILENO, flags, 7);\n\tif (!is_prefixed_with(flags, BINARY_KEYMAP_MAGIC))\n\t\tbb_error_msg_and_die(\"not a valid binary keymap\");\n\n\txread(STDIN_FILENO, flags, MAX_NR_KEYMAPS);\n\n\tfor (i = 0; i < MAX_NR_KEYMAPS; i++) {\n\t\tif (flags[i] != 1)\n\t\t\tcontinue;\n\t\txread(STDIN_FILENO, ibuff, NR_KEYS * sizeof(uint16_t));\n\t\tfor (j = 0; j < NR_KEYS; j++) {\n\t\t\tke.kb_index = j;\n\t\t\tke.kb_table = i;\n\t\t\tke.kb_value = ibuff[j];\n\t\t\t/*\n\t\t\t * Note: table[idx:0] can contain special value\n\t\t\t * K_ALLOCATED (marks allocated tables in kernel).\n\t\t\t * dumpkmap saves the value as-is; but attempts\n\t\t\t * to load it here fail, since it isn't a valid\n\t\t\t * key value: it is K(KT_SPEC,126) == 2<<8 + 126,\n\t\t\t * whereas last valid KT_SPEC is\n\t\t\t * K_BARENUMLOCK == K(KT_SPEC,19).\n\t\t\t * So far we just ignore these errors:\n\t\t\t */\n\t\t\tioctl(fd, KDSKBENT, &ke);\n\t\t}\n\t}\n\n\tif (ENABLE_FEATURE_CLEAN_UP) {\n\t\tclose(fd);\n\t\tRELEASE_CONFIG_BUFFER(flags);\n\t}\n\treturn EXIT_SUCCESS;\n}",
    "comment": "Loads a binary keymap from standard input and updates the keyboard mapping using ioctl calls for each valid keymap.",
    "prorec_sum": "Processes a binary keymap file, validates its format, and registers all defined key mappings into the system using the provided device identifier.",
    "filter_prorec_sum": "Processes a binary keymap file, validates its header, and registers mappings for active keys using a given device identifier.",
    "prorec_aug_sum": "Processes a binary keymap file, validates its signature, and registers all defined key mappings using the specified device or configuration identifier.",
    "filter_prorec_aug_sum": "Processes a binary keymap file, validates its header, and registers key mappings by iterating through key codes and associated mapping values.",
    "work_score": {
        "prorec": {
            "summary": "Processes a binary keymap file, validates its format, and registers all defined key mappings into the system using the provided device identifier.",
            "score": [
                0.6,
                0.6,
                0.2
            ],
            "reason": [
                "The summary contains partially accurate claims: it correctly states that the function processes a binary keymap file and validates its format, and that it registers key mappings into the system. However, it inaccurately mentions use of a 'provided device identifier'\u2014the code obtains a console file descriptor internally rather than using a passed-in identifier. This incorrect detail reduces the proportion of accurate claims to around 66%, indicating mixed reliability.",
                "The summary correctly notes that the function processes a binary keymap file and validates its format, which matches the code\u2019s reading of keymap data from stdin and checking for a magic prefix. It also captures the core purpose of registering key mappings into the system via ioctl on a console file descriptor, effectively covering the primary domain action. However, it inaccurately states that this is done using a 'provided device identifier', which is misleading since the device is obtained internally by get_console_fd_or_die() rather than being supplied as an argument. The summary omits important secondary details such as rejecting extra command-line arguments, handling allocated table values specially, and cleanup behavior, resulting in partial coverage of secondary semantics.",
                "The summary correctly states that the function processes a binary keymap file and validates its format, which matches the code reading from stdin, checking the magic prefix, and iterating over keymap tables. However, it inaccurately claims that the registration uses a 'provided device identifier' \u2014 the code obtains the console file descriptor internally, not from an external identifier in the arguments. This is a domain-semantics mismatch on a key I/O detail, constituting a FATAL error impacting the core behavior. The rest of the summary is generally accurate but lacks deeper specifics, limiting positive gain."
            ]
        },
        "filter_prorec": {
            "summary": "Processes a binary keymap file, validates its header, and registers mappings for active keys using a given device identifier.",
            "score": [
                0.8,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function processes a binary keymap file and validates its header, which matches the header read and check against BINARY_KEYMAP_MAGIC in the source. It also accurately notes registering mappings for active keys, as indicated by iterating over key tables where flags[i] == 1 and using ioctl to set entries. However, the claim about using a 'given device identifier' is inaccurate, since the function obtains a console file descriptor programmatically rather than taking a device identifier from input. Overall, most claims are accurate with one notable inaccuracy.",
                "The summary correctly notes processing a binary keymap and validating its header, which matches reading from STDIN, checking the magic prefix, and handling keymaps. However, it inaccurately states 'using a given device identifier,' while the code specifically obtains a console file descriptor rather than an arbitrary device ID. The core purpose\u2014reading a binary keymap from STDIN and loading it into the kernel via ioctl calls\u2014is only partially covered; the summary omits important details such as rejecting extra CLI args, reading flags per table, iterating over key tables, handling invalid key values, and cleanup steps. Coverage of core action is incomplete and secondary behavior is thin.",
                "The summary correctly states that the function processes a binary keymap file and validates its header, which aligns with the code reading flags from stdin, checking the magic prefix, and proceeding only on valid files. It also notes that mappings for active keys are registered, matching the ioctl calls in the loop for flags[i] == 1 entries. However, it inaccurately mentions using a 'given device identifier,' which is not evident in the code; the function obtains the console fd internally without taking an identifier from input. This is a minor inaccuracy but related to core I/O details, reducing trust somewhat though not severely. The rest of the claims are accurate and specific enough to be helpful, with low noise."
            ]
        }
    }
}
{
    "source_code": "\nstatic int i915_ring_freq_table(struct seq_file *m, void *unused)\n{\n\tstruct drm_info_node *node = (struct drm_info_node *) m->private;\n\tstruct drm_device *dev = node->minor->dev;\n\tdrm_i915_private_t *dev_priv = dev->dev_private;\n\tint ret;\n\tint gpu_freq, ia_freq;\n\n\tif (!(IS_GEN6(dev) || IS_GEN7(dev))) {\n\t\tseq_printf(m, \"unsupported on this chipset\\n\");\n\t\treturn 0;\n\t}\n\n\tret = mutex_lock_interruptible(&dev_priv->rps.hw_lock);\n\tif (ret)\n\t\treturn ret;\n\n\tseq_printf(m, \"GPU freq (MHz)\\tEffective CPU freq (MHz)\\tEffective Ring freq (MHz)\\n\");\n\n\tfor (gpu_freq = dev_priv->rps.min_delay;\n\t     gpu_freq <= dev_priv->rps.max_delay;\n\t     gpu_freq++) {\n\t\tia_freq = gpu_freq;\n\t\tsandybridge_pcode_read(dev_priv,\n\t\t\t\t       GEN6_PCODE_READ_MIN_FREQ_TABLE,\n\t\t\t\t       &ia_freq);\n\t\tseq_printf(m, \"%d\\t\\t%d\\t\\t\\t\\t%d\\n\",\n\t\t\t   gpu_freq * GT_FREQUENCY_MULTIPLIER,\n\t\t\t   ((ia_freq >> 0) & 0xff) * 100,\n\t\t\t   ((ia_freq >> 8) & 0xff) * 100);\n\t}\n\n\tmutex_unlock(&dev_priv->rps.hw_lock);\n\n\treturn 0;\n}",
    "comment": "Retrieves and prints GPU, effective CPU, and effective Ring frequencies for Intel Gen6 and Gen7 chipsets, while protecting access with a mutex lock.",
    "prorec_sum": "Displays a formatted table of GPU, effective CPU, and ring frequencies if supported by the chipset, otherwise reports unsupported hardware.",
    "filter_prorec_sum": "Displays the GPU, effective CPU, and ring frequency table for supported Intel chipsets via a seq_file interface.",
    "prorec_aug_sum": "Outputs GPU, CPU, and ring frequencies in MHz for supported chipsets, iterating measurement points and printing formatted results via the provided stream.",
    "filter_prorec_aug_sum": "Outputs GPU, effective CPU, and Ring frequencies in MHz, iterating supported steps, or reports chipset unsupported if capability check fails.",
    "work_score": {
        "prorec": {
            "summary": "Displays a formatted table of GPU, effective CPU, and ring frequencies if supported by the chipset, otherwise reports unsupported hardware.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function displays a formatted table of GPU, effective CPU, and ring frequencies and that it reports 'unsupported' for hardware not meeting chipset conditions, which aligns with the source code's check for GEN6 or GEN7 and the table output. No inaccuracies are present, and all claims map directly to the code behavior, making them highly specific and accurate.",
                "The summary correctly captures the core purpose: producing a formatted table of GPU, CPU, and ring frequencies when the chipset is supported, and indicating unsupported hardware otherwise. This matches the code's domain-specific functionality. However, it omits important secondary details, such as the Gen6/Gen7 condition specifically, the use of mutex locking/unlocking for thread safety, iteration over frequency ranges from min_delay to max_delay, and reading frequency data via sandybridge_pcode_read. Coverage of secondary behavior-critical semantics is weak and incomplete.",
                "The summary correctly states the primary behavior: outputting a formatted table of GPU, effective CPU, and ring frequencies, and reporting unsupported hardware for non-Gen6/Gen7 chipsets. These are accurate, domain-specific claims matching the code\u2019s conditional check and seq_printf outputs. No contradictory or irrelevant claims are present, and while the gain is moderate due to conciseness, the core semantics are conveyed clearly."
            ]
        },
        "filter_prorec": {
            "summary": "Displays the GPU, effective CPU, and ring frequency table for supported Intel chipsets via a seq_file interface.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function displays GPU, effective CPU, and ring frequencies, and notes that it works with supported Intel chipsets through a seq_file interface. These claims match the source code\u2019s behavior: the code prints these frequency values and checks for supported generations (Gen6/Gen7) via seq_printf, using seq_file as output. No inaccurate or irrelevant claims are present, yielding very high alignment.",
                "The summary accurately identifies that the function outputs a table of GPU, CPU, and ring frequencies, and that it is limited to supported Intel chipsets via the seq_file interface, which matches the core purpose of iterating over supported frequency ranges and printing results. However, it omits secondary details such as the chipset generation checks (GEN6/GEN7), the specific use of mutex locking to protect hardware access, and the `sandybridge_pcode_read` call to obtain frequencies. These missing points limit coverage of important behavior-critical semantics.",
                "The summary correctly identifies the primary purpose of the function: outputting a table of GPU, effective CPU, and ring frequencies for supported Intel chipsets via a seq_file interface. This matches the core loop and output in the code, as well as the chipset check at the start. There are no inaccurate or noisy claims, and the statement is concise, accurate, and semantically aligned with the code behavior. The gain is moderate due to accuracy and correct focus on the primary purpose, though specifics like GEN6/GEN7 chipset limitation or detailed iteration over frequency range are omitted."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nlisting_page (list_info_type *list)\n{\n  /* Grope around, see if we can see a title or subtitle edict coming up\n     soon.  (we look down 10 lines of the page and see if it's there)  */\n  if ((eject || (on_page >= (unsigned int) paper_height))\n      && paper_height != 0)\n    {\n      unsigned int c = 10;\n      int had_title = 0;\n      int had_subtitle = 0;\n\n      page++;\n\n      while (c != 0 && list)\n\t{\n\t  if (list->edict == EDICT_SBTTL && !had_subtitle)\n\t    {\n\t      had_subtitle = 1;\n\t      subtitle = list->edict_arg;\n\t    }\n\t  if (list->edict == EDICT_TITLE && !had_title)\n\t    {\n\t      had_title = 1;\n\t      title = list->edict_arg;\n\t    }\n\t  list = list->next;\n\t  c--;\n\t}\n\n      if (page > 1)\n\t{\n\t  fprintf (list_file, \"\\f\");\n\t}\n\n      fprintf (list_file, \"%s %s \\t\\t\\tpage %d\\n\", LISTING_HEADER, fn, page);\n      fprintf (list_file, \"%s\\n\", title);\n      fprintf (list_file, \"%s\\n\", subtitle);\n      on_page = 3;\n      eject = 0;\n    }\n}",
    "comment": "The function checks for titles and subtitles in a list before printing the current page header, title, and subtitle to a file.",
    "prorec_sum": "Generates a formatted \u201cGAS LISTING\u201d page header and prints stored source and location lines to the listing output file.",
    "filter_prorec_sum": "Generates a formatted \u201cGAS LISTING\u201d page header and outputs associated title and subtitle strings to the listing file stream.",
    "prorec_aug_sum": "Generates a formatted \u201cGAS LISTING\u201d page header and prints stored title and subtitle lines to the listing output file.",
    "filter_prorec_aug_sum": "Generates a formatted \"GAS LISTING\" page header and outputs associated title and subtitle lines to the listing file stream.",
    "work_score": {
        "prorec": {
            "summary": "Generates a formatted \u201cGAS LISTING\u201d page header and prints stored source and location lines to the listing output file.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims that the function generates a formatted 'GAS LISTING' page header and prints stored source and location lines. While the header generation is partially accurate\u2014since the code writes a header with LISTING_HEADER, filename, page number, title, and subtitle\u2014there is no evidence of printing stored source or location lines; instead, it only handles title and subtitle detection and writes them. This means a significant portion of the claim, specifically about printing source and location lines, is inaccurate.",
                "The summary claims it generates a 'GAS LISTING' page header and prints stored source/location lines, but the source code shows it builds and prints a header including title, subtitle, and page number when certain conditions are met, without any evidence of printing stored source or location lines. The core purpose\u2014detecting upcoming title/subtitle within 10 lines and formatting the page header\u2014is missing from the summary, and the stated behavior about source/location lines is inaccurate.",
                "The summary contains a FATAL inaccuracy about the PRIMARY PURPOSE: it claims the function prints stored source and location lines, but the code only writes a header and optional title/subtitle without outputting any stored source/location data. This misstates the core I/O behavior of the function. While the mention of generating a formatted page header is partially accurate, the severe misrepresentation of what is printed makes the summary untrustworthy."
            ]
        },
        "filter_prorec": {
            "summary": "Generates a formatted \u201cGAS LISTING\u201d page header and outputs associated title and subtitle strings to the listing file stream.",
            "score": [
                0.6,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function generates a formatted page header and outputs title and subtitle to the listing file stream, which matches the observed fprintf calls in the source code. However, it inaccurately specifies the header content as \u201cGAS LISTING,\u201d which is not evidenced in the source (the header uses LISTING_HEADER and fn). Aside from this discrepancy, the description aligns with the function\u2019s behavior, resulting in only partial accuracy.",
                "The summary accurately identifies that the function generates a listing page header and outputs the title and subtitle to the listing file, which matches the core purpose of the code. However, it omits key conditional logic (only executes when page eject conditions are met), the search for title/subtitle within the next 10 list entries, updating page count, outputting a form feed for pages beyond the first, and resetting state variables. These omissions weaken coverage of secondary, behavior-critical semantics.",
                "The summary correctly states that the function outputs a page header with title and subtitle to the listing file, aligning with the code\u2019s behavior of printing a header, title, and subtitle. However, the description omits relevant conditional triggers, such as checking `eject` or `on_page` against `paper_height`, and limiting lookahead to 10 list entries to find these strings. The gain is moderate due to its generic phrasing and lack of operational detail, but no factual errors are present and noise is minimal."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_multifit_fdfsolver_test (const gsl_multifit_fdfsolver * s,\n                             const double xtol, const double gtol,\n                             const double ftol, int *info)\n{\n  int status;\n  double gnorm, fnorm, phi;\n\n  *info = 0;\n\n  status = gsl_multifit_test_delta(s->dx, s->x, xtol*xtol, xtol);\n  if (status == GSL_SUCCESS)\n    {\n      *info = 1;\n      return GSL_SUCCESS;\n    }\n\n  /* compute gradient g = J^T f */\n  (s->type->gradient) (s->state, s->g);\n\n  /* compute gnorm = max_i( g_i * max(x_i, 1) ) */\n  gnorm = scaled_infnorm(s->x, s->g);\n\n  /* compute fnorm = ||f|| */\n  fnorm = gsl_blas_dnrm2(s->f);\n  phi = 0.5 * fnorm * fnorm;\n\n  if (gnorm <= gtol * GSL_MAX(phi, 1.0))\n    {\n      *info = 2;\n      return GSL_SUCCESS;\n    }\n\n#if 0\n  if (dfnorm <= ftol * GSL_MAX(fnorm, 1.0))\n    {\n      *info = 3;\n      return GSL_SUCCESS;\n    }\n#endif\n\n  return GSL_CONTINUE;\n}",
    "comment": "Evaluates the convergence of a multifit solver by checking parameter changes, gradient norms, and function norms against specified tolerances.",
    "prorec_sum": "Checks nonlinear fit convergence using delta and residual norms, updating status and returning codes based on scaled residual magnitude thresholds.",
    "filter_prorec_sum": "Checks nonlinear fit solver convergence using parameter changes and residual norms, updating status codes or invoking callbacks when thresholds are met.",
    "prorec_aug_sum": "Tests convergence of a GSL multifit solver using delta and residual norms, updating status codes based on tolerance and scaled Jacobian step magnitude.",
    "filter_prorec_aug_sum": "Tests convergence of a GSL multifit solver by comparing delta, residual norms, and Jacobian scaling, then sets the termination status accordingly.",
    "work_score": {
        "prorec": {
            "summary": "Checks nonlinear fit convergence using delta and residual norms, updating status and returning codes based on scaled residual magnitude thresholds.",
            "score": [
                0.9,
                0.6,
                0.5
            ],
            "reason": [
                "The summary correctly identifies that the function checks nonlinear fit convergence, uses delta and residual norms, and updates status with codes based on thresholds, which aligns with the code's use of gsl_multifit_test_delta, scaled_infnorm, and gtol. However, it omits some specifics such as handling of *info values (1 and 2) and the exact conditions involving phi. All claims made are accurate but somewhat generic, reflecting the core semantics without introducing inaccuracies.",
                "The summary correctly identifies that the function checks convergence for a nonlinear fit using delta and residual norms, and that it updates status and returns codes based on thresholds. This matches the core purpose of the function, which is to test solver convergence using changes in parameters and scaled gradient norms and set *info accordingly. However, the summary omits several specifics: it does not mention the separate handling of delta (xtol) versus gradient norm (gtol), the calculation of gnorm via scaled_infnorm, the computation of fnorm and phi, or the precise criteria for setting *info values. Secondary details such as the ignored ftol branch are also missing.",
                "The summary correctly identifies that the function checks for convergence in a nonlinear fit using delta and norms, and that it updates a status code based on thresholds. However, it omits key specifics: the first check compares parameter changes (via gsl_multifit_test_delta) to xtol, the second uses a scaled gradient norm versus gtol and a function norm-derived phi, while no check on residual magnitude alone (ftol) is active. The term 'scaled residual magnitude' is inaccurate here, as the code scales the gradient norm, not residuals. This is a minor semantic mismatch but not a fatal contradiction. Overall, gain is low because the description is too generic and does not cover the detailed stopping conditions, but noise is not overwhelming."
            ]
        },
        "filter_prorec": {
            "summary": "Checks nonlinear fit solver convergence using parameter changes and residual norms, updating status codes or invoking callbacks when thresholds are met.",
            "score": [
                0.6,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function checks convergence of a nonlinear fit solver using parameter changes and residual norms, and updates status codes accordingly. However, it inaccurately adds that callbacks are invoked when thresholds are met, which is not present in the source code. This extra incorrect detail reduces overall accuracy, making roughly two-thirds of the claims accurate and the rest misleading.",
                "The summary correctly states that the function checks nonlinear fit solver convergence using parameter changes and residual norms, which aligns with the core purpose of testing delta and gradient-based criteria against tolerances. However, it inaccurately mentions invoking callbacks, which is not present in the source, and omits specific details such as scaled infinity norm calculation, the exact gradient computation method, phi derivation, and the `info` codes for different convergence conditions. Coverage of secondary behavior is minimal, and critical internal computations and branch logic are missing.",
                "The summary correctly describes the convergence check based on parameter changes and residual norms, and mentions updating status codes, which aligns with the code's logic. However, it inaccurately adds that callbacks are invoked when thresholds are met, which is not present in the source code. This is a FATAL error since it misstates a core side effect of the function. The remaining accurate claims are generic, so the net benefit is very low."
            ]
        }
    }
}
{
    "source_code": "\nZSTD_CStream* ZSTD_createCStream_advanced(ZSTD_customMem customMem)\n{\n    ZSTD_CStream* zcs;\n\n    if (!customMem.customAlloc && !customMem.customFree) customMem = defaultCustomMem;\n    if (!customMem.customAlloc || !customMem.customFree) return NULL;\n\n    zcs = (ZSTD_CStream*)ZSTD_malloc(sizeof(ZSTD_CStream), customMem);\n    if (zcs==NULL) return NULL;\n    memset(zcs, 0, sizeof(ZSTD_CStream));\n    memcpy(&zcs->customMem, &customMem, sizeof(ZSTD_customMem));\n    zcs->cctx = ZSTD_createCCtx_advanced(customMem);\n    if (zcs->cctx == NULL) { ZSTD_freeCStream(zcs); return NULL; }\n    return zcs;\n}",
    "comment": "Creates and initializes a ZSTD_CStream object with custom memory allocation, returning NULL on failure or invalid parameters.",
    "prorec_sum": "Allocates and initializes a 200-byte structure with provided callback functions and parameters, invoking a secondary setup routine before returning the created object.",
    "filter_prorec_sum": "Allocates and initializes a 200\u2011byte structure with provided function pointers and context data, invoking a secondary setup routine before returning the created object.",
    "prorec_aug_sum": "Allocates and initializes a 200-byte structure with function callbacks and parameters, then performs a secondary setup step, returning the structure on success.",
    "filter_prorec_aug_sum": "Allocates and initializes a 200\u2011byte structure with provided callback pointers and parameters, invoking a secondary setup routine and cleaning up on failure.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a 200-byte structure with provided callback functions and parameters, invoking a secondary setup routine before returning the created object.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary makes several specific claims that do not match the source code. It states the structure is 200 bytes, but the code allocates sizeof(ZSTD_CStream) without specifying a fixed size. It also describes 'provided callback functions and parameters', which is overly vague and omits the explicit handling of custom memory alloc/free pointers. Additionally, it incorrectly condenses the flow as invoking a secondary setup routine before returning, without noting the multiple NULL checks and cleanup steps. These mismatches mean most claims are inaccurate.",
                "The summary misstates critical details from the source code, such as incorrectly claiming a 200-byte structure instead of using sizeof(ZSTD_CStream), and referring to 'callback functions and parameters' rather than the custom memory alloc/free function pointers. The description omits the core purpose of creating and initializing a ZSTD_CStream with custom memory management and a compression context via ZSTD_createCCtx_advanced. While it mentions allocation, initialization, and a secondary setup routine, these are too generic and do not accurately capture the domain-specific core operation. Key branches for defaulting customMem, handling NULL checks, and freeing resources on failure are missing.",
                "The summary contains a major inaccuracy: it specifies '200-byte structure,' which is not present in the source code and depends on sizeof(ZSTD_CStream), making this a fabricated detail. It also incorrectly states 'provided callback functions and parameters' without accurately reflecting the validation of custom alloc/free fields. While it mentions invoking a secondary setup routine (ZSTD_createCCtx_advanced) before returning, the size claim and vague parameter description contradict the actual code. This represents a FATAL error on the core allocation detail, outweighing any accurate parts."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a 200\u2011byte structure with provided function pointers and context data, invoking a secondary setup routine before returning the created object.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains multiple inaccuracies: it specifies a '200\u2011byte structure', which contradicts the source code that uses sizeof(ZSTD_CStream) without defining a fixed size. It also omits key correctness details from the function, such as the conditional replacement of customMem with defaultCustomMem, validation of both customAlloc and customFree, and the null checks leading to early returns. While it mentions allocation, initialization, and invoking a secondary setup routine, these are generic, low\u2011info descriptions that cannot be fully verified from the source. Overall, fewer than half of the claims are accurate.",
                "The summary incorrectly specifies allocating a 200\u2011byte structure, which contradicts the source code\u2019s use of sizeof(ZSTD_CStream) (actual size is unknown here). It fails to mention the core purpose of creating a ZSTD compression stream with custom memory management and advanced CCtx creation, which is the main domain\u2011specific action. Although it references allocation, initialization, and a secondary setup routine, it omits key details like handling default memory functions, null checks, and cleanup on failure. The core intent is not accurately covered, and secondary behaviors are only vaguely touched with inaccuracies.",
                "The summary inaccurately states that the function allocates a 200\u2011byte structure, whereas the code allocates sizeof(ZSTD_CStream), whose size is not specified and may differ. This is a specific and verifiable domain claim about the core allocation behavior, making it a FATAL error on the primary purpose. It also omits key conditional logic for validating and defaulting custom memory handlers. While it correctly describes initialization and a secondary setup routine, the severe inaccuracy on structure size critically undermines trustworthiness."
            ]
        }
    }
}
{
    "source_code": "static enum mu_filter_result\n_crlfdot_decoder (void *xd,\n\t\t  enum mu_filter_command cmd,\n\t\t  struct mu_filter_io *iobuf)\n{\n  int *pstate = xd;\n  size_t i, j;\n  const unsigned char *iptr;\n  size_t isize;\n  char *optr;\n  size_t osize;\n\n  switch (cmd)\n    {\n    case mu_filter_init:\n      *pstate = crlfdot_decode_init;\n      return mu_filter_ok;\n      \n    case mu_filter_done:\n      return mu_filter_ok;\n      \n    default:\n      break;\n    }\n  \n  iptr = (const unsigned char *) iobuf->input;\n  isize = iobuf->isize;\n  optr = iobuf->output;\n  osize = iobuf->osize;\n\n  for (i = j = 0; *pstate != crlfdot_decode_end && i < isize && j < osize; i++)\n    {\n      unsigned char c = *iptr++;\n\n      if (c == '\\r')\n\t{\n\t  if (i + 1 == isize)\n\t    break;\n\t  *pstate = new_decode_state (*pstate, c);\n\t  if (*iptr == '\\n')\n\t    continue;\n\t}\n      else if (c == '.' &&\n\t       (*pstate == crlfdot_decode_init ||\n\t\t*pstate == crlfdot_decode_crlf))\n\t{\n\t  /* Make sure we have two more characters in the buffer */\n\t  if (i + 2 == isize)\n\t    break;\n\t  *pstate = new_decode_state (*pstate, c);\n\t  if (*iptr != '\\r')\n\t    continue;\n\t}\n      else\n\t*pstate = new_decode_state (*pstate, c);\n      optr[j++] = c;\n    }\n  \n  if (*pstate == crlfdot_decode_end)\n    {\n      j -= 2; /* remove the trailing .\\n */\n      iobuf->eof = 1;\n    }\n  iobuf->isize = i;\n  iobuf->osize = j;\n  return mu_filter_ok;\n}",
    "comment": "Decodes input data by processing CRLF sequences and dots, modifying the state and output buffer accordingly, until reaching the end condition.",
    "prorec_sum": "Parses bytes from an input buffer into a destination, handling carriage returns, dots, and updating parsing state and processed lengths.",
    "filter_prorec_sum": "Processes an input byte stream, updating a parser state and output buffer while handling carriage return, line feed, and period characters with special rules.",
    "prorec_aug_sum": "Parses bytes from an input buffer into an output buffer while updating a parsing state and handling carriage return and period as special cases.",
    "filter_prorec_aug_sum": "Parses bytes from an input buffer into a destination buffer, updating state and handling carriage return, line feed, and period characters with specific rules.",
    "work_score": {
        "prorec": {
            "summary": "Parses bytes from an input buffer into a destination, handling carriage returns, dots, and updating parsing state and processed lengths.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly captures the core behavior of the function \u2014 reading from an input buffer to an output buffer, processing carriage returns and dots, updating parsing state, and adjusting processed byte counts \u2014 all of which are reflected in the source code. It omits some finer details like handling EOF and specific state conditions, but the claims made are accurate and relevant to code semantics.",
                "The summary correctly describes that the function reads bytes from the input buffer to the output buffer, manages carriage returns and dots, updates parsing state, and tracks processed lengths, which aligns with the core purpose of decoding CRLF-dot sequences while maintaining state. However, it omits critical details such as the specific CRLF-dot termination handling, early break conditions when buffer limits are reached, removal of trailing '.\\n', and setting the EOF flag on completion. These omissions result in incomplete coverage of key behavior-critical semantics.",
                "The summary\u2019s single claim about parsing bytes, handling carriage returns and dots, updating state, and processed lengths is broadly correct and matches the source code\u2019s core behavior. However, it is generic and omits key specifics such as special handling of CRLF-dot sequences, EOF detection, and removal of trailing data. There are no inaccurate or contradictory statements (no FATAL), but the gain is low due to lack of detail, and noise is minimal."
            ]
        },
        "filter_prorec": {
            "summary": "Processes an input byte stream, updating a parser state and output buffer while handling carriage return, line feed, and period characters with special rules.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly describes the core behavior: processing an input byte stream, updating parser state, and handling CR, LF, and '.' with special rules, all of which are evident in the source code's loop and conditional handling. There are no contradictory or irrelevant claims, and while the description is high level, it is accurate in targeting the code's semantics.",
                "The summary accurately describes that the function processes an input byte stream, updates parser state, and applies special rules for CR, LF, and period characters, which aligns with the core purpose of decoding CRLF-dot sequences. However, it omits several important secondary behaviors from the source code, such as initializing and ending states via commands, handling buffer limits, breaking on incomplete sequences, stripping the trailing '.\\n', and setting EOF flag. Coverage of critical branching and edge cases is missing, so while the core is covered, the secondary details are sparse.",
                "The summary accurately captures the core function purpose: processing an input byte stream, updating parser state, and applying special handling for carriage return, line feed, and period characters, which matches the code\u2019s CRLF and dot decoding logic. There are no inaccurate or contradictory claims, but the description is generic, lacking mention of key behaviors such as EOF handling, removal of trailing dot-newline, and initialization/done commands. This limits its informational gain despite being correct."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\ntry_load_plugin (const char *pname, bfd *abfd, int *has_plugin_p)\n{\n  void *plugin_handle;\n  struct ld_plugin_tv tv[4];\n  int i;\n  ld_plugin_onload onload;\n  enum ld_plugin_status status;\n\n  *has_plugin_p = 0;\n\n  plugin_handle = dlopen (pname, RTLD_NOW);\n  if (!plugin_handle)\n    {\n      _bfd_error_handler (\"%s\\n\", dlerror ());\n      return 0;\n    }\n\n  onload = dlsym (plugin_handle, \"onload\");\n  if (!onload)\n    goto err;\n\n  i = 0;\n  tv[i].tv_tag = LDPT_MESSAGE;\n  tv[i].tv_u.tv_message = message;\n\n  ++i;\n  tv[i].tv_tag = LDPT_REGISTER_CLAIM_FILE_HOOK;\n  tv[i].tv_u.tv_register_claim_file = register_claim_file;\n\n  ++i;\n  tv[i].tv_tag = LDPT_ADD_SYMBOLS;\n  tv[i].tv_u.tv_add_symbols = add_symbols;\n\n  ++i;\n  tv[i].tv_tag = LDPT_NULL;\n  tv[i].tv_u.tv_val = 0;\n\n  status = (*onload)(tv);\n\n  if (status != LDPS_OK)\n    goto err;\n\n  *has_plugin_p = 1;\n\n  abfd->plugin_format = bfd_plugin_no;\n\n  if (!claim_file)\n    goto err;\n\n  if (!try_claim (abfd))\n    goto err;\n\n  abfd->plugin_format = bfd_plugin_yes;\n\n  return 1;\n\n err:\n  return 0;\n}",
    "comment": "Loads a plugin from a specified path, initializes it, and claims a file if successful, returning the status of the operation.",
    "prorec_sum": "Loads a shared library, invokes its \"onload\" entry with callbacks, and updates file state flags based on plugin-provided data via lseek operations.",
    "filter_prorec_sum": "Loads a shared library, executes its \"onload\" routine with callbacks, and conditionally updates flags and state based on file descriptor operations.",
    "prorec_aug_sum": "Loads a shared library, invokes its \"onload\" entry with callbacks, and updates flags and file position based on plugin-provided data.",
    "filter_prorec_aug_sum": "Loads a shared library, calls its `onload` entry with callbacks, and updates state based on optional file descriptor and handler results.",
    "work_score": {
        "prorec": {
            "summary": "Loads a shared library, invokes its \"onload\" entry with callbacks, and updates file state flags based on plugin-provided data via lseek operations.",
            "score": [
                0.3,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function loads a shared library and invokes its 'onload' entry with callbacks, which matches the dlopen, dlsym, and tv array setup in the source code. However, it inaccurately describes 'updates file state flags based on plugin-provided data via lseek operations'\u2014the code updates plugin_format flags and checks claim_file/try_claim without any lseek usage. This introduces a semantic contradiction, lowering accuracy to less than half of the claims.",
                "The summary identifies loading a shared library and invoking its 'onload' entry with callbacks, which matches the core code behavior of using dlopen/dlsym and calling the plugin's initialization with a list of hooks. However, it inaccurately claims updates based on 'lseek operations', which are absent from the source code. It also omits key details about specific hooks registered, status checks, error handling, and the changes to 'abfd->plugin_format' based on claim_file and try_claim outcomes, thus coverage of secondary semantics is weak.",
                "The summary correctly states that the function loads a shared library and invokes its 'onload' entry with callbacks, which matches the code. However, it inaccurately claims updates to file state flags are based on plugin-provided data via lseek operations\u2014there are no lseek operations in the source, making this a false assertion about key behavior. This is a FATAL error on describing the side effect logic, significantly undermining trust. Accurate points are generic and low-info, with the worst failure mode being the incorrect lseek claim."
            ]
        },
        "filter_prorec": {
            "summary": "Loads a shared library, executes its \"onload\" routine with callbacks, and conditionally updates flags and state based on file descriptor operations.",
            "score": [
                0.8,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function loads a shared library and executes its 'onload' routine with callbacks, which matches the code\u2019s use of dlopen, dlsym, and the tv array setup passed to onload. It also notes conditional updating of flags and state, aligning with updates to *has_plugin_p and abfd->plugin_format after checks and try_claim. However, mentioning 'file descriptor operations' is inaccurate since the code operates on a bfd object and plugin claim logic, not low-level file descriptors. Despite this, most claims are accurate, giving strong coverage of the function\u2019s semantics.",
                "The summary correctly identifies that the function loads a shared library and calls its \"onload\" routine with callbacks, aligning with the core purpose of attempting to initialize a plugin via dlopen/dlsym. However, it inaccurately describes the conditionals as based on file descriptor operations, whereas the code actually checks plugin status, the presence of a claim_file hook, and the success of try_claim, updating bfd->plugin_format accordingly. It omits key secondary details such as error handling via _bfd_error_handler, specific LDPT_* tags assigned, and the exact plugin_format changes.",
                "The summary correctly states that the function loads a shared library and executes its 'onload' routine with callbacks, which matches the presence of dlopen, dlsym, and the tv-tag setup in the code. However, it inaccurately describes the subsequent behavior as conditional updates based on file descriptor operations, whereas in the source code the conditions depend on plugin status and whether the file is claimed via try_claim. This is a semantic mismatch targeting the core behavior after the onload, making it a FATAL error regarding the primary purpose of state updates."
            ]
        }
    }
}
{
    "source_code": "static int\nxmlDOMWrapNSNormGatherInScopeNs(xmlNsMapPtr *map,\n\t\t\t\txmlNodePtr node)\n{\n    xmlNodePtr cur;\n    xmlNsPtr ns;\n    xmlNsMapItemPtr mi;\n    int shadowed;\n\n    if ((map == NULL) || (*map != NULL))\n\treturn (-1);\n    if ((node == NULL) || (node->type == XML_NAMESPACE_DECL))\n        return (-1);\n    /*\n    * Get in-scope ns-decls of @parent.\n    */\n    cur = node;\n    while ((cur != NULL) && (cur != (xmlNodePtr) cur->doc)) {\n\tif (cur->type == XML_ELEMENT_NODE) {\n\t    if (cur->nsDef != NULL) {\n\t\tns = cur->nsDef;\n\t\tdo {\n\t\t    shadowed = 0;\n\t\t    if (XML_NSMAP_NOTEMPTY(*map)) {\n\t\t\t/*\n\t\t\t* Skip shadowed prefixes.\n\t\t\t*/\n\t\t\tXML_NSMAP_FOREACH(*map, mi) {\n\t\t\t    if ((ns->prefix == mi->newNs->prefix) ||\n\t\t\t\txmlStrEqual(ns->prefix, mi->newNs->prefix)) {\n\t\t\t\tshadowed = 1;\n\t\t\t\tbreak;\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\t\t    /*\n\t\t    * Insert mapping.\n\t\t    */\n\t\t    mi = xmlDOMWrapNsMapAddItem(map, 0, NULL,\n\t\t\tns, XML_TREE_NSMAP_PARENT);\n\t\t    if (mi == NULL)\n\t\t\treturn (-1);\n\t\t    if (shadowed)\n\t\t\tmi->shadowDepth = 0;\n\t\t    ns = ns->next;\n\t\t} while (ns != NULL);\n\t    }\n\t}\n\tcur = cur->parent;\n    }\n    return (0);\n}",
    "comment": "Gathers in-scope namespace declarations from the given node's ancestors and updates the namespace mapping, avoiding shadowed prefixes.",
    "prorec_sum": "Processes an XML namespace list, matching prefixes with existing entries and adding new ones using a provided construction routine.",
    "filter_prorec_sum": "Traverses XML node namespaces, matching names with an existing set, and adds unmatched namespaces to the target collection using xmlStrEqual for comparison.",
    "prorec_aug_sum": "Traverses XML node structures, matching element names, and adds corresponding entries to a collection using xmlStrEqual-based comparisons.",
    "filter_prorec_aug_sum": "Traverses XML node chains, matching names with an existing set, and adds missing nodes using xmlStrEqual comparisons until traversal completes or fails.",
    "work_score": {
        "prorec": {
            "summary": "Processes an XML namespace list, matching prefixes with existing entries and adding new ones using a provided construction routine.",
            "score": [
                0.6,
                0.4,
                0.6
            ],
            "reason": [
                "The summary captures part of the domain semantics \u2014 iterating over existing XML namespaces, matching prefixes, and adding new ones \u2014 which aligns with the code's behavior using xmlDOMWrapNsMapAddItem. However, it is incomplete: it omits important conditions such as initial parameter validation, traversal up the parent chain, handling in-scope namespace declarations, and skipping shadowed prefixes. While the stated claim is accurate, it provides a narrow view of the function\u2019s behavior, leading to only partial coverage of key semantics.",
                "The summary correctly notes that the function matches namespace prefixes against existing entries and adds new ones, which aligns with the core behavior of gathering in-scope XML namespaces and mapping them. However, it omits key specifics: the traversal of ancestor elements, skipping of shadowed prefixes based on the namespace map, handling of null parameters and invalid node types, and return codes for error conditions. The core purpose of gathering namespaces from ancestor nodes is only partially implied and not explicitly covered, and secondary behavior-critical details are largely missing.",
                "The summary correctly notes the handling of XML namespace lists and matching prefixes before adding new entries, which aligns with the code\u2019s iteration over nsDef and prefix-shadow checks using XML_NSMAP_FOREACH and xmlStrEqual. However, it omits critical context such as the in-scope namespace gathering up the ancestor chain, the skip of XML_NAMESPACE_DECL nodes, and null parameter checks. The claims are mostly accurate but are generic and do not convey the detailed control flow or termination conditions, resulting in low specificity and low gain. Noise is minimal and no fatal error is present."
            ]
        },
        "filter_prorec": {
            "summary": "Traverses XML node namespaces, matching names with an existing set, and adds unmatched namespaces to the target collection using xmlStrEqual for comparison.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function traverses XML node namespaces, compares names using xmlStrEqual, and adds unmatched ones to the target collection, which matches the code\u2019s behavior of iterating over xmlNs objects, checking for shadowed prefixes, and inserting new namespace mappings. However, it omits important accuracy details such as the initialization and error checks for map and node, the specific handling of shadowed prefixes via both pointer equality and xmlStrEqual, and the traversal stopping conditions. Despite these omissions, the core functional description is mostly aligned with the source code.",
                "The summary covers part of the core behavior by noting traversal of XML node namespaces, comparison with existing ones using xmlStrEqual, and adding unmatched ones. However, it omits critical specifics: the traversal is up the ancestry chain to collect in-scope namespace declarations, skips shadowed prefixes, uses xmlDOMWrapNsMapAddItem with specific parameters, and handles error cases and shadow depth adjustments. The description of the target as a 'collection' is vague and does not clearly align with the namespace map structure. Secondary behaviors such as initial parameter checks and return codes are missing.",
                "The summary correctly notes traversal of XML node namespaces, matching via xmlStrEqual, and adding unmatched namespaces to a collection, which matches the core loop and comparison logic in the code. However, it omits important details such as skipping shadowed prefixes, handling of multiple nsDefs, error conditions when map/node are NULL or invalid, and the specific insertion through xmlDOMWrapNsMapAddItem including shadowDepth. There are no factual inaccuracies, but the gain is low due to the generic and incomplete coverage of key behaviors, and minimal insight beyond basic comparison and addition logic."
            ]
        }
    }
}
{
    "source_code": "\nssize_t led_trigger_show(struct device *dev, struct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct led_classdev *led_cdev = dev_get_drvdata(dev);\n\tstruct led_trigger *trig;\n\tint len = 0;\n\n\tdown_read(&triggers_list_lock);\n\tdown_read(&led_cdev->trigger_lock);\n\n\tif (!led_cdev->trigger)\n\t\tlen += sprintf(buf+len, \"[none] \");\n\telse\n\t\tlen += sprintf(buf+len, \"none \");\n\n\tlist_for_each_entry(trig, &trigger_list, next_trig) {\n\t\tif (led_cdev->trigger && !strcmp(led_cdev->trigger->name,\n\t\t\t\t\t\t\ttrig->name))\n\t\t\tlen += sprintf(buf+len, \"[%s] \", trig->name);\n\t\telse\n\t\t\tlen += sprintf(buf+len, \"%s \", trig->name);\n\t}\n\tup_read(&led_cdev->trigger_lock);\n\tup_read(&triggers_list_lock);\n\n\tlen += sprintf(len+buf, \"\\n\");\n\treturn len;\n}",
    "comment": "Retrieves the current LED trigger state and lists available triggers, marking the active trigger with brackets in the output buffer.",
    "prorec_sum": "Formats a device-related status string into the provided buffer, listing active items or \u201cnone\u201d, and returns the total output length including newline.",
    "filter_prorec_sum": "Formats a status string into `a11` listing active entries or \"none\", then appends each matching item name with optional formatting.",
    "prorec_aug_sum": "Formats a string into the provided buffer listing \u201cnone\u201d or bracketed entries from a global list, then appends a newline and returns its length.",
    "filter_prorec_aug_sum": "Builds a textual list of registered items into the output buffer, inserting \"none\" if empty, and appends a newline before returning its length.",
    "work_score": {
        "prorec": {
            "summary": "Formats a device-related status string into the provided buffer, listing active items or \u201cnone\u201d, and returns the total output length including newline.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function formats a status string into the buffer, lists items or 'none', and returns the output length including a newline. These claims are accurate and verifiable against the source code, as the function builds a string of triggers, marks 'none' if no trigger is active, appends a newline, and returns the length. There are no false or irrelevant statements, though the summary omits finer details like marking active triggers with brackets or the locking mechanism.",
                "The summary correctly states that the function formats a status string into a buffer, lists active items or 'none', and returns the total output length including a newline, which aligns with the core purpose of showing LED triggers. However, it omits specific core semantics such as handling the LED trigger list, marking the currently active trigger with brackets, and locking mechanisms for safe concurrent access. While the core idea of formatting and listing is covered, much of the secondary detail about triggers and their representation is missing.",
                "The summary contains mostly accurate information: it correctly notes that the function formats a status string into the buffer, includes either 'none' or active items, and returns the total length including a newline. However, it omits important specifics from the source code, such as the distinction between '[none]' and 'none', the bracketed marking of the active trigger, and the fact that triggers are listed from a global list under read locks. These omissions reduce gain and specificity, though there are no outright inaccuracies targeting the core semantics."
            ]
        },
        "filter_prorec": {
            "summary": "Formats a status string into `a11` listing active entries or \"none\", then appends each matching item name with optional formatting.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary incorrectly describes the function as formatting into `a11` and listing active entries, which does not correspond to the buffer parameter `buf` in the code. It also omits critical details such as the handling of `[none]` vs. `none` depending on whether a trigger is set, iterating through `trigger_list`, and conditionally surrounding the current trigger name with brackets. These inaccuracies and omissions mean that less than half of the claims accurately reflect the code\u2019s semantics.",
                "The summary vaguely states formatting a status string and listing active entries or \"none\" but fails to identify the core purpose: producing a formatted list of LED triggers, marking the active one in brackets and handling the specific case when no trigger is set. It omits crucial domain context (LED subsystem, trigger_lock and triggers_list_lock usage) and key behaviors such as distinguishing \"[none]\" versus \"none\", iterating over trigger_list, and bracket-marking the current trigger. The wording \"active entries\" is ambiguous and not clearly tied to LED triggers, making coverage of the core purpose incomplete.",
                "The summary incorrectly refers to 'a11' instead of the actual buffer parameter and omits key details such as the locking operations, differentiation between '[none]' and 'none', and the iteration over all triggers with conditional bracket formatting. This constitutes noise and inaccuracy about the function's core string formatting behavior, with no specific high-value GOLD insights. The worst issue is noise rather than a fatal contradiction, but the gain is very low."
            ]
        }
    }
}
{
    "source_code": "\nvoid ping_rcv(struct sk_buff *skb)\n{\n\tstruct sock *sk;\n\tstruct net *net = dev_net(skb->dev);\n\tstruct iphdr *iph = ip_hdr(skb);\n\tstruct icmphdr *icmph = icmp_hdr(skb);\n\t__be32 saddr = iph->saddr;\n\t__be32 daddr = iph->daddr;\n\n\t/* We assume the packet has already been checked by icmp_rcv */\n\n\tpr_debug(\"ping_rcv(skb=%p,id=%04x,seq=%04x)\\n\",\n\t\t skb, ntohs(icmph->un.echo.id), ntohs(icmph->un.echo.sequence));\n\n\t/* Push ICMP header back */\n\tskb_push(skb, skb->data - (u8 *)icmph);\n\n\tsk = ping_v4_lookup(net, saddr, daddr, ntohs(icmph->un.echo.id),\n\t\t\t    skb->dev->ifindex);\n\tif (sk != NULL) {\n\t\tpr_debug(\"rcv on socket %p\\n\", sk);\n\t\tping_queue_rcv_skb(sk, skb_get(skb));\n\t\tsock_put(sk);\n\t\treturn;\n\t}\n\tpr_debug(\"no socket, dropping\\n\");\n\n\t/* We're called from icmp_rcv(). kfree_skb() is done there. */\n}",
    "comment": "Processes received ICMP packets, checks for an associated socket, and queues the packet for delivery if a corresponding socket is found.",
    "prorec_sum": "Processes packet-related buffer data by retrieving header fields, preparing a target buffer, copying data into it, and releasing the associated reference when done.",
    "filter_prorec_sum": "Processes SCTP packet data from buffer pointers, invokes helper routines to copy and prepare payload, and finalizes transmission with reference count management.",
    "prorec_aug_sum": "Processes routing entry data, acquires a related resource, performs an operation using provided parameters, and releases the resource when its reference count reaches zero.",
    "filter_prorec_aug_sum": "Processes routing cache entries by locating a matching destination, performing related operations, and releasing resources when reference counts drop to zero.",
    "work_score": {
        "prorec": {
            "summary": "Processes packet-related buffer data by retrieving header fields, preparing a target buffer, copying data into it, and releasing the associated reference when done.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary contains mostly inaccurate or generic claims. While it notes processing buffer data and retrieving header fields, it incorrectly describes 'preparing a target buffer' and 'copying data into it', which are not reflected in the source code. The code pushes the ICMP header back and queues the skb to a socket if found, rather than copying data into a new buffer. It also omits critical domain-specific behaviors like socket lookup and conditionally queuing or dropping packets. Less than half of the claims are accurate.",
                "The summary gives a vague description of manipulating buffers and headers but fails to capture the core purpose: handling incoming ICMP echo (ping) packets by looking up the corresponding socket, queueing the packet if found, and otherwise dropping it. The claims do not explicitly mention ICMP, socket lookup, or the domain-specific behavior, so the core is not covered. Some generic buffer and header manipulation references are correct but offer minimal secondary detail and miss branches and side effects.",
                "The summary contains mostly inaccurate and overly generic descriptions. Claims like 'retrieving header fields' are accurate to the code, as the function gets IP and ICMP headers, but 'preparing a target buffer' and 'copying data into it' are misleading or incorrect, since the code pushes the ICMP header back rather than copying payloads. The core behavior\u2014looking up a matching socket and queueing the skb\u2014is omitted, meaning that key primary purpose details are missing. The inaccuracies are mostly noise, with very low gain from the few correct points."
            ]
        },
        "filter_prorec": {
            "summary": "Processes SCTP packet data from buffer pointers, invokes helper routines to copy and prepare payload, and finalizes transmission with reference count management.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about processing SCTP packet data, copying payloads, and finalizing transmission are entirely inaccurate for the provided code. The source code handles ICMP echo (ping) packet reception, uses helper functions for socket lookup and queuing, and does not involve SCTP or transmission logic. All claims are unrelated to the actual function behavior, resulting in no accurate matches.",
                "The summary's claims about processing SCTP packet data, copying payload, and finalizing transmission with reference count management are inaccurate; the source code actually handles ICMP ping packets, pushes headers, looks up matching sockets, queues them if found, and logs or drops otherwise. The core purpose of receiving and routing ICMP echo requests to sockets is entirely missing, and no secondary behaviors from the code are correctly covered.",
                "The summary contains multiple inaccurate claims about the source code\u2019s semantics. It incorrectly identifies the function as processing SCTP packets, copying payloads, and finalizing transmission, while the source actually handles ICMP echo (ping) packet reception, socket lookup, queuing, and reference management. These are fatal inaccuracies about the primary purpose and core I/O behavior, making the description untrustworthy."
            ]
        }
    }
}
{
    "source_code": "static int snd_seq_device_free(struct snd_seq_device *dev)\n{\n\tstruct ops_list *ops;\n\n\tif (snd_BUG_ON(!dev))\n\t\treturn -EINVAL;\n\n\tops = find_driver(dev->id, 0);\n\tif (ops == NULL)\n\t\treturn -ENXIO;\n\n\t/* remove the device from the list */\n\tmutex_lock(&ops->reg_mutex);\n\tlist_del(&dev->list);\n\tops->num_devices--;\n\tmutex_unlock(&ops->reg_mutex);\n\n\tfree_device(dev, ops);\n\tif (dev->private_free)\n\t\tdev->private_free(dev);\n\tkfree(dev);\n\n\tunlock_driver(ops);\n\n\treturn 0;\n}",
    "comment": "Frees a sequencer device by removing it from the list, releasing resources, and invoking the device's private cleanup function if defined.",
    "prorec_sum": "Initializes and detaches internal codec structures, updates linked lists, invokes optional callbacks, and finalizes power or state changes for an audio device.",
    "filter_prorec_sum": "Initializes and detaches a codec-related structure, updates linked list pointers, invokes a codec callback, and performs cleanup before returning success or error.",
    "prorec_aug_sum": "Removes an object from linked lists, decrements its reference counters, invokes a callback, and finalizes related resources if the handle is valid.",
    "filter_prorec_aug_sum": "Removes an allocated object from linked structures, updates related counters, invokes cleanup callbacks, and finalizes the deallocation process for a given handle.",
    "work_score": {
        "prorec": {
            "summary": "Initializes and detaches internal codec structures, updates linked lists, invokes optional callbacks, and finalizes power or state changes for an audio device.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary makes several domain-specific claims (initializing codec structures, finalizing power/state changes) that have no basis in the source code, which deals with freeing a sequencer device, removing it from a list, decrementing a count, invoking optional cleanup callbacks, and releasing resources. While the linked list update and optional callback invocation are accurate, most claims are unrelated or incorrect given the implementation, resulting in less than half of the claims being accurate.",
                "The summary\u2019s claims about initializing codec structures and finalizing power/state changes are inaccurate as they do not match the source code\u2019s semantics, which focus on freeing an ALSA sequencer device, removing it from a linked list, managing a mutex, invoking an optional private_free callback, deallocating memory, and unlocking driver resources. The core purpose of freeing and unregistering a sequencer device is not accurately covered, and most details are unrelated to the actual operation.",
                "The summary contains multiple inaccurate claims about the function's purpose and behavior. It states that the function initializes codec structures and finalizes power or state changes for an audio device, which contradicts the actual source code. The code deals with freeing a sequencer device, updating linked lists, invoking an optional cleanup callback, and releasing memory. The primary purpose and key side effects are misrepresented, constituting a severe FATAL error. There are no accurate, detailed claims to provide positive gain, making the net benefit unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes and detaches a codec-related structure, updates linked list pointers, invokes a codec callback, and performs cleanup before returning success or error.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains multiple inaccuracies: it refers to a codec-related structure and a codec callback, which are not present in the source code. The function actually frees an snd_seq_device, manages a linked list of devices, invokes an optional private_free callback, and returns appropriate error codes or success. While it mentions list updates and cleanup, most claims are inaccurate or irrelevant to the actual code semantics, resulting in less than half of the claims being accurate.",
                "The summary fails to capture the core purpose of freeing a sequencer device from its driver\u2019s list, decrementing the device count, and releasing associated resources. The core is not covered at all\u2014claims about initializing and detaching a codec-related structure are inaccurate, as the code does not deal with codecs or initialization. While it mentions linked list updates, callbacks, and cleanup, these are framed incorrectly relative to the domain semantics and thus do not provide accurate coverage of behavior-critical details.",
                "The summary contains several inaccurate claims: it mentions initializing a codec-related structure, invoking a codec callback, and detaching codecs, none of which are present in the source code. The function actually finds a driver based on the device ID, removes the device from a linked list under a mutex, decrements a device counter, frees resources, and calls a private_free callback if defined. These mismatches are FATAL because they misrepresent the primary purpose and core actions of the function, making the summary misleading and untrustworthy."
            ]
        }
    }
}
{
    "source_code": "static void\nmixed_string_buffer_flush_curr (struct mixed_string_buffer *bp)\n{\n  if (bp->curr_type == utf8_encoded)\n    mixed_string_buffer_flush_utf16_surr (bp);\n  if (bp->curr_type != -1)\n    {\n      if (bp->curr_buflen > 0)\n        {\n          struct mixed_string_segment *segment =\n            segment_alloc (bp->curr_type, bp->curr_buffer, bp->curr_buflen);\n          mixed_string_buffer_add_segment (bp, segment);\n        }\n      bp->curr_buflen = 0;\n    }\n}",
    "comment": "Flushes the current buffer to segments based on its type, handling UTF-8 encoding and resetting the buffer length after addition.",
    "prorec_sum": "Stores the current element data with its type into a dynamically resized list and resets the element\u2019s temporary storage buffer.",
    "filter_prorec_sum": "Appends a new memory-copied data entry with its state code to a dynamically resized list and clears the pending buffer reference.",
    "prorec_aug_sum": "Stores the current state and associated data into a dynamically growing list, allocating memory and copying contents as needed.",
    "filter_prorec_aug_sum": "Stores the current state and associated data into a dynamically resized array, resetting temporary buffers and handling pending operations if flagged.",
    "work_score": {
        "prorec": {
            "summary": "Stores the current element data with its type into a dynamically resized list and resets the element\u2019s temporary storage buffer.",
            "score": [
                0.2,
                0.4,
                0.5
            ],
            "reason": [
                "The summary incorrectly describes the function as storing element data into a dynamically resized list, which is not indicated by the source code. The code actually flushes the current buffer by optionally processing UTF-16 surrogate encoding, allocating a segment, adding it to the buffer, and resetting the length. The claim about a 'dynamically resized list' and 'element\u2019s temporary storage buffer' is imprecise and misaligned with the actual semantics, resulting in most claims being inaccurate.",
                "The summary captures a generic notion of storing data with its type and clearing a buffer, which aligns in part with the function's behavior of creating a segment from the current buffer and adding it to a collection, then resetting the length. However, it misses the core purpose of flushing the current mixed string segment, including the conditional handling for UTF-8 encoded data via a specialized flush function and the checks for valid type and buffer length. These domain-specific operations are critical to the function's semantics and are absent from the summary.",
                "The summary inaccurately describes the code\u2019s behavior, stating it stores element data into a dynamically resized list, which is not explicitly shown in the source. The function checks the current type, flushes UTF-16 surrogates if needed, allocates a segment when there is buffered content, and adds it to the buffer\u2019s segment list, then resets the buffer length. The mismatch between \u2018element\u2019 terminology and actual segment handling is misleading, but there is no severe contradiction on the core purpose. The positive accuracy is limited to noting that data and type are stored and that the buffer is reset, both of which are correct but generic. Noise is noticeable and specific gain is low."
            ]
        },
        "filter_prorec": {
            "summary": "Appends a new memory-copied data entry with its state code to a dynamically resized list and clears the pending buffer reference.",
            "score": [
                0.3,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function appends a memory-copied data entry to a dynamically resized list and clears a pending buffer reference. While the code does add a segment based on current buffer contents and resets the buffer length, there is no explicit evidence of a 'memory-copied' operation or a 'dynamically resized list'. The description omits the conditional utf8 handling and type checks, and introduces inaccuracies about dynamic resizing, making most claims misaligned with the source.",
                "The summary incorrectly describes the function as appending a memory-copied data entry with a state code to a dynamic list, which is too generic and misses the core purpose of flushing the current mixed string buffer. The source code specifically checks for a UTF-8 encoded type to handle UTF-16 surrogate pairs, allocates a mixed string segment if buffered data exists, adds it to the buffer, and resets the length. The core domain action of flushing a typed string buffer, conditional UTF-16 handling, and segment allocation is not mentioned, making the description inaccurate and failing to cover the primary purpose or critical semantics.",
                "The summary incorrectly describes the function as appending a memory-copied data entry with a state code to a dynamically resized list, which is misleading. The source actually flushes the current buffer by optionally transforming UTF-8 data into UTF-16 surrogates, creating a segment object, and adding it to the mixed string buffer. There is no dynamically resized list or explicit state code concept in the code, and the clearing is of the buffer length, not a reference. This constitutes a FATAL in describing the primary purpose and key I/O, making the net benefit unusable."
            ]
        }
    }
}
{
    "source_code": "\nstruct sequence *\nnew_C_string_sequence (const char * delimitor)\n{\n  struct sequence * res = XMALLOC (struct sequence, 1);\n  res->open = rule_new (xustrdup (delimitor), NULL,\n\t\t\trhs_new_single (NULL, 0, Plain_fface),\n\t\t\t__FILE__, __LINE__);\n  res->face = String_fface;\n  res->exceptions = new_C_exceptions ();\n  res->close = words_new (\"C Close: strings\", \"C Close: regex\", 5, 5);\n  words_add_string (res->close,\n\t\t    rule_new (xustrdup (delimitor), NULL,\n\t\t\t      rhs_new_single (NULL, 0, Plain_fface),\n\t\t\t      __FILE__, __LINE__));\n  words_finalize (res->close);\n  return res;\n}",
    "comment": "Creates and initializes a new string sequence structure with a specified delimiter and associated rules for processing strings.",
    "prorec_sum": "Builds and returns a structure describing C string and regex exception patterns, including common escape sequences and matching rules for opening and closing.",
    "filter_prorec_sum": "Initializes a C language string handling structure with escape sequence rules and closure patterns for strings and regular expressions.",
    "prorec_aug_sum": "Constructs and returns a structure grouping C string and regex exceptions with specific escape patterns and related closing definitions.",
    "filter_prorec_aug_sum": "Constructs a C language parsing rule set for strings and regex, including escape sequence exceptions and closing conditions.",
    "work_score": {
        "prorec": {
            "summary": "Builds and returns a structure describing C string and regex exception patterns, including common escape sequences and matching rules for opening and closing.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims that the function describes C string and regex exception patterns and includes common escape sequences and matching rules for opening and closing. While the source code indeed sets up a sequence structure with rules for opening and closing based on the given delimiter and creates a close ruleset mentioning 'C Close: strings' and 'C Close: regex', it does not explicitly handle common escape sequences nor does it describe exception patterns beyond calling new_C_exceptions(). These additional details in the summary are not supported by the code, making several claims inaccurate. Only part of the summary aligns with the actual setup and return of the structure.",
                "The summary claims the function describes C string and regex exception patterns with common escape sequences and matching rules. The source code shows it allocates a 'sequence' struct with specific rules for opening and closing based on a given delimiter, sets a string face, and initializes C exceptions, but it does not mention common escape sequences or regex exceptions as such. The core purpose\u2014creating and configuring a new C string sequence object with delimiter-based rules\u2014is missing or misrepresented, making the core coverage absent and the summary inaccurate.",
                "The summary claims the function describes C string and regex exception patterns with common escape sequences and matching rules, but the source code simply builds a `sequence` struct with specific rule and word objects based on a given delimiter. There is no mention or handling of common escape sequences, nor broad description of exception patterns as stated, making these claims inaccurate. The inaccuracies center on the primary purpose and behavior, which is creating delimiter-based opening/closing rules, leading to a severe mismatch between summary and code semantics."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a C language string handling structure with escape sequence rules and closure patterns for strings and regular expressions.",
            "score": [
                0.5,
                0.3,
                0.2
            ],
            "reason": [
                "The summary claims the function initializes a C string handling structure with escape sequence rules and closure patterns for strings and regular expressions. While it is accurate that the function creates a structure for C strings and sets closure patterns for strings and regex, the mention of escape sequence rules is not evident in the source code, which instead sets up rules based on the given delimiter with Plain_fface and exceptions, without explicit escape handling. This makes some claims inaccurate, resulting in mixed reliability overall.",
                "The summary states it initializes a C string handling structure with escape sequence rules and closure patterns, which loosely reflects the creation of a struct sequence and setting 'open', 'face', 'exceptions', and 'close'. However, it does not explicitly cover the core purpose: constructing a new sequence configured with a specific delimiter, string face, C exceptions, and closure rules containing that same delimiter for both plain strings and regex patterns. The mention of 'escape sequence rules' is inaccurate because the code uses 'Plain_fface' and not explicit escape logic, reducing alignment. Secondary details like the use of delimiter strings in both open and close rules and constants passed to 'words_new' are missing.",
                "The summary claims the function initializes a C language string handling structure with escape sequence rules and closure patterns for strings and regex. The source code shows it allocates a sequence, sets specific face types, creates exceptions, and defines closing words including a given delimiter for strings and regex patterns. However, there is no evidence of escape sequence handling\u2014this is inaccurate and relates to the core purpose of the function, making this a FATAL error. The accurate part about closure patterns for strings and regex is correct but generic. Overall, the severe inaccuracy on core behavior outweighs the limited accurate details."
            ]
        }
    }
}
{
    "source_code": "int mmc_get_phys_format_info(struct burn_drive *d, int *disk_category,\n\t\t\tchar **book_name, int *part_version, int *num_layers,\n\t\t\tint *num_blocks, int flag)\n{\n\tint ret, reply_len, prf;\n\tchar *reply = NULL;\n\tstatic char book_names[][16] = {\n\t\t\"DVD-ROM\", \"DVD-RAM\", \"DVD-R\", \"DVD-RW\",\n\t\t\"HD DVD-ROM\", \"HD DVD-RAM\", \"HD DVD-R\", \"unknown\",\n\t\t\"unknown\", \"DVD+RW\", \"DVD+R\", \"unknown\", \"unknown\",\n\t\t\"unknown\", \"DVD+RW DL\", \"DVD+R DL\", \"unknown\"\n\t};\n\n\tprf = d->current_profile;\n\tif (!(prf == 0x11 || prf == 0x13 || prf == 0x14 || prf == 0x15 ||\n\t      prf == 0x51))\n\t\treturn 0; /* Not a [HD] DVD-R[W] loaded */\n\tret = mmc_read_disc_structure(d, 0, 0, 0x10, 12, &reply,\n\t\t\t\t\t\t\t &reply_len, 0);\n\tif (ret <= 0)\n\t\tgoto ex;\n\tif(reply_len < 12) {\n\t\tlibdax_msgs_submit(libdax_messenger, -1, 0x00000002,\n\t\t\tLIBDAX_MSGS_SEV_DEBUG, LIBDAX_MSGS_PRIO_ZERO,\n\t\t\t\"READ DISC STRUCTURE format 10h: Less than 12 bytes\",\n\t\t\t0, 0);\n\t\t{ret = 0; goto ex;}\n\t}\n\t*disk_category = (reply[0] >> 4) & 0xf;\n\t*book_name = book_names[*disk_category];\n\t*part_version = reply[0] & 0xf;\n\t*num_layers = ((reply[2] >> 5) & 0x3) + 1;\n\t*num_blocks = ((reply[9] << 16) | (reply[10] << 8) | reply[11]) -\n\t              ((reply[5] << 16) | (reply[6] << 8) | reply[7]) + 1;\n\tret = 1;\nex:;\n\tif (reply != NULL)\n\t\tfree(reply);\n\treturn ret;\n}",
    "comment": "Retrieves physical format information of a disc in the drive, including disk category, book name, version, layer count, and block count.",
    "prorec_sum": "Reads and parses disc structure format 0x10h to extract track, address, session, and sector count information, then frees allocated memory.",
    "filter_prorec_sum": "Reads and parses a disc structure format 0x10h from the device, extracting fields into output parameters and logging an error if data is too short.",
    "prorec_aug_sum": "Reads a disc structure format 0x10h from the device, extracts header fields, computes range length, and returns parsed values to callers.",
    "filter_prorec_aug_sum": "Reads and parses optical disc structure format 0x10h data, extracting fields like layer, format, and sector range before freeing allocated memory.",
    "work_score": {
        "prorec": {
            "summary": "Reads and parses disc structure format 0x10h to extract track, address, session, and sector count information, then frees allocated memory.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary introduces several claims about extracting track, address, and session information that are not supported by the source code, which instead retrieves disk category, book name, part version, number of layers, and number of blocks. While it correctly states that the function reads disc structure format 0x10h and frees allocated memory, most domain-specific claims contradict the actual semantics. This results in less than half of the claims being accurate.",
                "The summary incorrectly describes the extracted data as track, address, session, and sector count, which contradicts the source code's actual outputs of disk category, book name, part version, number of layers, and number of blocks. Although it mentions reading format 0x10h and freeing memory, the core purpose\u2014deriving specific DVD/media physical format info from the disc structure\u2014is missing and key details are inaccurate.",
                "The summary claims the function extracts track, address, and session information, which is not supported by the source code. The code actually retrieves disk category, book name, part version, number of layers, and number of blocks. This is a FATAL inaccuracy about the primary purpose and key I/O, making the summary misleading and unusable despite correctly noting that allocated memory is freed."
            ]
        },
        "filter_prorec": {
            "summary": "Reads and parses a disc structure format 0x10h from the device, extracting fields into output parameters and logging an error if data is too short.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function reads and parses disc structure format 0x10h, extracts fields into output parameters, and logs an error if data is too short. These claims align with the source code, which calls mmc_read_disc_structure with format 0x10, assigns values to output pointers, and submits a debug message if reply_len is less than 12. No claims contradict or stray from the code\u2019s semantics, and all are factual and specific to the function\u2019s behavior.",
                "The summary accurately captures the core purpose of reading and parsing the disc structure format 0x10h and extracting its fields into output parameters, as well as logging an error when the data length is insufficient. This matches the function\u2019s main operation in the source code. However, it omits key secondary details such as the initial profile check for specific DVD types, the specific fields extracted (disk category mapped to book name, part version, number of layers, number of blocks), and the freeing of allocated memory, which limits completeness.",
                "The summary correctly identifies that the function reads and parses disc structure format 0x10h, extracts fields into output parameters, and logs a debug-level message if the returned data is insufficient. These are accurate reflections of the code\u2019s semantics, focusing on the primary purpose and core I/O without introducing errors. The claims are concise but somewhat generic, offering moderate insight into the specific behavior."
            ]
        }
    }
}
{
    "source_code": "int aaip_add_acl_st_mode(char *acl_text, mode_t st_mode, int flag)\n{\n char *wpt;\n int tag_types= 0;\n\n tag_types = aaip_cleanout_st_mode(acl_text, &st_mode, 1);\n if(!(tag_types & (4 | 32))) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"user::%c%c%c\\n\",\n           st_mode & S_IRUSR ? 'r' : '-',\n           st_mode & S_IWUSR ? 'w' : '-',\n           st_mode & S_IXUSR ? 'x' : '-');\n }\n if(!(tag_types & (2 | 16 | 1024))) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"group::%c%c%c\\n\",\n         st_mode & S_IRGRP ? 'r' : '-',\n         st_mode & S_IWGRP ? 'w' : '-',\n         st_mode & S_IXGRP ? 'x' : '-');\n }\n if(!(tag_types & (1 | 8))) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"other::%c%c%c\\n\",\n         st_mode & S_IROTH ? 'r' : '-',\n         st_mode & S_IWOTH ? 'w' : '-',\n         st_mode & S_IXOTH ? 'x' : '-');\n }\n if((tag_types & (128 | 256)) && !(tag_types & 512)) {\n   wpt= acl_text + strlen(acl_text);\n   sprintf(wpt, \"mask::%c%c%c\\n\",\n         st_mode & S_IRGRP ? 'r' : '-',\n         st_mode & S_IWGRP ? 'w' : '-',\n         st_mode & S_IXGRP ? 'x' : '-');\n }\n return(1); \n}",
    "comment": "Adds entries for user, group, other, and mask permissions to an ACL string based on the provided `mode_t` and existing ACL tags.",
    "prorec_sum": "Formats and appends user, group, other, and mask permission strings to a buffer based on bit flags in the provided permissions value.",
    "filter_prorec_sum": "Formats and appends user, group, other, and mask permission strings based on access flags into the provided buffer.",
    "prorec_aug_sum": "Formats and appends user, group, other, and mask permission strings to a buffer based on specified access mode bits.",
    "filter_prorec_aug_sum": "Appends formatted user, group, other, and mask permission strings to the buffer based on the provided access mode flags.",
    "work_score": {
        "prorec": {
            "summary": "Formats and appends user, group, other, and mask permission strings to a buffer based on bit flags in the provided permissions value.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function formats and appends permission strings for user, group, other, and mask based on permission bits, which matches the code\u2019s conditional checks using st_mode and the bitwise logic on tag_types. It omits minor details such as the specific conditions under which each category is appended, but all claims target code semantics and are accurate overall.",
                "The summary accurately describes the core function of formatting and appending user, group, other, and mask permission strings based on st_mode bit flags, which matches the source code's primary purpose. It correctly captures that these strings are appended to the provided buffer and conditioned on tag_types bit checks. However, it omits mention of the initial cleaning step via aaip_cleanout_st_mode and the specific conditional logic for when each permission type is added, which are secondary behavior-critical details.",
                "The summary correctly states the core behavior: the function formats and appends user, group, other, and mask permission strings to the ACL text buffer based on mode bit flags. This is a specific and accurate reflection of the source code's main purpose and output logic. There is no contradictory or irrelevant information (no FATAL, minimal noise), but the summary is concise and lacks detail about the conditional nature of appending and preprocessing via aaip_cleanout_st_mode, so informational gain is moderate rather than maximal."
            ]
        },
        "filter_prorec": {
            "summary": "Formats and appends user, group, other, and mask permission strings based on access flags into the provided buffer.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly captures the function\u2019s core behavior of formatting and appending permission strings for user, group, other, and mask based on access flags into the provided buffer. All elements mentioned are directly supported by the code: the function checks tag_types flags, appends the corresponding permissions, and uses the provided acl_text buffer. There are no contradictory or irrelevant claims, making the statement both accurate and aligned with the source code semantics.",
                "The summary accurately captures the core purpose of the function, which is to format and append user, group, other, and mask permission strings derived from mode bits into the provided ACL text buffer when certain tag conditions are not met. It reflects the conditional appending logic based on tag_types flags, covering the main domain operation. However, it omits secondary details like the preceding cleanup call to remove existing mode entries, the exact permission-bit mapping (read/write/execute), and specific tag bit values controlling which entries are added. This limits coverage of other behavior-critical semantics.",
                "The summary correctly captures the primary purpose of the function: formatting and appending permission strings for user, group, other, and mask into the provided buffer based on the mode and tag flags. This matches the source code's logic with calls to sprintf conditioned on tag_types. There are no inaccurate claims, and noise is minimal. While accurate, the summary is somewhat generic and lacks detail about how tag_types control which entries are added, so the gain is moderate rather than high."
            ]
        }
    }
}
{
    "source_code": "int get_counters(struct thread_data *t, struct core_data *c, struct pkg_data *p)\n{\n\tint cpu = t->cpu_id;\n\tunsigned long long msr;\n\n\tif (cpu_migrate(cpu)) {\n\t\tfprintf(stderr, \"Could not migrate to CPU %d\\n\", cpu);\n\t\treturn -1;\n\t}\n\n\tt->tsc = rdtsc();\t/* we are running on local CPU of interest */\n\n\tif (has_aperf) {\n\t\tif (get_msr(cpu, MSR_IA32_APERF, &t->aperf))\n\t\t\treturn -3;\n\t\tif (get_msr(cpu, MSR_IA32_MPERF, &t->mperf))\n\t\t\treturn -4;\n\t}\n\n\tif (do_smi) {\n\t\tif (get_msr(cpu, MSR_SMI_COUNT, &msr))\n\t\t\treturn -5;\n\t\tt->smi_count = msr & 0xFFFFFFFF;\n\t}\n\tif (extra_delta_offset32) {\n\t\tif (get_msr(cpu, extra_delta_offset32, &msr))\n\t\t\treturn -5;\n\t\tt->extra_delta32 = msr & 0xFFFFFFFF;\n\t}\n\n\tif (extra_delta_offset64)\n\t\tif (get_msr(cpu, extra_delta_offset64, &t->extra_delta64))\n\t\t\treturn -5;\n\n\tif (extra_msr_offset32) {\n\t\tif (get_msr(cpu, extra_msr_offset32, &msr))\n\t\t\treturn -5;\n\t\tt->extra_msr32 = msr & 0xFFFFFFFF;\n\t}\n\n\tif (extra_msr_offset64)\n\t\tif (get_msr(cpu, extra_msr_offset64, &t->extra_msr64))\n\t\t\treturn -5;\n\n\t/* collect core counters only for 1st thread in core */\n\tif (!(t->flags & CPU_IS_FIRST_THREAD_IN_CORE))\n\t\treturn 0;\n\n\tif (do_nhm_cstates) {\n\t\tif (get_msr(cpu, MSR_CORE_C3_RESIDENCY, &c->c3))\n\t\t\treturn -6;\n\t\tif (get_msr(cpu, MSR_CORE_C6_RESIDENCY, &c->c6))\n\t\t\treturn -7;\n\t}\n\n\tif (do_snb_cstates)\n\t\tif (get_msr(cpu, MSR_CORE_C7_RESIDENCY, &c->c7))\n\t\t\treturn -8;\n\n\tif (do_dts) {\n\t\tif (get_msr(cpu, MSR_IA32_THERM_STATUS, &msr))\n\t\t\treturn -9;\n\t\tc->core_temp_c = tcc_activation_temp - ((msr >> 16) & 0x7F);\n\t}\n\n\n\t/* collect package counters only for 1st core in package */\n\tif (!(t->flags & CPU_IS_FIRST_CORE_IN_PACKAGE))\n\t\treturn 0;\n\n\tif (do_nhm_cstates) {\n\t\tif (get_msr(cpu, MSR_PKG_C3_RESIDENCY, &p->pc3))\n\t\t\treturn -9;\n\t\tif (get_msr(cpu, MSR_PKG_C6_RESIDENCY, &p->pc6))\n\t\t\treturn -10;\n\t}\n\tif (do_snb_cstates) {\n\t\tif (get_msr(cpu, MSR_PKG_C2_RESIDENCY, &p->pc2))\n\t\t\treturn -11;\n\t\tif (get_msr(cpu, MSR_PKG_C7_RESIDENCY, &p->pc7))\n\t\t\treturn -12;\n\t}\n\tif (do_c8_c9_c10) {\n\t\tif (get_msr(cpu, MSR_PKG_C8_RESIDENCY, &p->pc8))\n\t\t\treturn -13;\n\t\tif (get_msr(cpu, MSR_PKG_C9_RESIDENCY, &p->pc9))\n\t\t\treturn -13;\n\t\tif (get_msr(cpu, MSR_PKG_C10_RESIDENCY, &p->pc10))\n\t\t\treturn -13;\n\t}\n\tif (do_rapl & RAPL_PKG) {\n\t\tif (get_msr(cpu, MSR_PKG_ENERGY_STATUS, &msr))\n\t\t\treturn -13;\n\t\tp->energy_pkg = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_CORES) {\n\t\tif (get_msr(cpu, MSR_PP0_ENERGY_STATUS, &msr))\n\t\t\treturn -14;\n\t\tp->energy_cores = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_DRAM) {\n\t\tif (get_msr(cpu, MSR_DRAM_ENERGY_STATUS, &msr))\n\t\t\treturn -15;\n\t\tp->energy_dram = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_GFX) {\n\t\tif (get_msr(cpu, MSR_PP1_ENERGY_STATUS, &msr))\n\t\t\treturn -16;\n\t\tp->energy_gfx = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_PKG_PERF_STATUS) {\n\t\tif (get_msr(cpu, MSR_PKG_PERF_STATUS, &msr))\n\t\t\treturn -16;\n\t\tp->rapl_pkg_perf_status = msr & 0xFFFFFFFF;\n\t}\n\tif (do_rapl & RAPL_DRAM_PERF_STATUS) {\n\t\tif (get_msr(cpu, MSR_DRAM_PERF_STATUS, &msr))\n\t\t\treturn -16;\n\t\tp->rapl_dram_perf_status = msr & 0xFFFFFFFF;\n\t}\n\tif (do_ptm) {\n\t\tif (get_msr(cpu, MSR_IA32_PACKAGE_THERM_STATUS, &msr))\n\t\t\treturn -17;\n\t\tp->pkg_temp_c = tcc_activation_temp - ((msr >> 16) & 0x7F);\n\t}\n\treturn 0;\n}",
    "comment": "Aggregates packet and byte counters from multiple CPU entries into a single counter array based on the provided old counters.",
    "prorec_sum": "Iterates over indexed structures, aggregating 64-bit values into an output buffer while pausing on concurrent access flags until all entries are processed.",
    "filter_prorec_sum": "Iterates through indexed data structures, aggregating 64-bit values into an output array while synchronizing access using memory pause when contention is detected.",
    "prorec_aug_sum": "Iterates over rule entries, aggregating matched IPv6 packet data into an output array while synchronizing access with spin-wait on shared state flags.",
    "filter_prorec_aug_sum": "Iterates over table entries, accumulating specific 64\u2011bit values into an output array while synchronizing on entry locks and skipping busy entries.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over indexed structures, aggregating 64-bit values into an output buffer while pausing on concurrent access flags until all entries are processed.",
            "score": [
                0.0,
                0.0,
                0.2
            ],
            "reason": [
                "The summary describes iteration over structures, aggregation of 64-bit values, and handling of concurrent access flags, none of which align with the actual source code behavior. The function in the source reads MSR registers for specific CPU, core, and package counters under certain conditions and returns early on errors, without performing aggregation or iteration over multiple entries. All claims fail to match the real semantics, resulting in no accurate claims.",
                "The summary's claims about iterating over indexed structures, aggregating 64-bit values, and pausing on concurrent access flags are unrelated to the source code. The function actually migrates to a specific CPU, reads various MSR registers for thread, core, and package performance and power metrics, handles specific error codes, and processes only certain CPUs based on flags. The core purpose of collecting MSR-based counters is not mentioned, and none of the summary's points accurately reflect the code's semantics.",
                "The summary describes iteration over structures and aggregation of 64-bit values with concurrency pauses, which does not match the actual function. The source code reads MSRs for various CPU/core/package metrics, assigns them to specific fields, and returns early based on thread/core/package flags, without any concurrent access pausing or generic aggregation into an output buffer. This is a FATAL in primary purpose since the described behavior significantly contradicts the core semantics."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates through indexed data structures, aggregating 64-bit values into an output array while synchronizing access using memory pause when contention is detected.",
            "score": [
                0.0,
                0.0,
                0.2
            ],
            "reason": [
                "The summary's claims about iterating through indexed data structures, aggregating 64-bit values, and using memory pause on contention do not align with the source code, which reads various MSR registers for a specific CPU, stores them in struct fields, and returns error codes without any indication of array aggregation or contention handling. All claims are inaccurate as they do not describe the actual function behavior.",
                "The summary describes iterating through indexed data structures and aggregating values with synchronization, which is unrelated to the actual function. The source code reads multiple hardware MSR counters for CPU, core, and package metrics and returns various error codes, with no indication of iteration over generic data structures or memory pause contention. Core purpose and secondary behaviors are entirely missing or are inaccurately represented.",
                "The summary describes iteration over data structures, aggregation of 64-bit values, and synchronization using memory pause during contention, none of which align with the actual function. The source code instead reads various MSR registers for CPU, core, and package metrics, with conditional logic for different hardware features and returns error codes on failure. This mismatch is a severe inaccuracy affecting the primary purpose of the function, making the description unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic R_xlen_t\ncompact_intseq_Get_region(SEXP sx, R_xlen_t i, R_xlen_t n, int *buf)\n{\n    /* should not get here if x is already expanded */\n    CHECK_NOT_EXPANDED(sx);\n\n    SEXP info = COMPACT_SEQ_INFO(sx);\n    R_xlen_t size = COMPACT_INTSEQ_INFO_LENGTH(info);\n    R_xlen_t n1 = COMPACT_INTSEQ_INFO_FIRST(info);\n    int inc = COMPACT_INTSEQ_INFO_INCR(info);\n\n    R_xlen_t ncopy = size - i > n ? n : size - i;\n    if (inc == 1) {\n\tfor (R_xlen_t k = 0; k < ncopy; k++)\n\t    buf[k] = (int) (n1 + k + i);\n\treturn ncopy;\n    }\n    else if (inc == -1) {\n\tfor (R_xlen_t k = 0; k < ncopy; k++)\n\t    buf[k] = (int) (n1 - k - i);\n\treturn ncopy;\n    }\n    else\n\terror(\"compact sequences with increment %d not supported yet\", inc);\n}",
    "comment": "Extracts a specified region from a compact integer sequence into a buffer, handling both increasing and decreasing increments.",
    "prorec_sum": "Generates a sequence of integer indices from compact vector metadata, supporting increments of 1 or -1, and raises errors for unsupported formats.",
    "filter_prorec_sum": "Generates a sequence of integer indices from a compact R vector representation, validating increment support and handling increasing or decreasing sequences.",
    "prorec_aug_sum": "Generates a sequence of integer indices from compact vector metadata, supporting increments of 1 or -1, and raises errors for unsupported increments or expanded vectors.",
    "filter_prorec_aug_sum": "Generates a compact integer sequence from vector metadata, enforcing unexpanded state and rejecting unsupported increments.",
    "work_score": {
        "prorec": {
            "summary": "Generates a sequence of integer indices from compact vector metadata, supporting increments of 1 or -1, and raises errors for unsupported formats.",
            "score": [
                0.9,
                0.8,
                0.8
            ],
            "reason": [
                "The summary correctly reflects that the function derives integer values from compact sequence metadata, supports increments of 1 and -1, and raises an error for unsupported increments. These details align well with the source code\u2019s use of COMPACT_INTSEQ_INFO_* macros, increment conditions, and error handling. Minor imprecision exists in describing the output as 'indices' rather than direct integer values starting from a given first element, but overall the claims are accurate and specific.",
                "The summary accurately describes generating integer sequences from compact vector metadata using increments of 1 or -1, and mentions errors for unsupported formats, matching the core purpose and key branching behavior in the source code. However, it omits some secondary details such as the calculation of the number of items to copy, the role of input parameters i and n, and the requirement that the sequence is not yet expanded, which are important for completeness.",
                "The summary accurately captures the core behavior: it uses compact sequence metadata to generate integer values (indices) with increments of 1 or -1, and signals an error for other increments. These are specific, verifiable claims aligned with the code's structure and control flow. There is minimal noise and no inaccurate or contradictory elements, though the description is slightly broad by calling the output 'indices' instead of integers from the sequence, reducing some precision. Overall gain is moderately high due to its correctness and specificity."
            ]
        },
        "filter_prorec": {
            "summary": "Generates a sequence of integer indices from a compact R vector representation, validating increment support and handling increasing or decreasing sequences.",
            "score": [
                0.9,
                0.6,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function generates a sequence of integers from a compact R vector and distinguishes between increasing and decreasing sequences based on the increment value. It also mentions validation of increment support, which aligns with the error path for unsupported increments. However, the term 'integer indices' is slightly misleading since they are values from a sequence, not necessarily indices, and the summary omits the detail about calculating the number of elements to copy. Most claims are accurate, with minor imprecision.",
                "The summary correctly states that the function generates a sequence of integers from a compact R vector and handles both increasing and decreasing increments, which matches the core operation in the source code. It also notes validation of increment support, aligning with the error handling for unsupported increment values. However, it omits several important secondary details such as retrieving sequence metadata (length, first element, increment), computing the exact number of elements to copy, and writing them into a provided buffer. These omissions mean secondary coverage is only moderate.",
                "The summary correctly identifies that the function deals with compact R sequence data, supports increasing and decreasing increments, and validates unsupported increments, which aligns with the source\u2019s increment handling logic. However, it inaccurately describes the output as \u2018integer indices\u2019, whereas the function actually generates integer values from an arithmetic sequence offset by i, not indices. This is a semantic mismatch targeting core I/O, which is a FATAL error affecting the primary purpose. The rest of the claims are accurate but generic, yielding low net benefit."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\nxmlIsDocNameStartChar(xmlDocPtr doc, int c) {\n    if ((doc == NULL) || (doc->properties & XML_DOC_OLD10) == 0) {\n        /*\n\t * Use the new checks of production [4] [4a] amd [5] of the\n\t * Update 5 of XML-1.0\n\t */\n\tif (((c >= 'a') && (c <= 'z')) ||\n\t    ((c >= 'A') && (c <= 'Z')) ||\n\t    (c == '_') || (c == ':') ||\n\t    ((c >= 0xC0) && (c <= 0xD6)) ||\n\t    ((c >= 0xD8) && (c <= 0xF6)) ||\n\t    ((c >= 0xF8) && (c <= 0x2FF)) ||\n\t    ((c >= 0x370) && (c <= 0x37D)) ||\n\t    ((c >= 0x37F) && (c <= 0x1FFF)) ||\n\t    ((c >= 0x200C) && (c <= 0x200D)) ||\n\t    ((c >= 0x2070) && (c <= 0x218F)) ||\n\t    ((c >= 0x2C00) && (c <= 0x2FEF)) ||\n\t    ((c >= 0x3001) && (c <= 0xD7FF)) ||\n\t    ((c >= 0xF900) && (c <= 0xFDCF)) ||\n\t    ((c >= 0xFDF0) && (c <= 0xFFFD)) ||\n\t    ((c >= 0x10000) && (c <= 0xEFFFF)))\n\t    return(1);\n    } else {\n        if (IS_LETTER(c) || (c == '_') || (c == ':'))\n\t    return(1);\n    }\n    return(0);\n}",
    "comment": "Determines if a character is a valid starting character for an XML document name based on XML-1.0 specifications or old document properties.",
    "prorec_sum": "Checks whether a character code is valid as an XML name character, considering optional extended Unicode ranges and context-specific constraints.",
    "filter_prorec_sum": "Determines if a character code is valid for XML names by checking allowed ASCII symbols, Unicode ranges, and base character groups.",
    "prorec_aug_sum": "Checks if a given Unicode code point is a valid XML name character, considering parser state and XML specification character ranges.",
    "filter_prorec_aug_sum": "Determines if a character code is valid for XML name characters, supporting ASCII letters, digits, certain symbols, and specific Unicode ranges.",
    "work_score": {
        "prorec": {
            "summary": "Checks whether a character code is valid as an XML name character, considering optional extended Unicode ranges and context-specific constraints.",
            "score": [
                0.8,
                0.2,
                0.7
            ],
            "reason": [
                "The summary correctly notes that the function checks if a character code is valid for XML naming and that extended Unicode ranges are considered, which aligns with the code's conditional ranges and rules. However, it inaccurately generalizes the scope: the function specifically checks for a valid *start* character in an XML name, not any name character, and 'context-specific constraints' is vague compared to the precise old vs new XML version logic in the code. Most of the claim is accurate but missing specificity, yielding a high proportion of correct but somewhat generic statements.",
                "The summary's core claim about checking validity of an XML name character is inaccurate for the given code because the function specifically checks if a character can be a start character of a document name, following XML 1.0 updated rules and ranges, and not general name characters. It omits the distinction between start character rules versus other name rules, and does not convey the conditional branch depending on 'doc->properties' and older/newer specification handling. This means the core primary purpose is not correctly covered and secondary details such as specific ranges, property checks, or XML version differences are missing.",
                "The summary accurately conveys the core function: determining if a character code is valid for an XML name, and notes extended Unicode ranges and contextual conditions. It omits some specifics, such as differentiating between name start characters and other name characters, and does not mention the old XML 1.0 check path, but these omissions are minor. There is no contradictory or irrelevant content, and the claims are aligned with the code, though the gain is moderate due to general wording."
            ]
        },
        "filter_prorec": {
            "summary": "Determines if a character code is valid for XML names by checking allowed ASCII symbols, Unicode ranges, and base character groups.",
            "score": [
                0.8,
                0.6,
                0.5
            ],
            "reason": [
                "The summary correctly identifies that the function checks whether a character code is valid for XML names, referencing ASCII symbols, Unicode ranges, and character groups, which aligns with the source code logic. However, it omits the conditional logic based on the doc properties and older XML 1.0 rules, making it slightly incomplete but still largely accurate.",
                "The summary correctly states that the function checks if a character code is valid for XML names using ASCII symbols, Unicode ranges, and base characters, which matches the core purpose of validating XML name start characters per XML 1.0 rules. However, it omits the important conditional logic based on the document's XML version properties (XML_DOC_OLD10) and the distinction between the newer production rules and the older IS_LETTER check. Secondary domain details like handling for null document pointers and specific branching behavior are not covered.",
                "The summary correctly states the core purpose of the function\u2014to determine if a character code is valid for XML names\u2014and notes checking allowed ASCII symbols and Unicode ranges, which matches the code. However, the claim about 'base character groups' is generic and not clearly reflected in the code\u2019s specific conditional logic for XML 1.0 update ranges or old doc property handling. The summary omits the branch for XML_DOC_OLD10 and the distinction between newer and older checks, losing specificity and high-value insight. No FATAL errors are present, but the gain is low due to missing detailed rules and conditions, with mostly broad SAFE claims."
            ]
        }
    }
}
{
    "source_code": "\nstatic void uncore_pci_remove(struct pci_dev *pdev)\n{\n\tstruct intel_uncore_box *box = pci_get_drvdata(pdev);\n\tstruct intel_uncore_pmu *pmu = box->pmu;\n\tint cpu, phys_id = pcibus_to_physid[pdev->bus->number];\n\n\tif (WARN_ON_ONCE(phys_id != box->phys_id))\n\t\treturn;\n\n\tpci_set_drvdata(pdev, NULL);\n\n\traw_spin_lock(&uncore_box_lock);\n\tlist_del(&box->list);\n\traw_spin_unlock(&uncore_box_lock);\n\n\tfor_each_possible_cpu(cpu) {\n\t\tif (*per_cpu_ptr(pmu->box, cpu) == box) {\n\t\t\t*per_cpu_ptr(pmu->box, cpu) = NULL;\n\t\t\tatomic_dec(&box->refcnt);\n\t\t}\n\t}\n\n\tWARN_ON_ONCE(atomic_read(&box->refcnt) != 1);\n\tkfree(box);\n}",
    "comment": "Removes an uncore PCI device, updates reference counts, and frees associated resources while ensuring proper synchronization in a multi-CPU environment.",
    "prorec_sum": "Unregisters an Intel uncore performance event, removes it from tracking lists, decrements references, and logs anomalies during cleanup.",
    "filter_prorec_sum": "Removes and cleans up an Intel uncore performance event when its configuration matches, updating linked structures and logging inconsistencies.",
    "prorec_aug_sum": "Unregisters an Intel uncore performance event, removes related references, updates counters, and logs inconsistencies in refcount during cleanup.",
    "filter_prorec_aug_sum": "Finalizes and cleans up an Intel uncore performance event, removing references, updating counters, and logging mismatches in perf_event_intel_uncore.c.",
    "work_score": {
        "prorec": {
            "summary": "Unregisters an Intel uncore performance event, removes it from tracking lists, decrements references, and logs anomalies during cleanup.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies key semantics: the function removes an Intel uncore entity from tracking lists, decrements reference counters per CPU, and logs anomalies via WARN_ON_ONCE checks during cleanup. It omits some specifics like validation of phys_id, pci driver data handling, and freeing the box, but none of its claims contradict the source. The majority of claims align well with the function\u2019s behavior, though they are somewhat generic and lack technical detail.",
                "The summary correctly captures the core purpose\u2014cleaning up and unregistering an Intel uncore performance monitoring unit\u2014and notes key actions like list removal, reference decrementing, and anomaly logging via WARN_ON_ONCE. However, it omits several critical details from the source code such as matching and validating phys_id before proceeding, clearing PCI driver data, locking/unlocking around list operations, and explicitly freeing the allocated box structure. These omissions make the coverage of secondary behaviors incomplete.",
                "The summary correctly captures that the function performs cleanup by removing from tracking lists, decrementing references, and logging anomalies, aligning with the WARN_ON_ONCE checks and list/atomic operations in the code. However, it inaccurately states that it unregisters an Intel uncore performance event, which is not explicitly shown in the code; the function instead cleans up a PCI device\u2019s uncore box. This is a mild semantic distortion but not a severe FATAL on the core purpose. Overall, the claims are mostly accurate with some slight noise and limited detail."
            ]
        },
        "filter_prorec": {
            "summary": "Removes and cleans up an Intel uncore performance event when its configuration matches, updating linked structures and logging inconsistencies.",
            "score": [
                0.9,
                0.4,
                0.5
            ],
            "reason": [
                "The summary claims the function removes and cleans up an Intel uncore performance event when its configuration matches, updates linked structures, and logs inconsistencies. The code does remove and clean up an Intel uncore box tied to a PCI device, and it updates linked structures (list manipulation and per-CPU pointers) while logging inconsistencies via WARN_ON_ONCE checks, which aligns well. However, the phrase 'when its configuration matches' is unsupported by the source code \u2014 the removal is gated by a phys_id consistency check rather than general configuration matching. Most claims align with the code, with only a minor inaccuracy, resulting in a high proportion of accurate statements.",
                "The summary states that the function removes and cleans up an Intel uncore performance event and logs inconsistencies, which aligns generally with the source code's actions of removing an Intel uncore PCI device, updating linked lists, clearing per-CPU pointers, decrementing references, and issuing WARN_ON_ONCE checks. However, the core domain purpose in the code is specifically removing the Intel uncore PCI device and freeing its associated box structure, not conditionally based on configuration matches, so the 'matches configuration' part is inaccurate. While the summary covers the main removal/cleanup operation and mentions logging inconsistencies, it misses multiple key secondary details like clearing driver data, the specific WARN_ON_ONCE checks, locking around list removal, and handling per-CPU pointers with refcount decrement. Coverage of core is partial and secondary info is thin and partly off-target.",
                "The summary correctly captures the core purpose that the function removes and cleans up an Intel uncore performance monitoring unit, and mentions updating linked structures and logging inconsistencies, which aligns with the WARN_ON_ONCE checks. However, it inaccurately adds 'when its configuration matches,' which is not present in the source code \u2014 the condition is on the physical ID, not a general 'configuration match.' This is a mild inaccuracy but not a fatal one, as the primary removal/cleanup behavior is correctly described. The summary is generic and lacks specifics such as the per-CPU pointer nullification and reference count decrement, limiting its information gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void sig_child_handler(int sig_no UNUSED_PARAM)\n{\n\tpid_t pid;\n\tint l;\n\n\tif (verbose)\n\t\tbb_error_msg(INFO\"sig%s received\", \"child\");\n\twhile ((pid = wait_any_nohang(&wstat)) > 0) {\n\t\tfor (l = 0; l < dirn; ++l) {\n\t\t\tif (dir[l].ppid == pid) {\n\t\t\t\tdir[l].ppid = 0;\n\t\t\t\tprocessorstop(&dir[l]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}",
    "comment": "Handles SIGCHLD signals by cleaning up and processing terminated child processes that match entries in the directory.",
    "prorec_sum": "Processes incoming event codes, logs an \"end\" message with type and details, and conditionally invokes a final handler based on a global state flag.",
    "filter_prorec_sum": "Processes incoming event codes, logs them as either \"signal\" or \"exit\" with details, and finalizes handling based on a global state flag.",
    "prorec_aug_sum": "Processes input events, logs an \"end\" message with event details, and conditionally triggers further handling based on global state.",
    "filter_prorec_aug_sum": "Processes incoming event codes, logs an \"end\" message with exit or signal status, and triggers final handling if the global active flag is set.",
    "work_score": {
        "prorec": {
            "summary": "Processes incoming event codes, logs an \"end\" message with type and details, and conditionally invokes a final handler based on a global state flag.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about processing event codes, logging an 'end' message with type/details, and invoking a final handler based on a global state flag do not align with the source code, which handles SIGCHLD signals, logs reception of a child signal, waits for child processes, and stops matching processors. All summary claims are inaccurate relative to the code.",
                "The summary fails to describe the actual core purpose, which is handling SIGCHLD signals, waiting for terminated child processes, matching them to entries in a directory list, resetting their parent PID, and stopping their processor. The provided description about processing event codes, logging an 'end' message, and invoking a final handler based on a global state flag is inaccurate and unrelated to the source code semantics. No accurate claims cover the core domain action or any secondary behaviors such as looping through processes or logging the signal event.",
                "The summary contains multiple inaccuracies relative to the source code. It claims the function processes event codes, logs an 'end' message, and invokes a final handler based on a global flag, but the source actually handles SIGCHLD signals, logs a 'child' message when verbose, waits for terminated child processes, and stops relevant processors. These are core semantic mismatches targeting the primary purpose and key side effects, constituting a severe FATAL error on the core action. No accurate claims are present to offset this."
            ]
        },
        "filter_prorec": {
            "summary": "Processes incoming event codes, logs them as either \"signal\" or \"exit\" with details, and finalizes handling based on a global state flag.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function's behavior. The source code handles SIGCHLD signals, logs a specific 'child' message when verbose is enabled, waits for child processes without blocking, and calls processorstop for matching entries. There is no evidence of processing generic event codes, logging them as 'signal' or 'exit', or using a global state flag to finalize handling. All claims are inaccurate, so the precision is extremely low.",
                "The summary does not cover the core purpose of the function, which is handling a SIGCHLD signal by waiting for terminated child processes, updating their tracking structures, and stopping associated processors. The claims in the summary about processing event codes, differentiating between 'signal' or 'exit', and using a global state flag are inaccurate with respect to the actual source code and introduce unrelated semantics. No accurate claims about the code's domain behavior are present, leading to a failure to cover both the core function and secondary details.",
                "The summary inaccurately describes the function\u2019s core purpose: the source code specifically handles SIGCHLD signals, logs a fixed 'child' message when verbose, and uses wait_any_nohang to detect terminated child processes before stopping their associated processors. The summary instead mentions 'event codes' being logged as 'signal' or 'exit' and handling based on a global state flag, which contradicts the actual key I/O and behavior, making this a fatal error on the primary purpose. No accurate, domain-specific statements are present to offset this."
            ]
        }
    }
}
{
    "source_code": "\nint\nrl_arrow_keys (int count, int key)\n{\n  int ch;\n\n  RL_SETSTATE(RL_STATE_MOREINPUT);\n  ch = rl_read_key ();\n  RL_UNSETSTATE(RL_STATE_MOREINPUT);\n  if (ch < 0)\n    return (1);\n\n  switch (_rl_to_upper (ch))\n    {\n    case 'A':\n      rl_get_previous_history (count, ch);\n      break;\n\n    case 'B':\n      rl_get_next_history (count, ch);\n      break;\n\n    case 'C':\n      if (MB_CUR_MAX > 1 && rl_byte_oriented == 0)\n\trl_forward_char (count, ch);\n      else\n\trl_forward_byte (count, ch);\n      break;\n\n    case 'D':\n      if (MB_CUR_MAX > 1 && rl_byte_oriented == 0)\n\trl_backward_char (count, ch);\n      else\n\trl_backward_byte (count, ch);\n      break;\n\n    default:\n      rl_ding ();\n    }\n\n  return 0;\n}",
    "comment": "Handles arrow key inputs to navigate command history or move the cursor forward/backward, depending on the key pressed and character encoding.",
    "prorec_sum": "Handles arrow key input in readline, updating history navigation or cursor movement based on key codes and character encoding settings.",
    "filter_prorec_sum": "Handles arrow key inputs in readline, moving through command history or cursor position based on key type and character encoding settings.",
    "prorec_aug_sum": "Handles terminal arrow key input to navigate command history or move the cursor, supporting both single-byte and multibyte character environments.",
    "filter_prorec_aug_sum": "Handles arrow key input for navigating history and moving the cursor within a readline interface, supporting both byte-oriented and multibyte character modes.",
    "work_score": {
        "prorec": {
            "summary": "Handles arrow key input in readline, updating history navigation or cursor movement based on key codes and character encoding settings.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly describes that the function processes arrow key input for readline and either navigates history or moves the cursor depending on key codes and encoding settings. These points are directly supported by the source code\u2019s switch cases for 'A', 'B', 'C', and 'D', and the conditional handling for multibyte versus byte-oriented movement. All claims are accurate and domain-specific, with no incorrect or irrelevant statements.",
                "The summary correctly identifies the core purpose as handling arrow key input in readline, mapping key codes to history navigation or cursor movement with consideration for character encoding settings. This matches the source code\u2019s logic that processes 'A' and 'B' for history navigation and 'C'/'D' for cursor movement with multi-byte awareness. However, it omits secondary details such as the RL_SETSTATE/RL_UNSETSTATE calls, the read key operation and error check (ch < 0 returns 1), the distinction between byte-oriented and character-oriented movement, and the default case triggering rl_ding. The coverage of secondary behavior is therefore limited.",
                "The summary correctly identifies that the function processes arrow key inputs, supports history navigation for certain keys, and adjusts cursor movement depending on character encoding settings. These are specific, accurate reflections of the switch cases in the source code. There are no factual errors or irrelevant noise, though the explanation is moderately high-level and omits some detail (e.g., exact mappings of 'A', 'B', 'C', 'D' cases). Overall, the claims are accurate and provide clear insight into the core behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Handles arrow key inputs in readline, moving through command history or cursor position based on key type and character encoding settings.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function handles arrow key inputs within readline, navigates through command history for certain keys, and moves the cursor depending on character encoding settings, which matches the switch cases and MB_CUR_MAX logic in the source code. All claims are accurate and specific to the code\u2019s behavior, with no contradictions or irrelevant statements.",
                "The summary accurately describes the core purpose of handling arrow key inputs in readline, including movement through command history and cursor navigation depending on character encoding settings. This matches the core domain behavior of the function, which processes specific arrow key codes to navigate history or move the cursor forward/backward with multibyte-aware logic. However, it omits other secondary details such as the initial state setting/unsetting, the handling of invalid input with a return value, the default case triggering a bell, and specific branch conditions for different keys, resulting in incomplete coverage of behavior-critical semantics.",
                "The summary accurately captures the core function behavior: it processes arrow key inputs in readline, moving through command history for up/down keys and adjusting cursor position for left/right keys based on multibyte encoding settings. All claims align with the source code, with no contradictions or irrelevant noise. While the description is concise and somewhat generic, it reflects the primary purpose and key conditional logic correctly, offering moderate specificity without high-level detail."
            ]
        }
    }
}
{
    "source_code": "\nint rtc_update_irq_enable(struct rtc_device *rtc, unsigned int enabled)\n{\n\tint err = mutex_lock_interruptible(&rtc->ops_lock);\n\tif (err)\n\t\treturn err;\n\n#ifdef CONFIG_RTC_INTF_DEV_UIE_EMUL\n\tif (enabled == 0 && rtc->uie_irq_active) {\n\t\tmutex_unlock(&rtc->ops_lock);\n\t\treturn rtc_dev_update_irq_enable_emul(rtc, 0);\n\t}\n#endif\n\t/* make sure we're changing state */\n\tif (rtc->uie_rtctimer.enabled == enabled)\n\t\tgoto out;\n\n\tif (rtc->uie_unsupported) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (enabled) {\n\t\tstruct rtc_time tm;\n\t\tktime_t now, onesec;\n\n\t\t__rtc_read_time(rtc, &tm);\n\t\tonesec = ktime_set(1, 0);\n\t\tnow = rtc_tm_to_ktime(tm);\n\t\trtc->uie_rtctimer.node.expires = ktime_add(now, onesec);\n\t\trtc->uie_rtctimer.period = ktime_set(1, 0);\n\t\terr = rtc_timer_enqueue(rtc, &rtc->uie_rtctimer);\n\t} else\n\t\trtc_timer_remove(rtc, &rtc->uie_rtctimer);\n\nout:\n\tmutex_unlock(&rtc->ops_lock);\n#ifdef CONFIG_RTC_INTF_DEV_UIE_EMUL\n\t/*\n\t * Enable emulation if the driver did not provide\n\t * the update_irq_enable function pointer or if returned\n\t * -EINVAL to signal that it has been configured without\n\t * interrupts or that are not available at the moment.\n\t */\n\tif (err == -EINVAL)\n\t\terr = rtc_dev_update_irq_enable_emul(rtc, enabled);\n#endif\n\treturn err;\n\n}",
    "comment": "Updates the RTC interrupt state, enabling or disabling the timer based on the provided flag, while handling potential emulation requirements.",
    "prorec_sum": "Changes the device\u2019s power state, updating related timestamps and invoking appropriate initialization or shutdown routines depending on the requested state.",
    "filter_prorec_sum": "Switches a codec\u2019s power state between active and idle, updating timing fields and invoking helper routines for initialization or shutdown as needed.",
    "prorec_aug_sum": "Changes a device\u2019s operational state based on the given mode, updating timing parameters and invoking start or stop routines before releasing a synchronization lock.",
    "filter_prorec_aug_sum": "Switches the device between active and inactive states, updating timing parameters and invoking appropriate initialization or shutdown routines based on the requested state.",
    "work_score": {
        "prorec": {
            "summary": "Changes the device\u2019s power state, updating related timestamps and invoking appropriate initialization or shutdown routines depending on the requested state.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function changes the device\u2019s power state, updates timestamps, and invokes initialization or shutdown routines. These are inaccurate because the source code shows it enables or disables RTC update interrupts by manipulating timers, locks, and emulation logic, without altering power state or performing generic device initialization/shutdown. None of the claims match the actual domain-specific behavior in the code, resulting in no accurate claims.",
                "The summary incorrectly describes the function as changing the device\u2019s power state with initialization or shutdown routines, which contradicts the code\u2019s core purpose of enabling or disabling RTC update interrupts and managing associated timers. No accurate claims match the primary domain behavior, and key semantics such as locking, emulation handling, error cases, and timer configuration are missing entirely.",
                "The summary contains a single claim that the function changes the device\u2019s power state, updates timestamps, and invokes initialization/shutdown routines based on that state. This is inaccurate with respect to the source code: the function enables or disables RTC update interrupts and manages a timer, not power state. The only relatively relevant part is the mention of timestamps, which is tangential since it calculates timer expiration, but most of the claim is incorrect. This is a FATAL error on the primary purpose, making the description misleading and unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Switches a codec\u2019s power state between active and idle, updating timing fields and invoking helper routines for initialization or shutdown as needed.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary claims the function switches a codec\u2019s power state and involves initialization or shutdown, which is entirely unrelated to the given source code. The source code deals with enabling or disabling RTC update interrupts, manipulating timers, and handling emulation conditions. None of the summary\u2019s claims match the code\u2019s semantics, resulting in 0% accurate claims.",
                "The summary's claims about switching a codec\u2019s power state and invoking helper routines for initialization or shutdown are unrelated to the source code, which handles enabling or disabling RTC update interrupts via timer manipulation, emulation handling, mutex locking, and error checks. None of the claims accurately reflect the core domain action or secondary behaviors from the code, resulting in no coverage of the primary purpose or any critical details.",
                "The summary\u2019s core claim that the function switches a codec\u2019s power state is entirely inaccurate, as the source code deals with enabling or disabling RTC update interrupts, not audio codec power. This is a severe factual error targeting the primary purpose of the function, which is managing RTC IRQ timer state and related timing, making the summary unusable. No accurate claims are present to offset this fatal flaw, and noise is total."
            ]
        }
    }
}
{
    "source_code": "\nstatic ngx_int_t\nngx_http_variable_tcpinfo(ngx_http_request_t *r, ngx_http_variable_value_t *v,\n    uintptr_t data)\n{\n    struct tcp_info  ti;\n    socklen_t        len;\n    uint32_t         value;\n\n    len = sizeof(struct tcp_info);\n    if (getsockopt(r->connection->fd, IPPROTO_TCP, TCP_INFO, &ti, &len) == -1) {\n        v->not_found = 1;\n        return NGX_OK;\n    }\n\n    v->data = ngx_pnalloc(r->pool, NGX_INT32_LEN);\n    if (v->data == NULL) {\n        return NGX_ERROR;\n    }\n\n    switch (data) {\n    case 0:\n        value = ti.tcpi_rtt;\n        break;\n\n    case 1:\n        value = ti.tcpi_rttvar;\n        break;\n\n    case 2:\n        value = ti.tcpi_snd_cwnd;\n        break;\n\n    case 3:\n        value = ti.tcpi_rcv_space;\n        break;\n\n    /* suppress warning */\n    default:\n        value = 0;\n        break;\n    }\n\n    v->len = ngx_sprintf(v->data, \"%uD\", value) - v->data;\n    v->valid = 1;\n    v->no_cacheable = 0;\n    v->not_found = 0;\n\n    return NGX_OK;\n}",
    "comment": "Retrieves TCP connection statistics like RTT, RTT variance, send window size, or receive space and stores the result in an HTTP variable.",
    "prorec_sum": "Retrieves TCP connection statistics via `getsockopt` and formats a selected metric into a string buffer for further use in the response structure.",
    "filter_prorec_sum": "Retrieves TCP connection statistics via getsockopt and writes a selected metric as a formatted string into a provided buffer structure.",
    "prorec_aug_sum": "Retrieves TCP connection statistics via getsockopt and formats a selected metric into a string buffer for later use in the associated structure.",
    "filter_prorec_aug_sum": "Retrieves TCP connection info via `getsockopt` and stores a selected metric as a formatted string into an NGINX buffer structure.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves TCP connection statistics via `getsockopt` and formats a selected metric into a string buffer for further use in the response structure.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly describes that the function uses `getsockopt` to retrieve TCP connection statistics and formats a chosen metric into a string for inclusion in the response structure, which matches the code's behavior. There are no contradictory or irrelevant statements. Although the summary is concise and omits specific details like the possible metrics (`tcpi_rtt`, `tcpi_rttvar`, etc.), all included claims are accurate and grounded in the source.",
                "The summary correctly states that the function uses getsockopt to retrieve TCP connection statistics and formats a selected metric into a string, which aligns with the core purpose of extracting a specific TCP_INFO field and preparing it for use in an HTTP variable. However, it omits several important secondary details such as handling of errors when getsockopt fails, allocation from the request pool, the specific metrics selected via the data switch (rtt, rttvar, snd_cwnd, rcv_space), and setting response flags (valid, no_cacheable, not_found). Coverage of the core is adequate, but secondary semantics are weak.",
                "The summary accurately states that the function uses `getsockopt` to obtain TCP connection statistics and formats a selected metric into a string buffer within the response structure. These claims align with the source code\u2019s behavior, specifically retrieving `struct tcp_info` fields based on the `data` parameter and writing them to `v->data`. No inaccurate or noisy claims are present, but the summary is generic and omits specifics such as which metrics can be selected or conditions for early return, limiting the informational gain."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves TCP connection statistics via getsockopt and writes a selected metric as a formatted string into a provided buffer structure.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function uses getsockopt to retrieve TCP connection statistics and that it writes a selected metric into the provided buffer as a formatted string. These details match the source code's behavior of calling getsockopt with TCP_INFO, selecting a metric based on the 'data' parameter, and formatting it with ngx_sprintf into v->data. All claims are accurate and specific to the source code\u2019s semantics, with no inaccurate or irrelevant statements present.",
                "The summary correctly identifies the core purpose as retrieving TCP connection statistics using getsockopt and formatting a selected metric into the output buffer, which aligns with the function\u2019s domain-specific action. However, it omits key secondary details such as handling the not_found flag when getsockopt fails, allocating memory with ngx_pnalloc, the specific metrics chosen via a switch on 'data', and the final flag settings in the variable structure, resulting in only partial coverage of behavior-critical semantics.",
                "The summary correctly identifies that the function uses getsockopt to retrieve TCP connection statistics and formats a selected metric into the provided buffer, which matches the source code's core behavior. There is no inaccurate or misleading information, but the claim is generic and lacks specifics about which metrics can be selected, the error handling, and the exact formatting. This makes the gain low but with negligible noise."
            ]
        }
    }
}
{
    "source_code": "\nint libjte_write_header(struct libjte_env *o)\n{\n    int ret;\n\n    if (o->jtemplate_out == NULL || o->jjigdo_out == NULL ||\n        o->outfile == NULL || o->jmd5_list == NULL) {\n        sprintf(o->message_buffer,\n               \"Undefined: template_path, jigdo_path, md5_paths, or outfile.\");\n        libjte_add_msg_entry(o, o->message_buffer, 0);\n        return 0;\n    }\n    \n    o->jttemplate = fopen(o->jtemplate_out, \"wb\");\n    if (o->jttemplate == NULL) {\n        sprintf(o->message_buffer,\n                \"Cannot open template file '%1.1024s' for writing. errno=%d\",\n                o->jtemplate_out, errno);\n        libjte_add_msg_entry(o, o->message_buffer, 0);\n        return 0;\n    }\n    o->jtjigdo = fopen(o->jjigdo_out, \"wb\");\n    if (o->jtjigdo == NULL) {\n        sprintf(o->message_buffer,\n                \"Cannot open jigdo file '%1.1024s' for writing. errno=%d\",\n                o->jjigdo_out, errno);\n        libjte_add_msg_entry(o, o->message_buffer, 0);\n        return 0;\n    }\n\n    ret = write_jt_header(o, o->jttemplate, o->jtjigdo);\n    if (ret <= 0)\n        return ret;\n    return 1;\n}",
    "comment": "Initializes output files for a template and jigdo, checks for errors, and writes the header using the provided environment structure.",
    "prorec_sum": "Opens specified template and jigdo output files for writing, reports detailed errors if opening fails, then processes them with a dedicated handler function.",
    "filter_prorec_sum": "Opens specified template and jigdo output files for writing, reports detailed errors if opening fails, and processes them through a subsequent file-handling routine.",
    "prorec_aug_sum": "Opens specified template and jigdo files for writing, reports detailed errors if opening fails, and processes them when both are successfully opened.",
    "filter_prorec_aug_sum": "Opens specified template and jigdo files for writing, reports detailed errors if opening fails, and processes them using a subsequent file-handling routine.",
    "work_score": {
        "prorec": {
            "summary": "Opens specified template and jigdo output files for writing, reports detailed errors if opening fails, then processes them with a dedicated handler function.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary captures the key behavior in the source: opening the specified template and jigdo files for writing, reporting detailed errors when failures occur, and processing them with a dedicated handler function (`write_jt_header`). All claims directly align with the code's semantics, with no inaccuracies or irrelevant content, making the description both specific and accurate.",
                "The summary correctly captures the core purpose of opening the template and jigdo output files for writing, which matches the function\u2019s domain-specific effect. It also notes detailed error reporting upon failure, aligning with the code\u2019s handling of missing paths and fopen errors. However, it omits key secondary behaviors: the initial null-pointer checks for required fields, invocation of libjte_add_msg_entry with specific error messages, and the return value logic based on write_jt_header\u2019s result. These gaps reduce completeness despite accurate core coverage.",
                "The summary correctly states that the function opens the specified template and jigdo output files for writing, reports detailed error messages when opening fails, and then processes them with a handler function. These claims match the source code\u2019s logic without inaccuracies or noise. However, the description is somewhat generic and omits the initial precondition check for required paths and files and the specific return values, which limits the informational gain."
            ]
        },
        "filter_prorec": {
            "summary": "Opens specified template and jigdo output files for writing, reports detailed errors if opening fails, and processes them through a subsequent file-handling routine.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function opens template and jigdo output files for writing, reports detailed errors if opening fails, and processes them through another routine. These points align with the code's behavior, including the fopen calls, error handling using message_buffer, and the call to write_jt_header. It omits only minor details such as initial null-pointer checks before opening files, but over 80% of the claims are accurate and connected to the source semantics.",
                "The summary correctly captures the core action of opening template and jigdo files for writing and reporting detailed errors on failure, which matches the source code\u2019s main purpose. It also notes passing these files to another handling routine, aligning with the write_jt_header call. However, it omits other behavior-critical checks like verifying that required output paths and md5 list are defined before trying to open files, and does not mention specific return values used for error handling and success. Coverage of secondary semantics is limited.",
                "The summary correctly captures the main purpose of the function: opening template and jigdo output files for writing, providing detailed error messages upon failure, and passing opened file handles to another routine (`write_jt_header`). It omits the initial check for required output path pointers and the MD5 list, but this is a minor gap rather than a contradiction. All claims are accurate and target the code\u2019s semantics, with no fatal errors present. The gain is moderate, as the summary contains specific details about error reporting and file-handling but lacks full coverage of all preconditions."
            ]
        }
    }
}
{
    "source_code": "\nint __ipv6_addr_type(const struct in6_addr *addr)\n{\n\t__be32 st;\n\n\tst = addr->s6_addr32[0];\n\n\t/* Consider all addresses with the first three bits different of\n\t   000 and 111 as unicasts.\n\t */\n\tif ((st & htonl(0xE0000000)) != htonl(0x00000000) &&\n\t    (st & htonl(0xE0000000)) != htonl(0xE0000000))\n\t\treturn (IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\n\n\tif ((st & htonl(0xFF000000)) == htonl(0xFF000000)) {\n\t\t/* multicast */\n\t\t/* addr-select 3.1 */\n\t\treturn (IPV6_ADDR_MULTICAST |\n\t\t\tipv6_addr_scope2type(IPV6_ADDR_MC_SCOPE(addr)));\n\t}\n\n\tif ((st & htonl(0xFFC00000)) == htonl(0xFE800000))\n\t\treturn (IPV6_ADDR_LINKLOCAL | IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_LINKLOCAL));\t\t/* addr-select 3.1 */\n\tif ((st & htonl(0xFFC00000)) == htonl(0xFEC00000))\n\t\treturn (IPV6_ADDR_SITELOCAL | IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_SITELOCAL));\t\t/* addr-select 3.1 */\n\tif ((st & htonl(0xFE000000)) == htonl(0xFC000000))\n\t\treturn (IPV6_ADDR_UNICAST |\n\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t\t\t/* RFC 4193 */\n\n\tif ((addr->s6_addr32[0] | addr->s6_addr32[1]) == 0) {\n\t\tif (addr->s6_addr32[2] == 0) {\n\t\t\tif (addr->s6_addr32[3] == 0)\n\t\t\t\treturn IPV6_ADDR_ANY;\n\n\t\t\tif (addr->s6_addr32[3] == htonl(0x00000001))\n\t\t\t\treturn (IPV6_ADDR_LOOPBACK | IPV6_ADDR_UNICAST |\n\t\t\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_LINKLOCAL));\t/* addr-select 3.4 */\n\n\t\t\treturn (IPV6_ADDR_COMPATv4 | IPV6_ADDR_UNICAST |\n\t\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t/* addr-select 3.3 */\n\t\t}\n\n\t\tif (addr->s6_addr32[2] == htonl(0x0000ffff))\n\t\t\treturn (IPV6_ADDR_MAPPED |\n\t\t\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t/* addr-select 3.3 */\n\t}\n\n\treturn (IPV6_ADDR_UNICAST |\n\t\tIPV6_ADDR_SCOPE_TYPE(IPV6_ADDR_SCOPE_GLOBAL));\t/* addr-select 3.4 */\n}",
    "comment": "Determines the IPv6 address type (unicast, multicast, link-local, site-local, loopback, or any) based on the address structure and specific bit patterns.",
    "prorec_sum": "Classifies packet header data based on specific byte patterns and bit masks, returning distinct constant codes for recognized network protocol conditions.",
    "filter_prorec_sum": "Determines packet type codes by inspecting specific byte patterns and bitfields in a memory buffer, returning distinct constants for recognized protocol signatures.",
    "prorec_aug_sum": "Evaluates the first bytes of a data block against specific bit patterns and constants to identify and return a corresponding numeric type code.",
    "filter_prorec_aug_sum": "Evaluates the first bytes of a memory block against specific constants and returns a code identifying the detected data format or special marker.",
    "work_score": {
        "prorec": {
            "summary": "Classifies packet header data based on specific byte patterns and bit masks, returning distinct constant codes for recognized network protocol conditions.",
            "score": [
                0.6,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly captures that the function uses bit masks and byte patterns to classify data and returns constant codes, which aligns with the source\u2019s use of specific bitwise checks on IPv6 address bytes to determine address types and scopes. However, it inaccurately describes the input as 'packet header data' rather than an IPv6 address structure, omitting important details about the specific classification categories (unicast, multicast, link-local, etc.). This makes the summary partially accurate but overly generic and slightly misleading about the function\u2019s domain semantics.",
                "The summary generically describes classification of packet header data by byte patterns and bit masks, but does not accurately state the function\u2019s core purpose of determining IPv6 address type and scope. While it loosely matches the idea of using bit masks and returning constants, it misrepresents the domain semantics by referring to 'packet header' and 'network protocol conditions' instead of IPv6 address classification, and omits specific address categories handled (unicast, multicast, link-local, etc.). Thus, the core is not covered and secondary details are minimal.",
                "The summary vaguely states classification of packet header data but does not specify IPv6 addresses, address types, or the detailed conditions used in the function. While it somewhat aligns with the idea of using bit masks, it inaccurately generalizes the purpose as packet header data rather than IPv6 address classification. This is a semantic mismatch on the primary purpose, making it a FATAL error related to the core function\u2019s intent. The accurate elements are minimal and generic, offering low informational value."
            ]
        },
        "filter_prorec": {
            "summary": "Determines packet type codes by inspecting specific byte patterns and bitfields in a memory buffer, returning distinct constants for recognized protocol signatures.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as determining packet type codes from a memory buffer based on protocol signatures. In reality, the code inspects the bits of an IPv6 address to classify it into types such as unicast, multicast, link-local, site-local, loopback, etc., and returns constants indicating address type and scope. None of the claims in the summary accurately target the actual domain-specific behavior of the function, resulting in a complete mismatch.",
                "The summary misrepresents the function's purpose. The source code determines IPv6 address types and scopes by checking bit patterns in the address structure, returning appropriate IPV6_ADDR_* constants, not packet type codes for protocol signatures. The core purpose of categorizing IPv6 addresses is completely missing, and no accurate claims align with the actual domain-specific behavior. Secondary details such as handling multicast, link-local, and special addresses are also absent.",
                "The summary is inaccurate because it describes determining packet type codes from generic memory buffers and protocol signatures, which contradicts the code\u2019s actual purpose of identifying IPv6 address types based on prefix bit patterns in an in6_addr structure. This is a severe FATAL error targeting the primary purpose (core domain: IPv6 address classification), making the description misleading and unusable. No accurate, specific claims are present to offset this fault."
            ]
        }
    }
}
{
    "source_code": "static void\nnlmsvc_insert_block_locked(struct nlm_block *block, unsigned long when)\n{\n\tstruct nlm_block *b;\n\tstruct list_head *pos;\n\n\tdprintk(\"lockd: nlmsvc_insert_block(%p, %ld)\\n\", block, when);\n\tif (list_empty(&block->b_list)) {\n\t\tkref_get(&block->b_count);\n\t} else {\n\t\tlist_del_init(&block->b_list);\n\t}\n\n\tpos = &nlm_blocked;\n\tif (when != NLM_NEVER) {\n\t\tif ((when += jiffies) == NLM_NEVER)\n\t\t\twhen ++;\n\t\tlist_for_each(pos, &nlm_blocked) {\n\t\t\tb = list_entry(pos, struct nlm_block, b_list);\n\t\t\tif (time_after(b->b_when,when) || b->b_when == NLM_NEVER)\n\t\t\t\tbreak;\n\t\t}\n\t\t/* On normal exit from the loop, pos == &nlm_blocked,\n\t\t * so we will be adding to the end of the list - good\n\t\t */\n\t}\n\n\tlist_add_tail(&block->b_list, pos);\n\tblock->b_when = when;\n}",
    "comment": "Inserts a network lock block into a sorted list based on its scheduled time, managing its reference count and handling the list initialization.",
    "prorec_sum": "Manipulates a doubly linked list to replace an element, handle reference counting, and update associated offset metadata.",
    "filter_prorec_sum": "Manages slab cache list pointers and reference counts, inserting or updating an entry based on object index and initializing kref when first accessed.",
    "prorec_aug_sum": "Updates doubly-linked list pointers for an object, increments its reference count, and positions it according to a computed offset value.",
    "filter_prorec_aug_sum": "Adjusts linked list pointers for an entry, updates its reference count, and sets its position based on an offset within a global list.",
    "work_score": {
        "prorec": {
            "summary": "Manipulates a doubly linked list to replace an element, handle reference counting, and update associated offset metadata.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary inaccurately describes the function\u2019s behavior. The source code shows that the function inserts a block into a global list, conditionally increments a reference counter or removes it from its list, and updates its timestamp, but it does not replace an element or update any offset metadata. Only the mention of reference counting is accurate; the claims about element replacement and offset handling are incorrect, resulting in a low proportion of accurate claims.",
                "The summary makes inaccurate claims: it mentions replacing an element and offset metadata, which are not present in the source code. The function actually maintains a list of NLM blocks, adjusting reference counts if the block is new, repositions it based on a 'when' scheduling value, and sets its scheduled time. The core purpose of inserting a block into the nlm_blocked list in order by time is not captured, and there is no accurate coverage of secondary behavior like time comparison with NLM_NEVER or jiffies adjustment.",
                "The summary contains a major inaccuracy about the function's primary purpose: it states that the function replaces an element and updates 'offset metadata', which is not reflected in the code. The code inserts a block into the nlm_blocked list based on timing, adjusts reference counts, and sets the 'b_when' field; there is no replacement of elements or offset metadata handling. This is a FATAL error on the core semantics (WHAT), making the description misleading and untrustworthy. While 'handle reference counting' aligns with the kref_get call, the critical misrepresentation of the operation's main purpose severely reduces net benefit."
            ]
        },
        "filter_prorec": {
            "summary": "Manages slab cache list pointers and reference counts, inserting or updating an entry based on object index and initializing kref when first accessed.",
            "score": [
                0.2,
                0.1,
                0.1
            ],
            "reason": [
                "The summary incorrectly describes the function as managing slab cache list pointers, object indices, and initializing kref on first access. In reality, the code manipulates an `nlm_block` linked list, adjusts reference counts using `kref_get` only when the block's list is empty, and inserts the block based on a time value. The object index and slab cache references are not present in the source, making the majority of claims inaccurate.",
                "The summary's claims about managing slab cache list pointers, object index, and initializing kref when first accessed do not accurately reflect the source code's domain semantics. The function actually inserts an NLM lock block into a global blocked list in time order, adjusting reference counts and list membership based on whether it's new or already present, and handling special constants like NLM_NEVER. The core purpose of time-ordered insertion into the NLM blocked list is not covered, and the summary's mention of slab cache and object index is incorrect noise unrelated to the actual code.",
                "The summary contains multiple INACCURATE claims: it references slab cache list pointers, object index, and first access semantics, none of which are present in the function. The primary purpose\u2014managing NLM block structures in a blocked list and ordering them by timing\u2014is entirely misrepresented, constituting a severe FATAL error on the core domain behavior. No accurate claims align with the actual source code logic, resulting in zero usable insight."
            ]
        }
    }
}
{
    "source_code": "void mm_drop_all_locks(struct mm_struct *mm)\n{\n\tstruct vm_area_struct *vma;\n\tstruct anon_vma_chain *avc;\n\n\tBUG_ON(down_read_trylock(&mm->mmap_sem));\n\tBUG_ON(!mutex_is_locked(&mm_all_locks_mutex));\n\n\tfor (vma = mm->mmap; vma; vma = vma->vm_next) {\n\t\tif (vma->anon_vma)\n\t\t\tlist_for_each_entry(avc, &vma->anon_vma_chain, same_vma)\n\t\t\t\tvm_unlock_anon_vma(avc->anon_vma);\n\t\tif (vma->vm_file && vma->vm_file->f_mapping)\n\t\t\tvm_unlock_mapping(vma->vm_file->f_mapping);\n\t}\n\n\tmutex_unlock(&mm_all_locks_mutex);\n}",
    "comment": "Releases all locks on virtual memory areas and their associated anonymous virtual memory structures in the specified memory management structure.",
    "prorec_sum": "Cleans up and releases DRM file-private resources, iterating related objects to clear flags, drop references, and finalize associated synchronization primitives.",
    "filter_prorec_sum": "Traverses and cleans up file-private DRM data structures, releasing associated fences and reference counts before final global teardown.",
    "prorec_aug_sum": "Releases queued work items and clears pending flags before finalizing and freeing associated workqueue control structures.",
    "filter_prorec_aug_sum": "Cleans up and releases resources for a linked list of workqueue-related structures, resetting pending work bits and invoking required finalization routines.",
    "work_score": {
        "prorec": {
            "summary": "Cleans up and releases DRM file-private resources, iterating related objects to clear flags, drop references, and finalize associated synchronization primitives.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary makes claims about DRM file-private resources, clearing flags, dropping references, and finalizing synchronization primitives, none of which are reflected in the source code. The function instead unlocks anonymous VMA chains and file mappings for a given memory structure, and releases a specific mutex. All claims are inaccurate and unrelated to the code\u2019s actual domain semantics.",
                "The summary\u2019s claims focus on releasing DRM file-private resources and related synchronization primitives, which do not match the source code\u2019s core purpose of iterating VM areas in a memory map to unlock associated anon_vma and file mappings, enforced under a specific mutex and semaphore state. The core domain operation is entirely absent and the provided details target unrelated semantics, making all claims inaccurate with no coverage of real behavior.",
                "The summary's claims about cleaning up and releasing DRM file-private resources, clearing flags, dropping references, and finalizing synchronization primitives are entirely inaccurate relative to the source code. The function actually releases memory management (mm) related locks by iterating over VMAs to unlock anon_vma and mapping structures, with no DRM involvement. This is a severe FATAL error targeting the core purpose, making the description misleading and unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Traverses and cleans up file-private DRM data structures, releasing associated fences and reference counts before final global teardown.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims the function handles DRM data structures, releases fences, and adjusts reference counts, none of which are reflected in the source code. The actual code iterates over VMAs in an mm_struct, unlocking anon_vma and file mapping resources, and finally releases a mutex. All claims target unrelated semantics, making them inaccurate.",
                "The summary's claims about cleaning up DRM data structures, releasing fences, and managing reference counts are entirely unrelated to the source code, which operates on virtual memory areas, anonymous VMA chains, and file mappings to release locks within an mm_struct. None of the summary's claims accurately reflect the core purpose of dropping all locks on VMA-related resources. This means the core functionality is not covered, and all provided information is noise with no secondary relevant details.",
                "The summary is entirely inaccurate: it describes cleaning up DRM data structures, fences, and reference counts, which are unrelated to the source code. The actual function drops various locks in memory management structures, unlocking anon_vma and file mappings before releasing a mutex. This is a severe FATAL error targeting the primary purpose, yielding no correct claims and making the description unusable."
            ]
        }
    }
}
{
    "source_code": "int\ngnet_stats_finish_copy(struct gnet_dump *d)\n{\n\tif (d->tail)\n\t\td->tail->nla_len = skb_tail_pointer(d->skb) - (u8 *)d->tail;\n\n\tif (d->compat_tc_stats)\n\t\tif (gnet_stats_copy(d, d->compat_tc_stats, &d->tc_stats,\n\t\t\tsizeof(d->tc_stats)) < 0)\n\t\t\treturn -1;\n\n\tif (d->compat_xstats && d->xstats) {\n\t\tif (gnet_stats_copy(d, d->compat_xstats, d->xstats,\n\t\t\td->xstats_len) < 0)\n\t\t\treturn -1;\n\t}\n\n\tspin_unlock_bh(d->lock);\n\treturn 0;\n}",
    "comment": "Finalizes the statistics copy process by updating lengths and copying compatible statistics into the provided structures before unlocking the spinlock.",
    "prorec_sum": "Frees and resets a PCM substream\u2019s allocated buffers after invoking preparation routines, returning status based on buffer validity checks.",
    "filter_prorec_sum": "Frees and cleans up a PCM substream\u2019s allocated buffers after attempting necessary data preparation or transfer operations.",
    "prorec_aug_sum": "Processes VLAN-related data from a network bridge, validates device state, invokes packet handling, and cleans up associated resources after execution.",
    "filter_prorec_aug_sum": "Processes VLAN-related data from a bridge structure, validates associated device state, invokes a handler, resets fields, and signals completion or failure.",
    "work_score": {
        "prorec": {
            "summary": "Frees and resets a PCM substream\u2019s allocated buffers after invoking preparation routines, returning status based on buffer validity checks.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary describes freeing and resetting a PCM substream's buffers and buffer validity checks, which is entirely unrelated to the code's semantics of copying statistics structures, adjusting lengths, unlocking a spinlock, and returning status. None of the claims in the summary align with the source code behavior, resulting in 0% accurate claims.",
                "The summary's claims about freeing and resetting PCM substream buffers and preparation routines are unrelated to the actual function, which finishes copying network statistics within a gnet dump, adjusts nla_len, copies compat stats with error checks, and unlocks a spinlock. The core domain purpose is not mentioned, and all claims are inaccurate with respect to the source code semantics.",
                "The summary makes claims about freeing and resetting PCM substream buffers and performing preparation routines, which are entirely unrelated to the source code for `gnet_stats_finish_copy`. The actual function finalizes copying statistics into netlink attributes, handles compatibility structures, and unlocks a spinlock, with no operations on PCM substream buffers. This constitutes a severe factual inaccuracy on the primary purpose/behavior, making it a FATAL error that misrepresents the function\u2019s core semantics."
            ]
        },
        "filter_prorec": {
            "summary": "Frees and cleans up a PCM substream\u2019s allocated buffers after attempting necessary data preparation or transfer operations.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary describes freeing and cleaning up PCM substream buffers, which is unrelated to the source code\u2019s actual functionality of finalizing network statistics copying and releasing a lock. None of the claims in the summary target the domain semantics or behavior of the provided function, making them completely inaccurate.",
                "The summary describes freeing and cleaning up PCM substream buffers, which is unrelated to the actual function\u2019s core purpose of finalizing a generic netlink statistics copy, handling compatibility stats, and unlocking a spinlock. None of the fact-based claims in the summary align with the source code\u2019s domain or operations, meaning the core purpose is not covered and all claims are inaccurate.",
                "The summary\u2019s single claim about freeing and cleaning up PCM substream buffers after data preparation/transfer is completely unrelated to the source code, which deals with finalizing a statistics copy in a gnet_dump structure, adjusting lengths, copying stats, and unlocking a spinlock. This is a FATAL error about the core function purpose, rendering the description unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic int checkscript(void)\n{\n\tchar *prog[2];\n\tstruct stat s;\n\tint pid, w;\n\n\tif (stat(\"check\", &s) == -1) {\n\t\tif (errno == ENOENT) return 1;\n\t\tbb_perror_msg(WARN\"can't stat %s/check\", *service);\n\t\treturn 0;\n\t}\n\t/* if (!(s.st_mode & S_IXUSR)) return 1; */\n\tprog[0] = (char*)\"./check\";\n\tprog[1] = NULL;\n\tpid = spawn(prog);\n\tif (pid <= 0) {\n\t\tbb_perror_msg(WARN\"can't %s child %s/check\", \"run\", *service);\n\t\treturn 0;\n\t}\n\twhile (safe_waitpid(pid, &w, 0) == -1) {\n\t\tbb_perror_msg(WARN\"can't %s child %s/check\", \"wait for\", *service);\n\t\treturn 0;\n\t}\n\treturn WEXITSTATUS(w) == 0;\n}",
    "comment": "Checks for the existence of the \"check\" script, executes it, and returns true if it exits successfully.",
    "prorec_sum": "Checks for the existence and execution of a \"./check\" program, waits for its child process to finish, and returns success if it exits cleanly.",
    "filter_prorec_sum": "Checks for a \"./check\" file, executes it if present, waits for its child process, and returns success if the child exits cleanly.",
    "prorec_aug_sum": "Checks for the existence of the \"./check\" file, attempts to run and wait for it, and returns success status or logs warnings.",
    "filter_prorec_aug_sum": "Checks if the \"./check\" file exists, executes it as a child process, waits for completion, and returns success status with warnings on failure.",
    "work_score": {
        "prorec": {
            "summary": "Checks for the existence and execution of a \"./check\" program, waits for its child process to finish, and returns success if it exits cleanly.",
            "score": [
                1.0,
                0.5,
                0.7
            ],
            "reason": [
                "The summary accurately captures the main behavior: it checks for the existence of the './check' program, executes it as a child process, waits for its completion, and considers it successful if the exit status is zero. All claims correspond directly to the source code logic with no contradictions or irrelevant statements, demonstrating high alignment with the code semantics.",
                "The summary accurately states the core function: it checks for a \"./check\" program, executes it, waits for completion, and returns success on clean exit. This covers the core purpose derived from the code with similar specificity. However, it omits secondary details such as the specific handling of missing files (returns 1 for ENOENT), error logging via bb_perror_msg on stat/spawn/wait failures, and the exact return values in non-success cases. These omissions mean secondary behavior coverage is limited.",
                "The summary accurately captures the core purpose: it checks for the './check' program, executes it via a child process, waits for completion, and returns success if the exit status is zero. There are no contradictions with the code and no significant noise; however, the description is somewhat generic and omits handling of missing files and error messaging, making the gain modest rather than high."
            ]
        },
        "filter_prorec": {
            "summary": "Checks for a \"./check\" file, executes it if present, waits for its child process, and returns success if the child exits cleanly.",
            "score": [
                0.9,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately states that the function checks for a \"./check\" file, executes it if present, waits for its child process, and returns success if the child exits cleanly. These details align with the source code: the stat call checks for the file, spawn runs it, safe_waitpid waits, and WEXITSTATUS determines success. Minor omission exists regarding error handling and return value differences for missing files versus failures, but all main behavior claims are correct, leading to high accuracy.",
                "The summary accurately captures the core behavior of detecting the \"./check\" file, executing it, waiting for completion, and returning success on a clean exit, which aligns with the primary purpose of the function. However, it omits secondary details such as handling ENOENT by returning 1, issuing warnings via bb_perror_msg on stat, spawn, and waitpid failures, and returning 0 in those error cases. These omissions reduce completeness of coverage of error handling and side effects.",
                "The summary correctly captures the core behavior: it checks for the './check' file, runs it if found, waits for its process, and returns true if it exits successfully. All claims are accurate and align with the source code semantics, including the use of WEXITSTATUS to determine success. There is no noise or inaccuracies, and the description is concise yet specific to the function's purpose."
            ]
        }
    }
}
{
    "source_code": "\nstatic int ieee80211_scan(struct wiphy *wiphy,\n\t\t\t  struct cfg80211_scan_request *req)\n{\n\tstruct ieee80211_sub_if_data *sdata;\n\n\tsdata = IEEE80211_WDEV_TO_SUB_IF(req->wdev);\n\n\tswitch (ieee80211_vif_type_p2p(&sdata->vif)) {\n\tcase NL80211_IFTYPE_STATION:\n\tcase NL80211_IFTYPE_ADHOC:\n\tcase NL80211_IFTYPE_MESH_POINT:\n\tcase NL80211_IFTYPE_P2P_CLIENT:\n\tcase NL80211_IFTYPE_P2P_DEVICE:\n\t\tbreak;\n\tcase NL80211_IFTYPE_P2P_GO:\n\t\tif (sdata->local->ops->hw_scan)\n\t\t\tbreak;\n\t\t/*\n\t\t * FIXME: implement NoA while scanning in software,\n\t\t * for now fall through to allow scanning only when\n\t\t * beaconing hasn't been configured yet\n\t\t */\n\tcase NL80211_IFTYPE_AP:\n\t\t/*\n\t\t * If the scan has been forced (and the driver supports\n\t\t * forcing), don't care about being beaconing already.\n\t\t * This will create problems to the attached stations (e.g. all\n\t\t * the  frames sent while scanning on other channel will be\n\t\t * lost)\n\t\t */\n\t\tif (sdata->u.ap.beacon &&\n\t\t    (!(wiphy->features & NL80211_FEATURE_AP_SCAN) ||\n\t\t     !(req->flags & NL80211_SCAN_FLAG_AP)))\n\t\t\treturn -EOPNOTSUPP;\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn ieee80211_request_scan(sdata, req);\n}",
    "comment": "Handles scanning requests for various Wi-Fi interface types, ensuring appropriate conditions are met before initiating a scan.",
    "prorec_sum": "Processes a network object based on its type and flags, invoking a routing-related handler when conditions meet specific protocol and state requirements.",
    "filter_prorec_sum": "Processes a network object's state and type to decide whether to forward IPv6 routing information or return an error code.",
    "prorec_aug_sum": "Checks connection state and type codes, then conditionally forwards parameters to a handler or returns an error based on device and session flags.",
    "filter_prorec_aug_sum": "Checks a device or connection state and conditionally forwards parameters to another handler based on mode, flags, and associated structure field values.",
    "work_score": {
        "prorec": {
            "summary": "Processes a network object based on its type and flags, invoking a routing-related handler when conditions meet specific protocol and state requirements.",
            "score": [
                0.3,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claim about processing a network object based on type and flags is generally aligned with the code\u2019s switch over interface types and conditional checks. However, the reference to a 'routing-related handler' is inaccurate; the function invokes a scan request, not routing logic. The conditions in the code relate to Wi-Fi interface modes and scanning capabilities, not specific 'protocol and state requirements' in the networking sense the summary implies. Overall, only part of the claim matches the source behavior, with significant semantic drift in the handler description.",
                "The summary does not accurately reflect the core purpose of initiating an IEEE 802.11 scan based on interface type and driver/AP capabilities. It misstates the behavior as routing-related processing, which contradicts the source code\u2019s wireless scan logic. No [ACCURATE] claims cover the core domain action, and secondary details like interface type checks, beacon state conditions, and error returns are absent.",
                "The summary mischaracterizes the core function: the code performs wireless scan requests depending on interface type and specific flags, not routing-related handling. The claim about processing a 'network object' based on type and flags is overly generic, but the statement about invoking a routing-related handler is inaccurate because the call is to a scan request handler. This is a FATAL error affecting the primary purpose, with little accurate detail present and no GOLD-level insight."
            ]
        },
        "filter_prorec": {
            "summary": "Processes a network object's state and type to decide whether to forward IPv6 routing information or return an error code.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary claims the function processes a network object's state and type to decide whether to forward IPv6 routing information, which is unrelated to the source code. The source code implements a scan request logic for different interface types in an IEEE 802.11 context, not IPv6 routing. All fact-based claims in the summary are inaccurate because they misrepresent the domain and the behavior/contract of the function.",
                "The summary's claim about processing a network object's state to forward IPv6 routing information is entirely inaccurate, as the source code handles Wi-Fi interface type checks to decide whether to initiate a scan or return an unsupported error. The core purpose of performing conditional IEEE 802.11 scan initiation is not mentioned, and there is no accurate coverage of any secondary behaviors such as handling AP beaconing, feature flags, or hardware scan capabilities.",
                "The summary makes a highly specific claim about forwarding IPv6 routing information, which is not present in the source code. The function instead decides whether to initiate a wireless scan based on interface type, beaconing status, and driver capabilities, returning an error if unsupported. This is a severe FATAL error on the primary purpose, as it describes completely unrelated behavior to the actual core domain action, rendering the summary unusable."
            ]
        }
    }
}
{
    "source_code": "void dnotify_flush(struct file *filp, fl_owner_t id)\n{\n\tstruct fsnotify_mark *fsn_mark;\n\tstruct dnotify_mark *dn_mark;\n\tstruct dnotify_struct *dn;\n\tstruct dnotify_struct **prev;\n\tstruct inode *inode;\n\n\tinode = file_inode(filp);\n\tif (!S_ISDIR(inode->i_mode))\n\t\treturn;\n\n\tfsn_mark = fsnotify_find_inode_mark(dnotify_group, inode);\n\tif (!fsn_mark)\n\t\treturn;\n\tdn_mark = container_of(fsn_mark, struct dnotify_mark, fsn_mark);\n\n\tmutex_lock(&dnotify_mark_mutex);\n\n\tspin_lock(&fsn_mark->lock);\n\tprev = &dn_mark->dn;\n\twhile ((dn = *prev) != NULL) {\n\t\tif ((dn->dn_owner == id) && (dn->dn_filp == filp)) {\n\t\t\t*prev = dn->dn_next;\n\t\t\tkmem_cache_free(dnotify_struct_cache, dn);\n\t\t\tdnotify_recalc_inode_mask(fsn_mark);\n\t\t\tbreak;\n\t\t}\n\t\tprev = &dn->dn_next;\n\t}\n\n\tspin_unlock(&fsn_mark->lock);\n\n\t/* nothing else could have found us thanks to the dnotify_mark_mutex */\n\tif (dn_mark->dn == NULL)\n\t\tfsnotify_destroy_mark(fsn_mark, dnotify_group);\n\n\tmutex_unlock(&dnotify_mark_mutex);\n\n\tfsnotify_put_mark(fsn_mark);\n}",
    "comment": "Removes a dnotify structure associated with a file if the owner ID matches, and cleans up the corresponding fsnotify mark if no more notifications exist.",
    "prorec_sum": "Removes a matching entry from an inode-associated list, processes related metadata updates, and finalizes state changes with synchronization.",
    "filter_prorec_sum": "Removes a matching inode entry from an internal list, updates related structures, and finalizes state changes with synchronization locks.",
    "prorec_aug_sum": "Removes a matching entry from a linked list under a spinlock, processes it, updates reference counts, and finalizes state if the list becomes empty.",
    "filter_prorec_aug_sum": "Removes a matching lock entry from a linked list, updates related structures, and finalizes state synchronization for the targeted resource.",
    "work_score": {
        "prorec": {
            "summary": "Removes a matching entry from an inode-associated list, processes related metadata updates, and finalizes state changes with synchronization.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly describes removing a matching entry from an inode-associated list, which matches the loop searching for dn_owner and dn_filp and unlinking the struct. It also notes processing related metadata updates, consistent with the call to dnotify_recalc_inode_mask, and mentions finalizing state changes with synchronization, which aligns with the mutex and spinlock usage. While the claims are somewhat high-level, they are accurate reflections of the source code and cover the main semantics without contradictions.",
                "The summary correctly notes that the function removes an entry from a list tied to an inode, updates metadata, and uses synchronization, which matches the code's removal of a dnotify entry, recalculation of the inode mask, and mutex/spin locks. However, it does not capture the core purpose with sufficient specificity \u2014 namely flushing dnotify marks for a given file and owner in a directory inode \u2014 nor does it mention key error/branch handling like returning early for non-directory inodes or missing marks, or conditional destruction of the fsnotify mark. Secondary behaviors such as freeing memory are also omitted.",
                "The summary correctly captures that the function removes a matching entry from an inode-associated list and does metadata updates with synchronization, which matches the loop removing `dn` entries and calls like `dnotify_recalc_inode_mask` under locks. However, it is generic and omits specific matching criteria (`dn_owner` and `dn_filp` comparison), conditional mark destruction, and precise synchronization mechanisms used. The claims are accurate but low-information, with no contradictory or irrelevant points, resulting in low gain from accuracy and minimal noise."
            ]
        },
        "filter_prorec": {
            "summary": "Removes a matching inode entry from an internal list, updates related structures, and finalizes state changes with synchronization locks.",
            "score": [
                0.8,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly captures the general behavior: the function removes a matching entry from an internal list, updates related structures, and uses synchronization locks, which aligns with the code\u2019s removal of a matching dnotify_struct, its memory free operations, inode mask recalculations, and use of mutex and spinlock. However, the wording is overly generic and omits key specifics such as the conditional checks for directory type, matching owner and file, and destruction of the mark when the list is empty. Most claims are accurate but lack precise details matching the source semantics.",
                "The summary correctly notes removing an entry and updating structures with synchronization, aligning vaguely with the code\u2019s removal of a matching dnotify entry and use of locks. However, it fails to capture the core purpose: specifically flushing dnotify marks for a directory inode matching a given file and owner, recalculating masks, and potentially destroying the mark. No mention of directory-only check, ownership/file match criteria, mark destruction, or memory freeing is present, making coverage of secondary critical behavior quite thin.",
                "The summary contains mostly generic, low-information claims that broadly match the code but omit key specifics such as operating only on directory inodes, matching both owner and file pointer, freeing memory from a cache, and recalculating the inode mask. While the statement about synchronization locks and updating structures is accurate in a general sense, it lacks detail and context. There are no clearly inaccurate or contradictory claims, but the noise is high relative to the minimal specific content, resulting in low net benefit."
            ]
        }
    }
}
{
    "source_code": "\nint x86_pmu_handle_irq(struct pt_regs *regs)\n{\n\tstruct perf_sample_data data;\n\tstruct cpu_hw_events *cpuc;\n\tstruct perf_event *event;\n\tint idx, handled = 0;\n\tu64 val;\n\n\tcpuc = &__get_cpu_var(cpu_hw_events);\n\n\t/*\n\t * Some chipsets need to unmask the LVTPC in a particular spot\n\t * inside the nmi handler.  As a result, the unmasking was pushed\n\t * into all the nmi handlers.\n\t *\n\t * This generic handler doesn't seem to have any issues where the\n\t * unmasking occurs so it was left at the top.\n\t */\n\tapic_write(APIC_LVTPC, APIC_DM_NMI);\n\n\tfor (idx = 0; idx < x86_pmu.num_counters; idx++) {\n\t\tif (!test_bit(idx, cpuc->active_mask)) {\n\t\t\t/*\n\t\t\t * Though we deactivated the counter some cpus\n\t\t\t * might still deliver spurious interrupts still\n\t\t\t * in flight. Catch them:\n\t\t\t */\n\t\t\tif (__test_and_clear_bit(idx, cpuc->running))\n\t\t\t\thandled++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tevent = cpuc->events[idx];\n\n\t\tval = x86_perf_event_update(event);\n\t\tif (val & (1ULL << (x86_pmu.cntval_bits - 1)))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * event overflow\n\t\t */\n\t\thandled++;\n\t\tperf_sample_data_init(&data, 0, event->hw.last_period);\n\n\t\tif (!x86_perf_event_set_period(event))\n\t\t\tcontinue;\n\n\t\tif (perf_event_overflow(event, &data, regs))\n\t\t\tx86_pmu_stop(event, 0);\n\t}\n\n\tif (handled)\n\t\tinc_irq_stat(apic_perf_irqs);\n\n\treturn handled;\n}",
    "comment": "Handles performance monitoring unit interrupts by checking active counters, updating event values, and managing event overflows, while ensuring proper NMI handling.",
    "prorec_sum": "Scans a per-CPU list of memory structures, processes those matching conditions, and increments a global counter for successfully handled entries.",
    "filter_prorec_sum": "Iterates over CPU-associated entries, checks bit flags, processes eligible ones, and increments a global counter for successfully handled entries.",
    "prorec_aug_sum": "Iterates over active CPU entries, checking scheduling constraints and performing runtime updates, then increments a kernel per\u2011CPU counter if qualifying tasks are processed.",
    "filter_prorec_aug_sum": "Iterates over active CPU entries, checks scheduling conditions, and triggers task handling routines while updating a global counter for processed CPUs.",
    "work_score": {
        "prorec": {
            "summary": "Scans a per-CPU list of memory structures, processes those matching conditions, and increments a global counter for successfully handled entries.",
            "score": [
                0.3,
                0.1,
                0.4
            ],
            "reason": [
                "The summary's claim about scanning per-CPU memory structures and processing those matching conditions is loosely accurate, as the code iterates over per-CPU data structures. However, the description omits critical domain-specific details such as handling active counters, updating events, and overflow detection. The statement about incrementing a global counter for handled entries is somewhat accurate but oversimplifies the usage of inc_irq_stat for performance IRQs. Overall, the claims are too generic and miss precise function semantics, with less than half being highly specific and verifiable against the source.",
                "The summary describes a generic iteration over per-CPU memory structures and a global counter increment but omits the core domain-specific purpose: handling x86 performance monitoring unit hardware interrupts, updating counters, detecting overflows, and invoking perf event handling routines. There is no mention of IRQ handling, APIC interaction, performance counters, or overflow detection, so the core is not covered, and secondary behavioral details are also missing.",
                "The summary makes a generic claim about scanning per-CPU memory structures and incrementing a global counter for handled entries. While partially aligning with the loop over per-CPU events and the final inc_irq_stat call, it omits critical specifics such as handling performance monitoring unit interrupts, checking active masks, updating counters, detecting overflows, and invoking event-specific handlers. The statement is overly broad and lacks noise reduction value, providing low insight into the function\u2019s actual core behavior, but does not contradict the code directly."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates over CPU-associated entries, checks bit flags, processes eligible ones, and increments a global counter for successfully handled entries.",
            "score": [
                0.6,
                0.2,
                0.5
            ],
            "reason": [
                "The summary captures general iteration over CPU-related entries, checking flags, and incrementing a counter for handled cases, which aligns with the loop logic, bitmask checks, and final increment in the source code. However, it omits key specifics such as handling spurious interrupts for inactive counters, updating event values, detecting overflow, reloading periods, and stopping events. While mostly accurate on broad control flow, the lack of explicit mention of core domain behavior reduces precision.",
                "The summary correctly notes iteration over CPU-associated entries, checking bit flags, and incrementing a global counter, which are accurate generic behaviors from the code. However, it fails to cover the core domain purpose of handling x86 PMU interrupt events and processing performance counter overflows, as well as numerous specific behaviors such as unmasking APIC_LVTPC, distinguishing inactive counters, updating event counters, reloading periods, and stopping events on overflow. The omission of these key semantics results in missing the core purpose and most secondary details.",
                "The summary correctly notes iteration over CPU-related entries, flag checks, and updating a global counter, which matches the loop, bit testing, and inc_irq_stat logic in the code. However, it omits critical specifics such as handling spurious interrupts, updating performance events, detecting overflows, reinitializing sample data, setting event periods, and stopping events. These omissions mean the PRIMARY PURPOSE\u2014handling PMU IRQs with detailed counter processing\u2014is underrepresented, but there is no outright contradiction. The gain is low due to the generic description, and noise is minimal."
            ]
        }
    }
}
{
    "source_code": "int Findjob_set_name_expr(struct FindjoB *o, char *name_expr, int flag)\n{\n char *regexpr= NULL;\n regex_t *name_re;\n struct ExprtesT *t;\n int ret;\n\n regexpr= TSOB_FELD(char, 2*SfileadrL+2);\n if(regexpr == NULL)\n   {ret= -1; goto ex;}\n if(strlen(name_expr)>=SfileadrL)\n   {ret= 0; goto ex;};\n\n ret= Findjob_default_and(o, 0);\n if(ret <= 0)\n   goto ex;\n t= o->cursor->test;\n t->test_type= 1;\n if ((flag & 3) == 1)\n   t->test_type= 13;\n else if((flag & 3) == 2)\n   t->test_type= 16;\n else if((flag & 3) == 3)\n   t->test_type= 20;\n t->arg1= strdup(name_expr);\n if(t->arg1 == NULL)\n   {ret= -1; goto ex;};\n\n if((flag & 3) == 3)\n   {ret= 1; goto ex;}\n\n name_re= (regex_t *) calloc(1, sizeof(regex_t));\n if(name_re == NULL)\n   {ret= -1; goto ex;};\n Xorriso__bourne_to_reg(name_expr, regexpr, 0);\n if(regcomp(name_re, regexpr, 0) != 0) {\n   free((char *) name_re);\n   {ret= 0; goto ex;};\n }\n t->arg2= name_re;\n ret= 1;\nex:;\n Xorriso_free_meM(regexpr);\n return(ret);\n}",
    "comment": "Constructs a regex from a given name expression and updates a job's testing criteria based on a specified flag, returning success status.",
    "prorec_sum": "Compiles a regex from the given pattern string, stores it with associated mode flags in a target structure, and returns success or error status.",
    "filter_prorec_sum": "Compiles a provided pattern string into a regex object, stores it in a structure, and configures matching mode based on the given flag.",
    "prorec_aug_sum": "Compiles a regex from the given pattern string, stores it with configuration flags in a target structure, and returns success or failure.",
    "filter_prorec_aug_sum": "Compiles a provided pattern string into a regex object, stores it with associated mode, and updates the target structure accordingly.",
    "work_score": {
        "prorec": {
            "summary": "Compiles a regex from the given pattern string, stores it with associated mode flags in a target structure, and returns success or error status.",
            "score": [
                0.8,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly notes that the function compiles a regex from the given string, stores it in a target structure, and returns a status, which aligns with core behavior in the source code. However, it inaccurately states that associated mode flags are stored with the regex; while flags influence test_type assignment, they are not directly stored with the regex. This minor inaccuracy reduces overall claim precision, though most claims remain accurate.",
                "The summary correctly states that the function compiles a regex from the input string, applies mode flags, stores it in a target structure, and returns a status, which matches the core primary purpose of constructing and storing a compiled regex based on the provided name expression and flags. However, it omits several important secondary behaviors present in the code, such as setting different test_type values based on flag bits, handling special case where flag==3 by skipping regex compilation, validating input length, and detailed error handling for memory allocation or regex compilation failures. These omissions result in incomplete coverage of critical control flow and edge cases.",
                "The summary correctly notes that a regex is compiled from the input string and stored in a target structure, and that a status code is returned, which aligns with the source code. However, it omits several key specifics: the conditional logic for setting test_type based on flag values, the case where regex compilation is skipped when flag & 3 equals 3, the strdup of the name_expr into arg1, and early returns for length and allocation failures. No outright contradictions (no FATAL), but the account is overly generic, with limited coverage of the function\u2019s detailed behavior, making the net benefit low."
            ]
        },
        "filter_prorec": {
            "summary": "Compiles a provided pattern string into a regex object, stores it in a structure, and configures matching mode based on the given flag.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function compiles the provided string into a regex object and stores it in a structure, and that the matching mode is configured based on the flag. These align with the code's use of `regcomp` on a transformed `name_expr`, assigning it to `t->arg2`, and setting `t->test_type` depending on `flag & 3`. However, it omits important details such as validation checks, memory allocation failures, early returns when certain conditions are met, and special handling when the flag value leads to skipping regex compilation. Despite these omissions, the included claims are accurate and code-related, with no incorrect statements.",
                "The summary correctly notes compiling the provided pattern into a regex, storing it in a structure, and configuring matching mode based on the flag \u2014 all key actions seen in the code. This covers the core purpose of setting up a regex-based name match with mode selection. However, it omits critical secondary behaviors such as memory allocation and deallocation steps, error handling for allocation and regex compilation failures, and flag-specific early return behavior when flag & 3 equals 3. These missed details reduce completeness.",
                "The summary correctly identifies that the function compiles a provided string into a regex object and stores it in a structure, and notes configuration based on the flag, which matches the code logic. However, it omits important details such as allocation failure handling, length checks on the input string, early returns when certain flags are set, and initial setup via Findjob_default_and. There are no inaccurate claims, but the coverage is shallow and lacks specific domain semantics, resulting in low informational gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void tg3_phy_toggle_apd(struct tg3 *tp, bool enable)\n{\n\tu32 reg;\n\n\tif (!tg3_flag(tp, 5705_PLUS) ||\n\t    (tg3_flag(tp, 5717_PLUS) &&\n\t     (tp->phy_flags & TG3_PHYFLG_MII_SERDES)))\n\t\treturn;\n\n\tif (tp->phy_flags & TG3_PHYFLG_IS_FET) {\n\t\ttg3_phy_fet_toggle_apd(tp, enable);\n\t\treturn;\n\t}\n\n\treg = MII_TG3_MISC_SHDW_WREN |\n\t      MII_TG3_MISC_SHDW_SCR5_SEL |\n\t      MII_TG3_MISC_SHDW_SCR5_LPED |\n\t      MII_TG3_MISC_SHDW_SCR5_DLPTLM |\n\t      MII_TG3_MISC_SHDW_SCR5_SDTL |\n\t      MII_TG3_MISC_SHDW_SCR5_C125OE;\n\tif (tg3_asic_rev(tp) != ASIC_REV_5784 || !enable)\n\t\treg |= MII_TG3_MISC_SHDW_SCR5_DLLAPD;\n\n\ttg3_writephy(tp, MII_TG3_MISC_SHDW, reg);\n\n\n\treg = MII_TG3_MISC_SHDW_WREN |\n\t      MII_TG3_MISC_SHDW_APD_SEL |\n\t      MII_TG3_MISC_SHDW_APD_WKTM_84MS;\n\tif (enable)\n\t\treg |= MII_TG3_MISC_SHDW_APD_ENABLE;\n\n\ttg3_writephy(tp, MII_TG3_MISC_SHDW, reg);\n}",
    "comment": "Toggles the APD feature of a PHY interface based on device flags and configurations, writing appropriate values to the hardware registers.",
    "prorec_sum": "Updates specific ATA port register fields to control flags and values based on device status and the provided command parameter.",
    "filter_prorec_sum": "Updates specific SATA PHY control registers to enable or disable features based on device flags and input, ensuring proper link configuration.",
    "prorec_aug_sum": "Updates specific PHY/MAC register fields based on status flags and input parameter to control link or media configuration on a network adapter.",
    "filter_prorec_aug_sum": "Updates specific PHY register bits based on link and management flags to control hardware behavior according to the given enable or disable parameter.",
    "work_score": {
        "prorec": {
            "summary": "Updates specific ATA port register fields to control flags and values based on device status and the provided command parameter.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary incorrectly describes the function as updating ATA port register fields and controlling ATA flags based on device status and a command parameter. The source code operates on PHY register shadow fields within a tg3 network driver to toggle auxiliary power down (APD) based on hardware flags and revision, with no relation to ATA ports. This mismatch means none of the claims are accurate regarding the code's semantics.",
                "The summary incorrectly describes the function as dealing with ATA port registers and device status, which contradicts the source code's actual purpose of toggling Auto Power Down (APD) features in a Broadcom tg3 PHY via specific MII shadow register writes. The core domain action is not mentioned, and none of the claims align with the source code semantics; all content is inaccurate and unrelated to the implementation.",
                "The summary's sole claim describes updating ATA port registers per device status and a command parameter, which is completely unrelated to the source code. The function actually toggles Auto Power Down (APD) settings for a PHY in tg3 network hardware by writing to MII_TG3_MISC_SHDW registers, not ATA ports. This is a FATAL inaccuracy on the primary purpose, targeting core semantics incorrectly, leaving no accurate domain information and making the description unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Updates specific SATA PHY control registers to enable or disable features based on device flags and input, ensuring proper link configuration.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly claims the function updates SATA PHY control registers, while the source code operates on Ethernet PHY registers for tg3 devices. Although it notes enabling/disabling features based on flags and inputs, the misidentification of the protocol type is a critical inaccuracy that undermines alignment. The majority of the summary's information is thus inaccurate with respect to the code\u2019s actual domain semantics.",
                "The summary incorrectly states that the function updates \"SATA PHY\" registers, while the source code clearly manipulates Broadcom tg3 Ethernet PHY registers using tg3_writephy and MII_TG3_MISC_SHDW constants. This misidentifies the domain and therefore the core purpose is not covered. While it vaguely mentions toggling features based on flags and input, the description is too generic and inaccurate to reflect the specific action of toggling Auto Power Down and related PHY settings, and it omits other critical details like early returns for certain ASIC revisions or FET handling.",
                "The summary contains a major inaccuracy: it claims the function updates SATA PHY control registers, while the source code clearly operates on Ethernet PHY registers in a Broadcom tg3 driver, toggling automatic power-down features based on device flags and conditions. This is a FATAL error affecting the primary purpose description. The mention of enabling/disabling features based on flags is somewhat accurate but generic, and cannot offset the severe misidentification of the hardware domain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void calc_mode_timings(int xres, int yres, int refresh,\n\t\t\t      struct fb_videomode *mode)\n{\n\tstruct fb_var_screeninfo *var;\n\n\tvar = kzalloc(sizeof(struct fb_var_screeninfo), GFP_KERNEL);\n\n\tif (var) {\n\t\tvar->xres = xres;\n\t\tvar->yres = yres;\n\t\tfb_get_mode(FB_VSYNCTIMINGS | FB_IGNOREMON,\n\t\t\t    refresh, var, NULL);\n\t\tmode->xres = xres;\n\t\tmode->yres = yres;\n\t\tmode->pixclock = var->pixclock;\n\t\tmode->refresh = refresh;\n\t\tmode->left_margin = var->left_margin;\n\t\tmode->right_margin = var->right_margin;\n\t\tmode->upper_margin = var->upper_margin;\n\t\tmode->lower_margin = var->lower_margin;\n\t\tmode->hsync_len = var->hsync_len;\n\t\tmode->vsync_len = var->vsync_len;\n\t\tmode->vmode = 0;\n\t\tmode->sync = 0;\n\t\tkfree(var);\n\t}\n}",
    "comment": "Calculates video mode timings based on resolution and refresh rate, populating the provided fb_videomode structure with these settings.",
    "prorec_sum": "Allocates and initializes a PCI bus-related data structure with provided parameters, updates the target structure fields, and finalizes the allocation.",
    "filter_prorec_sum": "Allocates and initializes a 160-byte structure with provided parameters, updates target memory fields, then finalizes and releases the allocated structure.",
    "prorec_aug_sum": "Allocates and initializes a 160-byte structure with provided parameters, updates related memory fields, and finalizes by releasing the allocated structure.",
    "filter_prorec_aug_sum": "Allocates and initializes a 160-byte structure with provided parameters, updates related fields in a target buffer, then releases the allocated structure.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a PCI bus-related data structure with provided parameters, updates the target structure fields, and finalizes the allocation.",
            "score": [
                0.1,
                0.1,
                0.1
            ],
            "reason": [
                "The summary incorrectly describes allocating and initializing a PCI bus-related data structure, while the source code allocates a framebuffer-related struct (fb_var_screeninfo), sets resolution/refresh parameters, copies timing fields to the target fb_videomode, and frees the allocation. The only partially accurate element is that it mentions updating the target structure fields, but most claims are inaccurate and unrelated to the actual code semantics, resulting in very low alignment.",
                "The summary incorrectly describes PCI bus-related behavior, which is not present in the source code. The function actually allocates a fb_var_screeninfo structure, computes mode timings using resolution and refresh rate, updates an fb_videomode structure, and frees the allocation. The core purpose of calculating and populating display mode timing information is entirely missing, and no accurate claims match the true semantics.",
                "The summary is entirely inaccurate as it describes allocating and initializing a PCI bus-related data structure, while the source code actually allocates a framebuffer screen info structure, computes video mode timings, and populates a target fb_videomode structure. This is a severe FATAL error on the primary purpose and I/O, making the description misleading for the core function behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a 160-byte structure with provided parameters, updates target memory fields, then finalizes and releases the allocated structure.",
            "score": [
                0.7,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly notes allocation, setting fields from parameters, and eventual release of the structure, aligning with the source code. However, it inaccurately specifies a constant size of 160 bytes, which is not indicated in the code. This incorrect size detail reduces overall accuracy, though most of the described behavior matches the implementation.",
                "The summary notes allocation, initialization, field updates, and freeing of a structure, which generally aligns with parts of the code. However, it incorrectly specifies a fixed 160-byte size for the allocation, which contradicts the source\u2019s actual sizeof(struct fb_var_screeninfo). It also fails to cover the core purpose of calculating mode timings by calling fb_get_mode with specific flags and copying timing-related fields to the target mode. This omission means the main domain-specific behavior is not represented.",
                "The summary contains one specific claim about allocating a 160-byte structure, which is inaccurate because the code allocates sizeof(struct fb_var_screeninfo) and the exact size is not stated in the source. While it correctly notes allocation, initialization with provided parameters, updating target structure fields, and freeing the allocated memory, the inaccurate size detail targets code semantics and misstates a key aspect. This is a FATAL error about the core operation (allocation details), significantly reducing trustworthiness despite some accurate generic statements."
            ]
        }
    }
}
{
    "source_code": "int img_collect_inos(IsoImage *image, IsoDir *dir, int flag)\n{\n    int ret, register_dir = 1;\n    IsoDirIter *iter = NULL;\n    IsoNode *node;\n    IsoDir *subdir;\n\n    if (dir == NULL)\n        dir = image->root;\n    if (image->used_inodes == NULL) {\n        image->used_inodes = calloc(ISO_USED_INODE_RANGE / 8, 1);\n        if (image->used_inodes == NULL)\n            return ISO_OUT_OF_MEM;\n    } else if(!(flag & 1)) {\n        memset(image->used_inodes, 0, ISO_USED_INODE_RANGE / 8);\n    } else {\n        register_dir = 0;\n    }\n    if (register_dir) {\n        node = (IsoNode *) dir;\n        ret = img_register_ino(image, node, 0);\n        if (ret < 0)\n            return ret;\n    }\n\n    ret = iso_dir_get_children(dir, &iter);\n    if (ret < 0)\n        return ret;\n    while (iso_dir_iter_next(iter, &node) == 1 ) {\n        ret = img_register_ino(image, node, 0);\n        if (ret < 0)\n            goto ex;\n        if (iso_node_get_type(node) == LIBISO_DIR) {\n            subdir = (IsoDir *) node;\n            ret = img_collect_inos(image, subdir, flag | 1);\n            if (ret < 0)\n                goto ex;\n        }\n    }\n    ret = 1;\nex:;\n    if (iter != NULL)\n        iso_dir_iter_free(iter);\n    return ret;\n}",
    "comment": "Registers inodes for an ISO image and its subdirectories, initializing used inode tracking if necessary.",
    "prorec_sum": "Recursively processes ISO9660 directory entries, allocating and resetting buffers, and traversing subdirectories while invoking helper routines for each entry.",
    "filter_prorec_sum": "Recursively processes ISO9660 directory entries, allocating and clearing buffers as needed, and traverses subdirectories while invoking directory entry handling routines.",
    "prorec_aug_sum": "Initializes a 32\u202fKB buffer in the image structure and recursively processes file or directory entries while preserving existing data when requested.",
    "filter_prorec_aug_sum": "Recursively processes ISO9660 directory entries, allocating or clearing a buffer, and invoking handlers for each subentry while tracking operation results.",
    "work_score": {
        "prorec": {
            "summary": "Recursively processes ISO9660 directory entries, allocating and resetting buffers, and traversing subdirectories while invoking helper routines for each entry.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly captures the recursive traversal of ISO9660 directory entries, allocation/reset of the used_inodes buffer, and invocation of helper routines for each entry, all of which align with the source code. There are no contradictory or irrelevant claims, and each element is domain-specific and verifiable in the function\u2019s logic, indicating high accuracy.",
                "The summary correctly mentions recursive processing of ISO9660 directory entries, allocation/resetting of buffers, and traversal of subdirectories with helper invocations, which aligns with the function\u2019s core purpose of registering inodes for each node in directories and subdirectories. However, it omits specific domain-critical details such as the inode registration logic (`img_register_ino`), handling of the `flag` parameter to control resetting or registering the root directory, and the error-handling branches. The coverage of secondary behavior is minimal and lacks error cases and conditional handling specifics.",
                "The summary correctly captures the primary purpose of recursively traversing ISO directory entries and invoking helper routines, aligning with the function's core behavior. It also notes buffer allocation and resetting, which matches the calloc and memset usage in the code. However, it omits specific details such as handling the NULL 'dir' parameter, the 'flag' logic to control whether to register the starting directory, and returning error codes from helper functions. The omissions reduce its informativeness, though there are no inaccurate or contradictory claims and noise is minimal."
            ]
        },
        "filter_prorec": {
            "summary": "Recursively processes ISO9660 directory entries, allocating and clearing buffers as needed, and traverses subdirectories while invoking directory entry handling routines.",
            "score": [
                0.8,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly captures the recursive traversal of ISO9660 directory entries and subdirectories as well as the allocation and clearing of buffers, aligning with the code\u2019s behavior of initializing `used_inodes` and calling `img_collect_inos` on subdirectories. However, it is vague about the specific operations such as inode registration and flag handling, using the generic term 'directory entry handling routines' without mentioning `img_register_ino` or iteration logic. Most claims are accurate but at a high level, with minimal detail loss impacting precision slightly.",
                "The summary correctly notes the recursive traversal of ISO9660 directories and buffer allocation/clearing, which aligns with the code\u2019s handling of iterating over directory entries, allocating `used_inodes`, and recursing into subdirectories. However, it does not capture the core purpose of registering inodes via `img_register_ino`, which is the primary domain-specific action. Secondary behaviors like flag handling, error checks, and iterator cleanup are also omitted.",
                "The summary accurately captures the primary purpose of recursively processing ISO9660 directory entries and traversing subdirectories, which matches the source code's directory iteration and recursion. It also correctly notes buffer allocation and clearing for used_inodes, though it uses generic phrasing like \"directory entry handling routines\" instead of the specific img_register_ino operation, resulting in low specificity. There are no incorrect or contradictory claims, but the gain is limited due to broad, non-detailed language that offers little engineering insight."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nxmlFARegExecSaveInputString(xmlRegExecCtxtPtr exec, const xmlChar *value,\n\t                    void *data) {\n#ifdef DEBUG_PUSH\n    printf(\"saving value: %d:%s\\n\", exec->inputStackNr, value);\n#endif\n    if (exec->inputStackMax == 0) {\n\texec->inputStackMax = 4;\n\texec->inputStack = (xmlRegInputTokenPtr)\n\t    xmlMalloc(exec->inputStackMax * sizeof(xmlRegInputToken));\n\tif (exec->inputStack == NULL) {\n\t    xmlRegexpErrMemory(NULL, \"pushing input string\");\n\t    exec->inputStackMax = 0;\n\t    return;\n\t}\n    } else if (exec->inputStackNr + 1 >= exec->inputStackMax) {\n\txmlRegInputTokenPtr tmp;\n\n\texec->inputStackMax *= 2;\n\ttmp = (xmlRegInputTokenPtr) xmlRealloc(exec->inputStack,\n\t\t\texec->inputStackMax * sizeof(xmlRegInputToken));\n\tif (tmp == NULL) {\n\t    xmlRegexpErrMemory(NULL, \"pushing input string\");\n\t    exec->inputStackMax /= 2;\n\t    return;\n\t}\n\texec->inputStack = tmp;\n    }\n    exec->inputStack[exec->inputStackNr].value = xmlStrdup(value);\n    exec->inputStack[exec->inputStackNr].data = data;\n    exec->inputStackNr++;\n    exec->inputStack[exec->inputStackNr].value = NULL;\n    exec->inputStack[exec->inputStackNr].data = NULL;\n}",
    "comment": "Stores an input string and associated data in a dynamically expanding stack within the xmlRegExecCtxt structure.",
    "prorec_sum": "Adds a duplicated XML string and associated data to a dynamically resized array stored in the given context structure.",
    "filter_prorec_sum": "Adds a duplicated XML string and associated data to a dynamically resized array within the given structure.",
    "prorec_aug_sum": "Adds a duplicated XML string and associated metadata to a dynamically resized array within the parser context structure.",
    "filter_prorec_aug_sum": "Adds a duplicated XML string and associated data into a dynamically resized array within the given structure.",
    "work_score": {
        "prorec": {
            "summary": "Adds a duplicated XML string and associated data to a dynamically resized array stored in the given context structure.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary accurately describes the function's main behavior: duplicating an XML string, associating data with it, and storing these in a dynamically resized array within the provided context. This aligns with the source code, which reallocates the input stack as needed, stores xmlStrdup(value) and data, and increments the index. There are no incorrect or irrelevant claims, indicating high precision.",
                "The summary accurately captures the core purpose of adding a duplicated XML string and its associated data to a dynamically resized array within the context structure. This aligns with the main domain action in the source code. However, it omits important secondary details such as initial allocation when the stack is empty, doubling capacity on overflow, error handling when memory allocation fails, and setting trailing NULL values. These omissions reduce completeness despite correct core coverage.",
                "The summary correctly captures the core functionality: duplicating the provided XML string, associating it with accompanying data, and storing it in a dynamically resized array within the context structure. This aligns with the source code\u2019s semantics and primary purpose without introducing inaccuracies or irrelevant noise. While concise and accurate, it provides moderate detail and lacks deeper specifics about memory allocation branching and NULL termination, so the gain is solid but not maximal."
            ]
        },
        "filter_prorec": {
            "summary": "Adds a duplicated XML string and associated data to a dynamically resized array within the given structure.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function duplicates the XML string, associates it with given data, and stores it in a dynamically resized array within the provided structure. These details directly match the source code\u2019s behavior: use of xmlStrdup for duplication, dynamic resizing via xmlMalloc/xmlRealloc, and storing both value and data in exec->inputStack. No inaccuracies are present, and the claim is specific and verifiable against the code.",
                "The summary correctly captures the core purpose: adding a duplicated XML string and data to a dynamically resized array in the structure, matching the code\u2019s behavior of duplicating the value with xmlStrdup and storing it along with data in inputStack, resizing when needed. However, it omits other important semantics such as initial allocation when stackMax is zero, error handling on malloc/realloc failures, setting NULL sentinels after insertion, and the DEBUG_PUSH logging. These omissions reduce coverage of secondary details.",
                "The summary correctly captures the primary purpose: duplicating an XML string and storing it with related data in a dynamically resized array. It reflects the core behavior\u2014dynamic resizing of the input stack, storage of duplicated strings, and associated data\u2014without introducing inaccuracies. There is no noise or contradiction, but the claim is generic and lacks details about conditions (e.g., initial allocation, capacity doubling, memory error handling), resulting in low informational gain."
            ]
        }
    }
}
{
    "source_code": "static void statPush(\n  sqlite3_context *context,\n  int argc,\n  sqlite3_value **argv\n){\n  int i;\n\n  /* The three function arguments */\n  Stat4Accum *p = (Stat4Accum*)sqlite3_value_blob(argv[0]);\n  int iChng = sqlite3_value_int(argv[1]);\n\n  UNUSED_PARAMETER( argc );\n  UNUSED_PARAMETER( context );\n  assert( p->nCol>0 );\n  assert( iChng<p->nCol );\n\n  if( p->nRow==0 ){\n    /* This is the first call to this function. Do initialization. */\n    for(i=0; i<p->nCol; i++) p->current.anEq[i] = 1;\n  }else{\n    /* Second and subsequent calls get processed here */\n    samplePushPrevious(p, iChng);\n\n    /* Update anDLt[], anLt[] and anEq[] to reflect the values that apply\n    ** to the current row of the index. */\n    for(i=0; i<iChng; i++){\n      p->current.anEq[i]++;\n    }\n    for(i=iChng; i<p->nCol; i++){\n      p->current.anDLt[i]++;\n#ifdef SQLITE_ENABLE_STAT3_OR_STAT4\n      p->current.anLt[i] += p->current.anEq[i];\n#endif\n      p->current.anEq[i] = 1;\n    }\n  }\n  p->nRow++;\n#ifdef SQLITE_ENABLE_STAT3_OR_STAT4\n  if( sqlite3_value_type(argv[2])==SQLITE_INTEGER ){\n    sampleSetRowidInt64(p->db, &p->current, sqlite3_value_int64(argv[2]));\n  }else{\n    sampleSetRowid(p->db, &p->current, sqlite3_value_bytes(argv[2]),\n                                       sqlite3_value_blob(argv[2]));\n  }\n  p->current.iHash = p->iPrn = p->iPrn*1103515245 + 12345;\n#endif\n\n#ifdef SQLITE_ENABLE_STAT4\n  {\n    tRowcnt nLt = p->current.anLt[p->nCol-1];\n\n    /* Check if this is to be a periodic sample. If so, add it. */\n    if( (nLt/p->nPSample)!=(nLt+1)/p->nPSample ){\n      p->current.isPSample = 1;\n      p->current.iCol = 0;\n      sampleInsert(p, &p->current, p->nCol-1);\n      p->current.isPSample = 0;\n    }\n\n    /* Update the aBest[] array. */\n    for(i=0; i<(p->nCol-1); i++){\n      p->current.iCol = i;\n      if( i>=iChng || sampleIsBetterPost(p, &p->current, &p->aBest[i]) ){\n        sampleCopy(p, &p->aBest[i], &p->current);\n      }\n    }\n  }\n#endif\n}",
    "comment": "Processes statistical data by updating counts and tracking samples based on input changes and row identifiers within a given dataset structure.",
    "prorec_sum": "Updates cache entry counters and flags based on provided index, initializing entries when empty and incrementing relevant ranges before returning the final index.",
    "filter_prorec_sum": "Updates indexed counters and flags within a cache entry structure based on lookup results, incrementing tracking fields and marking relevant positions as active.",
    "prorec_aug_sum": "Updates counters and flags in a list-like structure based on an index from input parameters, then increments the structure\u2019s primary operation count.",
    "filter_prorec_aug_sum": "Updates counters and flags in a data structure based on an input index, initializing entries if empty and incrementing usage tracking fields.",
    "work_score": {
        "prorec": {
            "summary": "Updates cache entry counters and flags based on provided index, initializing entries when empty and incrementing relevant ranges before returning the final index.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains mostly inaccurate claims. It describes 'cache entry counters and flags' and 'returning the final index', which are not present in the source code. The function manipulates statistics arrays (anEq, anDLt, anLt) and sampling arrays in a Stat4Accum object, not a cache. Only the initial description of 'initializing entries when empty' loosely aligns with the initialization logic in the code. Overall, fewer than half of the claims accurately reflect the actual source behavior.",
                "The summary describes generic updates to cache entries, counters, and flags, but does not mention the core domain-specific purpose of processing and maintaining statistical samples for SQLite indices, including initialization, updating anEq/anDLt/anLt arrays, handling periodic samples, and maintaining aBest[] entries. The core operation of updating column-based statistics and sample sets is missing, and the description's terminology (cache entries, final index) is inaccurate relative to the source code's semantics.",
                "The summary incorrectly describes the function\u2019s primary purpose, framing it as updating cache entry counters with a final index return, while the source code shows it operates on Stat4Accum structures to maintain statistical counters and samples without returning a value. This is a FATAL error on the core domain action. The summary omits key verifiable behaviors such as initializing anEq, updating anDLt/anLt arrays, conditionally inserting periodic samples, and updating aBest entries, thereby failing to capture the actual I/O and side effects. The inaccuracies significantly outweigh any correct generic aspects."
            ]
        },
        "filter_prorec": {
            "summary": "Updates indexed counters and flags within a cache entry structure based on lookup results, incrementing tracking fields and marking relevant positions as active.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary makes generic claims about updating counters, flags, and marking positions as active, but it introduces incorrect context by referring to a 'cache entry structure' and 'lookup results'\u2014concepts not present in the source code. The function manipulates statistical tracking arrays within a Stat4Accum structure based on column changes and sampling logic, not cache lookups. While there is superficial accuracy in mentioning updates to counters, most claims are either inaccurate or vague, resulting in well under half of the claims aligning correctly with the actual code semantics.",
                "The summary vaguely mentions updating counters and flags but does not capture the core purpose of maintaining and sampling index statistics in a Stat4Accum structure. The source code\u2019s primary function is to process successive index rows, adjust equality/less-than counters, perform periodic sampling, and update best samples, with handling for first-call initialization and various STAT3/STAT4-specific branches. These details, including row id setting and sampling insertion logic, are absent, and the wording about 'cache entry' and 'lookup results' is inaccurate for this domain.",
                "The summary is inaccurate because it describes updating a cache entry structure based on lookup results, which does not align with the source code. The function actually processes a Stat4Accum structure, initializing and updating statistical counters related to database index sampling, with no mention of cache entries or lookups. This is a FATAL error on the primary purpose, as it misidentifies the domain entirely, making the description misleading and unreliable."
            ]
        }
    }
}
{
    "source_code": "\nstatic u32\nacpi_ex_convert_to_ascii(u64 integer, u16 base, u8 *string, u8 data_width)\n{\n\tu64 digit;\n\tu32 i;\n\tu32 j;\n\tu32 k = 0;\n\tu32 hex_length;\n\tu32 decimal_length;\n\tu32 remainder;\n\tu8 supress_zeros;\n\n\tACPI_FUNCTION_ENTRY();\n\n\tswitch (base) {\n\tcase 10:\n\n\t\t/* Setup max length for the decimal number */\n\n\t\tswitch (data_width) {\n\t\tcase 1:\n\t\t\tdecimal_length = ACPI_MAX8_DECIMAL_DIGITS;\n\t\t\tbreak;\n\n\t\tcase 4:\n\t\t\tdecimal_length = ACPI_MAX32_DECIMAL_DIGITS;\n\t\t\tbreak;\n\n\t\tcase 8:\n\t\tdefault:\n\t\t\tdecimal_length = ACPI_MAX64_DECIMAL_DIGITS;\n\t\t\tbreak;\n\t\t}\n\n\t\tsupress_zeros = TRUE;\t/* No leading zeros */\n\t\tremainder = 0;\n\n\t\tfor (i = decimal_length; i > 0; i--) {\n\n\t\t\t/* Divide by nth factor of 10 */\n\n\t\t\tdigit = integer;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t\t(void)acpi_ut_short_divide(digit, 10, &digit,\n\t\t\t\t\t\t\t   &remainder);\n\t\t\t}\n\n\t\t\t/* Handle leading zeros */\n\n\t\t\tif (remainder != 0) {\n\t\t\t\tsupress_zeros = FALSE;\n\t\t\t}\n\n\t\t\tif (!supress_zeros) {\n\t\t\t\tstring[k] = (u8) (ACPI_ASCII_ZERO + remainder);\n\t\t\t\tk++;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase 16:\n\n\t\t/* hex_length: 2 ascii hex chars per data byte */\n\n\t\thex_length = ACPI_MUL_2(data_width);\n\t\tfor (i = 0, j = (hex_length - 1); i < hex_length; i++, j--) {\n\n\t\t\t/* Get one hex digit, most significant digits first */\n\n\t\t\tstring[k] =\n\t\t\t    (u8) acpi_ut_hex_to_ascii_char(integer,\n\t\t\t\t\t\t\t   ACPI_MUL_4(j));\n\t\t\tk++;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn (0);\n\t}\n\n\t/*\n\t * Since leading zeros are suppressed, we must check for the case where\n\t * the integer equals 0\n\t *\n\t * Finally, null terminate the string and return the length\n\t */\n\tif (!k) {\n\t\tstring[0] = ACPI_ASCII_ZERO;\n\t\tk = 1;\n\t}\n\n\tstring[k] = 0;\n\treturn ((u32) k);\n}",
    "comment": "Converts a given integer to its ASCII representation in either decimal or hexadecimal format based on specified parameters and returns the string length.",
    "prorec_sum": "Formats numeric data from the given source into a string buffer as decimal or hexadecimal based on input parameters and returns its length.",
    "filter_prorec_sum": "Generates a numeric string representation from input data, formatting either decimal digits or extracted bytes based on specified type and length parameters.",
    "prorec_aug_sum": "Converts an ACPI object\u2019s numeric data into a null\u2011terminated decimal or hexadecimal string representation based on the specified type and length.",
    "filter_prorec_aug_sum": "Formats data from a given source into a hexadecimal or decimal string representation based on input parameters and stores it in the output buffer.",
    "work_score": {
        "prorec": {
            "summary": "Formats numeric data from the given source into a string buffer as decimal or hexadecimal based on input parameters and returns its length.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function formats numeric data into a string buffer in either decimal or hexadecimal format based on input parameters and returns its length. These claims align with the source code\u2019s switch on base values (10 and 16), the string building logic, and the return of the length. While the summary omits details such as suppression of leading zeros and handling of zero values, the provided claims are accurate and correspond directly to the code\u2019s behavior.",
                "The summary correctly states the core purpose of converting a numeric value to a decimal or hexadecimal string and returning its length, matching the main domain operation in the code. However, it omits important secondary details such as suppression of leading zeros in decimal mode, behavior when the input is zero, handling of data width for formatting, and the default case where unsupported bases result in a return of 0. These omissions limit coverage of key behavior-critical semantics.",
                "The summary accurately states the core purpose: converting a numeric value to a decimal or hexadecimal string based on parameters and returning its length. This matches the source code's behavior without introducing contradictions. However, it is generic and omits details such as suppression of leading zeros, handling of different data widths, the null termination of the string, and the handling when the integer is zero. There is no noise or fatal inaccuracy, but the informational gain is low due to lack of specificity."
            ]
        },
        "filter_prorec": {
            "summary": "Generates a numeric string representation from input data, formatting either decimal digits or extracted bytes based on specified type and length parameters.",
            "score": [
                0.6,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function generates a numeric string representation and supports decimal formatting, which matches the code\u2019s decimal conversion logic. However, it inaccurately describes hexadecimal processing as 'extracted bytes based on specified type and length,' which is vague and does not clearly reflect the actual per-digit hex conversion process in the source. This results in only partial alignment with the code semantics, lowering precision of claims.",
                "The summary correctly states that the function generates a numeric string in either decimal or an alternative format based on parameters, which partially matches the source code's core purpose. However, it inaccurately describes the hexadecimal formatting as 'extracted bytes' rather than explicitly converting to ASCII hex characters, omits the suppression of leading zeros, treatment of zero values, null-termination, and the conditional handling based on base and data width. The core action of converting an integer to an ASCII string in decimal or hexadecimal is covered, but secondary, behavior-critical details are missing.",
                "The summary correctly captures that the function generates a numeric string representation and supports decimal formatting, but it inaccurately states that hexadecimal output is based on 'extracted bytes' rather than converting digits from the integer according to a base of 16. It omits key details such as suppression of leading zeros, null termination, handling of zero cases, and the specific branching by data width. The inaccuracies are moderate and the gain is low, with only a general description of behavior and no GOLD-level specifics."
            ]
        }
    }
}
{
    "source_code": "static void renameTriggerFunc(\n  sqlite3_context *context,\n  int NotUsed,\n  sqlite3_value **argv\n){\n  unsigned char const *zSql = sqlite3_value_text(argv[0]);\n  unsigned char const *zTableName = sqlite3_value_text(argv[1]);\n\n  int token;\n  Token tname;\n  int dist = 3;\n  unsigned char const *zCsr = zSql;\n  int len = 0;\n  char *zRet;\n  sqlite3 *db = sqlite3_context_db_handle(context);\n\n  UNUSED_PARAMETER(NotUsed);\n\n  /* The principle used to locate the table name in the CREATE TRIGGER \n  ** statement is that the table name is the first token that is immediately\n  ** preceded by either TK_ON or TK_DOT and immediately followed by one\n  ** of TK_WHEN, TK_BEGIN or TK_FOR.\n  */\n  if( zSql ){\n    do {\n\n      if( !*zCsr ){\n        /* Ran out of input before finding the table name. Return NULL. */\n        return;\n      }\n\n      /* Store the token that zCsr points to in tname. */\n      tname.z = (char*)zCsr;\n      tname.n = len;\n\n      /* Advance zCsr to the next token. Store that token type in 'token',\n      ** and its length in 'len' (to be used next iteration of this loop).\n      */\n      do {\n        zCsr += len;\n        len = sqlite3GetToken(zCsr, &token);\n      }while( token==TK_SPACE );\n      assert( len>0 );\n\n      /* Variable 'dist' stores the number of tokens read since the most\n      ** recent TK_DOT or TK_ON. This means that when a WHEN, FOR or BEGIN \n      ** token is read and 'dist' equals 2, the condition stated above\n      ** to be met.\n      **\n      ** Note that ON cannot be a database, table or column name, so\n      ** there is no need to worry about syntax like \n      ** \"CREATE TRIGGER ... ON ON.ON BEGIN ...\" etc.\n      */\n      dist++;\n      if( token==TK_DOT || token==TK_ON ){\n        dist = 0;\n      }\n    } while( dist!=2 || (token!=TK_WHEN && token!=TK_FOR && token!=TK_BEGIN) );\n\n    /* Variable tname now contains the token that is the old table-name\n    ** in the CREATE TRIGGER statement.\n    */\n    zRet = sqlite3MPrintf(db, \"%.*s\\\"%w\\\"%s\", (int)(((u8*)tname.z) - zSql),\n       zSql, zTableName, tname.z+tname.n);\n    sqlite3_result_text(context, zRet, -1, SQLITE_DYNAMIC);\n  }\n}",
    "comment": "Replaces the old table name in a CREATE TRIGGER SQL statement with a new table name provided as an argument.",
    "prorec_sum": "Parses a byte stream for specific opcode sequences and, upon matching, formats and dispatches a constructed string payload for further processing.",
    "filter_prorec_sum": "Parses a byte stream, detects specific control codes, and formats a quoted string with embedded data for further processing or dispatch.",
    "prorec_aug_sum": "Parses a byte sequence, checks token codes, and formats a labeled string with inserted data before dispatching it through a processing callback.",
    "filter_prorec_aug_sum": "Parses a byte sequence, detects specific token codes, and formats a quoted string with additional data for further processing.",
    "work_score": {
        "prorec": {
            "summary": "Parses a byte stream for specific opcode sequences and, upon matching, formats and dispatches a constructed string payload for further processing.",
            "score": [
                0.1,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims the function parses a byte stream for opcode sequences and dispatches a payload, which misrepresents the actual behavior. The source code processes SQL text to locate a table name in a CREATE TRIGGER statement and replaces it, with no concept of opcodes or generic byte stream processing. All factual claims are inaccurate and do not align with the code\u2019s purpose.",
                "The summary incorrectly describes the function as parsing a byte stream for opcode sequences and dispatching a payload, which does not match the actual SQLite-specific logic in the source. The core purpose is to locate a table name in a CREATE TRIGGER SQL statement and replace it with a new name, which is entirely absent from the summary. No accurate claims about the function's domain behavior are present, so the core is not covered and there is no valid secondary detail.",
                "The summary's core claim about parsing a byte stream for specific opcode sequences is inaccurate; the function parses a SQL CREATE TRIGGER statement string to locate a table name based on token patterns, not arbitrary byte-stream opcodes. This is a FATAL error about the primary purpose. There are no accurate claims reflecting the actual behavior, so the net benefit is zero."
            ]
        },
        "filter_prorec": {
            "summary": "Parses a byte stream, detects specific control codes, and formats a quoted string with embedded data for further processing or dispatch.",
            "score": [
                0.2,
                0.1,
                0.3
            ],
            "reason": [
                "The summary claims that the function parses a byte stream, detects control codes, and formats a quoted string for dispatch. While the function does parse text tokens and format a string with embedded table name, the term 'byte stream' and 'control codes' are inaccurate given the source code operates on SQL strings and token types, not generic control codes. It also omits the specific trigger renaming logic and conditions involving TK_ON, TK_DOT, TK_WHEN, TK_FOR, and TK_BEGIN. These omissions and inaccuracies mean less than half of the claims correctly reflect the code.",
                "The summary does not accurately reflect the source code\u2019s core purpose, which is to locate the original table name within a CREATE TRIGGER SQL statement based on specific token sequences (TK_ON/TK_DOT followed by TK_WHEN/TK_FOR/TK_BEGIN), then replace it with a new table name using sqlite3 formatting APIs. The described 'byte stream' parsing and 'control codes' are incorrect in this context; the function is parsing SQL tokens, not generic control codes. As a result, the core semantic is entirely missing and no accurate secondary behaviors are covered.",
                "The summary contains several inaccuracies: it claims the function parses a byte stream and detects control codes, which do not align with the actual token-based parsing logic to locate a table name in a CREATE TRIGGER SQL string. It omits the core purpose of finding and replacing the table name in the SQL statement, thus missing the primary I/O and domain semantics. Noise dominates since its description focuses on unrelated concepts like 'control codes' and 'dispatch', providing little correct insight beyond generic formatting mention."
            ]
        }
    }
}
{
    "source_code": "int blk_bio_map_sg(struct request_queue *q, struct bio *bio,\n\t\t   struct scatterlist *sglist)\n{\n\tstruct bio_vec *bvec, *bvprv;\n\tstruct scatterlist *sg;\n\tint nsegs, cluster;\n\tunsigned long i;\n\n\tnsegs = 0;\n\tcluster = blk_queue_cluster(q);\n\n\tbvprv = NULL;\n\tsg = NULL;\n\tbio_for_each_segment(bvec, bio, i) {\n\t\t__blk_segment_map_sg(q, bvec, sglist, &bvprv, &sg,\n\t\t\t\t     &nsegs, &cluster);\n\t} /* segments in bio */\n\n\tif (sg)\n\t\tsg_mark_end(sg);\n\n\tBUG_ON(bio->bi_phys_segments && nsegs > bio->bi_phys_segments);\n\treturn nsegs;\n}",
    "comment": "Maps segments of a block I/O bio to a scatter-gather list, updating the number of segments and handling physical segment constraints.",
    "prorec_sum": "Iterates over consecutive block entries, processes them via a helper, updates allocation flags, and enforces maximum block count constraints.",
    "filter_prorec_sum": "Iterates over consecutive filesystem block entries, processes them with a helper, updates status flags, and returns the count of successfully handled blocks.",
    "prorec_aug_sum": "Processes consecutive entries from a table, invokes a helper for each, updates flags, and validates the total processed count against a limit.",
    "filter_prorec_aug_sum": "Processes consecutive data chunks from a specified index, updating tracking variables and flags, and verifies the processed count does not exceed defined limits.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over consecutive block entries, processes them via a helper, updates allocation flags, and enforces maximum block count constraints.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary contains multiple claims, including iterating over consecutive block entries, processing them via a helper, updating allocation flags, and enforcing maximum block count constraints. The code indeed iterates over bio segments using a helper function and enforces a constraint on the number of segments, which are accurate. However, the mention of 'consecutive block entries' is less precise than the actual 'bio segments', and 'updates allocation flags' does not match any explicit flag logic in the source code, making it inaccurate. Approximately half of the claims align with the source, resulting in mixed reliability.",
                "The summary describes iteration over block entries and enforcing maximum block count constraints, which loosely relates to looping over bio segments and checking against bi_phys_segments. However, it omits the core purpose of mapping bio segments into a scatter-gather list using a helper function, which is the primary operation in the source code. The mention of 'updates allocation flags' is inaccurate as the function does not manage allocation flags, and 'consecutive block entries' is less precise than the actual bio segment iteration. Overall, the core domain action is not covered and some claims do not match code semantics.",
                "The summary claims the function iterates over block entries and uses a helper, which is broadly accurate for the bio_for_each_segment loop and __blk_segment_map_sg call. However, it inaccurately states that it updates allocation flags and enforces maximum block count constraints\u2014these terms do not appear in the source; the code instead tracks scatter-gather segments and ensures the number of physical segments does not exceed bio->bi_phys_segments. These inaccuracies introduce noise and misrepresent semantics. While there is no severe contradiction about the primary purpose, the specific gain is low due to vague wording and incorrect details."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates over consecutive filesystem block entries, processes them with a helper, updates status flags, and returns the count of successfully handled blocks.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains mostly inaccurate claims about the function's behavior. It correctly notes iteration over elements and processing via a helper, but incorrectly identifies them as 'filesystem block entries' instead of bio segments, misstates 'updates status flags' which is not shown in the code, and inaccurately describes returning the count of 'successfully handled blocks' instead of returning the number of mapped scatter-gather segments. Less than half of the claims align with the source code semantics, indicating low accuracy.",
                "The summary incorrectly frames the function as operating on filesystem block entries and handling status flags, which contradicts the source code's actual domain of mapping a bio's segments into a scatterlist for I/O. The core purpose of iterating over bio segments and invoking __blk_segment_map_sg to populate a scatterlist is not covered. There is no accurate claim that matches the specific domain operation, and secondary details like marking the end scatterlist entry and validating segment counts are also missing.",
                "The summary claims the function iterates over filesystem block entries, which is inaccurate since it processes bio segments, not generic filesystem blocks. It also states that it updates status flags, which is not present in the source code, and refers to 'successfully handled blocks', which is misleading because the function simply counts mapped segments without success checks. These are FATAL inaccuracies targeting the primary purpose and core I/O description, making the summary unreliable. Accurate detail is minimal."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\ncleanup (void)\n{\n  if (close (STDIN_FILENO) < 0)\n    die (EXIT_FAILURE, errno, _(\"closing input file %s\"), quoteaf (input_file));\n\n  /* Don't remove this call to close, even though close_stdout\n     closes standard output.  This close is necessary when cleanup\n     is called as part of a signal handler.  */\n  if (close (STDOUT_FILENO) < 0)\n    die (EXIT_FAILURE, errno,\n         _(\"closing output file %s\"), quoteaf (output_file));\n}",
    "comment": "Cleans up temporary nodes by unlinking their associated names and resets the temporary head pointer to NULL.",
    "prorec_sum": "Handles specific signals by optionally logging, resetting timers, and sending them to a target process and process group using POSIX `kill` and `signal`.",
    "filter_prorec_sum": "Handles signal delivery to a process, optionally logging \u201csending signal %s to command %s\u201d, and triggering related cleanup and follow-up signals.",
    "prorec_aug_sum": "Handles signal delivery to a specified process, optionally logging the action, and sends additional stop signals unless certain signal types are specified.",
    "filter_prorec_aug_sum": "Handles signal dispatch to a process, optionally logging \u201csending signal %s to command %s\u201d, and manages follow\u2011up stop/continue signals based on global flags.",
    "work_score": {
        "prorec": {
            "summary": "Handles specific signals by optionally logging, resetting timers, and sending them to a target process and process group using POSIX `kill` and `signal`.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary describes behavior involving signal handling, logging, timers, and use of POSIX `kill` and `signal`, none of which occur in the source code. The code only closes standard input and output and handles possible errors. All claims are unrelated to actual code semantics, resulting in no accurate matches.",
                "The summary describes signal handling, logging, and usage of POSIX `kill` and `signal`, which are entirely unrelated to the source code's actual purpose of closing standard input and output file descriptors during cleanup, possibly in a signal handler, and handling errors via `die`. None of the claims match the core domain operation, resulting in no coverage of core or secondary semantics.",
                "The summary entirely misrepresents the source code. The function simply closes STDIN and STDOUT, handling errors with `die`, and is intended to be used in cleanup, possibly in a signal handler. There is no use of `kill`, `signal`, timers, or sending signals to processes/groups. This is a FATAL inaccuracy about the core purpose, which claims signal handling when the code is strictly about closing file descriptors."
            ]
        },
        "filter_prorec": {
            "summary": "Handles signal delivery to a process, optionally logging \u201csending signal %s to command %s\u201d, and triggering related cleanup and follow-up signals.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary describes signal handling, logging, and sending signals to commands, which are not reflected in the source code. The function only closes STDIN and STDOUT, handling errors via `die`, and notes a special case for cleanup in a signal handler. None of the claims in the summary are accurate with respect to the code's actual semantics, resulting in 0% accurate claims.",
                "The summary describes behavior related to sending signals and logging, which is unrelated to the actual function. The source code performs cleanup by closing standard input and output, with error handling, particularly noting its use in signal handlers. The core purpose of closing file descriptors and handling potential errors is completely missing, and none of the claims in the summary are accurate with respect to the code.",
                "The summary claims the function handles signal delivery, logs signal and command information, and triggers follow-up signals. None of these are present in the source code, which solely closes standard input/output file descriptors and reports errors. All claims are NOISE with no accurate reflection of the actual cleanup behavior, making them completely irrelevant to the code\u2019s primary purpose. The worst failure mode is overwhelming NOISE without any accurate detail."
            ]
        }
    }
}
{
    "source_code": "int schedule_on_each_cpu(work_func_t func)\n{\n\tint cpu;\n\tstruct work_struct __percpu *works;\n\n\tworks = alloc_percpu(struct work_struct);\n\tif (!works)\n\t\treturn -ENOMEM;\n\n\tget_online_cpus();\n\n\tfor_each_online_cpu(cpu) {\n\t\tstruct work_struct *work = per_cpu_ptr(works, cpu);\n\n\t\tINIT_WORK(work, func);\n\t\tschedule_work_on(cpu, work);\n\t}\n\n\tfor_each_online_cpu(cpu)\n\t\tflush_work(per_cpu_ptr(works, cpu));\n\n\tput_online_cpus();\n\tfree_percpu(works);\n\treturn 0;\n}",
    "comment": "Schedules a specified work function on each online CPU and waits for their completion before freeing allocated resources.",
    "prorec_sum": "Initializes per-CPU structures, iterates over all CPUs to configure data with provided parameters, then finalizes by cleaning up and freeing allocated memory.",
    "filter_prorec_sum": "Allocates a buffer and initializes per-IRQ data structures, processes them with provided parameters, then finalizes and frees allocated resources.",
    "prorec_aug_sum": "Iterates over registered objects, initializes and processes them with provided parameters, finalizes their state, and releases allocated resources.",
    "filter_prorec_aug_sum": "Allocates memory, iterates over indexed objects to initialize them with provided parameters, processes each, then finalizes and frees allocated resources.",
    "work_score": {
        "prorec": {
            "summary": "Initializes per-CPU structures, iterates over all CPUs to configure data with provided parameters, then finalizes by cleaning up and freeing allocated memory.",
            "score": [
                0.8,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly notes initialization of per-CPU structures, iteration over CPUs, and cleanup of allocated memory, which matches the code's alloc_percpu, for_each_online_cpu loops, and free_percpu. However, it generically says 'configure data with provided parameters' instead of specifying that it initializes and schedules work using the given function pointer, omitting key semantic details of the domain behavior. Most claims are accurate but lack precision, resulting in slightly reduced alignment.",
                "The summary correctly notes initialization of per-CPU structures, iteration over CPUs, and cleanup/freeing memory, which aligns with parts of the source code. However, it fails to state the core purpose: scheduling and executing a given work function on each online CPU, including flushing the work, which is central to the function\u2019s domain behavior. Secondary details such as error handling for allocation failure, use of get_online_cpus/put_online_cpus, and synchronous execution via flush_work are also missing, making coverage incomplete.",
                "The summary correctly notes initialization of per-CPU structures, iteration over CPUs, and cleanup/freeing memory, which matches the source code. However, it omits key specifics: the configuration is actually initialization and scheduling of work with the provided function, followed by flushing that work. These omissions mean the core purpose and I/O semantics are incompletely described. There is no outright contradiction (no FATAL), but the accuracy is limited and detail is generic, resulting in low gain."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates a buffer and initializes per-IRQ data structures, processes them with provided parameters, then finalizes and frees allocated resources.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as dealing with per-IRQ data structures and processing with provided parameters, which does not align with the source code's actual behavior of allocating per-CPU work structures, initializing them with a given function, scheduling work on each CPU, and cleaning up. This results in most claims being inaccurate, with only the resource allocation and freeing aspects partially aligning.",
                "The summary\u2019s claims about allocating a buffer, initializing per-IRQ data structures, and processing with parameters are inaccurate relative to the source code, which allocates per-CPU work structures, schedules a given function on each online CPU, flushes the work, and then frees resources. The core purpose of scheduling work on each online CPU is not covered, and most descriptions misinterpret the domain semantics, leaving no accurate coverage of critical behaviors.",
                "The summary's core claim about allocating a buffer and initializing per-IRQ data structures is inaccurate, as the function allocates per-CPU work_structs, not per-IRQ data. This is a severe FATAL error affecting the primary purpose and I/O semantics. While it correctly notes allocation, processing, and freeing resources in a generic sense, the noise from incorrect context (IRQ) undermines trust and provides low net benefit."
            ]
        }
    }
}
{
    "source_code": "\nstatic int put_compat_statfs(struct compat_statfs __user *ubuf, struct kstatfs *kbuf)\n{\n\t\n\tif (sizeof ubuf->f_blocks == 4) {\n\t\tif ((kbuf->f_blocks | kbuf->f_bfree | kbuf->f_bavail |\n\t\t     kbuf->f_bsize | kbuf->f_frsize) & 0xffffffff00000000ULL)\n\t\t\treturn -EOVERFLOW;\n\t\t/* f_files and f_ffree may be -1; it's okay\n\t\t * to stuff that into 32 bits */\n\t\tif (kbuf->f_files != 0xffffffffffffffffULL\n\t\t && (kbuf->f_files & 0xffffffff00000000ULL))\n\t\t\treturn -EOVERFLOW;\n\t\tif (kbuf->f_ffree != 0xffffffffffffffffULL\n\t\t && (kbuf->f_ffree & 0xffffffff00000000ULL))\n\t\t\treturn -EOVERFLOW;\n\t}\n\tif (!access_ok(VERIFY_WRITE, ubuf, sizeof(*ubuf)) ||\n\t    __put_user(kbuf->f_type, &ubuf->f_type) ||\n\t    __put_user(kbuf->f_bsize, &ubuf->f_bsize) ||\n\t    __put_user(kbuf->f_blocks, &ubuf->f_blocks) ||\n\t    __put_user(kbuf->f_bfree, &ubuf->f_bfree) ||\n\t    __put_user(kbuf->f_bavail, &ubuf->f_bavail) ||\n\t    __put_user(kbuf->f_files, &ubuf->f_files) ||\n\t    __put_user(kbuf->f_ffree, &ubuf->f_ffree) ||\n\t    __put_user(kbuf->f_namelen, &ubuf->f_namelen) ||\n\t    __put_user(kbuf->f_fsid.val[0], &ubuf->f_fsid.val[0]) ||\n\t    __put_user(kbuf->f_fsid.val[1], &ubuf->f_fsid.val[1]) ||\n\t    __put_user(kbuf->f_frsize, &ubuf->f_frsize) ||\n\t    __put_user(kbuf->f_flags, &ubuf->f_flags) ||\n\t    __clear_user(ubuf->f_spare, sizeof(ubuf->f_spare)))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
    "comment": "Validates and transfers filesystem statistics from kernel to user space, ensuring no overflow occurs for 32-bit fields.",
    "prorec_sum": "Validates 64-bit fields from a user-provided structure for 32-bit compliance, copies them into a destination array, and performs a final integrity check.",
    "filter_prorec_sum": "Validates 64-bit fields from a user-provided structure for 32-bit constraints, copies them into a destination buffer, and performs additional range checks.",
    "prorec_aug_sum": "Validates multiple 64-bit fields from a2 for 32-bit range, copies them into a1, and performs additional bounds and integrity checks before returning.",
    "filter_prorec_aug_sum": "Validates 64-bit fields for 32-bit range compliance, copies them into an output structure, and performs a final bounds check before returning success or error codes.",
    "work_score": {
        "prorec": {
            "summary": "Validates 64-bit fields from a user-provided structure for 32-bit compliance, copies them into a destination array, and performs a final integrity check.",
            "score": [
                0.3,
                0.3,
                0.2
            ],
            "reason": [
                "The summary incorrectly states that the function copies fields into a destination array, whereas the source code writes fields from a kernel struct into a user-provided struct using __put_user. It also mislabels the integrity check: the code performs specific overflow checks for certain fields and an access validation, but not a generic final integrity check. Only the part about validating 64-bit fields for 32-bit compliance is accurate, resulting in less than half of the claims being correct.",
                "The summary mentions validation of 64-bit fields for 32-bit compliance, which aligns with the overflow checks in the source code, but it inaccurately states that data is copied into a 'destination array' and that a 'final integrity check' is performed. The actual code writes fields into a user-provided struct using __put_user and __clear_user, with final error handling based on access_ok and write results. The core purpose\u2014writing kstatfs data to a compat_statfs user structure with overflow checks\u2014is only partly covered, and secondary details like per-field copying, access validation, and specific return codes are missing or misrepresented.",
                "The summary contains key inaccuracies. It states that data is copied into a 'destination array', but in the code the data is transferred into a user-provided compat_statfs structure via __put_user calls, not an array. It also mentions a 'final integrity check', which is not present; instead, the function performs overflow checks for 32-bit field compliance before copying, and access verification before writing. These misleading claims target the core purpose and semantics, making them FATAL regarding the function\u2019s data output behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Validates 64-bit fields from a user-provided structure for 32-bit constraints, copies them into a destination buffer, and performs additional range checks.",
            "score": [
                0.7,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function checks 64-bit fields for 32-bit constraints and copies them into another buffer, which matches the code's overflow checks and __put_user calls. However, it inaccurately describes the source of data \u2014 the fields are from a kernel-provided kstatfs struct and written to the user struct, not 'user-provided' input. The mention of 'additional range checks' is vague but aligns with the specific overflow logic present. Overall, most claims are accurate but there is a notable source attribution error.",
                "The summary correctly notes the 64-bit to 32-bit constraint validation and range checks, which correspond to overflow checks when sizeof f_blocks == 4. It also captures the copy operation, though it omits specifics that the copy is from a kernel-space kstatfs to a user-space compat_statfs after access_ok verification. The core purpose of writing kstatfs data to a compat_statfs user buffer with proper overflow and access checks is covered, but secondary details like specific fields copied, error codes (-EOVERFLOW, -EFAULT), and branch conditions are missing, making coverage of secondary behaviors incomplete.",
                "The summary correctly notes that the function checks 64-bit fields against 32-bit constraints and copies data to the destination buffer, which aligns with the code\u2019s overflow checks and __put_user calls. However, it inaccurately states that the source is user-provided and the destination is a buffer, whereas in the code the source is the kernel-space kbuf and the destination is a user-space ubuf. This misrepresentation of the data flow affects the primary purpose, making it a core semantic error (FATAL) despite otherwise accurate range checking description."
            ]
        }
    }
}
{
    "source_code": "\n\nsize_t ZSTD_compressEnd (ZSTD_CCtx* cctx,\n                         void* dst, size_t dstCapacity,\n                   const void* src, size_t srcSize)\n{\n    size_t endResult;\n    size_t const cSize = ZSTD_compressContinue_internal(cctx, dst, dstCapacity, src, srcSize, 1, 1);\n    if (ZSTD_isError(cSize)) return cSize;\n    endResult = ZSTD_writeEpilogue(cctx, (char*)dst + cSize, dstCapacity-cSize);\n    if (ZSTD_isError(endResult)) return endResult;\n    return cSize + endResult;\n}",
    "comment": "Compresses data using a continuation method, writes an epilogue, and returns the total compressed size or an error code if the process fails.",
    "prorec_sum": "Processes a data block with state-driven transformations, writing control values to the output and updating internal state before returning total bytes consumed.",
    "filter_prorec_sum": "Processes a data block with staged state transitions, writes control values, and appends an extra byte from a stored context before returning total bytes handled.",
    "prorec_aug_sum": "Processes a data block with state-dependent steps, writes control and optional values into the buffer, and returns the total bytes written or an error code.",
    "filter_prorec_aug_sum": "Processes a data block based on state flags, writing control values and optional byte, then returns processed length or specific error codes.",
    "work_score": {
        "prorec": {
            "summary": "Processes a data block with state-driven transformations, writing control values to the output and updating internal state before returning total bytes consumed.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains mostly inaccurate claims. The function compresses input data and writes an epilogue, returning the total bytes written, but the description references 'state-driven transformations' and 'control values' which are not evident in the source code. Internal state updates are implied by the compression functions, but 'bytes consumed' is incorrect since the function returns bytes produced. Less than half of the claims accurately reflect the code's operations.",
                "The summary does not clearly state the core purpose of finalizing compression by calling ZSTD_compressContinue_internal followed by ZSTD_writeEpilogue and returning the combined output size. Instead, it uses vague terms like 'state-driven transformations' and 'writing control values', which do not align with the specific compression and epilogue-writing operations in the source code. While it hints at processing data and updating state, it omits critical error handling and function sequencing details, failing to cover the core purpose.",
                "The summary misrepresents the function\u2019s core behavior: it does not mention compression or the specific sequence of calling `ZSTD_compressContinue_internal` and `ZSTD_writeEpilogue`. It incorrectly claims the function writes 'control values' and returns 'bytes consumed', whereas the code writes compressed data, appends an epilogue, and returns total output size in bytes. This is a FATAL inaccuracy about the primary purpose and key I/O, making the description untrustworthy. There are no accurate, specific claims to offset this error."
            ]
        },
        "filter_prorec": {
            "summary": "Processes a data block with staged state transitions, writes control values, and appends an extra byte from a stored context before returning total bytes handled.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about staged state transitions, control values, and appending an extra byte from a stored context do not directly match the source code's semantics. The code actually performs compression continuation and writes an epilogue, returning the sum of their sizes. None of the summary's atomic claims accurately describe these operations, resulting in no verifiable alignment.",
                "The summary does not accurately describe the core purpose of the function, which is completing a compression operation using ZSTD by continuing compression, writing an epilogue, handling errors, and returning the combined size. Claims about staged state transitions, control values, and appending an extra byte from a stored context are not supported by the source code, meaning the core behavior is missed and the content is largely inaccurate.",
                "The summary contains claims about 'staged state transitions', 'writing control values', and 'appending an extra byte from a stored context', none of which are represented in the source code. The actual function calls an internal compression routine, checks for errors, writes an epilogue, and returns the sum of compressed data and epilogue sizes. These mismatched claims are inaccurate and contradict core semantics, especially the primary purpose of handling compression and epilogue writing. This is a severe FATAL error on the core domain action, making the description untrustworthy."
            ]
        }
    }
}
{
    "source_code": "void nfs_init_timeout_values(struct rpc_timeout *to, int proto,\n\t\t\t\t    unsigned int timeo, unsigned int retrans)\n{\n\tto->to_initval = timeo * HZ / 10;\n\tto->to_retries = retrans;\n\n\tswitch (proto) {\n\tcase XPRT_TRANSPORT_TCP:\n\tcase XPRT_TRANSPORT_RDMA:\n\t\tif (to->to_retries == 0)\n\t\t\tto->to_retries = NFS_DEF_TCP_RETRANS;\n\t\tif (to->to_initval == 0)\n\t\t\tto->to_initval = NFS_DEF_TCP_TIMEO * HZ / 10;\n\t\tif (to->to_initval > NFS_MAX_TCP_TIMEOUT)\n\t\t\tto->to_initval = NFS_MAX_TCP_TIMEOUT;\n\t\tto->to_increment = to->to_initval;\n\t\tto->to_maxval = to->to_initval + (to->to_increment * to->to_retries);\n\t\tif (to->to_maxval > NFS_MAX_TCP_TIMEOUT)\n\t\t\tto->to_maxval = NFS_MAX_TCP_TIMEOUT;\n\t\tif (to->to_maxval < to->to_initval)\n\t\t\tto->to_maxval = to->to_initval;\n\t\tto->to_exponential = 0;\n\t\tbreak;\n\tcase XPRT_TRANSPORT_UDP:\n\t\tif (to->to_retries == 0)\n\t\t\tto->to_retries = NFS_DEF_UDP_RETRANS;\n\t\tif (!to->to_initval)\n\t\t\tto->to_initval = NFS_DEF_UDP_TIMEO * HZ / 10;\n\t\tif (to->to_initval > NFS_MAX_UDP_TIMEOUT)\n\t\t\tto->to_initval = NFS_MAX_UDP_TIMEOUT;\n\t\tto->to_maxval = NFS_MAX_UDP_TIMEOUT;\n\t\tto->to_exponential = 1;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n}",
    "comment": "Initializes timeout values for NFS RPC transport depending on the protocol type, setting retries, initial timeout, and limits accordingly.",
    "prorec_sum": "Configures timing parameters and state fields in a structure based on input type, duration, and multiplier, enforcing bounds and defaults for specific modes.",
    "filter_prorec_sum": "Configures timing parameters and related fields for a lock operation based on input type, duration, and count, enforcing upper and default limits.",
    "prorec_aug_sum": "Configures timing parameters and related state fields based on input type and multiplier, enforcing bounds and defaults for subsequent operations.",
    "filter_prorec_aug_sum": "Configures timing parameters and limits in a structure based on operation type, rate, and count, applying defaults and caps for special conditions.",
    "work_score": {
        "prorec": {
            "summary": "Configures timing parameters and state fields in a structure based on input type, duration, and multiplier, enforcing bounds and defaults for specific modes.",
            "score": [
                0.8,
                0.3,
                0.5
            ],
            "reason": [
                "The summary gives a generic description of configuring timing parameters based on input and enforcing bounds, which loosely matches the source code's behavior for TCP and UDP modes. However, it omits many specific, verifiable details such as protocol-specific defaults, exponential flag settings, and max value adjustments. All claims are safe but low-information; no inaccurate statements are made, but precision is low.",
                "The summary captures the general idea of setting parameters in a structure based on type and inputs, and mentions bounds and defaults, which are accurate but generic. It does not explicitly state the core domain action of initializing NFS RPC timeout values for TCP, RDMA, or UDP transports, nor does it highlight critical secondary semantics such as protocol-specific constants, retries handling, increment/max calculation, exponential backoff differences, or the BUG() case. As a result, the core purpose is not clearly covered and secondary detail coverage is minimal.",
                "The summary provides a generic and broadly correct description of setting timing parameters and applying bounds/defaults based on mode, which matches the function's role. However, it lacks specific details about TCP vs UDP behavior, exact fields adjusted, and constants used. There are no incorrect (FATAL) claims targeting the primary purpose, but the information gain is low due to lack of precision, and the generic phrasing reduces utility."
            ]
        },
        "filter_prorec": {
            "summary": "Configures timing parameters and related fields for a lock operation based on input type, duration, and count, enforcing upper and default limits.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as configuring parameters for a lock operation, while the source code clearly configures NFS RPC timeout values depending on transport protocol (TCP or UDP). Although it mentions input type, duration, and count, and the enforcement of upper/default limits\u2014parts of which align with the code\u2014its core operation type is wrong, making the main claim inaccurate. This results in less than half of the claims being accurate.",
                "The summary incorrectly describes the function as configuring timing parameters for a lock operation, which contradicts the source code's actual purpose of initializing NFS RPC timeout values for different transport protocols (TCP, RDMA, UDP). This is a fatal inaccuracy targeting core semantics. Although it mentions timing parameters and limits, these are generic and misapplied to the wrong domain, meaning the core purpose is not covered and secondary protocol-specific behaviors are omitted.",
                "The summary introduces a FATAL inaccuracy by claiming the function configures parameters for a 'lock operation', which contradicts the source code's actual primary purpose of initializing RPC timeout values for NFS based on protocol type, timeo, and retrans parameters. While the mention of enforcing upper and default limits is loosely correct, the core WHAT is wrong, making the description unreliable for understanding the function's semantics."
            ]
        }
    }
}
{
    "source_code": "\nint\nfreadseek (FILE *fp, size_t offset)\n{\n  size_t total_buffered;\n  int fd;\n\n  if (offset == 0)\n    return 0;\n\n  /* Seek over the already read and buffered input as quickly as possible,\n     without doing any system calls.  */\n  total_buffered = freadahead (fp);\n  /* This loop is usually executed at most twice: once for ungetc buffer (if\n     present) and once for the main buffer.  */\n  while (total_buffered > 0)\n    {\n      size_t buffered;\n\n      if (freadptr (fp, &buffered) != NULL && buffered > 0)\n        {\n          size_t increment = (buffered < offset ? buffered : offset);\n\n          freadptrinc (fp, increment);\n          offset -= increment;\n          if (offset == 0)\n            return 0;\n          total_buffered -= increment;\n          if (total_buffered == 0)\n            break;\n        }\n      /* Read one byte.  If we were reading from the ungetc buffer, this\n         switches the stream back to the main buffer.  */\n      if (fgetc (fp) == EOF)\n        goto eof;\n      offset--;\n      if (offset == 0)\n        return 0;\n      total_buffered--;\n    }\n\n  /* Test whether the stream is seekable or not.  */\n  fd = fileno (fp);\n  if (fd >= 0 && lseek (fd, 0, SEEK_CUR) >= 0)\n    {\n      /* FP refers to a regular file.  fseek is most efficient in this case.  */\n      return fseeko (fp, offset, SEEK_CUR);\n    }\n  else\n    {\n      /* FP is a non-seekable stream, possibly not even referring to a file\n         descriptor.  Read OFFSET bytes explicitly and discard them.  */\n      char buf[4096];\n\n      do\n        {\n          size_t count = (sizeof (buf) < offset ? sizeof (buf) : offset);\n          if (fread (buf, 1, count, fp) < count)\n            goto eof;\n          offset -= count;\n        }\n      while (offset > 0);\n\n      return 0;\n   }\n\n eof:\n  /* EOF, or error before or while reading.  */\n  if (ferror (fp))\n    return EOF;\n  else\n    /* Encountered EOF.  */\n    return 0;\n}",
    "comment": "The function efficiently skips a specified number of bytes in a FILE stream, handling buffered input and seeking on regular files when possible.",
    "prorec_sum": "Reads and discards a specified number of bytes from a FILE stream using buffered or unbuffered methods until the count is exhausted or an error occurs.",
    "filter_prorec_sum": "Reads and discards a specified number of bytes from a FILE stream, using buffered, unbuffered, or seek-based methods depending on stream state.",
    "prorec_aug_sum": "Skips a specified number of bytes in a FILE stream using buffered reading, direct seeking, or unbuffered reads depending on stream capabilities.",
    "filter_prorec_aug_sum": "Reads and discards a specified number of bytes from a file stream, using buffered reads, single-byte reads, or seeks depending on stream state.",
    "work_score": {
        "prorec": {
            "summary": "Reads and discards a specified number of bytes from a FILE stream using buffered or unbuffered methods until the count is exhausted or an error occurs.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary captures the core behavior of reading and discarding bytes from a FILE stream until the specified count is met or an error occurs, which aligns with the code's handling through buffered reads, unbuffered fallback, EOF, and error cases. However, it omits some specific semantics such as checking the seekability of the stream and using fseeko for regular files, but these omissions do not introduce inaccuracies. The majority of the single atomic claim is accurate.",
                "The summary accurately describes that the function reads and discards a number of bytes from a FILE stream until the count is exhausted or an error occurs, covering the core purpose. However, it omits important secondary details such as optimized skipping via buffered data without system calls, handling seekable vs non-seekable streams differently, use of fseeko for regular files, and EOF/error return value distinctions. These omissions reduce completeness in covering key behavior-critical semantics.",
                "The summary correctly captures the main purpose of the function\u2014discarding a specified number of bytes from a FILE stream\u2014and notes the termination conditions of exhausting the count or encountering an error. However, it omits significant details from the source code, such as the optimized skipping of buffered data without system calls and the fallback to seeking for regular files. These omissions reduce specificity and value, but there are no contradictory statements or severe inaccuracies. The output is primarily accurate but low in informational gain."
            ]
        },
        "filter_prorec": {
            "summary": "Reads and discards a specified number of bytes from a FILE stream, using buffered, unbuffered, or seek-based methods depending on stream state.",
            "score": [
                1.0,
                0.5,
                0.7
            ],
            "reason": [
                "The summary's main claim\u2014that the function reads and discards a specified number of bytes from a FILE stream using buffered, unbuffered, or seek-based methods depending on stream state\u2014is accurate and matches the source code's behavior. The code first skips buffered data, then seeks if possible, and otherwise reads/discards bytes, with handling for EOF and errors. There are no contradictory or irrelevant claims, and the statement captures the function's semantic behavior correctly.",
                "The summary correctly states the core behavior of discarding a specified number of bytes from a FILE stream and notes that different methods are used depending on stream state, which aligns with the function\u2019s main purpose. However, it lacks detail on specific mechanisms such as skipping buffered data without system calls, handling ungetc buffer, distinguishing between seekable and non-seekable streams, reading in fixed-size chunks, and EOF/error handling. These omissions mean secondary coverage is weak despite the core being addressed.",
                "The summary correctly identifies the core purpose of the function \u2014 discarding a specified number of bytes from a FILE stream \u2014 and mentions buffered, unbuffered, and seek-based methods, which align with the code\u2019s logic for handling ungetc/main buffer, fseek for regular files, and fread for non-seekable streams. The claim is accurate, concise, and targets the core domain action without introducing contradictions or irrelevant noise. However, it is somewhat generic and lacks mention of specific implementation details such as EOF/error handling, making the gain moderate rather than high."
            ]
        }
    }
}
{
    "source_code": "\nstatic Rconnection\nnewxzfile(const char *description, const char *mode, int type, int compress)\n{\n    Rconnection new;\n    new = (Rconnection) malloc(sizeof(struct Rconn));\n    if(!new) error(_(\"allocation of xzfile connection failed\"));\n    new->class = (char *) malloc(strlen(\"xzfile\") + 1);\n    if(!new->class) {\n\tfree(new);\n\terror(_(\"allocation of xzfile connection failed\"));\n\t/* for Solaris 12.5 */ new = NULL;\n    }\n    strcpy(new->class, \"xzfile\");\n    new->description = (char *) malloc(strlen(description) + 1);\n    if(!new->description) {\n\tfree(new->class); free(new);\n\terror(_(\"allocation of xzfile connection failed\"));\n\t/* for Solaris 12.5 */ new = NULL;\n    }\n    init_con(new, description, CE_NATIVE, mode);\n\n    new->canseek = FALSE;\n    new->open = &xzfile_open;\n    new->close = &xzfile_close;\n    new->vfprintf = &dummy_vfprintf;\n    new->fgetc_internal = &xzfile_fgetc_internal;\n    new->fgetc = &dummy_fgetc;\n    new->seek = &null_seek;\n    new->fflush = &null_fflush;\n    new->read = &xzfile_read;\n    new->write = &xzfile_write;\n    new->private = (void *) malloc(sizeof(struct xzfileconn));\n    memset(new->private, 0, sizeof(struct xzfileconn));\n    if(!new->private) {\n\tfree(new->description); free(new->class); free(new);\n\terror(_(\"allocation of xzfile connection failed\"));\n\t/* for Solaris 12.5 */ new = NULL;\n    }\n    ((Rxzfileconn) new->private)->type = type;\n    ((Rxzfileconn) new->private)->compress = compress;\n    return new;\n}",
    "comment": "Allocates and initializes a new xzfile connection, setting its properties and handling memory for class, description, and private data structures.",
    "prorec_sum": "Initializes and returns an xzfile connection object, allocating required buffers, setting handler function pointers, and storing provided parameters.",
    "filter_prorec_sum": "Initializes and returns an xzfile connection structure, allocating buffers and setting function pointers for I/O operations and configuration parameters.",
    "prorec_aug_sum": "Initializes and returns an xzfile connection structure, setting its handlers, storing parameters, and allocating buffers for subsequent compressed file operations.",
    "filter_prorec_aug_sum": "Creates and initializes an xzfile connection structure with associated callbacks, buffers, and parameters, reporting an error if memory allocation fails.",
    "work_score": {
        "prorec": {
            "summary": "Initializes and returns an xzfile connection object, allocating required buffers, setting handler function pointers, and storing provided parameters.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary accurately states that the function initializes and returns an xzfile connection object, allocates necessary buffers, sets handler function pointers, and stores provided parameters. Each of these claims aligns with the source code: the code allocates memory for the connection and its properties, assigns function pointers for operations, and stores the 'type' and 'compress' parameters. All extracted claims are correct and directly supported by the source.",
                "The summary correctly identifies the function's core purpose as initializing and returning an xzfile connection with allocated buffers, function pointers, and parameters, which matches the code's primary domain action. It covers the critical allocation steps and assignment of handlers, reflecting accurate key behaviors. However, it omits secondary details such as multiple error handling branches for failed allocations, specific values set (e.g., canseek = FALSE), initializing with init_con and CE_NATIVE, and zeroing out private data. These omissions mean secondary coverage is limited.",
                "The summary accurately describes the core purpose: creating and returning an xzfile connection with allocated buffers, assigned handler function pointers, and stored input parameters, matching the source code\u2019s behavior. There are no contradictory statements, and no noise, but the description is fairly generic and lacks specifics such as the exact fields initialized or the error handling logic. The gain is modest due to limited detail, though accuracy is high."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes and returns an xzfile connection structure, allocating buffers and setting function pointers for I/O operations and configuration parameters.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary accurately states that the function initializes and returns an xzfile connection, allocates memory buffers, and sets function pointers for various I/O operations while storing configuration parameters such as type and compression. These details match the source code\u2019s behavior, with no contradictory or irrelevant claims present.",
                "The summary accurately conveys the core purpose of creating and initializing an xzfile connection, including memory allocation, assignment of I/O function pointers, and configuration of parameters, which matches the source code\u2019s behavior. However, it omits important secondary details such as explicit error handling on allocation failures, the inability to seek, and initialization of internal structures to zero. The coverage of the core is strong but secondary semantics are only partially represented.",
                "The summary correctly captures the primary purpose of the function \u2014 creation and initialization of an xzfile connection \u2014 and notes allocation and assignment of I/O function pointers along with configuration parameters. These are accurate and align with the source code\u2019s semantics. While the description is fairly general and omits details such as specific error handling and all assigned functions, there are no incorrect or irrelevant claims, so noise is minimal and gain is moderate."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_multifit_linear_applyW(const gsl_matrix * X,\n                           const gsl_vector * w,\n                           const gsl_vector * y,\n                           gsl_matrix * WX,\n                           gsl_vector * Wy)\n{\n  const size_t n = X->size1;\n  const size_t p = X->size2;\n\n  if (n != y->size)\n    {\n      GSL_ERROR(\"y vector does not match X\", GSL_EBADLEN);\n    }\n  else if (w != NULL && n != w->size)\n    {\n      GSL_ERROR(\"weight vector does not match X\", GSL_EBADLEN);\n    }\n  else if (n != WX->size1 || p != WX->size2)\n    {\n      GSL_ERROR(\"WX matrix dimensions do not match X\", GSL_EBADLEN);\n    }\n  else if (n != Wy->size)\n    {\n      GSL_ERROR(\"Wy vector must be length n\", GSL_EBADLEN);\n    }\n  else\n    {\n      size_t i;\n\n      /* copy WX = X; Wy = y if distinct pointers */\n      if (WX != X)\n        gsl_matrix_memcpy(WX, X);\n      if (Wy != y)\n        gsl_vector_memcpy(Wy, y);\n\n      if (w != NULL)\n        {\n          /* construct WX = sqrt(W) X and Wy = sqrt(W) y */\n          for (i = 0; i < n; ++i)\n            {\n              double wi = gsl_vector_get(w, i);\n              double swi;\n              gsl_vector_view row = gsl_matrix_row(WX, i);\n              double *yi = gsl_vector_ptr(Wy, i);\n\n              if (wi < 0.0)\n                wi = 0.0;\n\n              swi = sqrt(wi);\n              gsl_vector_scale(&row.vector, swi);\n              *yi *= swi;\n            }\n        }\n\n      return GSL_SUCCESS;\n    }\n}",
    "comment": "Applies weighted transformations to input matrix X and vector y, storing results in WX and Wy, respectively, while handling potential dimension mismatches.",
    "prorec_sum": "Validates dimensional consistency of input matrices/vectors and applies weight scaling to X and y for weighted linear regression fitting.",
    "filter_prorec_sum": "Validates matching dimensions of input vectors/matrices, then copies and applies weight scaling to X and y data for weighted linear regression.",
    "prorec_aug_sum": "Validates vector and matrix dimensions, then copies and applies weights to regression data by scaling rows and corresponding vector elements.",
    "filter_prorec_aug_sum": "Validates dimensions of input matrices/vectors and applies square root weight scaling to rows and corresponding vector elements for weighted linear regression.",
    "work_score": {
        "prorec": {
            "summary": "Validates dimensional consistency of input matrices/vectors and applies weight scaling to X and y for weighted linear regression fitting.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary captures the main behavior of the function: checking dimension consistency of inputs and applying weight scaling to X and y, which aligns with the source code\u2019s validation checks and scaling logic for weighted linear regression. There are no incorrect or unrelated claims, and all atomic statements are accurate and relevant to the code behavior described.",
                "The summary correctly identifies the main purpose as validating input dimensions and applying weight scaling for weighted linear regression, which matches the core function behavior of checking matrix/vector sizes and constructing WX and Wy with sqrt of weights. However, it omits several secondary semantics present in the code, such as handling NULL weights, copying data when pointers differ, clamping negative weights to zero, and returning error codes for mismatches. These omissions reduce coverage of behavior-critical details beyond the core purpose.",
                "The summary accurately captures the main purpose of the function: it checks that matrix/vector dimensions match and applies weight scaling to X and y, which aligns with the code\u2019s behavior. The claim is both specific and fact-based (GOLD), addressing the primary purpose without introducing inaccuracies or noise. While concise, it covers core inputs, validation, and transformation, yielding high relevance and low noise."
            ]
        },
        "filter_prorec": {
            "summary": "Validates matching dimensions of input vectors/matrices, then copies and applies weight scaling to X and y data for weighted linear regression.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function validates dimensions of the input vectors and matrices, and applies weight scaling to X and y, which matches the source code. It omits certain specifics like handling NULL weights and copying only when pointers differ, but the core functional description is accurate. Overall, the majority of claims are factually correct and relevant to the code\u2019s domain semantics.",
                "The summary accurately describes the core operation\u2014checking dimension compatibility of inputs, copying data, and applying sqrt-based weight scaling to prepare X and y for weighted linear regression\u2014aligning with the function's primary purpose. It covers dimension validation and weight application but omits some secondary details such as handling of negative weights by setting them to zero, conditional copying when pointers differ, and specific error reporting behavior via GSL_ERROR codes.",
                "The summary contains two ACCURATE claims: it correctly notes that the function validates dimensions of input vectors/matrices, and that it copies and applies weight scaling to X and y. These align with the source code, which checks sizes, copies data if needed, and scales by sqrt of weights for weighted regression. The claims are specific to the core behavior and have minimal noise, with no inaccurate or contradictory statements. The gain is moderate since the description captures the primary purpose and key operations succinctly."
            ]
        }
    }
}
{
    "source_code": "\nstatic double InReal(R_inpstream_t stream)\n{\n    char word[128];\n    char buf[128];\n    double d;\n\n    switch (stream->type) {\n    case R_pstream_ascii_format:\n\tInWord(stream, word, sizeof(word));\n\tif(sscanf(word, \"%127s\", buf) != 1) error(_(\"read error\"));\n\tif (strcmp(buf, \"NA\") == 0)\n\t    return NA_REAL;\n\telse if (strcmp(buf, \"NaN\") == 0)\n\t    return R_NaN;\n\telse if (strcmp(buf, \"Inf\") == 0)\n\t    return R_PosInf;\n\telse if (strcmp(buf, \"-Inf\") == 0)\n\t    return R_NegInf;\n\telse\n\t    if(\n#ifdef Win32\n\t\ttrio_sscanf(buf, \"%lg\", &d)\n#else\n\t\tsscanf(buf, \"%lg\", &d)\n#endif\n\t\t!= 1) error(_(\"read error\"));\n\treturn d;\n    case R_pstream_binary_format:\n\tstream->InBytes(stream, &d, sizeof(double));\n\treturn d;\n    case R_pstream_xdr_format:\n\tstream->InBytes(stream, buf, R_XDR_DOUBLE_SIZE);\n\treturn R_XDRDecodeDouble(buf);\n    default:\n\treturn NA_REAL;\n    }\n}",
    "comment": "Reads a double value from a specified input stream format (ASCII, binary, or XDR) and handles special cases like NA, NaN, and infinity.",
    "prorec_sum": "Parses numeric or special string values from input, handles \u201cNA\u201d/\u201cNaN\u201d/\u201cInf\u201d cases, and raises an error if reading fails.",
    "filter_prorec_sum": "Parses numeric or special string values from input, handling \"NA\", \"NaN\", and infinities, and reports a read error on invalid data.",
    "prorec_aug_sum": "Parses numeric or special string values from input, handling NA/Inf cases, and invokes appropriate processing or error reporting based on a type code.",
    "filter_prorec_aug_sum": "Parses numeric or special string values from input, handles \u201cNA\u201d/\u201cNaN\u201d/\u201cInf\u201d cases, and reports a \u201cread error\u201d through R\u2019s error mechanism if invalid.",
    "work_score": {
        "prorec": {
            "summary": "Parses numeric or special string values from input, handles \u201cNA\u201d/\u201cNaN\u201d/\u201cInf\u201d cases, and raises an error if reading fails.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly captures the function\u2019s core behavior of parsing numeric or special string values from the input, identifying 'NA', 'NaN', and 'Inf', and raising an error if reading fails. It omits some specifics from the source code such as handling '-Inf', different stream types, and binary/XDR format parsing, but the claims it does make are accurate and grounded in the code. Overall, more than 80% of the claims are accurate despite the lack of detail.",
                "The summary correctly identifies that the function parses numeric or special values and explicitly mentions handling of 'NA', 'NaN', and 'Inf', as well as error raising on read failures. These are accurate claims reflecting parts of the code. However, it omits the core primary purpose detail that the parsing depends on the input stream format (ASCII, binary, XDR) and includes logic for each format, which is critical to the function\u2019s domain behavior. No mention is made of binary or XDR decoding or platform-specific parsing fallback, so coverage of secondary, behavior-critical semantics is weak despite the core idea of parsing being present.",
                "The summary accurately notes that the function parses numeric or special string values (NA, NaN, Inf) and raises an error on read failure. These are correct, domain-relevant claims matching the ASCII parsing branch of the source. However, it omits key behavior such as handling '-Inf', the separate binary and XDR format parsing logic, and the default case returning NA_REAL. There are no incorrect statements (no FATAL), but the coverage is partial and generic, limiting informational gain."
            ]
        },
        "filter_prorec": {
            "summary": "Parses numeric or special string values from input, handling \"NA\", \"NaN\", and infinities, and reports a read error on invalid data.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary accurately states that the function parses numeric and special string values such as \"NA\", \"NaN\", and infinities, and triggers a read error on invalid data, which is consistent with the ASCII case handling in the source code. However, it omits other format types supported by the function, such as binary and XDR formats, making it incomplete but largely correct for the aspects it covers.",
                "The summary accurately states the function parses numeric or special string values, handles \"NA\", \"NaN\", and infinities, and reports read errors on invalid input. This matches the core purpose of reading and interpreting data from the stream in ASCII format. However, it omits other key behaviors: handling multiple stream types (binary and XDR formats), returning NA_REAL for unknown formats, and using specific decoding methods for binary/XDR cases. Secondary coverage is weak, as broader domain semantics and format-specific processing are missing.",
                "The summary makes accurate claims about parsing numeric and special string values, handling 'NA', 'NaN', and infinities, and reporting an error on invalid data, all of which match the source code's ASCII case logic. However, it omits support for binary and XDR formats, meaning it incompletely conveys the domain semantics. There are no false or contradictory claims, but the gain is limited because the coverage is partial and mostly generic."
            ]
        }
    }
}
{
    "source_code": "dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,\n\t\t\t    unsigned long offset, size_t size,\n\t\t\t    enum dma_data_direction dir,\n\t\t\t    struct dma_attrs *attrs)\n{\n\tphys_addr_t map, phys = page_to_phys(page) + offset;\n\tdma_addr_t dev_addr = phys_to_dma(dev, phys);\n\n\tBUG_ON(dir == DMA_NONE);\n\t/*\n\t * If the address happens to be in the device's DMA window,\n\t * we can safely return the device addr and not worry about bounce\n\t * buffering it.\n\t */\n\tif (dma_capable(dev, dev_addr, size) && !swiotlb_force)\n\t\treturn dev_addr;\n\n\t/* Oh well, have to allocate and map a bounce buffer. */\n\tmap = map_single(dev, phys, size, dir);\n\tif (map == SWIOTLB_MAP_ERROR) {\n\t\tswiotlb_full(dev, size, dir, 1);\n\t\treturn phys_to_dma(dev, io_tlb_overflow_buffer);\n\t}\n\n\tdev_addr = phys_to_dma(dev, map);\n\n\t/* Ensure that the address returned is DMA'ble */\n\tif (!dma_capable(dev, dev_addr, size)) {\n\t\tswiotlb_tbl_unmap_single(dev, map, size, dir);\n\t\treturn phys_to_dma(dev, io_tlb_overflow_buffer);\n\t}\n\n\treturn dev_addr;\n}",
    "comment": "Maps a page of memory for DMA access, handling bounce buffers if the device cannot directly access the address.",
    "prorec_sum": "Maps a physical address range for DMA access, validates boundaries, and logs warnings if mapping fails or exceeds allowed memory limits.",
    "filter_prorec_sum": "Allocates or validates a DMA-accessible memory range, logging warnings for oversized regions and handling read, write, or random access types.",
    "prorec_aug_sum": "Validates and maps a given memory range for DMA access, logging warnings for unsafe read, write, or general access conditions.",
    "filter_prorec_aug_sum": "Validates and maps a DMA memory range, logging warnings for large random access patterns and handling errors or out-of-bounds conditions.",
    "work_score": {
        "prorec": {
            "summary": "Maps a physical address range for DMA access, validates boundaries, and logs warnings if mapping fails or exceeds allowed memory limits.",
            "score": [
                0.3,
                0.3,
                0.2
            ],
            "reason": [
                "The summary mentions mapping a physical address range for DMA access, which matches the core function behavior and is accurate. However, it incorrectly states that the function validates boundaries and logs warnings\u2014there is no logging in the code, and validation is performed via capability checks, not explicit boundary validation per se. Additionally, the description of exceeding allowed memory limits is not reflected in the code. These inaccuracies mean fewer than half the claims match the source code semantics.",
                "The summary's main claim about mapping a physical address range for DMA access is generally accurate, as the function converts a physical address to a DMA address and handles edge cases. However, it inaccurately describes behavior by stating 'validates boundaries' and 'logs warnings if mapping fails or exceeds allowed memory limits,' which do not match the source; the code checks DMA capability, handles bounce buffers, and returns fallback addresses without logging warnings. The core purpose of mapping pages for DMA with bounce buffering support is only partially captured and lacks mention of critical behaviors like bounce buffer allocation, error handling via swiotlb_full, and device capability checks.",
                "The summary inaccurately states that the function logs warnings if mapping fails or exceeds allowed memory limits, which does not occur in the source code. Mapping failure results in using an overflow buffer without logging. The claim about validating boundaries is generic and loosely matches the `dma_capable` checks but lacks specificity. The primary purpose of mapping a physical address range for DMA is correctly captured, but the inclusion of the incorrect logging detail is a FATAL error affecting key side effect understanding."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates or validates a DMA-accessible memory range, logging warnings for oversized regions and handling read, write, or random access types.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains several inaccuracies: it claims logging of warnings for oversized regions, which is not present in the code, and references handling of read, write, or random access types, whereas the function only checks for a valid DMA direction and bounce buffering. While it loosely mentions allocating or validating a DMA-accessible range, the majority of the statements either contradict or fail to target the actual code semantics, resulting in low alignment.",
                "The summary fails to capture the core purpose of the function, which is to map a given page for DMA using swiotlb, returning a device-accessible address or fallback buffers depending on capability checks and error handling. It inaccurately mentions logging warnings for oversized regions, which is not present, and omits the bounce buffer allocation, capability checks, and fallback behavior. The claim about handling read, write, or random access types is too vague and not aligned with the specific DMA direction handling in the code.",
                "The summary inaccurately claims that the function logs warnings for oversized regions and handles read, write, or random access types, which are not present in the source code. The core purpose\u2014mapping a page for DMA and handling bounce buffers\u2014is misrepresented, making these errors FATAL with respect to the primary purpose. There are no accurate, specific details about the actual mapping or device capability checks, and noise dominates due to false behavioral descriptions."
            ]
        }
    }
}
{
    "source_code": "\nasmlinkage int sys_modify_ldt(int func, void __user *ptr,\n\t\t\t      unsigned long bytecount)\n{\n\tint ret = -ENOSYS;\n\n\tswitch (func) {\n\tcase 0:\n\t\tret = read_ldt(ptr, bytecount);\n\t\tbreak;\n\tcase 1:\n\t\tret = write_ldt(ptr, bytecount, 1);\n\t\tbreak;\n\tcase 2:\n\t\tret = read_default_ldt(ptr, bytecount);\n\t\tbreak;\n\tcase 0x11:\n\t\tret = write_ldt(ptr, bytecount, 0);\n\t\tbreak;\n\t}\n\treturn ret;\n}",
    "comment": "The function modifies the local descriptor table (LDT) by reading or writing its entries based on the specified operation code.",
    "prorec_sum": "Handles different command types to transfer data from an internal buffer or directly to a target address, returning appropriate status or error codes.",
    "filter_prorec_sum": "Handles various command types to transfer or validate data buffers, including special cases for specific command IDs and staged memory copy operations.",
    "prorec_aug_sum": "Handles different command codes to transfer data between a buffer and a target address, returning success lengths or specific error codes.",
    "filter_prorec_aug_sum": "Handles different command codes to transfer data between a kernel buffer and a user address, enforcing size limits and returning status codes.",
    "work_score": {
        "prorec": {
            "summary": "Handles different command types to transfer data from an internal buffer or directly to a target address, returning appropriate status or error codes.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary makes generic claims about handling command types, transferring data, and returning status/error codes, but these do not align closely with the actual source code behavior. The code operates on LDT read/write functions for specific func values, not generic internal buffer transfers to target addresses. Only the mention of handling commands and returning codes is loosely accurate, so the majority of claims are imprecise or misleading relative to the code.",
                "The summary omits the core purpose of the function, which is to modify or read entries in the Local Descriptor Table (LDT) based on the `func` value. While it vaguely mentions handling different command types and transferring data, this is too generic and does not reflect the specific domain semantics or the distinct read/write operations defined in the source code. No accurate claim aligns with the primary LDT-related behavior, and secondary details such as specific function codes, branching, and error handling are missing.",
                "The claim that the function handles different command types is generally accurate, as the code switches on 'func' to perform various read or write LDT operations. However, the summary inaccurately states data is transferred from an internal buffer or directly to a target address, which contradicts the actual source code semantics\u2014these operations interact with the LDT rather than generic buffers or target addresses. This is a FATAL error regarding the primary purpose, making the description misleading about the core domain action. The remaining accurate part is generic and low in informational value."
            ]
        },
        "filter_prorec": {
            "summary": "Handles various command types to transfer or validate data buffers, including special cases for specific command IDs and staged memory copy operations.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains vague descriptions such as transferring or validating data buffers and staged memory copy operations that are not clearly reflected in the source code, which actually deals with reading and writing the LDT based on specific function codes. While it mentions handling various command types and special command IDs\u2014loosely aligning with the switch cases\u2014most claims are generic or inaccurate with respect to the actual system call semantics, resulting in less than half being accurate.",
                "The summary does not accurately reflect the core purpose of the function, which is to handle specific sys_modify_ldt cases by reading or writing LDT structures based on the func parameter. Phrases like 'transfer or validate data buffers' and 'staged memory copy operations' are vague and not aligned with the actual domain semantics of modifying or reading the local descriptor table. No accurate claim covers the core primary purpose, and secondary behaviors such as distinct case IDs for read/write default LDT are omitted or misrepresented.",
                "The summary contains mostly inaccurate claims regarding the function\u2019s core purpose. The code is a syscall handler that reads or writes LDT entries based on specific func values, not generic data buffer transfers, validation, or staged memory copy operations. These misrepresentations target the primary domain action and semantics, constituting FATAL errors on the core purpose. Accurate information is minimal, so overall benefit is negative."
            ]
        }
    }
}
{
    "source_code": "\nstatic int usb_set_lpm_timeout(struct usb_device *udev,\n\t\tenum usb3_link_state state, int timeout)\n{\n\tint ret;\n\tint feature;\n\n\tswitch (state) {\n\tcase USB3_LPM_U1:\n\t\tfeature = USB_PORT_FEAT_U1_TIMEOUT;\n\t\tbreak;\n\tcase USB3_LPM_U2:\n\t\tfeature = USB_PORT_FEAT_U2_TIMEOUT;\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(&udev->dev, \"%s: Can't set timeout for non-U1 or U2 state.\\n\",\n\t\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (state == USB3_LPM_U1 && timeout > USB3_LPM_U1_MAX_TIMEOUT &&\n\t\t\ttimeout != USB3_LPM_DEVICE_INITIATED) {\n\t\tdev_warn(&udev->dev, \"Failed to set %s timeout to 0x%x, \"\n\t\t\t\t\"which is a reserved value.\\n\",\n\t\t\t\tusb3_lpm_names[state], timeout);\n\t\treturn -EINVAL;\n\t}\n\n\tret = set_port_feature(udev->parent,\n\t\t\tUSB_PORT_LPM_TIMEOUT(timeout) | udev->portnum,\n\t\t\tfeature);\n\tif (ret < 0) {\n\t\tdev_warn(&udev->dev, \"Failed to set %s timeout to 0x%x,\"\n\t\t\t\t\"error code %i\\n\", usb3_lpm_names[state],\n\t\t\t\ttimeout, ret);\n\t\treturn -EBUSY;\n\t}\n\tif (state == USB3_LPM_U1)\n\t\tudev->u1_params.timeout = timeout;\n\telse\n\t\tudev->u2_params.timeout = timeout;\n\treturn 0;\n}",
    "comment": "Sets the low power mode timeout for a USB device based on the specified USB 3.0 link state, validating the timeout value before applying it.",
    "prorec_sum": "Sets USB link power management timeout for U1 or U2 states, validating values and reporting errors when applying them to the device.",
    "filter_prorec_sum": "Sets USB port U1 or U2 low-power timeout values via control transfer, rejecting invalid states and reserved timing values with error logging.",
    "prorec_aug_sum": "Sets the USB device\u2019s U1 or U2 link power management timeout, validating values and reporting errors for unsupported states or reserved timings.",
    "filter_prorec_aug_sum": "Sets USB U1 or U2 power state timeout values and logs errors when given invalid or unsupported states or reserved timeout values.",
    "work_score": {
        "prorec": {
            "summary": "Sets USB link power management timeout for U1 or U2 states, validating values and reporting errors when applying them to the device.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function sets USB link power management timeout for U1 or U2 states, matches the code\u2019s state handling, and mentions validation and error reporting, both of which are present. It omits specifics such as rejecting non-U1/U2 states, reserved value checks for U1, and updating device parameters, but contains no inaccurate claims, making its accuracy high despite being somewhat generic.",
                "The summary correctly captures the core purpose of setting the USB link power management timeout for U1 or U2 states and mentions validation and error reporting, which match the code's branching for state checking, timeout limits, and warnings. However, it omits secondary key details such as specific handling of reserved timeout values for U1, use of set_port_feature to apply settings, return codes (-EINVAL, -EBUSY), and updating udev's internal timeout parameters. Coverage of secondary behavior is moderate but not comprehensive.",
                "The summary correctly states that the function sets USB link power management timeout for U1 or U2 states, performs value validation, and reports errors when applying them, which matches the source code\u2019s switch on state, range check for U1 timeout, and warning/error returns. There are no inaccurate claims, and noise is minimal. However, the details are generic and omit specifics like reserved value checks, distinction between validation for U1 vs U2, and updating device parameters, resulting in low informative gain despite correctness."
            ]
        },
        "filter_prorec": {
            "summary": "Sets USB port U1 or U2 low-power timeout values via control transfer, rejecting invalid states and reserved timing values with error logging.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function sets USB port U1 or U2 low-power timeout values and that it rejects invalid states (non-U1/U2) and reserved timing values with error logging, aligning well with the code\u2019s logic. The mention of 'via control transfer' is not explicitly supported by the source code and could be considered speculative. Apart from that, the claims are accurate and specific to the function\u2019s behavior, making the majority of claims ACCURATE.",
                "The summary correctly identifies the core purpose as setting low-power timeout values for U1 or U2 states and notes rejection of invalid states and reserved timing values with error logging, aligning with the source code's main flow. However, it inaccurately adds 'via control transfer', which is not evident from the source, and omits secondary details like specific error codes (-EINVAL, -EBUSY), handling of maximum timeout conditions, and assignment to state-specific parameters. Overall, it captures the core but misses several key secondary behaviors and includes a small inaccurate element.",
                "The summary correctly states that the function sets U1 or U2 low-power timeout values and rejects invalid states and reserved values, with logging, which matches the code\u2019s switch statement, timeout validation, and dev_warn usage. However, the mention of doing this 'via control transfer' is inaccurate, as the source code uses set_port_feature rather than any explicit USB control transfer mechanism. This is a minor semantic error (NOISE) and does not misrepresent the core purpose, so noise level is low and primary claims are specific and accurate."
            ]
        }
    }
}
{
    "source_code": "\nstatic struct rpc_cred *\nunx_create_cred(struct rpc_auth *auth, struct auth_cred *acred, int flags)\n{\n\tstruct unx_cred\t*cred;\n\tunsigned int groups = 0;\n\tunsigned int i;\n\n\tdprintk(\"RPC:       allocating UNIX cred for uid %d gid %d\\n\",\n\t\t\tfrom_kuid(&init_user_ns, acred->uid),\n\t\t\tfrom_kgid(&init_user_ns, acred->gid));\n\n\tif (!(cred = kmalloc(sizeof(*cred), GFP_NOFS)))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\trpcauth_init_cred(&cred->uc_base, acred, auth, &unix_credops);\n\tcred->uc_base.cr_flags = 1UL << RPCAUTH_CRED_UPTODATE;\n\n\tif (acred->group_info != NULL)\n\t\tgroups = acred->group_info->ngroups;\n\tif (groups > NFS_NGROUPS)\n\t\tgroups = NFS_NGROUPS;\n\n\tcred->uc_gid = acred->gid;\n\tfor (i = 0; i < groups; i++)\n\t\tcred->uc_gids[i] = GROUP_AT(acred->group_info, i);\n\tif (i < NFS_NGROUPS)\n\t\tcred->uc_gids[i] = INVALID_GID;\n\n\treturn &cred->uc_base;\n}",
    "comment": "Allocates and initializes a UNIX credential structure with user and group identifiers based on provided authentication credentials.",
    "prorec_sum": "Allocates and initializes a socket-like structure with request data, setting fixed fields and copying up to sixteen configuration integers from linked input structures.",
    "filter_prorec_sum": "Allocates and initializes a network socket structure, copying configuration data from the provided parameters with bounded array handling.",
    "prorec_aug_sum": "Allocates and initializes a structured object from input parameters, copies up to sixteen integer entries from a secondary structure, and sets default values when absent.",
    "filter_prorec_aug_sum": "Allocates and initializes a fixed-size structure, copies group-related integers from input data, and fills remaining entries with -1 when fewer than sixteen are provided.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a socket-like structure with request data, setting fixed fields and copying up to sixteen configuration integers from linked input structures.",
            "score": [
                0.1,
                0.1,
                0.1
            ],
            "reason": [
                "The summary contains multiple inaccuracies. It describes the function as working with a 'socket-like structure' and 'request data', which do not match the source code semantics; the function actually allocates and initializes a UNIX RPC credential structure with UID, GID, and group IDs. The claim about copying 'up to sixteen configuration integers' is misleading, as the code copies group IDs up to NFS_NGROUPS, which is unrelated to configuration integers. None of the claims accurately reflect the domain-specific behavior, resulting in a very low proportion of accurate claims.",
                "The summary misidentifies the structure as socket-like with request data, which contradicts the source code's clear purpose of creating and initializing a UNIX RPC credential from provided authentication data. It omits the core operation of setting user/group IDs and limiting copied groups based on NFS_NGROUPS, and instead introduces inaccurate claims unrelated to the code. No accurate coverage of the core function is present.",
                "The summary contains a FATAL error about the primary purpose: it misidentifies the function as allocating a socket-like structure with request data, whereas the source code clearly allocates and initializes an RPC UNIX credential structure. It also incorrectly states copying up to sixteen configuration integers instead of group IDs, and introduces unrelated terminology. These inaccuracies target the core semantics, making the description misleading and unusable. No accurate claims are present to offset the error."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a network socket structure, copying configuration data from the provided parameters with bounded array handling.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as allocating and initializing a network socket structure, whereas the source code allocates and initializes a UNIX RPC credential structure. The claim about copying configuration data is vague and misaligned with the actual copying of group IDs from the provided credentials. There is also no mention of network sockets in the source, making the only claims present factually inaccurate relative to the code.",
                "The summary incorrectly describes the function as dealing with a network socket structure, while the source code actually allocates and initializes a UNIX RPC credential structure, populating user and group IDs with bounds checking. This is a direct semantic mismatch for the core purpose, so the core is not covered. No accurate claims about the actual domain behavior or secondary details from the code are present.",
                "The summary's core claim that the function allocates and initializes a network socket structure is a severe factual error, as the source code clearly allocates and initializes a UNIX RPC credential structure instead. The description of copying configuration data is misleading since the code copies UID, GID, and group IDs, not network socket configuration. Array bounds handling is correctly mentioned but wrapped in an incorrect context. This constitutes a FATAL error on the primary purpose, making the summary untrustworthy."
            ]
        }
    }
}
{
    "source_code": "\nvoid\nstatcmd (void)\n{\n  struct sockaddr_storage *sin;\n  unsigned char *a, *p;\n\n  lreply (211, \"%s FTP server status:\", hostname);\n  if (!no_version)\n    printf (\"     ftpd (%s) %s\\r\\n\", PACKAGE_NAME, PACKAGE_VERSION);\n  printf (\"     Connected to %s\", cred.remotehost);\n  (void) getnameinfo ((struct sockaddr *) &his_addr, his_addrlen,\n\t\t      addrstr, sizeof (addrstr), NULL, 0, NI_NUMERICHOST);\n  if (!isdigit (cred.remotehost[0]))\n    printf (\" (%s)\", addrstr);\n  printf (\"\\r\\n\");\n  printf (\"     Session timeout is %d seconds\\r\\n\", timeout);\n  if (cred.logged_in)\n    {\n      if (cred.guest)\n\tprintf (\"     Logged in anonymously\\r\\n\");\n      else\n\tprintf (\"     Logged in as %s\\r\\n\", cred.name);\n    }\n  else if (askpasswd)\n    printf (\"     Waiting for password\\r\\n\");\n  else\n    printf (\"     Waiting for user name\\r\\n\");\n  printf (\"     TYPE: %s\", typenames[type]);\n  if (type == TYPE_A || type == TYPE_E)\n    printf (\", FORM: %s\", formnames[form]);\n  if (type == TYPE_L)\n#ifdef CHAR_BIT\n    printf (\" %d\", CHAR_BIT);\n#else\n# if NBBY == 8\n    printf (\" %d\", NBBY);\n# else\n    printf (\" %d\", bytesize);\t/* need definition! */\n# endif\n#endif\n  printf (\"; STRUcture: %s; transfer MODE: %s\\r\\n\",\n\t  strunames[stru], modenames[stru_mode]);\n  if (data != -1)\n    printf (\"     Data connection open\\r\\n\");\n  else if (pdata != -1)\n    {\n      printf (\"     in Passive mode\");\n      sin = &pasv_addr;\n      goto printaddr;\n    }\n  else if (usedefault == 0)\n    {\n      printf (\"     PORT\");\n      sin = &data_dest;\n    printaddr:\n      a = (unsigned char *) & ((struct sockaddr_in *) sin)->sin_addr;\n      p = (unsigned char *) & ((struct sockaddr_in *) sin)->sin_port;\n#define UC(b) (((int) b) & 0xff)\n      printf (\" (%d,%d,%d,%d,%d,%d)\\r\\n\", UC (a[0]),\n\t      UC (a[1]), UC (a[2]), UC (a[3]), UC (p[0]), UC (p[1]));\n#undef UC\n    }\n  else\n    printf (\"     No data connection\\r\\n\");\n  reply (211, \"End of status\");\n}",
    "comment": "Displays the current status of the FTP server, including connection details, session timeout, user login status, data connection status, and transfer settings.",
    "prorec_sum": "Displays comprehensive FTP server status including connection info, session settings, login state, transfer parameters, and data connection details.",
    "filter_prorec_sum": "Outputs current FTP server and session status details, including connection info, login state, transfer settings, and data connection mode.",
    "prorec_aug_sum": "Displays the current FTP session status, including server info, login state, transfer settings, and data connection details, then ends with a status footer.",
    "filter_prorec_aug_sum": "Outputs a detailed FTP server status report including connection info, session parameters, login state, transfer settings, and data connection mode.",
    "work_score": {
        "prorec": {
            "summary": "Displays comprehensive FTP server status including connection info, session settings, login state, transfer parameters, and data connection details.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly captures the purpose of the function: it outputs a detailed FTP server status including connection info, session timeout, login state, transfer type and structure, and data connection state. All these aspects are present in the code and described accurately. The summary is slightly generic but aligns well with the actual domain semantics without introducing incorrect or irrelevant claims, yielding a very high proportion of accurate statements.",
                "The summary accurately describes the function\u2019s purpose of displaying detailed FTP server status, covering connection info, session settings, login state, transfer parameters, and data connection details, which aligns with the core operation seen in the code. However, it omits specifics on conditional branches such as passive mode address printing, waiting states (for username/password), and precise type/form/structure/mode outputs, limiting coverage of secondary behavior-critical details.",
                "The summary accurately captures the core purpose and behavior of the function, noting its display of FTP server status with details on connection info, session settings, login state, transfer parameters, and data connection details. These points align with the source code, which prints all these aspects in its output. The information is correct but somewhat generic, lacking deeper specifics such as exact conditional branches or formats, yet there is minimal noise and no contradictory claims."
            ]
        },
        "filter_prorec": {
            "summary": "Outputs current FTP server and session status details, including connection info, login state, transfer settings, and data connection mode.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary accurately describes the function's behavior: it outputs FTP server status including connection information, login state, transfer settings, and data connection mode, all of which are explicitly implemented in the code. No contradictory or irrelevant claims are present, and all points target actual code semantics.",
                "The summary correctly describes the core purpose of the function as outputting FTP server and session status details. It includes accurate coverage of the main action and mentions secondary aspects such as connection info, login state, transfer settings, and data connection mode, all of which match behavior in the source code. However, it lacks more granular details like specific output formatting, edge cases for login prompts, precise TYPE/FORM/STRUCTURE/MODE handling, and passive mode/PORT address output, so coverage of secondary behaviors is incomplete.",
                "The summary accurately captures the core behavior of the function by stating it outputs FTP server status, connection info, login state, transfer settings, and data connection mode. These claims match the source code's detailed printing of hostname, version, remote host, timeout, login status, transfer type/structure/mode, and data connection information. There are no inaccurate or noisy claims, but the description is high-level and lacks the specific details (e.g., exact formatting or conditions) that would make it highly informative, resulting in modest gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic ssize_t snd_pcm_oss_write2(struct snd_pcm_substream *substream, const char *buf, size_t bytes, int in_kernel)\n{\n\tstruct snd_pcm_runtime *runtime = substream->runtime;\n\tsnd_pcm_sframes_t frames, frames1;\n#ifdef CONFIG_SND_PCM_OSS_PLUGINS\n\tif (runtime->oss.plugin_first) {\n\t\tstruct snd_pcm_plugin_channel *channels;\n\t\tsize_t oss_frame_bytes = (runtime->oss.plugin_first->src_width * runtime->oss.plugin_first->src_format.channels) / 8;\n\t\tif (!in_kernel) {\n\t\t\tif (copy_from_user(runtime->oss.buffer, (const char __force __user *)buf, bytes))\n\t\t\t\treturn -EFAULT;\n\t\t\tbuf = runtime->oss.buffer;\n\t\t}\n\t\tframes = bytes / oss_frame_bytes;\n\t\tframes1 = snd_pcm_plug_client_channels_buf(substream, (char *)buf, frames, &channels);\n\t\tif (frames1 < 0)\n\t\t\treturn frames1;\n\t\tframes1 = snd_pcm_plug_write_transfer(substream, channels, frames1);\n\t\tif (frames1 <= 0)\n\t\t\treturn frames1;\n\t\tbytes = frames1 * oss_frame_bytes;\n\t} else\n#endif\n\t{\n\t\tframes = bytes_to_frames(runtime, bytes);\n\t\tframes1 = snd_pcm_oss_write3(substream, buf, frames, in_kernel);\n\t\tif (frames1 <= 0)\n\t\t\treturn frames1;\n\t\tbytes = frames_to_bytes(runtime, frames1);\n\t}\n\treturn bytes;\n}",
    "comment": "Writes audio data from a buffer to a PCM substream, handling potential OSS plugin processing and user-kernel memory copying.",
    "prorec_sum": "Processes audio PCM substream write operations, handling buffer preparation, data copying, and frame size conversions depending on hardware configuration.",
    "filter_prorec_sum": "Processes and writes PCM audio data from a substream, handling both mmap-enabled and standard buffer copy modes with frame size adjustments.",
    "prorec_aug_sum": "Processes PCM substream data transfer, adjusting for hardware buffer size and invoking appropriate routines based on hardware state and provided parameters.",
    "filter_prorec_aug_sum": "Processes PCM substream data, adjusting frames based on hardware parameters, and delegates handling to appropriate routines depending on hardware configuration presence.",
    "work_score": {
        "prorec": {
            "summary": "Processes audio PCM substream write operations, handling buffer preparation, data copying, and frame size conversions depending on hardware configuration.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function processes PCM substream write operations with buffer preparation, data copying from user space when required, and frame size conversions. These claims match the source code\u2019s behavior of handling OSS plugin or non-plugin paths, calculating frame sizes, and copying data. All elements are accurate but somewhat generic, with no contradictions or extraneous noise, resulting in a high proportion of accurate claims.",
                "The summary correctly identifies that the function handles PCM substream write operations and involves data copying and frame size conversions, which matches the source code\u2019s logic for both plugin and non-plugin paths. However, it does not explicitly cover the core purpose of writing audio data with plugin processing or direct write via snd_pcm_oss_write3, nor does it mention branches for plugin versus non-plugin, the copy_from_user call for user-space buffers, or detailed error-handling returns. The coverage is accurate but lacks specificity and key secondary points like conditional handling and external interactions.",
                "The summary correctly identifies that the function processes audio PCM substream write operations and includes buffer preparation, data copying, and frame size conversions, which align with the code\u2019s handling of plugin-based channels, user buffer copying, and byte/frame conversions. However, it omits specific conditional branches and distinguishes between plugin and non-plugin cases only generally, offering low-detail SAFE claims. There are no inaccurate or contradictory statements, and noise is minimal, but the gain is limited due to lack of specific GOLD-level details."
            ]
        },
        "filter_prorec": {
            "summary": "Processes and writes PCM audio data from a substream, handling both mmap-enabled and standard buffer copy modes with frame size adjustments.",
            "score": [
                0.3,
                0.4,
                0.2
            ],
            "reason": [
                "The summary claims handling of both mmap-enabled and standard buffer copy modes, but the source code only distinguishes between scenarios using OSS plugins and non-plugin paths, with optional user-space copying via copy_from_user when not in kernel. There is no explicit mmap-enabled mode mentioned. While 'processes and writes PCM audio data from a substream' is broadly accurate, the specific mmap-related detail is inaccurate, making less than half of the claims correct.",
                "The summary correctly states that PCM audio data from a substream is processed and written, and mentions different buffer handling modes, which loosely aligns with the plugin vs non-plugin branches in the code. However, it inaccurately describes them as mmap-enabled and standard copy modes, which are not explicitly shown; the code differentiates plugin-based and direct write methods, with an optional copy-from-user step if not in kernel. The core purpose of writing PCM data with conditional plugin processing is partially covered but with vague and somewhat incorrect terminology, and important details like error handling branches, frame calculations, and conversion between bytes and frames are omitted.",
                "The summary correctly identifies that the function processes and writes PCM audio data from a substream and handles buffer copying with frame size adjustments, which matches the source code. However, it inaccurately introduces 'mmap-enabled' mode, which is not present in the implementation. This is a FATAL error on a primary purpose detail since the actual modes handled involve optional plugin-based user buffer copying, not mmap. The gain from accurate claims is low due to their generic nature, and the incorrect mode undermines trust in the core behavioral description."
            ]
        }
    }
}
{
    "source_code": "static int\nbackward_move_node_structure (WINDOW *window, int behaviour)\n{\n  if (window->node->flags & (N_IsInternal | N_IsManPage))\n    return 1;\n\n  switch (behaviour)\n    {\n    case IS_PageOnly:\n      info_error (\"%s\", msg_at_node_top);\n      return 1;\n\n    case IS_NextOnly:\n      return !info_handle_pointer (\"Prev\", window);\n      break;\n\n    case IS_Continuous:\n      if (window->node->up)\n        {\n          /* If up is the dir node, we are at the top node.\n             Don't do anything. */\n          if (!strncasecmp (window->node->up, \"(dir)\", strlen (\"(dir)\")))\n            {\n              info_error (\"%s\", _(\"No 'Prev' or 'Up' for this node within this document\"));\n              return 1;\n            }\n          /* If 'Prev' and 'Up' are the same, we are at the first node\n             of the 'Up' node's menu. Go to up node. */\n          else if (window->node->prev\n              && !strcmp(window->node->prev, window->node->up))\n            {\n              if (!info_handle_pointer (\"Up\", window))\n                return 1;\n            }\n          /* Otherwise, go to 'Prev' node and go down the last entry\n             in the menus as far as possible. */\n          else if (window->node->prev)\n            {\n              int starting_hist_index = window->hist_index;\n              if (!info_handle_pointer (\"Prev\", window))\n                return 1;\n              if (!(window->node->flags & N_IsIndex))\n                {\n                  while (1)\n                    {\n                      REFERENCE *entry = select_menu_digit (window, '0');\n                      if (!entry)\n                        break;\n                      if (!info_select_reference (window, entry))\n                        break;\n                    }\n                  /* Don't include intermediate nodes in the window's\n                     history.  */\n                  cleanup_history (window, starting_hist_index,\n                                   window->hist_index - 1);\n                }\n            }\n          else /* 'Up' but no 'Prev' */\n            {\n              if (!info_handle_pointer (\"Up\", window))\n                return 1;\n            }\n        }\n      else if (window->node->prev) /* 'Prev' but no 'Up' */\n        {\n          if (!info_handle_pointer (\"Prev\", window))\n            return 1;\n        }\n      else\n        {\n          info_error (\"%s\", _(\"No 'Prev' or 'Up' for this node within this document\"));\n          return 1;\n        }\n\n      break; /* case IS_Continuous: */\n    }\n  return 0;\n}",
    "comment": "Handles backward navigation in a document's node structure based on specified behavior, managing transitions to previous or upward nodes as necessary.",
    "prorec_sum": "Determines and executes navigation to \u201cPrev\u201d or \u201cUp\u201d nodes, handling directory markers and displaying an error if such navigation is unavailable.",
    "filter_prorec_sum": "Determines navigation availability and performs actions for \u201cPrev\u201d or \u201cUp\u201d document nodes, displaying an error message when neither is accessible.",
    "prorec_aug_sum": "Determines navigation availability for \u201cPrev\u201d or \u201cUp\u201d within a document, performing related actions or showing an error message when these links are absent.",
    "filter_prorec_aug_sum": "Determines navigation actions within a document, executing \u201cPrev\u201d or \u201cUp\u201d commands or showing an error when those links are unavailable.",
    "work_score": {
        "prorec": {
            "summary": "Determines and executes navigation to \u201cPrev\u201d or \u201cUp\u201d nodes, handling directory markers and displaying an error if such navigation is unavailable.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary contains a single atomic claim about navigating to 'Prev' or 'Up' nodes, handling directory markers, and displaying an error when navigation is unavailable. This aligns well with the source code, which implements logic for these cases, including checks for '(dir)' and error messages when both 'Prev' and 'Up' are missing. Although the summary omits details about different behaviour modes and complex branching, its core claim is accurate and relevant to the function's semantics.",
                "The summary correctly conveys the core purpose of navigating to 'Prev' or 'Up' nodes and mentions error handling when navigation is unavailable, aligning with the main branching logic in the code. However, it omits important secondary details such as handling different behaviour modes (IS_PageOnly, IS_NextOnly, IS_Continuous), the special handling for directory markers '(dir)', history cleanup, and traversal through menu entries, which makes the coverage of key behaviours incomplete.",
                "The summary correctly captures the core behavior of the function by describing navigation to 'Prev' or 'Up' nodes, handling directory markers, and showing an error message when navigation is unavailable. This aligns with the source code logic for different behaviours without introducing inaccuracies, and while it is accurate, the description is generic and omits specific branching details such as handling 'IS_PageOnly' or continuous navigation down menu entries. The gain is low because the information is broad and lacks deeper specifics, but there is no noise or fatal error."
            ]
        },
        "filter_prorec": {
            "summary": "Determines navigation availability and performs actions for \u201cPrev\u201d or \u201cUp\u201d document nodes, displaying an error message when neither is accessible.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary accurately captures the general purpose of the function\u2014checking for availability of 'Prev' or 'Up' nodes and displaying an error if neither exists\u2014without introducing incorrect details. While it omits more specific behavior such as handling special node flags, different behaviour cases, and menu traversal when moving to 'Prev', the claims made are correct and broadly reflect the source code's navigation logic. Given the summary is generic but accurate, the proportion of accurate claims is high.",
                "The summary correctly states that the function deals with navigation to 'Prev' or 'Up' nodes and shows an error when neither is accessible, which reflects the core purpose. However, it omits significant secondary details present in the code, such as handling different behaviours (IS_PageOnly, IS_NextOnly, IS_Continuous), special cases like '(dir)' top node and 'Prev' equal to 'Up', iterative menu traversal, and history cleanup. These omissions limit completeness beyond the core description.",
                "The summary correctly captures the core purpose of the function \u2014 deciding navigation availability and taking action for 'Prev' or 'Up' nodes, and showing an error when neither is available. This aligns with the source code's logic across different behaviours, especially 'IS_Continuous'. However, it omits detail about the behaviour parameter cases (IS_PageOnly, IS_NextOnly, IS_Continuous) and the specific conditions under which navigation is blocked or menu traversal occurs. There is no inaccurate claim or unrelated noise, but the gain is modest because the description is high-level and lacks these specifics."
            ]
        }
    }
}
{
    "source_code": "\nstatic void *\ndogleg_alloc (const void * params, const size_t n, const size_t p)\n{\n  dogleg_state_t *state;\n  \n  state = calloc(1, sizeof(dogleg_state_t));\n  if (state == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate dogleg state\", GSL_ENOMEM);\n    }\n\n  state->dx_gn = gsl_vector_alloc(p);\n  if (state->dx_gn == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for dx_gn\", GSL_ENOMEM);\n    }\n\n  state->dx_sd = gsl_vector_alloc(p);\n  if (state->dx_sd == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for dx_sd\", GSL_ENOMEM);\n    }\n\n  state->workp1 = gsl_vector_alloc(p);\n  if (state->workp1 == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for workp1\", GSL_ENOMEM);\n    }\n\n  state->workp2 = gsl_vector_alloc(p);\n  if (state->workp2 == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for workp2\", GSL_ENOMEM);\n    }\n\n  state->workn = gsl_vector_alloc(n);\n  if (state->workn == NULL)\n    {\n      GSL_ERROR_NULL (\"failed to allocate space for workn\", GSL_ENOMEM);\n    }\n\n  state->n = n;\n  state->p = p;\n  state->params = *(const gsl_multilarge_nlinear_parameters *) params;\n\n  return state;\n}",
    "comment": "Allocates memory for a dogleg optimization state and its associated vectors, initializing parameters for nonlinear optimization.",
    "prorec_sum": "Allocates and initializes a dogleg solver state structure with multiple GSL vectors, copying parameters and data from the provided source structure.",
    "filter_prorec_sum": "Allocates and initializes a GSL dogleg minimizer state structure with required working vectors, copying initial parameters from the provided source state.",
    "prorec_aug_sum": "Allocates and initializes a dogleg method state structure with multiple GSL vectors, copying initial parameters from the provided source structure.",
    "filter_prorec_aug_sum": "Allocates and initializes a GSL-based dogleg state structure with working vectors, copying parameters and initial data from an existing state.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a dogleg solver state structure with multiple GSL vectors, copying parameters and data from the provided source structure.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately reflects the function's behavior: it allocates and initializes a dogleg state structure and creates multiple GSL vectors based on parameters n and p, then copies fields from the provided parameters structure. All claims are fact-based and align with the source code without errors.",
                "The summary correctly identifies the core purpose as allocating and initializing a dogleg solver state structure with multiple GSL vectors and copying parameters, matching the code's primary operation. However, it omits critical secondary details such as zero-initialization via calloc, explicit error handling on each allocation failure using GSL_ERROR_NULL, and the specific assignment of scalar fields n and p. These omissions limit its coverage of behavior-critical semantics beyond the core.",
                "The summary correctly states that the function allocates and initializes a dogleg solver state structure and creates multiple GSL vectors, which matches the allocation of dx_gn, dx_sd, workp1, workp2, and workn in the source code. It also accurately notes copying parameters from the provided structure. However, the phrase 'copying parameters and data' is slightly misleading, as only parameters (a struct) are copied and no arbitrary data beyond vectors is duplicated. Overall, the claim is accurate but generic, with no major noise or fatal errors and only limited detail about allocation error handling."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a GSL dogleg minimizer state structure with required working vectors, copying initial parameters from the provided source state.",
            "score": [
                0.7,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function allocates and initializes a GSL dogleg state structure and creates the necessary working vectors, matching the calloc and gsl_vector_alloc calls in the code. However, it inaccurately claims that initial parameters are copied from a source state; in reality, the function copies fields from the provided parameters struct, not from another state. This inaccuracy reduces precision, but the majority of the claims align with the source behavior.",
                "The summary correctly describes the function\u2019s core purpose of allocating and initializing a GSL dogleg state structure and setting up required working vectors, and notes that parameters are copied from provided input. This matches the core action in the code, including allocation of `dogleg_state_t` and vectors `dx_gn`, `dx_sd`, `workp1`, `workp2`, and `workn`, along with copying `params`. However, it omits key secondary semantics such as explicit null checks after each allocation, error handling via `GSL_ERROR_NULL`, and the specific dimensions used (`n` and `p` assigned to state), resulting in incomplete coverage of the function\u2019s behavior.",
                "The summary accurately states that the function allocates and initializes a dogleg minimizer state structure and sets up working vectors of appropriate sizes. However, the phrase 'copying initial parameters from the provided source state' is inaccurate: the function copies from a passed-in parameters structure, not from another state. This is a minor semantic error but it touches on a core aspect of input handling. Overall, there is no overwhelming noise, most claims are correct but fairly generic, resulting in moderate net benefit with small inaccuracy."
            ]
        }
    }
}
{
    "source_code": "\n\nngx_int_t\nngx_os_init(ngx_log_t *log)\n{\n    ngx_time_t  *tp;\n    ngx_uint_t   n;\n#if (NGX_HAVE_LEVEL1_DCACHE_LINESIZE)\n    long         size;\n#endif\n\n#if (NGX_HAVE_OS_SPECIFIC_INIT)\n    if (ngx_os_specific_init(log) != NGX_OK) {\n        return NGX_ERROR;\n    }\n#endif\n\n    if (ngx_init_setproctitle(log) != NGX_OK) {\n        return NGX_ERROR;\n    }\n\n    ngx_pagesize = getpagesize();\n    ngx_cacheline_size = NGX_CPU_CACHE_LINE;\n\n    for (n = ngx_pagesize; n >>= 1; ngx_pagesize_shift++) { /* void */ }\n\n#if (NGX_HAVE_SC_NPROCESSORS_ONLN)\n    if (ngx_ncpu == 0) {\n        ngx_ncpu = sysconf(_SC_NPROCESSORS_ONLN);\n    }\n#endif\n\n    if (ngx_ncpu < 1) {\n        ngx_ncpu = 1;\n    }\n\n#if (NGX_HAVE_LEVEL1_DCACHE_LINESIZE)\n    size = sysconf(_SC_LEVEL1_DCACHE_LINESIZE);\n    if (size > 0) {\n        ngx_cacheline_size = size;\n    }\n#endif\n\n    ngx_cpuinfo();\n\n    if (getrlimit(RLIMIT_NOFILE, &rlmt) == -1) {\n        ngx_log_error(NGX_LOG_ALERT, log, errno,\n                      \"getrlimit(RLIMIT_NOFILE) failed\");\n        return NGX_ERROR;\n    }\n\n    ngx_max_sockets = (ngx_int_t) rlmt.rlim_cur;\n\n#if (NGX_HAVE_INHERITED_NONBLOCK || NGX_HAVE_ACCEPT4)\n    ngx_inherited_nonblocking = 1;\n#else\n    ngx_inherited_nonblocking = 0;\n#endif\n\n    tp = ngx_timeofday();\n    srandom(((unsigned) ngx_pid << 16) ^ tp->sec ^ tp->msec);\n\n    return NGX_OK;\n}",
    "comment": "Initializes operating system parameters, retrieves CPU information, sets process title, and configures resource limits for a server application.",
    "prorec_sum": "Initializes OS-specific parameters, retrieves system page size, CPU and cache info, sets resource limits, and seeds the random number generator for Nginx.",
    "filter_prorec_sum": "Initializes OS-specific settings for Nginx, determines system page and cache parameters, retrieves resource limits, and seeds the random number generator.",
    "prorec_aug_sum": "Initializes OS-specific settings, detects CPU and memory parameters, configures resource limits, and seeds randomness for the Nginx runtime environment.",
    "filter_prorec_aug_sum": "Initializes Nginx OS-specific settings, determines CPU and memory parameters, configures resource limits, and seeds the random number generator.",
    "work_score": {
        "prorec": {
            "summary": "Initializes OS-specific parameters, retrieves system page size, CPU and cache info, sets resource limits, and seeds the random number generator for Nginx.",
            "score": [
                0.9,
                0.8,
                0.8
            ],
            "reason": [
                "The summary captures key actions of the function, including OS-specific initialization, fetching page size, CPU core count, cache line size, setting resource limits, and seeding the random number generator. These are all supported by the source code. Although it omits some specifics such as setting the process title and toggling inherited nonblocking mode, the majority of claims are accurate and reflect the code's actual behavior.",
                "The summary accurately captures the core purpose of initializing OS-specific parameters and system information, which matches the function\u2019s main role. Key secondary details such as retrieving page size, CPU count, cache line size, setting resource limits, and seeding the random number generator are correctly mentioned. However, it omits coverage of error handling branches (e.g., failures of ngx_os_specific_init, ngx_init_setproctitle, getrlimit) and certain conditional logic, so the coverage is broad but not complete.",
                "The summary correctly captures the primary purpose\u2014initializing OS-specific parameters\u2014and accurately mentions retrieving page size, CPU and cache info, setting resource limits, and seeding the random number generator, all of which match the source code. While it omits some minor steps like initializing the process title and handling inherited non-blocking sockets, these are secondary. There are no inaccurate claims, and the accurate claims are broad but correctly aligned with key functions, providing moderate insight."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes OS-specific settings for Nginx, determines system page and cache parameters, retrieves resource limits, and seeds the random number generator.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary captures key behaviors from the source code, including OS-specific initialization, determining system page and cache parameters, retrieving resource limits, and seeding the random number generator. All listed claims are accurate and directly supported by the code, with no contradictory or irrelevant information present.",
                "The summary correctly identifies the core purpose\u2014initializing OS-specific settings for Nginx\u2014but does so in general terms without detailing specific initialization steps like setting the process title or fetching CPU count, which are key domain actions in the source. It accurately mentions retrieving pagesize/cacheline size, resource limits, and seeding the RNG, aligning with the code\u2019s behavior, but omits other critical secondary behaviors such as invoking ngx_cpuinfo, handling RLIMIT_NOFILE errors, and determining non-blocking inheritance. Coverage of the core is present, but secondary details are incomplete.",
                "The summary contains accurate, concise claims about the function\u2019s purpose: it performs OS-specific initialization, sets page and cache parameters, retrieves file descriptor limits, and seeds the random generator. All are consistent with the source code and target core semantics. However, the summary omits several secondary but relevant behaviors such as determining the number of CPUs, setting process title, and configuring inherited non-blocking mode. These omissions reduce the informational gain, though there is no inaccurate or noisy content."
            ]
        }
    }
}
{
    "source_code": "static int tcp_match_skb_to_sack(struct sock *sk, struct sk_buff *skb,\n\t\t\t\t  u32 start_seq, u32 end_seq)\n{\n\tint err;\n\tbool in_sack;\n\tunsigned int pkt_len;\n\tunsigned int mss;\n\n\tin_sack = !after(start_seq, TCP_SKB_CB(skb)->seq) &&\n\t\t  !before(end_seq, TCP_SKB_CB(skb)->end_seq);\n\n\tif (tcp_skb_pcount(skb) > 1 && !in_sack &&\n\t    after(TCP_SKB_CB(skb)->end_seq, start_seq)) {\n\t\tmss = tcp_skb_mss(skb);\n\t\tin_sack = !after(start_seq, TCP_SKB_CB(skb)->seq);\n\n\t\tif (!in_sack) {\n\t\t\tpkt_len = start_seq - TCP_SKB_CB(skb)->seq;\n\t\t\tif (pkt_len < mss)\n\t\t\t\tpkt_len = mss;\n\t\t} else {\n\t\t\tpkt_len = end_seq - TCP_SKB_CB(skb)->seq;\n\t\t\tif (pkt_len < mss)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* Round if necessary so that SACKs cover only full MSSes\n\t\t * and/or the remaining small portion (if present)\n\t\t */\n\t\tif (pkt_len > mss) {\n\t\t\tunsigned int new_len = (pkt_len / mss) * mss;\n\t\t\tif (!in_sack && new_len < pkt_len) {\n\t\t\t\tnew_len += mss;\n\t\t\t\tif (new_len > skb->len)\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tpkt_len = new_len;\n\t\t}\n\t\terr = tcp_fragment(sk, skb, pkt_len, mss);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\treturn in_sack;\n}",
    "comment": "Determines if a TCP segment belongs to the SACK range and fragments it accordingly based on MSS and sequence numbers.",
    "prorec_sum": "Validates offsets against stored bounds and segment size, invoking a helper to process data when within range, else returning error or limit status.",
    "filter_prorec_sum": "Validates positional offsets against configured limits and segment sizes, invoking a helper to process within range or returning specific status codes otherwise.",
    "prorec_aug_sum": "Validates packet size against path MTU and invokes adjustment logic to handle fragmentation or transmission constraints based on route and offset parameters.",
    "filter_prorec_aug_sum": "Checks packet position against stored offsets and segment size, invoking a helper to process available data or returning specific error/status codes.",
    "work_score": {
        "prorec": {
            "summary": "Validates offsets against stored bounds and segment size, invoking a helper to process data when within range, else returning error or limit status.",
            "score": [
                0.3,
                0.3,
                0.3
            ],
            "reason": [
                "The summary offers a generic interpretation of bounds checking and helper invocation, but it omits critical TCP-specific details from the source code such as SACK range determination, MSS alignment, fragmentation logic, and conditional return values. While parts of the description loosely match the presence of range checks and error returns, most of the domain semantics are absent or inaccurately generalized, resulting in less than half of the claims being precise and verifiable against the code.",
                "The summary vaguely describes validating offsets and processing data within range, which loosely relates to checking packet sequence bounds and segment sizes in the code. However, it fails to identify the core purpose \u2014 determining if a TCP skb is within a SACK block and potentially fragmenting it accordingly. Key semantics such as SACK matching, handling multi-packet skbs, MSS alignment, and specific error returns are missing, resulting in incomplete coverage of both the core and secondary behaviors.",
                "The summary is largely inaccurate (NOISE) because it generically describes validating offsets against bounds and processing data, but omits critical TCP-specific semantics\u2014such as matching sequence numbers to SACK ranges, splitting SKBs based on MSS, and returning boolean in_sack or error codes accordingly. No clear GOLD-level claim about core purpose or key I/O is made, and the vague range-validating description fails to capture core functionality, making the net benefit minimal."
            ]
        },
        "filter_prorec": {
            "summary": "Validates positional offsets against configured limits and segment sizes, invoking a helper to process within range or returning specific status codes otherwise.",
            "score": [
                0.2,
                0.1,
                0.4
            ],
            "reason": [
                "The summary provides a generic description of validating offsets and limits, but the source code specifically checks TCP sequence numbers against SACK ranges, handles multi-packet sk_buffs, adjusts segment sizes to MSS boundaries, and calls tcp_fragment. The summary omits these critical TCP and MSS-specific semantics and instead gives vague, non-domain-specific statements. Most claims do not directly align with the actual code behavior, resulting in a low proportion of accurate claims.",
                "The summary provides a vague description about validating offsets and calling a helper, but it fails to accurately convey the core purpose of determining whether a TCP segment falls within a SACK range and possibly fragmenting it. It does not mention SACK, sequence numbers, MSS alignment, or the specific branch/error handling present in the code, making the core domain action completely uncovered and omitting critical secondary details.",
                "The summary is mostly inaccurate or overly generic. It refers to 'positional offsets', 'configured limits', and 'segment sizes' in vague terms, which loosely correspond to sequence numbers and MSS from the code but lack specificity about how SACK range matching is done. Critical logic such as checking if a packet is within the SACK range, handling multi-packet segments, rounding lengths to MSS multiples, and invoking tcp_fragment is not captured accurately. The claim about returning specific status codes is misleading as the function returns integers for errors or boolean in_sack, not arbitrary status codes. Overall, the noise outweighs accurate details, with no FATAL but low gain due to generic phrasing."
            ]
        }
    }
}
{
    "source_code": "static int o_save_ptr_helper(o_string *o, int n)\n{\n\tchar **list = (char**)o->data;\n\tint string_start;\n\tint string_len;\n\n\tif (!o->has_empty_slot) {\n\t\tstring_start = ((n + 0xf) & ~0xf) * sizeof(list[0]);\n\t\tstring_len = o->length - string_start;\n\t\tif (!(n & 0xf)) { /* 0, 0x10, 0x20...? */\n\t\t\tdebug_printf_list(\"list[%d]=%d string_start=%d (growing)\\n\", n, string_len, string_start);\n\t\t\t/* list[n] points to string_start, make space for 16 more pointers */\n\t\t\to->maxlen += 0x10 * sizeof(list[0]);\n\t\t\to->data = xrealloc(o->data, o->maxlen + 1);\n\t\t\tlist = (char**)o->data;\n\t\t\tmemmove(list + n + 0x10, list + n, string_len);\n\t\t\to->length += 0x10 * sizeof(list[0]);\n\t\t} else {\n\t\t\tdebug_printf_list(\"list[%d]=%d string_start=%d\\n\",\n\t\t\t\t\tn, string_len, string_start);\n\t\t}\n\t} else {\n\t\t/* We have empty slot at list[n], reuse without growth */\n\t\tstring_start = ((n+1 + 0xf) & ~0xf) * sizeof(list[0]); /* NB: n+1! */\n\t\tstring_len = o->length - string_start;\n\t\tdebug_printf_list(\"list[%d]=%d string_start=%d (empty slot)\\n\",\n\t\t\t\tn, string_len, string_start);\n\t\to->has_empty_slot = 0;\n\t}\n\to->has_quoted_part = 0;\n\tlist[n] = (char*)(uintptr_t)string_len;\n\treturn n + 1;\n}",
    "comment": "Reallocates string storage for a list, handles empty slots, and updates the length and state of the string data structure.",
    "prorec_sum": "Updates an entry in a table, allocating and initializing new storage when needed, then writes the computed offset and returns the next index.",
    "filter_prorec_sum": "Updates an entry in a structured memory table, allocating and initializing a new block when aligned conditions are met.",
    "prorec_aug_sum": "Updates an entry in a data structure, allocating and initializing a new block when needed, then stores the computed offset and advances the index.",
    "filter_prorec_aug_sum": "Updates an entry in a table, allocating and initializing a new block when needed, then stores a size-adjusted offset for the given index.",
    "work_score": {
        "prorec": {
            "summary": "Updates an entry in a table, allocating and initializing new storage when needed, then writes the computed offset and returns the next index.",
            "score": [
                0.5,
                0.4,
                0.5
            ],
            "reason": [
                "The summary contains partially accurate elements: it correctly notes that the function may allocate new storage when needed and returns the next index. However, it inaccurately describes core semantics by referring to updating a generic table and initializing storage, while the code specifically manipulates a list of string pointers in an o_string structure, manages slots, computes and stores string lengths as offsets, and resets certain flags. These omissions and generalizations reduce precision, resulting in mixed reliability.",
                "The summary correctly notes allocation when needed and writing an offset before returning the next index, which partially aligns with the code\u2019s behavior. However, it misses the core purpose: manipulating a pointer list within an o_string structure by shifting entries when growing space in blocks of 16, handling an empty-slot reuse path, and updating structure flags. These domain-specific details and branching behaviors are absent, making the coverage of secondary semantics very limited despite core action being loosely mentioned.",
                "The summary makes a generic claim about updating an entry in a table and allocating new storage if needed, which loosely matches the code's behavior but omits critical specifics such as the handling of empty slots, the 16-pointer growth increments, debug printing, and the exact computation of string_start and string_len. While not factually wrong, the description is too abstract to be reliably tied to the source semantics, offering low informational gain. No fatal inaccuracies are present, but the high-level nature constitutes noticeable noise with minimal specific insight."
            ]
        },
        "filter_prorec": {
            "summary": "Updates an entry in a structured memory table, allocating and initializing a new block when aligned conditions are met.",
            "score": [
                0.6,
                0.2,
                0.5
            ],
            "reason": [
                "The summary claims that the function updates an entry in a structured memory table and allocates/initializes a new block when certain alignment conditions are met. The source code indeed updates a specific entry in what appears to be an array of pointers and performs reallocation when `n` is a multiple of 16 (alignment). However, it omits important details such as handling the `has_empty_slot` flag, calculating offsets, moving existing elements, and doesn't mention that 'initializing' a new block is not explicitly done beyond memory allocation and shifting pointers. The alignment condition is roughly captured, and the update action is somewhat accurate, so the claim aligns partially with the code but lacks precision and completeness.",
                "The summary gives a vague and partially incorrect description; it does not clearly capture the core purpose, which is shifting and possibly expanding a char* list in an o_string structure with specific alignment and empty-slot logic. While it mentions allocation under certain conditions, it omits critical details like the 16-pointer growth increment, memmove of existing entries, reuse without growth when an empty slot exists, and resetting flags. The core semantics are not covered with adequate specificity, and secondary behavior is largely missing.",
                "The summary claims the function updates an entry in a structured memory table and allocates/initializes a new block when alignment conditions are met. The function indeed updates a pointer array and reallocates memory when the index is a multiple of 16, which can be seen as an alignment condition, so this part is accurate. However, it does not initialize a 'new block' in the sense of general object setup, but adjusts an existing array and shifts elements. The term 'structured memory table' is a vague and imprecise description of the pointer array. The inaccuracies are minor and there is no FATAL claim about the primary purpose; noise is moderate due to vague terminology and lack of detail. Overall, information gain is low due to the generic nature of the summary."
            ]
        }
    }
}
{
    "source_code": "\nvoid\ndatamash_ops_free ( struct datamash_ops* p )\n{\n  assert (p != NULL);                            /* LCOV_EXCL_LINE */\n  for (size_t i=0; i<p->num_grps; ++i)\n    free (p->grps[i].name);\n  free (p->grps);\n  p->grps = NULL;\n\n  #ifndef _STANDALONE_\n  for (size_t i=0; i<p->num_ops; ++i)\n    field_op_free (&p->ops[i]);\n  #endif\n\n  free (p->ops);\n  p->ops = NULL;\n\n  for  (size_t i=0; i<_fields_used; ++i) {\n    free (_fields[i].name);\n  }\n  free (_fields);\n  _fields = NULL;\n  _fields_alloc = 0;\n  _fields_used = 0;\n\n  free (_params);\n  _params_alloc = 0;\n  _params_used = 0;\n\n  free (p);\n}",
    "comment": "Frees allocated memory for operation groups, fields, parameters, and the datamash_ops structure while ensuring no memory leaks occur.",
    "prorec_sum": "Frees all dynamically allocated memory associated with an operation parser structure, including its internal arrays, related global buffers, and the structure itself.",
    "filter_prorec_sum": "Frees all allocated memory and resources associated with datamash operation structures and global state, then releases the main structure itself.",
    "prorec_aug_sum": "Frees all dynamically allocated memory associated with an operation parser structure and related global lists before releasing the structure itself.",
    "filter_prorec_aug_sum": "Frees all dynamically allocated operation data structures and related global buffers, then releases the main structure\u2019s memory.",
    "work_score": {
        "prorec": {
            "summary": "Frees all dynamically allocated memory associated with an operation parser structure, including its internal arrays, related global buffers, and the structure itself.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately describes the function\u2019s behavior: it frees all dynamically allocated memory for the given structure, including its internal arrays, global buffers, and finally the structure itself. This matches the source code\u2019s operations, which deallocate group names, group array, ops array, global _fields and _params arrays, and reset related counters before freeing the main pointer. All claims are directly supported by the code, with no inaccuracies.",
                "The summary accurately describes the core purpose of the function as deallocating all dynamically allocated memory for the operation parser structure, matching the code's main behavior of freeing its internal arrays, global buffers, and the structure itself. However, it lacks coverage of notable secondary details from the code, such as freeing individual element names within arrays, handling the _STANDALONE_ conditional to free ops via field_op_free, and resetting global counters to zero. This limits completeness of coverage beyond the central action.",
                "The summary correctly states that the function frees dynamically allocated memory tied to the given structure, including internal arrays, relevant global buffers, and the structure itself. This matches the code\u2019s behavior, which frees group names, group array, ops array (with possible field_op_free calls), global _fields and _params arrays, and resets associated counters before freeing the main struct. The claim is accurate, specific to the core purpose, and contains no noise or inaccuracies, offering clear insight into the function\u2019s domain-semantic behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Frees all allocated memory and resources associated with datamash operation structures and global state, then releases the main structure itself.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary accurately captures the core behavior of the function, which deallocates memory for group names, group and ops arrays, fields, parameters, and finally frees the main struct. It correctly reflects both the freeing of resources tied to the datamash_ops structure and related global state. No contradictory or irrelevant claims are present, resulting in high alignment with the source code.",
                "The summary correctly states the core purpose of freeing all memory and resources tied to datamash operations and related global state, matching the source code\u2019s main action. However, it is generic and does not mention specific secondary details such as freeing group names, ops via `field_op_free` under certain conditions, resetting pointers to NULL, and zeroing allocation/usage counters. This limits coverage of critical, specific behaviors beyond the core action.",
                "The summary correctly conveys the primary purpose of the function: freeing all allocated memory tied to the datamash_ops structure, related resources, and global state, then releasing the main structure pointer. This matches the code, which iterates through group and operation arrays, frees names and fields, resets allocation counters, and finally frees the main struct. There are no inaccurate or off-topic claims, but the description is generic and lacks specifics about conditional freeing of operations or exact fields reset, resulting in low positive gain."
            ]
        }
    }
}
{
    "source_code": "\nbfd_boolean\n_bfd_elf_maybe_strip_eh_frame_hdr (struct bfd_link_info *info)\n{\n  struct elf_link_hash_table *htab;\n  struct eh_frame_hdr_info *hdr_info;\n  struct bfd_link_hash_entry *bh = NULL;\n  struct elf_link_hash_entry *h;\n\n  htab = elf_hash_table (info);\n  hdr_info = &htab->eh_info;\n  if (hdr_info->hdr_sec == NULL)\n    return TRUE;\n\n  if (bfd_is_abs_section (hdr_info->hdr_sec->output_section)\n      || info->eh_frame_hdr_type == 0\n      || (info->eh_frame_hdr_type == DWARF2_EH_HDR\n\t  && !_bfd_elf_eh_frame_present (info))\n      || (info->eh_frame_hdr_type == COMPACT_EH_HDR\n\t  && !_bfd_elf_eh_frame_entry_present (info)))\n    {\n      hdr_info->hdr_sec->flags |= SEC_EXCLUDE;\n      hdr_info->hdr_sec = NULL;\n      return TRUE;\n    }\n\n  /* Add a hidden symbol so that systems without access to PHDRs can\n     find the table.  */\n  if (! (_bfd_generic_link_add_one_symbol\n\t (info, info->output_bfd, \"__GNU_EH_FRAME_HDR\", BSF_LOCAL,\n\t  hdr_info->hdr_sec, 0, NULL, FALSE, FALSE, &bh)))\n    return FALSE;\n\n  h = (struct elf_link_hash_entry *) bh;\n  h->def_regular = 1;\n  h->other = STV_HIDDEN;\n  get_elf_backend_data\n    (info->output_bfd)->elf_backend_hide_symbol (info, h, TRUE);\n\n  if (!hdr_info->frame_hdr_is_compact)\n    hdr_info->u.dwarf.table = TRUE;\n  return TRUE;\n}",
    "comment": "Modifies the header section flags and adds a hidden symbol if specific conditions for EH frame header presence are not met.",
    "prorec_sum": "Configures and registers the `__GNU_EH_FRAME_HDR` section for an object, adjusting related flags and state based on header bits and validation results.",
    "filter_prorec_sum": "Loads and processes the \"__GNU_EH_FRAME_HDR\" section if header flags permit, updating related structures and state, otherwise marks and clears the associated entry.",
    "prorec_aug_sum": "Processes ELF frame header data, updating related structures and flags, and marks dynamic section state based on specific byte flags and helper checks.",
    "filter_prorec_aug_sum": "Processes the `__GNU_EH_FRAME_HDR` section for a loaded object, updating related flags and invoking its handler based on header status bits.",
    "work_score": {
        "prorec": {
            "summary": "Configures and registers the `__GNU_EH_FRAME_HDR` section for an object, adjusting related flags and state based on header bits and validation results.",
            "score": [
                0.5,
                0.3,
                0.2
            ],
            "reason": [
                "The summary's claim that the function 'configures and registers the __GNU_EH_FRAME_HDR section' is partially accurate, as the code does add the symbol and adjust section flags. However, it incorrectly frames this as unconditional configuration based on 'header bits and validation results' without mentioning the specific conditional checks involving section type, hdr_type, and EH frame presence. It omits details such as stripping the section when conditions are met and setting symbol visibility. The claim is overly generic and misses key semantic behavior, leading to mixed accuracy.",
                "The summary generically mentions configuring and registering the `__GNU_EH_FRAME_HDR` section, but the function\u2019s core purpose is to optionally strip or exclude the `.eh_frame_hdr` section based on conditions (like section type, header type, presence of EH frame data) and, if kept, to add a hidden symbol for locating it. The core conditional exclusion behavior and symbol visibility adjustments are missing in the summary, and it inaccurately frames the primary action as registration without emphasizing the stripping logic. Secondary details of validation and flag modifications are vaguely noted but not specific to the actual branches and constants used.",
                "The summary incorrectly frames the function's purpose as always configuring and registering the `__GNU_EH_FRAME_HDR` section, omitting that the code may instead exclude and remove the header section under certain conditions. This is a FATAL error affecting the primary purpose and core control flow. While the mention of adjusting flags and state is partially accurate, the claim is misleading regarding the function's core action, and there is no notable specific or detailed gain to offset the error."
            ]
        },
        "filter_prorec": {
            "summary": "Loads and processes the \"__GNU_EH_FRAME_HDR\" section if header flags permit, updating related structures and state, otherwise marks and clears the associated entry.",
            "score": [
                0.5,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains two main claims: that the function loads and processes the \"__GNU_EH_FRAME_HDR\" section if header flags permit, and that it otherwise marks and clears the associated entry. The second claim is accurate, as the code conditionally sets SEC_EXCLUDE and nullifies hdr_sec when certain conditions are met. However, the first claim is partially inaccurate: the function does not generally load and process the section; it specifically adds a hidden symbol named \"__GNU_EH_FRAME_HDR\" and updates related structures if conditions pass, but this occurs regardless of direct 'header flags' in the sense implied and is tied to complex conditional checks. The summary oversimplifies and misattributes the trigger condition, so only about half of the claims align precisely with the code.",
                "The summary vaguely mentions loading and processing the '__GNU_EH_FRAME_HDR' but incorrectly frames the core purpose, which is conditionally stripping or retaining the .eh_frame_hdr section based on header type and presence checks, and adding a hidden symbol for accessibility when retained. It omits key domain specifics like conditional exclusion using SEC_EXCLUDE, the checks for DWARF2/COMPACT EH frames, and the hidden symbol creation, thus failing to accurately cover the core semantics. Secondary behaviors like symbol visibility changes and DWARF table flag setting are also missing.",
                "The summary inaccurately claims the function 'loads and processes' the section, which is misleading: the code does not load content but conditionally adds a symbol and updates metadata. The conditional logic in code is complex, based on header section presence, section type, and EH frame existence, but the summary condenses it incorrectly, omitting key conditions and effects. This constitutes a FATAL error on the primary purpose, as the main behavior is misrepresented. There are minimal accurate elements, such as noting a section may be marked and cleared, but overall the noise from the inaccuracy overwhelms any gain."
            ]
        }
    }
}
{
    "source_code": "static int\ngmp_stronglucas (const mpz_t x, mpz_t Qk)\n{\n  mp_bitcnt_t b0;\n  mpz_t V, n;\n  mp_limb_t maxD, D; /* The absolute value is stored. */\n  long Q;\n  mp_limb_t tl;\n\n  /* Test on the absolute value. */\n  mpz_roinit_normal_n (n, x->_mp_d, GMP_ABS (x->_mp_size));\n\n  assert (mpz_odd_p (n));\n  /* assert (mpz_gcd_ui (NULL, n, 6) == 1); */\n  if (mpz_root (Qk, n, 2))\n    return 0; /* A square is composite. */\n\n  /* Check Ds up to square root (in case, n is prime)\n     or avoid overflows */\n  maxD = (Qk->_mp_size == 1) ? Qk->_mp_d [0] - 1 : GMP_LIMB_MAX;\n\n  D = 3;\n  /* Search a D such that (D/n) = -1 in the sequence 5,-7,9,-11,.. */\n  /* For those Ds we have (D/n) = (n/|D|) */\n  do\n    {\n      if (D >= maxD)\n\treturn 1 + (D != GMP_LIMB_MAX); /* (1 + ! ~ D) */\n      D += 2;\n      tl = mpz_tdiv_ui (n, D);\n      if (tl == 0)\n\treturn 0;\n    }\n  while (gmp_jacobi_coprime (tl, D) == 1);\n\n  mpz_init (V);\n\n  /* n-(D/n) = n+1 = d*2^{b0}, with d = (n>>b0) | 1 */\n  b0 = mpz_scan0 (n, 0);\n\n  /* D= P^2 - 4Q; P = 1; Q = (1-D)/4 */\n  Q = (D & 2) ? (long) (D >> 2) + 1 : -(long) (D >> 2);\n\n  if (! gmp_lucas_mod (V, Qk, Q, b0, n))\t/* If Ud != 0 */\n    while (V->_mp_size != 0 && --b0 != 0)\t/* while Vk != 0 */\n      /* V <- V ^ 2 - 2Q^k */\n      /* Q^{2k} = (Q^k)^2 */\n      gmp_lucas_step_k_2k (V, Qk, n);\n\n  mpz_clear (V);\n  return (b0 != 0);\n}",
    "comment": "Determines if an odd integer is prime using the Lucas-Lehmer test and computes the Lucas sequence value based on specific parameters.",
    "prorec_sum": "Performs a strong Lucas primality test on a given large integer using mini-GMP routines to determine if it is prime.",
    "filter_prorec_sum": "Checks if a given large integer is an odd prime using a strong Lucas primality test implementation from the mini-GMP library.",
    "prorec_aug_sum": "Performs a strong Lucas probable prime test on a given odd number using mini-gmp functions and returns the primality result.",
    "filter_prorec_aug_sum": "Performs a strong Lucas primality test on a given odd multi-precision integer using mini-GMP functions and returns the result.",
    "work_score": {
        "prorec": {
            "summary": "Performs a strong Lucas primality test on a given large integer using mini-GMP routines to determine if it is prime.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary makes a single claim that the function performs a strong Lucas primality test using mini-GMP routines to determine if a given integer is prime. This accurately reflects the purpose of the code, which implements the strong Lucas test via GMP utility functions to assess primality. There are no inaccurate statements and the claim is targeted to the code's semantics, but it is general rather than detailing specific algorithm steps.",
                "The summary correctly identifies the core operation as performing a strong Lucas primality test with mini-GMP routines, aligning with the function's primary purpose of testing an odd integer for primality using Lucas sequences. However, it omits important secondary details from the code, such as the initial square check, the search for an appropriate D value via Jacobi symbol conditions, iterative Lucas sequence updates, and the specific return conditions for composite detection. These omissions limit coverage of behavior-critical semantics beyond the core purpose.",
                "The summary claims the function performs a strong Lucas primality test to determine if a given large integer is prime, which is consistent with the code's detailed Lucas sequence steps, Jacobi symbol checks, and square check. There are no contradictory or irrelevant statements, but the description is highly generic and lacks specific details about algorithm steps (e.g., D search pattern, Q computation, loop conditions). This provides only minimal insight beyond the primary purpose, so the gain is low, though accuracy is intact and noise absent."
            ]
        },
        "filter_prorec": {
            "summary": "Checks if a given large integer is an odd prime using a strong Lucas primality test implementation from the mini-GMP library.",
            "score": [
                0.5,
                0.4,
                0.2
            ],
            "reason": [
                "The summary makes two claims: that it checks if a given large integer is an odd prime, and that it uses a strong Lucas primality test from the mini-GMP library. The code indeed uses a strong Lucas test (ACCURATE), but it does not guarantee primality\u2014return values may indicate composite status or continue testing\u2014and the oddness is asserted rather than determined here. The \u2018odd prime\u2019 phrasing is misleading because the code functions as part of a composite check, not as a definitive prime detector. Thus, only about half of the claims are accurate.",
                "The summary correctly identifies that the function uses a strong Lucas primality test and that it operates on an odd integer, which aligns with the source code's behavior. This matches the core purpose: performing a strong Lucas test on a large integer via mini-GMP to determine primality. However, it omits important details such as preliminary composite checks (square root, divisibility), the selection of parameter D, handling of special cases, and the iterative Lucas sequence steps, so coverage of secondary behavior-critical semantics is weak.",
                "The summary incorrectly states that the function checks if a number is an odd prime, which is a FATAL error on the primary purpose. The source code implements a strong Lucas test that can return composite for squares and operates on odd integers, but does not guarantee primality\u2014it\u2019s part of a larger primality routine. The key claim about confirming an odd prime contradicts the actual behavior. There is minimal accurate detail (mentions strong Lucas test from mini-GMP), but the incorrect core-purpose statement makes the description unreliable."
            ]
        }
    }
}
{
    "source_code": "\n\nint ec_GFp_simple_group_get_curve(const EC_GROUP *group, BIGNUM *p, BIGNUM *a, BIGNUM *b, BN_CTX *ctx)\n\t{\n\tint ret = 0;\n\tBN_CTX *new_ctx = NULL;\n\t\n\tif (p != NULL)\n\t\t{\n\t\tif (!BN_copy(p, &group->field)) return 0;\n\t\t}\n\n\tif (a != NULL || b != NULL)\n\t\t{\n\t\tif (group->meth->field_decode)\n\t\t\t{\n\t\t\tif (ctx == NULL)\n\t\t\t\t{\n\t\t\t\tctx = new_ctx = BN_CTX_new();\n\t\t\t\tif (ctx == NULL)\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\tif (a != NULL)\n\t\t\t\t{\n\t\t\t\tif (!group->meth->field_decode(group, a, &group->a, ctx)) goto err;\n\t\t\t\t}\n\t\t\tif (b != NULL)\n\t\t\t\t{\n\t\t\t\tif (!group->meth->field_decode(group, b, &group->b, ctx)) goto err;\n\t\t\t\t}\n\t\t\t}\n\t\telse\n\t\t\t{\n\t\t\tif (a != NULL)\n\t\t\t\t{\n\t\t\t\tif (!BN_copy(a, &group->a)) goto err;\n\t\t\t\t}\n\t\t\tif (b != NULL)\n\t\t\t\t{\n\t\t\t\tif (!BN_copy(b, &group->b)) goto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\n\tret = 1;\n\t\n err:\n\tif (new_ctx)\n\t\tBN_CTX_free(new_ctx);\n\treturn ret;\n\t}",
    "comment": "Retrieves the elliptic curve parameters (field, a, and b) from the specified EC_GROUP structure into provided BIGNUM variables.",
    "prorec_sum": "Retrieves the prime field curve parameters a, b, and p from an EC group, using BN_copy or group-specific methods with optional BN_CTX management.",
    "filter_prorec_sum": "Retrieves the elliptic curve parameters a, b, and field prime from a GFp group, using BN_copy or a method callback with optional BN_CTX.",
    "prorec_aug_sum": "Retrieves the curve parameters a, b, and field modulus from a GFp EC_GROUP, using BN_copy or method-specific operations with optional BN_CTX management.",
    "filter_prorec_aug_sum": "Retrieves the elliptic curve group parameters a, b, and field modulus into supplied BIGNUMs, using method-specific or direct BN_copy operations with optional BN_CTX.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves the prime field curve parameters a, b, and p from an EC group, using BN_copy or group-specific methods with optional BN_CTX management.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly identifies that the function retrieves curve parameters p, a, and b from an EC_GROUP and uses BN_copy or group-specific field_decode methods, along with optional BN_CTX handling. All elements directly match the source code behavior, making the claims specific, accurate, and verifiable.",
                "The summary correctly identifies the core purpose as retrieving the prime field curve parameters p, a, and b from an EC group, which matches the function\u2019s primary action. It notes use of BN_copy and group-specific methods, aligning with the conditional use of BN_copy or field_decode in the code, and mentions optional BN_CTX management, reflecting the handling of ctx and new_ctx. However, it omits error branch specifics (immediate returns on failure), conditional logic based on field_decode presence, and freeing BN_CTX on error, so coverage of secondary behaviors is only partial.",
                "The summary accurately describes the primary purpose of the function: retrieving the prime field curve parameters a, b, and p from an EC group using BN_copy or group-specific decode methods, and notes the optional BN_CTX management when needed. There are no incorrect or irrelevant claims, and the information is specific to the code's behavior, though not highly detailed about all branches. Noise is minimal and gain is moderate due to clear alignment with the source code."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves the elliptic curve parameters a, b, and field prime from a GFp group, using BN_copy or a method callback with optional BN_CTX.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately reflects the function\u2019s core behavior: retrieving the elliptic curve parameters a, b, and the field prime from an EC_GROUP, using BN_copy or the group\u2019s field_decode callback, with optional BN_CTX creation. All elements mentioned align with the source code, with no contradictions or irrelevant claims, resulting in a very high proportion of accurate statements.",
                "The summary accurately states the core purpose: retrieving the field prime p and coefficients a and b from a GFp EC_GROUP using BN_copy or the group\u2019s field_decode method, with optional BN_CTX handling. It covers the primary domain operation clearly and mentions the alternate method callback and optional context creation. However, it omits secondary details such as conditional allocation of a new BN_CTX, specific error handling paths, and freeing of allocated context, making the coverage of secondary behavior incomplete.",
                "The summary correctly states the core purpose: retrieving the elliptic curve parameters a, b, and the field prime from a GFp group. It accurately notes that BN_copy is used and that a method callback may be invoked, with BN_CTX optionally used. These are specific and verifiable details matching the source code. There is minimal noise and no factual errors; the claims align with the function\u2019s primary purpose and logic. The gains are moderate to high, as the summary captures both the core intent and key implementation options."
            ]
        }
    }
}
{
    "source_code": "\nvoid FAST_FUNC bb_perror_msg(const char *s, ...)\n{\n\tva_list p;\n\n\tva_start(p, s);\n\t/* Guard against \"<error message>: Success\" */\n\tbb_verror_msg(s, p, errno ? strerror(errno) : NULL);\n\tva_end(p);\n}",
    "comment": "Logs an error message along with the string representation of the current errno value, using a variable argument list for additional context.",
    "prorec_sum": "Packages input parameters and optional SIMD values, computes a derived value if configured, and forwards them to another routine for final processing.",
    "filter_prorec_sum": "Builds a parameter block from scalar and vector inputs, computes optional doubles via a helper, and forwards them to another processing routine.",
    "prorec_aug_sum": "Constructs parameter data from provided coordinates and calls a processing routine, optionally transforming vectors through an auxiliary computation if a global flag is set.",
    "filter_prorec_aug_sum": "Constructs parameter data from provided vectors and conditionally computes a double-based value before invoking a secondary processing routine with these arguments.",
    "work_score": {
        "prorec": {
            "summary": "Packages input parameters and optional SIMD values, computes a derived value if configured, and forwards them to another routine for final processing.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary makes claims about packaging parameters with optional SIMD values, computing a derived value, and forwarding to another routine. The source code shows that the function simply initializes a va_list for variable arguments, chooses an error message based on errno, and calls bb_verror_msg. There is no SIMD-related processing or derived value computation, so all claims are inaccurate and do not reflect the actual semantics.",
                "The summary makes no specific or accurate reference to the source code's core purpose of formatting and printing an error message with a guard against misleading success messages. Instead, it describes generic packaging of parameters, SIMD values, and derived computation, which contradicts the actual function behavior. The core is not covered and the claims are inaccurate.",
                "The summary's claims about packaging input parameters, optional SIMD values, and computing derived values are not reflected in the source code, which instead formats a variable argument list and forwards an error message to another function. All claims are unrelated to actual semantics, constituting NOISE and providing no accurate insight into the function, resulting in overwhelming inaccuracy with no positive gain."
            ]
        },
        "filter_prorec": {
            "summary": "Builds a parameter block from scalar and vector inputs, computes optional doubles via a helper, and forwards them to another processing routine.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary describes building a parameter block from scalar and vector inputs, computing optional doubles, and forwarding them to a processing routine, which does not match the source code. The actual function initializes a variable argument list, processes an error message using a helper, and includes a specific guard condition, with no mention of parameter blocks, vectors, or double computations. All claims are unrelated to the code\u2019s semantics, resulting in no accurate matches.",
                "The summary's claims about building parameter blocks from scalar and vector inputs, computing optional doubles, and forwarding them to another routine are entirely unrelated to the source code's actual purpose, which is to format and print an error message using a variadic argument list and optionally include the errno string. The core purpose is not covered and no accurate claims reflect the function's behavior.",
                "The summary's claims about building a parameter block from scalar and vector inputs, computing optional doubles via a helper, and forwarding them to another routine are entirely unrelated to the actual function, which formats and forwards an error message string using variadic arguments and errno. These are NOISE claims that do not match any domain semantics of the source code, with no accurate statements present. The worst failure mode is overwhelming NOISE, resulting in no net benefit."
            ]
        }
    }
}
{
    "source_code": "int mls_import_netlbl_cat(struct context *context,\n\t\t\t  struct netlbl_lsm_secattr *secattr)\n{\n\tint rc;\n\n\tif (!policydb.mls_enabled)\n\t\treturn 0;\n\n\trc = ebitmap_netlbl_import(&context->range.level[0].cat,\n\t\t\t\t   secattr->attr.mls.cat);\n\tif (rc != 0)\n\t\tgoto import_netlbl_cat_failure;\n\n\trc = ebitmap_cpy(&context->range.level[1].cat,\n\t\t\t &context->range.level[0].cat);\n\tif (rc != 0)\n\t\tgoto import_netlbl_cat_failure;\n\n\treturn 0;\n\nimport_netlbl_cat_failure:\n\tebitmap_destroy(&context->range.level[0].cat);\n\tebitmap_destroy(&context->range.level[1].cat);\n\treturn rc;\n}",
    "comment": "Imports and copies the MLS category attributes into the context structure if MLS is enabled, handling errors by destroying allocated resources.",
    "prorec_sum": "Checks a global state and performs two geometry-related update operations on structures at given offsets, returning success if either update is executed.",
    "filter_prorec_sum": "Checks global initialization and performs two object-related update operations using provided parameters, returning a status code if either succeeds.",
    "prorec_aug_sum": "Processes two related data structures using multiple computation routines, updating them when certain conditions are met, and returns a status code indicating the operation result.",
    "filter_prorec_aug_sum": "Processes two related data structures with provided parameters, performing conditional sub-operations only if initial checks succeed, then returns the computed status code.",
    "work_score": {
        "prorec": {
            "summary": "Checks a global state and performs two geometry-related update operations on structures at given offsets, returning success if either update is executed.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary misrepresents the function's behavior: it incorrectly states the operations are geometry-related when they actually import and copy MLS category bitmaps, and falsely claims success if either update is executed, whereas the function requires both to succeed. No claims accurately reflect the specific code semantics, resulting in a low purity of accurate statements.",
                "The summary misrepresents the source code: it describes 'geometry-related update operations' which is unrelated to the MLS category bitmap imports and copies in the code. It also incorrectly states that success is returned if either update is executed, while the function only returns success if both operations succeed, otherwise it cleans up and returns an error. The core purpose of importing MLS category bitmaps from a netlabel attribute into both levels of the context is not covered, and no secondary accurate details are mentioned.",
                "The summary contains a severe inaccuracy about the primary purpose: it misstates the domain as 'geometry-related update operations' instead of importing MLS category bitmaps and copying them, and it wrongly claims success if either update is executed, whereas the code requires both operations to succeed. These are FATAL errors in describing the core behavior and return conditions, making the summary untrustworthy. No accurate, domain-specific details from the source are present."
            ]
        },
        "filter_prorec": {
            "summary": "Checks global initialization and performs two object-related update operations using provided parameters, returning a status code if either succeeds.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains significant inaccuracies: it claims the function returns a status code if either operation succeeds, whereas in the source code it returns 0 if both succeed and an error if either fails. Additionally, the description of 'global initialization' is vague and does not correctly capture the specific check for 'policydb.mls_enabled'. While it mentions two update operations using provided parameters, this is only partly aligned with the actual `ebitmap_netlbl_import` and `ebitmap_cpy` calls. Less than half of the claims are accurate.",
                "The summary fails to capture the core primary purpose of importing MLS category bits from a NetLabel security attribute into a context and duplicating them for both levels. It inaccurately states that a status code is returned if either operation succeeds, whereas the function returns 0 on success and an error code on failure. Key behavior-specific details such as policydb.mls_enabled check, use of ebitmap functions, and cleanup on failure are omitted.",
                "The summary contains a FATAL inaccuracy: it states the function returns a status code if either operation succeeds, whereas the source code logic returns 0 only on full success and an error code on any failure. The description of 'global initialization' is misleading, since the code checks a global mls_enabled flag rather than performing initialization. These errors misrepresent the core purpose and key I/O behavior, making the summary unreliable despite touching on object updates."
            ]
        }
    }
}
{
    "source_code": "\nvoid assert_pipe(struct drm_i915_private *dev_priv,\n\t\t enum pipe pipe, bool state)\n{\n\tint reg;\n\tu32 val;\n\tbool cur_state;\n\tenum transcoder cpu_transcoder = intel_pipe_to_cpu_transcoder(dev_priv,\n\t\t\t\t\t\t\t\t      pipe);\n\n\t/* if we need the pipe A quirk it must be always on */\n\tif (pipe == PIPE_A && dev_priv->quirks & QUIRK_PIPEA_FORCE)\n\t\tstate = true;\n\n\tif (!intel_using_power_well(dev_priv->dev) &&\n\t    cpu_transcoder != TRANSCODER_EDP) {\n\t\tcur_state = false;\n\t} else {\n\t\treg = PIPECONF(cpu_transcoder);\n\t\tval = I915_READ(reg);\n\t\tcur_state = !!(val & PIPECONF_ENABLE);\n\t}\n\n\tWARN(cur_state != state,\n\t     \"pipe %c assertion failure (expected %s, current %s)\\n\",\n\t     pipe_name(pipe), state_string(state), state_string(cur_state));\n}",
    "comment": "Asserts the state of a specified display pipe in the Intel graphics driver, ensuring it matches the expected enablement state.",
    "prorec_sum": "Checks an Intel GPU display pipe\u2019s enabled state and logs an assertion failure if it differs from the expected on/off configuration.",
    "filter_prorec_sum": "Checks an Intel GPU display pipe\u2019s state against expectations and logs an assertion failure with pipe ID and on/off status details.",
    "prorec_aug_sum": "Checks the expected on/off state of a display pipe and logs an assertion failure if the current hardware state does not match.",
    "filter_prorec_aug_sum": "Checks a GPU display pipe\u2019s expected on/off state against hardware status and logs an assertion failure if the states differ.",
    "work_score": {
        "prorec": {
            "summary": "Checks an Intel GPU display pipe\u2019s enabled state and logs an assertion failure if it differs from the expected on/off configuration.",
            "score": [
                1.0,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly captures the core semantics: the function checks the enabled state of an Intel GPU display pipe and logs a warning/assertion if it differs from the expected state. This aligns with the source code, which compares current and expected pipe states and issues a WARN message on mismatch. There are no contradictory or irrelevant claims, and all information is specific to the code behavior.",
                "The summary accurately conveys the core function: verifying whether a specified Intel GPU display pipe is enabled and warning if it does not match the expected state. This matches the source\u2019s core purpose, which is to assert the pipe\u2019s state using hardware registers and log discrepancies. However, it omits secondary details such as the special PIPE_A quirk override, the conditions involving power wells and EDP transcoder, and how the current state is determined via PIPECONF register reads. These omissions reduce coverage of behavior-critical semantics.",
                "The summary correctly captures the core purpose of the function: verifying the enabled state of an Intel GPU display pipe and issuing an assertion failure when it does not match the expected state. This is a specific and accurate representation of the source code's primary function without introducing contradictions or irrelevant noise. While the description is accurate, it is relatively concise and lacks deeper detail about conditional handling such as PIPE_A quirk or power well checks, thus offering only moderate informational gain."
            ]
        },
        "filter_prorec": {
            "summary": "Checks an Intel GPU display pipe\u2019s state against expectations and logs an assertion failure with pipe ID and on/off status details.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly captures the core semantic of the function: it checks the pipe's state against an expected value and logs an assertion failure with identifying details if they differ. This aligns with the code's behavior, including referencing the Intel GPU's display pipe and reporting pipe ID and on/off status. While the summary omits some conditional logic nuances such as quirks and power well checks, it does not introduce inaccuracies, keeping all claims relevant and accurate.",
                "The summary correctly states that the function checks an Intel GPU display pipe\u2019s state against expectations and logs an assertion failure, which matches the core purpose of asserting the pipe state and reporting mismatches. However, it omits important secondary details such as handling the PIPE_A quirk forcing the state to on, the check for power well usage and exclusion of the EDP transcoder, and the specific hardware register read operation. Coverage of secondary behavior-critical semantics is minimal.",
                "The summary accurately captures the core purpose of the function: verifying an Intel GPU display pipe\u2019s state against an expected value and logging an assertion failure with identifying and status details if they differ. There are no contradictory or irrelevant claims, and while the description is correct, it is somewhat generic and lacks specifics about quirks handling, CPU transcoder conditions, and register reads present in the code. The absence of noise or FATAL errors keeps the assessment positive, but limited detail reduces the net benefit."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic int pcmcia_card_add(struct pcmcia_socket *s)\n{\n\tcistpl_longlink_mfc_t mfc;\n\tunsigned int no_funcs, i, no_chains;\n\tint ret = -EAGAIN;\n\n\tmutex_lock(&s->ops_mutex);\n\tif (!(s->resource_setup_done)) {\n\t\tdev_dbg(&s->dev,\n\t\t\t   \"no resources available, delaying card_add\\n\");\n\t\tmutex_unlock(&s->ops_mutex);\n\t\treturn -EAGAIN; /* try again, but later... */\n\t}\n\n\tif (pcmcia_validate_mem(s)) {\n\t\tdev_dbg(&s->dev, \"validating mem resources failed, \"\n\t\t       \"delaying card_add\\n\");\n\t\tmutex_unlock(&s->ops_mutex);\n\t\treturn -EAGAIN; /* try again, but later... */\n\t}\n\tmutex_unlock(&s->ops_mutex);\n\n\tret = pccard_validate_cis(s, &no_chains);\n\tif (ret || !no_chains) {\n\t\tdev_dbg(&s->dev, \"invalid CIS or invalid resources\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (!pccard_read_tuple(s, BIND_FN_ALL, CISTPL_LONGLINK_MFC, &mfc))\n\t\tno_funcs = mfc.nfn;\n\telse\n\t\tno_funcs = 1;\n\ts->functions = no_funcs;\n\n\tfor (i = 0; i < no_funcs; i++)\n\t\tpcmcia_device_add(s, i);\n\n\treturn ret;\n}",
    "comment": "Adds a PCMCIA card to the socket after validating resources and reading its function information from the card's CIS.",
    "prorec_sum": "Initializes and validates a hardware context, retrieves a count value, and iteratively performs device-specific operations for each enumerated unit.",
    "filter_prorec_sum": "Initializes device state, validates readiness, retrieves configuration data, and triggers operations for each configured unit using provided parameters.",
    "prorec_aug_sum": "Configures a device by validating state, reading parameters, and issuing initialization commands for each detected channel or endpoint.",
    "filter_prorec_aug_sum": "Configures and initiates device operations based on retrieved parameters, performing repeated command dispatches for each available unit and returning status codes on failure or completion.",
    "work_score": {
        "prorec": {
            "summary": "Initializes and validates a hardware context, retrieves a count value, and iteratively performs device-specific operations for each enumerated unit.",
            "score": [
                0.6,
                0.4,
                0.4
            ],
            "reason": [
                "The summary correctly captures some aspects of the function, such as initialization/validation steps and performing operations for multiple units, but omits critical details like specific conditions for delaying the operation, error handling via return codes, and CIS/resource validation logic. It also generically describes retrieving a count without noting how it is determined from either the multi-function tuple or defaulting to one. Given that over half but not all claims align with the source code, the precision is moderate.",
                "The summary provides a generic idea of initialization, validation, and iteration over devices, which loosely covers the loop adding each PCMCIA device. However, it fails to mention the specific core purpose of adding PCMCIA cards to a socket, the particular validations performed (resource setup, memory validation, CIS validation), and the specific error handling with retry logic. The description lacks concrete domain terms and omits critical branching and side-effect details from the source code, making coverage of core and secondary semantics weak.",
                "The summary is mostly generic and omits critical domain-specific details from the source code. While it correctly reflects a general initialization, validation, retrieval of a count, and iteration over devices (SAFE claims), it fails to mention the function\u2019s context-specific behavior such as mutex locking, handling resource setup failure, specific return codes (-EAGAIN, -ENODEV), CIS validation, and reading CISTPL_LONGLINK_MFC tuples. No factually incorrect (FATAL) claims are present, but the lack of specificity results in low informational value, with noise in the form of vague phrasing outweighing precise gains."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes device state, validates readiness, retrieves configuration data, and triggers operations for each configured unit using provided parameters.",
            "score": [
                0.9,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly captures general steps such as initialization, validation, retrieving configuration, and performing operations, which align with the code\u2019s behavior of locking resources, performing memory checks, validating CIS, determining function count, and adding devices. However, the claims are generic and omit key specifics like handling EAGAIN/ENODEV, the exact validation calls, and the function-specific loop. All claims are broadly accurate but low in detail, making them SAFE rather than GOLD, with no inaccurate statements.",
                "The summary accurately notes initialization, readiness validation, configuration retrieval, and iterative operations, which reflect the function\u2019s locking and validation steps, CIS reading, and looping over functions. However, it fails to explicitly cover the core domain purpose of adding a PCMCIA card to a socket, missing specific domain terminology and references to handling delayed addition via error codes. Secondary behaviors like branching on mfc tuple presence and different error returns are not mentioned, leading to incomplete coverage.",
                "The summary contains mostly generic SAFE claims such as initializing state, validating readiness, and triggering operations, which broadly align with the source but lack specificity about key checks (like resource_setup_done, pcmcia_validate_mem failures, CIS validation, and MFC tuple reading). There are no FATAL inaccuracies, but the description omits critical details about error handling paths and specific functions invoked, resulting in low informational gain. Noise is moderate, with the content being accurate but overly broad."
            ]
        }
    }
}
{
    "source_code": "\nint cms_SignedData_final(CMS_ContentInfo *cms, BIO *chain)\n\t{\n\tSTACK_OF(CMS_SignerInfo) *sinfos;\n\tCMS_SignerInfo *si;\n\tint i;\n\tsinfos = CMS_get0_SignerInfos(cms);\n\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t{\n\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\tif (!cms_SignerInfo_content_sign(cms, si, chain))\n\t\t\treturn 0;\n\t\t}\n\tcms->d.signedData->encapContentInfo->partial = 0;\n\treturn 1;\n\t}",
    "comment": "Finalizes the signing process for all signer information in the CMS_ContentInfo structure by signing the content and marking it as complete.",
    "prorec_sum": "Finalizes signing for each CMS signer by completing digests, adding required signed attributes, generating signatures, and storing them in the signer information structures.",
    "filter_prorec_sum": "Finalizes CMS SignedData by processing each signer\u2019s digest context, adding required signed attributes, generating signatures, and storing them in the structure.",
    "prorec_aug_sum": "Generates and finalizes CMS signed-data signatures by processing each signer\u2019s digest, adding required attributes, and creating the final signature output.",
    "filter_prorec_aug_sum": "Finalizes CMS SignedData by computing digests or signatures for each signer and updating corresponding attributes, handling errors and freeing resources.",
    "work_score": {
        "prorec": {
            "summary": "Finalizes signing for each CMS signer by completing digests, adding required signed attributes, generating signatures, and storing them in the signer information structures.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary describes specific behaviors such as completing digests, adding signed attributes, and storing signatures, but these actions are not evidenced in the provided source code. The code iterates over signers and calls a function to sign content, then marks the content as complete, without clear logic for digest completion or attribute handling. Most claims do not directly match the code\u2019s semantics, resulting in a low proportion of accurate statements.",
                "The summary claims specific cryptographic actions like completing digests, adding signed attributes, and storing signatures, but the source code only calls a function to sign content and marks the partial flag as false without explicitly performing those detailed steps. While it correctly notes signing for each signer, it overstates unverified internal actions, failing to accurately cover the core primary purpose in a verifiable way.",
                "The summary claims that the function completes digests, adds signed attributes, generates signatures, and stores them in signer information structures. The source code shows it iterates over signer infos, calls a signing helper, and marks the content as complete, but there is no explicit evidence of digest computation or attribute addition in the shown logic; these details are inferred and not verifiable here, making them inaccurate. The inaccuracies target the primary purpose by misstating specific steps, which qualifies as a FATAL error. There are no clearly accurate, detailed claims beyond the general notion of finalizing signing, so net benefit is very low."
            ]
        },
        "filter_prorec": {
            "summary": "Finalizes CMS SignedData by processing each signer\u2019s digest context, adding required signed attributes, generating signatures, and storing them in the structure.",
            "score": [
                0.5,
                0.5,
                0.2
            ],
            "reason": [
                "The summary claims that the function processes each signer\u2019s digest context, adds signed attributes, generates signatures, and stores them, which is only partially supported by the code. The code iterates through signers and calls `cms_SignerInfo_content_sign`, but the specific details about digest contexts, adding attributes, and storing signatures are not directly verifiable from the source. Thus, only a portion of the claims accurately match the observed domain behavior; several details are speculative.",
                "The summary accurately conveys that the function finalizes a CMS SignedData by iterating through signers and generating signatures, which covers the core purpose of signing each CMS_SignerInfo and marking the content as complete. However, it adds extra details like processing digest contexts and adding signed attributes that are not explicitly evident in the source code, reducing alignment. It also omits explicit mention of the 'partial' flag being cleared, which is a key secondary semantic.",
                "The summary claims that the function processes each signer's digest context, adds signed attributes, generates signatures, and stores them, which is not directly verifiable from the provided source code. The code iterates over signer infos and calls another function to perform signing, sets a 'partial' flag to 0, and returns a success indicator; detailed actions like digest processing or attribute handling are not evident. These are semantic claims about the primary purpose and core I/O that contradict what is explicitly visible, making them fatal inaccuracies."
            ]
        }
    }
}
{
    "source_code": "static void tcp_set_skb_tso_segs(const struct sock *sk, struct sk_buff *skb,\n\t\t\t\t unsigned int mss_now)\n{\n\tif (skb->len <= mss_now || !sk_can_gso(sk) ||\n\t    skb->ip_summed == CHECKSUM_NONE) {\n\t\t/* Avoid the costly divide in the normal\n\t\t * non-TSO case.\n\t\t */\n\t\tskb_shinfo(skb)->gso_segs = 1;\n\t\tskb_shinfo(skb)->gso_size = 0;\n\t\tskb_shinfo(skb)->gso_type = 0;\n\t} else {\n\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss_now);\n\t\tskb_shinfo(skb)->gso_size = mss_now;\n\t\tskb_shinfo(skb)->gso_type = sk->sk_gso_type;\n\t}\n}",
    "comment": "Sets the TCP segmentation offload parameters for a socket buffer based on its length and the maximum segment size.",
    "prorec_sum": "Configures TCP segment header fields based on connection state and packet size, logging anomalies once, before finalizing length and identifier values.",
    "filter_prorec_sum": "Calculates and updates TCP output segment header fields based on connection state, segment size, and flags, with a one-time debug log on anomaly.",
    "prorec_aug_sum": "Updates TCP output header fields based on segment and connection state, logging anomalies once, to prepare acknowledgment or segment size information.",
    "filter_prorec_aug_sum": "Calculates and writes TCP segment count, size, and sequence fields into the packet buffer header based on connection state and provided parameters.",
    "work_score": {
        "prorec": {
            "summary": "Configures TCP segment header fields based on connection state and packet size, logging anomalies once, before finalizing length and identifier values.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains claims about configuring TCP segment header fields, logging anomalies, and finalizing identifier values, none of which are evident in the source code. The function adjusts GSO fields based on MSS and conditions but does not involve header manipulation, anomaly logging, or identifier finalization. All claims are inaccurate regarding code semantics, resulting in zero alignment with the evaluation steps.",
                "The summary inaccurately describes the function as configuring TCP segment header fields and logging anomalies, which are not present in the source code. The actual core action is setting gso_segs, gso_size, and gso_type for a TCP skb based on MSS, length, and checksum state, avoiding division when not using TSO. No [ACCURATE] claims in the summary capture this core purpose, and secondary details are largely incorrect or irrelevant.",
                "The summary contains multiple inaccurate claims: it mentions configuring TCP segment header fields and logging anomalies, which are not present in the source code. The actual function sets GSO segmentation values based on MSS, packet length, checksum state, and GSO capability. There is no logging, anomaly detection, or setting of header identifier values. These are FATAL inaccuracies about the primary purpose, making the description misleading and untrustworthy."
            ]
        },
        "filter_prorec": {
            "summary": "Calculates and updates TCP output segment header fields based on connection state, segment size, and flags, with a one-time debug log on anomaly.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function logs anomalies, but the source code shows no logging; this is a clear inaccuracy. While it correctly mentions calculating and updating TCP segment-related fields based on segment size and connection state, this is generic and only partially reflects the actual code logic. Overall, less than half of the claims are accurate, with the logging detail being completely unsupported.",
                "The summary claims inclusion of a one-time debug log on anomaly, which is not present in the source code, making it inaccurate. It vaguely references calculating TCP output segment header fields but does not explicitly cover the core purpose of setting skb_shinfo gso parameters based on MSS and conditions like sk_can_gso or CHECKSUM_NONE. Although it touches lightly on segment size and connection state, the description is too generic and misses key branch behaviors and specific field updates, resulting in poor alignment.",
                "The summary contains one accurate low-info claim about updating fields based on connection state and segment size, reflecting the function\u2019s behavior of setting gso_segs, gso_size, and gso_type. However, it inaccurately introduces a one-time debug log on anomaly, which is not present in the source code, making this a FATAL error regarding side effects. This false side effect substantially misrepresents the function\u2019s output behavior, resulting in severe mistrust despite some correct generic points."
            ]
        }
    }
}
{
    "source_code": "\nSEXP attribute_hidden do_dynunload(SEXP call, SEXP op, SEXP args, SEXP env)\n{\n    char buf[2 * PATH_MAX];\n\n    checkArity(op,args);\n    if (!isString(CAR(args)) || LENGTH(CAR(args)) != 1)\n\terror(_(\"character argument expected\"));\n    GetFullDLLPath(call, buf, translateChar(STRING_ELT(CAR(args), 0)));\n    if(!DeleteDLL(buf))\n\terror(_(\"shared object '%s\\' was not loaded\"), buf);\n    return R_NilValue;\n}",
    "comment": "Unloads a shared object from memory by verifying the argument and deleting its associated DLL using the full path derived from the input.",
    "prorec_sum": "Validates a single character argument specifying a shared object name, loads it, and raises an error if the object is not found.",
    "filter_prorec_sum": "Validates a single string argument and reports an error if the specified shared object was not successfully loaded.",
    "prorec_aug_sum": "Loads a shared object by name from a character argument, invoking an internal loader and erroring if the object is not loaded.",
    "filter_prorec_aug_sum": "Validates a single string argument, translates it, and reports an error if the corresponding shared object is not loaded.",
    "work_score": {
        "prorec": {
            "summary": "Validates a single character argument specifying a shared object name, loads it, and raises an error if the object is not found.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains an inaccurate claim by stating the function 'loads' the shared object, whereas the source code clearly performs an unload operation (`DeleteDLL`). While it correctly notes the single character argument and error handling if the object is not found, the primary action described is wrong, which makes the majority of claims unreliable.",
                "The summary incorrectly describes the function as loading a shared object, while the source code's core purpose is to unload (delete) a dynamically loaded shared object. This is a direct contradiction of the primary domain operation. While it notes argument validation and error handling, the misstatement of core functionality means the primary purpose is not covered and core semantics are inaccurate.",
                "The summary incorrectly states that the function loads a shared object, whereas the source code performs unloading via DeleteDLL, making this a severe factual error about the primary purpose. The validation of a single-character argument and error when the object is not found are partially accurate, but the core action misdescription is a FATAL error, heavily undermining trust."
            ]
        },
        "filter_prorec": {
            "summary": "Validates a single string argument and reports an error if the specified shared object was not successfully loaded.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function validates a single string argument, which matches the check for a string of length 1. However, it inaccurately claims the error is triggered when the shared object was not successfully loaded; in the source code, the error occurs when deletion fails, indicating the object was not loaded. This is a semantic contradiction, making only part of the summary accurate and reducing overall claim precision below 50%.",
                "The summary inaccurately states that the function reports an error if the shared object was not successfully loaded, whereas the source code reports an error if the specified shared object was not loaded when attempting to unload it. The core purpose\u2014unloading a DLL/shared object by validating the argument, resolving its full path, and invoking DeleteDLL\u2014is entirely missing. Although the argument validation is mentioned, it omits path resolution and the actual unloading action, and misrepresents the error condition.",
                "The summary correctly notes that the function validates a single string argument, which matches the code\u2019s type and length check. However, it inaccurately states that an error is reported if the shared object was not successfully loaded, whereas the code reports an error when the object is not loaded for deletion, meaning it could not be found or unloaded. This is a FATAL in describing the primary purpose, as it misrepresents the core action related to DLL unloading."
            ]
        }
    }
}
{
    "source_code": "int audit_alloc(struct task_struct *tsk)\n{\n\tstruct audit_context *context;\n\tenum audit_state     state;\n\tchar *key = NULL;\n\n\tif (likely(!audit_ever_enabled))\n\t\treturn 0; /* Return if not auditing. */\n\n\tstate = audit_filter_task(tsk, &key);\n\tif (state == AUDIT_DISABLED)\n\t\treturn 0;\n\n\tif (!(context = audit_alloc_context(state))) {\n\t\tkfree(key);\n\t\taudit_log_lost(\"out of memory in audit_alloc\");\n\t\treturn -ENOMEM;\n\t}\n\tcontext->filterkey = key;\n\n\ttsk->audit_context  = context;\n\tset_tsk_thread_flag(tsk, TIF_SYSCALL_AUDIT);\n\treturn 0;\n}",
    "comment": "Allocates an audit context for a given task if auditing is enabled and filters the task based on its audit state.",
    "prorec_sum": "Allocates and initializes an audit data structure for the given object, setting type-specific fields and marking it with an audit flag.",
    "filter_prorec_sum": "Allocates and initializes an audit data structure for the given object, linking it to global lists and handling out-of-memory errors.",
    "prorec_aug_sum": "Allocates and initializes an audit data structure for the given task, linking it to global lists and marking the task with an audit flag.",
    "filter_prorec_aug_sum": "Allocates and initializes an audit record for the given context, linking it to global structures and handling memory exhaustion errors.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes an audit data structure for the given object, setting type-specific fields and marking it with an audit flag.",
            "score": [
                0.6,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly notes that the function allocates and initializes an audit structure and sets an audit flag, which matches the code\u2019s behavior of allocating an audit_context, assigning it to the task, and setting TIF_SYSCALL_AUDIT. However, it omits important condition checks before allocation, such as returning immediately if auditing is disabled and handling out-of-memory cases, and it generalizes 'object' instead of specifying a task_struct. While the existing claims are broadly accurate, they lack specificity and miss key details, resulting in moderate alignment.",
                "The summary correctly notes that an audit structure is allocated and initialized, and that an audit flag is set, which aligns with the function's allocation of `audit_context` and use of `set_tsk_thread_flag`. However, it fails to capture the core purpose with sufficient specificity \u2014 namely allocating and attaching an audit context to a `task_struct` when auditing is enabled and the task passes filtering. It omits key behaviors such as early return when auditing is disabled, filtering via `audit_filter_task`, handling out-of-memory with logging and freeing, and setting the filter key. These omissions mean the core is only vaguely addressed and most critical secondary details are missing.",
                "The summary captures the core purpose\u2014allocation and initialization of an audit-related structure and setting an audit flag\u2014so it is generally accurate regarding the primary behavior. However, it omits important details from the code such as the conditional early returns when auditing is disabled, handling of allocation failure, and association of a filter key from task filtering. The claims are somewhat generic and low-info, lacking specifics about control flow and error handling, which limits the usefulness for an engineer. There is no fatal inaccuracy, but gain is low due to missing precision."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes an audit data structure for the given object, linking it to global lists and handling out-of-memory errors.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function links the audit data structure to global lists, which is unsupported by the source code. The source only allocates an audit_context, assigns it to the task_struct, sets a thread flag, and handles out-of-memory errors. While the allocation and error handling parts are accurate, the initialization description is partially generic and misrepresents the actual behavior by adding the global list linkage. With less than half of the claims being accurate, precision is low.",
                "The summary claims that the function links the audit data structure to global lists, which is inaccurate, as the code only assigns the context to the task and sets a thread flag. It also fails to cover the core purpose with sufficient specificity: determining audit state for a task, allocating context accordingly, and associating it with the task. While it mentions handling out-of-memory errors, it omits key secondary behaviors such as returning early when auditing is disabled and applying filters to tasks.",
                "The summary contains a major inaccuracy: it states that the function links the audit data structure to global lists, which is not present in the source code. This is a FATAL error because it misrepresents the core behavior by adding nonexistent side effects. While it correctly notes allocation and handling out-of-memory, these are generic and low-info, and the core purpose is distorted by the inaccurate claim."
            ]
        }
    }
}
{
    "source_code": "int Xorriso_register_matched_adr(struct XorrisO *xorriso,\n                                char *adr, int count_limit,\n                                int *filec, char **filev, off_t *mem, int flag)\n{\n int l;\n\n if(flag&1) {\n   (*filec)++;\n   l= strlen(adr)+1;\n   (*mem)+= sizeof(char *)+l;\n   if(l % sizeof(char *))\n     (*mem)+= sizeof(char *)-(l % sizeof(char *));\n } else {\n   if(*filec >= count_limit) {\n     sprintf(xorriso->info_text,\n         \"Number of matching files changed unexpectedly (> %d)\",\n         count_limit);\n     Xorriso_msgs_submit(xorriso, 0, xorriso->info_text, 0,\n                         (flag&2 ? \"FATAL\" : \"WARNING\"), 0);\n     return(flag&2 ? -1 : 0);\n   }\n   filev[*filec]= strdup(adr);\n   if(filev[*filec]==NULL) {\n     Xorriso_no_pattern_memory(xorriso, (off_t) (strlen(adr)+1), 0);\n     return(-1);\n   }\n   (*filec)++;\n }\n return(1);\n}",
    "comment": "Registers a matched address by updating file count, allocating memory for the address, and handling errors based on a specified flag.",
    "prorec_sum": "Adds a file path to a list, updates counters and memory alignment, and logs a warning or fatal error if expected count is exceeded.",
    "filter_prorec_sum": "Adds a matching filename to a list, updating counters and alignment, or logs a warning/fatal if the match count exceeds the expected limit.",
    "prorec_aug_sum": "Handles adding a matching filename to a list, updating counters and buffers, and issuing warnings or fatal errors if count limits are exceeded.",
    "filter_prorec_aug_sum": "Adds a matching file name to a list, updating counters and buffers, and logs warnings or fatal errors if count limits are exceeded.",
    "work_score": {
        "prorec": {
            "summary": "Adds a file path to a list, updates counters and memory alignment, and logs a warning or fatal error if expected count is exceeded.",
            "score": [
                0.9,
                0.8,
                0.9
            ],
            "reason": [
                "The summary captures the core behavior of the function accurately. It notes that the function adds a file path to a list, updates counters, and adjusts memory alignment \u2014 all present in the branch when flag&1 is set or when adding to filev. It also correctly states that a warning or fatal error is logged if the count exceeds the limit, matching the else branch's handling via Xorriso_msgs_submit. The only minor omission is the conditional nature of the operations based on the flag parameter, but since the description still aligns with the main semantics, accuracy is very high.",
                "The summary accurately mentions adding a file path to a list, updating counters and memory alignment, and logging warnings or fatal errors when count limits are exceeded, which aligns with the source code\u2019s core purpose and key behaviors. It covers the core operation of appending to the list with limit checking and captures relevant error handling and side effect details, though it omits specifics about handling memory allocation failure and the conditional behavior when the flag bit is set.",
                "The summary accurately captures the core behavior: it adds a file path to a list, increments counters, adjusts memory alignment when appropriate, and logs either a warning or fatal error when the count exceeds the limit. These are specific and directly supported by the source code, with no contradictory or irrelevant claims. The coverage of primary purpose, memory adjustments, and error handling is concise and fully correct, yielding high informational value with negligible noise."
            ]
        },
        "filter_prorec": {
            "summary": "Adds a matching filename to a list, updating counters and alignment, or logs a warning/fatal if the match count exceeds the expected limit.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly states that the function adds a matching filename to a list and updates counters and alignment, reflecting the branch where `flag & 1` modifies `filec` and `mem`. It also accurately captures that a warning or fatal log occurs when the match count exceeds the limit, matching the `*filec >= count_limit` branch. These are precise domain-specific behaviors present in the source code, and no claims contradict the implementation.",
                "The summary accurately describes adding a matching filename to a list, updating counters and alignment, and logging warnings or fatal errors when the match count exceeds the limit, which matches the core purpose and key branches in the source code. However, it omits certain secondary behaviors such as memory allocation via strdup, handling NULL allocation with Xorriso_no_pattern_memory, and the specific differentiation of behavior when flag bit 1 is set. These omissions moderately reduce completeness.",
                "The summary correctly states that the function adds a matching filename to a list and updates counters and alignment when flag&1 is set, and that it logs a warning or fatal if the match count exceeds the count_limit. These are accurate, specific descriptions of the function\u2019s core purpose and branching behavior, with no contradictory or irrelevant claims. While brief, the claims are GOLD-level as they capture the core domain action and side effect without noise."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\ngmbus_xfer_read(struct drm_i915_private *dev_priv, struct i2c_msg *msg,\n\t\tu32 gmbus1_index)\n{\n\tint reg_offset = dev_priv->gpio_mmio_base;\n\tu16 len = msg->len;\n\tu8 *buf = msg->buf;\n\n\tI915_WRITE(GMBUS1 + reg_offset,\n\t\t   gmbus1_index |\n\t\t   GMBUS_CYCLE_WAIT |\n\t\t   (len << GMBUS_BYTE_COUNT_SHIFT) |\n\t\t   (msg->addr << GMBUS_SLAVE_ADDR_SHIFT) |\n\t\t   GMBUS_SLAVE_READ | GMBUS_SW_RDY);\n\twhile (len) {\n\t\tint ret;\n\t\tu32 val, loop = 0;\n\n\t\tret = gmbus_wait_hw_status(dev_priv, GMBUS_HW_RDY,\n\t\t\t\t\t   GMBUS_HW_RDY_EN);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tval = I915_READ(GMBUS3 + reg_offset);\n\t\tdo {\n\t\t\t*buf++ = val & 0xff;\n\t\t\tval >>= 8;\n\t\t} while (--len && ++loop < 4);\n\t}\n\n\treturn 0;\n}",
    "comment": "Reads data from a GMBUS device into a buffer, handling timing and status checks during the transfer process.",
    "prorec_sum": "Transfers data blocks from a buffer to hardware registers in 256-byte chunks, invoking helper routines for writing and reading until all bytes are processed.",
    "filter_prorec_sum": "Transfers data blocks from a buffer to hardware registers in chunks, issuing commands and writing bytes with periodic status checks until complete.",
    "prorec_aug_sum": "Transfers data blocks from a buffer to hardware registers in fixed-size chunks, invoking lower-level routines to send and retrieve byte values.",
    "filter_prorec_aug_sum": "Transfers chunks of up to 256 bytes from a buffer to hardware registers, invoking helper calls for data output and synchronization until completion.",
    "work_score": {
        "prorec": {
            "summary": "Transfers data blocks from a buffer to hardware registers in 256-byte chunks, invoking helper routines for writing and reading until all bytes are processed.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as transferring data from a buffer to hardware registers in 256-byte chunks, implying a write operation, while the source code implements a read transfer from hardware into a buffer via gmbus. It also specifies a chunk size of 256 bytes, which is not present in the code; the actual loop reads up to 4 bytes at a time. Additionally, claiming both writing and reading is inaccurate since only read operations occur. These contradictions mean that most claims are inaccurate, with little alignment to the actual semantics.",
                "The summary incorrectly describes transferring data from a buffer to hardware registers in 256-byte chunks, while the source code actually performs an I2C read via GMBUS from hardware registers into a buffer, processing up to 4 bytes at a time. The core domain action of initiating a GMBUS read transaction and filling the provided buffer is missing, and the direction of data flow is inverted. No accurate claims match the core purpose, hence no coverage of secondary behaviors like hardware-ready wait loops or byte shifting.",
                "The summary claims the function transfers data from a buffer to hardware registers in 256-byte chunks and uses helper routines for writing and reading until completion. In reality, the code reads data from hardware registers into a buffer via I2C over GMBUS, processing up to 4 bytes per loop iteration, not 256-byte chunks, and does not perform any writes. These are severe inaccuracies directly about the primary purpose and core I/O behavior, making the description untrustworthy."
            ]
        },
        "filter_prorec": {
            "summary": "Transfers data blocks from a buffer to hardware registers in chunks, issuing commands and writing bytes with periodic status checks until complete.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function transfers data from a buffer to hardware in chunks, issuing commands and writing bytes with periodic status checks. In reality, the code reads data from hardware registers (GMBUS3) into a buffer while checking status via gmbus_wait_hw_status. The direction of data transfer is reversed in the summary, making the primary claim inaccurate. Minor elements like status checks are correct, but most of the core functional description contradicts the source, resulting in low accuracy.",
                "The summary incorrectly describes the direction of transfer: the code reads data from hardware registers into a buffer, not from a buffer to hardware. This makes the core domain action misrepresented and the primary purpose (reading I2C data via GMBUS in chunks with status checks) absent. While it mentions chunks and status checks, these secondary points cannot compensate for the inaccurate core description.",
                "The summary incorrectly states that data is transferred from a buffer to hardware registers, whereas the code reads data from hardware registers into a buffer via the GMBUS interface. This is a FATAL error affecting the primary purpose, as it reverses the core I/O direction. While the mention of periodic status checks is accurate, the fundamental misrepresentation of the primary action makes the summary untrustworthy."
            ]
        }
    }
}
{
    "source_code": "static void purge_old_ps_buffers(struct ieee80211_local *local)\n{\n\tint total = 0, purged = 0;\n\tstruct sk_buff *skb;\n\tstruct ieee80211_sub_if_data *sdata;\n\tstruct sta_info *sta;\n\n\tlist_for_each_entry_rcu(sdata, &local->interfaces, list) {\n\t\tstruct ps_data *ps;\n\n\t\tif (sdata->vif.type == NL80211_IFTYPE_AP)\n\t\t\tps = &sdata->u.ap.ps;\n\t\telse if (ieee80211_vif_is_mesh(&sdata->vif))\n\t\t\tps = &sdata->u.mesh.ps;\n\t\telse\n\t\t\tcontinue;\n\n\t\tskb = skb_dequeue(&ps->bc_buf);\n\t\tif (skb) {\n\t\t\tpurged++;\n\t\t\tdev_kfree_skb(skb);\n\t\t}\n\t\ttotal += skb_queue_len(&ps->bc_buf);\n\t}\n\n\t/*\n\t * Drop one frame from each station from the lowest-priority\n\t * AC that has frames at all.\n\t */\n\tlist_for_each_entry_rcu(sta, &local->sta_list, list) {\n\t\tint ac;\n\n\t\tfor (ac = IEEE80211_AC_BK; ac >= IEEE80211_AC_VO; ac--) {\n\t\t\tskb = skb_dequeue(&sta->ps_tx_buf[ac]);\n\t\t\ttotal += skb_queue_len(&sta->ps_tx_buf[ac]);\n\t\t\tif (skb) {\n\t\t\t\tpurged++;\n\t\t\t\tieee80211_free_txskb(&local->hw, skb);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tlocal->total_ps_buffered = total;\n\tps_dbg_hw(&local->hw, \"PS buffers full - purged %d frames\\n\", purged);\n}",
    "comment": "Purges old Power Save buffers from access points and stations, freeing memory and updating the total buffered frame count.",
    "prorec_sum": "Traverses two linked lists, processes selected entries with a helper routine, accumulates their counters, and stores the total into the object's data field.",
    "filter_prorec_sum": "Traverses two linked lists of objects, processes those with valid data using a helper routine, sums specific integer fields, and stores the accumulated total.",
    "prorec_aug_sum": "Aggregates specific node values from two linked lists, processes matching entries, and updates a total count field in the given data structure.",
    "filter_prorec_aug_sum": "Aggregates specific node metrics from two linked lists, processes matching entries, and stores the total count into the parent structure\u2019s field.",
    "work_score": {
        "prorec": {
            "summary": "Traverses two linked lists, processes selected entries with a helper routine, accumulates their counters, and stores the total into the object's data field.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary makes generic claims about traversing two linked lists, processing entries with a helper routine, accumulating counters, and storing the total, which are mostly accurate: the function does iterate through two RCU lists and updates counters before assigning to a field. However, it omits key specifics such as conditional selection based on interface type, the purging of specific buffers, and the exact nature of the helper functions used (skb_free functions), making the description overly vague. Most claims align broadly with the source code but lack precision, resulting in mixed reliability.",
                "The summary describes traversing two linked lists, processing entries, and accumulating counters, which is partially accurate to the code's structure. However, it fails to convey the core purpose of purging old power-save buffers for AP and mesh interfaces and dropping one frame per station from the lowest-priority AC, including freeing SKBs. No mention is made of the specific buffer types, conditions, or deallocation side effects, resulting in missing critical domain semantics.",
                "The summary generically describes traversing linked lists, processing entries, and updating a counter, which loosely aligns with the code\u2019s iteration over interfaces and stations, freeing buffers, and tracking totals. However, it omits critical specifics such as the selection criteria (AP or mesh interfaces, lowest-priority AC), the freeing of specific buffer types, and the purpose of the helper routines (dev_kfree_skb, ieee80211_free_txskb). No FATAL inaccuracies are present, but the claims are overly generic and lack domain-specific detail, resulting in low informational gain with some noise."
            ]
        },
        "filter_prorec": {
            "summary": "Traverses two linked lists of objects, processes those with valid data using a helper routine, sums specific integer fields, and stores the accumulated total.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims traversal of two linked lists, processing objects with valid data via a helper, and summing integer fields. While traversal of two linked lists is accurate, the summary fails to specify the actual purging of buffers and freeing of SKBs seen in the code, mislabels the processing as using a generic helper routine, and incorrectly abstracts the integer summation as \"specific integer fields\" instead of queue lengths. Only part of the description aligns with source semantics, so the accuracy proportion is low.",
                "The summary omits the core purpose of purging old power-save buffers for AP or mesh interfaces and stations; it generically describes traversing lists and processing with a helper, which doesn't capture the specific domain action. While it notes summing integers and storing a total, it lacks any mention of dequeuing frames, freeing SKBs, or handling different interface types and access categories, thus missing key secondary behaviors such as conditional branching and hardware debug output.",
                "The summary is mostly inaccurate: it does not capture the core purpose of the function, which is to purge one or more frames from buffered power-save queues for AP and mesh interfaces and stations, and update totals. It generically refers to 'linked lists of objects' and 'processing those with valid data using a helper routine', which is vague and omits critical behaviors like conditional purging, queue length counting, and updating local->total_ps_buffered. This is a FATAL miss concerning the primary purpose and core I/O, with no specific GOLD-level accuracy present, making it untrustworthy."
            ]
        }
    }
}
{
    "source_code": "\nstatic void mroute_netlink_event(struct mr_table *mrt, struct mfc_cache *mfc,\n\t\t\t\t int cmd)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct sk_buff *skb;\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(mroute_msgsize(mfc->mfc_parent >= MAXVIFS, mrt->maxvif),\n\t\t\tGFP_ATOMIC);\n\tif (skb == NULL)\n\t\tgoto errout;\n\n\terr = ipmr_fill_mroute(mrt, skb, 0, 0, mfc, cmd);\n\tif (err < 0)\n\t\tgoto errout;\n\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV4_MROUTE, NULL, GFP_ATOMIC);\n\treturn;\n\nerrout:\n\tkfree_skb(skb);\n\tif (err < 0)\n\t\trtnl_set_sk_err(net, RTNLGRP_IPV4_MROUTE, err);\n}",
    "comment": "Notifies the kernel about multicast route changes by creating and sending a netlink message based on the provided mfc_cache and command.",
    "prorec_sum": "Allocates and initializes a routing-related structure with provided parameters, handles errors by freeing resources, and reports status to the networking subsystem.",
    "filter_prorec_sum": "Allocates and initializes a network-related structure with provided parameters, handles errors by freeing resources, and reports status through a specified context.",
    "prorec_aug_sum": "Allocates and initializes a data structure with provided parameters, processes it, and handles cleanup and error reporting based on the operation\u2019s result.",
    "filter_prorec_aug_sum": "Allocates and initializes a data structure with provided parameters, invokes a setup routine, handles errors by cleanup, and signals the result to a managing context.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a routing-related structure with provided parameters, handles errors by freeing resources, and reports status to the networking subsystem.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims allocation and initialization of a routing-related structure, which is inaccurate because the function allocates a netlink message buffer, not a routing structure. It correctly notes error handling via resource freeing and status reporting to the networking subsystem, which matches the code behavior. However, the incorrect core description of the allocation target makes less than half of the claims accurate.",
                "The summary generically describes allocating and initializing a routing-related structure and handling errors, but it fails to capture the core purpose of sending a netlink multicast routing event via rtnl_notify. While 'allocates... handles errors' is factually accurate, it is too vague, missing the specific domain action and parameters related to multicast routing and netlink messaging, thus the core is not covered and secondary details are sparse.",
                "The summary incorrectly claims the function allocates and initializes a routing-related structure, while the code actually allocates a netlink message buffer and fills it with multicast route information; this is a FATAL error on the primary purpose. Error handling by freeing resources and reporting status is accurately described, but the core functional description is wrong, resulting in very low net benefit."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a network-related structure with provided parameters, handles errors by freeing resources, and reports status through a specified context.",
            "score": [
                0.2,
                0.3,
                0.4
            ],
            "reason": [
                "The summary is mostly inaccurate: it describes allocating and initializing a generic 'network-related structure', which does not match the source code\u2019s specific behavior of allocating a netlink message via nlmsg_new and filling it with multicast route data. It omits critical details (use of mfc and mrt, rtnl_notify to notify) and makes vague statements that don't target specific code semantics. Only the error handling part (freeing resources and reporting status) is accurate. Less than half of the claims directly and correctly reflect the source code.",
                "The summary makes generic claims about allocating a network-related structure, error handling, and reporting status, which are broadly accurate but lack the specific core purpose of sending multicast routing events over netlink with detailed message construction. It does not mention netlink message size computation, filling the message via ipmr_fill_mroute, or notifying via rtnl_notify. Secondary semantics like freeing skb and setting socket errors are lightly covered but without precision.",
                "The summary\u2019s claims are mostly generic and partially inaccurate. It correctly notes resource allocation and error handling, but misstates the primary purpose: the function specifically creates and fills a netlink message for multicast routing events, not just a generic 'network-related structure'. There is no mention of message filling or notification via rtnl_notify, which is core to its semantics. This omission and vague wording make the description low-info and introduce NOISE that outweighs the accurate parts. No severe FATAL errors on key I/O, but the net benefit is low."
            ]
        }
    }
}
{
    "source_code": "\nvoid inet_twdr_twkill_work(struct work_struct *work)\n{\n\tstruct inet_timewait_death_row *twdr =\n\t\tcontainer_of(work, struct inet_timewait_death_row, twkill_work);\n\tint i;\n\n\tBUILD_BUG_ON((INET_TWDR_TWKILL_SLOTS - 1) >\n\t\t\t(sizeof(twdr->thread_slots) * 8));\n\n\twhile (twdr->thread_slots) {\n\t\tspin_lock_bh(&twdr->death_lock);\n\t\tfor (i = 0; i < INET_TWDR_TWKILL_SLOTS; i++) {\n\t\t\tif (!(twdr->thread_slots & (1 << i)))\n\t\t\t\tcontinue;\n\n\t\t\twhile (inet_twdr_do_twkill_work(twdr, i) != 0) {\n\t\t\t\tif (need_resched()) {\n\t\t\t\t\tspin_unlock_bh(&twdr->death_lock);\n\t\t\t\t\tschedule();\n\t\t\t\t\tspin_lock_bh(&twdr->death_lock);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ttwdr->thread_slots &= ~(1 << i);\n\t\t}\n\t\tspin_unlock_bh(&twdr->death_lock);\n\t}\n}",
    "comment": "Processes and removes active threads from the timewait death row while managing concurrency using spin locks and checking for rescheduling needs.",
    "prorec_sum": "Processes and clears active bit flags by invoking associated handlers until no flags remain, repeatedly performing conditional operations based on status bits.",
    "filter_prorec_sum": "Processes pending flags for up to eight channels, invoking handlers until conditions clear, then updates the flag mask and repeats until all are serviced.",
    "prorec_aug_sum": "Processes up to eight flagged work items, repeatedly invoking handlers until completion, clearing processed flags, and looping until no pending tasks remain.",
    "filter_prorec_aug_sum": "Processes up to eight flagged entries by repeatedly invoking handler routines until completion and clearing processed flags in the given data structure.",
    "work_score": {
        "prorec": {
            "summary": "Processes and clears active bit flags by invoking associated handlers until no flags remain, repeatedly performing conditional operations based on status bits.",
            "score": [
                0.8,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function processes active bit flags, invokes associated handlers, and clears them until none remain, which aligns with the bitwise slot checking, handler invocation, and clearing in the code. However, it omits key details such as explicit slot count iterations, rescheduling conditions, and lock handling, making the description somewhat generic. Overall, most claims are accurate but lack specificity.",
                "The summary generically describes clearing bit flags and invoking handlers, but does not state the specific core purpose of terminating time-wait sockets via inet_twdr_do_twkill_work in the inet_timewait_death_row structure. While its reference to processing flags and conditional operations loosely matches code flow, it misses key domain semantics (time-wait killing, locking, rescheduling) and lacks detail on edge cases or constants. This results in partial coverage of behavior-critical semantics without covering the true core purpose.",
                "The summary correctly notes that the function processes and clears bit flags until none remain, which matches the loop clearing thread_slots bits. However, it omits specific domain semantics like working on TCP time-wait kill slots, using spinlocks, and scheduling when needed. The description is generic and low detail, providing minimal gain, and contains no inaccurate or contradictory claims. Noise is moderate due to lack of specificity, with overall benefit low."
            ]
        },
        "filter_prorec": {
            "summary": "Processes pending flags for up to eight channels, invoking handlers until conditions clear, then updates the flag mask and repeats until all are serviced.",
            "score": [
                0.3,
                0.3,
                0.2
            ],
            "reason": [
                "The summary claims that the function processes pending flags for up to eight channels and invokes handlers until conditions clear, then updates a flag mask and repeats until all are serviced. The code actually processes time-wait kill work slots (number defined by INET_TWDR_TWKILL_SLOTS, not necessarily eight), calling inet_twdr_do_twkill_work for each active slot, handling rescheduling and updating the thread_slots bitmask. The 'eight channels' detail is inaccurate, as the slot count is determined by the constant, and the term 'channels' is misleading. The loop and flag-processing behavior are somewhat aligned, but the inaccurate specifics reduce precision to below 50%.",
                "The summary correctly describes iterating over up to eight slots and processing until conditions are cleared, which aligns with the loop over INET_TWDR_TWKILL_SLOTS and clearing bits in thread_slots. However, it fails to cover the core purpose of performing TCP time-wait socket cleanup (via inet_twdr_do_twkill_work) and omits critical details like the use of spin locks, scheduling when rescheduling is needed, and the specific domain context. Secondary coverage is generic and misses most behavior-critical semantics.",
                "The summary claims the function processes pending flags for up to eight channels, which inaccurately generalizes the actual logic: the code processes time-wait 'thread_slots' tied to `INET_TWDR_TWKILL_SLOTS` via the death row mechanism, not generic channels. It omits mentioning the specific TCP time-wait killing work and synchronization, and introduces unrelated terminology ('channels' and 'handlers'), making this a core semantic mismatch. This is a FATAL error on the primary purpose, leaving little accurate detail to gain value."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic int unix_getname(struct socket *sock, struct sockaddr *uaddr, int *uaddr_len, int peer)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct unix_sock *u;\n\tDECLARE_SOCKADDR(struct sockaddr_un *, sunaddr, uaddr);\n\tint err = 0;\n\n\tif (peer) {\n\t\tsk = unix_peer_get(sk);\n\n\t\terr = -ENOTCONN;\n\t\tif (!sk)\n\t\t\tgoto out;\n\t\terr = 0;\n\t} else {\n\t\tsock_hold(sk);\n\t}\n\n\tu = unix_sk(sk);\n\tunix_state_lock(sk);\n\tif (!u->addr) {\n\t\tsunaddr->sun_family = AF_UNIX;\n\t\tsunaddr->sun_path[0] = 0;\n\t\t*uaddr_len = sizeof(short);\n\t} else {\n\t\tstruct unix_address *addr = u->addr;\n\n\t\t*uaddr_len = addr->len;\n\t\tmemcpy(sunaddr, addr->name, *uaddr_len);\n\t}\n\tunix_state_unlock(sk);\n\tsock_put(sk);\nout:\n\treturn err;\n}",
    "comment": "Retrieves the Unix socket's address or initializes it as empty if not connected, handling peer connections appropriately.",
    "prorec_sum": "Retrieves address data into a buffer, updates a reference count, and invokes cleanup when no longer referenced.",
    "filter_prorec_sum": "Retrieves address data from a socket structure, updates output parameters, and manages reference counts with locking and cleanup on zero references.",
    "prorec_aug_sum": "Retrieves an associated data entry, updates reference counters, copies its contents into the destination buffer, and performs cleanup when no longer referenced.",
    "filter_prorec_aug_sum": "Retrieves and writes structured data from an object, updating reference counts and invoking cleanup when no references remain.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves address data into a buffer, updates a reference count, and invokes cleanup when no longer referenced.",
            "score": [
                0.5,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains partial alignment with the source code: it correctly notes retrieval of address data into a buffer and reference count updates, which match the memcpy to the sockaddr structure and the sock_hold/sock_put behavior. However, the claim about invoking cleanup when no longer referenced is inaccurate, as the code does not explicitly perform cleanup; it just releases the reference. Overall, only about half of the claims are accurate, with the rest being misleading or unsupported.",
                "The summary vaguely mentions retrieving address data, reference count updates, and cleanup, but does not specify the core domain purpose of obtaining a UNIX socket address (local or peer) and returning it in sockaddr_un format. It omits key behavior such as peer selection logic, handling of missing address by setting sun_family and sun_path, copying the address name, and error handling (-ENOTCONN). While 'retrieves address data' is partially accurate, the lack of specificity and omission of core purpose and multiple critical details result in very poor alignment.",
                "The summary contains mostly inaccurate claims. While it vaguely aligns on retrieving address data into a buffer, it omits key details like conditional handling for peer sockets and setting AF_UNIX family, and instead adds incorrect semantics about updating a reference count and invoking cleanup when no longer referenced, which are not explicit in the source code. The incorrect statements target core behavior and I/O, making the description misleading. The worst failure mode is FATAL due to misrepresentation of the function's primary purpose."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves address data from a socket structure, updates output parameters, and manages reference counts with locking and cleanup on zero references.",
            "score": [
                0.8,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function retrieves address data from a socket structure and updates output parameters, which matches the code's use of `sunaddr` and `uaddr_len`. It also notes reference count management and locking, aligning with `sock_hold`, `sock_put`, and `unix_state_lock/unlock`. However, the mention of cleanup on zero references is not explicitly represented in the source code, making this part inaccurate. Most claims are accurate but not highly specific, resulting in high proportion accuracy with slight imprecision.",
                "The summary correctly notes that the function retrieves address data from a socket and updates output parameters, which aligns with the code. It also mentions reference count management and locking, both present in the implementation. However, it fails to specifically cover the core purpose: obtaining the local or peer AF_UNIX socket address and handling the distinction when no address is set, including filling the structure accordingly. The peer parameter logic and error handling (-ENOTCONN) are omitted, and secondary details such as exact fields set, memory copy from stored address, and explicit unlock/put sequence are missing.",
                "The summary correctly identifies that the function retrieves address information from a socket and updates output parameters, and that it uses locking and cleanup, which aligns with the code. However, it is vague on the details, omitting key conditional logic depending on the 'peer' parameter, the exact handling for unbound sockets, and the distinction between reference count operations (sock_hold/sock_put) and 'cleanup on zero references'. There are no outright incorrect statements (no FATAL errors), but the lack of specificity limits the gain and introduces minor noise through imprecise wording. The net benefit is low due to generic coverage rather than domain-specific detail."
            ]
        }
    }
}
{
    "source_code": "void sqlite3AddDefaultValue(Parse *pParse, ExprSpan *pSpan){\n  Table *p;\n  Column *pCol;\n  sqlite3 *db = pParse->db;\n  p = pParse->pNewTable;\n  if( p!=0 ){\n    pCol = &(p->aCol[p->nCol-1]);\n    if( !sqlite3ExprIsConstantOrFunction(pSpan->pExpr, db->init.busy) ){\n      sqlite3ErrorMsg(pParse, \"default value of column [%s] is not constant\",\n          pCol->zName);\n    }else{\n      /* A copy of pExpr is used instead of the original, as pExpr contains\n      ** tokens that point to volatile memory. The 'span' of the expression\n      ** is required by pragma table_info.\n      */\n      Expr x;\n      sqlite3ExprDelete(db, pCol->pDflt);\n      memset(&x, 0, sizeof(x));\n      x.op = TK_SPAN;\n      x.u.zToken = sqlite3DbStrNDup(db, (char*)pSpan->zStart,\n                                    (int)(pSpan->zEnd - pSpan->zStart));\n      x.pLeft = pSpan->pExpr;\n      x.flags = EP_Skip;\n      pCol->pDflt = sqlite3ExprDup(db, &x, EXPRDUP_REDUCE);\n      sqlite3DbFree(db, x.u.zToken);\n    }\n  }\n  sqlite3ExprDelete(db, pSpan->pExpr);\n}",
    "comment": "Validates and sets a default value for the last column of a new table, ensuring it is a constant expression before storing it.",
    "prorec_sum": "Sets a constant default value for a database column, creating and assigning the associated expression object, or reports an error if non-constant.",
    "filter_prorec_sum": "Updates a table column\u2019s default value when it is a constant, otherwise logs an error, and manages related memory references.",
    "prorec_aug_sum": "Validates a column\u2019s default value as constant, builds and assigns its data structure, and cleans up or reports an error if validation fails.",
    "filter_prorec_aug_sum": "Updates a table column\u2019s default value if it is constant, creating and attaching the necessary internal object, otherwise logs an error.",
    "work_score": {
        "prorec": {
            "summary": "Sets a constant default value for a database column, creating and assigning the associated expression object, or reports an error if non-constant.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function sets a constant default value for a column and reports an error if the value is not constant, which aligns with the code's check using sqlite3ExprIsConstantOrFunction and sqlite3ErrorMsg. It also accurately conveys that an expression object is created and assigned when valid, matching the code's construction and duplication of the Expr structure. All claims are specific to the function's semantics and consistent with the source code, with no incorrect or irrelevant statements present.",
                "The summary correctly states the core purpose of setting a constant default value for a database column and reporting an error if non-constant, which matches the function's main logic. However, it omits secondary details such as verifying constant or function expressions, handling volatile memory by duplicating expressions, freeing previous defaults, and the role of TK_SPAN and EP_Skip flags. Coverage of edge handling and memory management is lacking, so while the core is covered, secondary coverage is thin.",
                "The summary captures the primary purpose accurately by stating that the function sets a constant default value for a database column or reports an error if it is non-constant, which matches the source code's constant check and error handling. However, it condenses the expression creation process into a generic description without mentioning important specifics like copying the span to avoid volatile memory issues, deletion of previous defaults, or duplication flags. There are no inaccurate claims and noise is minimal, but the gain is limited due to the lack of detailed, verifiable behavior beyond the core action."
            ]
        },
        "filter_prorec": {
            "summary": "Updates a table column\u2019s default value when it is a constant, otherwise logs an error, and manages related memory references.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly captures the core behavior: it updates the default value of the last column in a new table when the provided expression is constant, logs an error otherwise, and handles memory management for expression tokens. All of these points are explicitly implemented in the source code and are accurate; there are no incorrect or irrelevant claims.",
                "The summary correctly identifies that the function updates a column\u2019s default value only if it is constant and otherwise reports an error, matching the core purpose of enforcing valid default values. It also references memory management generally, which aligns with the deletion, duplication, and freeing of memory in the code, though without detailing specifics such as Span nodes or EP_Skip flag. Secondary behavior like copying the expression span for table_info pragma is omitted, so while the core is covered, secondary coverage is limited.",
                "The summary captures the core behavior: it sets a column's default value only if the expression is constant, logs an error otherwise, and performs memory management. These are accurate reflections of the code\u2019s main purpose and side effects, with no contradictory claims or irrelevant noise. While the summary is concise and high-level, it omits some lower-level specifics like checking via sqlite3ExprIsConstantOrFunction and duplicating span tokens, so the gain is moderate rather than maximal."
            ]
        }
    }
}
{
    "source_code": "\nstatic void igmp_group_added(struct ip_mc_list *im)\n{\n\tstruct in_device *in_dev = im->interface;\n\n\tif (im->loaded == 0) {\n\t\tim->loaded = 1;\n\t\tip_mc_filter_add(in_dev, im->multiaddr);\n\t}\n\n#ifdef CONFIG_IP_MULTICAST\n\tif (im->multiaddr == IGMP_ALL_HOSTS)\n\t\treturn;\n\n\tif (in_dev->dead)\n\t\treturn;\n\tif (IGMP_V1_SEEN(in_dev) || IGMP_V2_SEEN(in_dev)) {\n\t\tspin_lock_bh(&im->lock);\n\t\tigmp_start_timer(im, IGMP_Initial_Report_Delay);\n\t\tspin_unlock_bh(&im->lock);\n\t\treturn;\n\t}\n\t/* else, v3 */\n\n\tim->crcount = in_dev->mr_qrv ? in_dev->mr_qrv :\n\t\tIGMP_Unsolicited_Report_Count;\n\tigmp_ifc_event(in_dev);\n#endif\n}",
    "comment": "The function processes the addition of an IGMP multicast group, initializing it and managing timers based on the interface's multicast version and state.",
    "prorec_sum": "Initializes a wireless station context if not already done, then updates or blocks its state based on connection flags and timing conditions.",
    "filter_prorec_sum": "Initializes a station context and updates its status or triggers wake/block actions based on connection flags and timing conditions.",
    "prorec_aug_sum": "Initializes state for a network device and conditionally triggers timestamp or mode updates based on its configuration flags and time-related checks.",
    "filter_prorec_aug_sum": "Initializes device state and conditionally triggers timer or status updates based on control fields and time comparisons within the associated device structure.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a wireless station context if not already done, then updates or blocks its state based on connection flags and timing conditions.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about initializing a wireless station context and managing its state based on connection flags and timing conditions are unrelated to the source code, which handles adding an IGMP multicast group, updating loaded status, filtering addresses, and triggering IGMP timers/events. None of the claims accurately describe the actual function behavior, resulting in no accurate matches.",
                "The summary describes initializing a wireless station context and handling connection flags, which is unrelated to the actual function that handles IGMP group addition for a network interface, applies multicast filtering, checks for specific group addresses, interface state, IGMP version detection, and starts timers or sends events accordingly. None of the actual domain semantics are mentioned, and the core purpose is entirely missed.",
                "The summary's claims about initializing a wireless station context, updating or blocking state based on connection flags and timing, are completely unrelated to the source code's actual behavior of managing IGMP multicast group membership. This is a FATAL error on the primary purpose since the summary misidentifies the domain, making it untrustworthy and unusable. There are no accurate claims present to provide positive gain."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a station context and updates its status or triggers wake/block actions based on connection flags and timing conditions.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary's claims about initializing a station context and handling wake/block actions based on connection flags and timing are unrelated to the source code, which deals with adding an IGMP multicast group, updating flags, and starting IGMP timers. None of the claims accurately reflect the function's domain semantics, resulting in no ACCURATE matches.",
                "The summary's claims about initializing a station context and handling connection flags and timing do not correspond to any behavior in the source code, which deals with multicast group addition in IGMP, applying filters, checking multicast address and device status, and starting timers. The core purpose of adding an IGMP group and triggering appropriate reports is entirely missing, and no accurate claims align with the actual function logic.",
                "The summary is entirely inaccurate with respect to the source code. The source code handles adding an IGMP multicast group, updating its state, managing timers, and triggering interface events, while the summary describes initializing a station context and handling connection flags \u2014 concepts unrelated to IGMP or multicast group management. This is pure NOISE with no factual alignment, resulting in no trustworthy information."
            ]
        }
    }
}
{
    "source_code": "static int shrink_dqcache_memory(struct shrinker *shrink,\n\t\t\t\t struct shrink_control *sc)\n{\n\tint nr = sc->nr_to_scan;\n\n\tif (nr) {\n\t\tspin_lock(&dq_list_lock);\n\t\tprune_dqcache(nr);\n\t\tspin_unlock(&dq_list_lock);\n\t}\n\treturn ((unsigned)\n\t\tpercpu_counter_read_positive(&dqstats.counter[DQST_FREE_DQUOTS])\n\t\t/100) * sysctl_vfs_cache_pressure;\n}",
    "comment": "Releases disk quota cache memory by pruning unused entries based on the specified number of entries to scan and adjusts the cache pressure accordingly.",
    "prorec_sum": "Releases and cleans up a set of linked resource objects under a lock, invoking their destructors, then returns a scaled usage metric value.",
    "filter_prorec_sum": "Cleans up and unlinks a set of linked structures, invokes their cleanup callbacks, and returns a scaled value based on a global counter.",
    "prorec_aug_sum": "Cleans up and unlinks a series of list entries, invoking associated destructors, then returns a scaled value based on a global counter.",
    "filter_prorec_aug_sum": "Cleans up and unlinks multiple linked structures, invokes their termination callbacks, then returns a scaled value based on a global 64\u2011bit counter.",
    "work_score": {
        "prorec": {
            "summary": "Releases and cleans up a set of linked resource objects under a lock, invoking their destructors, then returns a scaled usage metric value.",
            "score": [
                0.2,
                0.4,
                0.2
            ],
            "reason": [
                "The summary incorrectly claims that the function invokes destructors, which is not evident in the code; it instead calls prune_dqcache. It also generalizes the returned value as a scaled usage metric, but the code specifically returns a scaled count of free dquots divided by 100 times sysctl_vfs_cache_pressure. The only accurate part is that it releases resources under a lock, making less than half of the claims precise to the code's semantics.",
                "The summary correctly notes that resources are cleaned under a lock and a scaled metric value is returned, aligning with the lock acquisition, prune_dqcache call, and the final calculation in the code. However, it inaccurately frames the operation as releasing linked resources and invoking destructors, which is not explicitly shown in the source \u2014 the code prunes cached quota structures, not generic linked resource objects. The core purpose of shrinking the dqcache to free dquot entries is not precisely conveyed, and secondary details such as the conditional check on nr_to_scan and use of per-CPU counters are omitted.",
                "The summary claims the function invokes destructors on linked resource objects, which contradicts the source code \u2014 it calls `prune_dqcache(nr)` under a spinlock but does not specifically invoke destructors or indicate linked resource object semantics. This is a FATAL in describing the core purpose. While it correctly notes that something is cleaned/released under a lock and that a scaled metric value is returned, the misleading destructor detail and use of vague 'linked resource objects' misrepresents the domain. Worst failure mode is a FATAL on primary purpose, so the net benefit is very low despite minor accurate elements."
            ]
        },
        "filter_prorec": {
            "summary": "Cleans up and unlinks a set of linked structures, invokes their cleanup callbacks, and returns a scaled value based on a global counter.",
            "score": [
                0.2,
                0.1,
                0.4
            ],
            "reason": [
                "The summary incorrectly describes domain semantics: it mentions unlinking linked structures and invoking cleanup callbacks, neither of which is present in the code. The actual function prunes a dqcache under a spinlock when nr_to_scan is nonzero, and returns a scaled value based on a per-CPU counter and a sysctl parameter. Only the final part about returning a scaled value from a global counter aligns with the source; most claims are inaccurate.",
                "The summary incorrectly states that the function 'cleans up and unlinks a set of linked structures' and 'invokes their cleanup callbacks,' which is not supported by the source code. The actual core purpose is to prune cached disk quota structures safely under a spinlock and return a scaled value based on the number of free quota structures and cache pressure. The summary misses this specific domain focus, misrepresents behavior, and does not cover critical semantics such as locking, branch based on nr_to_scan, and the precise calculation for the return value.",
                "The summary contains multiple inaccurate claims. It incorrectly states that the function 'cleans up and unlinks a set of linked structures' and 'invokes their cleanup callbacks,' which is not reflected in the source code \u2014 the code locks a list, prunes a dqcache, and unlocks it without any explicit unlinking or callback invocation. The only accurate part is that it returns a scaled value based on a global counter, but this is outweighed by the noise and semantic errors. The worst failure mode is NOISE dominating, with inaccurate descriptions of the core cleanup operation, leading to low net benefit."
            ]
        }
    }
}
{
    "source_code": "\nvoid BN_CTX_end(BN_CTX *ctx)\n\t{\n\tCTXDBG_ENTRY(\"BN_CTX_end\", ctx);\n\tif(ctx->err_stack)\n\t\tctx->err_stack--;\n\telse\n\t\t{\n\t\tunsigned int fp = BN_STACK_pop(&ctx->stack);\n\t\t/* Does this stack frame have anything to release? */\n\t\tif(fp < ctx->used)\n\t\t\tBN_POOL_release(&ctx->pool, ctx->used - fp);\n\t\tctx->used = fp;\n\t\t/* Unjam \"too_many\" in case \"get\" had failed */\n\t\tctx->too_many = 0;\n\t\t}\n\tCTXDBG_EXIT(ctx);\n\t}",
    "comment": "Releases resources associated with the BN_CTX structure, updating the used stack frame and resetting the too_many flag if necessary.",
    "prorec_sum": "Ends a big number context by restoring stack state, releasing allocated blocks, and updating depth and position tracking fields.",
    "filter_prorec_sum": "Releases temporary BIGNUM resources in a BN_CTX context, restoring stack and pool state after a scoped allocation ends.",
    "prorec_aug_sum": "Releases temporary big number variables and stack frames from a BN_CTX structure, restoring internal counters and linked context frames.",
    "filter_prorec_aug_sum": "Releases allocated big number context frames and restores internal state counters after nested usage.",
    "work_score": {
        "prorec": {
            "summary": "Ends a big number context by restoring stack state, releasing allocated blocks, and updating depth and position tracking fields.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function ends a big number context by restoring the stack state, releasing allocated blocks, and updating tracking fields. These claims align with the source code: the function pops the stack frame, conditionally releases memory from the pool, updates the 'used' field, and resets 'too_many'. All noted behaviors are accurate and specific to the code\u2019s implementation, with no contradictions or irrelevant noise.",
                "The summary correctly captures the core purpose: ending a big number context by restoring the stack state, releasing allocated blocks, and updating tracking fields, which aligns with the source's restoration of stack frame depth (`ctx->used`), conditional pool release, and resetting `too_many`. However, it omits secondary behavior-critical details such as handling `err_stack` decrement when nonzero, the specific field `too_many` reset as a failure recovery, and the conditional nature of resource release based on `fp < used`. These gaps reduce completeness despite covering the main domain effect.",
                "The summary contains accurate, domain-relevant statements: it correctly notes that the function restores the stack state (via BN_STACK_pop and resetting ctx->used), releases allocated blocks (BN_POOL_release when needed), and updates tracking fields (ctx->used and ctx->too_many). There is no contradictory or irrelevant claim. However, the phrasing is somewhat generic and omits specific details such as the conditional decrement of err_stack, making the gain modest rather than high. Noise is minimal, and there are no fatal inaccuracies."
            ]
        },
        "filter_prorec": {
            "summary": "Releases temporary BIGNUM resources in a BN_CTX context, restoring stack and pool state after a scoped allocation ends.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function releases temporary BIGNUM resources and restores stack and pool state after a scoped allocation ends, which matches the source code's behavior: popping the stack frame, releasing unused pool elements, and resetting state. These are accurate, domain-specific claims directly grounded in the implementation, with no incorrect or irrelevant statements, yielding a high proportion of accurate claims.",
                "The summary correctly identifies the core function of releasing temporary BIGNUM resources and restoring stack/pool state after a scoped allocation, which matches the source code\u2019s operations involving BN_POOL_release, BN_STACK_pop, and resetting ctx->used and ctx->too_many. However, it omits secondary details such as decrementing err_stack when applicable, handling the condition where no resources need releasing, and the debug entry/exit calls. This partial coverage of secondary behavior places it in the range of decent but incomplete coverage.",
                "The summary correctly describes the core purpose of BN_CTX_end: it releases temporary BIGNUM resources from the BN_CTX pool and restores stack state after a scoped allocation. This aligns with the code's behavior of popping the stack frame, releasing unused pool entries, resetting 'used', and clearing 'too_many'. While the wording is high-level and lacks mention of the err_stack decrement logic, there are no inaccurate claims or irrelevant noise. The accuracy is strong but the detail level is moderate, giving some domain insight without full specifics."
            ]
        }
    }
}
{
    "source_code": "\nstatic ssize_t\narray_size_store(struct mddev *mddev, const char *buf, size_t len)\n{\n\tsector_t sectors;\n\n\tif (strncmp(buf, \"default\", 7) == 0) {\n\t\tif (mddev->pers)\n\t\t\tsectors = mddev->pers->size(mddev, 0, 0);\n\t\telse\n\t\t\tsectors = mddev->array_sectors;\n\n\t\tmddev->external_size = 0;\n\t} else {\n\t\tif (strict_blocks_to_sectors(buf, &sectors) < 0)\n\t\t\treturn -EINVAL;\n\t\tif (mddev->pers && mddev->pers->size(mddev, 0, 0) < sectors)\n\t\t\treturn -E2BIG;\n\n\t\tmddev->external_size = 1;\n\t}\n\n\tmddev->array_sectors = sectors;\n\tif (mddev->pers) {\n\t\tset_capacity(mddev->gendisk, mddev->array_sectors);\n\t\trevalidate_disk(mddev->gendisk);\n\t}\n\treturn len;\n}",
    "comment": "Sets the array size for a storage device based on input, updating capacity and validating the disk if a specific size is provided.",
    "prorec_sum": "Configures a device\u2019s operational mode, default or parsed from input, validates capacity, updates internal state, and applies provided parameter values.",
    "filter_prorec_sum": "Sets a device\u2019s configuration value to \u201cdefault\u201d or a parsed custom setting, validates limits, updates state, and applies provided calibration parameters.",
    "prorec_aug_sum": "Sets a device parameter to either the default or a validated custom value and updates related structures with provided configuration data.",
    "filter_prorec_aug_sum": "Configures the target object's current profile to either \"default\" or a validated custom value and updates related parameters through a linked handler.",
    "work_score": {
        "prorec": {
            "summary": "Configures a device\u2019s operational mode, default or parsed from input, validates capacity, updates internal state, and applies provided parameter values.",
            "score": [
                0.5,
                0.3,
                0.4
            ],
            "reason": [
                "The summary contains several claims: that the function configures a device\u2019s operational mode, handles default or parsed input, validates capacity, updates internal state, and applies provided parameter values. While 'handles default or parsed input' and 'validates capacity' map to actual code behaviors such as checking the \"default\" string, parsing sectors, and size validation, the claim about configuring an operational mode is inaccurate since the function sets array size rather than mode. The phrase 'applies provided parameter values' is vague and not clearly grounded in the exact code semantics. Overall, only about half of the claims are accurate, resulting in mixed reliability.",
                "The summary lacks the specific core purpose of setting the RAID array size based on either a default or parsed sector count. While it mentions configuring a mode and validating capacity, it does not clearly state the action of updating 'array_sectors' and adjusting disk capacity via set_capacity and revalidate_disk. The wording is generic and omits key behaviors such as handling the 'default' keyword, converting blocks to sectors, and error returns for invalid input or too-large sizes.",
                "The summary contains mostly generic statements and fails to capture specific behaviors from the code, such as handling the 'default' keyword, parsing sectors via strict_blocks_to_sectors, checking for oversize input against mddev->pers->size, setting external_size flags, and updating capacity with set_capacity and revalidate_disk. These omissions mean there are no FATAL inaccuracies, but the information gain is very low and key implementation details are absent, causing noise to outweigh accurate content."
            ]
        },
        "filter_prorec": {
            "summary": "Sets a device\u2019s configuration value to \u201cdefault\u201d or a parsed custom setting, validates limits, updates state, and applies provided calibration parameters.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function sets a configuration either to a default or parsed custom value, validates limits, and updates state, which matches the code's behavior. However, it inaccurately adds that it applies provided calibration parameters \u2014 no such calibration handling exists in the source. This extra incorrect claim lowers the accuracy proportion to around 75%, resulting in mixed reliability.",
                "The summary vaguely describes setting a configuration to 'default' or a custom setting and validating limits, which loosely aligns with the code's handling of 'default' input, parsing values, and error checks. However, it omits the core purpose: updating mddev's array size in sectors and interacting with its gendisk (via set_capacity and revalidate_disk). Additionally, the mention of 'calibration parameters' is inaccurate and unrelated to the source code. Secondary details like specific error cases (-EINVAL, -E2BIG) and external size flag logic are also missing.",
                "The summary correctly notes that the function sets a configuration to a default or a parsed custom value, validates size limits, and updates internal state, which aligns with the source code's use of 'default' checks, strict_blocks_to_sectors parsing, and array_sectors updates. However, the phrase 'applies provided calibration parameters' is inaccurate, as the code instead adjusts disk capacity and revalidates the disk without any calibration concept; this is a clear noise/inaccuracy. There is no fatal misrepresentation of the primary purpose, but the gain is low as the accurate claims are generic and the added noise reduces clarity."
            ]
        }
    }
}
{
    "source_code": "void exit_itimers(struct signal_struct *sig)\n{\n\tstruct k_itimer *tmr;\n\n\twhile (!list_empty(&sig->posix_timers)) {\n\t\ttmr = list_entry(sig->posix_timers.next, struct k_itimer, list);\n\t\titimer_delete(tmr);\n\t}\n}",
    "comment": "Deletes all posix timers associated with the given signal structure by iterating through and removing each timer from the list.",
    "prorec_sum": "Removes and cleans up expired POSIX timers from a linked list, invoking appropriate callbacks or logging errors when timer handlers are missing.",
    "filter_prorec_sum": "Processes and removes expired POSIX timers from a linked list, invoking type-specific handlers and cleaning up associated resources.",
    "prorec_aug_sum": "Removes expired POSIX timers from a task\u2019s timer list, invoking their callbacks or cleanup routines as appropriate.",
    "filter_prorec_aug_sum": "Removes expired or invalid POSIX timer entries from a linked list and cleans up associated resources in kernel/posix-timers.c.",
    "work_score": {
        "prorec": {
            "summary": "Removes and cleans up expired POSIX timers from a linked list, invoking appropriate callbacks or logging errors when timer handlers are missing.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary introduces claims about removing only expired timers, invoking callbacks, and logging errors when handlers are missing, none of which are supported by the source code. The function iterates over all POSIX timers in the linked list and deletes them, without filtering by expiration, handling callbacks, or logging errors. These inaccuracies significantly reduce alignment with the actual code behavior.",
                "The summary's main claim about removing POSIX timers from a linked list is somewhat aligned with the code, though the code removes all timers rather than specifically expired ones. The additional statements about invoking callbacks or logging errors contradict the source, which simply calls itimer_delete without explicit callbacks or error logging. The core purpose\u2014deleting all POSIX timers from a signal_struct\u2014is not clearly or accurately captured, and most secondary details are inaccurate.",
                "The summary incorrectly claims that the function handles only expired POSIX timers and may invoke callbacks or log errors when handlers are missing, none of which is reflected in the source code. The actual code iterates through all timers in the linked list and deletes them without checking expiration or invoking callbacks/logging. This is a FATAL in describing the primary purpose, making the summary misleading on the core behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Processes and removes expired POSIX timers from a linked list, invoking type-specific handlers and cleaning up associated resources.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims that the function processes and removes expired POSIX timers and invokes type-specific handlers, which is inaccurate. The source code shows it iterates over all POSIX timers in a process's linked list and deletes them using `itimer_delete`, without checking expiration or invoking type-specific handlers. Only the cleanup of associated resources aligns partially with the code, so the majority of claims are inaccurate.",
                "The summary claims that the function processes and removes expired POSIX timers and invokes type-specific handlers, but the source code shows it iteratively deletes all timers in the posix_timers list regardless of expiration status, using itimer_delete for cleanup. The mention of 'expired' and 'type-specific handlers' is inaccurate, and the core purpose of deleting all timers from the list is not correctly covered. Secondary details about cleanup are slightly present but misrepresented.",
                "The summary incorrectly states that the function processes and removes expired POSIX timers, and invokes type-specific handlers, which contradicts the source code. The code simply iterates through all POSIX timers in the signal_struct, regardless of expiration status, and deletes them using itimer_delete without any type-specific handling. This is a FATAL in describing the core purpose, making the description untrustworthy. Accurate detail about deleting timers from a linked list is minimal and outweighed by the primary inaccuracy."
            ]
        }
    }
}
{
    "source_code": "\nstatic int snd_pcm_unlink(struct snd_pcm_substream *substream)\n{\n\tstruct snd_pcm_substream *s;\n\tint res = 0;\n\n\tdown_write(&snd_pcm_link_rwsem);\n\twrite_lock_irq(&snd_pcm_link_rwlock);\n\tif (!snd_pcm_stream_linked(substream)) {\n\t\tres = -EALREADY;\n\t\tgoto _end;\n\t}\n\tlist_del(&substream->link_list);\n\tsubstream->group->count--;\n\tif (substream->group->count == 1) {\t/* detach the last stream, too */\n\t\tsnd_pcm_group_for_each_entry(s, substream) {\n\t\t\trelink_to_local(s);\n\t\t\tbreak;\n\t\t}\n\t\tkfree(substream->group);\n\t}\n\trelink_to_local(substream);\n       _end:\n\twrite_unlock_irq(&snd_pcm_link_rwlock);\n\tup_write(&snd_pcm_link_rwsem);\n\treturn res;\n}",
    "comment": "Unlinks a PCM substream from its group and releases resources if it was the last linked stream in the group.",
    "prorec_sum": "Removes an entry from a linked structure, updates related counters, reinitializes list links, and triggers further processing when only one item remains.",
    "filter_prorec_sum": "Removes an entry from a linked list, updates related queue counters, resets pointers, and triggers follow-up processing with provided parameters.",
    "prorec_aug_sum": "Removes and reinitializes a linked list entry from an audio device structure, updates related counters, and triggers subsequent audio stream handling operations.",
    "filter_prorec_aug_sum": "Removes and invalidates a linked substream structure, updates reference counters, triggers cleanup routines, and reinitializes its list pointers before returning a status code.",
    "work_score": {
        "prorec": {
            "summary": "Removes an entry from a linked structure, updates related counters, reinitializes list links, and triggers further processing when only one item remains.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly captures core behaviors such as removing an entry from a linked structure (`list_del`), updating counters (`group->count--`), reinitializing links (`relink_to_local`), and handling the case when one item remains by triggering further processing (loop and `kfree`). These align closely with the function's actual operations without introducing incorrect or irrelevant claims. Almost all extracted claims are accurate representations of the source code semantics.",
                "The summary correctly captures aspects of the function such as removing an entry from a linked structure, updating counters, and performing additional processing when a single item remains, which aligns with the code's unlinking from a list, decrementing group count, and handling the last stream case. However, it omits the core domain-specific purpose of unlinking an ALSA PCM substream from its group, and lacks mention of key details like concurrency locks, error handling for already unlinked streams, and memory deallocation. This results in partial but not complete coverage of the function's behavior.",
                "The summary correctly captures the main actions of the function: removing an entry from a linked structure, updating a counter, re-linking entries, and performing additional steps when only one stream remains. These are accurate and aligned with the source code's behavior involving list deletion, decrementing `group->count`, conditional handling when count equals 1, and calls to `relink_to_local`. There is minimal noise and no inaccuracies, but the gain is modest because the description is generic and omits specific details such as locking mechanisms, error conditions, and the freeing of the group structure."
            ]
        },
        "filter_prorec": {
            "summary": "Removes an entry from a linked list, updates related queue counters, resets pointers, and triggers follow-up processing with provided parameters.",
            "score": [
                0.3,
                0.2,
                0.4
            ],
            "reason": [
                "The summary contains partially accurate elements, such as removing an entry from a linked list, but inaccurately describes other operations. It mentions updating queue counters instead of the group count, uses vague 'resets pointers' which does not match the specific relinking logic in the code, and describes 'triggers follow-up processing with provided parameters' which does not directly reflect the observed relinking and cleanup behavior. These mismatches mean less than half of the claims are accurate.",
                "The summary generically describes removing a linked list entry and updating counters, which matches part of the function's actions, but it fails to mention the core purpose of unlinking an ALSA PCM substream from its linked group. It omits critical domain-specific details such as handling the 'already unlinked' error (-EALREADY), the lock operations, relinking streams back to local, and freeing the group structure when only one stream remains. The core domain semantics are not covered, and only partial low-info accurate elements appear.",
                "The summary inaccurately describes the function by mentioning 'queue counters' and 'provided parameters', which are not present in the source code. While it correctly notes removal from a linked list, it omits core purpose details such as unlinking PCM substreams, handling group detachment, and relinking streams locally. The mismatch between 'resets pointers' and the actual relinking logic adds to the noise. There is no severe contradiction of the primary purpose, but inaccurate and generic claims lead to low net benefit with minimal specific insight."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic ngx_int_t\nngx_http_chunked_header_filter(ngx_http_request_t *r)\n{\n    ngx_http_core_loc_conf_t       *clcf;\n    ngx_http_chunked_filter_ctx_t  *ctx;\n\n    if (r->headers_out.status == NGX_HTTP_NOT_MODIFIED\n        || r->headers_out.status == NGX_HTTP_NO_CONTENT\n        || r->headers_out.status < NGX_HTTP_OK\n        || r != r->main\n        || r->method == NGX_HTTP_HEAD)\n    {\n        return ngx_http_next_header_filter(r);\n    }\n\n    if (r->headers_out.content_length_n == -1\n        || r->expect_trailers)\n    {\n        clcf = ngx_http_get_module_loc_conf(r, ngx_http_core_module);\n\n        if (r->http_version >= NGX_HTTP_VERSION_11\n            && clcf->chunked_transfer_encoding)\n        {\n            if (r->expect_trailers) {\n                ngx_http_clear_content_length(r);\n            }\n\n            r->chunked = 1;\n\n            ctx = ngx_pcalloc(r->pool, sizeof(ngx_http_chunked_filter_ctx_t));\n            if (ctx == NULL) {\n                return NGX_ERROR;\n            }\n\n            ngx_http_set_ctx(r, ctx, ngx_http_chunked_filter_module);\n\n        } else if (r->headers_out.content_length_n == -1) {\n            r->keepalive = 0;\n        }\n    }\n\n    return ngx_http_next_header_filter(r);\n}",
    "comment": "The function processes HTTP responses to enable chunked transfer encoding when conditions regarding content length and HTTP version are met.",
    "prorec_sum": "Handles HTTP request state by checking connection and configuration flags, resetting or allocating chunked filter context, and returning a status indicator.",
    "filter_prorec_sum": "Handles HTTP request state checks and initializes the chunked filter context if conditions are met, otherwise resets related fields and returns immediately.",
    "prorec_aug_sum": "Handles HTTP request state checks, clears or resets related fields, and allocates chunked filter context when specific conditions on timers and flags are met.",
    "filter_prorec_aug_sum": "Manages HTTP request state for chunked transfer encoding, validating conditions and allocating filter context before enabling the chunked filter module.",
    "work_score": {
        "prorec": {
            "summary": "Handles HTTP request state by checking connection and configuration flags, resetting or allocating chunked filter context, and returning a status indicator.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary includes some correct, generic statements such as handling HTTP request state and allocating chunked filter context, which align with the code\u2019s behavior. However, it omits specific conditions checked in the code (HTTP status values, version checks, content length, expect trailers) and inaccurately generalizes the return value as a status indicator without noting it delegates to the next header filter. This results in only partial semantic coverage with several key details missing.",
                "The summary is too generic and does not explicitly cover the core purpose of enabling chunked transfer encoding for HTTP responses without a known content length (or expecting trailers) under HTTP/1.1 when configured. It vaguely mentions handling request state and allocating context but omits key semantics such as status checks that short-circuit, clearing content length for trailers, disabling keepalive when no length under non-chunked conditions, and conditions based on HTTP version and configuration. Core domain action is missing, and secondary behavior coverage is minimal.",
                "The summary is mostly generic and lacks specific, verifiable detail about the actual code behavior. While it correctly notes that the function handles HTTP request state and may allocate chunked filter context, it omits key decision criteria such as status checks for 304, 204, HEAD requests, HTTP version requirements, and chunked transfer encoding flags. It does not contradict the code but provides low informational value, with noise outweighing precise insights."
            ]
        },
        "filter_prorec": {
            "summary": "Handles HTTP request state checks and initializes the chunked filter context if conditions are met, otherwise resets related fields and returns immediately.",
            "score": [
                0.6,
                0.5,
                0.6
            ],
            "reason": [
                "The summary captures the general flow of the function\u2014checking HTTP request state, initializing a chunked filter context, and returning when conditions are not met\u2014which matches the source code's main logic. However, it omits important specifics such as the exact conditions for returning early, the HTTP version and chunked transfer encoding checks, the clearing of the content length when trailers are expected, and disabling keepalive when content length is unknown and chunked is not enabled. As a result, while the claims are broadly accurate, they are generic and lack several precise, verifiable details from the code.",
                "The summary mentions handling HTTP request state checks and initializing the chunked filter context, which accurately reflects the core purpose of deciding when to enable chunked transfer encoding. However, it is vague and omits critical specifics such as checking particular HTTP status codes, content length behavior, HTTP version requirements, expectation of trailers, and actions like clearing the content length or disabling keepalive. It also fails to capture the branching and error handling present in the code, providing only a generic description without domain-specific conditions.",
                "The summary correctly captures the overall behavior that the function performs state checks and may initialize a chunked filter context under certain conditions. It omits specific and important condition details from the source, such as exact status codes, HTTP version requirements, and trailer handling, which limits accuracy to a generic level. There are no contradictory (FATAL) claims, and noise is minimal; however, the gain is low due to lack of specificity."
            ]
        }
    }
}
{
    "source_code": "static int compute_partition_size(Ecma119Image *t, char *disk_path,\n                                  uint32_t *size, int flag)\n{\n    int ret, keep;\n    off_t num;\n    struct stat stbuf;\n    struct iso_interval_reader *ivr;\n    off_t byte_count;\n\n    if (flag & 1) {\n        ret = iso_interval_reader_new(t->image, disk_path,\n                                      &ivr, &byte_count, 0);\n        if (ret < 0)\n            return ret;\n        *size = (byte_count + BLOCK_SIZE - 1) / BLOCK_SIZE;\n        keep = iso_interval_reader_keep(t, ivr, 0);\n        iso_interval_reader_destroy(&ivr, 0);\n        if (keep < 0)\n            return keep;\n        return ISO_SUCCESS + (keep > 0);\n    }\n\n    *size = 0;\n    ret = stat(disk_path, &stbuf);\n    if (ret == -1)\n        return ISO_BAD_PARTITION_FILE;\n    if (! S_ISREG(stbuf.st_mode))\n        return ISO_BAD_PARTITION_FILE;\n    num = ((stbuf.st_size + 2047) / 2048);\n    if (num > 0x3fffffff || num == 0)\n        return ISO_BAD_PARTITION_FILE;\n    *size = num;\n    return ISO_SUCCESS;\n}",
    "comment": "Calculates the partition size from a disk path or an image based on a specified flag, ensuring valid file attributes and conditions.",
    "prorec_sum": "Determines a regular file\u2019s size in 2\u202fKB blocks using either a cached lookup or direct stat, returning error codes for invalid conditions.",
    "filter_prorec_sum": "Determines a file\u2019s block count from device or size data, using cached stat information when requested, and validates it is a regular file.",
    "prorec_aug_sum": "Retrieves file or device size in 2\u202fKB blocks after validating it is a regular file, returning specific error codes on failure conditions.",
    "filter_prorec_aug_sum": "Determines the file\u2019s size in 2\u202fKB blocks after validating its type, or retrieves equivalent size information via a filesystem-specific lookup.",
    "work_score": {
        "prorec": {
            "summary": "Determines a regular file\u2019s size in 2\u202fKB blocks using either a cached lookup or direct stat, returning error codes for invalid conditions.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function determines a file\u2019s size in 2\u202fKB blocks and uses either a cached lookup (via iso_interval_reader when flag & 1) or direct stat. It also correctly notes that error codes are returned for invalid conditions. All claims are rooted in the actual code behavior without contradiction or irrelevant content, leading to a high proportion of accurate statements.",
                "The summary identifies computing a regular file's size in 2\u202fKB blocks and mentions error handling for invalid conditions, aligning with the code's two methods (via iso_interval_reader or stat). It misses some specifics such as the flag check to choose the method, the rounding method for block size, the constants ISO_SUCCESS and ISO_BAD_PARTITION_FILE, and handling of the 'keep' result in the cached reader path. Core purpose is covered, but secondary details are limited.",
                "The summary contains an accurate core description: it identifies that the function determines the size of a regular file in 2\u202fKB blocks and outlines the two retrieval modes (cached via interval reader vs direct stat). It also correctly notes that error codes are returned for invalid conditions. The claim is GOLD-level for the purpose and key I/O, with no contradictions or overwhelming noise. While details such as specific flag checks and precise error scenarios are omitted, the noise level is minimal and accuracy on primary purpose is strong."
            ]
        },
        "filter_prorec": {
            "summary": "Determines a file\u2019s block count from device or size data, using cached stat information when requested, and validates it is a regular file.",
            "score": [
                0.5,
                0.3,
                0.4
            ],
            "reason": [
                "The summary claims the function uses cached stat information when requested, which is inaccurate since the code performs a fresh stat call instead. It correctly notes that the function determines a file\u2019s block count from device or size data and validates it is a regular file, but omits key details such as different logic when the flag is set and the specific error conditions checked. Only part of the claims align with the source code, resulting in mixed reliability.",
                "The summary misrepresents core behavior: it claims use of 'cached stat information when requested,' which is inaccurate since the flag branch uses iso_interval_reader to compute block count from device data, not a cached stat. The core purpose\u2014computing a partition size either from interval reader when flag&1 or from stat of a regular file\u2014is only partially conveyed; the description of validating the file type is correct but lacks detail on size constraints (nonzero, <= 0x3fffffff) and specific error returns. This leaves the core coverage incomplete and misses several key secondary behaviors.",
                "The summary contains some accurate elements such as determining the file's block count and validating it is a regular file, which matches the code's logic. However, it inaccurately mentions using cached stat information when requested\u2014there is no caching logic in the source; instead, it directly calls `stat`. The description of input source as 'device or size data' is vague and partially misleading given the actual branch using `iso_interval_reader_new`. The noise and inaccuracy in describing the file stat behavior outweighs the small accurate portion, and there is no GOLD-level detail provided."
            ]
        }
    }
}
{
    "source_code": "\nstruct timeval* dtls1_get_timeout(SSL *s, struct timeval* timeleft)\n\t{\n\tstruct timeval timenow;\n\n\t/* If no timeout is set, just return NULL */\n\tif (s->d1->next_timeout.tv_sec == 0 && s->d1->next_timeout.tv_usec == 0)\n\t\t{\n\t\treturn NULL;\n\t\t}\n\n\t/* Get current time */\n\tget_current_time(&timenow);\n\n\t/* If timer already expired, set remaining time to 0 */\n\tif (s->d1->next_timeout.tv_sec < timenow.tv_sec ||\n\t\t(s->d1->next_timeout.tv_sec == timenow.tv_sec &&\n\t\t s->d1->next_timeout.tv_usec <= timenow.tv_usec))\n\t\t{\n\t\tmemset(timeleft, 0, sizeof(struct timeval));\n\t\treturn timeleft;\n\t\t}\n\n\t/* Calculate time left until timer expires */\n\tmemcpy(timeleft, &(s->d1->next_timeout), sizeof(struct timeval));\n\ttimeleft->tv_sec -= timenow.tv_sec;\n\ttimeleft->tv_usec -= timenow.tv_usec;\n\tif (timeleft->tv_usec < 0)\n\t\t{\n\t\ttimeleft->tv_sec--;\n\t\ttimeleft->tv_usec += 1000000;\n\t\t}\n\n\t/* If remaining time is less than 15 ms, set it to 0\n\t * to prevent issues because of small devergences with\n\t * socket timeouts.\n\t */\n\tif (timeleft->tv_sec == 0 && timeleft->tv_usec < 15000)\n\t\t{\n\t\tmemset(timeleft, 0, sizeof(struct timeval));\n\t\t}\n\t\n\n\treturn timeleft;\n\t}",
    "comment": "Calculates the remaining timeout for a DTLS connection and returns a struct timeval with the time left until expiration.",
    "prorec_sum": "Calculates the remaining time before a DTLS event expires and returns zero when the deadline has passed or is within 15 milliseconds.",
    "filter_prorec_sum": "Calculates the remaining time until a DTLS handshake retransmission deadline and returns zero if expired or below a minimal threshold.",
    "prorec_aug_sum": "Calculates and returns the remaining time until a stored DTLS timer expires, or zero if the deadline has passed or is very close.",
    "filter_prorec_aug_sum": "Calculates and returns the remaining time until the DTLS retransmission timeout based on current time and stored expiry values.",
    "work_score": {
        "prorec": {
            "summary": "Calculates the remaining time before a DTLS event expires and returns zero when the deadline has passed or is within 15 milliseconds.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary accurately captures the core behavior: it calculates remaining time until a DTLS timeout and returns zero when expired or within 15 milliseconds. This matches the source code\u2019s logic, including the special case for <15 ms and expired timers. No inaccuracies are present, and the claim is domain-specific and verifiable.",
                "The summary correctly identifies the core purpose as calculating the remaining time until a DTLS timeout and notes two key behaviors: returning zero if the timeout has passed or is within 15 milliseconds. This matches the source code's main domain effect and includes one secondary condition. However, it omits other important details such as handling the case when no timeout is set (returning NULL), the logic for adjusting negative microseconds, and the explicit copying of the timeout value before calculation, resulting in incomplete coverage of secondary behaviors.",
                "The summary accurately captures the primary purpose of the function: computing the remaining time before a DTLS timeout and returning zero when expired or within 15 milliseconds. There are no contradictory (FATAL) claims, and noise is minimal. However, the summary omits details about handling the case when no timeout is set (returns NULL) and specifics of the time calculation steps, so the gain is moderate rather than high."
            ]
        },
        "filter_prorec": {
            "summary": "Calculates the remaining time until a DTLS handshake retransmission deadline and returns zero if expired or below a minimal threshold.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately describes that the function computes the remaining time for a DTLS handshake retransmission deadline, returns zero if expired, and also zero if below a minimal threshold, all of which match the source code's logic. These are specific and verifiable claims aligned with the code\u2019s behavior, with no inaccuracies or irrelevant noise present.",
                "The summary accurately states the core purpose: computing the remaining time until a DTLS handshake retransmission deadline and returning zero when expired or below a threshold, which matches the function's domain semantic of calculating the timeout until the next retransmission with an adjustment for minimal values. However, it omits secondary details such as returning NULL when no timeout is set, handling negative microseconds via adjustment, and the 15 ms threshold rationale. The coverage of the core is solid, but secondary semantics are only partially addressed.",
                "The summary accurately captures the core function: computing time until the next DTLS handshake retransmission deadline, returning zero if expired or below the small threshold. It matches the source code\u2019s logic of checking expiration, calculating remaining time, and applying the 15 ms cutoff. No inaccuracies or noise are present, and the claim is specific and high-value for understanding the primary purpose."
            ]
        }
    }
}
{
    "source_code": "static int mmc_get_leadin_text_al(struct burn_drive *d,\n                                  unsigned char **text_packs, int *alloc_len,\n                                  int flag)\n{\n\tstruct buffer *buf = NULL;\n\tstruct command *c = NULL;\n\tunsigned char *data;\n\tint ret, data_length;\n\n\t*text_packs = NULL;\n\n\tBURN_ALLOC_MEM(buf, struct buffer, 1);\n\tBURN_ALLOC_MEM(c, struct command, 1);\n\n\tscsi_init_command(c, MMC_GET_LEADTEXT, sizeof(MMC_GET_LEADTEXT));\n\tc->dxfer_len = *alloc_len;\n\tc->opcode[7]= (c->dxfer_len >> 8) & 0xff;\n\tc->opcode[8]= c->dxfer_len & 0xff;\n\tc->retry = 1;\n\tc->page = buf;\n\tc->page->bytes = 0;\n\tc->page->sectors = 0;\n\n\tc->dir = FROM_DRIVE;\n\td->issue_command(d, c);\n\tif (c->error)\n\t\t{ret = 0; goto ex;}\n\n\tdata = c->page->data;\t\n\tdata_length = (data[0] << 8) + data[1];\n\t*alloc_len = data_length + 2;\n\tif (*alloc_len >= 22 && !(flag & 1)) {\n\t\tBURN_ALLOC_MEM(*text_packs, unsigned char, *alloc_len - 4);\n\t\tmemcpy(*text_packs, data + 4, *alloc_len - 4);\n\t}\n\tret = 1;\t\nex:;\n\tBURN_FREE_MEM(c);\n\tBURN_FREE_MEM(buf);\n\treturn ret;\n}",
    "comment": "Retrieves lead-in text from a drive and allocates memory for the text if the conditions are met, returning success or failure.",
    "prorec_sum": "Allocates and initializes buffers, processes data through a callback, and optionally extracts a payload segment into output based on size and flag conditions.",
    "filter_prorec_sum": "Allocates buffers, invokes a callback to fill them, validates length, and copies resulting ISO9660 volume data into the provided output pointer.",
    "prorec_aug_sum": "Allocates buffers, invokes a callback to fill them, reads a length-prefixed payload, and optionally copies the payload data into a provided output buffer.",
    "filter_prorec_aug_sum": "Allocates buffers, invokes a callback to fill them, then extracts and optionally copies payload data based on header length and a control flag.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes buffers, processes data through a callback, and optionally extracts a payload segment into output based on size and flag conditions.",
            "score": [
                0.9,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly notes buffer allocation/initialization and conditional extraction of a payload segment depending on size and flag, aligning with the code's memory management and flag-based copy logic. However, the phrase 'processes data through a callback' is inaccurate, as the function issues a command directly via the drive's function pointer rather than a generic callback. Most of the claims target actual semantics and are correct, with only a minor inaccuracy, yielding high overall accuracy.",
                "The summary captures buffer allocation/initialization and conditional extraction based on size and flag, which are accurate secondary behaviors. However, it omits the core primary purpose of issuing an MMC_GET_LEADTEXT SCSI command to retrieve lead-in text from the drive, making it incomplete with respect to the source code\u2019s main operation.",
                "The summary contains mostly accurate but very generic claims. It correctly notes buffer allocation/initialization, data processing, and conditional payload extraction based on size and flag. However, it mischaracterizes 'issue_command' as a generic callback rather than a specific SCSI command execution, losing domain-specific detail. There are no fatal inaccuracies targeting the primary purpose, but the description is too high-level and omits key specifics like SCSI command opcode setup, data length calculation, and actual data copy offsets, resulting in low-information gain and moderate noise."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates buffers, invokes a callback to fill them, validates length, and copies resulting ISO9660 volume data into the provided output pointer.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as handling ISO9660 volume data and invoking a callback to fill buffers, which does not align with the source code. The source code deals with MMC GET LEADTEXT SCSI command, allocates buffers, sets command parameters, reads lead-in text data, and conditionally copies it into the output buffer. Most claims are inaccurate, with only the allocation and copying parts loosely matching, resulting in less than half being accurate.",
                "The summary claims it copies ISO9660 volume data, but the code retrieves MMC lead-in text via a SCSI command, making this core purpose inaccurately described. While the summary mentions buffer allocation, callback invocation, and length validation, these are generic and do not capture the specific primary domain action. As the core functionality is not covered and the main domain semantics are misrepresented, alignment is very weak.",
                "The summary contains a FATAL inaccuracy: it claims the function copies ISO9660 volume data, whereas the source code actually issues an MMC_GET_LEADTEXT command to retrieve lead-in text metadata from an optical drive. This misidentifies the PRIMARY PURPOSE and the nature of the data handled. While it correctly notes buffer allocation, invoking a drive command, validating length, and copying data under certain conditions, the core description is wrong, making the function untrustworthy based on the summary."
            ]
        }
    }
}
{
    "source_code": "\nstatic int mntns_install(struct nsproxy *nsproxy, void *ns)\n{\n\tstruct fs_struct *fs = current->fs;\n\tstruct mnt_namespace *mnt_ns = ns;\n\tstruct path root;\n\n\tif (!ns_capable(mnt_ns->user_ns, CAP_SYS_ADMIN) ||\n\t    !nsown_capable(CAP_SYS_CHROOT) ||\n\t    !nsown_capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tif (fs->users != 1)\n\t\treturn -EINVAL;\n\n\tget_mnt_ns(mnt_ns);\n\tput_mnt_ns(nsproxy->mnt_ns);\n\tnsproxy->mnt_ns = mnt_ns;\n\n\t/* Find the root */\n\troot.mnt    = &mnt_ns->root->mnt;\n\troot.dentry = mnt_ns->root->mnt.mnt_root;\n\tpath_get(&root);\n\twhile(d_mountpoint(root.dentry) && follow_down_one(&root))\n\t\t;\n\n\t/* Update the pwd and root */\n\tset_fs_pwd(fs, &root);\n\tset_fs_root(fs, &root);\n\n\tpath_put(&root);\n\treturn 0;\n}",
    "comment": "Validates permissions, checks filesystem usage, updates the mount namespace in the nsproxy, and sets the current process's root and working directory.",
    "prorec_sum": "Validates inode-related conditions before updating a file reference and performing subsequent filesystem operations on the associated directory entry.",
    "filter_prorec_sum": "Validates several conditions, updates a reference to a new object, and performs a series of linked data structure operations if the current state equals one.",
    "prorec_aug_sum": "Validates multiple conditions, updates a reference, processes data through several helper routines, and finalizes operations when a specific runtime flag equals one.",
    "filter_prorec_aug_sum": "Validates multiple conditions on input parameters, updates a shared pointer, and performs a sequence of synchronized operations on associated data structures.",
    "work_score": {
        "prorec": {
            "summary": "Validates inode-related conditions before updating a file reference and performing subsequent filesystem operations on the associated directory entry.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary inaccurately describes the code as validating inode-related conditions and updating a file reference, which is not reflected in the source. The function instead checks namespace capabilities, ensures 'fs->users' is 1, manages mount namespace references, retrieves and updates root and working directory paths. None of these involve inode-specific validation or a generic file reference update, making the summary largely irrelevant to the code semantics.",
                "The summary does not align with the actual core purpose of the function, which is installing a new mount namespace for a task after checking user capabilities and ensuring the fs_struct is singly referenced, then updating the task's root and current working directory. The summary inaccurately refers to inode-related conditions and generic file reference updates, which are not reflected in the source code, and thus fails to cover the core domain semantics.",
                "The summary is inaccurate as it introduces unrelated inode-related conditions and a file reference, which do not appear in the source code. The function actually checks for namespace capabilities and fs_struct user count before switching the mount namespace and updating root and working directory paths. This represents a severe FATAL error about the primary purpose, misrepresenting the core domain action and key I/O semantics, with no accurate claims to offset the error."
            ]
        },
        "filter_prorec": {
            "summary": "Validates several conditions, updates a reference to a new object, and performs a series of linked data structure operations if the current state equals one.",
            "score": [
                0.5,
                0.1,
                0.4
            ],
            "reason": [
                "The summary correctly notes that the function validates conditions and updates a reference to a new object, which matches the permission checks and namespace assignment in the code. However, the claim 'performs a series of linked data structure operations if the current state equals one' misrepresents the semantics: the check for fs->users == 1 is a condition to proceed, not a trigger for linked data structure operations. The summary omits key accurate details such as the specific capability checks and path root adjustments, making only about half of the claims accurate.",
                "The summary makes vague claims about validating conditions, updating a reference, and performing linked data structure operations, but it does not accurately capture the specific core purpose of installing a new mount namespace into the current process, nor does it mention the detailed permission checks (CAP_SYS_ADMIN, CAP_SYS_CHROOT), user count validation, root path adjustments, or namespace reference management. The lack of concrete domain wording and omission of critical behavior means the core is not covered and secondary details are absent.",
                "The summary captures some generic aspects such as validating conditions and updating a reference, but it omits key specifics from the source code, including capability checks, error codes, and precise operations on mount namespaces and file system paths. The statement 'if the current state equals one' is vague and misrepresents the actual check on fs->users == 1, making it an inaccurate, low-detail claim. Most information is broad and lacks domain-specific precision, with noticeable noise and low gain."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic void gen6_bsd_ring_write_tail(struct intel_ring_buffer *ring,\n\t\t\t\t     u32 value)\n{\n\tdrm_i915_private_t *dev_priv = ring->dev->dev_private;\n\n       /* Every tail move must follow the sequence below */\n\n\t/* Disable notification that the ring is IDLE. The GT\n\t * will then assume that it is busy and bring it out of rc6.\n\t */\n\tI915_WRITE(GEN6_BSD_SLEEP_PSMI_CONTROL,\n\t\t   _MASKED_BIT_ENABLE(GEN6_BSD_SLEEP_MSG_DISABLE));\n\n\t/* Clear the context id. Here be magic! */\n\tI915_WRITE64(GEN6_BSD_RNCID, 0x0);\n\n\t/* Wait for the ring not to be idle, i.e. for it to wake up. */\n\tif (wait_for((I915_READ(GEN6_BSD_SLEEP_PSMI_CONTROL) &\n\t\t      GEN6_BSD_SLEEP_INDICATOR) == 0,\n\t\t     50))\n\t\tDRM_ERROR(\"timed out waiting for the BSD ring to wake up\\n\");\n\n\t/* Now that the ring is fully powered up, update the tail */\n\tI915_WRITE_TAIL(ring, value);\n\tPOSTING_READ(RING_TAIL(ring->mmio_base));\n\n\t/* Let the ring send IDLE messages to the GT again,\n\t * and so let it sleep to conserve power when idle.\n\t */\n\tI915_WRITE(GEN6_BSD_SLEEP_PSMI_CONTROL,\n\t\t   _MASKED_BIT_DISABLE(GEN6_BSD_SLEEP_MSG_DISABLE));\n}",
    "comment": "Updates the tail of the BSD ring buffer after ensuring the ring is active and managing power-saving notifications.",
    "prorec_sum": "Writes commands to the BSD ring buffer and waits for it to become idle before issuing further GPU instructions.",
    "filter_prorec_sum": "Writes commands to the gen6 BSD hardware ring, waits for it to wake up with a timeout, then issues final control writes.",
    "prorec_aug_sum": "Writes commands to the BSD ring buffer and waits until it becomes ready, logging a timeout error if wake\u2011up does not occur.",
    "filter_prorec_aug_sum": "Writes commands to the Gen6 BSD ring buffer and waits for it to wake, timing out and logging an error if necessary.",
    "work_score": {
        "prorec": {
            "summary": "Writes commands to the BSD ring buffer and waits for it to become idle before issuing further GPU instructions.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims that the function writes commands to the BSD ring buffer and waits for it to become idle before issuing further GPU instructions. In the source code, the function writes to the BSD ring buffer tail but explicitly waits for the ring to wake up (become non-idle) before updating the tail, which contradicts the claim in the summary. This is a key semantic mismatch, making the primary claim inaccurate.",
                "The summary incorrectly states that the function waits for the BSD ring to become idle before proceeding, whereas the source code explicitly waits for the ring to wake up from idle. This is a fatal contradiction to the core behavior. The true core purpose\u2014bringing the BSD ring out of idle/power-saving, clearing context, waiting for readiness, then updating the tail\u2014is not captured accurately. Secondary operational details such as disabling/enabling sleep messages, clearing context ID, and handling timeouts are also omitted.",
                "The summary contains a fatal inaccuracy about the primary purpose: the code waits for the BSD ring to become active (not idle) before updating the tail, then re-enables idle messages. The claim that it waits for the ring to become idle directly contradicts the core behavior, which is to ensure the ring is powered up before writing. This misrepresentation of the core action makes the summary untrustworthy despite its concise form."
            ]
        },
        "filter_prorec": {
            "summary": "Writes commands to the gen6 BSD hardware ring, waits for it to wake up with a timeout, then issues final control writes.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly captures that the function writes to the Gen6 BSD ring, waits for it to wake up with a timeout, and then performs final control register writes. These correspond directly with the source code steps: issuing initial control writes to disable idle notification, clearing context, waiting for wake-up with a timeout, updating the tail, and re-enabling idle messages. The description is concise but omits some specifics (such as clearing the context ID), though all presented claims are accurate.",
                "The summary captures the core action of writing to the Gen6 BSD ring and includes accurate mention of waiting for it to wake with a timeout, which aligns with the function\u2019s primary purpose. However, it omits several secondary, behavior-critical details such as disabling/enabling idle notifications, clearing the context ID, the specific ordering of operations, posting reads for synchronization, and re-enabling power-saving modes. This results in incomplete coverage of the function\u2019s semantics beyond the core step.",
                "The summary captures the core sequence of actions: writing to the gen6 BSD ring, waiting for wakeup with a timeout, and performing control writes afterward. These are all accurate reflections of the source code and target its domain semantics correctly. However, the description is quite generic and omits key specifics such as disabling/enabling idle notifications, clearing the context ID, and updating the tail pointer, which limits its informativeness. No inaccurate or noisy claims are present, but the gain is low due to the lack of detail."
            ]
        }
    }
}
{
    "source_code": "int ata_qc_complete_multiple(struct ata_port *ap, u32 qc_active)\n{\n\tint nr_done = 0;\n\tu32 done_mask;\n\n\tdone_mask = ap->qc_active ^ qc_active;\n\n\tif (unlikely(done_mask & qc_active)) {\n\t\tata_port_err(ap, \"illegal qc_active transition (%08x->%08x)\\n\",\n\t\t\t     ap->qc_active, qc_active);\n\t\treturn -EINVAL;\n\t}\n\n\twhile (done_mask) {\n\t\tstruct ata_queued_cmd *qc;\n\t\tunsigned int tag = __ffs(done_mask);\n\n\t\tqc = ata_qc_from_tag(ap, tag);\n\t\tif (qc) {\n\t\t\tata_qc_complete(qc);\n\t\t\tnr_done++;\n\t\t}\n\t\tdone_mask &= ~(1 << tag);\n\t}\n\n\treturn nr_done;\n}",
    "comment": "Processes and completes multiple ATA queued commands based on the active command status while checking for illegal state transitions.",
    "prorec_sum": "Validates and updates qc_active state bits, logging illegal transitions and invoking handlers for each newly activated bit in the ATA port structure.",
    "filter_prorec_sum": "Validates qc_active bit transitions, logs illegal changes, and processes newly activated bits by invoking related handlers.",
    "prorec_aug_sum": "Validates and processes changes to a qc_active bitmask, logging illegal transitions and invoking handlers for each newly activated queue command slot.",
    "filter_prorec_aug_sum": "Validates and processes changes in qc_active bitmask, logging illegal transitions and invoking handlers for newly activated ATA queued commands.",
    "work_score": {
        "prorec": {
            "summary": "Validates and updates qc_active state bits, logging illegal transitions and invoking handlers for each newly activated bit in the ATA port structure.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary states that the function validates and updates qc_active bits and logs illegal transitions, which aligns with the code\u2019s XOR-based done_mask calculation and the error logging when invalid transitions are detected. However, it incorrectly claims that handlers are invoked for newly activated bits; in reality, the function iterates over bits transitioning from active to inactive (completed commands) and calls ata_qc_complete for each. This semantic error reduces the proportion of accurate claims to below half.",
                "The summary inaccurately describes the core behavior. The function identifies completed ATA queued commands by comparing current and new qc_active bits, logs an error for illegal transitions, and completes and counts commands for bits cleared in qc_active. The summary instead describes handling newly activated bits rather than completed ones, missing the core purpose and misrepresenting the domain semantics. Secondary details like completion counting are absent.",
                "The summary claims the function handles 'newly activated' bits, but the source code logic processes commands that have completed (bits that changed from active to inactive), making this a FATAL in describing the primary purpose. While it accurately notes validation of qc_active transitions and logging errors, the core semantic is misstated, which severely impacts trustworthiness."
            ]
        },
        "filter_prorec": {
            "summary": "Validates qc_active bit transitions, logs illegal changes, and processes newly activated bits by invoking related handlers.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function validates qc_active bit transitions and logs illegal changes, which aligns with the code's check using done_mask and ata_port_err. However, it inaccurately describes processing 'newly activated bits'\u2014in actuality, the function processes bits that have become inactive (completed commands) by invoking ata_qc_complete. This mischaracterization means less than half of the claims are accurate.",
                "The summary correctly notes validation of qc_active transitions and logging of illegal changes, aligning with the code's error check and message output. However, it inaccurately describes the core behavior: the function actually processes completed commands (bits cleared from qc_active), not newly activated bits. This means the core primary purpose of iterating over completed tags and invoking ata_qc_complete is missing, leading to a failure to cover the main domain action despite mentioning some secondary details.",
                "The summary correctly notes validation of qc_active transitions and logging of illegal changes, which matches the code's bitmask check and ata_port_err call. However, the claim that it processes newly activated bits is inaccurate: the function actually processes completed commands (bits that were active and are now inactive), not newly activated ones. This is a FATAL error about the core purpose of the function, significantly undermining trust in the description."
            ]
        }
    }
}
{
    "source_code": "\nstatic bin_tree_t *\nparse_reg_exp (re_string_t *regexp, regex_t *preg, re_token_t *token,\n\t       reg_syntax_t syntax, Idx nest, reg_errcode_t *err)\n{\n  re_dfa_t *dfa = preg->buffer;\n  bin_tree_t *tree, *branch = NULL;\n  bitset_word_t initial_bkref_map = dfa->completed_bkref_map;\n  tree = parse_branch (regexp, preg, token, syntax, nest, err);\n  if (__glibc_unlikely (*err != REG_NOERROR && tree == NULL))\n    return NULL;\n\n  while (token->type == OP_ALT)\n    {\n      fetch_token (token, regexp, syntax | RE_CARET_ANCHORS_HERE);\n      if (token->type != OP_ALT && token->type != END_OF_RE\n\t  && (nest == 0 || token->type != OP_CLOSE_SUBEXP))\n\t{\n\t  bitset_word_t accumulated_bkref_map = dfa->completed_bkref_map;\n\t  dfa->completed_bkref_map = initial_bkref_map;\n\t  branch = parse_branch (regexp, preg, token, syntax, nest, err);\n\t  if (__glibc_unlikely (*err != REG_NOERROR && branch == NULL))\n\t    {\n\t      if (tree != NULL)\n\t\tpostorder (tree, free_tree, NULL);\n\t      return NULL;\n\t    }\n\t  dfa->completed_bkref_map |= accumulated_bkref_map;\n\t}\n      else\n\tbranch = NULL;\n      tree = create_tree (dfa, tree, branch, OP_ALT);\n      if (__glibc_unlikely (tree == NULL))\n\t{\n\t  *err = REG_ESPACE;\n\t  return NULL;\n\t}\n    }\n  return tree;\n}",
    "comment": "Parses a regular expression into a binary tree structure while managing alternative branches and backreference mapping.",
    "prorec_sum": "Processes repeated type\u201110 records by invoking subordinate handlers, temporarily adjusting a link\u2011state field, and merging their results into a cumulative linked structure.",
    "filter_prorec_sum": "Processes and merges link-related symbol data in a loop when a specific flag is set, handling errors and restoring state appropriately.",
    "prorec_aug_sum": "Processes input records with type 10 by repeatedly merging results from two retrieval calls, updating state fields, and handling error or cleanup conditions.",
    "filter_prorec_aug_sum": "Processes input records with type 10 by repeatedly merging parsed results and updating state, handling errors via cleanup and restoring section pointer values.",
    "work_score": {
        "prorec": {
            "summary": "Processes repeated type\u201110 records by invoking subordinate handlers, temporarily adjusting a link\u2011state field, and merging their results into a cumulative linked structure.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary describes processing 'type\u201110 records' with subordinate handlers and a link\u2011state field, which is unrelated to the actual source code. The function in the source code parses regular expression branches with alternation operators, manages backreference maps, and constructs a binary tree. None of the summary's claims match the domain-specific behavior of the code, resulting in no accurate claims.",
                "The summary describes processing of 'type-10 records' with subordinate handlers, link-state adjustments, and merging into a linked structure, which does not align with the actual source code that parses regular expressions, handles alternation tokens, manages back-reference maps, and constructs a syntax tree. The core primary purpose of parsing branches with alternation in regex syntax is entirely missing, and none of the summary's claims accurately target the code's domain semantics.",
                "The summary's claims about handling 'type\u201110 records', adjusting a 'link\u2011state field', and merging results into a cumulative linked structure do not correspond to the source code, which parses regular expression branches with alternation, manages backreference maps, and constructs a binary tree. These are domain\u2011semantic contradictions targeting the core purpose and key data handling of the function, representing a severe FATAL error on the primary purpose, making the description unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Processes and merges link-related symbol data in a loop when a specific flag is set, handling errors and restoring state appropriately.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims that the function processes and merges link-related symbol data based on a flag, which does not align with the source code. The actual code parses regular expressions, handling alternation (OP_ALT) tokens, maintaining and restoring back-reference maps, and managing errors. None of the described behaviors in the summary are accurate with respect to the code\u2019s semantics, resulting in all claims being inaccurate.",
                "The summary's claim about processing and merging link-related symbol data under a flag does not match the source code, which parses regular expression branches, handles alternations, manages back-reference maps, and error conditions. The core purpose of parsing and constructing a regex syntax tree is completely absent, and the provided description targets unrelated semantics, making it inaccurate with no coverage of the actual logic.",
                "The summary's claims about processing and merging link-related symbol data under a specific flag are entirely unrelated to the actual source code, which parses regular expression branches, handles alternation tokens, manages backreference maps, and constructs a binary tree. This is a severe FATAL error affecting the primary purpose description, making the summary unusable for understanding the function."
            ]
        }
    }
}
{
    "source_code": "static int\nefivar_create_sysfs_entry(struct efivar_entry *new_var)\n{\n\tint i, short_name_size;\n\tchar *short_name;\n\tunsigned long variable_name_size;\n\tefi_char16_t *variable_name;\n\n\tvariable_name = new_var->var.VariableName;\n\tvariable_name_size = ucs2_strlen(variable_name) * sizeof(efi_char16_t);\n\n\t/*\n\t * Length of the variable bytes in ASCII, plus the '-' separator,\n\t * plus the GUID, plus trailing NUL\n\t */\n\tshort_name_size = variable_name_size / sizeof(efi_char16_t)\n\t\t\t\t+ 1 + EFI_VARIABLE_GUID_LEN + 1;\n\n\tshort_name = kzalloc(short_name_size, GFP_KERNEL);\n\n\tif (!short_name)\n\t\treturn 1;\n\n\t/* Convert Unicode to normal chars (assume top bits are 0),\n\t   ala UTF-8 */\n\tfor (i=0; i < (int)(variable_name_size / sizeof(efi_char16_t)); i++) {\n\t\tshort_name[i] = variable_name[i] & 0xFF;\n\t}\n\t/* This is ugly, but necessary to separate one vendor's\n\t   private variables from another's.         */\n\n\t*(short_name + strlen(short_name)) = '-';\n\tefi_guid_unparse(&new_var->var.VendorGuid,\n\t\t\t short_name + strlen(short_name));\n\n\tnew_var->kobj.kset = efivars_kset;\n\n\ti = kobject_init_and_add(&new_var->kobj, &efivar_ktype,\n\t\t\t\t   NULL, \"%s\", short_name);\n\tkfree(short_name);\n\tif (i)\n\t\treturn 1;\n\n\tkobject_uevent(&new_var->kobj, KOBJ_ADD);\n\tefivar_entry_add(new_var, &efivar_sysfs_list);\n\n\treturn 0;\n}",
    "comment": "Creates a sysfs entry for a new EFI variable by converting its Unicode name to ASCII and adding it to the kernel's object hierarchy.",
    "prorec_sum": "Formats a memory buffer with a \u201c%pUl\u201d identifier, updates device-specific pointers, and registers the prepared data structure for further processing.",
    "filter_prorec_sum": "Formats a string containing a GUID with the \"%pUl\" specifier, stores it in a buffer, and registers it into the object's data structure.",
    "prorec_aug_sum": "Allocates and formats a buffer with a device identifier, updates related state pointers, invokes registration routines, and finalizes associated device setup.",
    "filter_prorec_aug_sum": "Formats and sends a \"%pUl\" identifier to a hardware-related structure, updates associated pointers, and finalizes with a device-specific handler call.",
    "work_score": {
        "prorec": {
            "summary": "Formats a memory buffer with a \u201c%pUl\u201d identifier, updates device-specific pointers, and registers the prepared data structure for further processing.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function formats a memory buffer with a '%pUl' identifier, updates device-specific pointers, and registers a prepared data structure. The source code shows conversion of a Unicode variable name to ASCII, appending a GUID, creating and adding a kobject to sysfs, but there is no '%pUl' formatting or explicit device-specific pointer updates. Only the registration aspect loosely matches. Most claims are inaccurate or not supported by the code, leading to low accuracy.",
                "The summary's claims about formatting a buffer with a '%pUl' identifier, updating device-specific pointers, and registering a data structure do not match the source code's actual behavior. The function converts a Unicode EFI variable name to ASCII, appends a GUID, creates and adds a sysfs kobject, and adds the entry to a list. None of these domain-specific actions are accurately described, so the core purpose is not covered and no accurate secondary details are provided.",
                "The summary contains multiple inaccurate claims about the core behavior. It describes formatting with a '%pUl' identifier, updating device-specific pointers, and registering a prepared data structure, none of which match the actual source code\u2019s primary purpose. The code constructs a short_name from an EFI variable name and GUID, initializes and adds a kobject to sysfs, and emits a uevent. These contradictions affect the primary purpose (what the function does), making the inaccuracies severe and rendering the summary untrustworthy."
            ]
        },
        "filter_prorec": {
            "summary": "Formats a string containing a GUID with the \"%pUl\" specifier, stores it in a buffer, and registers it into the object's data structure.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function uses the \"%pUl\" specifier to format a GUID and store it in a buffer, but the source code instead uses `efi_guid_unparse` and manual string manipulation. The claim about registering it into the object's data structure is partially aligned with the code's initialization of `new_var->kobj` and adding the entry, but the formatting detail is inaccurate. Overall, most claims are incorrect or misleading about actual code semantics.",
                "The summary inaccurately describes the function's core behavior. It claims the use of the \"%pUl\" specifier to format a GUID, which is not present in the source code. The actual function converts a Unicode variable name to ASCII, appends a '-' and formats the GUID using efi_guid_unparse, then creates and registers a sysfs kobject. This core operation is completely missing from the summary, and the provided description misrepresents the code's semantics, offering no accurate coverage of the primary purpose or secondary details.",
                "The summary introduces a FATAL inaccuracy about the primary purpose: it claims the function formats a GUID using the \"%pUl\" specifier, which does not occur in the source. The actual code converts a Unicode variable name to ASCII, appends a dash and GUID via efi_guid_unparse, and registers the variable in sysfs. This misstatement of the core action and omission of most actual steps make the description untrustworthy despite touching related concepts like storing GUIDs."
            ]
        }
    }
}
{
    "source_code": "\nvoid __cpuinit start_secondary(void)\n{\n\tunsigned int cpu;\n\tunsigned long thread_ptr;\n\n\t/*  Calculate thread_info pointer from stack pointer  */\n\t__asm__ __volatile__(\n\t\t\"%0 = SP;\\n\"\n\t\t: \"=r\" (thread_ptr)\n\t);\n\n\tthread_ptr = thread_ptr & ~(THREAD_SIZE-1);\n\n\t__asm__ __volatile__(\n\t\tQUOTED_THREADINFO_REG \" = %0;\\n\"\n\t\t:\n\t\t: \"r\" (thread_ptr)\n\t);\n\n\t/*  Set the memory struct  */\n\tatomic_inc(&init_mm.mm_count);\n\tcurrent->active_mm = &init_mm;\n\n\tcpu = smp_processor_id();\n\n\tsetup_irq(BASE_IPI_IRQ + cpu, &ipi_intdesc);\n\n\t/*  Register the clock_event dummy  */\n\tsetup_percpu_clockdev();\n\n\tprintk(KERN_INFO \"%s cpu %d\\n\", __func__, current_thread_info()->cpu);\n\n\tnotify_cpu_starting(cpu);\n\n\tset_cpu_online(cpu, true);\n\n\tlocal_irq_enable();\n\n\tcpu_startup_entry(CPUHP_ONLINE);\n}",
    "comment": "Initializes the secondary CPU by configuring memory management, enabling interrupts, and signaling readiness for operation within a multiprocessor environment.",
    "prorec_sum": "Initializes and synchronizes a secondary CPU during SMP startup, performing setup, waiting for readiness, and enabling interrupts before resuming execution.",
    "filter_prorec_sum": "Initializes and synchronizes a CPU during SMP startup, setting per\u2011CPU state, invoking init callbacks, and enabling it for scheduling.",
    "prorec_aug_sum": "Initializes and synchronizes a CPU during SMP startup, performing hardware setup, time initialization, memory mapping, and enabling interrupts before entering normal operation.",
    "filter_prorec_aug_sum": "Initializes a secondary CPU during SMP boot, synchronizing with startup flags, setting per\u2011CPU data, and enabling it for normal operation.",
    "work_score": {
        "prorec": {
            "summary": "Initializes and synchronizes a secondary CPU during SMP startup, performing setup, waiting for readiness, and enabling interrupts before resuming execution.",
            "score": [
                0.5,
                0.4,
                0.5
            ],
            "reason": [
                "The summary captures the general idea that the function is part of SMP startup and involves setting up and enabling interrupts for a secondary CPU, which aligns broadly with the source code's operations like setting active_mm, registering IRQs, enabling local interrupts, and marking the CPU online. However, it inaccurately adds non-existent behavior such as 'synchronizing', 'waiting for readiness', and 'resuming execution', which are not present in the code. This introduces notable inaccuracies despite some correct elements.",
                "The summary does identify that the function initializes a secondary CPU in SMP startup and enables interrupts, which matches the core action in the code. However, it omits many specific secondary behaviors present, such as calculating and storing the thread_info pointer from the stack, incrementing init_mm.mm_count, setting active_mm, setting up inter-processor interrupt handlers, registering a per-CPU clock device, notifying CPU startup state, and marking the CPU online. Additionally, the phrase 'waiting for readiness' is not supported by the source code and is inaccurate.",
                "The summary correctly identifies that the function deals with secondary CPU initialization in SMP, which is broadly accurate, but it adds inaccurate elements such as 'waiting for readiness' and 'resuming execution' that are not present in the source code. The description lacks mention of specific, verifiable steps like calculating the thread_info pointer, setting up IRQs, and registering the clock device. This results in mostly generic SAFE claims mixed with NOISE, with no FATAL on the primary purpose but low informational gain overall."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes and synchronizes a CPU during SMP startup, setting per\u2011CPU state, invoking init callbacks, and enabling it for scheduling.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary accurately reflects the core semantics of the function: it describes SMP startup, per\u2011CPU state initialization, invoking startup notifications/callbacks, and enabling the CPU for scheduling, all of which are evident in the source via setting active_mm, registering interrupts, calling notify_cpu_starting, set_cpu_online, and cpu_startup_entry. The claims are domain\u2011specific and match the code behavior with no evident inaccuracies, leading to a high proportion of accurate statements.",
                "The summary accurately captures the core purpose\u2014starting and initializing a secondary CPU in SMP by setting per\u2011CPU state, running init callbacks, and enabling scheduling\u2014which aligns with the code\u2019s main behavior. However, it fails to mention several secondary details such as calculating and storing the thread_info pointer from the stack pointer, incrementing init_mm.mm_count, setting active_mm, registering the per\u2011CPU clock device, and establishing IRQ handlers. These omissions limit coverage of other behavior-critical semantics.",
                "The summary contains one primary claim: that the function initializes and synchronizes a CPU during SMP startup, sets per\u2011CPU state, invokes init callbacks, and enables it for scheduling. This is broadly accurate regarding the core purpose and behavior: the source code sets up per\u2011CPU memory structures, registers interrupts, enables the CPU, and enters the startup loop. However, the summary is generic and omits specifics such as calculating the thread_info pointer, setting active_mm, configuring IPI IRQs, and setting up the per\u2011CPU clock device. No inaccurate or contradictory statements are present, but the level of detail is low, limiting its benefit."
            ]
        }
    }
}
{
    "source_code": "\nstatic acpi_status acpi_dev_process_resource(struct acpi_resource *ares,\n\t\t\t\t\t     void *context)\n{\n\tstruct res_proc_context *c = context;\n\tstruct resource r;\n\tint i;\n\n\tif (c->preproc) {\n\t\tint ret;\n\n\t\tret = c->preproc(ares, c->preproc_data);\n\t\tif (ret < 0) {\n\t\t\tc->error = ret;\n\t\t\treturn AE_CTRL_TERMINATE;\n\t\t} else if (ret > 0) {\n\t\t\treturn AE_OK;\n\t\t}\n\t}\n\n\tmemset(&r, 0, sizeof(r));\n\n\tif (acpi_dev_resource_memory(ares, &r)\n\t    || acpi_dev_resource_io(ares, &r)\n\t    || acpi_dev_resource_address_space(ares, &r)\n\t    || acpi_dev_resource_ext_address_space(ares, &r))\n\t\treturn acpi_dev_new_resource_entry(&r, c);\n\n\tfor (i = 0; acpi_dev_resource_interrupt(ares, i, &r); i++) {\n\t\tacpi_status status;\n\n\t\tstatus = acpi_dev_new_resource_entry(&r, c);\n\t\tif (ACPI_FAILURE(status))\n\t\t\treturn status;\n\t}\n\n\treturn AE_OK;\n}",
    "comment": "Processes ACPI resources by calling preprocessing functions, handling memory, I/O, and address space resources, and creating new resource entries as needed.",
    "prorec_sum": "Processes hardware or ACPI data from the given structure, invoking resource-specific handlers and iterating elements to apply a standardized processing routine with error handling.",
    "filter_prorec_sum": "Processes hardware resource data from an input structure, invoking specific handlers and performing iterative operations to update the target structure with provided parameters.",
    "prorec_aug_sum": "Processes ACPI operand data by invoking region handlers or iterating field extraction routines, then dispatches results to a common evaluation function with provided parameters.",
    "filter_prorec_aug_sum": "Processes an ACPI operand by invoking its handler or iterating field elements, populating a local buffer, and executing a common evaluation routine.",
    "work_score": {
        "prorec": {
            "summary": "Processes hardware or ACPI data from the given structure, invoking resource-specific handlers and iterating elements to apply a standardized processing routine with error handling.",
            "score": [
                0.6,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly captures the general purpose of processing ACPI resource data, invoking specialized handlers, iterating over elements, and handling errors, which aligns with the source code logic. However, it remains high-level and omits specifics such as the handling of memory, I/O, and address space resources, the use of a preprocessor function with early termination conditions, and the explicit loop over interrupts. These omissions reduce precision, leading to a mix of accurate but generic statements rather than highly specific verifiable claims.",
                "The summary correctly notes that the function processes ACPI/hardware data using resource-specific handlers and applies error handling, which aligns with the ACPI resource extraction and iteration in the code. However, it fails to cover the core primary purpose with sufficient domain specificity\u2014i.e., extracting and creating new resource entries from various ACPI resource types and interrupt resources. It omits critical details such as the conditional pre-processing step, handling multiple resource types explicitly, and the branching based on return values. The coverage of secondary points is minimal beyond a generic mention of iteration and error handling.",
                "The summary captures the general idea that the function processes ACPI resource data with specific handlers and includes error handling, which matches the code\u2019s use of preproc callbacks, resource-specific functions, and iteration over interrupts. However, it remains generic, omitting specific conditions such as the return behavior when memory/IO/address space resources are found or how interrupt resources are processed individually. No claims contradict the code, but the lack of detailed GOLD information makes the gain low and leans toward SAFE accuracy with minimal insight."
            ]
        },
        "filter_prorec": {
            "summary": "Processes hardware resource data from an input structure, invoking specific handlers and performing iterative operations to update the target structure with provided parameters.",
            "score": [
                0.5,
                0.2,
                0.5
            ],
            "reason": [
                "The summary contains very generic statements about processing hardware resources, invoking handlers, and iterating to update a structure, which loosely matches the code but lacks specific accuracy about the conditional pre-processing, different resource type checks, and termination/error handling. While it aligns broadly with the function\u2019s purpose, it omits several critical details and uses vague language, making only part of the claims clearly accurate.",
                "The summary generically states processing hardware resource data and invoking handlers, but it does not explicitly cover the core purpose of identifying and converting ACPI resource types (memory, I/O, address space, interrupts) into new resource entries in the given context. While it loosely refers to iterative operations and updating a structure, it omits specific ACPI semantics, branching on preproc return values, and handling of multiple resource types, resulting in core purpose not being properly covered and minimal secondary detail.",
                "The summary is broadly correct in describing that the function processes hardware resource data and calls specific handlers, but it is vague and omits key details such as the conditional use of a pre-processing callback, handling of early termination based on return codes, distinct processing of different resource types, and iterative addition of interrupt resources. The claims are mostly generic SAFE statements with little domain-specific insight, and there is no clear FATAL error, but the low specificity yields only limited net benefit."
            ]
        }
    }
}
{
    "source_code": "\nvoid native_play_dead(void)\n{\n\tplay_dead_common();\n\ttboot_shutdown(TB_SHUTDOWN_WFS);\n\n\tmwait_play_dead();\t/* Only returns on failure */\n\tif (cpuidle_play_dead())\n\t\thlt_play_dead();\n}",
    "comment": "Initiates a shutdown sequence and enters a low-power state, managing transitions based on CPU idle status and system power states.",
    "prorec_sum": "Initializes CPU idle monitoring using MONITOR/MWAIT instructions when specific hardware conditions are met, otherwise handles CPU bug checks and halts if critical errors occur.",
    "filter_prorec_sum": "Monitors a specific memory location using CPU MWAIT until triggered, then executes a handler, otherwise halts the processor under certain system state conditions.",
    "prorec_aug_sum": "Puts the CPU into a monitored low\u2011power idle state using MWAIT after cache flush, based on specific system and processor capability checks.",
    "filter_prorec_aug_sum": "Initializes CPU cache monitoring parameters and repeatedly enters low-power wait states until a wake condition occurs, then handles system halt on critical state.",
    "work_score": {
        "prorec": {
            "summary": "Initializes CPU idle monitoring using MONITOR/MWAIT instructions when specific hardware conditions are met, otherwise handles CPU bug checks and halts if critical errors occur.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary introduces claims about initializing CPU idle monitoring using MONITOR/MWAIT under certain hardware conditions and performing CPU bug checks with halting on critical errors. The source code simply calls functions related to 'play dead' states, including tboot shutdown, mwait_play_dead, cpuidle_play_dead, and hlt_play_dead, without explicit references to MONITOR/MWAIT instructions, hardware condition checks, or bug checking logic. These discrepancies mean the claims are largely inaccurate regarding the actual code semantics.",
                "The summary does not describe the core purpose of the function, which is to execute a CPU play-dead sequence by calling play_dead_common(), initiating a tboot shutdown, attempting mwait-based idle, and, if necessary, using cpuidle and halt mechanisms. Instead, it mentions CPU idle monitoring, MONITOR/MWAIT instructions, and CPU bug checks, which are either incorrect or unrelated to the specific semantics in the source code. It fails to capture the shutdown and failover steps entirely.",
                "The summary contains several inaccurate claims: it asserts that the function initializes CPU idle monitoring using MONITOR/MWAIT, relies on specific hardware conditions, and performs CPU bug checks for critical errors, none of which are evident in the source code. The actual code calls `play_dead_common`, initiates a tboot shutdown, uses `mwait_play_dead` until failure, then conditionally calls `cpuidle_play_dead` and `hlt_play_dead`. No MONITOR instruction or bug check logic is present. These inaccuracies target the core behavior, making them FATAL errors on the primary purpose, thus greatly reducing trustworthiness."
            ]
        },
        "filter_prorec": {
            "summary": "Monitors a specific memory location using CPU MWAIT until triggered, then executes a handler, otherwise halts the processor under certain system state conditions.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes monitoring a memory location with MWAIT and triggering a handler, which is not reflected in the source. The code invokes play_dead_common(), tboot_shutdown(), then mwait_play_dead(), and conditionally calls cpuidle_play_dead() and hlt_play_dead(). No memory monitoring or specific handler logic is evident, and the halt is conditional, not tied to 'specific system state conditions' as implied. Most claims are inaccurate regarding the actual function behavior.",
                "The summary misinterprets the function\u2019s purpose, describing memory monitoring and triggers via MWAIT that are not present in the source code. The actual core purpose is to execute a sequence of play_dead procedures\u2014calling common shutdown routines, attempting mwait-based dead states, then CPU idle and halt variants if needed. The core behavior of shutting down and entering a dead state is not covered, and the claims are inaccurate with respect to the actual operations, resulting in no alignment.",
                "The summary is inaccurate about the code's core purpose. It claims the function monitors a memory location with MWAIT and executes a handler, which is not reflected in the source. The code actually calls play_dead_common(), initiates a shutdown via tboot_shutdown(), then attempts to enter CPU low-power states through mwait_play_dead(), cpuidle_play_dead(), or hlt_play_dead. The erroneous MWAIT monitoring description is a FATAL error targeting the primary purpose, making the summary misleading. No accurate, high-gain details are present to offset the inaccuracy."
            ]
        }
    }
}
{
    "source_code": "static int apply_envelope(struct ml_effect_state *state, int value,\n\t\t\t  struct ff_envelope *envelope)\n{\n\tstruct ff_effect *effect = state->effect;\n\tunsigned long now = jiffies;\n\tint time_from_level;\n\tint time_of_envelope;\n\tint envelope_level;\n\tint difference;\n\n\tif (envelope->attack_length &&\n\t    time_before(now,\n\t\t\tstate->play_at + msecs_to_jiffies(envelope->attack_length))) {\n\t\tpr_debug(\"value = 0x%x, attack_level = 0x%x\\n\",\n\t\t\t value, envelope->attack_level);\n\t\ttime_from_level = jiffies_to_msecs(now - state->play_at);\n\t\ttime_of_envelope = envelope->attack_length;\n\t\tenvelope_level = min_t(u16, envelope->attack_level, 0x7fff);\n\n\t} else if (envelope->fade_length && effect->replay.length &&\n\t\t   time_after(now,\n\t\t\t      state->stop_at - msecs_to_jiffies(envelope->fade_length)) &&\n\t\t   time_before(now, state->stop_at)) {\n\t\ttime_from_level = jiffies_to_msecs(state->stop_at - now);\n\t\ttime_of_envelope = envelope->fade_length;\n\t\tenvelope_level = min_t(u16, envelope->fade_level, 0x7fff);\n\t} else\n\t\treturn value;\n\n\tdifference = abs(value) - envelope_level;\n\n\tpr_debug(\"difference = %d\\n\", difference);\n\tpr_debug(\"time_from_level = 0x%x\\n\", time_from_level);\n\tpr_debug(\"time_of_envelope = 0x%x\\n\", time_of_envelope);\n\n\tdifference = difference * time_from_level / time_of_envelope;\n\n\tpr_debug(\"difference = %d\\n\", difference);\n\n\treturn value < 0 ?\n\t\t-(difference + envelope_level) : (difference + envelope_level);\n}",
    "comment": "Adjusts the input value based on an attack or fade envelope, modifying the output according to the elapsed time and specified envelope levels.",
    "prorec_sum": "Adjusts an input value toward a target limit based on buffer occupancy thresholds and scaling factors from provided parameters.",
    "filter_prorec_sum": "Calculates and returns a rate-adjusted value based on input signal parameters, enforcing limits and bounds from current buffer and timing constraints.",
    "prorec_aug_sum": "Adjusts a signed input value based on threshold checks and scaling calculations using fields from two data structures and given 16\u2011bit parameters.",
    "filter_prorec_aug_sum": "Adjusts an input value proportionally based on threshold checks and scaling parameters retrieved from the provided data structure and measurement function.",
    "work_score": {
        "prorec": {
            "summary": "Adjusts an input value toward a target limit based on buffer occupancy thresholds and scaling factors from provided parameters.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function adjusts an input value based on buffer occupancy thresholds and scaling factors, which is not reflected in the source code. The source code shows the function applies an envelope effect using attack and fade lengths, calculating adjustments based on time from play/stop and envelope levels, without any mention of buffer occupancy or generic scaling factors. All claims in the summary are inaccurate relative to the actual code.",
                "The summary's claim about adjusting an input based on buffer occupancy thresholds and scaling factors does not align with the actual code, which applies an attack/fade envelope to a force-feedback effect value using timing relative to play/stop times and envelope levels. The core primary purpose of applying the envelope based on attack/fade timing and levels is entirely missing, and no accurate claims from the summary match or cover it. The provided description is not grounded in the code's semantics and introduces unrelated concepts.",
                "The summary claims the function adjusts an input value based on buffer occupancy thresholds and scaling factors, which does not match the source code. The code applies an attack/fade envelope to a force feedback effect using timing values and envelope levels, with no mention of buffer occupancy or target limits. This is a FATAL error about the primary purpose, making the description misleading and unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Calculates and returns a rate-adjusted value based on input signal parameters, enforcing limits and bounds from current buffer and timing constraints.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is overly generic and does not accurately capture the specific envelope application logic visible in the source code. It fails to mention critical aspects such as handling attack and fade lengths, timing comparisons using jiffies, conditional calculation of envelope level, and the adjustment of the input value based on these envelope parameters. While it alludes to timing constraints, it omits enough domain-specific details that most of its claims are either low-information or vague, resulting in less than half of the claims being precise and verifiable against the code.",
                "The summary gives a vague description of calculating a rate-adjusted value with limits and timing constraints, but it does not capture the core purpose of applying an FF envelope's attack or fade parameters to the effect value based on jiffies and envelope lengths. It misses key specifics like handling attack_level/fade_level, time_from_level, and replay length, and omits the conditional logic for different envelope phases. The wording is generic and not grounded in the concrete domain semantics of force feedback envelope processing in the code.",
                "The summary\u2019s main claim about calculating a 'rate-adjusted value' based on input parameters has some vague alignment with the function\u2019s adjustment of the input value using envelope attack/fade timing, but it omits key specifics such as envelope levels, attack/fade conditions, and how timing differences are computed. References to 'current buffer' and 'timing constraints' are inaccurate or misleading because the code does not involve any buffer management, and timing constraints are specifically related to jiffies-based attack/fade periods. The omissions and incorrect terms introduce noise; however, no fatal contradictions about the core purpose occur, and some alignment exists in that the function transforms the value based on timing."
            ]
        }
    }
}
{
    "source_code": "\nvoid write_xattr(char *pathname, unsigned int xattr)\n{\n\tunsigned int count;\n\tstruct xattr_list *xattr_list;\n\tint i;\n\tstatic int nonsuper_error = FALSE;\n\tstatic int ignore_xattrs = FALSE;\n\tstatic int nospace_error = 0;\n\n\tif(ignore_xattrs || xattr == SQUASHFS_INVALID_XATTR ||\n\t\t\tsBlk.s.xattr_id_table_start == SQUASHFS_INVALID_BLK)\n\t\treturn;\n\n\txattr_list = get_xattr(xattr, &count, 1);\n\tif(xattr_list == NULL) {\n\t\tERROR(\"Failed to read xattrs for file %s\\n\", pathname);\n\t\treturn;\n\t}\n\n\tfor(i = 0; i < count; i++) {\n\t\tint prefix = xattr_list[i].type & SQUASHFS_XATTR_PREFIX_MASK;\n\n\t\tif(user_xattrs && prefix != SQUASHFS_XATTR_USER)\n\t\t\tcontinue;\n\n\t\tif(root_process || prefix == SQUASHFS_XATTR_USER) {\n\t\t\tint res = lsetxattr(pathname, xattr_list[i].full_name,\n\t\t\t\txattr_list[i].value, xattr_list[i].vsize, 0);\n\n\t\t\tif(res == -1) {\n\t\t\t\tif(errno == ENOTSUP) {\n\t\t\t\t\t/*\n\t\t\t\t\t * If the destination filesystem cannot\n\t\t\t\t\t * suppport xattrs, print error, and\n\t\t\t\t\t * disable xattr output as this error is\n\t\t\t\t\t * unlikely to go away, and printing\n\t\t\t\t\t * screenfulls of the same error message\n\t\t\t\t\t * is rather annoying\n\t\t\t\t\t */\n\t\t\t\t\tERROR(\"write_xattr: failed to write \"\n\t\t\t\t\t\t\"xattr %s for file %s because \" \n\t\t\t\t\t\t\"extended attributes are not \"\n\t\t\t\t\t\t\"supported by the destination \"\n\t\t\t\t\t\t\"filesystem\\n\",\n\t\t\t\t\t\txattr_list[i].full_name,\n\t\t\t\t\t\tpathname);\n\t\t\t\t\tERROR(\"Ignoring xattrs in \"\n\t\t\t\t\t\t\t\t\"filesystem\\n\");\n\t\t\t\t\tERROR(\"To avoid this error message, \"\n\t\t\t\t\t\t\"specify -no-xattrs\\n\");\n\t\t\t\t\tignore_xattrs = TRUE;\n\t\t\t\t} else if((errno == ENOSPC || errno == EDQUOT)\n\t\t\t\t\t\t&& nospace_error < NOSPACE_MAX) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Many filesystems like ext2/3/4 have\n\t\t\t\t\t * limits on the amount of xattr\n\t\t\t\t\t * data that can be stored per file\n\t\t\t\t\t * (typically one block or 4K), so\n\t\t\t\t\t * we shouldn't disable xattr ouput,\n\t\t\t\t\t * as the error may be restriced to one\n\t\t\t\t\t * file only.  If we get a lot of these\n\t\t\t\t\t * then suppress the error messsage\n\t\t\t\t\t */\n\t\t\t\t\tERROR(\"write_xattr: failed to write \"\n\t\t\t\t\t\t\"xattr %s for file %s because \" \n\t\t\t\t\t\t\"no extended attribute space \"\n\t\t\t\t\t\t\"remaining (per file or \"\n\t\t\t\t\t\t\"filesystem limit)\\n\",\n\t\t\t\t\t\txattr_list[i].full_name,\n\t\t\t\t\t\tpathname);\n\t\t\t\t\tif(++ nospace_error == NOSPACE_MAX)\n\t\t\t\t\t\tERROR(\"%d of these errors \"\n\t\t\t\t\t\t\t\"printed, further error \"\n\t\t\t\t\t\t\t\"messages of this type \"\n\t\t\t\t\t\t\t\"are suppressed!\\n\",\n\t\t\t\t\t\t\tNOSPACE_MAX);\n\t\t\t\t} else\n\t\t\t\t\tERROR(\"write_xattr: failed to write \"\n\t\t\t\t\t\t\"xattr %s for file %s because \"\n\t\t\t\t\t\t\"%s\\n\", xattr_list[i].full_name,\n\t\t\t\t\t\tpathname, strerror(errno));\n\t\t\t}\n\t\t} else if(nonsuper_error == FALSE) {\n\t\t\t/*\n\t\t\t * if extract user xattrs only then\n\t\t\t * error message is suppressed, if not\n\t\t\t * print error, and then suppress further error\n\t\t\t * messages to avoid possible screenfulls of the\n\t\t\t * same error message!\n\t\t\t */\n\t\t\tERROR(\"write_xattr: could not write xattr %s \"\n\t\t\t\t\t\"for file %s because you're not \"\n\t\t\t\t\t\"superuser!\\n\",\n\t\t\t\t\txattr_list[i].full_name, pathname);\n\t\t\tERROR(\"write_xattr: to avoid this error message, either\"\n\t\t\t\t\" specify -user-xattrs, -no-xattrs, or run as \"\n\t\t\t\t\"superuser!\\n\");\n\t\t\tERROR(\"Further error messages of this type are \"\n\t\t\t\t\"suppressed!\\n\");\n\t\t\tnonsuper_error = TRUE;\n\t\t}\n\t}\n\n\tfree_xattr(xattr_list, count);\n}",
    "comment": "Writes extended attributes to a specified file while handling errors for unsupported filesystems, space limitations, and non-superuser access.",
    "prorec_sum": "Sets multiple extended file attributes on the specified path from provided data and handles specific errno cases with retries or state flags.",
    "filter_prorec_sum": "Sets multiple extended file attributes on the given path from retrieved records, handling specific errno conditions and updating related global error state flags.",
    "prorec_aug_sum": "Sets extended file attributes on the given path from retrieved metadata, handling specific errno cases and updating related global error state flags.",
    "filter_prorec_aug_sum": "Sets extended file attributes from a descriptor onto the specified path, handling specific errno cases and maintaining related operation state flags.",
    "work_score": {
        "prorec": {
            "summary": "Sets multiple extended file attributes on the specified path from provided data and handles specific errno cases with retries or state flags.",
            "score": [
                0.7,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly notes that the function sets multiple extended file attributes on the given path and handles specific errno cases using state flags. However, it inaccurately mentions retries, which the source does not perform; instead, errors lead to suppression or disabling behavior. Overall, most claims are accurate but there is a clear semantic error about retry handling.",
                "The summary correctly notes that the function sets multiple extended file attributes from provided data and handles specific errno cases using state flags, which aligns with the core purpose of applying xattrs and managing error states like ENOTSUP, ENOSPC, and permission issues. However, it overgeneralizes 'retries' where the code actually continues processing rather than retrying failed writes, and omits key specifics such as filtering attributes by prefix, conditional writes based on root/user flags, suppression of repeated error messages, and the interplay of ignore_xattrs and nospace_error thresholds. Coverage of the core purpose is solid, but important secondary details are lacking.",
                "The summary correctly states that the function sets multiple extended file attributes on a specified path and that it handles specific errno cases using state flags, which matches the code\u2019s loop writing multiple xattrs and its conditional handling of ENOTSUP, ENOSPC/EDQUOT, and non\u2011superuser cases. However, the mention of 'retries' is inaccurate\u2014there is no retry logic in the code. This is a minor semantic error but not a FATAL on primary purpose. Overall, the summary is mostly accurate with slight noise from the incorrect retry claim."
            ]
        },
        "filter_prorec": {
            "summary": "Sets multiple extended file attributes on the given path from retrieved records, handling specific errno conditions and updating related global error state flags.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function sets multiple extended file attributes from retrieved records, which matches the loop over `xattr_list` and calls to `lsetxattr`. It also notes handling of specific errno conditions and updating global error state flags, which corresponds to the ENOTSUP, ENOSPC/EDQUOT, and nonsuper_error cases as well as the modifications to `ignore_xattrs` and `nospace_error`. Although somewhat condensed, all claims are accurate and grounded in the source code with no contradictory or irrelevant statements.",
                "The summary correctly captures the core purpose: applying multiple extended attributes to a specified path based on retrieved data. It also notes handling of specific errno values and updating global state flags, which aligns with the code's error handling for unsupported xattrs, no space, and non-superuser cases. However, it omits several detailed behaviors such as filtering prefixes with user_xattrs/root_process logic, conditions that skip processing when certain globals or invalid IDs are set, and the suppression of repeated error messages, so coverage of secondary details is only partial.",
                "The summary correctly captures the main action of the function: setting multiple extended file attributes on a given path from retrieved records. It also accurately notes handling of specific errno conditions and updating global error state flags, which matches how the code processes ENOTSUP, ENOSPC, EDQUOT, and superuser errors while toggling ignore_xattrs and nonsuper_error. There is no contradictory or irrelevant detail, and the description aligns well with the primary purpose and side effects, though the gain is modest due to lack of deeper specifics (e.g., filtering prefixes or conditional skips). The overall noise is minimal and accuracy is high."
            ]
        }
    }
}
{
    "source_code": "static void __synchronize_srcu(struct srcu_struct *sp, int trycount)\n{\n\tstruct rcu_synchronize rcu;\n\tstruct rcu_head *head = &rcu.head;\n\tbool done = false;\n\n\trcu_lockdep_assert(!lock_is_held(&sp->dep_map) &&\n\t\t\t   !lock_is_held(&rcu_bh_lock_map) &&\n\t\t\t   !lock_is_held(&rcu_lock_map) &&\n\t\t\t   !lock_is_held(&rcu_sched_lock_map),\n\t\t\t   \"Illegal synchronize_srcu() in same-type SRCU (or RCU) read-side critical section\");\n\n\tmight_sleep();\n\tinit_completion(&rcu.completion);\n\n\thead->next = NULL;\n\thead->func = wakeme_after_rcu;\n\tspin_lock_irq(&sp->queue_lock);\n\tif (!sp->running) {\n\t\t/* steal the processing owner */\n\t\tsp->running = true;\n\t\trcu_batch_queue(&sp->batch_check0, head);\n\t\tspin_unlock_irq(&sp->queue_lock);\n\n\t\tsrcu_advance_batches(sp, trycount);\n\t\tif (!rcu_batch_empty(&sp->batch_done)) {\n\t\t\tBUG_ON(sp->batch_done.head != head);\n\t\t\trcu_batch_dequeue(&sp->batch_done);\n\t\t\tdone = true;\n\t\t}\n\t\t/* give the processing owner to work_struct */\n\t\tsrcu_reschedule(sp);\n\t} else {\n\t\trcu_batch_queue(&sp->batch_queue, head);\n\t\tspin_unlock_irq(&sp->queue_lock);\n\t}\n\n\tif (!done)\n\t\twait_for_completion(&rcu.completion);\n}",
    "comment": "Synchronizes SRCU processing by queuing a completion task and waiting for it to finish if not already done by the processing owner.",
    "prorec_sum": "Initializes lock-related state, updates linked list pointers, enables interrupts, and invokes further processing with provided parameters.",
    "filter_prorec_sum": "Initializes and links internal queue elements, enables interrupts, and dispatches processing of provided parameters within a locked synchronization context.",
    "prorec_aug_sum": "Initializes and links internal data structures, enables interrupts, and processes parameters before invoking a secondary handler for further execution.",
    "filter_prorec_aug_sum": "Initializes internal queue pointers, enables interrupts, and processes a hardware event with provided parameters before invoking the corresponding handler.",
    "work_score": {
        "prorec": {
            "summary": "Initializes lock-related state, updates linked list pointers, enables interrupts, and invokes further processing with provided parameters.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary contains mostly generic or inaccurate claims. While it vaguely notes initialization and updating pointers, it omits critical domain-specific behaviors like lockdep assertions, queuing batches with spinlocks, and waiting for completion. The claim about enabling interrupts contradicts the source, which uses spin_lock_irq/spin_unlock_irq, and is not clearly equivalent. Overall, less than half of the claims correctly and specifically reflect the function\u2019s semantics.",
                "The summary provides generic statements about initialization, pointer updates, interrupts, and processing calls, but it fails to accurately capture the core purpose of the function, which is to synchronize SRCU by queuing batch work, advancing batches, and waiting for completion. The claims lack domain-specific SRCU/RCU semantics and miss critical details such as lock assertions, conditional ownership transfer, rescheduling, and error handling. As a result, the core is not covered and secondary details are minimal and generic.",
                "The summary contains mostly inaccurate and vague claims. It incorrectly states that the function 'enables interrupts,' which is not supported by the source code. Core actions like asserting lock state, queueing RCU batches, advancing SRCU batches, and waiting for completion are omitted. The mention of 'initializes lock-related state' and 'updates linked list pointers' is generic, low-detail, and partially accurate, but the overall content is overwhelmed by noise and misleading elements. The worst failure mode is NOISE dominating with at least one incorrect semantics targeting the code."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes and links internal queue elements, enables interrupts, and dispatches processing of provided parameters within a locked synchronization context.",
            "score": [
                0.3,
                0.2,
                0.4
            ],
            "reason": [
                "The summary claims include initializing and linking internal queue elements, and dispatching processing within a locked synchronization context. While initialization and queuing are accurate to the code, the statement about enabling interrupts is inaccurate because the function uses spin_lock_irq and spin_unlock_irq but does not explicitly enable interrupts as a primary operation. Additionally, 'dispatches processing of provided parameters' is vague and does not precisely match the function\u2019s SRCU batch processing logic. Overall, less than half of the claims are specific and accurate to the code semantics.",
                "The summary does not capture the core purpose of the function, which is to synchronize SRCU by queuing an RCU callback, potentially taking ownership of processing, advancing SRCU batches, and waiting for completion outside of RCU read-side critical sections. While it vaguely mentions initializing and linking queue elements and operating in a locked context, these are imprecise and miss the specific domain semantics and critical behaviors like assertion checks, conditional batch processing, and completion waiting. No secondary behavior details such as lock assertions, ownership transfer, or batch advancement are addressed.",
                "The summary contains vague and partially incorrect claims. While it generically notes queue initialization and processing in a locked context, it inaccurately states 'enables interrupts', which is not present in the source code\u2014spin_lock_irq disables interrupts temporarily, and spin_unlock_irq restores them. The description omits crucial primary purpose details: performing SRCU synchronization by queueing a callback, advancing batches, and waiting for completion. There are no specific GOLD-level insights, and the noise from vague phrasing outweighs accurate parts. Worst failure mode is NOISE with some inaccuracy in lock/interrupt behavior."
            ]
        }
    }
}
{
    "source_code": "\nint kernel_ident_mapping_init(struct x86_mapping_info *info, pgd_t *pgd_page,\n\t\t\t      unsigned long addr, unsigned long end)\n{\n\tunsigned long next;\n\tint result;\n\tint off = info->kernel_mapping ? pgd_index(__PAGE_OFFSET) : 0;\n\n\tfor (; addr < end; addr = next) {\n\t\tpgd_t *pgd = pgd_page + pgd_index(addr) + off;\n\t\tpud_t *pud;\n\n\t\tnext = (addr & PGDIR_MASK) + PGDIR_SIZE;\n\t\tif (next > end)\n\t\t\tnext = end;\n\n\t\tif (pgd_present(*pgd)) {\n\t\t\tpud = pud_offset(pgd, 0);\n\t\t\tresult = ident_pud_init(info, pud, addr, next);\n\t\t\tif (result)\n\t\t\t\treturn result;\n\t\t\tcontinue;\n\t\t}\n\n\t\tpud = (pud_t *)info->alloc_pgt_page(info->context);\n\t\tif (!pud)\n\t\t\treturn -ENOMEM;\n\t\tresult = ident_pud_init(info, pud, addr, next);\n\t\tif (result)\n\t\t\treturn result;\n\t\tset_pgd(pgd, __pgd(__pa(pud) | _KERNPG_TABLE));\n\t}\n\n\treturn 0;\n}",
    "comment": "Initializes kernel identity mapping by setting up page entries in the page global directory for the specified address range, allocating pages as needed.",
    "prorec_sum": "Maps a virtual address range to physical pages in an IOMMU domain, allocating and setting page table entries as required.",
    "filter_prorec_sum": "Maps a virtual address range to physical memory in an IOMMU page table, allocating and linking page table entries when absent.",
    "prorec_aug_sum": "Traverses a virtual address range, allocating and linking page table entries as needed, and delegates processing of each mapped segment to a helper function.",
    "filter_prorec_aug_sum": "Traverses a range of virtual addresses, allocating and mapping missing page table entries, and recursively processing already present mappings.",
    "work_score": {
        "prorec": {
            "summary": "Maps a virtual address range to physical pages in an IOMMU domain, allocating and setting page table entries as required.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function maps a virtual address range to physical pages in an IOMMU domain, which is inaccurate because the source code shows it operates on kernel page tables and address mapping without any IOMMU-specific handling. It correctly notes allocation and setting of page table entries, but the domain context is wrong. Since only one part of the claim is accurate and the main semantic focus is incorrect, the proportion of accurate claims is less than 50%.",
                "The summary incorrectly states that the function maps virtual addresses to physical pages in an IOMMU domain, which contradicts the source code\u2019s actual purpose of setting up identity mappings in kernel page tables for a given address range. This misidentification of the domain makes the core purpose coverage absent. While it mentions allocating and setting page table entries, this is secondary detail that cannot compensate for the wrong core context.",
                "The summary introduces a FATAL inaccuracy by stating the function maps addresses in an IOMMU domain, whereas the source code clearly operates on kernel page tables for x86 virtual memory mapping, unrelated to IOMMU. This misstates the primary purpose and core domain action. While there is a minor accurate element about allocating and setting page tables, the fundamental misrepresentation of context makes the description unreliable."
            ]
        },
        "filter_prorec": {
            "summary": "Maps a virtual address range to physical memory in an IOMMU page table, allocating and linking page table entries when absent.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the code maps a virtual address range to physical memory in an IOMMU page table, which is inaccurate because the function actually sets up identity mapping in kernel page tables on x86, not IOMMU-specific structures. While it correctly notes allocation and linking of page table entries when absent, the core domain semantic is misrepresented. This results in less than half of the claims being accurate.",
                "The summary incorrectly describes the function as mapping addresses in an IOMMU page table, which contradicts the source code's actual behavior of initializing kernel identity mappings in x86 page tables. While it mentions allocating and linking page table entries, which aligns with the allocation logic in the code, it fails to cover the core purpose tied to kernel virtual-to-physical identity mapping setup and misstates the domain context. The core semantic is thus not covered, and secondary details are minimal.",
                "The summary\u2019s main claim that it maps a virtual address range to physical memory is partially aligned with the function\u2019s behavior. However, it inaccurately specifies that this occurs in an IOMMU page table, which contradicts the source code\u2014this is a severe FATAL error since it misstates the primary purpose and the context of the mapping. The function operates on the kernel\u2019s x86 page tables, not an IOMMU. While the description of allocating and linking page table entries when absent is accurate, the critical misidentification of the table type renders the summary unreliable for understanding core functionality."
            ]
        }
    }
}
{
    "source_code": "\nstatic reg_errcode_t\n__attribute_warn_unused_result__\nregister_state (const re_dfa_t *dfa, re_dfastate_t *newstate,\n\t\tre_hashval_t hash)\n{\n  struct re_state_table_entry *spot;\n  reg_errcode_t err;\n  Idx i;\n\n  newstate->hash = hash;\n  err = re_node_set_alloc (&newstate->non_eps_nodes, newstate->nodes.nelem);\n  if (BE (err != REG_NOERROR, 0))\n    return REG_ESPACE;\n  for (i = 0; i < newstate->nodes.nelem; i++)\n    {\n      Idx elem = newstate->nodes.elems[i];\n      if (!IS_EPSILON_NODE (dfa->nodes[elem].type))\n\tif (! re_node_set_insert_last (&newstate->non_eps_nodes, elem))\n\t  return REG_ESPACE;\n    }\n\n  spot = dfa->state_table + (hash & dfa->state_hash_mask);\n  if (BE (spot->alloc <= spot->num, 0))\n    {\n      Idx new_alloc = 2 * spot->num + 2;\n      re_dfastate_t **new_array = re_realloc (spot->array, re_dfastate_t *,\n\t\t\t\t\t      new_alloc);\n      if (BE (new_array == NULL, 0))\n\treturn REG_ESPACE;\n      spot->array = new_array;\n      spot->alloc = new_alloc;\n    }\n  spot->array[spot->num++] = newstate;\n  return REG_NOERROR;\n}",
    "comment": "Registers a new DFA state in the state table, allocating memory as needed and populating non-epsilon nodes.",
    "prorec_sum": "Allocates and initializes a data structure, validates its elements, and appends it into a dynamically resized list within a container object.",
    "filter_prorec_sum": "Allocates and initializes an entry structure, validates referenced elements, and appends it into a dynamically resized list within the primary data container.",
    "prorec_aug_sum": "Initializes a data structure, allocates memory for its elements, validates them, and inserts the structure into a dynamically managed list indexed by a mask.",
    "filter_prorec_aug_sum": "Allocates and initializes an entry structure, validates referenced elements, and appends it into a dynamically resized list within the given container.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a data structure, validates its elements, and appends it into a dynamically resized list within a container object.",
            "score": [
                0.9,
                0.3,
                0.5
            ],
            "reason": [
                "The summary correctly conveys that the function allocates and initializes a structure, validates elements, and appends it into a dynamically resized container list, which matches the source code's behavior of initializing non-epsilon nodes, resizing the state table array if needed, and inserting the new state. The claims are generic but accurate and align with the function's domain semantics, with no contradictory or irrelevant statements.",
                "The summary presents generic actions like allocation, initialization, validation, and appending to a dynamically resized list, which loosely match operations in the source code. However, it omits the core primary purpose of registering a DFA state in the regex engine\u2019s state table with hash-based placement and handling epsilon nodes. It also fails to mention key specifics such as the use of non-epsilon node sets, hash masking, and error handling for memory allocation. As a result, while partially accurate in describing broad mechanics, it misses critical domain-specific semantics and most secondary details.",
                "The summary is generally accurate in that the function allocates and initializes part of a state structure, checks elements, and appends it to a dynamically resized array within a container. However, it is vague and omits key domain-specific details such as the DFA state context, handling of non-epsilon nodes, hash assignment, and specific reallocation logic. There are no direct contradictions (no FATAL errors), but the description is generic and offers low informational gain, with minimal insight into the function's core semantics."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes an entry structure, validates referenced elements, and appends it into a dynamically resized list within the primary data container.",
            "score": [
                0.6,
                0.3,
                0.5
            ],
            "reason": [
                "The summary partially aligns with the source code, correctly describing allocation, initialization, validation of elements, and appending to a dynamic list. However, it is overly generic and omits key domain-specific details such as handling non-epsilon nodes, error codes (REG_ESPACE, REG_NOERROR), and use of hash-based indexing in the state table. While most claims are not contradictory, their lack of specificity reduces their value for describing the function\u2019s precise behavior.",
                "The summary vaguely describes allocation, initialization, validation, and appending to a dynamic list, which generally aligns with parts of the code. However, it fails to accurately capture the core purpose of registering a DFA state in the state table keyed by a hash and correctly handling non-epsilon nodes. It omits critical domain-specific aspects such as hash association, handling REG_ESPACE errors, and resizing the state table array. The coverage of the core purpose is missing and secondary details are shallow and generic.",
                "The summary makes broad, generic claims about allocation, initialization, validation, and appending to a container, which loosely match the code's actions (allocating non-epsilon node set, validating node types, and inserting into the state table). However, it lacks specific domain details such as the use of hash values, handling of REG_ESPACE errors, or the precise nature of the structures involved, reducing its informational value. No factual contradictions are present, but the low specificity means gain is weak and noise is moderate."
            ]
        }
    }
}
{
    "source_code": "\napr_fileperms_t apr_unix_mode2perms(mode_t mode)\n{\n    apr_fileperms_t perms = 0;\n\n    if (mode & S_ISUID)\n        perms |= APR_USETID;\n    if (mode & S_IRUSR)\n        perms |= APR_UREAD;\n    if (mode & S_IWUSR)\n        perms |= APR_UWRITE;\n    if (mode & S_IXUSR)\n        perms |= APR_UEXECUTE;\n\n    if (mode & S_ISGID)\n        perms |= APR_GSETID;\n    if (mode & S_IRGRP)\n        perms |= APR_GREAD;\n    if (mode & S_IWGRP)\n        perms |= APR_GWRITE;\n    if (mode & S_IXGRP)\n        perms |= APR_GEXECUTE;\n\n#ifdef S_ISVTX\n    if (mode & S_ISVTX)\n        perms |= APR_WSTICKY;\n#endif\n    if (mode & S_IROTH)\n        perms |= APR_WREAD;\n    if (mode & S_IWOTH)\n        perms |= APR_WWRITE;\n    if (mode & S_IXOTH)\n        perms |= APR_WEXECUTE;\n\n    return perms;\n}",
    "comment": "Converts a Unix file mode into an APR file permissions representation by checking user, group, and others' read, write, and execute bits.",
    "prorec_sum": "Converts a Unix file mode bitmask into an APR permission bitfield representing read, write, execute, and special mode flags.",
    "filter_prorec_sum": "Converts a Unix file mode bitmask into a corresponding APR permission bitfield representation.",
    "prorec_aug_sum": "Converts a Unix file mode bitmask into an APR-style permission flag representation.",
    "filter_prorec_aug_sum": "Converts a Unix file mode bitmask into an APR-style permission bitfield encoding owner, group, and other read, write, execute, and special bits.",
    "work_score": {
        "prorec": {
            "summary": "Converts a Unix file mode bitmask into an APR permission bitfield representing read, write, execute, and special mode flags.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function converts a Unix file mode bitmask into an APR permission bitfield, and correctly identifies that this includes read, write, execute, and special mode flags. All details are supported by the source code and directly reflect its semantics, with no inaccuracies or unrelated content.",
                "The summary correctly states that the function converts a Unix mode bitmask into an APR permission bitfield and mentions read, write, execute, and special mode flags, which matches the core domain action. However, it lacks details about the specific flags handled (S_ISUID, S_ISGID, S_ISVTX) and the separate handling for user, group, and world permissions. This results in partial coverage of secondary, behavior-critical semantics.",
                "The summary accurately captures the core purpose of the function, which is the conversion of a Unix file mode bitmask into an APR permission bitfield, and mentions inclusion of read, write, execute, and special mode flags. This aligns with the source code's handling of user, group, and other permission bits along with special flags like setuid, setgid, and sticky. The claim is correct, focused on primary functionality, and contains no inaccuracies or noise, but it is somewhat generic and lacks deeper specifics such as distinction between user/group/other bits or exact mapping constants."
            ]
        },
        "filter_prorec": {
            "summary": "Converts a Unix file mode bitmask into a corresponding APR permission bitfield representation.",
            "score": [
                1.0,
                0.4,
                0.7
            ],
            "reason": [
                "The single claim that the function converts a Unix file mode bitmask into an APR permission bitfield is accurate and matches the function\u2019s semantics, which maps Unix mode flags to corresponding APR permission constants. There are no inaccurate or irrelevant statements, making the claim highly precise and aligned with the source code behavior.",
                "The summary accurately captures the core purpose of converting a Unix file mode bitmask to an APR permission bitfield, which aligns with the source code\u2019s primary function. However, it omits secondary details such as handling specific mode bits for user, group, and others, inclusion of special bits like S_ISUID, S_ISGID, and optional S_ISVTX, and mapping them to corresponding APR constants. This results in a correct but minimal coverage beyond the core purpose.",
                "The summary correctly states the primary purpose of the function: converting a Unix file mode bitmask into an APR permission bitfield. This is a single accurate GOLD claim directly aligned with the code's core semantics. There is no noise or inaccurate information, but the description is generic and lacks specific details about how individual bits are mapped, resulting in low informational gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic int check_policy(X509_STORE_CTX *ctx)\n\t{\n\tint ret;\n\tif (ctx->parent)\n\t\treturn 1;\n\tret = X509_policy_check(&ctx->tree, &ctx->explicit_policy, ctx->chain,\n\t\t\t\tctx->param->policies, ctx->param->flags);\n\tif (ret == 0)\n\t\t{\n\t\tX509err(X509_F_CHECK_POLICY,ERR_R_MALLOC_FAILURE);\n\t\treturn 0;\n\t\t}\n\t/* Invalid or inconsistent extensions */\n\tif (ret == -1)\n\t\t{\n\t\t/* Locate certificates with bad extensions and notify\n\t\t * callback.\n\t\t */\n\t\tX509 *x;\n\t\tint i;\n\t\tfor (i = 1; i < sk_X509_num(ctx->chain); i++)\n\t\t\t{\n\t\t\tx = sk_X509_value(ctx->chain, i);\n\t\t\tif (!(x->ex_flags & EXFLAG_INVALID_POLICY))\n\t\t\t\tcontinue;\n\t\t\tctx->current_cert = x;\n\t\t\tctx->error = X509_V_ERR_INVALID_POLICY_EXTENSION;\n\t\t\tif(!ctx->verify_cb(0, ctx))\n\t\t\t\treturn 0;\n\t\t\t}\n\t\treturn 1;\n\t\t}\n\tif (ret == -2)\n\t\t{\n\t\tctx->current_cert = NULL;\n\t\tctx->error = X509_V_ERR_NO_EXPLICIT_POLICY;\n\t\treturn ctx->verify_cb(0, ctx);\n\t\t}\n\n\tif (ctx->param->flags & X509_V_FLAG_NOTIFY_POLICY)\n\t\t{\n\t\tctx->current_cert = NULL;\n\t\tctx->error = X509_V_OK;\n\t\tif (!ctx->verify_cb(2, ctx))\n\t\t\treturn 0;\n\t\t}\n\n\treturn 1;\n\t}",
    "comment": "Validates X509 certificate policies, checks for invalid extensions, and invokes a callback for policy notifications or errors during the verification process.",
    "prorec_sum": "Checks X.509 certificate policies using `X509_policy_check` and triggers appropriate error handling or callbacks based on the validation result.",
    "filter_prorec_sum": "Performs X.509 certificate policy checking and invokes configured callbacks to handle compliance, violations, or errors during verification.",
    "prorec_aug_sum": "Checks X.509 certificate policies and invokes a callback to handle specific policy violations or errors during SSL certificate verification.",
    "filter_prorec_aug_sum": "Validates X.509 certificate policies via `X509_policy_check` and triggers appropriate error handling or callbacks based on the check result.",
    "work_score": {
        "prorec": {
            "summary": "Checks X.509 certificate policies using `X509_policy_check` and triggers appropriate error handling or callbacks based on the validation result.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function checks X.509 certificate policies using `X509_policy_check` and initiates error handling or callbacks based on results, which matches the source code\u2019s behavior. Although it omits specific details about distinct return codes and exact error conditions, the claim is fact-based, domain-relevant, and consistent with the implementation, resulting in a high proportion of accurate statements.",
                "The summary accurately identifies the use of `X509_policy_check` to validate X.509 certificate policies and notes that errors or callbacks are triggered based on results, which covers the core purpose of the function. However, it lacks detail on key secondary aspects such as the specific return values handled (0, -1, -2), the nature of extension checks, the use of flags like `X509_V_FLAG_NOTIFY_POLICY`, and distinctions between different error codes and callback outcomes. These omissions make the coverage of critical secondary semantics incomplete.",
                "The summary correctly captures the core function\u2019s purpose of checking X.509 certificate policies via `X509_policy_check` and invoking error handling or callbacks based on the result. This aligns with the source code\u2019s primary flow: early return if parent exists, use of `X509_policy_check`, branching on return values for specific error states or callback notifications, and ultimately returning success/failure. The claim is accurate, concise, and domain-specific, but lacks detailed coverage of the various specific return value conditions and their handling paths, so while it is GOLD for the core purpose, it provides only moderate insight rather than extensive detail. No inaccurate or noisy claims are present."
            ]
        },
        "filter_prorec": {
            "summary": "Performs X.509 certificate policy checking and invokes configured callbacks to handle compliance, violations, or errors during verification.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function performs X.509 certificate policy checking and invokes callbacks for handling compliance, violations, or errors, which aligns with the source code's use of X509_policy_check and verify_cb under various conditions. These are fact-based and accurate descriptions of the core behavior without contradictions or irrelevant noise, resulting in a high proportion of accurate claims.",
                "The summary correctly identifies that the function performs X.509 certificate policy checks and uses callbacks to handle compliance, violations, or errors, which matches the core primary purpose in the source. However, it is generic and omits key specifics such as handling explicit policy flags, different return conditions from X509_policy_check, and details of error codes and notification logic. Secondary coverage is weak, lacking mention of branches like invalid policy extension handling, no explicit policy handling, and notify policy flag cases.",
                "The summary correctly identifies that the function performs X.509 certificate policy checks and references that callbacks are invoked to handle compliance, violations, or errors, which aligns with the source code\u2019s verification process and callback calls in multiple branches. However, it is generic, lacking specifics about conditions such as handling EXFLAG_INVALID_POLICY, malloc failure, explicit policy absence, or notification flags. No inaccurate or contradictory claims are present, but the low level of detail limits its usefulness."
            ]
        }
    }
}
{
    "source_code": "void\nmpz_rootrem (mpz_t x, mpz_t r, const mpz_t y, unsigned long z)\n{\n  int sgn;\n  mpz_t t, u;\n\n  sgn = y->_mp_size < 0;\n  if ((~z & sgn) != 0)\n    gmp_die (\"mpz_rootrem: Negative argument, with even root.\");\n  if (z == 0)\n    gmp_die (\"mpz_rootrem: Zeroth root.\");\n\n  if (mpz_cmpabs_ui (y, 1) <= 0) {\n    if (x)\n      mpz_set (x, y);\n    if (r)\n      r->_mp_size = 0;\n    return;\n  }\n\n  mpz_init (u);\n  mpz_init (t);\n  mpz_setbit (t, mpz_sizeinbase (y, 2) / z + 1);\n\n  if (z == 2) /* simplify sqrt loop: z-1 == 1 */\n    do {\n      mpz_swap (u, t);\t\t\t/* u = x */\n      mpz_tdiv_q (t, y, u);\t\t/* t = y/x */\n      mpz_add (t, t, u);\t\t/* t = y/x + x */\n      mpz_tdiv_q_2exp (t, t, 1);\t/* x'= (y/x + x)/2 */\n    } while (mpz_cmpabs (t, u) < 0);\t/* |x'| < |x| */\n  else /* z != 2 */ {\n    mpz_t v;\n\n    mpz_init (v);\n    if (sgn)\n      mpz_neg (t, t);\n\n    do {\n      mpz_swap (u, t);\t\t\t/* u = x */\n      mpz_pow_ui (t, u, z - 1);\t\t/* t = x^(z-1) */\n      mpz_tdiv_q (t, y, t);\t\t/* t = y/x^(z-1) */\n      mpz_mul_ui (v, u, z - 1);\t\t/* v = x*(z-1) */\n      mpz_add (t, t, v);\t\t/* t = y/x^(z-1) + x*(z-1) */\n      mpz_tdiv_q_ui (t, t, z);\t\t/* x'=(y/x^(z-1) + x*(z-1))/z */\n    } while (mpz_cmpabs (t, u) < 0);\t/* |x'| < |x| */\n\n    mpz_clear (v);\n  }\n\n  if (r) {\n    mpz_pow_ui (t, u, z);\n    mpz_sub (r, y, t);\n  }\n  if (x)\n    mpz_swap (x, u);\n  mpz_clear (u);\n  mpz_clear (t);\n}",
    "comment": "Computes the nth root and remainder of a multi-precision integer, handling special cases for negative and zero values.",
    "prorec_sum": "Computes the integer a4\u2011th root of a given big integer and optionally returns the remainder and root, rejecting invalid or negative inputs.",
    "filter_prorec_sum": "Computes the integer n\u2011th root of a large number and optionally returns the remainder, rejecting invalid negative or zero\u2011root inputs.",
    "prorec_aug_sum": "Computes the integer nth root of a large number and optionally returns the remainder, rejecting invalid zero or even\u2011root negative inputs.",
    "filter_prorec_aug_sum": "Computes the integer n\u2011th root of a large number, with optional remainder output, rejecting invalid root values or negative inputs for even roots.",
    "work_score": {
        "prorec": {
            "summary": "Computes the integer a4\u2011th root of a given big integer and optionally returns the remainder and root, rejecting invalid or negative inputs.",
            "score": [
                0.8,
                0.6,
                0.2
            ],
            "reason": [
                "The summary states that the function computes the integer a4-th root of a big integer, optionally returns the remainder and root, and rejects invalid or negative inputs. The source code shows it computes the z-th root of y using iterative methods, handles even roots for negative inputs by throwing errors, returns both root and remainder if requested, and rejects z=0. The only inaccuracy is the reference to 'a4-th root', which is likely a misstatement; otherwise, the rest aligns with the code's behavior. Thus, most claims are accurate, with only one minor incorrect detail.",
                "The summary correctly captures the core function \u2014 computing an integer z\u2011th root (with 'a4-th root' likely a placeholder) and optionally providing the remainder \u2014 and mentions invalid or negative input rejection, which aligns with the code's checks for negative arguments with even roots and zeroth root. However, it omits important secondary details such as handling the case when |y| \u2264 1, the use of different iterative methods for z = 2 versus z \u2260 2, and specifics on internal GMP operations and memory handling. These omissions make coverage of secondary behavior incomplete.",
                "The summary correctly notes that the function computes an integer root of a large integer and can return both root and remainder while rejecting invalid inputs, which aligns with the code\u2019s behavior of handling even negative roots and zero root cases. However, it inaccurately specifies 'a4-th root' instead of a general z-th root parameter, which misstates the core purpose. This is a FATAL error targeting the primary action of the function, making the description unreliable despite otherwise aligning with input validation and optional remainder output."
            ]
        },
        "filter_prorec": {
            "summary": "Computes the integer n\u2011th root of a large number and optionally returns the remainder, rejecting invalid negative or zero\u2011root inputs.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function computes the integer n-th root of a large number and can return the remainder, matching the root-and-remainder logic in the code. It also accurately notes that negative arguments with even roots and zero-root inputs are rejected. All claims align with the source code\u2019s semantics, with no incorrect or irrelevant content.",
                "The summary accurately states the core purpose of computing the integer n-th root and optionally returning the remainder, including validation that rejects negative arguments for even roots and zero roots. These directly match the key domain semantics in the source. However, it omits secondary details such as handling small absolute values of y, the separate optimization for square roots, the iterative approximation method, and final remainder computation steps. This results in core coverage but limited breadth of secondary behaviors.",
                "The summary accurately states the primary purpose: computing the integer n\u2011th root and optionally returning the remainder, and notes input validation for negative arguments with even roots and zero root cases. These are all consistent with the source code\u2019s behavior. The claims are specific to the function\u2019s domain semantics with no inaccuracies or irrelevant noise, though the summary omits minor implementation details such as special handling for small absolute values of y and the iterative method used. The gain is moderate due to correct coverage of key inputs and outputs and rejection cases."
            ]
        }
    }
}
{
    "source_code": "\nint\nmutil_parse_field_map (const char *map, mu_assoc_t *passoc_tab, int *perr)\n{\n  int rc;\n  int i;\n  struct mu_wordsplit ws;\n  mu_assoc_t assoc_tab = NULL;\n\n  ws.ws_delim = \":\";\n  if (mu_wordsplit (map, &ws, MU_WRDSF_DEFFLAGS|MU_WRDSF_DELIM))\n    {\n      mu_error (_(\"cannot split line `%s': %s\"), map,\n\t\tmu_wordsplit_strerror (&ws));\n      return errno;\n    }\n\n  for (i = 0; i < ws.ws_wordc; i++)\n    {\n      char *tok = ws.ws_wordv[i];\n      char *p = strchr (tok, '=');\n      char *pptr;\n      \n      if (!p)\n\t{\n\t  rc = EINVAL;\n\t  break;\n\t}\n      if (!assoc_tab)\n\t{\n\t  rc = mu_assoc_create (&assoc_tab, 0);\n\t  if (rc)\n\t    break;\n\t  mu_assoc_set_destroy_item (assoc_tab, mu_list_free_item);\n\t  *passoc_tab = assoc_tab;\n\t}\n      *p++ = 0;\n      pptr = strdup (p);\n      if (!pptr)\n\t{\n\t  rc = errno;\n\t  break;\n\t}\n      rc = mu_assoc_install (assoc_tab, tok, pptr);\n      if (rc)\n\t{\n\t  free (p);\n\t  break;\n\t}\n    }\n\n  mu_wordsplit_free (&ws);\n  if (rc && perr)\n    *perr = i;\n  return rc;\n}",
    "comment": "Parses a colon-delimited string into a key-value association table, handling errors for malformed entries and memory allocation failures.",
    "prorec_sum": "Parses a colon-separated string of key=value pairs into an associative map, handling errors and returning the index of any malformed entry.",
    "filter_prorec_sum": "Parses a colon-delimited string of key=value pairs into an associative map, reporting errors on malformed entries or memory allocation failure.",
    "prorec_aug_sum": "Parses a colon-separated line into key-value pairs, storing them in an association object and reporting errors on invalid or memory allocation failures.",
    "filter_prorec_aug_sum": "Parses a colon-separated field map string into a key-value association, handling errors and storing the map in the provided output pointer.",
    "work_score": {
        "prorec": {
            "summary": "Parses a colon-separated string of key=value pairs into an associative map, handling errors and returning the index of any malformed entry.",
            "score": [
                0.9,
                0.6,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function parses a colon-separated string of key=value pairs into an associative map and handles errors, which aligns with the implementation that splits on ':' and installs pairs into an assoc_tab. However, while it returns the index of the problematic token via `*perr`, this only happens if an error occurs and `perr` is not NULL, so the phrasing 'returning the index of any malformed entry' could be misleading if interpreted as always returning it. Overall, the majority of the claims match the source code, with only a minor overgeneralization regarding error index reporting.",
                "The summary correctly describes the core purpose: parsing a colon-separated string of key=value pairs into an associative map. It also notes error handling and returning the index of a malformed entry, which matches the perr logic in the code. However, it omits several secondary details such as use of mu_wordsplit with specific flags, creation and setup of the assoc_tab only when needed, memory allocation via strdup, freeing resources, and handling specific error codes. These omissions make the coverage of secondary behavior incomplete.",
                "The summary correctly states that the function parses a colon-separated string of key=value pairs into an associative map and handles errors, which matches the code's core purpose. However, it inaccurately claims the function returns the index of any malformed entry; in reality, it sets the provided `perr` pointer to the index only if an error occurs, and returns an error code. This is a factual error about a key output, making it a severe failure on primary I/O behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Parses a colon-delimited string of key=value pairs into an associative map, reporting errors on malformed entries or memory allocation failure.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function parses a colon-delimited string into key=value pairs and stores them in an associative map, which aligns with the use of mu_wordsplit and mu_assoc_install. It also accurately notes error handling for malformed entries (missing '=') and memory allocation failure. All claims are specific to the function's semantics and match the source code, with no inaccuracies detected.",
                "The summary correctly identifies the core purpose as parsing a colon-delimited key=value string into an associative map, which matches the function's main domain operation. It also mentions error reporting for malformed entries and memory allocation failure, aligning with specific branches in the code (EINVAL, strdup failure). However, it omits several secondary details such as the use of mu_wordsplit for splitting, assoc creation upon first valid entry, freeing word split data, and the possible return of errno from the splitter or associative installation failures. Coverage of key secondary behaviors is incomplete.",
                "The summary accurately captures the core purpose of the function: splitting a colon-delimited string of key=value pairs into an associative map. It also correctly notes error reporting for malformed entries (missing '=') and memory allocation failures. These are specific, correct statements grounded in the source code, with no contradictory or irrelevant claims. The gain is moderate to high since the summary succinctly reflects both the primary purpose and key error conditions, and noise is minimal."
            ]
        }
    }
}
{
    "source_code": "static int\nxmlRelaxNGRegisterTypeLibrary(const xmlChar * namespace, void *data,\n                              xmlRelaxNGTypeHave have,\n                              xmlRelaxNGTypeCheck check,\n                              xmlRelaxNGTypeCompare comp,\n                              xmlRelaxNGFacetCheck facet,\n                              xmlRelaxNGTypeFree freef)\n{\n    xmlRelaxNGTypeLibraryPtr lib;\n    int ret;\n\n    if ((xmlRelaxNGRegisteredTypes == NULL) || (namespace == NULL) ||\n        (check == NULL) || (comp == NULL))\n        return (-1);\n    if (xmlHashLookup(xmlRelaxNGRegisteredTypes, namespace) != NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"Relax-NG types library '%s' already registered\\n\",\n                        namespace);\n        return (-1);\n    }\n    lib =\n        (xmlRelaxNGTypeLibraryPtr)\n        xmlMalloc(sizeof(xmlRelaxNGTypeLibrary));\n    if (lib == NULL) {\n        xmlRngVErrMemory(NULL, \"adding types library\\n\");\n        return (-1);\n    }\n    memset(lib, 0, sizeof(xmlRelaxNGTypeLibrary));\n    lib->namespace = xmlStrdup(namespace);\n    lib->data = data;\n    lib->have = have;\n    lib->comp = comp;\n    lib->check = check;\n    lib->facet = facet;\n    lib->freef = freef;\n    ret = xmlHashAddEntry(xmlRelaxNGRegisteredTypes, namespace, lib);\n    if (ret < 0) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"Relax-NG types library failed to register '%s'\\n\",\n                        namespace);\n        xmlRelaxNGFreeTypeLibrary(lib, namespace);\n        return (-1);\n    }\n    return (0);\n}",
    "comment": "Registers a new Relax-NG types library with a given namespace and associated functions in the xmlRelaxNGRegisteredTypes hash table.",
    "prorec_sum": "Registers a new Relax-NG types library in a global XML hash table, allocating and storing its associated callbacks, with error reporting on duplicates or failures.",
    "filter_prorec_sum": "Registers a new Relax-NG types library in a global hash, allocating and storing its callbacks, and reports errors if it already exists or registration fails.",
    "prorec_aug_sum": "Registers a new Relax-NG types library in an XML hash table, allocating and storing its metadata, and reports errors if already registered or on failure.",
    "filter_prorec_aug_sum": "Registers a new Relax-NG types library in a global XML hash, reporting errors if the library is already registered or registration fails.",
    "work_score": {
        "prorec": {
            "summary": "Registers a new Relax-NG types library in a global XML hash table, allocating and storing its associated callbacks, with error reporting on duplicates or failures.",
            "score": [
                1.0,
                0.8,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function registers a new Relax-NG types library in a global XML hash table, allocates and stores its callbacks, and reports errors for duplicates or failures. These details match the source code behavior, including allocation via xmlMalloc, populating callback fields, duplicate detection using xmlHashLookup, and error handling. All claims are precise and verifiable against the implementation, with no inaccuracies present.",
                "The summary correctly identifies the core purpose as registering a new Relax-NG types library in a global hash, including allocation and storing callbacks, which matches the function's domain-specific logic. It also notes error reporting for duplicates and failures, covering key secondary behavior like duplicate detection and registration failure handling. However, it omits some additional specifics from the code such as the null parameter checks, exact required callbacks, memory error handling, and freeing resources on failed registration, making the coverage solid but not exhaustive.",
                "The summary accurately describes the core purpose of registering a new Relax-NG types library in a global hash, including allocation and storing callbacks, and correctly notes error handling for duplicates or failures. All claims align with the source code and are specific to the function's behavior, with no inaccuracies or irrelevant noise present. While the gain is moderate due to the concise description, it conveys the primary semantics clearly and without error."
            ]
        },
        "filter_prorec": {
            "summary": "Registers a new Relax-NG types library in a global hash, allocating and storing its callbacks, and reports errors if it already exists or registration fails.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately describes the key functionality: registering a Relax-NG types library in a global hash, allocating memory for it, storing provided callback functions, and reporting errors if already registered or if registration fails. All claims match the source code behavior, with no inaccuracies or irrelevant content.",
                "The summary accurately captures the core purpose of registering a new Relax-NG type library in a global hash with allocation and callback storage, which matches the function's primary domain action. It also notes key error conditions: existing registration and registration failure. However, it omits other specific details such as null pointer checks for required parameters, memory allocation failure handling, and association of specific callback functions and data fields, leading to incomplete coverage of secondary behavior-critical semantics.",
                "The summary correctly identifies the primary purpose of registering a Relax-NG types library in a global hash and mentions allocation of the structure with its callbacks, along with error handling for duplicates or registration failures. All these details align accurately with the source code, with no contradictory or irrelevant claims. The claims are concise but contain specific domain-relevant behavior, providing clear insight without noise."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nevhttp_read_header(struct evhttp_connection *evcon,\n\t\t   struct evhttp_request *req)\n{\n\tenum message_read_status res;\n\tevutil_socket_t fd = evcon->fd;\n\n\tres = evhttp_parse_headers_(req, bufferevent_get_input(evcon->bufev));\n\tif (res == DATA_CORRUPTED || res == DATA_TOO_LONG) {\n\t\t/* Error while reading, terminate */\n\t\tevent_debug((\"%s: bad header lines on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, EV_SOCK_ARG(fd)));\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\treturn;\n\t} else if (res == MORE_DATA_EXPECTED) {\n\t\t/* Need more header lines */\n\t\treturn;\n\t}\n\n\t/* Callback can shut down connection with negative return value */\n\tif (req->header_cb != NULL) {\n\t\tif ((*req->header_cb)(req, req->cb_arg) < 0) {\n\t\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_EOF);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Done reading headers, do the real work */\n\tswitch (req->kind) {\n\tcase EVHTTP_REQUEST:\n\t\tevent_debug((\"%s: checking for post data on \"EV_SOCK_FMT\"\\n\",\n\t\t\t__func__, EV_SOCK_ARG(fd)));\n\t\tevhttp_get_body(evcon, req);\n\t\t/* note the request may have been freed in evhttp_get_body */\n\t\tbreak;\n\n\tcase EVHTTP_RESPONSE:\n\t\t/* Start over if we got a 100 Continue response. */\n\t\tif (req->response_code == 100) {\n\t\t\tstruct evbuffer *output = bufferevent_get_output(evcon->bufev);\n\t\t\tevbuffer_add_buffer(output, req->output_buffer);\n\t\t\tevhttp_start_write_(evcon);\n\t\t\treturn;\n\t\t}\n\t\tif (!evhttp_response_needs_body(req)) {\n\t\t\tevent_debug((\"%s: skipping body for code %d\\n\",\n\t\t\t\t\t__func__, req->response_code));\n\t\t\tevhttp_connection_done(evcon);\n\t\t} else {\n\t\t\tevent_debug((\"%s: start of read body for %s on \"\n\t\t\t\tEV_SOCK_FMT\"\\n\",\n\t\t\t\t__func__, req->remote_host, EV_SOCK_ARG(fd)));\n\t\t\tevhttp_get_body(evcon, req);\n\t\t\t/* note the request may have been freed in\n\t\t\t * evhttp_get_body */\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tevent_warnx(\"%s: bad header on \"EV_SOCK_FMT, __func__,\n\t\t    EV_SOCK_ARG(fd));\n\t\tevhttp_connection_fail_(evcon, EVREQ_HTTP_INVALID_HEADER);\n\t\tbreak;\n\t}\n\t/* request may have been freed above */\n}",
    "comment": "Processes incoming HTTP headers, validates them, invokes a callback if present, and handles the request or response body based on the type and status.",
    "prorec_sum": "Parses HTTP headers from a bufferevent, handles status-specific logic, and manages connection failure or response writing based on parsing results.",
    "filter_prorec_sum": "Parses HTTP headers from a bufferevent, handles status-specific responses, and triggers appropriate connection failure or subsequent write operations.",
    "prorec_aug_sum": "Processes HTTP headers from a bufferevent, handles specific status codes, and manages connection failure or transition to response writing as appropriate.",
    "filter_prorec_aug_sum": "Processes HTTP headers from a buffered event, handles connection failures, and manages response writing based on status codes with optional debug logging.",
    "work_score": {
        "prorec": {
            "summary": "Parses HTTP headers from a bufferevent, handles status-specific logic, and manages connection failure or response writing based on parsing results.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function parses HTTP headers from a bufferevent and applies logic based on the parsing status, including connection failure handling and response writing. These points align with the code\u2019s behavior in handling DATA_CORRUPTED, DATA_TOO_LONG, MORE_DATA_EXPECTED, and managing responses. However, it is somewhat generic and omits specifics such as callback handling, differentiation between request and response cases, and detailed conditions like 100 Continue. All stated claims are accurate but lack depth.",
                "The summary correctly notes parsing HTTP headers from a bufferevent and handling status-specific logic, including connection failures and response writing, which aligns with the core function of processing headers and reacting to parse results. However, it lacks key specifics from the source code such as handling different request kinds (request vs. response), specific status codes like 100 Continue, distinctions between DATA_CORRUPTED/DATA_TOO_LONG/MORE_DATA_EXPECTED, and conditional body reading/skipping. These omissions reduce coverage of secondary, behavior-critical semantics.",
                "The summary correctly states that the function parses HTTP headers from a bufferevent and includes logic dependent on parsing results, which matches the code\u2019s use of evhttp_parse_headers_ and subsequent branching. It also accurately notes connection failure handling and response writing flows. However, it is quite generic, omitting key specifics such as the handling of DATA_CORRUPTED, MORE_DATA_EXPECTED, header callback behavior, different logic for requests vs. responses, and special handling for HTTP 100 Continue. There are no inaccurate or contradictory claims, but the lack of detail limits its usefulness."
            ]
        },
        "filter_prorec": {
            "summary": "Parses HTTP headers from a bufferevent, handles status-specific responses, and triggers appropriate connection failure or subsequent write operations.",
            "score": [
                0.8,
                0.6,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function parses HTTP headers from a bufferevent and handles different status scenarios, including triggering connection failures and initiating write operations for specific cases like 100 Continue responses. These are accurate reflections of the source code's behavior. However, it omits details about handling different request kinds, the header callback, and conditions for reading or skipping the body, making it less comprehensive but still largely accurate.",
                "The summary correctly notes parsing HTTP headers from a bufferevent and handling status-specific outcomes, which covers the core purpose of reading and processing HTTP headers. It mentions triggering connection failures and subsequent write operations, aligning with the code\u2019s handling of invalid headers, 100 Continue responses, and body retrieval. However, it omits several important secondary details such as distinguishing between request and response cases, handling MORE_DATA_EXPECTED, skipping bodies based on response codes, and executing header callbacks. These omissions prevent full coverage of critical branch and edge case behavior.",
                "The summary correctly captures the core purpose of parsing HTTP headers from a bufferevent and notes that different statuses trigger different follow-up actions, such as connection failure or initiating writes. However, it is fairly generic and omits key specifics, such as handling 'MORE_DATA_EXPECTED', invoking a request header callback that can abort, processing request vs. response kinds with distinct logic, and the special case for 100 Continue responses. There is no fatal inaccuracy, but the lack of detail reduces the informational value, resulting in low gain despite accuracy."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nset_level_indent(const char *str)\n{\n     long n;\n     const char *p;\n     char *q;\n     \n     n = strtol(str, &q, 0);\n     if (*q == 0 && n > 0) {\n\t  char *s = xmalloc(n+1);\n\t  memset(s, ' ', n-1);\n\t  s[n-1] = 0;\n\t  level_indent[0] = level_indent[1] = s;\n\t  return;\n     }\n     \n     p = str;\n     while (*p != '=') {\n\t  if (*p == 0)\n\t       error(EX_USAGE, 0, _(\"level-indent syntax\"));\n\t  p++;\n     }\n     ++p;\n    \n     switch (find_option_type(level_indent_optype, str, p - str - 1)) {\n     case LEVEL_BEGIN:\n\t  parse_level_string(p, &level_begin);\n\t  break;\n     case LEVEL_INDENT0:\n\t  parse_level_string(p, &level_indent[0]);\n\t  break;\n     case LEVEL_INDENT1:\n\t  parse_level_string(p, &level_indent[1]);\n\t  break;\n     case LEVEL_END0:\n\t  parse_level_string(p, &level_end[0]);\n\t  break;\n     case LEVEL_END1:\n\t  parse_level_string(p, &level_end[1]);\n\t  break;\n     default:\n\t  error(EX_USAGE, 0, _(\"unknown level indent option: %s\"), str);\n     }\n}",
    "comment": "Sets the level indentation based on a string input, allocating space for indentation or parsing specific level configuration options.",
    "prorec_sum": "Parses a level-indent option string or numeric value and configures corresponding indentation settings, reporting errors for invalid or unknown options.",
    "filter_prorec_sum": "Parses a level-indent specification string, validating syntax, and updates global indent style or whitespace padding based on numeric or named options.",
    "prorec_aug_sum": "Parses a level indent specification from a string, validates its format, and updates corresponding global indentation style or spacing settings.",
    "filter_prorec_aug_sum": "Parses a level-indent option or numeric value and sets corresponding global indentation strings, reporting errors for invalid syntax or unknown options.",
    "work_score": {
        "prorec": {
            "summary": "Parses a level-indent option string or numeric value and configures corresponding indentation settings, reporting errors for invalid or unknown options.",
            "score": [
                0.9,
                0.8,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function parses either a numeric value or option string for level indentation, sets corresponding indentation settings, and reports errors for invalid or unknown options. These details align with the source code behavior, with no contradictory or irrelevant claims present, indicating high alignment.",
                "The summary accurately states that the function parses a level-indent option string or numeric value and configures indentation settings, including error reporting for invalid or unknown options, which matches the core behavior derived from the source code. It covers both numeric handling and option-type parsing via a switch, as well as error cases, though it lacks detail on specific option types and how the indentation is stored or initialized.",
                "The summary correctly states that the function parses a level-indent option string or numeric value and configures indentation settings, and notes that it reports errors for invalid or unknown options. These are accurate reflections of the code\u2019s behavior. The claims target the main purpose and core I/O without contradiction, and there is minimal noise since all details are relevant. However, the gain is moderate because the summary is broad and omits specifics such as handling numeric input via strtol, memory allocation for indentation strings, and parsing of distinct option types. Overall, accuracy is solid but the informational detail is limited."
            ]
        },
        "filter_prorec": {
            "summary": "Parses a level-indent specification string, validating syntax, and updates global indent style or whitespace padding based on numeric or named options.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function processes a level-indent specification string and updates global indent settings based on numeric or named options, which aligns with the code's parsing of a string, syntax validation, and either allocating whitespace for numeric input or handling named options via a switch statement. This matches more than 80% of claims to the source code, with only minor omissions in detail such as specific error handling paths.",
                "The summary correctly states that the function parses a level-indent specification string, validates syntax, and adjusts global indent style based on numeric or named options, which matches the core purpose of interpreting the string and updating the appropriate global indent buffers. However, it omits important secondary details like handling the '=' separator, allocating space for numeric values, distinct handling of LEVEL_BEGIN/END and LEVEL_INDENT0/1 cases, and error reporting for unknown options or malformed strings, so coverage of overall behavior is incomplete.",
                "The summary is mostly accurate: it correctly describes that the function parses a level-indent specification string, validates syntax, and updates global indent configurations depending on numeric or named options. This aligns with the code\u2019s handling of numeric padding via strtol and named options via find_option_type and parse_level_string. However, details like the manipulation of level_indent[0] and level_indent[1] with allocated whitespace are only broadly implied as 'whitespace padding', limiting specificity. No factual errors or fatal inaccuracies are present, but the coverage is high-level and low-detail, offering modest gain."
            ]
        }
    }
}
{
    "source_code": "\n\nvoid *\nngx_http_map_find(ngx_http_request_t *r, ngx_http_map_t *map, ngx_str_t *match)\n{\n    void        *value;\n    u_char      *low;\n    size_t       len;\n    ngx_uint_t   key;\n\n    len = match->len;\n\n    if (len) {\n        low = ngx_pnalloc(r->pool, len);\n        if (low == NULL) {\n            return NULL;\n        }\n\n    } else {\n        low = NULL;\n    }\n\n    key = ngx_hash_strlow(low, match->data, len);\n\n    value = ngx_hash_find_combined(&map->hash, key, low, len);\n    if (value) {\n        return value;\n    }\n\n#if (NGX_PCRE)\n\n    if (len && map->nregex) {\n        ngx_int_t              n;\n        ngx_uint_t             i;\n        ngx_http_map_regex_t  *reg;\n\n        reg = map->regex;\n\n        for (i = 0; i < map->nregex; i++) {\n\n            n = ngx_http_regex_exec(r, reg[i].regex, match);\n\n            if (n == NGX_OK) {\n                return reg[i].value;\n            }\n\n            if (n == NGX_DECLINED) {\n                continue;\n            }\n\n            /* NGX_ERROR */\n\n            return NULL;\n        }\n    }\n\n#endif\n\n    return NULL;\n}",
    "comment": "Finds a corresponding value in a hash map or regex patterns for a given string in an HTTP request.",
    "prorec_sum": "Finds a matching value in an HTTP map using lowercase hashing, and falls back to evaluating configured regular expressions if no hash match is found.",
    "filter_prorec_sum": "Finds a lowercase-hashed map entry by string key, falling back to regex pattern matching when no direct hash match is found.",
    "prorec_aug_sum": "Looks up an HTTP map entry by lowercase-hashed key, falling back to matching configured regular expressions when no direct hash match is found.",
    "filter_prorec_aug_sum": "Finds a value in a combined hash by lowercase key, falling back to regex matching if no direct hash entry is found.",
    "work_score": {
        "prorec": {
            "summary": "Finds a matching value in an HTTP map using lowercase hashing, and falls back to evaluating configured regular expressions if no hash match is found.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately describes the function\u2019s core logic: it searches an HTTP map by computing a lowercase hash of the match string, and if no match is found, it iterates over configured regular expressions for possible matches. These behaviors are explicitly present in the source code. No incorrect or irrelevant claims are made, resulting in a high level of alignment.",
                "The summary accurately captures the core purpose of locating a value in an HTTP map via lowercase hashing and correctly notes the fallback to regex evaluation when no hash match is found. These align well with the source code\u2019s primary operation and key secondary behavior involving regex checks. However, it omits other notable implementation details such as memory allocation, NULL handling, and error conditions (e.g., NGX_ERROR cases), so coverage of secondary aspects is incomplete.",
                "The summary correctly captures the core function behavior: it first attempts a lookup using a lowercase hash of the match string, then falls back to iterating through configured regular expressions if no hash match is found. These are accurate, specific, and directly tied to the code\u2019s primary purpose, with no evident inaccuracies or noise. The claims are high-gain as they concisely convey the key control flow and matching logic."
            ]
        },
        "filter_prorec": {
            "summary": "Finds a lowercase-hashed map entry by string key, falling back to regex pattern matching when no direct hash match is found.",
            "score": [
                0.9,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly describes the function's primary behavior: it computes a lowercase hash of the input string key to find a direct match in the map, and if no hash match is found, it iterates over regex patterns as a fallback. It omits minor implementation details such as the allocation of a lowercase buffer and conditional checks for string length and regex count, but these do not contradict the code. The claims are specific and aligned with the function's domain semantics, making them highly accurate overall.",
                "The summary accurately describes the core purpose of finding a map entry using a lowercased hash of the match string and then falling back to regex matching when no hash match is found, which aligns well with the source code's main functionality. However, it omits secondary details such as allocation from the request pool, handling empty match strings, error return conditions from regex execution, and the conditional compilation for PCRE support. These omissions make coverage of behavior-critical semantics incomplete.",
                "The summary accurately reflects the function\u2019s primary purpose: it first performs a lowercase hash lookup by the string key, and if that fails, it checks regex patterns in the map. These are specific, domain-relevant details aligned with the code, with no factual errors or extraneous noise. The description captures both key lookup methods and their order, providing clear insight into the function\u2019s behavior."
            ]
        }
    }
}
{
    "source_code": "\n\nngx_int_t\nngx_http_request_body_save_filter(ngx_http_request_t *r, ngx_chain_t *in)\n{\n    ngx_buf_t                 *b;\n    ngx_chain_t               *cl;\n    ngx_http_request_body_t   *rb;\n\n    rb = r->request_body;\n\n#if (NGX_DEBUG)\n\n#if 0\n    for (cl = rb->bufs; cl; cl = cl->next) {\n        ngx_log_debug7(NGX_LOG_DEBUG_EVENT, r->connection->log, 0,\n                       \"http body old buf t:%d f:%d %p, pos %p, size: %z \"\n                       \"file: %O, size: %O\",\n                       cl->buf->temporary, cl->buf->in_file,\n                       cl->buf->start, cl->buf->pos,\n                       cl->buf->last - cl->buf->pos,\n                       cl->buf->file_pos,\n                       cl->buf->file_last - cl->buf->file_pos);\n    }\n#endif\n\n    for (cl = in; cl; cl = cl->next) {\n        ngx_log_debug7(NGX_LOG_DEBUG_EVENT, r->connection->log, 0,\n                       \"http body new buf t:%d f:%d %p, pos %p, size: %z \"\n                       \"file: %O, size: %O\",\n                       cl->buf->temporary, cl->buf->in_file,\n                       cl->buf->start, cl->buf->pos,\n                       cl->buf->last - cl->buf->pos,\n                       cl->buf->file_pos,\n                       cl->buf->file_last - cl->buf->file_pos);\n    }\n\n#endif\n\n    /* TODO: coalesce neighbouring buffers */\n\n    if (ngx_chain_add_copy(r->pool, &rb->bufs, in) != NGX_OK) {\n        return NGX_HTTP_INTERNAL_SERVER_ERROR;\n    }\n\n    if (r->request_body_no_buffering) {\n        return NGX_OK;\n    }\n\n    if (rb->rest > 0) {\n\n        if (rb->buf && rb->buf->last == rb->buf->end\n            && ngx_http_write_request_body(r) != NGX_OK)\n        {\n            return NGX_HTTP_INTERNAL_SERVER_ERROR;\n        }\n\n        return NGX_OK;\n    }\n\n    /* rb->rest == 0 */\n\n    if (rb->temp_file || r->request_body_in_file_only) {\n\n        if (ngx_http_write_request_body(r) != NGX_OK) {\n            return NGX_HTTP_INTERNAL_SERVER_ERROR;\n        }\n\n        if (rb->temp_file->file.offset != 0) {\n\n            cl = ngx_chain_get_free_buf(r->pool, &rb->free);\n            if (cl == NULL) {\n                return NGX_HTTP_INTERNAL_SERVER_ERROR;\n            }\n\n            b = cl->buf;\n\n            ngx_memzero(b, sizeof(ngx_buf_t));\n\n            b->in_file = 1;\n            b->file_last = rb->temp_file->file.offset;\n            b->file = &rb->temp_file->file;\n\n            rb->bufs = cl;\n        }\n    }\n\n    return NGX_OK;\n}",
    "comment": "Saves the request body data by copying buffers and managing temporary files for further processing in an NGINX HTTP request.",
    "prorec_sum": "Appends incoming request body buffers to storage and finalizes processing, allocating a new buffer if needed, otherwise returning an error status.",
    "filter_prorec_sum": "Saves incoming HTTP request body data into a buffer chain, flushing or allocating buffers as needed and returning errors on failure.",
    "prorec_aug_sum": "Appends incoming request body data to the buffer chain and manages buffer reuse, returning HTTP 500 on copy or processing failures.",
    "filter_prorec_aug_sum": "Buffers and chains incoming HTTP request body data, invoking further processing when thresholds are met and allocating a free buffer for remaining content.",
    "work_score": {
        "prorec": {
            "summary": "Appends incoming request body buffers to storage and finalizes processing, allocating a new buffer if needed, otherwise returning an error status.",
            "score": [
                0.6,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function appends incoming request body buffers to storage and may allocate a new buffer, which matches the use of ngx_chain_add_copy and ngx_chain_get_free_buf. However, it inaccurately suggests that an error is returned if no new buffer is needed, whereas in the source code errors are only returned on failures like allocation issues or write errors. The finalization aspect is also vague compared to the specific logic for writing to a temp file and handling no-buffering cases. This results in mixed reliability with more than half of the claims accurate but some misrepresentation of conditions for error returns.",
                "The summary correctly notes that incoming request body buffers are appended to storage, which matches the core functionality of adding the new buffers to rb->bufs via ngx_chain_add_copy. However, its mention of allocating a new buffer if needed is only partially accurate and omits critical conditions, such as writing buffers to a temporary file, handling r->request_body_no_buffering, and the specific branches for rb->rest and rb->temp_file scenarios. It also incorrectly implies that allocation happens before error return rather than as part of specific branch logic, and fails to mention key secondary behaviors like error cases for ngx_http_write_request_body, different return codes, and debug logging. Overall, the core is covered but the summary is thin on important secondary semantics.",
                "The summary accurately states that incoming request body buffers are appended to storage, which matches the function\u2019s use of `ngx_chain_add_copy` to add buffers to `rb->bufs`. However, it is partially inaccurate: the claim about allocating a new buffer if needed is misleading because buffer allocation only occurs specifically when certain file conditions are met after `rb->rest == 0`, not as a general fallback. The summary also omits key conditional logic around `request_body_no_buffering`, writing to temp files, and returning error statuses in specific branches, making it overly generic. The worst failure mode is minor NOISE from oversimplification rather than a fatal contradiction, resulting in low net benefit."
            ]
        },
        "filter_prorec": {
            "summary": "Saves incoming HTTP request body data into a buffer chain, flushing or allocating buffers as needed and returning errors on failure.",
            "score": [
                0.8,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function saves incoming HTTP request body data into a buffer chain and returns errors on failure, both of which align with the source code. However, the phrase 'flushing or allocating buffers as needed' is partially accurate: while the code allocates a new buffer in certain conditions, 'flushing' is not explicitly the main behavior\u2014it writes to a request body file under certain flags. Overall, most of the claims are accurate but the summary lacks specificity about the conditions and steps, making it somewhat generic.",
                "The summary correctly states the core behavior of saving incoming HTTP request body data into a buffer chain, which matches the function\u2019s primary purpose of appending the 'in' chain to rb->bufs. However, it is vague and omits important secondary details from the code, such as conditional writing to a temp file, handling rb->rest, the request_body_no_buffering flag, creation of in-file buffers, and specific error paths. This lack of coverage of key branches and side effects limits completeness.",
                "The summary correctly states the core purpose\u2014saving incoming HTTP request body data into a buffer chain\u2014and the possibility of returning errors on failure, which aligns with the code's main logic. However, it omits key conditional behaviors, such as handling of the 'no buffering' flag, writing request body to temporary files, and the specific conditions for flushing or creating file buffers. The phrase 'flushing or allocating buffers as needed' is somewhat generic and does not capture the precise control flow present in the source, but it is not contradictory. The shortcomings are mainly due to low detail rather than inaccuracy, so noise is minimal and all claims are accurate but broad, yielding low gain."
            ]
        }
    }
}
{
    "source_code": "\nint __init APIC_init_uniprocessor(void)\n{\n\tif (disable_apic) {\n\t\tpr_info(\"Apic disabled\\n\");\n\t\treturn -1;\n\t}\n#ifdef CONFIG_X86_64\n\tif (!cpu_has_apic) {\n\t\tdisable_apic = 1;\n\t\tpr_info(\"Apic disabled by BIOS\\n\");\n\t\treturn -1;\n\t}\n#else\n\tif (!smp_found_config && !cpu_has_apic)\n\t\treturn -1;\n\n\t/*\n\t * Complain if the BIOS pretends there is one.\n\t */\n\tif (!cpu_has_apic &&\n\t    APIC_INTEGRATED(apic_version[boot_cpu_physical_apicid])) {\n\t\tpr_err(\"BIOS bug, local APIC 0x%x not detected!...\\n\",\n\t\t\tboot_cpu_physical_apicid);\n\t\treturn -1;\n\t}\n#endif\n\n\tdefault_setup_apic_routing();\n\n\tverify_local_APIC();\n\tconnect_bsp_APIC();\n\n#ifdef CONFIG_X86_64\n\tapic_write(APIC_ID, SET_APIC_ID(boot_cpu_physical_apicid));\n#else\n\t/*\n\t * Hack: In case of kdump, after a crash, kernel might be booting\n\t * on a cpu with non-zero lapic id. But boot_cpu_physical_apicid\n\t * might be zero if read from MP tables. Get it from LAPIC.\n\t */\n# ifdef CONFIG_CRASH_DUMP\n\tboot_cpu_physical_apicid = read_apic_id();\n# endif\n#endif\n\tphysid_set_mask_of_physid(boot_cpu_physical_apicid, &phys_cpu_present_map);\n\tsetup_local_APIC();\n\n#ifdef CONFIG_X86_IO_APIC\n\t/*\n\t * Now enable IO-APICs, actually call clear_IO_APIC\n\t * We need clear_IO_APIC before enabling error vector\n\t */\n\tif (!skip_ioapic_setup && nr_ioapics)\n\t\tenable_IO_APIC();\n#endif\n\n\tbsp_end_local_APIC_setup();\n\n#ifdef CONFIG_X86_IO_APIC\n\tif (smp_found_config && !skip_ioapic_setup && nr_ioapics)\n\t\tsetup_IO_APIC();\n\telse {\n\t\tnr_ioapics = 0;\n\t}\n#endif\n\n\tx86_init.timers.setup_percpu_clockev();\n\treturn 0;\n}",
    "comment": "Initializes the local APIC for uniprocessor systems, verifying configuration and enabling IO-APICs as necessary for proper operation.",
    "prorec_sum": "Initializes ACPI-related hardware state, clears and updates a 1024-entry table, and invokes multiple platform callbacks based on specific configuration flags.",
    "filter_prorec_sum": "Handles ACPI initialization by processing system tables, updating related data structures, and invoking hardware-specific setup routines based on configuration flags.",
    "prorec_aug_sum": "Initializes CPU-related data structures, configures interrupt handling, and updates global state based on hardware flags and initialization conditions.",
    "filter_prorec_aug_sum": "Initializes interrupt-related data structures, sets bit flags, and triggers hardware setup routines based on system state and configuration flags.",
    "work_score": {
        "prorec": {
            "summary": "Initializes ACPI-related hardware state, clears and updates a 1024-entry table, and invokes multiple platform callbacks based on specific configuration flags.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary contains claims about ACPI-related hardware initialization and a 1024-entry table, neither of which are present in the source code. The source code initializes and configures the APIC and IO-APIC, checks CPU/APIC presence, and runs platform setup functions, but does not involve ACPI or table clearing/updating. All claims are inaccurate relative to the code's actual behavior, resulting in no accurate claims.",
                "The summary's claims about initializing ACPI-related hardware, clearing/updating a 1024-entry table, and invoking platform callbacks do not match the source code semantics, which focus on initializing and configuring the local APIC and IO-APIC for a uniprocessor based on CPU/BIOS conditions and configuration flags. None of the claims accurately cover the core operation or the key behavior-critical details from the function.",
                "The summary's claims are all inaccurate: it describes initializing ACPI-related hardware, clearing and updating a 1024-entry table, and invoking platform callbacks, none of which match the source code semantics. The function actually initializes the local APIC and optionally the IO-APIC, checks CPU/APIC presence, configures APIC IDs, and sets up timers. There is a severe mismatch on the primary purpose and key operations, making the content unusable for understanding the code."
            ]
        },
        "filter_prorec": {
            "summary": "Handles ACPI initialization by processing system tables, updating related data structures, and invoking hardware-specific setup routines based on configuration flags.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function handles ACPI initialization, processes system tables, and updates related data structures, which are not reflected in the source code. The function instead initializes APIC in a uniprocessor environment with checks for disable flags, CPU APIC presence, BIOS behavior, and configuration-specific hardware setup routines. All main claims in the summary are inaccurate regarding the source code\u2019s actual semantics, resulting in no accurate matches.",
                "The summary incorrectly describes ACPI initialization, which is unrelated to the function's actual purpose of initializing the local APIC and possibly the IO-APIC on a uniprocessor system based on hardware detection and configuration flags. No accurate claim covers the core domain-specific behavior or other critical details such as BIOS checks, APIC routing, and enabling IO-APICs. All claims are inaccurate as they misidentify the subsystem and operations.",
                "The summary\u2019s primary claim about handling ACPI initialization and processing system tables is inaccurate; the source code focuses on APIC initialization, checking CPU/APIC availability, configuring routing, and setting up local/IO APICs. The mention of ACPI and system tables is unrelated noise that misrepresents the function's core purpose, which is a severe FATAL error on the main domain action. No accurate, specific GOLD claims are present, and the summary fails to reflect key I/O and side effects accurately."
            ]
        }
    }
}
{
    "source_code": "\nstatic int asn1_template_ex_d2i(ASN1_VALUE **val,\n\t\t\t\tconst unsigned char **in, long inlen,\n\t\t\t\tconst ASN1_TEMPLATE *tt, char opt,\n\t\t\t\t\t\t\tASN1_TLC *ctx)\n\t{\n\tint flags, aclass;\n\tint ret;\n\tlong len;\n\tconst unsigned char *p, *q;\n\tchar exp_eoc;\n\tif (!val)\n\t\treturn 0;\n\tflags = tt->flags;\n\taclass = flags & ASN1_TFLG_TAG_CLASS;\n\n\tp = *in;\n\n\t/* Check if EXPLICIT tag expected */\n\tif (flags & ASN1_TFLG_EXPTAG)\n\t\t{\n\t\tchar cst;\n\t\t/* Need to work out amount of data available to the inner\n\t\t * content and where it starts: so read in EXPLICIT header to\n\t\t * get the info.\n\t\t */\n\t\tret = asn1_check_tlen(&len, NULL, NULL, &exp_eoc, &cst,\n\t\t\t\t\t&p, inlen, tt->tag, aclass, opt, ctx);\n\t\tq = p;\n\t\tif (!ret)\n\t\t\t{\n\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tERR_R_NESTED_ASN1_ERROR);\n\t\t\treturn 0;\n\t\t\t}\n\t\telse if (ret == -1)\n\t\t\treturn -1;\n\t\tif (!cst)\n\t\t\t{\n\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tASN1_R_EXPLICIT_TAG_NOT_CONSTRUCTED);\n\t\t\treturn 0;\n\t\t\t}\n\t\t/* We've found the field so it can't be OPTIONAL now */\n\t\tret = asn1_template_noexp_d2i(val, &p, len, tt, 0, ctx);\n\t\tif (!ret)\n\t\t\t{\n\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tERR_R_NESTED_ASN1_ERROR);\n\t\t\treturn 0;\n\t\t\t}\n\t\t/* We read the field in OK so update length */\n\t\tlen -= p - q;\n\t\tif (exp_eoc)\n\t\t\t{\n\t\t\t/* If NDEF we must have an EOC here */\n\t\t\tif (!asn1_check_eoc(&p, len))\n\t\t\t\t{\n\t\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\t\tASN1_R_MISSING_EOC);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\telse\n\t\t\t{\n\t\t\t/* Otherwise we must hit the EXPLICIT tag end or its\n\t\t\t * an error */\n\t\t\tif (len)\n\t\t\t\t{\n\t\t\t\tASN1err(ASN1_F_ASN1_TEMPLATE_EX_D2I,\n\t\t\t\t\tASN1_R_EXPLICIT_LENGTH_MISMATCH);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse \n\t\t\treturn asn1_template_noexp_d2i(val, in, inlen,\n\t\t\t\t\t\t\t\ttt, opt, ctx);\n\n\t*in = p;\n\treturn 1;\n\n\terr:\n\tASN1_template_free(val, tt);\n\treturn 0;\n\t}",
    "comment": "Parses an ASN.1 encoded structure, handling explicit tags and validating length, while managing errors and memory for the decoded value.",
    "prorec_sum": "Parses ASN.1 encoded data with optional tag handling, validates structure, updates buffer position, and reports errors using OpenSSL\u2019s ASN.1 routines.",
    "filter_prorec_sum": "Decodes ASN.1 data with optional indefinite-length handling, validates content, updates the input pointer, and reports detailed errors on format violations.",
    "prorec_aug_sum": "Decodes an ASN.1 template with optional indefinite-length support, validates structure integrity, advances input pointer, and reports detailed errors on failure.",
    "filter_prorec_aug_sum": "Decodes ASN.1 template data with indefinite length handling, validates structure, updates parsing position, and reports detailed errors on failure.",
    "work_score": {
        "prorec": {
            "summary": "Parses ASN.1 encoded data with optional tag handling, validates structure, updates buffer position, and reports errors using OpenSSL\u2019s ASN.1 routines.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function parses ASN.1 encoded data, handles optional tags, validates structure, updates buffer position, and reports errors through OpenSSL ASN.1 routines. These points align with the source code's explicit tag checking, structure validation, position updates via `*in = p`, and use of `ASN1err` for error reporting. All claims are accurate and directly reflect the function's behavior, with no incorrect or irrelevant information.",
                "The summary correctly states that the function parses ASN.1 data, handles optional tags, validates structure, updates buffer position, and reports errors using OpenSSL routines, which matches the core purpose of decoding ASN.1 templates with possible explicit tagging. However, it omits crucial specifics such as handling EXPLICIT tags differently from non-EXPLICIT cases, checking for constructed form, processing lengths and End-of-Content markers, and freeing resources on error. The core is covered but secondary detail coverage is limited.",
                "The summary correctly captures the function\u2019s general purpose of parsing ASN.1 encoded data, handling optional/external tags, validating structure, updating the input pointer, and reporting errors with OpenSSL routines. While accurate, the claims are broad SAFE statements without details of specific tag-class logic, EXPLICIT tag processing, or error conditions found in the source. No factual inaccuracies or contradictions are present, but the gain is low due to lack of precise GOLD-level insights."
            ]
        },
        "filter_prorec": {
            "summary": "Decodes ASN.1 data with optional indefinite-length handling, validates content, updates the input pointer, and reports detailed errors on format violations.",
            "score": [
                0.9,
                0.3,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function decodes ASN.1 data, validates content, updates the input pointer, and reports detailed errors, all of which are evident in the source code. However, the mention of 'optional indefinite-length handling' is only partially accurate\u2014while the code checks for an end-of-content marker (exp_eoc) to handle NDEF encodings, this is specifically within certain EXPLICIT tag conditions, making the phrasing slightly overgeneralized. Overall, most claims are accurate, with minor imprecision on the indefinite-length aspect.",
                "The summary captures general decoding behavior, indefinite-length handling, pointer updates, and error reporting, which are accurate but generic. It fails to mention the core purpose of processing ASN.1 data through explicit tag handling and delegating to no-explicit decoding when appropriate, a key domain-specific operation evident in the source code. Missing details include explicit vs. non-explicit tag paths, constructed constraint enforcement, and specific length/end-of-content checks.",
                "The summary correctly states that the function decodes ASN.1 data, handles indefinite length (via exp_eoc), updates the input pointer, and reports detailed errors on format violations, which aligns with the source code. However, it omits the distinction between explicit and non-explicit tagging paths and does not mention conditional branches or specific tag checks, limiting the informational gain. No inaccurate claims are present, but the description is broadly generic and lacks deeper specifics about key behaviors."
            ]
        }
    }
}
{
    "source_code": "\nstatic psmouse_ret_t cypress_protocol_handler(struct psmouse *psmouse)\n{\n\tstruct cytp_data *cytp = psmouse->private;\n\n\tif (psmouse->pktcnt >= cytp->pkt_size) {\n\t\tcypress_process_packet(psmouse, 0);\n\t\treturn PSMOUSE_FULL_PACKET;\n\t}\n\n\treturn cypress_validate_byte(psmouse);\n}",
    "comment": "Handles packet processing for a Cypress device, validating bytes and triggering full packet processing when the expected packet size is reached.",
    "prorec_sum": "Adjusts a hardware control field based on status bytes and flags, or triggers a fallback routine when conditions invalidate the current sequence.",
    "filter_prorec_sum": "Adjusts device configuration based on status flags and counters, or invokes a reset routine when conditions are not met.",
    "prorec_aug_sum": "Updates a device state counter and conditionally modifies configuration flags or triggers a reset based on control byte and status field conditions.",
    "filter_prorec_aug_sum": "Updates a hardware control field based on device status flags and counters, or triggers a fallback handler when conditions are not met.",
    "work_score": {
        "prorec": {
            "summary": "Adjusts a hardware control field based on status bytes and flags, or triggers a fallback routine when conditions invalidate the current sequence.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes adjusting a hardware control field based on status bytes and flags, and triggering a fallback routine when conditions invalidate the sequence. None of these actions are present in the source code, which instead checks if the packet count meets or exceeds a size threshold, processes the packet, and returns appropriate constants or validation results. All claims are inaccurate as they contradict the function's actual behavior.",
                "The summary does not accurately reflect the source code, which checks if the packet count meets the expected packet size, processes the packet, and returns appropriate status, otherwise validates the byte. The claims about adjusting hardware control fields and triggering fallback routines are unrelated to the actual logic and domain operation. The core behavior of handling and validating Cypress protocol packets is entirely missing, and no secondary relevant details are provided.",
                "The summary claims that the function adjusts a hardware control field based on status bytes and flags, and triggers a fallback routine when conditions invalidate the current sequence. These statements do not match the source code, which processes a full packet when enough bytes are collected or validates a byte otherwise. There is no mention of hardware control fields, status bytes, or fallback routines in the code. This is a FATAL error on the primary purpose and key logic, making the description incorrect and misleading."
            ]
        },
        "filter_prorec": {
            "summary": "Adjusts device configuration based on status flags and counters, or invokes a reset routine when conditions are not met.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function adjusts device configuration and may invoke a reset routine when certain conditions are not met, but the source code shows it only processes a packet when a counter reaches a size threshold or validates a byte otherwise. There is no evidence of device configuration changes or a reset routine, making the claim inaccurate and unrelated to the actual behavior. All claims here are inaccurate, resulting in low alignment with the evaluation steps.",
                "The summary's claims about adjusting device configuration and invoking a reset routine do not align with the source code, which conditionally processes a packet when the accumulated byte count meets the expected packet size and otherwise validates individual bytes. The core purpose of handling Cypress mouse protocol packets is not covered, and no accurate domain-specific actions from the code are reflected in the summary.",
                "The summary claims the function adjusts device configuration based on status flags and counters, and invokes a reset routine when conditions are not met. These are inaccurate relative to the source code: the function checks if the packet count meets or exceeds the expected packet size, processes the packet if so, otherwise calls a validation function. There is no configuration adjustment or reset routine. This is a FATAL error regarding the primary purpose of the function, making the description misleading and unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\ninfo_signal_proc (int sig)\n{\n  signal_info *old_signal_handler = NULL;\n\n#if !defined (HAVE_SIGACTION)\n  /* best effort: first increment this counter and later block signals */\n  if (term_conf_busy)\n    return;\n  term_conf_busy++;\n#if defined (HAVE_SIGPROCMASK)\n    {\n      sigset_t nvar, ovar;\n      sigemptyset (&nvar);\n      mask_termsig (&nvar);\n      sigprocmask (SIG_BLOCK, &nvar, &ovar);\n    }\n#endif /* HAVE_SIGPROCMASK */\n#endif /* !HAVE_SIGACTION */\n  switch (sig)\n    {\n#if defined (SIGTSTP)\n    case SIGTSTP:\n    case SIGTTOU:\n    case SIGTTIN:\n#endif\n#if defined (SIGQUIT)\n    case SIGQUIT:\n#endif\n#if defined (SIGINT)\n    case SIGINT:\n#endif\n#if defined (SIGTERM)\n    case SIGTERM:\n#endif\n      {\n#if defined (SIGTSTP)\n        if (sig == SIGTSTP)\n          old_signal_handler = &old_TSTP;\n        if (sig == SIGTTOU)\n          old_signal_handler = &old_TTOU;\n        if (sig == SIGTTIN)\n          old_signal_handler = &old_TTIN;\n#endif /* SIGTSTP */\n#if defined (SIGQUIT)\n        if (sig == SIGQUIT)\n          old_signal_handler = &old_QUIT;\n#endif /* SIGQUIT */\n#if defined (SIGINT)\n        if (sig == SIGINT)\n          old_signal_handler = &old_INT;\n#endif /* SIGINT */\n#if defined (SIGTERM)\n        if (sig == SIGTERM)\n          old_signal_handler = &old_TERM;\n#endif /* SIGTERM */\n\n        /* For stop signals, restore the terminal IO, leave the cursor\n           at the bottom of the window, and stop us. */\n        terminal_goto_xy (0, screenheight - 1);\n        terminal_clear_to_eol ();\n        fflush (stdout);\n        terminal_unprep_terminal ();\n\trestore_termsig (sig, old_signal_handler);\n\tUNBLOCK_SIGNAL (sig);\n\tkill (getpid (), sig);\n\n        /* The program is returning now.  Restore our signal handler,\n           turn on terminal handling, redraw the screen, and place the\n           cursor where it belongs. */\n        terminal_prep_terminal ();\n\tset_termsig (sig, old_signal_handler);\n\t/* window size might be changed while sleeping */\n\treset_info_window_sizes ();\n      }\n      break;\n\n#if defined (SIGWINCH) || defined (SIGUSR1)\n#ifdef SIGWINCH\n    case SIGWINCH:\n#endif\n#ifdef SIGUSR1\n    case SIGUSR1:\n#endif\n      {\n\t/* Turn off terminal IO, tell our parent that the window has changed,\n\t   then reinitialize the terminal and rebuild our windows. */\n#ifdef SIGWINCH\n\tif (sig == SIGWINCH)\n\t  old_signal_handler = &old_WINCH;\n#endif\n#ifdef SIGUSR1\n\tif (sig == SIGUSR1)\n\t  old_signal_handler = &old_USR1;\n#endif\n\n        /* This seems risky: what if we receive a (real) signal before\n           the next line is reached? */\n#if 0\n\trestore_termsig (sig, old_signal_handler);\n\tkill (getpid (), sig);\n#endif\n\n\t/* After our old signal handler returns... */\n\tset_termsig (sig, old_signal_handler); /* needless? */\n\n        if (sigwinch_block_count != 0)\n          abort ();\n\n        /* Avoid any of the code unblocking the signal too early.  This\n           should set the variable to 1 because we shouldn't be here if\n           sigwinch_block_count > 0. */\n        sigwinch_block_count++;\n\n\treset_info_window_sizes ();\n\n        sigwinch_block_count--;\n        /* Don't unblock the signal until after we've finished. */\n\tUNBLOCK_SIGNAL (sig);\n      }\n      break;\n#endif /* SIGWINCH || SIGUSR1 */\n    }\n#if !defined (HAVE_SIGACTION)\n  /* at this time it is safer to perform unblock after decrement */\n  term_conf_busy--;\n#if defined (HAVE_SIGPROCMASK)\n    {\n      sigset_t nvar, ovar;\n      sigemptyset (&nvar);\n      mask_termsig (&nvar);\n      sigprocmask (SIG_UNBLOCK, &nvar, &ovar);\n    }\n#endif /* HAVE_SIGPROCMASK */\n#endif /* !HAVE_SIGACTION */\n}",
    "comment": "Handles various signals by restoring terminal settings, blocking signals during critical sections, and managing terminal window size changes.",
    "prorec_sum": "Handles specific signals by temporarily swapping handlers, masking the signal, sending it to the process, restoring handlers, and performing associated cleanup routines.",
    "filter_prorec_sum": "Handles specific signals by temporarily swapping sigaction handlers, delivering the signal to itself, and restoring the original handler configuration.",
    "prorec_aug_sum": "Handles specific signals by temporarily replacing their handlers, triggering the signal for self-delivery, and then restoring the original signal actions and masks.",
    "filter_prorec_aug_sum": "Handles specific signals by temporarily swapping handlers, flushing state, sending the signal to itself, then restoring the original signal actions.",
    "work_score": {
        "prorec": {
            "summary": "Handles specific signals by temporarily swapping handlers, masking the signal, sending it to the process, restoring handlers, and performing associated cleanup routines.",
            "score": [
                0.7,
                0.4,
                0.5
            ],
            "reason": [
                "The summary correctly identifies that the function handles specific signals and swaps handlers, sends the signal to the process, restores handlers, and does cleanup routines, which matches the code's logic for signals like SIGTSTP and SIGWINCH. However, it inaccurately generalizes the behavior by omitting conditional compilation details, the distinction between blocking/unblocking signals, and the scope-specific handling for window change signals, which reduces precision. Most of the claims are still accurate but lack specificity.",
                "The summary correctly notes that the function handles specific signals, swaps handlers, masks the signal, sends it to the process, restores handlers, and performs cleanup \u2014 all of which are supported by the source code. However, it fails to cover the core primary purpose at the required level of specificity: managing terminal state and window resizing in response to signals like SIGTSTP, SIGWINCH, etc. It omits key context such as restoring terminal I/O, repositioning the cursor, and handling SIGWINCH window size changes, which are central to the function's domain semantics.",
                "The summary is broadly consistent with the code\u2019s behavior for certain signals, correctly noting swapping handlers, masking, sending signals, restoring handlers, and cleanup. However, it is generic and omits key specifics such as differences in handling stop signals vs. window change/user signals, the terminal I/O preparation and restoration steps, and conditional compilation paths. No claims are outright false, but the lack of detail limits usefulness, making gain low despite accuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Handles specific signals by temporarily swapping sigaction handlers, delivering the signal to itself, and restoring the original handler configuration.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the implementation as using 'sigaction' handlers, while the source code conditionally uses older signal handling mechanisms and direct function calls instead. It omits important behaviors such as blocking/unblocking signals, terminal state management, and window size resets. Because the sole claim about swapping sigaction handlers and self-delivery is misleading in this context, the proportion of accurate claims is very low.",
                "The summary correctly notes that the function handles specific signals and restores handlers, but it inaccurately describes the mechanism as 'swapping sigaction handlers', which contradicts the code since sigaction isn't always used and legacy signal handling with conditional compilation is implemented. It omits the core purpose of safely processing terminal-related signals to manage terminal state (unprep, prep, redraw) and window size changes while blocking/unblocking signals to avoid race conditions. Secondary behaviors like handling SIGWINCH/SIGUSR1 to reset window sizes and the detailed terminal I/O restoration are not covered.",
                "The summary claims the function uses sigaction handlers, but the source code uses custom handler pointers and conditional compilation without direct sigaction calls, making this a factual inaccuracy about its core behavior. The rest of the description broadly matches the delivery of signals to itself and restoration of handlers, but the key mechanism is misrepresented. This constitutes a severe FATAL error on the primary purpose of the function, leading to very low trust."
            ]
        }
    }
}
{
    "source_code": "int ENGINE_add(ENGINE *e)\n\t{\n\tint to_return = 1;\n\tif(e == NULL)\n\t\t{\n\t\tENGINEerr(ENGINE_F_ENGINE_ADD,\n\t\t\tERR_R_PASSED_NULL_PARAMETER);\n\t\treturn 0;\n\t\t}\n\tif((e->id == NULL) || (e->name == NULL))\n\t\t{\n\t\tENGINEerr(ENGINE_F_ENGINE_ADD,\n\t\t\tENGINE_R_ID_OR_NAME_MISSING);\n\t\t}\n\tCRYPTO_w_lock(CRYPTO_LOCK_ENGINE);\n\tif(!engine_list_add(e))\n\t\t{\n\t\tENGINEerr(ENGINE_F_ENGINE_ADD,\n\t\t\tENGINE_R_INTERNAL_LIST_ERROR);\n\t\tto_return = 0;\n\t\t}\n\tCRYPTO_w_unlock(CRYPTO_LOCK_ENGINE);\n\treturn to_return;\n\t}",
    "comment": "Adds an ENGINE structure to a list after validating its parameters and managing thread safety with locks.",
    "prorec_sum": "Registers a new ENGINE into the global engine list with duplicate checks, error reporting, and linked-list management under locking.",
    "filter_prorec_sum": "Registers a new ENGINE structure into the global engine list with duplicate checks, error reporting, and thread\u2011safe list updates.",
    "prorec_aug_sum": "Registers a new ENGINE into OpenSSL\u2019s global linked list, ensuring uniqueness, updating linkage pointers, and reporting detailed errors under locking.",
    "filter_prorec_aug_sum": "Registers a new ENGINE structure into the global linked list with locking, validating identifiers, and reporting errors for duplicates or invalid inputs.",
    "work_score": {
        "prorec": {
            "summary": "Registers a new ENGINE into the global engine list with duplicate checks, error reporting, and linked-list management under locking.",
            "score": [
                0.8,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function registers a new ENGINE in the global engine list under locking and handles error reporting, which aligns with the source code. However, it inaccurately adds details about duplicate checks and linked-list management that are not explicitly present in the provided code, lowering claim accuracy. Most claims are accurate, but the extra unsupported elements slightly reduce precision.",
                "The summary's core claim about registering a new ENGINE into a global list under locking aligns with the code's primary purpose of adding an ENGINE to a global list with write locks. However, it inaccurately introduces 'duplicate checks' not evident in the source, as the code only validates that id and name are non-NULL and reports errors for missing values or internal list failures. It omits important specifics such as handling NULL parameter errors, missing identifiers, and the exact return value behavior. Coverage of the core purpose is present but secondary behavior descriptions are incomplete and partly incorrect.",
                "The summary correctly identifies that the function registers an ENGINE in a global list with error reporting and locking, which matches the source code. However, it inaccurately introduces 'duplicate checks' \u2014 the code shown only delegates to engine_list_add and does not explicitly implement duplicate detection in this snippet. The rest of the claims are accurate but somewhat generic. The incorrect 'duplicate checks' claim is a FATAL error on the core behavior, reducing trust in the summary."
            ]
        },
        "filter_prorec": {
            "summary": "Registers a new ENGINE structure into the global engine list with duplicate checks, error reporting, and thread\u2011safe list updates.",
            "score": [
                0.8,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function registers an ENGINE into a global list, includes error reporting, and uses thread\u2011safe updates via locks, which are supported by the code. However, it inaccurately adds a 'duplicate checks' detail that is not evident in the source; the code calls engine_list_add but does not explicitly show duplicate verification. Most claims are accurate, but the duplicate check is unsupported, reducing precision.",
                "The summary correctly states the core purpose of adding an ENGINE structure to a global list and notes thread safety and error reporting, which match the source code\u2019s use of CRYPTO_w_lock/CRYPTO_w_unlock and ENGINEerr calls. However, it inaccurately mentions duplicate checks, which are not evident in the code, and omits some specific error conditions such as null parameter handling, missing id/name, and internal list addition failure. Overall, it covers the primary purpose but leaves out several key behavioral details and includes a misleading claim.",
                "The summary correctly states that the function registers a new ENGINE structure into a global list, reports errors, and uses thread-safe updates, aligning with the source code\u2019s locking and error calls. However, it inaccurately adds a claim about duplicate checks, which is not evident in the provided code and thus constitutes a FATAL error regarding the function\u2019s core behavior. This severely undermines trustworthiness despite some accurate elements."
            ]
        }
    }
}
{
    "source_code": "\nstatic int inet6_addr_del(struct net *net, int ifindex, const struct in6_addr *pfx,\n\t\t\t  unsigned int plen)\n{\n\tstruct inet6_ifaddr *ifp;\n\tstruct inet6_dev *idev;\n\tstruct net_device *dev;\n\n\tif (plen > 128)\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tif ((idev = __in6_dev_get(dev)) == NULL)\n\t\treturn -ENXIO;\n\n\tread_lock_bh(&idev->lock);\n\tlist_for_each_entry(ifp, &idev->addr_list, if_list) {\n\t\tif (ifp->prefix_len == plen &&\n\t\t    ipv6_addr_equal(pfx, &ifp->addr)) {\n\t\t\tin6_ifa_hold(ifp);\n\t\t\tread_unlock_bh(&idev->lock);\n\n\t\t\tipv6_del_addr(ifp);\n\n\t\t\t/* If the last address is deleted administratively,\n\t\t\t   disable IPv6 on this interface.\n\t\t\t */\n\t\t\tif (list_empty(&idev->addr_list))\n\t\t\t\taddrconf_ifdown(idev->dev, 1);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tread_unlock_bh(&idev->lock);\n\treturn -EADDRNOTAVAIL;\n}",
    "comment": "Removes an IPv6 address from a network interface and disables IPv6 if it becomes the last address.",
    "prorec_sum": "Searches a socket\u2019s connection list for a matching endpoint by address and ID, updates its reference count, and triggers related handler routines.",
    "filter_prorec_sum": "Searches a socket\u2019s bound address list for a matching entry by length and identifier, updates reference counts, and triggers associated connection handling callbacks.",
    "prorec_aug_sum": "Searches for a matching entry by identifier and key, updates related metrics, and triggers further processing with provided parameters if found.",
    "filter_prorec_aug_sum": "Searches a multicast source list for a matching entry by address and key, updates related counters, and triggers associated processing callbacks.",
    "work_score": {
        "prorec": {
            "summary": "Searches a socket\u2019s connection list for a matching endpoint by address and ID, updates its reference count, and triggers related handler routines.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary\u2019s claims about searching a socket\u2019s connection list, matching by address and ID, updating reference counts, and triggering handler routines do not align with the source code. The function operates on IPv6 interface addresses\u2014validating prefix length, obtaining a network device, locking, searching its address list, removing a matching address, possibly disabling IPv6, and returning status codes. All claims in the summary target unrelated socket behavior, making them inaccurate.",
                "The summary\u2019s claims about searching a socket\u2019s connection list, matching by address and ID, and updating reference counts target a different domain than the source code, which deletes an IPv6 address from a network interface, checks for matching prefix length and address, handles locking, removes the address, and may disable IPv6. None of the summary\u2019s claims accurately describe the core purpose or any secondary behaviors from the function.",
                "The summary's claims about searching a socket\u2019s connection list, matching by address and ID, and triggering handler routines do not match the source code, which operates on IPv6 interface addresses in a network device, removes them, and may disable IPv6 if the last address is removed. These are FATAL inaccuracies about the primary purpose, describing unrelated socket operations instead of the actual address deletion logic. No accurate claims are present, yielding negative benefit."
            ]
        },
        "filter_prorec": {
            "summary": "Searches a socket\u2019s bound address list for a matching entry by length and identifier, updates reference counts, and triggers associated connection handling callbacks.",
            "score": [
                0.2,
                0.1,
                0.1
            ],
            "reason": [
                "The summary incorrectly describes searching a socket\u2019s bound address list and triggering connection handling callbacks, which is not present in the source code. The function actually searches an IPv6 interface\u2019s address list, matches prefix length and address, updates reference counts, deletes the address, and may disable IPv6 on the interface. None of these correct semantics are captured accurately, resulting in mostly inaccurate claims.",
                "The summary claims the function searches a socket\u2019s bound address list, manages reference counts, and triggers connection handling callbacks. These points are inaccurate: the function searches an IPv6 interface's address list in a network device, not a socket, and it deletes the matching address rather than invoking connection callbacks. It also deals with interface IPv6 state shutdown, which is missing from the summary. The core domain purpose\u2014removing an IPv6 address from a specific interface given a prefix and length\u2014is not covered, and there is negligible accurate information.",
                "The summary's claims largely misrepresent the function's actual behavior. It incorrectly states that the function searches a socket\u2019s bound address list and triggers connection handling callbacks, which contradicts the source code that operates on an IPv6 interface\u2019s address list and conditionally disables IPv6 after deleting a matching address. This is a FATAL error on the primary purpose, since it misidentifies the domain (interfaces vs. sockets) and misstates the core side effects. No accurate, domain-specific claims are present, so the net benefit is unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic char *\nstyle_sheet_mixed_new (const uchar * ancestors)\n{\n  struct style_sheet *sheet, *ancestor;\n  char *ancestor_key, *key, *cp;\n  char *ancestors_keys;\n  struct darray *ancestors_array;\n\n  /* It cannot be longer than ancestors_keys. */\n  key = ALLOCA (char, ustrlen (ancestors) + 1);\n  astrcpy (ancestors_keys, ancestors);\n\n  /* Create the darray of ancestors keys, and build the final key. */\n  ancestors_array = ancestors_new ();\n  ancestor_key = strtok (ancestors_keys, MIXED_SHEET_SEP);\n  da_append (ancestors_array, ancestor_key);\n  ancestor = get_style_sheet (ancestor_key);\n  cp = stpcpy (key, ancestor->key);\n\n  while ((ancestor_key = strtok (NULL, MIXED_SHEET_SEP)))\n    {\n      da_append (ancestors_array, ancestor_key);\n      ancestor = get_style_sheet (ancestor_key);\n      *cp++ =',';\n      cp = stpcpy (cp, ancestor->key);\n    }\n  *cp = '\\0';\n  key = xstrdup (key);\n\n  /* Create the style sheet. */\n  message (msg_sheet,\n\t   (stderr, \"Creating a mixed style sheet \\\"%s\\\"\\n\", key));\n  /* Its name is its key. */\n  sheet = new_style_sheet ((uchar *) key);\n  sheet->key = strdup (key);\n  da_concat (sheet->ancestors, ancestors_array);\n  da_erase (ancestors_array);\n  style_sheet_finalize (sheet);\n\n  return key;\n}",
    "comment": "Creates a new style sheet by concatenating keys from ancestor style sheets, storing them in a darray, and finalizing the new sheet.",
    "prorec_sum": "Parses a comma- or semicolon-separated list of ancestor style sheets, registers each, builds a combined name, and creates the corresponding mixed style sheet entry.",
    "filter_prorec_sum": "Parses a comma or semicolon separated list of style sheet names, registers them as \u201cAncestors,\u201d and creates a combined mixed style sheet entry.",
    "prorec_aug_sum": "Parses a comma- or semicolon-separated list of ancestor stylesheets, registers them, and creates a combined \u201cmixed style sheet\u201d entry with associated metadata.",
    "filter_prorec_aug_sum": "Parses a comma- or semicolon-separated list of stylesheet names, registers them as \"Ancestors\", and creates a combined mixed stylesheet entry.",
    "work_score": {
        "prorec": {
            "summary": "Parses a comma- or semicolon-separated list of ancestor style sheets, registers each, builds a combined name, and creates the corresponding mixed style sheet entry.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly identifies that the function processes a list of ancestor style sheets, registers each by appending them to an array, builds a combined key, and creates a mixed style sheet entry, aligning with the source code behavior. The only minor inaccuracy is the mention of both comma and semicolon as separators, while the actual separator is defined by MIXED_SHEET_SEP and not explicitly shown to be semicolon, making it slightly speculative. Overall, the majority of claims are accurate and grounded in the code.",
                "The summary accurately captures the core function's primary purpose: splitting the input list of ancestor style sheets using a predefined separator, retrieving each ancestor, concatenating their keys into a combined key, and creating a new mixed style sheet. It correctly identifies the parsing of separators, registration via appending to the ancestor array, name building, and creation of the mixed style sheet object. However, it omits secondary details such as memory allocation with ALLOCA/xstrdup, logging via message, finalization, and cleanup of the ancestor array, which limits completeness.",
                "The summary accurately states that the function takes a separated list of ancestor style sheets, processes each to build a combined key, and creates a mixed style sheet. The mention of comma separation is correct; however, semicolon separation is not verifiable from the code and likely inaccurate. Aside from that minor inaccuracy, the core purpose and key I/O behavior are correctly captured with low noise. Gain is moderate, as the description is fairly specific about the process."
            ]
        },
        "filter_prorec": {
            "summary": "Parses a comma or semicolon separated list of style sheet names, registers them as \u201cAncestors,\u201d and creates a combined mixed style sheet entry.",
            "score": [
                0.8,
                0.6,
                0.5
            ],
            "reason": [
                "The summary claims the function parses a comma or semicolon separated list of style sheet names, registers them as ancestors, and creates a combined mixed style sheet entry. The source code shows it splits input based on MIXED_SHEET_SEP, retrieves ancestor style sheets, appends their keys with commas, and constructs a new style sheet with those ancestors\u2014matching the parsing and combining part. However, the mention of semicolon separation is unsupported by the code, which does not explicitly indicate that MIXED_SHEET_SEP includes semicolons. Overall, most claims align, but there is a minor inaccuracy.",
                "The summary correctly captures the core purpose: parsing a delimited list of style sheet names and creating a mixed style sheet with those ancestors, which matches the source code\u2019s behavior of tokenizing by a separator, retrieving related sheets, building a combined key, and instantiating a new sheet. However, it does not mention key implementation details like building the unique key string from ancestor keys, logging the creation, duplicating and storing the key, concatenating ancestor arrays into the new sheet, and finalizing it. These omissions reduce coverage of critical secondary semantics.",
                "The summary correctly states that the function parses a list of style sheet names and creates a mixed style sheet entry, aligning with the code\u2019s process of splitting ancestor keys, building a combined key, and creating a new style sheet. However, it inaccurately specifies semicolons as possible separators, while the source only uses MIXED_SHEET_SEP (likely a comma) without evidence of semicolon handling. Additionally, the term 'registers them as Ancestors' is somewhat vague and does not clearly reflect the array construction and concatenation logic. The inaccuracies are minor and do not affect core purpose comprehension, but the summary provides only broad SAFE-level insight and lacks specific details such as the exact concatenation and memory handling, leading to a low net benefit."
            ]
        }
    }
}
{
    "source_code": "EXPORT BITCODE_H\ndwg_find_tablehandle (Dwg_Data *restrict dwg, const char *restrict name,\n                      const char *restrict table)\n{\n  BITCODE_BL i, num_entries = 0;\n  BITCODE_H ctrl = NULL, *hdlv = NULL;\n  Dwg_Object *obj;\n  Dwg_Object_APPID_CONTROL *_obj; // just some random generic type\n  Dwg_Header_Variables *vars = &dwg->header_vars;\n\n  if (!dwg || !name || !table)\n    return NULL;\n  // look for the _CONTROL table, and search for name in all entries\n  ctrl = dwg_ctrl_table (dwg, table);\n  if (strEQc (table, \"LTYPE\"))\n    {\n      if (strEQc (name, \"BYLAYER\") || strEQc (name, \"ByLayer\"))\n        {\n          if (vars->LTYPE_BYLAYER)\n            return vars->LTYPE_BYLAYER;\n        }\n      else if (strEQc (name, \"BYBLOCK\") || strEQc (name, \"ByBlock\"))\n        {\n          if (vars->LTYPE_BYBLOCK)\n            return vars->LTYPE_BYBLOCK;\n        }\n      else if (strEQc (name, \"CONTINUOUS\") || strEQc (name, \"Continuous\"))\n        {\n          if (vars->LTYPE_CONTINUOUS)\n            return vars->LTYPE_CONTINUOUS;\n        }\n    }\n  if (!ctrl)\n    { // TODO: silently search table_control. header_vars can be empty\n      LOG_TRACE (\"dwg_find_tablehandle: Empty header_vars table %s\\n\", table);\n      return NULL;\n    }\n  obj = dwg_resolve_handle (dwg, ctrl->absolute_ref);\n  if (!obj)\n    {\n      LOG_TRACE (\"dwg_find_tablehandle: Could not resolve table %s\\n\", table);\n      return NULL;\n    }\n  if (obj->type == DWG_TYPE_DICTIONARY)\n    return dwg_find_dicthandle_objname (dwg, ctrl, name);\n  if (!dwg_obj_is_control (obj))\n    {\n      LOG_ERROR (\"dwg_find_tablehandle: Could not resolve CONTROL object %s \"\n                 \"for table %s\",\n                 obj->name, table);\n      return NULL;\n    }\n  _obj = obj->tio.object->tio.APPID_CONTROL; // just random type\n  dwg_dynapi_entity_value (_obj, obj->name, \"num_entries\", &num_entries, NULL);\n  if (!num_entries)\n    return NULL;\n  dwg_dynapi_entity_value (_obj, obj->name, \"entries\", &hdlv, NULL);\n  if (!hdlv)\n    return NULL;\n  for (i = 0; i < num_entries; i++)\n    {\n      char *hdlname;\n      Dwg_Object *hobj;\n      Dwg_Object_APPID *_o;\n      int isnew = 0;\n      bool ok;\n\n      if (!hdlv[i])\n        continue;\n      hobj = dwg_resolve_handle (dwg, hdlv[i]->absolute_ref);\n      if (!hobj || !hobj->tio.object || !hobj->tio.object->tio.APPID)\n        continue;\n      _o = hobj->tio.object->tio.APPID;\n      ok = dwg_dynapi_entity_utf8text (_o, hobj->name, \"name\", &hdlname, &isnew, NULL);\n      LOG_HANDLE (\" %s.%s[%d] => %s.name: %s\\n\", obj->name, \"entries\", i,\n                  hobj->name, hdlname ? hdlname : \"NULL\");\n      if (ok && hdlname && (strEQ (name, hdlname) || !strcasecmp (name, hdlname)))\n        {\n          if (isnew)\n            free (hdlname);\n          return hdlv[i];\n        }\n      if (ok && isnew && hdlname)\n        free (hdlname);\n    }\n\n  return NULL;\n}",
    "comment": "Retrieves a handle for a specified named entry in a given table from a DWG file's control structure.",
    "prorec_sum": "Retrieves a DWG table handle by name, with special cases for common linetypes, resolving related handles and reporting errors when lookup fails.",
    "filter_prorec_sum": "Retrieves a specific DWG table entry handle by table and entry name, with special handling for common LTYPE names and error reporting.",
    "prorec_aug_sum": "Retrieves a specific CAD table handle from a DWG structure by matching table and entry names, with special handling for common linetype constants.",
    "filter_prorec_aug_sum": "Retrieves a DWG table handle for a specified table and entry name, with special handling for predefined LTYPE entries and error reporting.",
    "work_score": {
        "prorec": {
            "summary": "Retrieves a DWG table handle by name, with special cases for common linetypes, resolving related handles and reporting errors when lookup fails.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary captures core behavior accurately: it describes retrieving a DWG table handle by name, notes special handling for common linetypes like BYLAYER, BYBLOCK, CONTINUOUS, and mentions resolving handles and reporting errors when lookups fail. These points align with the source code\u2019s logic paths and error logging. While somewhat high-level, all claims are supported by the code with no contradictions.",
                "The summary correctly identifies that the function retrieves a DWG table handle by name and notes special handling for common linetypes, which matches the core purpose. It also mentions resolving handles and error logging when lookup fails, reflecting secondary behaviors in the code such as handle resolution and logging on failures. However, it omits many key implementation details like dictionary type handling, control object verification, header variable usage, iterating over entries to match names, and multiple specific null-return conditions, so coverage of secondary semantics is limited.",
                "The summary correctly states that the function retrieves a DWG table handle by name and has special handling for common linetypes, matching the code\u2019s branches for 'BYLAYER', 'BYBLOCK', and 'CONTINUOUS'. It also notes error reporting when lookups fail, which aligns with LOG_TRACE and LOG_ERROR calls. However, it omits key specifics about the lookup process, such as the resolution of control objects, dictionary handling, iteration through entries, and conditional returns for missing data. The claims are accurate but generally broad, providing low informational gain."
            ]
        },
        "filter_prorec": {
            "summary": "Retrieves a specific DWG table entry handle by table and entry name, with special handling for common LTYPE names and error reporting.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function retrieves a DWG table entry handle given a table and entry name, and that it has special handling for common LTYPE names, both of which are evident in the code. It also notes error reporting, which is supported by multiple LOG_TRACE and LOG_ERROR calls. These claims are specific to the function's semantics and align well with the source code, with no contradictory or irrelevant elements.",
                "The summary correctly states that the function retrieves a DWG table entry handle by table and entry name, and notes special handling for common LTYPE names as well as error reporting, all of which align with the source code's core purpose and behavior. However, it omits secondary details such as early NULL checks for inputs, resolution of control handles, dictionary-type handling, iteration over entries, and matching by name, which are important behavior-critical semantics.",
                "The summary correctly states the primary purpose of retrieving a DWG table entry handle by table and entry name, and notes special handling for common LTYPE names, which matches the code\u2019s explicit checks for \"BYLAYER\", \"BYBLOCK\", and \"CONTINUOUS\". It also mentions error reporting, aligning with multiple LOG_TRACE and LOG_ERROR calls. No contradictory or irrelevant claims are present, but the description is generic and omits details like fallback behavior to dictionary search, control checks, and iteration over entries, resulting in low informational gain despite being accurate."
            ]
        }
    }
}
{
    "source_code": "static void\nPerform_Justification(FIELD *field, WINDOW *win)\n{\n  FIELD_CELL *bp;\n  int len;\n\n  bp = (Field_Has_Option(field, O_NO_LEFT_STRIP)\n\t? field->buf\n\t: Get_Start_Of_Data(field->buf, Buffer_Length(field)));\n  len = (int)(After_End_Of_Data(field->buf, Buffer_Length(field)) - bp);\n\n  if (len > 0)\n    {\n      int col = 0;\n\n      assert(win && (field->drows == 1));\n\n      if (field->cols - len >= 0)\n\tswitch (field->just)\n\t  {\n\t  case JUSTIFY_LEFT:\n\t    break;\n\t  case JUSTIFY_CENTER:\n\t    col = (field->cols - len) / 2;\n\t    break;\n\t  case JUSTIFY_RIGHT:\n\t    col = field->cols - len;\n\t    break;\n\t  default:\n\t    break;\n\t  }\n\n      wmove(win, 0, col);\n      myADDNSTR(win, bp, len);\n    }\n}",
    "comment": "Justifies the contents of a field within a window by aligning text based on specified justification (left, center, right) and current field length.",
    "prorec_sum": "Trims leading and trailing space characters from a fixed-size byte buffer segment and writes the cleaned data into the destination buffer.",
    "filter_prorec_sum": "Trims leading and trailing space characters from a buffer segment and writes the resulting content into the destination with padding if needed.",
    "prorec_aug_sum": "Trims leading and trailing spaces from a data buffer and writes the trimmed segment into the destination with adjusted length handling.",
    "filter_prorec_aug_sum": "Trims leading and trailing space characters from a fixed-size byte buffer and writes the resulting segment to the specified output.",
    "work_score": {
        "prorec": {
            "summary": "Trims leading and trailing space characters from a fixed-size byte buffer segment and writes the cleaned data into the destination buffer.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly claims that the function trims leading and trailing spaces from a byte buffer and writes the cleaned data to a destination buffer. In the source code, leading spaces are only conditionally skipped based on the O_NO_LEFT_STRIP option, and trailing spaces are not explicitly trimmed. The actual behavior centers on determining the start and end of data within a form field buffer and then outputting it to a window with specific text justification, which is not mentioned in the summary. This mismatch makes the claims predominantly inaccurate.",
                "The summary inaccurately states that the function trims both leading and trailing spaces from a buffer and writes cleaned data into a destination buffer, which does not match the source code. The code conditionally strips leading spaces unless O_NO_LEFT_STRIP is set, calculates the length without trailing trim logic, determines column offset based on justification settings, and writes to a window, not a generic destination buffer. The core purpose of performing text justification within a single-row field in a curses window is completely missed, and no accurate claims cover the key semantics or side effects present.",
                "The summary contains a FATAL inaccuracy about the primary purpose: it claims the function trims leading and trailing spaces, but the source code only conditionally strips leading spaces depending on an option and does not remove trailing spaces. The actual purpose is to justify text within a single-row field based on alignment settings, then render it to the window. This mismatch on the core behavior makes the description misleading and unusable for understanding the function."
            ]
        },
        "filter_prorec": {
            "summary": "Trims leading and trailing space characters from a buffer segment and writes the resulting content into the destination with padding if needed.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims both leading and trailing spaces are trimmed, but the code only conditionally strips leading spaces based on the O_NO_LEFT_STRIP option and does not trim trailing spaces. It also omits key behavior such as justification modes (left, center, right). The description of 'padding if needed' is partially accurate but lacks specificity tied to the justification logic. Most claims are inaccurate or incomplete regarding the function\u2019s actual semantics.",
                "The summary claims trimming of both leading and trailing spaces, which is inaccurate since the code only conditionally strips leading spaces unless O_NO_LEFT_STRIP is set and never strips trailing spaces. It also omits the core purpose of positioning and writing field text into a window based on justification (left, center, right). While it mentions padding, it fails to describe justification logic, column calculations, or dependency on field and window parameters, leading to a mismatch with the function\u2019s behavior.",
                "The summary incorrectly claims that the function trims trailing spaces, while the source code only conditionally strips leading spaces based on the O_NO_LEFT_STRIP option and does not remove trailing spaces\u2014it uses buffer pointers defining start and end of data without explicit trimming. This is a FATAL error on the primary purpose, as it misstates the core data processing behavior. While the mention of writing content with padding loosely corresponds to justification logic, the misleading trimming claim undermines trust."
            ]
        }
    }
}
{
    "source_code": "\nvoid acpi_ut_mutex_terminate(void)\n{\n\tu32 i;\n\n\tACPI_FUNCTION_TRACE(ut_mutex_terminate);\n\n\t/* Delete each predefined mutex object */\n\n\tfor (i = 0; i < ACPI_NUM_MUTEX; i++) {\n\t\tacpi_ut_delete_mutex(i);\n\t}\n\n\tacpi_os_delete_mutex(acpi_gbl_osi_mutex);\n\n\t/* Delete the spinlocks */\n\n\tacpi_os_delete_lock(acpi_gbl_gpe_lock);\n\tacpi_os_delete_lock(acpi_gbl_hardware_lock);\n\tacpi_os_delete_lock(acpi_gbl_reference_count_lock);\n\n\t/* Delete the reader/writer lock */\n\n\tacpi_ut_delete_rw_lock(&acpi_gbl_namespace_rw_lock);\n\treturn_VOID;\n}",
    "comment": "Terminates and deletes all predefined mutex objects, spinlocks, and a reader/writer lock to clean up synchronization mechanisms.",
    "prorec_sum": "Processes and clears multiple stored context entries, then updates related structures before finalizing with a consolidated display or graphics state update.",
    "filter_prorec_sum": "Processes and resets multiple hardware state entries, then updates additional registers before finalizing via a consolidated state commit routine.",
    "prorec_aug_sum": "Processes and clears stored entries, updates related global data blocks, and performs final aggregated calculations using provided parameters.",
    "filter_prorec_aug_sum": "Processes and resets multiple global data entries, then performs sequential operations on remaining entries before returning a final computed result.",
    "work_score": {
        "prorec": {
            "summary": "Processes and clears multiple stored context entries, then updates related structures before finalizing with a consolidated display or graphics state update.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about processing stored context entries, updating related structures, and performing a display or graphics state update do not align with the source code, which deletes mutexes, spinlocks, and a reader/writer lock. All claims are unrelated to the actual function behavior, resulting in no accurate domain-specific statements.",
                "The summary's claims about processing context entries, updating related structures, and finalizing display/graphics updates are entirely unrelated to the source code, which specifically deletes ACPI mutexes, spinlocks, and a reader/writer lock during termination. No accurate claim covers the core purpose of cleaning up synchronization primitives, and there is no correct secondary detail about the actual function behavior.",
                "The summary contains only inaccurate claims that do not match the source code semantics. It describes processing stored context entries, updating related structures, and finalizing with a graphics state update, none of which occur in the function. The function actually deletes predefined mutexes, spinlocks, and a reader/writer lock. This is a severe FATAL error affecting the primary purpose of the code, leading to a highly misleading description."
            ]
        },
        "filter_prorec": {
            "summary": "Processes and resets multiple hardware state entries, then updates additional registers before finalizing via a consolidated state commit routine.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary describes processing hardware state entries, updating registers, and committing via a state routine, which does not match the source code's actual behavior of deleting predefined mutexes, spinlocks, and a reader/writer lock. None of the claims target or correctly describe the function's domain semantics, making them inaccurate and unrelated to the contract of the code. This results in a complete mismatch with the evaluation criteria.",
                "The summary's claims about processing hardware state entries and updating registers do not align with the source code, which actually deletes ACPI mutexes, spinlocks, and a reader/writer lock as part of cleanup. The core purpose of terminating and removing synchronization primitives is entirely missing, and no accurate secondary details are provided. All claims are inaccurate noise unrelated to the code semantics.",
                "The summary contains only inaccurate claims unrelated to the source code's semantics. The function in the source code deletes mutexes, spinlocks, and a reader/writer lock, but the summary describes processing hardware state entries, updating registers, and committing state, which are entirely absent. These are FATAL inaccuracies about the primary purpose, making the description unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic bool\ndigest_file (const char *filename, int *binary, unsigned char *bin_result,\n             bool *missing)\n{\n  FILE *fp;\n  int err;\n  bool is_stdin = STREQ (filename, \"-\");\n\n  *missing = false;\n\n  if (is_stdin)\n    {\n      have_read_stdin = true;\n      fp = stdin;\n      if (O_BINARY && *binary)\n        {\n          if (*binary < 0)\n            *binary = ! isatty (STDIN_FILENO);\n          if (*binary)\n            xset_binary_mode (STDIN_FILENO, O_BINARY);\n        }\n    }\n  else\n    {\n      fp = fopen (filename, (O_BINARY && *binary ? \"rb\" : \"r\"));\n      if (fp == NULL)\n        {\n          if (ignore_missing && errno == ENOENT)\n            {\n              *missing = true;\n              return true;\n            }\n          error (0, errno, \"%s\", quotef (filename));\n          return false;\n        }\n    }\n\n  fadvise (fp, FADVISE_SEQUENTIAL);\n\n#if HASH_ALGO_BLAKE2\n  err = DIGEST_STREAM (fp, bin_result, b2_length / 8);\n#else\n  err = DIGEST_STREAM (fp, bin_result);\n#endif\n  if (err)\n    {\n      error (0, errno, \"%s\", quotef (filename));\n      if (fp != stdin)\n        fclose (fp);\n      return false;\n    }\n\n  if (!is_stdin && fclose (fp) != 0)\n    {\n      error (0, errno, \"%s\", quotef (filename));\n      return false;\n    }\n\n  return true;\n}",
    "comment": "Calculates a digest of the specified file or standard input, handling binary mode and error management for file operations.",
    "prorec_sum": "Opens the specified file or standard input, validates readability, handles errors, and sets a flag if the file is missing.",
    "filter_prorec_sum": "Opens the specified file or standard input, prepares it for reading, and reports errors with detailed messages, setting a flag if missing.",
    "prorec_aug_sum": "Opens the specified file or standard input, checks for readability, reports errors via errno, and sets a flag if the file is missing.",
    "filter_prorec_aug_sum": "Opens the specified file or standard input for reading, reports errors via stderr, and sets a flag if the file is missing.",
    "work_score": {
        "prorec": {
            "summary": "Opens the specified file or standard input, validates readability, handles errors, and sets a flag if the file is missing.",
            "score": [
                0.9,
                0.2,
                0.5
            ],
            "reason": [
                "The summary contains mainly accurate claims: it describes opening a specified file or standard input, handling errors, and setting a missing flag, all of which match the source code. However, the phrase 'validates readability' is somewhat vague and not explicitly represented in the code\u2019s operations, reducing precision slightly. Overall, the majority of claims align with the code\u2019s behavior.",
                "The summary correctly notes opening a file or stdin, handling errors, and setting a missing flag, which are accurate and grounded in the code. However, it omits the core primary purpose: computing a digest of the file/stream data and storing it in the output buffer. No mention is made of binary mode handling, reading strategies, or digest computation, resulting in the core domain action being uncovered and secondary details being minimal.",
                "The summary contains mostly accurate claims: it correctly states that the function opens the specified file or standard input, performs error handling, and sets a flag if the file is missing. However, 'validates readability' is somewhat generic and does not capture the more specific digest computation behavior from the source code. There are no contradictions or fatal errors, but the claims are low-info and omit the core purpose of calculating a digest, resulting in limited gain and moderate noise."
            ]
        },
        "filter_prorec": {
            "summary": "Opens the specified file or standard input, prepares it for reading, and reports errors with detailed messages, setting a flag if missing.",
            "score": [
                1.0,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function opens the specified file or standard input, prepares it for reading, and sets a flag if the file is missing. It also accurately mentions reporting errors, which aligns with the source code's detailed error handling. All claims are specific to the code behavior and are factually correct, matching the function\u2019s implementation with high precision.",
                "The summary accurately notes that the function can open a file or standard input, prepare it for reading, report errors, and set a missing flag, which aligns with core file-handling steps in the code. However, it omits the core primary purpose of computing a file digest into a binary result buffer and lacks coverage of critical secondary semantics like handling binary mode, ignoring missing files based on a configuration flag, using sequential file access advice, conditionally using different digest lengths for specific algorithms, and proper resource cleanup. This makes the coverage of behavior-important details incomplete despite correctness of the included claims.",
                "The summary accurately captures the core behavior: opening a file or standard input, preparing it for reading, handling errors with detailed messages, and setting a missing flag when appropriate. It omits some specifics like binary mode handling, sequential read advice, and digest computation, but there are no inaccurate claims. The gains are modest because the claims are broad and generic, offering limited insight into the actual digest processing and binary handling logic."
            ]
        }
    }
}
{
    "source_code": "static noinline_for_stack\nvoid ext4_mb_simple_scan_group(struct ext4_allocation_context *ac,\n\t\t\t\t\tstruct ext4_buddy *e4b)\n{\n\tstruct super_block *sb = ac->ac_sb;\n\tstruct ext4_group_info *grp = e4b->bd_info;\n\tvoid *buddy;\n\tint i;\n\tint k;\n\tint max;\n\n\tBUG_ON(ac->ac_2order <= 0);\n\tfor (i = ac->ac_2order; i <= sb->s_blocksize_bits + 1; i++) {\n\t\tif (grp->bb_counters[i] == 0)\n\t\t\tcontinue;\n\n\t\tbuddy = mb_find_buddy(e4b, i, &max);\n\t\tBUG_ON(buddy == NULL);\n\n\t\tk = mb_find_next_zero_bit(buddy, max, 0);\n\t\tBUG_ON(k >= max);\n\n\t\tac->ac_found++;\n\n\t\tac->ac_b_ex.fe_len = 1 << i;\n\t\tac->ac_b_ex.fe_start = k << i;\n\t\tac->ac_b_ex.fe_group = e4b->bd_group;\n\n\t\text4_mb_use_best_found(ac, e4b);\n\n\t\tBUG_ON(ac->ac_b_ex.fe_len != ac->ac_g_ex.fe_len);\n\n\t\tif (EXT4_SB(sb)->s_mb_stats)\n\t\t\tatomic_inc(&EXT4_SB(sb)->s_bal_2orders);\n\n\t\tbreak;\n\t}\n}",
    "comment": "Scans the buddy system for free blocks, updates allocation context, and records statistics for memory management in an ext4 filesystem.",
    "prorec_sum": "Updates inode block mapping state by selecting the next valid extent, adjusting related counters and cache fields, and triggering integrity checks with BUG() on errors.",
    "filter_prorec_sum": "Validates and processes an ext4 extent entry, updating inode preallocation metadata and counters, and ensures consistency through cache updates and sanity checks.",
    "prorec_aug_sum": "Updates filesystem group descriptor data for a specific block group, validating parameters, adjusting inode state, and incrementing usage counters when conditions are met.",
    "filter_prorec_aug_sum": "Updates inode group allocation state by selecting the next available block group, computing block offsets, and synchronizing metadata with the ext4 filesystem structures.",
    "work_score": {
        "prorec": {
            "summary": "Updates inode block mapping state by selecting the next valid extent, adjusting related counters and cache fields, and triggering integrity checks with BUG() on errors.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function updates inode block mapping state and selects the next valid extent, which is inaccurate because the source code operates on an allocation context and group info for block allocation rather than inode mapping. While it does adjust counters and performs BUG_ON integrity checks, several claims misrepresent the domain semantics by conflating block group scanning with inode mapping. Most claims do not accurately reflect the code\u2019s contract.",
                "The summary omits the core purpose of scanning an ext4 block group for available buddy blocks matching a size order and updating the allocation context. While it mentions selecting an extent, counters, and BUG() checks, it inaccurately frames this as inode block mapping, which is not present in the source. The core domain action of locating and using the best available free block sequence via mb_find_buddy and mb_find_next_zero_bit is missing, and secondary behaviors such as stopping after a match, order constraints, and updating mb_stats are not clearly covered.",
                "The summary contains a key FATAL error by stating that the function updates \"inode block mapping state,\" which is not reflected in the source code. The code operates on an ext4 allocation context and group/buddy structures to find and set a suitable extent, not directly on an inode. This misidentifies the PRIMARY PURPOSE. While it correctly mentions selecting the next valid extent, adjusting counters, cache updates, and BUG() integrity checks, the fundamental misrepresentation of the core domain action severely undermines trustworthiness."
            ]
        },
        "filter_prorec": {
            "summary": "Validates and processes an ext4 extent entry, updating inode preallocation metadata and counters, and ensures consistency through cache updates and sanity checks.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains several specific claims that do not align with the source code. It mentions validating and processing an ext4 extent entry, updating inode preallocation metadata, and performing cache updates, none of which are explicitly present in the function. The code instead scans for free blocks in a group, updates allocation context fields, ensures sanity via BUG_ON checks, and increments a global statistic counter; these operations are only partially captured by the summary. Most claims target concepts (inode preallocation, cache updates) that are unsupported, making the proportion of accurate claims well below half.",
                "The summary does not cover the core purpose of scanning an ext4 block group for available contiguous free blocks using buddy bitmap counters and selecting the best allocation match. Instead, it inaccurately describes processing an extent entry and updating inode preallocation metadata, which is not present in the code. It misses critical details such as the loop over orders, buddy lookup, finding free positions, setting block extent parameters, and statistical counter updates, making most claims inaccurate or noise.",
                "The summary contains multiple inaccurate elements: it claims to process an ext4 extent entry by updating inode preallocation metadata and performing cache updates, which are not reflected in the source code. The function actually scans a buddy group for a suitable free block, updates allocation context fields, invokes a helper to use the best found block, performs sanity checks with BUG_ON, and optionally updates a statistics counter. These mismatches affect the core purpose description, making them FATAL errors. Although the summary mentions sanity checks, which aligns loosely with the BUG_ON calls, the majority is inaccurate, with no specific GOLD-level insights that match the code."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_linalg_cholesky_scale_apply(gsl_matrix * A, const gsl_vector * S)\n{\n  const size_t M = A->size1;\n  const size_t N = A->size2;\n\n  if (M != N)\n    {\n      GSL_ERROR(\"A is not a square matrix\", GSL_ENOTSQR);\n    }\n  else if (N != S->size)\n    {\n      GSL_ERROR(\"S must have length N\", GSL_EBADLEN);\n    }\n  else\n    {\n      size_t i, j;\n\n      /* compute: A <- diag(S) A diag(S) using lower triangle */\n      for (j = 0; j < N; ++j)\n        {\n          double sj = gsl_vector_get(S, j);\n\n          for (i = j; i < N; ++i)\n            {\n              double si = gsl_vector_get(S, i);\n              double *Aij = gsl_matrix_ptr(A, i, j);\n              *Aij *= si * sj;\n            }\n        }\n\n      return GSL_SUCCESS;\n    }\n}",
    "comment": "Scales the elements of square matrix A by the elements of vector S using diagonal multiplication in a Cholesky decomposition context.",
    "prorec_sum": "Validates matrix dimensions and scales a Cholesky factorization in-place using the provided diagonal scaling vector, reporting errors for mismatched sizes.",
    "filter_prorec_sum": "Validates matrix and scale vector dimensions, then applies element-wise scaling to a Cholesky factor matrix using the provided scale values.",
    "prorec_aug_sum": "Scales a Cholesky-decomposed square matrix by a matching-length vector, validating dimensions and reporting errors for invalid shapes.",
    "filter_prorec_aug_sum": "Validates matrix dimensions and scales a Cholesky-decomposed square matrix by a vector S, reporting dimension mismatches via gsl_error.",
    "work_score": {
        "prorec": {
            "summary": "Validates matrix dimensions and scales a Cholesky factorization in-place using the provided diagonal scaling vector, reporting errors for mismatched sizes.",
            "score": [
                0.6,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function validates matrix dimensions and uses a diagonal scaling vector to modify the matrix, and that it reports errors for mismatched sizes. These points align with the source code's checks for square matrices, matching vector length, and the scaling implementation. However, the summary inaccurately describes the operation as scaling a 'Cholesky factorization', which is misleading since the code simply scales the matrix's lower triangle without performing or requiring a Cholesky decomposition. This reduces claim accuracy but the majority of the summary is still grounded in the code.",
                "The summary correctly notes validation of matrix dimensions and that scaling is done in-place using a diagonal scaling vector, which aligns with the core purpose of applying diag(S) * A * diag(S) to the lower triangle of the matrix. It also mentions error reporting for mismatched sizes, which reflects the error paths. However, it inaccurately frames the operation as scaling a \"Cholesky factorization\"\u2014the code performs a general matrix scaling without necessarily involving a Cholesky factorization\u2014introducing a domain-specific inaccuracy. This reduces both core coverage accuracy and overall secondary detail quality.",
                "The summary correctly notes the matrix dimension validation and error handling for mismatched sizes, which matches the code. However, it inaccurately states that the function scales a Cholesky factorization, when in fact it scales the matrix using diag(S) without performing a Cholesky decomposition. This is a severe FATAL in describing the primary purpose, making the description untrustworthy for core behavior despite some accurate, generic elements."
            ]
        },
        "filter_prorec": {
            "summary": "Validates matrix and scale vector dimensions, then applies element-wise scaling to a Cholesky factor matrix using the provided scale values.",
            "score": [
                0.8,
                0.6,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function validates matrix and scale vector dimensions and applies scaling to a matrix using provided scale values. These claims match the source: it checks if the matrix is square and if the scale vector length matches N, and then scales elements in the lower triangle using si * sj. The term 'Cholesky factor matrix' is not explicitly evidenced in the code and introduces a minor inaccuracy, as the operation is on the given matrix without guaranteed Cholesky context. Overall, most claims are accurate but with slight over-specification.",
                "The summary correctly mentions dimension validation for the matrix and scale vector and describes scaling using the provided scale values. It captures the core purpose: scaling a Cholesky factor matrix by multiplying elements with products of scale factors from diag(S) on both sides. However, it uses slightly vague phrasing ('element-wise scaling') without specifying the lower-triangle processing or the exact diag(S) A diag(S) transformation, and misses details such as non-square matrix and mismatched length error handling. Coverage of secondary semantics like iteration structure and success return is limited.",
                "The summary correctly states that the function validates matrix and scale vector dimensions, which is present in the code. However, it inaccurately describes the scaling as element-wise applied to a Cholesky factor matrix, whereas the code specifically applies symmetric scaling using diag(S) on the lower triangle of the matrix regardless of whether it is a Cholesky factor. This misrepresentation of the core purpose is a FATAL error affecting the primary domain semantics."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\nfb_mmap(struct file *file, struct vm_area_struct * vma)\n{\n\tstruct fb_info *info = file_fb_info(file);\n\tstruct fb_ops *fb;\n\tunsigned long mmio_pgoff;\n\tunsigned long start;\n\tu32 len;\n\n\tif (!info)\n\t\treturn -ENODEV;\n\tfb = info->fbops;\n\tif (!fb)\n\t\treturn -ENODEV;\n\tmutex_lock(&info->mm_lock);\n\tif (fb->fb_mmap) {\n\t\tint res;\n\t\tres = fb->fb_mmap(info, vma);\n\t\tmutex_unlock(&info->mm_lock);\n\t\treturn res;\n\t}\n\n\t/*\n\t * Ugh. This can be either the frame buffer mapping, or\n\t * if pgoff points past it, the mmio mapping.\n\t */\n\tstart = info->fix.smem_start;\n\tlen = info->fix.smem_len;\n\tmmio_pgoff = PAGE_ALIGN((start & ~PAGE_MASK) + len) >> PAGE_SHIFT;\n\tif (vma->vm_pgoff >= mmio_pgoff) {\n\t\tif (info->var.accel_flags) {\n\t\t\tmutex_unlock(&info->mm_lock);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tvma->vm_pgoff -= mmio_pgoff;\n\t\tstart = info->fix.mmio_start;\n\t\tlen = info->fix.mmio_len;\n\t}\n\tmutex_unlock(&info->mm_lock);\n\n\tvma->vm_page_prot = vm_get_page_prot(vma->vm_flags);\n\tfb_pgprotect(file, vma, start);\n\n\treturn vm_iomap_memory(vma, start, len);\n}",
    "comment": "Maps the framebuffer or MMIO memory region into the process's address space based on the provided virtual memory area structure.",
    "prorec_sum": "Validates a block device context, adjusts buffer allocation, and initiates a data transfer based on current device state and request parameters.",
    "filter_prorec_sum": "Validates device state, adjusts memory counters, and executes a device-specific operation using provided parameters and function pointers.",
    "prorec_aug_sum": "Validates a context\u2019s mapped region, adjusts resource counters, and invokes a handler or performs a fallback operation to complete the mapping request.",
    "filter_prorec_aug_sum": "Validates a memory object handle, adjusts allocation counters, and invokes either a custom or default routine to map the specified region.",
    "work_score": {
        "prorec": {
            "summary": "Validates a block device context, adjusts buffer allocation, and initiates a data transfer based on current device state and request parameters.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes validating a block device context, adjusting buffer allocation, and initiating a data transfer, which does not align with the source code\u2019s actual behavior of handling framebuffer mmap operations, validating framebuffer info, adjusting offsets, and mapping memory regions. None of the claims are specific to the function\u2019s semantics, making them inaccurate relative to the source.",
                "The summary's claims about validating a block device, adjusting buffer allocation, and initiating data transfer do not match the source code, which handles memory mapping for a framebuffer device, including conditional MMIO mapping, mutex locking, error returns, and use of vm_iomap_memory. The core purpose of mapping framebuffer or MMIO memory regions to a user-space VMA is entirely missing, and none of the claims are accurate to the code's actual semantics.",
                "The summary claims the function validates a block device context, adjusts buffer allocation, and initiates a data transfer. These are inaccurate because the source code deals with mapping framebuffer memory to a user-space VMA, checking fb_info and fb_ops, handling framebuffer or MMIO mappings, and setting page protections. None of the described block device or data transfer behavior exists in the code, making the inaccuracies fatal by misrepresenting the primary purpose and key I/O operations."
            ]
        },
        "filter_prorec": {
            "summary": "Validates device state, adjusts memory counters, and executes a device-specific operation using provided parameters and function pointers.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary makes vague claims about device state validation and executing a device-specific operation, which loosely match parts of the code (e.g., checking `info` and `fbops`, and calling `fb->fb_mmap`). However, it inaccurately mentions adjusting memory counters, which the source code does not do, and omits critical semantic details like handling MMIO mapping offsets, mutex locking/unlocking, and error returns. Because only about half of the claims are accurate and the rest are misleading or generic, the alignment is mixed.",
                "The summary offers generic statements about validating device state and executing a device-specific operation, but it fails to mention the core purpose of mapping framebuffer or MMIO regions into a process\u2019s address space. No [ACCURATE] claim captures the specific domain action, so the main operation remains uncovered. It also omits critical secondary details like handling accel_flags, page offset adjustments, protection setup, and calls to vm_iomap_memory.",
                "The summary contains mostly generic statements that do not accurately reflect the function\u2019s specific behavior. While 'validates device state' loosely aligns with checking `info` and `fbops` for non-null, it inaccurately claims 'adjusts memory counters'\u2014the code adjusts offsets and maps memory regions, not counters. It also vaguely states 'executes a device-specific operation using provided parameters and function pointers,' which partially matches invoking `fb->fb_mmap`, but omits important details such as mapping framebuffer or MMIO memory and protection setup. Overall, the description is imprecise and largely noise, with minimal direct mapping to the core purpose."
            ]
        }
    }
}
{
    "source_code": "static void vt_disallocate_all(void)\n{\n\tstruct vc_data *vc[MAX_NR_CONSOLES];\n\tint i;\n\n\tconsole_lock();\n\tfor (i = 1; i < MAX_NR_CONSOLES; i++)\n\t\tif (!VT_BUSY(i))\n\t\t\tvc[i] = vc_deallocate(i);\n\t\telse\n\t\t\tvc[i] = NULL;\n\tconsole_unlock();\n\n\tfor (i = 1; i < MAX_NR_CONSOLES; i++) {\n\t\tif (vc[i] && i >= MIN_NR_CONSOLES) {\n\t\t\ttty_port_destroy(&vc[i]->port);\n\t\t\tkfree(vc[i]);\n\t\t}\n\t}\n}",
    "comment": "Deallocates all virtual consoles that are not busy, destroying associated tty ports and freeing memory for those consoles.",
    "prorec_sum": "Iterates over 62 stored entries, filtering and initializing active ones, then processes each through two geometry-related update routines using provided parameters.",
    "filter_prorec_sum": "Iterates through indexed hardware-related entries, clearing or initializing them based on status, then processes each initialized entry with two sequential computational and handling routines.",
    "prorec_aug_sum": "Iterates through device entries, skips inactive ones, processes active entries, and invokes two routines with provided parameters for each processed entry.",
    "filter_prorec_aug_sum": "Iterates through device entries, skips inactive ones, processes active entries, and applies two computation routines using provided double-precision parameters.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over 62 stored entries, filtering and initializing active ones, then processes each through two geometry-related update routines using provided parameters.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary's claims about iterating over 62 entries, filtering and initializing active ones, and performing geometry-related updates are unrelated to the source code's actual behavior. The function in the source deallocates console resources for non-busy consoles, using console locking, and calls memory deallocation functions, with no mention of geometry updates or a 62-entry iteration. All claims are inaccurate, resulting in 0% ACCURATE statements.",
                "The summary's claims about iterating over 62 entries, filtering active ones, and using geometry-related update routines do not align with the source code, which instead locks the console, iterates through virtual consoles to deallocate inactive ones, then destroys and frees them. The core purpose of deallocating all non-busy console structures is completely missing, and no accurate domain-specific details are covered. All claims are inaccurate and unrelated to the actual code semantics.",
                "The summary's claims about iterating over 62 stored entries, filtering/initializing active ones, and applying geometry-related update routines do not match the source code's semantics, which deal with deallocating virtual consoles, freeing resources, and destroying TTY ports. These are FATAL inaccuracies that contradict the core purpose and key I/O behavior of the function, making the description unusable. No accurate claims are present, and the mismatch directly affects the primary functionality."
            ]
        },
        "filter_prorec": {
            "summary": "Iterates through indexed hardware-related entries, clearing or initializing them based on status, then processes each initialized entry with two sequential computational and handling routines.",
            "score": [
                0.2,
                0.1,
                0.3
            ],
            "reason": [
                "The summary is overly generic and does not capture specific domain-semantic behaviors from the source code, such as the use of console locking, the check for VT_BUSY, deallocation via vc_deallocate, destruction of tty ports, or freeing memory with kfree. While it alludes vaguely to iterating through entries and processing them based on status, it omits critical technical details and mischaracterizes the actions as 'computational routines' rather than describing the actual resource deallocation. Most claims are imprecise and not clearly verifiable against the code.",
                "The summary does not mention the core purpose of disallocating and freeing virtual console structures, including checks on VT_BUSY, tty_port_destroy, and memory deallocation. Its wording about 'hardware-related entries' and 'computational routines' is vague, not mapping to the specific domain semantics of console lock/unlock or freeing vc_data. No [ACCURATE] claim captures the core domain action, and no secondary behavior such as conditionals, constants, or destruction routines is correctly described.",
                "The summary is largely inaccurate: it describes generic 'hardware-related entries' and vague 'computational and handling routines' rather than the specific console and tty port deallocation process present in the code. Key details like using VT_BUSY to check console usage, locking, freeing memory via kfree, and destroying tty ports are omitted or misrepresented. The description fails to convey the primary purpose of freeing unused virtual consoles, resulting in NOISE overwhelming any accurate content. No specific GOLD-level details are present."
            ]
        }
    }
}
{
    "source_code": "\nvoid FAST_FUNC bb_herror_msg(const char *s, ...)\n{\n\tva_list p;\n\n\tva_start(p, s);\n\tbb_verror_msg(s, p, hstrerror(h_errno));\n\tva_end(p);\n}",
    "comment": "Formats and displays an error message using a variable argument list and the current error description from `hstrerror(h_errno)`.",
    "prorec_sum": "Prepares structured parameters and vector data, then invokes a downstream routine to process them with retrieved configuration and floating\u2011point values.",
    "filter_prorec_sum": "Prepares structured parameters and floating\u2011point values before invoking a downstream routine to process data with retrieved configuration and formatting context.",
    "prorec_aug_sum": "Prepares structured parameter data and forwards multiple 128-bit vector and floating-point values to a downstream processing routine for further handling.",
    "filter_prorec_aug_sum": "Prepares vector and scalar parameters, retrieves configuration data, and invokes a processing routine to handle structured output based on the provided inputs.",
    "work_score": {
        "prorec": {
            "summary": "Prepares structured parameters and vector data, then invokes a downstream routine to process them with retrieved configuration and floating\u2011point values.",
            "score": [
                0.0,
                0.0,
                0.3
            ],
            "reason": [
                "The summary's claims about preparing structured parameters, vector data, retrieved configuration, and floating\u2011point values do not align with the source code, which simply initializes a variable argument list and passes it along with an error string to another function. None of the claims accurately describe the function's actual semantics, resulting in 0% accurate content.",
                "The summary describes handling structured parameters, configuration, and floating-point values, which is unrelated to the actual function. The source code shows a varargs function preparing a va_list, retrieving a human-readable error string from h_errno via hstrerror, and passing it to bb_verror_msg. The core purpose of reporting an error string based on h_errno is completely missing, and no accurate claims match the code's semantics. This represents a complete mismatch with the source behavior.",
                "The summary's claims about preparing structured parameters, vector data, retrieved configuration, and floating\u2011point values are entirely unrelated to the source code, which simply initializes a variadic argument list and calls a downstream function with an error string from hstrerror. All extracted claims are NOISE, with no accurate statements matching the actual domain semantics. Noise is overwhelming with no factual gain."
            ]
        },
        "filter_prorec": {
            "summary": "Prepares structured parameters and floating\u2011point values before invoking a downstream routine to process data with retrieved configuration and formatting context.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary contains claims about preparing structured parameters, floating-point values, and processing data with configuration/formatting context, which do not match the source code's actual function. The code uses a variadic argument list to call bb_verror_msg with an error string from hstrerror, involving error handling rather than the described structured or floating-point processing. All claims are inaccurate, yielding no alignment with the source.",
                "The summary's claims describe preparing parameters and floating\u2011point values for a data-processing routine, which is unrelated to the source code's actual function. The source code wraps a variadic call to bb_verror_msg, passing an error string derived from h_errno via hstrerror, and does not involve floating\u2011point handling or configuration context. The core purpose of reporting an error message with h_errno details is entirely absent, and no accurate coverage of secondary behaviors is provided.",
                "The summary contains only inaccurate, noisy claims unrelated to the source code\u2019s semantics. The function does not prepare floating\u2011point values or retrieve configuration; instead, it initializes a variable argument list and calls bb_verror_msg with an error string from hstrerror(h_errno). No accurate statements are present, and the description misrepresents the primary purpose, constituting a severe fatal error on the core functionality."
            ]
        }
    }
}
{
    "source_code": "int sysfs_merge_group(struct kobject *kobj,\n\t\t       const struct attribute_group *grp)\n{\n\tstruct sysfs_dirent *dir_sd;\n\tint error = 0;\n\tstruct attribute *const *attr;\n\tint i;\n\n\tdir_sd = sysfs_get_dirent(kobj->sd, NULL, grp->name);\n\tif (!dir_sd)\n\t\treturn -ENOENT;\n\n\tfor ((i = 0, attr = grp->attrs); *attr && !error; (++i, ++attr))\n\t\terror = sysfs_add_file(dir_sd, *attr, SYSFS_KOBJ_ATTR);\n\tif (error) {\n\t\twhile (--i >= 0)\n\t\t\tsysfs_hash_and_remove(dir_sd, NULL, (*--attr)->name);\n\t}\n\tsysfs_put(dir_sd);\n\n\treturn error;\n}",
    "comment": "Merges a specified attribute group into a kobject's sysfs directory, adding attributes and handling errors by removing any added attributes on failure.",
    "prorec_sum": "Traverses and processes a list of filesystem-related entries, performing conditional updates and cleanup, and returns a status code for the last processed entry.",
    "filter_prorec_sum": "Processes a list of inode extended attributes, updating entries as needed, and releases resources with reference counting before returning success or error status.",
    "prorec_aug_sum": "Initializes an object, iterates linked entries performing conditional operations, and releases resources, returning a status code indicating the first successful operation.",
    "filter_prorec_aug_sum": "Processes a list of objects by invoking comparison and cleanup routines, returning a status code, and freeing resources using reference counting.",
    "work_score": {
        "prorec": {
            "summary": "Traverses and processes a list of filesystem-related entries, performing conditional updates and cleanup, and returns a status code for the last processed entry.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary is overly generic and misses key specific behaviors from the source code, such as looking up a sysfs directory entry by name, adding each attribute to the directory, and rolling back changes if an error occurs. It incorrectly states returning a status for the last processed entry, whereas the function returns the final error status after attempting all attributes. Most claims do not accurately reflect the function's precise semantics, resulting in low alignment.",
                "The summary vaguely describes traversal and conditional updates for filesystem-related entries but fails to specify the core purpose: merging an attribute group into an existing sysfs directory entry for a given kobject. It omits mention of resolving the directory entry by name, adding each attribute via sysfs_add_file, rolling back additions on error, and proper reference handling. The core domain action and most critical behaviors are not covered, making the description overly generic and incomplete.",
                "The summary incorrectly describes the function\u2019s core purpose. The source code merges an attribute group into a kobject\u2019s sysfs directory, adding each attribute and performing cleanup on failure before returning an error status. The summary\u2019s claims about traversing generic 'filesystem-related entries' and returning a status for the last entry are misleading and not aligned with the actual semantics. This constitutes a FATAL error on the primary purpose and I/O behavior, making the description untrustworthy despite minimal noise."
            ]
        },
        "filter_prorec": {
            "summary": "Processes a list of inode extended attributes, updating entries as needed, and releases resources with reference counting before returning success or error status.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary makes incorrect semantic claims about processing inode extended attributes, which do not align with the source code's actual role of merging sysfs attribute groups and adding/removing files in the sysfs directory entries. None of the claims accurately reflect the function's domain-specific behavior, resulting in low alignment.",
                "The summary incorrectly describes handling of inode extended attributes, which is not what the source code does. The core purpose is merging a sysfs attribute group into an existing kobject directory by adding its files, and removing them on error \u2013 this is entirely missed. The claims fail to accurately reflect the domain semantics, and no accurate coverage of the core behavior or secondary details is present.",
                "The summary's core claim about processing inode extended attributes is incorrect; the function instead processes sysfs attribute groups. This is a severe FATAL error on the primary purpose. There is also an inaccurate mention of \"updating entries\" that does not reflect the actual add/remove logic, and the reference counting detail is generic but applied to the wrong resource type. The inaccuracies dominate, leaving no meaningful accurate claims."
            ]
        }
    }
}
{
    "source_code": "static int __kprobes write_mem(unsigned long val, unsigned long ea, int nb,\n\t\t\t       struct pt_regs *regs)\n{\n\tif (!address_ok(regs, ea, nb))\n\t\treturn -EFAULT;\n\tif ((ea & (nb - 1)) == 0)\n\t\treturn write_mem_aligned(val, ea, nb);\n\treturn write_mem_unaligned(val, ea, nb, regs);\n}",
    "comment": "Writes specified bytes from a buffer to a target object's memory section, logging the operation if enabled.",
    "prorec_sum": "Reads data in page-aligned chunks from a mapped memory region into a buffer, updating the offset and enforcing address range limits.",
    "filter_prorec_sum": "Reads data in page-aligned chunks from a source into memory, updating the offset and aborting if allocation or read fails.",
    "prorec_aug_sum": "Copies data in page-aligned chunks from a source address to a destination memory range, updating the offset and enforcing hardware address limits.",
    "filter_prorec_aug_sum": "Copies data in page-aligned chunks from a source buffer into a destination memory range, updating the offset pointer and enforcing address limit checks.",
    "work_score": {
        "prorec": {
            "summary": "Reads data in page-aligned chunks from a mapped memory region into a buffer, updating the offset and enforcing address range limits.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about reading data in page-aligned chunks, using a buffer, updating the offset, and enforcing address range limits are inaccurate relative to the source code. The function actually writes data to memory, checking address validity and alignment before delegating to aligned or unaligned write functions. None of the stated behaviors about reading or buffers are present, making the claim set entirely incorrect.",
                "The summary describes reading data in page-aligned chunks into a buffer, which contradicts the source code's actual purpose of writing a value to a memory address with checks for address validity and alignment. The core operation of conditional writes (aligned or unaligned) is entirely missed, and no secondary accurate details about the error handling or alignment logic are present.",
                "The summary's main claim that the function reads data in page-aligned chunks from a mapped memory region is incorrect, as the source code shows the function writes a given value to memory at a specified address. This is a FATAL error on the primary purpose (core domain action) since the summary misidentifies the fundamental operation. Additional details such as reading into a buffer and updating the offset are also unsupported in the code, adding more noise. There are no accurate, specific gains present."
            ]
        },
        "filter_prorec": {
            "summary": "Reads data in page-aligned chunks from a source into memory, updating the offset and aborting if allocation or read fails.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function reads data in page-aligned chunks from a source into memory, handles offsets, and aborts if allocation or read fails. These statements do not match the source code, which writes a value to a memory address, checks address validity, and chooses aligned or unaligned write functions. None of the claims are accurate with respect to the code\u2019s semantics, resulting in no verifiable alignment.",
                "The summary's claims about reading data in page-aligned chunks, updating offsets, and aborting on allocation/read failures are inaccurate because the source code performs memory writes, not reads, and handles alignment for the write operation. It also checks address validity rather than dealing with allocation or read failures. The core purpose of writing a value to a given address with alignment handling is completely missing, and there is no accurate coverage of the function's actual domain semantics.",
                "The summary describes reading data in page-aligned chunks with allocation and read failure handling, which contradicts the source code's actual behavior. The function writes data to a memory address, checks address validity, and chooses aligned or unaligned write operations. This is a severe factual error about the primary purpose and core I/O, representing a FATAL mismatch that makes the summary unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic int __init i8042_create_aux_port(int idx)\n{\n\tstruct serio *serio;\n\tint port_no = idx < 0 ? I8042_AUX_PORT_NO : I8042_MUX_PORT_NO + idx;\n\tstruct i8042_port *port = &i8042_ports[port_no];\n\n\tserio = kzalloc(sizeof(struct serio), GFP_KERNEL);\n\tif (!serio)\n\t\treturn -ENOMEM;\n\n\tserio->id.type\t\t= SERIO_8042;\n\tserio->write\t\t= i8042_aux_write;\n\tserio->start\t\t= i8042_start;\n\tserio->stop\t\t= i8042_stop;\n\tserio->port_data\t= port;\n\tserio->dev.parent\t= &i8042_platform_device->dev;\n\tif (idx < 0) {\n\t\tstrlcpy(serio->name, \"i8042 AUX port\", sizeof(serio->name));\n\t\tstrlcpy(serio->phys, I8042_AUX_PHYS_DESC, sizeof(serio->phys));\n\t\tserio->close = i8042_port_close;\n\t} else {\n\t\tsnprintf(serio->name, sizeof(serio->name), \"i8042 AUX%d port\", idx);\n\t\tsnprintf(serio->phys, sizeof(serio->phys), I8042_MUX_PHYS_DESC, idx + 1);\n\t}\n\n\tport->serio = serio;\n\tport->mux = idx;\n\tport->irq = I8042_AUX_IRQ;\n\n\treturn 0;\n}",
    "comment": "Initializes an i8042 auxiliary port, allocating a serio structure and configuring it for communication with the specified input device.",
    "prorec_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) port device, assigning handlers, naming paths, and updating global controller state arrays.",
    "filter_prorec_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) serio port with appropriate handlers and device names based on the provided port index.",
    "prorec_aug_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) serio port structure with appropriate handlers, names, and global table entries based on the port index.",
    "filter_prorec_aug_sum": "Initializes and registers an i8042 AUX (PS/2 mouse) port device, assigning handlers, identifiers, and storing it in global controller structures.",
    "work_score": {
        "prorec": {
            "summary": "Initializes and registers an i8042 AUX (PS/2 mouse) port device, assigning handlers, naming paths, and updating global controller state arrays.",
            "score": [
                0.7,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly identifies that the function initializes an i8042 AUX port device and assigns handlers, which matches the code\u2019s setting of function pointers and device attributes. However, it inaccurately claims that the function registers the port device, which the code does not perform\u2014it only sets up the struct and associates it with the port. The mention of updating global controller state arrays is partially accurate since it updates fields in the global i8042_ports array. Overall, most claims target code semantics and are accurate, but the registration claim is incorrect, reducing precision.",
                "The summary correctly states that the function initializes an i8042 AUX port and assigns handlers, which matches the code\u2019s allocation and initialization of a serio structure with write/start/stop functions. However, it claims the port is registered, which is inaccurate since the code only assigns it to the port structure without performing any registration. The core purpose\u2014creating and configuring a serio for an AUX or multiplexed port\u2014is covered, but secondary details are limited; it omits key specifics such as error handling for allocation failure, conditional naming based on idx, setting physical descriptors, assigning irq values, and parent device linking. The mention of updating global controller state arrays is vague and only partially reflects the assignment to the i8042_ports array.",
                "The summary correctly states the function initializes an i8042 AUX port, assigns handlers, sets names/paths, and updates controller state, matching code behavior such as setting function pointers, populating name/phys fields, and storing the serio in the port structure. However, it inaccurately claims that the function registers the device, which the code does not perform (no call to serio_register or similar). This is a FATAL error about the primary purpose by implying an extra core action, reducing trust in the description despite other accurate elements."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes and registers an i8042 AUX (PS/2 mouse) serio port with appropriate handlers and device names based on the provided port index.",
            "score": [
                0.8,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function initializes an i8042 AUX serio port and assigns handlers and names based on the port index, which matches the code's behavior. However, it inaccurately adds 'registers' and specifies 'PS/2 mouse', neither of which are explicitly confirmed in the provided source. Despite these minor inaccuracies, most of the summary aligns with the code's semantics.",
                "The summary accurately captures the core purpose of creating and initializing an i8042 AUX serio port with handlers and names based on the index, which matches the function\u2019s primary domain operation. However, it omits secondary details such as memory allocation failure handling, setting port data and IRQ, the distinction between AUX and MUX port numbering, and assignment of specific function pointers like start, stop, and close for certain cases. These omissions reduce coverage of behavior-critical semantics beyond the core purpose.",
                "The summary correctly captures the core purpose: initializing an i8042 AUX serio port, applying appropriate handlers, and naming based on index. All claims are [ACCURATE]\u2014the function allocates and sets handlers, assigns names depending on idx, and stores in the port structure. No contradictory or irrelevant statements are present, but the description is somewhat generic, lacking detail on specific handlers or other setup steps. Net benefit is positive but not high due to limited specificity."
            ]
        }
    }
}
{
    "source_code": "long keyctl_keyring_unlink(key_serial_t id, key_serial_t ringid)\n{\n\tkey_ref_t keyring_ref, key_ref;\n\tlong ret;\n\n\tkeyring_ref = lookup_user_key(ringid, 0, KEY_WRITE);\n\tif (IS_ERR(keyring_ref)) {\n\t\tret = PTR_ERR(keyring_ref);\n\t\tgoto error;\n\t}\n\n\tkey_ref = lookup_user_key(id, KEY_LOOKUP_FOR_UNLINK, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = PTR_ERR(key_ref);\n\t\tgoto error2;\n\t}\n\n\tret = key_unlink(key_ref_to_ptr(keyring_ref), key_ref_to_ptr(key_ref));\n\n\tkey_ref_put(key_ref);\nerror2:\n\tkey_ref_put(keyring_ref);\nerror:\n\treturn ret;\n}",
    "comment": "Unlinks a key from a specified keyring after verifying the existence of both the key and the keyring.",
    "prorec_sum": "Allocates two memory pages for cryptographic operations, processes them with provided parameters, and returns a result or an allocation pointer.",
    "filter_prorec_sum": "Allocates two memory pages for cryptographic processing, performs computations on them using provided double parameters, and returns the final processed page reference.",
    "prorec_aug_sum": "Processes two memory-mapped objects by applying computation functions with given double parameters and returns a status or updated reference address.",
    "filter_prorec_aug_sum": "Processes two numeric handles, performs linked operations using provided floating-point parameters, updates both resources, and returns the final resulting handle value.",
    "work_score": {
        "prorec": {
            "summary": "Allocates two memory pages for cryptographic operations, processes them with provided parameters, and returns a result or an allocation pointer.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims that the function allocates memory pages for cryptographic operations and processes them using provided parameters, which does not align with the source code. The source code instead performs key lookup operations, unlinks a key from a keyring, and releases references without any allocation of memory pages or cryptographic processing. All claims are inaccurate, resulting in no alignment with the code\u2019s actual behavior.",
                "The summary makes claims about allocating two memory pages for cryptographic operations, which is entirely unrelated to the source code\u2019s actual purpose of looking up two user keys and unlinking one from a keyring. None of the claims are accurate regarding the function\u2019s domain behavior, so the core purpose is not covered and there is no relevant secondary information.",
                "The summary contains only inaccurate claims unrelated to the source code semantics. The code does not allocate memory pages nor perform cryptographic operations; instead, it looks up user keys in a keyring, unlinks them, and returns the result code. This mismatch represents a severe FATAL error affecting the primary purpose of the function, making the summary unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates two memory pages for cryptographic processing, performs computations on them using provided double parameters, and returns the final processed page reference.",
            "score": [
                0.0,
                0.0,
                0.3
            ],
            "reason": [
                "The summary makes claims about allocating memory pages for cryptographic processing and using double parameters, which do not match the source code. The function actually looks up keyring and key references, unlinks a key from a keyring, and manages reference counts, with no memory page allocation or cryptographic processing. None of the claims are accurate, resulting in low alignment with the evaluation steps.",
                "The summary is entirely inaccurate as it describes allocating memory pages and cryptographic processing with double parameters, which is unrelated to the actual function. The source code handles unlinking a key from a keyring via user key lookups, error checks, and reference management. No accurate claims address the core purpose or any secondary behaviors, resulting in no alignment with the evaluation steps.",
                "The summary's claims about allocating memory pages, cryptographic processing, and double parameters are entirely unrelated to the source code, which manages keyring unlinking and key lookups. All claims are NOISE with no accurate statements describing the function's actual purpose, I/O, or side effects, resulting in zero usable information."
            ]
        }
    }
}
{
    "source_code": "\nbool ssh2_common_filter_queue(PacketProtocolLayer *ppl)\n{\n    static const char *const ssh2_disconnect_reasons[] = {\n        NULL,\n        \"host not allowed to connect\",\n        \"protocol error\",\n        \"key exchange failed\",\n        \"host authentication failed\",\n        \"MAC error\",\n        \"compression error\",\n        \"service not available\",\n        \"protocol version not supported\",\n        \"host key not verifiable\",\n        \"connection lost\",\n        \"by application\",\n        \"too many connections\",\n        \"auth cancelled by user\",\n        \"no more auth methods available\",\n        \"illegal user name\",\n    };\n\n    PktIn *pktin;\n    ptrlen msg;\n    int reason;\n\n    while ((pktin = pq_peek(ppl->in_pq)) != NULL) {\n        switch (pktin->type) {\n          case SSH2_MSG_DISCONNECT:\n            reason = get_uint32(pktin);\n            msg = get_string(pktin);\n\n            ssh_remote_error(\n                ppl->ssh, \"Remote side sent disconnect message\\n\"\n                \"type %d (%s):\\n\\\"%.*s\\\"\", reason,\n                ((reason > 0 && reason < lenof(ssh2_disconnect_reasons)) ?\n                 ssh2_disconnect_reasons[reason] : \"unknown\"),\n                PTRLEN_PRINTF(msg));\n            /* don't try to pop the queue, because we've been freed! */\n            return true;               /* indicate that we've been freed */\n\n          case SSH2_MSG_DEBUG:\n            /* XXX maybe we should actually take notice of the return value */\n            get_bool(pktin);\n            msg = get_string(pktin);\n            ppl_logevent(\"Remote debug message: %.*s\", PTRLEN_PRINTF(msg));\n            pq_pop(ppl->in_pq);\n            break;\n\n          case SSH2_MSG_IGNORE:\n            /* Do nothing, because we're ignoring it! Duhh. */\n            pq_pop(ppl->in_pq);\n            break;\n\n          default:\n            return false;\n        }\n    }\n\n    return false;\n}",
    "comment": "Processes incoming SSH2 packets, handling disconnect messages, debug messages, and ignores messages, while managing packet queue operations.",
    "prorec_sum": "Processes incoming messages from a connection, dispatching type\u2011specific handlers and invoking callbacks to handle control or command data until no more messages remain.",
    "filter_prorec_sum": "Processes successive command responses from an SSH-related connection context, handling specific message types and invoking appropriate callbacks for type\u20111 and type\u20114 events.",
    "prorec_aug_sum": "Processes event codes from a session handler, executing specific callbacks for recognized codes and terminating on unhandled or null events.",
    "filter_prorec_aug_sum": "Processes command codes from an input handler, executing associated actions or callbacks until no more commands are available.",
    "work_score": {
        "prorec": {
            "summary": "Processes incoming messages from a connection, dispatching type\u2011specific handlers and invoking callbacks to handle control or command data until no more messages remain.",
            "score": [
                0.2,
                0.3,
                0.2
            ],
            "reason": [
                "The summary makes generic claims about processing incoming messages and invoking callbacks, but it omits key, specific behaviors from the source code such as handling SSH2_MSG_DISCONNECT by logging an error and returning true, processing SSH2_MSG_DEBUG and SSH2_MSG_IGNORE with specific actions, and stopping when the queue is empty. It introduces vague ideas like 'control or command data' not evidenced in the code. Most claims are inaccurate or too generic, with less than half being aligned with actual code semantics.",
                "The summary generically describes processing incoming messages with type-specific handlers but omits the core purpose: handling SSH2 protocol control packets (DISCONNECT, DEBUG, IGNORE) with specific behavior such as logging, error reporting, queue popping, and freeing resources. It lacks protocol-specific detail and edge case handling, making it non-distinguishing and missing critical semantics from the source code.",
                "The summary makes a generic claim about processing incoming messages with type-specific handlers and callbacks, but the source code shows only three specific message types handled (disconnect, debug, ignore) with explicit logic, and does not continuously process until no messages remain \u2014 it breaks or returns depending on type. The mention of callbacks for control/command data is noise and does not match the actual side effects (logging, remote error reporting). This is a domain-semantic mismatch that misstates the primary purpose, making it a FATAL error on core behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Processes successive command responses from an SSH-related connection context, handling specific message types and invoking appropriate callbacks for type\u20111 and type\u20114 events.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains vague and inaccurate claims. It refers to handling 'successive command responses' and 'SSH-related connection context', which is loosely related but not specific to the packet queue processing logic in the code. The mention of 'invoking appropriate callbacks for type\u20111 and type\u20114 events' is incorrect because the function actually switches on SSH2 protocol message constants (e.g., SSH2_MSG_DISCONNECT, SSH2_MSG_DEBUG, SSH2_MSG_IGNORE), not numbered event types. Overall, most claims fail to accurately map to the source code\u2019s semantics, resulting in low precision.",
                "The summary does not accurately capture the core functionality of processing queued incoming SSH2 protocol packets, specifically handling disconnect, debug, and ignore message types with distinct actions. The references to 'successive command responses' and 'type\u20111 and type\u20114 events' are incorrect and do not align with the SSH2_MSG_* constants or the behavior in the source code. As a result, the core purpose of mapping message types to actions and handling disconnect gracefully is missing and no accurate secondary details are provided.",
                "The summary has a critical inaccuracy regarding the core purpose: it mislabels handled events as 'type\u20111 and type\u20114' which do not correspond to the actual SSH message types in the code (SSH2_MSG_DISCONNECT, SSH2_MSG_DEBUG, SSH2_MSG_IGNORE). This is a FATAL error affecting the primary semantics of the function. Additionally, the summary is vague and omits key specifics such as logging debug messages, ignoring certain messages, and returning true when freed, leading to very low informational gain."
            ]
        }
    }
}
{
    "source_code": "\nint __net_init fib4_rules_init(struct net *net)\n{\n\tint err;\n\tstruct fib_rules_ops *ops;\n\n\tops = fib_rules_register(&fib4_rules_ops_template, net);\n\tif (IS_ERR(ops))\n\t\treturn PTR_ERR(ops);\n\n\terr = fib_default_rules_init(ops);\n\tif (err < 0)\n\t\tgoto fail;\n\tnet->ipv4.rules_ops = ops;\n\tnet->ipv4.fib_has_custom_rules = false;\n\treturn 0;\n\nfail:\n\t/* also cleans all rules already added */\n\tfib_rules_unregister(ops);\n\treturn err;\n}",
    "comment": "Initializes IPv4 fib rules for a specified network, registering operations and setting default rules, or cleaning up on failure.",
    "prorec_sum": "Initializes a socket-related structure and performs three configuration steps, cleaning up and returning an error if any step fails.",
    "filter_prorec_sum": "Initializes a socket-related structure with multiple configuration steps, aborting on failure, and stores it in the given context structure.",
    "prorec_aug_sum": "Initializes a network-related structure with multiple configuration steps and stores it in the given context, cleaning up if any initialization stage fails.",
    "filter_prorec_aug_sum": "Initializes a network-related structure with multiple configuration calls, cleans up on error, and stores the result pointer into the given context object.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a socket-related structure and performs three configuration steps, cleaning up and returning an error if any step fails.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly states that the function initializes a socket-related structure, which is not reflected in the source code as it deals with IPv4 routing rules. While it mentions performing configuration steps and error handling, which matches the code\u2019s registration, initialization, and cleanup logic, the majority of the claims are inaccurate regarding the domain-specific semantics, leading to low alignment.",
                "The summary incorrectly describes the function as initializing a socket-related structure, which contradicts the code's actual purpose of registering and initializing IPv4 fib rules in a network namespace. This core domain action is not covered. While it mentions configuration steps and error cleanup, these are framed generically without capturing the specific semantics of fib_rules_register, fib_default_rules_init, and fib_rules_unregister. The mismatch in domain focus and lack of accurate core coverage leads to a low alignment score.",
                "The summary contains a major inaccuracy: it states the function initializes a socket-related structure, but the code actually initializes IPv4 fib rules for a network namespace using fib_rules_register and fib_default_rules_init. This is a FATAL error affecting the primary purpose. While it correctly notes that it performs multiple steps and cleans up on failure, these are generic SAFE claims and do not offset the severe misrepresentation of the core domain behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a socket-related structure with multiple configuration steps, aborting on failure, and stores it in the given context structure.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary incorrectly identifies the initialized structure as socket-related, whereas the source code clearly deals with IPv4 routing rules via fib_rules_ops, making this a semantic mismatch. While it correctly mentions initialization, multiple configuration steps, failure handling, and storing in a context structure, the core domain claim is inaccurate. This results in less than half of the claims aligning accurately with the source semantics.",
                "The summary generically mentions initializing a socket-related structure, but the source code is actually about registering IPv4 FIB rules and associating the ops with the net namespace. The core purpose\u2014initializing and registering IPv4 routing rules\u2014is not covered, and the term 'socket-related' is inaccurate for the code's domain. While it notes aborting on failure and storing in a context, these are generic details and do not capture the specific domain semantics, resulting in no accurate coverage of the core purpose.",
                "The summary incorrectly describes the function as initializing a socket-related structure, which is a FATAL inaccuracy regarding the primary purpose. The source code is actually registering IPv4 FIB rules and setting related fields in the net structure. Although the summary mentions aborting on failure and storing in a context, these are generic SAFE claims, but the core domain semantics are wrong, making the description untrustworthy."
            ]
        }
    }
}
{
    "source_code": "static int whereLoopCheaperProperSubset(\n  const WhereLoop *pX,       /* First WhereLoop to compare */\n  const WhereLoop *pY        /* Compare against this WhereLoop */\n){\n  int i, j;\n  if( pX->nLTerm-pX->nSkip >= pY->nLTerm-pY->nSkip ){\n    return 0; /* X is not a subset of Y */\n  }\n  if( pY->nSkip > pX->nSkip ) return 0;\n  if( pX->rRun >= pY->rRun ){\n    if( pX->rRun > pY->rRun ) return 0;    /* X costs more than Y */\n    if( pX->nOut > pY->nOut ) return 0;    /* X costs more than Y */\n  }\n  for(i=pX->nLTerm-1; i>=0; i--){\n    if( pX->aLTerm[i]==0 ) continue;\n    for(j=pY->nLTerm-1; j>=0; j--){\n      if( pY->aLTerm[j]==pX->aLTerm[i] ) break;\n    }\n    if( j<0 ) return 0;  /* X not a subset of Y since term X[i] not used by Y */\n  }\n  return 1;  /* All conditions meet */\n}",
    "comment": "Determines if WhereLoop `pX` is a proper subset of WhereLoop `pY` based on terms, costs, and skip values.",
    "prorec_sum": "Checks positional bounds and verifies matching 64\u2011bit entries between two indexed arrays, returning success only if all compared elements satisfy the match criteria.",
    "filter_prorec_sum": "Checks coordinate and index ranges, then validates corresponding entries in two arrays for equality before confirming a sequential match.",
    "prorec_aug_sum": "Checks positional bounds and verifies that corresponding entries in two indexed 2D data arrays match across a specified rectangular region.",
    "filter_prorec_aug_sum": "Checks positional bounds and verifies matching 64\u2011bit entries between two arrays, returning success if all compared elements satisfy the match criteria.",
    "work_score": {
        "prorec": {
            "summary": "Checks positional bounds and verifies matching 64\u2011bit entries between two indexed arrays, returning success only if all compared elements satisfy the match criteria.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary incorrectly describes the function as checking positional bounds and matching 64-bit entries between two indexed arrays, which does not align with the source code. The code compares properties of two WhereLoop structures, including term counts, skip values, runtime cost, output count, and presence of matching terms, not generic 64-bit array entries. None of the claims in the summary accurately reflect the function's actual semantics, resulting in no accurate claims.",
                "The summary inaccurately describes the function\u2019s core purpose. The source code determines whether one WhereLoop is a proper subset of another with lower or equal cost, involving multiple conditions on term counts, skips, run costs, output counts, and membership of terms. The summary\u2019s focus on positional bounds and matching 64\u2011bit entries between two indexed arrays does not match these domain semantics, omitting the subset logic and cost comparisons. No accurate claim covers the core purpose.",
                "The summary describes checking positional bounds and matching 64-bit entries between two indexed arrays, which does not align with the actual source code logic. The function compares the number of terms, skip counts, run time, output count, and verifies that all non-null terms from pX appear in pY, rather than matching raw 64-bit entries. This is a FATAL inaccuracy regarding the primary purpose and core domain action of the function, making the description misleading and unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Checks coordinate and index ranges, then validates corresponding entries in two arrays for equality before confirming a sequential match.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary misrepresents the function\u2019s purpose and logic. The source code compares two WhereLoop structures to determine if one is a cheaper proper subset by checking term counts, skips, runtime cost, output size, and whether all terms in X are present in Y. The summary\u2019s mention of coordinate and index ranges, and sequential match of array entries, is not grounded in the domain-semantic behavior present in the code, resulting in no accurate claims.",
                "The summary makes vague references to coordinate and index ranges and array comparison, which do not match the core purpose of checking if one WhereLoop is a cheaper proper subset of another through specific term membership, skip counts, cost, and output row estimates. The core domain semantics are entirely missing and no [ACCURATE] claims cover the primary purpose. The described behavior appears generic and unrelated to the source code logic.",
                "The summary makes generic claims about checking ranges and validating array entries but misrepresents the function\u2019s actual purpose. The code compares two WhereLoop structures to determine if pX is a cheaper proper subset of pY, using conditions on nLTerm, nSkip, rRun, nOut, and matching terms in aLTerm. The provided summary ignores critical cost and subset-check semantics, replacing them with vague notions of coordinate and index ranges, which are not present in the code. This is a FATAL error concerning the primary purpose and key I/O, making the description misleading and unusable."
            ]
        }
    }
}
{
    "source_code": "\nacpi_status acpi_ut_mutex_initialize(void)\n{\n\tu32 i;\n\tacpi_status status;\n\n\tACPI_FUNCTION_TRACE(ut_mutex_initialize);\n\n\t/* Create each of the predefined mutex objects */\n\n\tfor (i = 0; i < ACPI_NUM_MUTEX; i++) {\n\t\tstatus = acpi_ut_create_mutex(i);\n\t\tif (ACPI_FAILURE(status)) {\n\t\t\treturn_ACPI_STATUS(status);\n\t\t}\n\t}\n\n\t/* Create the spinlocks for use at interrupt level or for speed */\n\n\tstatus = acpi_os_create_lock (&acpi_gbl_gpe_lock);\n\tif (ACPI_FAILURE (status)) {\n\t\treturn_ACPI_STATUS (status);\n\t}\n\n\tstatus = acpi_os_create_lock (&acpi_gbl_hardware_lock);\n\tif (ACPI_FAILURE (status)) {\n\t\treturn_ACPI_STATUS (status);\n\t}\n\n\tstatus = acpi_os_create_lock(&acpi_gbl_reference_count_lock);\n\tif (ACPI_FAILURE(status)) {\n\t\treturn_ACPI_STATUS(status);\n\t}\n\n\t/* Mutex for _OSI support */\n\n\tstatus = acpi_os_create_mutex(&acpi_gbl_osi_mutex);\n\tif (ACPI_FAILURE(status)) {\n\t\treturn_ACPI_STATUS(status);\n\t}\n\n\t/* Create the reader/writer lock for namespace access */\n\n\tstatus = acpi_ut_create_rw_lock(&acpi_gbl_namespace_rw_lock);\n\treturn_ACPI_STATUS(status);\n}",
    "comment": "Initializes predefined mutexes and locks for synchronization, including mutexes for _OSI support and a reader/writer lock for namespace access.",
    "prorec_sum": "Iterates over a table of region descriptors, allocates and initializes buffers for each, and invokes setup routines for final region configuration.",
    "filter_prorec_sum": "Initializes or allocates multiple EFI-related data structures and invokes setup routines until successful, returning an error code if allocation or initialization fails.",
    "prorec_aug_sum": "Allocates and initializes multiple data buffers, iterating through a table array and invoking helper routines until successful or returning an error code.",
    "filter_prorec_aug_sum": "Initializes or allocates multiple data structures sequentially and invokes a setup routine, returning an error code if any allocation or initialization fails.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over a table of region descriptors, allocates and initializes buffers for each, and invokes setup routines for final region configuration.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary claims iteration over region descriptors and allocation/initialization of buffers, which are not present in the source code. The function actually iterates over a fixed number of mutex identifiers to create mutexes, then creates various locks and a reader/writer lock. None of the summary\u2019s described operations or objects (region descriptors, buffers, final region configuration) match the source code. This means all claims are inaccurate and do not target the code's true semantics.",
                "The summary claims the function iterates over region descriptors, allocates buffers, and configures regions, which does not align with the source code. The code actually initializes predefined mutexes and creates several locks, with error handling after each creation. The core purpose\u2014initializing ACPI synchronization primitives\u2014is completely missing, and none of the claims from the summary are accurate to the code\u2019s semantics.",
                "The summary is entirely inaccurate with respect to the source code. The function does not iterate over region descriptors, allocate buffers, or configure regions; instead, it initializes mutexes, spinlocks, and other synchronization primitives. This constitutes a severe FATAL error on the primary purpose, as the core domain action in the summary contradicts the actual code behavior, making the description unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes or allocates multiple EFI-related data structures and invokes setup routines until successful, returning an error code if allocation or initialization fails.",
            "score": [
                0.2,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims the function initializes or allocates EFI-related data structures, which is inaccurate because the source code pertains to ACPI mutex and lock initialization and does not involve EFI. While it correctly notes iterative setup and error handling, these are generic statements. The majority of claims are misaligned with the actual domain semantics, resulting in low accuracy.",
                "The summary incorrectly describes the function as dealing with EFI-related data structures, while the source code specifically initializes ACPI mutexes, spinlocks, and locks for synchronization. It misses the core purpose of creating predefined ACPI synchronization primitives, and fails to mention key behaviors such as iterating over ACPI_NUM_MUTEX, using acpi_ut_create_mutex, handling multiple specific locks, and returning status on failures. The description is both inaccurate in domain specificity and does not cover the core semantics.",
                "The summary contains a severe inaccuracy about the primary purpose, claiming initialization of EFI-related data structures, whereas the source code clearly initializes ACPI-related mutexes, spinlocks, and locks. This misidentification directly contradicts the core functionality and key I/O, resulting in a FATAL error. There are no accurate claims to offset this, so the net benefit is effectively zero."
            ]
        }
    }
}
{
    "source_code": "void __key_link(struct key *keyring, struct key *key,\n\t\tunsigned long *_prealloc)\n{\n\tstruct keyring_list *klist, *nklist;\n\tstruct key *discard;\n\n\tnklist = (struct keyring_list *)(*_prealloc & ~KEY_LINK_FIXQUOTA);\n\t*_prealloc = 0;\n\n\tkenter(\"%d,%d,%p\", keyring->serial, key->serial, nklist);\n\n\tklist = rcu_dereference_locked_keyring(keyring);\n\n\tatomic_inc(&key->usage);\n\tkeyring->last_used_at = key->last_used_at =\n\t\tcurrent_kernel_time().tv_sec;\n\n\t/* there's a matching key we can displace or an empty slot in a newly\n\t * allocated list we can fill */\n\tif (nklist) {\n\t\tkdebug(\"reissue %hu/%hu/%hu\",\n\t\t       nklist->delkey, nklist->nkeys, nklist->maxkeys);\n\n\t\tRCU_INIT_POINTER(nklist->keys[nklist->delkey], key);\n\n\t\trcu_assign_pointer(keyring->payload.subscriptions, nklist);\n\n\t\t/* dispose of the old keyring list and, if there was one, the\n\t\t * displaced key */\n\t\tif (klist) {\n\t\t\tkdebug(\"dispose %hu/%hu/%hu\",\n\t\t\t       klist->delkey, klist->nkeys, klist->maxkeys);\n\t\t\tcall_rcu(&klist->rcu, keyring_unlink_rcu_disposal);\n\t\t}\n\t} else if (klist->delkey < klist->nkeys) {\n\t\tkdebug(\"replace %hu/%hu/%hu\",\n\t\t       klist->delkey, klist->nkeys, klist->maxkeys);\n\n\t\tdiscard = rcu_dereference_protected(\n\t\t\tklist->keys[klist->delkey],\n\t\t\trwsem_is_locked(&keyring->sem));\n\t\trcu_assign_pointer(klist->keys[klist->delkey], key);\n\t\t/* The garbage collector will take care of RCU\n\t\t * synchronisation */\n\t\tkey_put(discard);\n\t} else {\n\t\t/* there's sufficient slack space to append directly */\n\t\tkdebug(\"append %hu/%hu/%hu\",\n\t\t       klist->delkey, klist->nkeys, klist->maxkeys);\n\n\t\tRCU_INIT_POINTER(klist->keys[klist->delkey], key);\n\t\tsmp_wmb();\n\t\tklist->nkeys++;\n\t}\n}",
    "comment": "Links a key to a keyring, replacing an existing key if necessary, while managing memory and usage references appropriately.",
    "prorec_sum": "Links a dentry to an inode, updates reference counts, and integrates it into its parent\u2019s child list with initialization callbacks.",
    "filter_prorec_sum": "Links a dentry with its inode, updates parent directory structures, and initializes related context and accounting information for filesystem operations.",
    "prorec_aug_sum": "Updates linked object references and counters, creating a new handle and inserting it into an existing structure or initializing a new entry with provided parameters.",
    "filter_prorec_aug_sum": "Links a new object into an existing structure, updating references and counters, and invokes appropriate callbacks or initialization for replacement or insertion.",
    "work_score": {
        "prorec": {
            "summary": "Links a dentry to an inode, updates reference counts, and integrates it into its parent\u2019s child list with initialization callbacks.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "All claims in the summary are inaccurate because they describe filesystem operations like linking a dentry to an inode, updating reference counts, and integrating into a parent\u2019s child list, which are unrelated to the source code. The function in the source code manipulates keyring lists, updates key usage counts, and assigns keys within a keyring, not filesystem structures. None of the claims match the domain or semantics of the code.",
                "The summary claims that the function links a dentry to an inode and integrates it into a parent\u2019s child list, which is inaccurate because the source code operates on 'key' and 'keyring' objects in a key management system, not filesystem dentries or inodes. No accurate coverage of the core purpose\u2014linking a key into a keyring list structure with RCU handling\u2014is provided, and secondary behaviors like usage count increment, timestamp updates, replacement, or appending logic are also missing.",
                "The summary's claims about linking a dentry to an inode, updating reference counts, and integrating into a parent's child list with initialization callbacks are entirely unrelated to the source code, which manipulates keyring structures, preallocated lists, usage counts, and RCU pointer assignment. This is a severe factual mismatch on the primary purpose and core I/O of the function, making the description completely untrustworthy."
            ]
        },
        "filter_prorec": {
            "summary": "Links a dentry with its inode, updates parent directory structures, and initializes related context and accounting information for filesystem operations.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary describes operations related to linking a dentry with an inode and filesystem structures, which is unrelated to the provided source code. The function actually manipulates keyring data structures, updates usage counters, and manages replacement or insertion in keyring lists. None of the claims in the summary accurately reflect the code's semantics, resulting in a 0% accuracy rate.",
                "The summary is inaccurate as it describes linking a dentry with its inode and updating filesystem directory structures, which does not match the source code's actual purpose. The function operates on kernel keyrings: it links a key into a keyring list, handles preallocated lists or existing slots, updates usage counters and timestamps, and manages replacement or appending in the key list with RCU and disposal logic. The core behavior of keyring management is entirely missing, and no accurate claims align with the source code semantics.",
                "The summary contains only inaccurate claims unrelated to the actual code. It describes filesystem operations involving dentries, inodes, and directory structures, whereas the source code handles linking keys into a keyring list, updating usage counters, timestamps, and managing RCU-protected data structures. This is a severe FATAL error on the primary purpose, as the WHAT of the function is completely misrepresented, making the summary unusable."
            ]
        }
    }
}
{
    "source_code": "\n\nstatic void\nngx_http_upstream_keepalive_close_handler(ngx_event_t *ev)\n{\n    ngx_http_upstream_keepalive_srv_conf_t  *conf;\n    ngx_http_upstream_keepalive_cache_t     *item;\n\n    int                n;\n    char               buf[1];\n    ngx_connection_t  *c;\n\n    ngx_log_debug0(NGX_LOG_DEBUG_HTTP, ev->log, 0,\n                   \"keepalive close handler\");\n\n    c = ev->data;\n\n    if (c->close || c->read->timedout) {\n        goto close;\n    }\n\n    n = recv(c->fd, buf, 1, MSG_PEEK);\n\n    if (n == -1 && ngx_socket_errno == NGX_EAGAIN) {\n        ev->ready = 0;\n\n        if (ngx_handle_read_event(c->read, 0) != NGX_OK) {\n            goto close;\n        }\n\n        return;\n    }\n\nclose:\n\n    item = c->data;\n    conf = item->conf;\n\n    ngx_http_upstream_keepalive_close(c);\n\n    ngx_queue_remove(&item->queue);\n    ngx_queue_insert_head(&conf->free, &item->queue);\n}",
    "comment": "Closes an upstream keepalive connection, handling read timeouts and queue management for connection reuse.",
    "prorec_sum": "Closes an Nginx connection when error or read event occurs, releasing its memory pool and unlinking it from active connection lists.",
    "filter_prorec_sum": "Closes an HTTP connection when socket or event conditions occur, cleans up its memory pool, and removes it from linked connection lists.",
    "prorec_aug_sum": "Closes a network connection and cleans up associated resources when a read event indicates closure, error, or specific connection state flags.",
    "filter_prorec_aug_sum": "Handles upstream connection closure by checking socket/read event conditions, destroying its memory pool, closing the connection, and unlinking it from peer management lists.",
    "work_score": {
        "prorec": {
            "summary": "Closes an Nginx connection when error or read event occurs, releasing its memory pool and unlinking it from active connection lists.",
            "score": [
                0.6,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function closes an Nginx connection when an error or read event occurs, releases its memory pool, and unlinks it from active connection lists. The source shows closure occurs if the connection is marked for close, read timed out, or a read event cannot be re-registered, aligning partially with 'error occurs'. However, it does not explicitly handle generic 'read events' as a trigger, and there is no evidence of releasing the memory pool \u2014 it instead queues the item back into a 'free' list. The unlinking from active lists is represented by queue removal and insertion. Overall, the majority of claims are accurate but contain an incorrect memory pool release detail.",
                "The summary omits the core purpose of handling upstream keepalive connection closing based on specific conditions like 'close' flag, read timeout, and MSG_PEEK return values. It incorrectly mentions releasing a memory pool, which is not present in the code, and generalizes active connection list removal without noting the actual free-queue reinsertion. These inaccuracies and lack of domain-specific detail mean the core functionality is not covered and secondary behaviors are misrepresented.",
                "The summary claims the function releases the memory pool, which is not supported by the source code and contradicts the actual behavior, making it a FATAL error targeting a key side effect. The function closes the connection on certain conditions and requeues the cache item but never frees a memory pool. While the closure on error or read timeout is mostly correct, the inclusion of the incorrect memory management detail severely reduces trustworthiness."
            ]
        },
        "filter_prorec": {
            "summary": "Closes an HTTP connection when socket or event conditions occur, cleans up its memory pool, and removes it from linked connection lists.",
            "score": [
                0.5,
                0.5,
                0.5
            ],
            "reason": [
                "The summary correctly states that the function closes an HTTP connection when certain socket or event conditions occur, aligning with the code's checks for `c->close` and `timedout`, and its call to `ngx_http_upstream_keepalive_close`. However, it inaccurately claims that the function cleans up its memory pool, which is not present in the source, and describes removal from 'linked connection lists' in generic terms rather than the specific queue operations shown. These inaccuracies reduce claim precision, resulting in mixed reliability.",
                "The summary correctly notes that the function closes an HTTP connection when certain socket or event conditions occur, which aligns with the core purpose of handling upstream keepalive connection closure. However, it inaccurately describes cleanup as involving a memory pool, which is not present in the code, and omits key specifics like peeking data with recv, handling EAGAIN by re-registering read events, and reinserting the cache item into the free queue. Secondary details about branching conditions and event handling are missing, reducing coverage of behavior-critical semantics.",
                "The summary correctly notes that the function closes an HTTP connection based on socket or event conditions, which aligns with the code's main behavior. However, it inaccurately claims that it cleans up a memory pool, which is not present in the source; the actual cleanup involves removing the connection from a queue and adding it to a free list. It also generalizes 'linked connection lists' in a way that is not clearly represented in the source. These inaccuracies target the semantics of the cleanup process, making the description misleading and reducing trust, though they are not fatal to the primary purpose statement."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nshow_arch (FILE *stream, int ext, int check)\n{\n  static char message[] = MESSAGE_TEMPLATE;\n  char *start = message + 27;\n  char *p;\n  int size = sizeof (MESSAGE_TEMPLATE);\n  int left;\n  const char *name;\n  int len;\n  unsigned int j;\n\n  p = start;\n  left = size - (start - message);\n  for (j = 0; j < ARRAY_SIZE (cpu_arch); j++)\n    {\n      /* Should it be skipped?  */\n      if (cpu_arch [j].skip)\n\tcontinue;\n\n      name = cpu_arch [j].name;\n      len = cpu_arch [j].len;\n      if (*name == '.')\n\t{\n\t  /* It is an extension.  Skip if we aren't asked to show it.  */\n\t  if (ext)\n\t    {\n\t      name++;\n\t      len--;\n\t    }\n\t  else\n\t    continue;\n\t}\n      else if (ext)\n\t{\n\t  /* It is an processor.  Skip if we show only extension.  */\n\t  continue;\n\t}\n      else if (check && ! cpu_arch[j].flags.bitfield.cpui386)\n\t{\n\t  /* It is an impossible processor - skip.  */\n\t  continue;\n\t}\n\n      p = output_message (stream, p, message, start, &left, name, len);\n    }\n\n  /* Display disabled extensions.  */\n  if (ext)\n    for (j = 0; j < ARRAY_SIZE (cpu_noarch); j++)\n      {\n\tname = cpu_noarch [j].name;\n\tlen = cpu_noarch [j].len;\n\tp = output_message (stream, p, message, start, &left, name,\n\t\t\t    len);\n      }\n\n  *p = '\\0';\n  fprintf (stream, \"%s\\n\", message);\n}",
    "comment": "Outputs architecture information to a specified stream, including enabled processors and disabled extensions, based on provided flags and conditions.",
    "prorec_sum": "Generates a formatted string from predefined name fragments and writes it to the given stream, appending an extra set when the second flag is set.",
    "filter_prorec_sum": "Formats and writes a composed filename string to the output stream based on directory entries, flags, and specified formatting rules.",
    "prorec_aug_sum": "Generates a formatted string from predefined entries based on flags and writes it with a newline to the specified output stream.",
    "filter_prorec_aug_sum": "Generates and prints a formatted version information string to the given stream based on conditionally included predefined text segments.",
    "work_score": {
        "prorec": {
            "summary": "Generates a formatted string from predefined name fragments and writes it to the given stream, appending an extra set when the second flag is set.",
            "score": [
                0.3,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function writes a formatted string to the given stream, which aligns with the final fprintf call and use of output_message. However, it inaccurately describes the control flags: the function has 'ext' and 'check' with specific roles, not a generic 'second flag'; it appends disabled extensions only when 'ext' is true, not an arbitrary extra set. Additionally, the summary omits important skip logic for certain entries and misrepresents the purpose of the flags, so less than half of the claims are precise and accurate.",
                "The summary describes producing a formatted string and writing it to a stream, which loosely corresponds to the function's output behavior, but it fails to capture the core primary purpose: iterating through CPU architecture and extension arrays, applying skip conditions based on flags, and outputting their names. It incorrectly generalizes the logic as merely appending an extra set when the second flag is set, omitting critical branch conditions for ext, check, and skip, as well as the handling of disabled extensions and name modification. The core domain-specific operation is not covered, and secondary details are minimal.",
                "The summary misrepresents the function's primary purpose: the code selectively appends processor or extension names based on flags `ext` and `check`, iterating over `cpu_arch` and possibly `cpu_noarch`. The description reduces this to 'predefined name fragments' and ignores the conditional filtering logic entirely, while also incorrectly describing 'second flag' behavior\u2014`check` flag does not trigger appending an extra set, it controls skipping impossible processors. This is a FATAL error about core behavior (WHAT), making the summary unreliable."
            ]
        },
        "filter_prorec": {
            "summary": "Formats and writes a composed filename string to the output stream based on directory entries, flags, and specified formatting rules.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function formats and writes a composed filename based on directory entries, flags, and formatting rules, which does not match the source code. The code iterates over CPU architecture arrays and selectively outputs architecture or extension names to a stream, with no handling of filenames or directory entries. All claims are inaccurate with respect to the code semantics, leading to a low accuracy proportion.",
                "The summary incorrectly states that the function formats and writes a filename string based on directory entries, which does not align with the source code. The actual core purpose is to compose and output a message listing CPU architectures or extensions according to filtering flags (`ext`, `check`), drawing from `cpu_arch` and `cpu_noarch` arrays and printing to a stream. The claimed behavior targets unrelated domain semantics, missing both the core purpose and other key details such as conditional skips and handling of disabled extensions.",
                "The summary is entirely inaccurate as it describes formatting and writing a filename based on directory entries, which is unrelated to the actual function. The source code processes CPU architecture and extension names, applies filters based on flags, constructs a message string, and writes it to the provided stream. This mismatch represents a severe FATAL error in the core purpose, making the description unusable."
            ]
        }
    }
}
{
    "source_code": "\nstatic boolean ReadICCProfile(j_decompress_ptr jpeg_info)\n{\n  char\n    magick[12];\n\n  ErrorManager\n    *error_manager;\n\n  Image\n    *image;\n\n  long\n    length;\n\n  register long\n    i;\n\n  unsigned char\n    *profile;\n\n  /*\n    Determine length of color profile.\n  */\n  length=(long) GetCharacter(jpeg_info) << 8;\n  length+=(long) GetCharacter(jpeg_info);\n  length-=2;\n  if (length <= 14)\n    {\n      while (--length >= 0)\n        (void) GetCharacter(jpeg_info);\n      return(True);\n    }\n  for (i=0; i < 12; i++)\n    magick[i]=GetCharacter(jpeg_info);\n  if (LocaleCompare(magick,\"ICC_PROFILE\") != 0)\n    {\n      /*\n        Not a ICC profile, return.\n      */\n      for (i=0; i < length-12; i++)\n        (void) GetCharacter(jpeg_info);\n      return(True);\n    }\n  (void) GetCharacter(jpeg_info);  /* id */\n  (void) GetCharacter(jpeg_info);  /* markers */\n  length-=14;\n  error_manager=(ErrorManager *) jpeg_info->client_data;\n  image=error_manager->image;\n\n  /*\n    Read color profile.\n  */\n  profile=error_manager->buffer;\n\n  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                        \"ICC profile chunk: %ld bytes\",\n    length);\n\n  for (i=0 ; i < length; i++)\n   profile[i]=GetCharacter(jpeg_info);\n\n  (void) AppendImageProfile(image,\"ICM\",profile,length);\n\n  return(True);\n}",
    "comment": "Reads an ICC color profile from JPEG data, storing it in an image's buffer if the profile is valid.",
    "prorec_sum": "Reads JPEG segment bytes, detects an \u201cICC_PROFILE\u201d marker, and if found extracts and stores the embedded ICC color profile data.",
    "filter_prorec_sum": "Processes a JPEG ICC_PROFILE segment, reading its bytes and storing the ICM data into the image structure for further handling.",
    "prorec_aug_sum": "Parses JPEG segment data to detect and process embedded ICC color profiles, storing profile bytes and invoking ICM handling for valid profiles.",
    "filter_prorec_aug_sum": "Processes JPEG data to detect an \"ICC_PROFILE\" marker and, if found, reads and stores the associated ICM profile into image structures.",
    "work_score": {
        "prorec": {
            "summary": "Reads JPEG segment bytes, detects an \u201cICC_PROFILE\u201d marker, and if found extracts and stores the embedded ICC color profile data.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary makes three core claims: it reads JPEG segment bytes, detects an 'ICC_PROFILE' marker, and if found extracts and stores the embedded ICC color profile data. All of these map directly to the source code: the function reads bytes via GetCharacter, compares them to 'ICC_PROFILE', and if matched, reads the remaining profile bytes and appends them to the image profile. No contradictory or irrelevant claims are present, indicating high accuracy.",
                "The summary accurately states the main function behavior: it reads JPEG segment bytes, checks for an 'ICC_PROFILE' marker, and if present, extracts and stores the ICC color profile. This directly matches the core purpose in the code, which involves identifying the ICC profile segment and appending its data to the image. However, it omits secondary details such as handling segments shorter than the minimum, skipping non-ICC data, logging events, and the exact profile storage mechanism. Coverage of other behavior-critical semantics is limited.",
                "The summary accurately describes the primary purpose of the function: reading JPEG segment bytes, detecting the 'ICC_PROFILE' marker, and, if found, extracting and storing the ICC color profile. The statement is specific to the code's core behavior, with no apparent inaccuracies or noise. However, while correct, it is concise and omits certain details such as handling of non-'ICC_PROFILE' segments, length checks, and logging, limiting the informational gain to a moderate level."
            ]
        },
        "filter_prorec": {
            "summary": "Processes a JPEG ICC_PROFILE segment, reading its bytes and storing the ICM data into the image structure for further handling.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly identifies that the function processes a JPEG ICC_PROFILE segment and that it reads the profile bytes and stores them in the image structure. These points match the source code, which reads the ICC profile data, stores it in the buffer, and appends it to the image as ICM. The description is accurate but omits some control flow details such as handling of non-ICC segments or small lengths, yet these omissions do not contradict the source behavior. Overall, most claims are accurate and relevant.",
                "The summary accurately states that the function processes a JPEG ICC_PROFILE segment, reads its bytes, and stores the data in the image structure, which matches the core purpose of reading and appending an ICC color profile from JPEG to an image. However, it omits important secondary details such as initial length calculation, magick string check to verify ICC_PROFILE, handling of non-ICC segments, logging of the profile size, and buffer usage from the error manager. Thus, while the core is covered, secondary semantics are only lightly addressed.",
                "The summary correctly identifies that the function processes a JPEG ICC_PROFILE segment, reads its bytes, and stores the data into the image profile. This matches the source code\u2019s behavior, which reads the ICC_PROFILE header, verifies it, extracts the profile data into a buffer, and appends it to the image under the \"ICM\" profile. The claim is specific, targets the function\u2019s primary purpose accurately, and contains no contradictory or irrelevant statements. Noise is minimal and gain is moderate due to clarity and correctness."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_permutation_linear_to_canonical (gsl_permutation * q,\n                                     const gsl_permutation * p)\n{\n  const size_t n = p->size;\n  size_t i, k, s;\n  size_t t = n;\n\n  const size_t *const pp = p->data;\n  size_t *const qq = q->data;\n\n  if (q->size != p->size)\n    {\n      GSL_ERROR (\"size of q does not match size of p\", GSL_EINVAL);\n    }\n\n  for (i = 0; i < n; i++)\n    {\n\n      k = pp[i];\n      s = 1;\n\n      while (k > i)\n        {\n          k = pp[k];\n          s++;\n        }\n\n      if (k < i)\n        continue;\n\n      /* Now have k == i, i.e the least in its cycle, and s == cycle length */\n\n      t -= s;\n\n      qq[t] = i;\n\n      k = pp[i];\n      s = 1;\n\n      while (k > i)\n        {\n          qq[t + s] = k;\n          k = pp[k];\n          s++;\n        }\n\n      if (t == 0)\n        break;\n    }\n\n  return GSL_SUCCESS;\n}",
    "comment": "Converts a given permutation `p` into its canonical form and stores the result in `q`.",
    "prorec_sum": "Converts a linear permutation array into canonical cycle form, validating equal sizes and reporting an error if permutations differ in length.",
    "filter_prorec_sum": "Converts a linear permutation representation into canonical cycle form, validating matching sizes and reporting an error if dimensions differ.",
    "prorec_aug_sum": "Converts a linear permutation into its canonical cycle form, storing cycles sequentially and reporting an error if permutation sizes differ.",
    "filter_prorec_aug_sum": "Converts a linear permutation into canonical cycle form, validating matching sizes and reporting an error if the permutation lengths differ.",
    "work_score": {
        "prorec": {
            "summary": "Converts a linear permutation array into canonical cycle form, validating equal sizes and reporting an error if permutations differ in length.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function converts a linear permutation to canonical cycle form and checks if the two permutations have equal sizes, reporting an error otherwise. These details match the source code\u2019s behavior, and no claims in the summary contradict the implementation. The information is concise, correct, and focuses on the function\u2019s domain semantics, with no irrelevant or incorrect elements.",
                "The summary accurately states the core purpose, describing conversion of a linear permutation to canonical cycle form and mentioning size validation and error reporting, which directly match the code\u2019s main effect and early size check. However, it omits details about how cycles are detected and stored, the ordering via variable t, and the specific loop logic for cycle traversal, meaning coverage of secondary behaviors is minimal.",
                "The summary correctly states that the function converts a linear permutation into canonical cycle form and checks that the sizes of the permutations match, returning an error if not. These are accurate reflections of the core domain purpose and validation step in the code. There are no inaccurate or irrelevant claims, and although the description is somewhat generic, it captures the primary behavior accurately with little noise."
            ]
        },
        "filter_prorec": {
            "summary": "Converts a linear permutation representation into canonical cycle form, validating matching sizes and reporting an error if dimensions differ.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function converts a linear permutation representation into canonical cycle form, which matches the code. It also accurately notes that the function validates matching sizes and reports an error if they differ, consistent with the explicit size check and GSL_ERROR call. All claims are specific, verifiable, and aligned with the code\u2019s semantics, with no inaccuracies present.",
                "The summary accurately states the core function: converting a linear permutation to a canonical cycle form, and correctly notes the size validation and error reporting when sizes differ. This matches the core purpose of the source code and a key secondary behavior. However, it omits other important secondary details, such as the specific logic for detecting cycle minima, tracking cycle length, manipulating index t, and populating the output array in order. These omissions limit completeness beyond the core and basic error handling.",
                "The summary correctly states the core purpose: converting a linear permutation representation to canonical cycle form, and accurately notes the size validation with an error on mismatch. Both claims are specific to the source code and match its semantics, with no inaccuracies or irrelevant noise. While accurate, the description is concise and lacks deeper detail of implementation, resulting in moderate gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic int slave_update(struct link_slave *slave)\n{\n\tstruct snd_ctl_elem_value *uctl;\n\tint err, ch;\n\n\tuctl = kmalloc(sizeof(*uctl), GFP_KERNEL);\n\tif (!uctl)\n\t\treturn -ENOMEM;\n\tuctl->id = slave->slave.id;\n\terr = slave->slave.get(&slave->slave, uctl);\n\tfor (ch = 0; ch < slave->info.count; ch++)\n\t\tslave->vals[ch] = uctl->value.integer.value[ch];\n\tkfree(uctl);\n\treturn 0;\n}",
    "comment": "Updates the values of a slave device by retrieving its current control element values and storing them in the slave's array.",
    "prorec_sum": "Initializes a newly allocated structure with state from the given context and invokes further processing on it using provided double parameters.",
    "filter_prorec_sum": "Allocates and initializes a structure with data from the given context, invokes a callback, updates fields, and performs additional setup operations.",
    "prorec_aug_sum": "Allocates and populates a 72\u2011byte structure from a1\u2019s fields, invokes its callback, updates state fields, and performs further initialization with provided doubles.",
    "filter_prorec_aug_sum": "Allocates and initializes a target structure with parameters from the source object, invokes its setup callback, updates state fields, and finalizes configuration.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a newly allocated structure with state from the given context and invokes further processing on it using provided double parameters.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary inaccurately describes the function's behavior. The source code allocates a control element value structure, sets its ID from the slave context, calls a getter function, copies integer values into the slave's vals array, and frees the structure. The summary incorrectly mentions 'double parameters' and 'further processing', which are not present. None of its claims accurately represent the code's semantics, resulting in no verifiable alignment.",
                "The summary inaccurately describes the function, mentioning \"double parameters\" and generic initialization that do not match the source code\u2019s actual behavior. The code allocates a snd_ctl_elem_value structure, copies an ID from a slave struct, invokes its get callback, transfers integer values to slave->vals across channels, and frees the allocated memory. The core purpose of fetching and updating channel values from a slave control is not covered, and no accurate claims align with the specific domain operations in the code.",
                "The summary is inaccurate and mostly noise: it claims the function initializes a newly allocated structure with state from context and invokes processing using double parameters, which contradicts the code. The actual code allocates a snd_ctl_elem_value, populates its id from the slave struct, calls a function pointer to fill it, copies integer values into slave->vals, and frees it\u2014no double parameters are involved. This mismatch is a FATAL error on the core functional purpose, making the description unreliable."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a structure with data from the given context, invokes a callback, updates fields, and performs additional setup operations.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary claims the function performs additional setup operations, which are not present in the source code, making that part inaccurate. While parts about allocation, initializing a structure, invoking a callback, and updating fields match the code, the extra 'setup operations' is misleading. With one notable inaccuracy, the proportion of accurate claims is slightly above 50%, indicating mixed reliability.",
                "The summary vaguely describes allocation, initialization, callback invocation, and updating fields but fails to capture the core purpose of retrieving control element values from a slave and updating its channel values. It lacks domain-specific details such as working with `snd_ctl_elem_value`, the use of `slave->slave.get`, and copying integer values into `slave->vals`. While some steps loosely match the sequence of operations, the wording is generic and omits critical audio control semantics, leading to poor coverage of the core and secondary behaviors.",
                "The summary contains mostly generic statements like 'allocates and initializes a structure' and 'invokes a callback,' which align broadly with the code but lack specificity. It misses key details such as the use of kmalloc for memory allocation, copying values for each channel, and freeing the allocated structure. The phrase 'additional setup operations' is inaccurate, as no such extra operations occur beyond updating fields and freeing memory. There is no severe contradiction targeting core logic, but the vague and slightly inaccurate detail adds noise and offers low informational gain."
            ]
        }
    }
}
{
    "source_code": "\n\f\nint\nalias_cb(enum grecs_callback_command cmd,\n\t grecs_locus_t *locus,\n\t void *varptr,\n\t grecs_value_t *value,\n\t void *cb_data)\n{\n    char **argv;\n    int argc;\n    int i;\n\n    if (cmd != grecs_callback_set_value) {\n\tgrecs_error(locus, 0, _(\"Unexpected block statement\"));\n\treturn 1;\n    }\n    if (value->type != GRECS_TYPE_ARRAY) {\n\tgrecs_error(locus, 0, _(\"Not enough arguments for alias\"));\n\treturn 1;\n    }\n    argc = value->v.arg.c - 1;\n    argv = xcalloc(argc + 1, sizeof(argv[0]));\n    for (i = 0; i < argc; i++) {\n\tif (value->v.arg.v[i+1]->type != GRECS_TYPE_STRING) {\n\t    grecs_error(locus, 0, _(\"argument %d has wrong type\"), i+1);\n\t    return 1;\n\t}\n\targv[i] = xstrdup(value->v.arg.v[i+1]->v.string);\n    }\n    argv[i] = NULL;\n    return alias_install(value->v.arg.v[0]->v.string, argc, argv, locus);\n}",
    "comment": "Processes a callback to set an alias by checking argument types and installing the alias with provided string parameters.",
    "prorec_sum": "Validates alias command arguments, converts them to strings, and invokes a handler with the alias name and processed argument list.",
    "filter_prorec_sum": "Validates alias arguments, converts them to strings, and invokes a command handler, reporting errors for unexpected blocks or incorrect argument types.",
    "prorec_aug_sum": "Validates alias block arguments, reports errors for wrong types or counts, builds an argument list, and invokes the alias execution routine.",
    "filter_prorec_aug_sum": "Validates alias command arguments, converts them to strings, and invokes the alias creation routine, reporting specific errors for unexpected blocks or wrong argument types.",
    "work_score": {
        "prorec": {
            "summary": "Validates alias command arguments, converts them to strings, and invokes a handler with the alias name and processed argument list.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function validates alias command arguments, converts them to strings, and calls a handler with the alias name and argument list, which matches the code\u2019s logic. However, it omits important specifics like the early returns on incorrect command types and argument type checks, and does not mention allocation details. Despite these omissions, the core described behavior is accurate.",
                "The summary accurately reflects the core purpose of the function, which is to validate alias command arguments, convert them to strings, and call a handler with the alias name and processed arguments. This aligns with how the source checks the command type, validates array and string types, builds the argv array, and passes it to alias_install. However, it omits important secondary details such as handling of unexpected command types, specific error reporting for argument type mismatches, memory allocation via xcalloc, and the final NULL termination of the argument array.",
                "The summary correctly states that the function validates alias command arguments, converts them to strings, and calls a handler with the alias name and arguments, which matches the code\u2019s core purpose and I/O behavior. It omits minor specifics such as the early error conditions for unexpected commands or wrong types, but these omissions do not introduce inaccuracies. The claims are accurate but somewhat generic, offering only basic insight into the function\u2019s behavior without detailed implementation nuances."
            ]
        },
        "filter_prorec": {
            "summary": "Validates alias arguments, converts them to strings, and invokes a command handler, reporting errors for unexpected blocks or incorrect argument types.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function validates alias arguments, converts them to strings, and reports errors for unexpected blocks or incorrect argument types, which matches the source code logic. However, the phrase 'invokes a command handler' is slightly less precise than 'calls alias_install', but it still reflects the purpose of the final call. Nearly all claims are accurate and aligned with the code's semantics, with only minor vagueness in terminology.",
                "The summary correctly captures the core action of validating alias arguments, converting them to strings, and handling errors, which aligns with the function's main purpose of preparing arguments for alias installation. It mentions error handling for unexpected blocks and wrong types, reflecting key branches in the code. However, it omits the specific core domain detail that the function installs an alias using 'alias_install', which is essential for precise coverage. Secondary behaviors like memory allocation and ensuring NULL-termination are also missing.",
                "The summary correctly captures the main behavior: it validates alias arguments, ensures they are strings, and reports errors for unexpected block statements or wrong argument types. It also notes invoking a handler, which aligns with the call to alias_install. All claims are accurate and specific to the code's logic, with no contradictory or irrelevant noise. The information is clear and gives a concise understanding of the function\u2019s purpose, though the level of detail is moderate rather than exhaustive."
            ]
        }
    }
}
{
    "source_code": "static int\nis_hidden_fd(struct redirtab *rp, int fd)\n{\n\tint i;\n\tstruct parsefile *pf;\n\n\tif (fd == -1)\n\t\treturn 0;\n\t/* Check open scripts' fds */\n\tpf = g_parsefile;\n\twhile (pf) {\n\t\t/* We skip pf_fd == 0 case because of the following case:\n\t\t * $ ash  # running ash interactively\n\t\t * $ . ./script.sh\n\t\t * and in script.sh: \"exec 9>&0\".\n\t\t * Even though top-level pf_fd _is_ 0,\n\t\t * it's still ok to use it: \"read\" builtin uses it,\n\t\t * why should we cripple \"exec\" builtin?\n\t\t */\n\t\tif (pf->pf_fd > 0 && fd == pf->pf_fd) {\n\t\t\treturn 1;\n\t\t}\n\t\tpf = pf->prev;\n\t}\n\n\tif (!rp)\n\t\treturn 0;\n\t/* Check saved fds of redirects */\n\tfd |= COPYFD_RESTORE;\n\tfor (i = 0; i < rp->pair_count; i++) {\n\t\tif (rp->two_fd[i].copy == fd) {\n\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}",
    "comment": "Checks if a file descriptor is already in use by open scripts or saved redirects in the given redirection table.",
    "prorec_sum": "Checks if the given identifier matches a valid entry in a global list or a flagged record within the specified structure.",
    "filter_prorec_sum": "Checks whether the given integer identifier matches an entry in a global list or a flagged ID within the specified object's array.",
    "prorec_aug_sum": "Checks whether the given integer identifier exists in a global linked list or in an array within the specified structure.",
    "filter_prorec_aug_sum": "Checks whether the specified integer identifier exists in a global linked list or in the given object's stored ID array.",
    "work_score": {
        "prorec": {
            "summary": "Checks if the given identifier matches a valid entry in a global list or a flagged record within the specified structure.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes checking an identifier against a global list or flagged record, which is overly generic and does not accurately reflect the function\u2019s specific behavior. The source code checks whether a given file descriptor matches an open script fd in a global parsefile chain (excluding fd=0) or matches saved fds in a redirection table with a COPYFD_RESTORE mask. The summary\u2019s terms like 'valid entry' and 'flagged record' miss these critical semantics, making most claims imprecise or incorrect.",
                "The summary fails to capture the core purpose of the function, which is to determine if a given file descriptor is considered 'hidden' by checking against open script file descriptors and saved redirect file descriptors with COPYFD_RESTORE applied. The provided description vaguely mentions an identifier and a list/record, which does not accurately reflect the file descriptor operations or context in the source code. No accurate claims match the concrete domain-specific behavior, leading to the omission of the core functionality and critical details such as skipping fd=0, iterating through linked parsefile structures, and checking redirect pairs.",
                "The summary incorrectly describes the function's logic: the code checks whether a given file descriptor matches those in either a global parsefile chain or saved redirect table, not a generic 'identifier' or 'valid entry in a global list'. This is a FATAL in the primary purpose because it misstates the actual domain semantics (file descriptors vs generic identifiers). No accurate claims are present, making the response untrustworthy."
            ]
        },
        "filter_prorec": {
            "summary": "Checks whether the given integer identifier matches an entry in a global list or a flagged ID within the specified object's array.",
            "score": [
                0.3,
                0.3,
                0.2
            ],
            "reason": [
                "The summary captures the gist of matching an identifier against stored values but is too vague and generic compared to the actual function. It omits domain-specific details such as checking a global parsefile list for matching file descriptors, skipping fd=0 cases, the specific fd modification with COPYFD_RESTORE, and iterating over saved redirect fds. While loosely correct in describing matching against two sources, it fails to convey accurate semantic behavior, resulting in a low proportion of precise, verifiable claims.",
                "The summary describes checking an integer ID against a global list or an object\u2019s array, which loosely corresponds to checking `fd` against `g_parsefile` and `rp->two_fd[]`. However, it fails to capture the core domain purpose: determining if a file descriptor is 'hidden' either because it matches an open script fd (with specific exclusion for fd=0) or a saved redirect fd (tagged with COPYFD_RESTORE). It omits domain-specific terminology, condition handling, and special-case logic, providing only a vague, generic account with minimal secondary details.",
                "The summary inaccurately describes the function's behavior. The code does not check against a generic 'global list' or a vague 'flagged ID'; instead, it specifically verifies if the fd matches an open script's pf_fd in g_parsefile or a saved fd in the redirtab structure after applying COPYFD_RESTORE. The primary purpose and core domain behavior are misstated, constituting a severe FATAL error on the main logic, making the description misleading and unusable."
            ]
        }
    }
}
{
    "source_code": "\nvoid ironlake_edp_panel_off(struct intel_dp *intel_dp)\n{\n\tstruct drm_device *dev = intel_dp_to_dev(intel_dp);\n\tstruct drm_i915_private *dev_priv = dev->dev_private;\n\tu32 pp;\n\tu32 pp_ctrl_reg;\n\n\tif (!is_edp(intel_dp))\n\t\treturn;\n\n\tDRM_DEBUG_KMS(\"Turn eDP power off\\n\");\n\n\tWARN(!intel_dp->want_panel_vdd, \"Need VDD to turn off panel\\n\");\n\n\tpp = ironlake_get_pp_control(intel_dp);\n\t/* We need to switch off panel power _and_ force vdd, for otherwise some\n\t * panels get very unhappy and cease to work. */\n\tpp &= ~(POWER_TARGET_ON | EDP_FORCE_VDD | PANEL_POWER_RESET | EDP_BLC_ENABLE);\n\n\tpp_ctrl_reg = IS_VALLEYVIEW(dev) ? PIPEA_PP_CONTROL : PCH_PP_CONTROL;\n\n\tI915_WRITE(pp_ctrl_reg, pp);\n\tPOSTING_READ(pp_ctrl_reg);\n\n\tintel_dp->want_panel_vdd = false;\n\n\tironlake_wait_panel_off(intel_dp);\n}",
    "comment": "Turns off eDP panel power by modifying control registers and ensuring no VDD is supplied, preventing panel damage during shutdown.",
    "prorec_sum": "Turns off the Ironlake eDP panel, logs the action, ensures required power conditions, updates hardware state, and waits for the panel power-off delay.",
    "filter_prorec_sum": "Turns off the Ironlake eDP panel, logs status, updates power control registers, clears VDD state, and waits for panel power-down timing.",
    "prorec_aug_sum": "Turns off an Ironlake eDP panel, logs status messages, manages VDD power state, and waits for required panel power-off timing.",
    "filter_prorec_aug_sum": "Turns off the Ironlake eDP panel power, logs the action, resets power flags, and waits for the panel power-off duration.",
    "work_score": {
        "prorec": {
            "summary": "Turns off the Ironlake eDP panel, logs the action, ensures required power conditions, updates hardware state, and waits for the panel power-off delay.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly describes the function\u2019s main operations: turning off the eDP panel, logging the action, enforcing required power conditions, updating hardware register state, and waiting for power-off completion. All claims are directly supported by the source code, with no contradictions or irrelevant content, indicating high alignment with the code\u2019s semantics.",
                "The summary correctly captures the core operation of turning off the Ironlake eDP panel, which is the main function behavior, along with logging the action and waiting for power-off completion. It also generally notes ensuring required power conditions and updating hardware state, which aligns with setting control register values and modifying want_panel_vdd. However, it omits specific secondary details such as checking the device type (is_edp), issuing a WARN if VDD is not needed, clearing specific bit flags (POWER_TARGET_ON, EDP_FORCE_VDD, etc.), selecting the register based on platform (Valleyview vs. PCH), and performing POSTING_READ. These omissions mean the secondary coverage is incomplete.",
                "The summary contains accurate, concise claims about the primary function: disabling the Ironlake eDP panel, logging the event, checking for VDD requirement, writing to control registers, and waiting for the panel to power down. All these points align with the source code without any contradictory or irrelevant noise. While the claims are broadly correct and cover key steps, they are high-level and lack deep technical specifics (e.g., exact register logic or bitmask details), so net gain is positive but not maximal."
            ]
        },
        "filter_prorec": {
            "summary": "Turns off the Ironlake eDP panel, logs status, updates power control registers, clears VDD state, and waits for panel power-down timing.",
            "score": [
                0.9,
                0.8,
                0.9
            ],
            "reason": [
                "The summary correctly captures the function\u2019s purpose of turning off the Ironlake eDP panel, logging the status, updating power control registers, clearing the VDD state, and waiting for the panel to power down. All these claims directly align with the source code\u2019s behavior and do not contradict it. While minor details like condition checks and specific bitmask operations are not included, the summary remains factually accurate for the core functionality.",
                "The summary accurately covers the core purpose of turning off the Ironlake eDP panel with sufficient specificity, matching the main operation in the code. It also correctly notes secondary behaviors such as logging status, updating power control registers, clearing the VDD state, and waiting for the panel to power down. However, it omits certain critical details like the initial eDP type check, the warning about VDD requirement, the precise bits cleared in the PP control register, and the conditional selection of the PP control register based on hardware type. This makes the coverage solid but incomplete on all behavior-critical aspects.",
                "The summary correctly captures the core purpose of the function\u2014turning off the Ironlake eDP panel\u2014and includes accurate details about logging, updating the appropriate power control registers, clearing the VDD state, and waiting for the panel to power down. All these points are consistent with the source code. There is no evidence of contradictory or irrelevant claims, and the claims are specific to the function\u2019s behavior, giving a concise and correct high-level overview."
            ]
        }
    }
}
{
    "source_code": "\nstatic void die_if_script(unsigned lineno, const char *fmt, ...)\n{\n\tva_list p;\n\n#if HUSH_DEBUG >= 2\n\tbb_error_msg(\"hush.c:%u\", lineno);\n#endif\n\tva_start(p, fmt);\n\tbb_verror_msg(fmt, p, NULL);\n\tva_end(p);\n\tif (!G_interactive_fd)\n\t\txfunc_die();\n}",
    "comment": "Logs an error message with the line number and format specified, then terminates the program if not in interactive mode.",
    "prorec_sum": "Processes a byte input with multiple double parameters and forwards them to a helper function, invoking a secondary routine if a status flag is unset.",
    "filter_prorec_sum": "Formats and sends multiple double-precision values with optional vector data to a processing routine, then triggers a secondary operation if no prior result exists.",
    "prorec_aug_sum": "Packages input parameters into a structured array, forwards them with floating-point vectors for processing, and triggers a secondary handler if no result is set.",
    "filter_prorec_aug_sum": "Prepares a structured argument block with optional vector data and invokes helper routines, returning a status code from a shared configuration variable.",
    "work_score": {
        "prorec": {
            "summary": "Processes a byte input with multiple double parameters and forwards them to a helper function, invoking a secondary routine if a status flag is unset.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims involve processing a byte input and multiple double parameters, which do not match the source code that takes an unsigned line number and a format string, uses variadic arguments, and conditionally calls xfunc_die. None of the claims accurately describe the function\u2019s domain semantics, so the proportion of accurate claims is effectively zero.",
                "The summary's claims about processing a byte input and multiple double parameters do not align with the source code, which logs an error with a line number under certain debug conditions, formats and sends an error message using va_list, and terminates the process if not in interactive mode. The description misidentifies parameter types and does not mention the core purpose of reporting an error and possibly terminating. No accurate claims cover the actual domain-specific behavior, resulting in a lack of core purpose coverage and no correct secondary details.",
                "The summary\u2019s claims about processing a byte input with multiple double parameters do not match the source code, which actually handles variable arguments for an error message and conditionally calls a termination function based on a flag. These mismatches represent FATAL inaccuracies targeting the core purpose and I/O of the function, making the description untrustworthy. There are no accurate claims to offset the severe errors, resulting in zero net benefit."
            ]
        },
        "filter_prorec": {
            "summary": "Formats and sends multiple double-precision values with optional vector data to a processing routine, then triggers a secondary operation if no prior result exists.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary claims the function formats and sends multiple double-precision values with optional vector data, and triggers a secondary operation if no prior result exists. None of these claims align with the source code, which actually handles variadic arguments for an error message, optionally prints debug info, and calls a termination function if not interactive. All claims are inaccurate and do not target the code's actual semantics.",
                "The summary's claims about formatting and sending double-precision values, optional vector data, and triggering a secondary operation are unrelated to the source code's actual purpose, which is to log an error message with a line number, format and display a specific error using variadic arguments, and terminate the program if not in interactive mode. The core functionality is not mentioned and all claims are inaccurate per the evaluation steps.",
                "The summary's claims about formatting and sending double-precision values, handling optional vector data, and triggering secondary operations are entirely unrelated to the source code, which formats error messages and terminates execution if not in interactive mode. This is pure NOISE with no accurate coverage of the function's actual purpose, resulting in no net benefit."
            ]
        }
    }
}
{
    "source_code": "\nasmlinkage long compat_sys_getdents64(unsigned int fd,\n\t\tstruct linux_dirent64 __user * dirent, unsigned int count)\n{\n\tstruct fd f;\n\tstruct linux_dirent64 __user * lastdirent;\n\tstruct compat_getdents_callback64 buf;\n\tint error;\n\n\tif (!access_ok(VERIFY_WRITE, dirent, count))\n\t\treturn -EFAULT;\n\n\tf = fdget(fd);\n\tif (!f.file)\n\t\treturn -EBADF;\n\n\tbuf.current_dir = dirent;\n\tbuf.previous = NULL;\n\tbuf.count = count;\n\tbuf.error = 0;\n\n\terror = vfs_readdir(f.file, compat_filldir64, &buf);\n\tif (error >= 0)\n\t\terror = buf.error;\n\tlastdirent = buf.previous;\n\tif (lastdirent) {\n\t\ttypeof(lastdirent->d_off) d_off = f.file->f_pos;\n\t\tif (__put_user_unaligned(d_off, &lastdirent->d_off))\n\t\t\terror = -EFAULT;\n\t\telse\n\t\t\terror = count - buf.count;\n\t}\n\tfdput(f);\n\treturn error;\n}",
    "comment": "Retrieves directory entries from a file descriptor and populates a user-provided buffer with the results, handling errors and offsets.",
    "prorec_sum": "Allocates space in a file at the specified offset and length, invoking a callback for associated operations when conditions are met.",
    "filter_prorec_sum": "Allocates space in a file at the specified offset and length, invoking callbacks and updating state based on operation results.",
    "prorec_aug_sum": "Handles a futex operation by initializing state, invoking a callback, and optionally performing additional processing based on arguments and operation results.",
    "filter_prorec_aug_sum": "Handles a futex operation by preparing parameters, invoking a handler, adjusting result codes, and optionally performing additional processing based on provided timing and control arguments.",
    "work_score": {
        "prorec": {
            "summary": "Allocates space in a file at the specified offset and length, invoking a callback for associated operations when conditions are met.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims the function allocates space in a file at a specified offset and length, which is inaccurate. The source code actually reads directory entries for a given file descriptor using `vfs_readdir` and fills a user-provided buffer, with error handling for invalid memory access or bad file descriptors. The described behavior does not match the code semantics at all, so none of the claims are accurate.",
                "The summary's claim about allocating space in a file at a specified offset and length is inaccurate and unrelated to the actual function, which reads directory entries from a file descriptor for 32-bit compatibility in getdents64. No accurate claims in the summary cover the core primary purpose, which involves verifying write access, invoking vfs_readdir with a compat callback, and handling offsets and errors of directory entries. The core operation and other critical semantics are entirely missing.",
                "The summary's main claim that the function allocates space in a file at a specified offset and length is completely inaccurate and contradicts the source code's primary purpose. The source code reads directory entries from a file descriptor into a buffer via vfs_readdir and related structs, with no allocation of file space, offset setting, or length-based space reservation. This is a severe FATAL error targeting the core domain action, making the summary misleading and unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates space in a file at the specified offset and length, invoking callbacks and updating state based on operation results.",
            "score": [
                0.0,
                0.1,
                0.1
            ],
            "reason": [
                "The summary claims the function allocates space in a file at a specified offset and length, which is not reflected in the source code. The actual code reads directory entries via vfs_readdir, checks memory access, handles file descriptor retrieval, updates offsets, and returns an error or entry count. None of the specific behaviors described in the summary match the code, making all claims inaccurate.",
                "The summary's core claim about allocating space in a file at a specified offset and length is inaccurate, as the source code performs reading directory entries for a given file descriptor in a 64-bit compatibility context. No [ACCURATE] claims match the actual core purpose of iterating directory entries via vfs_readdir and updating offsets. The summary covers neither the primary domain action nor any secondary behavior-critical details such as access checks, error handling, or user-space memory operations.",
                "The summary's core claim that the function allocates space in a file at a specified offset and length is entirely inaccurate\u2014it does not match the source code, which reads directory entries from a file descriptor and populates a user buffer. This is a severe FATAL error on the primary purpose, as the WHAT is wrong. No accurate claims are present to offset this, resulting in zero net benefit."
            ]
        }
    }
}
{
    "source_code": "\nint\ngsl_multilarge_nlinear_eval_df(const CBLAS_TRANSPOSE_t TransJ,\n                               const gsl_vector *x,\n                               const gsl_vector *f,\n                               const gsl_vector *u,\n                               const gsl_vector *swts,\n                               const double h,\n                               const gsl_multilarge_nlinear_fdtype fdtype,\n                               gsl_multilarge_nlinear_fdf *fdf,\n                               gsl_vector *v,\n                               gsl_matrix *JTJ,\n                               gsl_vector *work)\n{\n  const size_t n = fdf->n;\n  const size_t p = fdf->p;\n\n  if (u != NULL && ((TransJ == CblasNoTrans && u->size != p) ||\n                    (TransJ == CblasTrans && u->size != n)))\n    {\n      GSL_ERROR(\"u vector has wrong size\", GSL_EBADLEN);\n    }\n  else if (v != NULL && ((TransJ == CblasNoTrans && v->size != n) ||\n                         (TransJ == CblasTrans && v->size != p)))\n    {\n      GSL_ERROR(\"v vector has wrong size\", GSL_EBADLEN);\n    }\n  else if (JTJ != NULL && ((JTJ->size1 != p) || (JTJ->size2 != p)))\n    {\n      GSL_ERROR(\"JTJ matrix has wrong size\", GSL_EBADLEN);\n    }\n  else\n    {\n      int status;\n\n      if (fdf->df)\n        {\n          /* call user-supplied function */\n          status = ((*((fdf)->df)) (TransJ, x, u, fdf->params, v, JTJ));\n\n          if (v)\n            ++(fdf->nevaldfu);\n\n          if (JTJ)\n            ++(fdf->nevaldf2);\n        }\n      else\n        {\n#if 0\n          /* use finite difference Jacobian approximation */\n          status = gsl_multilarge_nlinear_df(h, fdtype, x, swts, fdf, f, df, work);\n#endif\n        }\n\n      return status;\n    }\n}",
    "comment": "Evaluates the Jacobian or its finite difference approximation for a nonlinear optimization problem, checking vector and matrix sizes for validity.",
    "prorec_sum": "Validates input vector and matrix dimensions for a nonlinear large-scale evaluation, reporting size errors before invoking the model\u2019s derivative function.",
    "filter_prorec_sum": "Validates vector and matrix dimensions for nonlinear evaluation, reports size errors, and calls the appropriate evaluation routine while updating call counters.",
    "prorec_aug_sum": "Validates vector and matrix dimensions for a nonlinear large-scale GSL solver before invoking its derivative evaluation callback.",
    "filter_prorec_aug_sum": "Validates vector and matrix dimensions for nonlinear large-scale evaluation, reporting size errors, then calls the model\u2019s derivative evaluation callback.",
    "work_score": {
        "prorec": {
            "summary": "Validates input vector and matrix dimensions for a nonlinear large-scale evaluation, reporting size errors before invoking the model\u2019s derivative function.",
            "score": [
                1.0,
                0.3,
                0.7
            ],
            "reason": [
                "The summary correctly captures that the function checks input vector and matrix dimensions and reports size errors before invoking a derivative function. These details match the source code\u2019s input validation for u, v, and JTJ sizes and subsequent call to fdf->df. The claim is accurate and aligns with the function\u2019s semantics, with no contradictory or irrelevant statements.",
                "The summary accurately notes validation of vector and matrix dimensions with error reporting, which matches the code\u2019s initial checks. However, it does not cover the core primary purpose of invoking the user-supplied derivative function for large-scale nonlinear models with given transpose mode and updating evaluation counters. This omission leaves important execution details unaddressed, resulting in incomplete coverage beyond the input validation stage.",
                "The summary correctly captures that the function validates input vector and matrix dimensions and reports size errors before calling the derivative function, matching the source code's dimension checks and error handling with GSL_ERROR. This is an accurate reflection of the core behavior (validation and derivative invocation) without introducing incorrect or irrelevant details. However, the gain is modest because the description is generic, omitting specifics such as the role of TransJ, the exact dimension conditions, and handling of evaluation counters, which would provide more engineering insight."
            ]
        },
        "filter_prorec": {
            "summary": "Validates vector and matrix dimensions for nonlinear evaluation, reports size errors, and calls the appropriate evaluation routine while updating call counters.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary correctly identifies that the function validates vector and matrix dimensions, reports size errors, calls an evaluation routine, and updates call counters\u2014all of which are clearly present in the source code. Each claim aligns with actual code semantics, and there are no inaccuracies or irrelevant statements, resulting in a very high proportion of accurate claims.",
                "The summary accurately captures the core purpose of the function: checking vector and matrix dimensions, reporting errors, and invoking the appropriate evaluation routine while incrementing counters. This aligns with the code\u2019s primary behavior of validating inputs for size consistency, performing the evaluation via a user-supplied derivative function, and updating evaluation counters. However, the summary lacks detail on specific branching conditions based on transpose mode, explicit types of errors (wrong size for u, v, JTJ), and the unused finite difference path. These omissions reduce completeness despite correct coverage of the core.",
                "The summary accurately captures the function\u2019s validation of vector and matrix dimensions, its reporting of size errors, and its invocation of the appropriate evaluation routine with updates to call counters. These are specific and verifiable behaviors in the source code. There is no evidence of contradictory or irrelevant claims, and noise is negligible. The claims are mostly GOLD, targeting core semantics including primary purpose and key side effects."
            ]
        }
    }
}
{
    "source_code": "\nvoid\njitter_hash_table_add (struct jitter_hash_table *t,\n                       const union jitter_word key,\n                       const union jitter_word value,\n                       jitter_hash_function f)\n{\n  /* We only enlarge the table (when it's getting too full) on add, and never\n     shrink it. */\n  if (jitter_hash_table_overfull (t))\n    jitter_hash_table_enlarge (t, f);\n\n  t->binding_no ++;\n  jitter_uint bucket_index = f (key) % t->bucket_no;\n\n  /* Find the bucket; make it if needed. */\n  struct jitter_hash_bucket *b = t->buckets [bucket_index];\n  if (b == NULL)\n    {\n      b = jitter_xmalloc (sizeof (struct jitter_hash_bucket));\n      b->allocated_binding_no = INITIAL_BINDING_NO_PER_BUCKET;\n      b->used_binding_no = 0;\n      b->bindings\n        = jitter_xmalloc (sizeof (struct jitter_hash_binding)\n                          * INITIAL_BINDING_NO_PER_BUCKET);\n      t->buckets [bucket_index] = b;\n    }\n\n  /* Find the binding where we need to write within the bucket; make place and\n     reallocate if needed. */\n  if (b->used_binding_no == b->allocated_binding_no)\n    {\n      //printf (\"enlarging the %i-th bucket: %li to %li\\n\", (int)bucket_index, (long)b->allocated_binding_no, (long)(b->allocated_binding_no * 2));\n\n      b->bindings = jitter_xrealloc (b->bindings,\n                                     sizeof (struct jitter_hash_binding)\n                                     * (b->allocated_binding_no *= 2));\n    }\n  struct jitter_hash_binding *bi = b->bindings + (b->used_binding_no ++);\n  bi->key = key;\n  bi->value = value;\n}",
    "comment": "Adds a key-value pair to a jitter hash table, reallocating bucket space if necessary, while ensuring the table size increases when overfull.",
    "prorec_sum": "Inserts a key\u2013value pair into a hash table, allocating or expanding buckets as needed and handling hash collisions via per-bucket dynamic arrays.",
    "filter_prorec_sum": "Inserts a key\u2013value pair into a hash table, allocating and growing bucket storage as needed to maintain capacity.",
    "prorec_aug_sum": "Inserts a key\u2013value pair into a hash table, allocating or expanding bucket storage when needed and storing the key with its associated data.",
    "filter_prorec_aug_sum": "Inserts a key\u2013value pair into a hash table, allocating or expanding bucket arrays as needed based on load factor and bucket capacity.",
    "work_score": {
        "prorec": {
            "summary": "Inserts a key\u2013value pair into a hash table, allocating or expanding buckets as needed and handling hash collisions via per-bucket dynamic arrays.",
            "score": [
                0.7,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly states that the function inserts a key\u2013value pair into a hash table and allocates or expands buckets as needed, which aligns with the source code. However, the claim about handling hash collisions via per-bucket dynamic arrays is inaccurate because the code stores entries in buckets indexed directly from the hash function and does not show explicit collision resolution beyond storing multiple bindings in an array. The majority of claims are accurate, but this inaccuracy reduces overall precision.",
                "The summary correctly states that the function inserts a key\u2013value pair and dynamically allocates or expands buckets, which aligns with the code\u2019s behavior. It also notes handling of collisions via per-bucket arrays, which matches the bucket structure and indexing logic. However, it omits the specific detail that the table enlarges only when overfull during addition, and doesn\u2019t mention the increment of binding counts or the initial allocation size constants, leading to incomplete coverage of secondary behaviors despite covering the core purpose.",
                "The summary correctly states that the function inserts a key\u2013value pair into a hash table and allocates or expands buckets as needed. It also notes the use of per-bucket dynamic arrays, which is accurate for handling multiple bindings in a bucket. However, mentioning 'handling hash collisions' is slightly imprecise, as the code does not implement collision resolution beyond storing multiple bindings in an expandable array; there is no actual collision handling logic like comparing keys. This is minor noise but not a fatal error, and the summary captures the core purpose accurately with moderate specificity."
            ]
        },
        "filter_prorec": {
            "summary": "Inserts a key\u2013value pair into a hash table, allocating and growing bucket storage as needed to maintain capacity.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function inserts a key\u2013value pair and allocates or grows bucket storage as needed, which matches the code's behavior of adding an entry, creating buckets when null, and reallocating bindings when full. It omits some details such as enlarging the whole table when overfull, but the claims present are accurate and focused on the core semantics.",
                "The summary correctly captures the core operation of adding a key\u2013value pair to a hash table and mentions allocation and growth of bucket storage, which matches the code's behavior when creating buckets or enlarging them. However, it omits the specific condition for enlarging the table when overfull, the increment of binding counts, and details of how bucket growth occurs. While the core is covered, coverage of secondary behaviors like resizing conditions and allocation initialization is incomplete.",
                "The summary accurately captures the primary purpose of inserting a key\u2013value pair into the hash table and mentions bucket allocation and growth when necessary. It aligns with the source code\u2019s logic, which checks for overfull conditions, enlarges the table, allocates buckets, and reallocates bindings when capacity is reached. There is no contradictory or irrelevant noise, but the claim is fairly generic with low detail, offering only a SAFE-level insight rather than GOLD specificity."
            ]
        }
    }
}
{
    "source_code": "\n\nvoid generate_file_priorities(struct dir_info *dir, int priority,\n\tstruct stat *buf)\n{\n\tstruct dir_ent *dir_ent = dir->list;\n\n\tpriority = get_priority(dir->pathname, buf, priority);\n\n\tfor(; dir_ent; dir_ent = dir_ent->next) {\n\t\tstruct stat *buf = &dir_ent->inode->buf;\n\t\tif(dir_ent->inode->root_entry)\n\t\t\tcontinue;\n\n\t\tswitch(buf->st_mode & S_IFMT) {\n\t\t\tcase S_IFREG:\n\t\t\t\tadd_priority_list(dir_ent,\n\t\t\t\t\tget_priority(pathname(dir_ent), buf,\n\t\t\t\t\tpriority));\n\t\t\t\tbreak;\n\t\t\tcase S_IFDIR:\n\t\t\t\tgenerate_file_priorities(dir_ent->dir,\n\t\t\t\t\tpriority, buf);\n\t\t\t\tbreak;\n\t\t}\n\t}\n}",
    "comment": "Recursively assigns priority values to regular files and directories within a specified directory structure based on their pathnames and inode information.",
    "prorec_sum": "Traverses a hierarchical file or link list, matching entries by identifiers, and processes them recursively or via a handler based on type flags.",
    "filter_prorec_sum": "Traverses linked file structures to propagate or update link-related identifiers, invoking child processing and handling special types via auxiliary lookup and operations.",
    "prorec_aug_sum": "Traverses a hierarchical structure to locate matching entries by identifiers, updating or processing linked nodes based on type-specific conditions.",
    "filter_prorec_aug_sum": "Traverses hierarchical data structures to match entries by identifiers and invokes appropriate processing routines based on node type flags and stored lookup values.",
    "work_score": {
        "prorec": {
            "summary": "Traverses a hierarchical file or link list, matching entries by identifiers, and processes them recursively or via a handler based on type flags.",
            "score": [
                0.2,
                0.3,
                0.4
            ],
            "reason": [
                "The summary inaccurately describes the function's behavior: it does not match entries by identifiers or process a link list, but rather iterates over directory entries, skips root entries, and recurses into subdirectories or calls a priority handler for regular files based on file type flags. While the mention of recursion for certain types aligns loosely with the code, most claims are either incorrect or irrelevant, resulting in low accuracy.",
                "The summary mentions traversal of a hierarchical list and processing based on type flags, which loosely aligns with the function\u2019s recursive iteration over directory entries by file type. However, it inaccurately asserts matching by identifiers, which is not present in the code, and omits the core purpose of assigning file priorities via get_priority/add_priority_list. Secondary details such as skipping root entries and handling regular files vs directories are missing or underspecified.",
                "The summary makes generic claims about traversing a hierarchical list and processing entries based on type flags, but it inaccurately states 'matching entries by identifiers,' which is not in the source code. The core behavior in the code is iterating over directory entries, skipping root entries, checking file type via st_mode, and either adding to a priority list or recursing into subdirectories. The inaccurate identifier matching introduces noise and omits the important priority assignment and directory/file distinction. No FATAL errors on primary purpose are present, but noise is noticeable and gain is low due to lack of detail on priority logic and specific conditions."
            ]
        },
        "filter_prorec": {
            "summary": "Traverses linked file structures to propagate or update link-related identifiers, invoking child processing and handling special types via auxiliary lookup and operations.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary's claims about propagating or updating link-related identifiers and handling special types via auxiliary lookup do not match the source code's actual behavior, which sets priorities based on file type and recurses into directories. While it mentions traversal and invoking child processing, which is generically correct, most specifics are inaccurate or irrelevant, resulting in less than half of the claims being accurate.",
                "The summary fails to accurately capture the core purpose of the function, which is to traverse directory entries and assign file priorities recursively for files and subdirectories based on their type. The mention of 'link-related identifiers' is inaccurate as the code operates on priority values, not links, and the description of handling 'special types' is vague. No claim matches the specific domain action in the code, and secondary details such as type checks for regular files and directories, skipping root entries, and recursive calls are either misrepresented or omitted.",
                "The summary incorrectly describes the function as dealing with link-related identifiers and special type handling, which contradicts the code. The actual code traverses a linked list of directory entries to assign and propagate file priority values using get_priority, recurses into subdirectories, and adds entries to a priority list for regular files. The core purpose\u2014priority computation and propagation\u2014is misrepresented, making this a severe FATAL error about the primary purpose. No accurate claims are present to offset the harm."
            ]
        }
    }
}
{
    "source_code": "void ZSTDMT_compressChunk(void* jobDescription)\n{\n    ZSTDMT_jobDescription* const job = (ZSTDMT_jobDescription*)jobDescription;\n    const void* const src = (const char*)job->srcStart + job->dictSize;\n    buffer_t const dstBuff = job->dstBuff;\n    DEBUGLOG(3, \"job (first:%u) (last:%u) : dictSize %u, srcSize %u\", job->firstChunk, job->lastChunk, (U32)job->dictSize, (U32)job->srcSize);\n    if (job->cdict) {\n        size_t const initError = ZSTD_compressBegin_usingCDict(job->cctx, job->cdict, job->fullFrameSize);\n        if (job->cdict) DEBUGLOG(3, \"using CDict \");\n        if (ZSTD_isError(initError)) { job->cSize = initError; goto _endJob; }\n    } else {\n        size_t const initError = ZSTD_compressBegin_advanced(job->cctx, job->srcStart, job->dictSize, job->params, job->fullFrameSize);\n        if (ZSTD_isError(initError)) { job->cSize = initError; goto _endJob; }\n        ZSTD_setCCtxParameter(job->cctx, ZSTD_p_forceWindow, 1);\n    }\n    if (!job->firstChunk) {  /* flush frame header */\n        size_t const hSize = ZSTD_compressContinue(job->cctx, dstBuff.start, dstBuff.size, src, 0);\n        if (ZSTD_isError(hSize)) { job->cSize = hSize; goto _endJob; }\n        ZSTD_invalidateRepCodes(job->cctx);\n    }\n\n    DEBUGLOG(4, \"Compressing : \");\n    DEBUG_PRINTHEX(4, job->srcStart, 12);\n    job->cSize = (job->lastChunk) ?   /* last chunk signal */\n                 ZSTD_compressEnd     (job->cctx, dstBuff.start, dstBuff.size, src, job->srcSize) :\n                 ZSTD_compressContinue(job->cctx, dstBuff.start, dstBuff.size, src, job->srcSize);\n    DEBUGLOG(3, \"compressed %u bytes into %u bytes   (first:%u) (last:%u)\", (unsigned)job->srcSize, (unsigned)job->cSize, job->firstChunk, job->lastChunk);\n\n_endJob:\n    PTHREAD_MUTEX_LOCK(job->jobCompleted_mutex);\n    job->jobCompleted = 1;\n    job->jobScanned = 0;\n    pthread_cond_signal(job->jobCompleted_cond);\n    pthread_mutex_unlock(job->jobCompleted_mutex);\n}",
    "comment": "Compresses data chunks using a context or dictionary, managing the compression state and signaling job completion through condition variables.",
    "prorec_sum": "Opens or reopens a B-tree cursor for a specified table segment, selecting creation or retrieval path based on existing handles and configuration flags.",
    "filter_prorec_sum": "Creates or reuses a B-tree cursor for a specified table or index and marks the cursor as active for subsequent operations.",
    "prorec_aug_sum": "Constructs or retrieves an internal resource handle using stored parameters, selecting creation or lookup paths, and updates state indicators upon successful acquisition.",
    "filter_prorec_aug_sum": "Initializes or retrieves an object handle using provided parameters and updates related state fields based on the success of creation or lookup operations.",
    "work_score": {
        "prorec": {
            "summary": "Opens or reopens a B-tree cursor for a specified table segment, selecting creation or retrieval path based on existing handles and configuration flags.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary discusses opening or reopening a B\u2011tree cursor for a table segment, which has no relation to the function in the source code. The source code performs compression of a chunk using Zstandard APIs and handles job completion signaling, not any B\u2011tree operations. All claims are unrelated to the actual code semantics, making them inaccurate.",
                "The summary describes operations related to managing a B-tree cursor for a table segment, which is entirely unrelated to the actual function that compresses a chunk of data using Zstandard with dictionary handling, chunk sequencing, error checks, and signaling job completion. None of the claims in the summary match or accurately reflect the core purpose or any secondary behaviors of the source code.",
                "The summary is entirely inaccurate, describing operations related to B-tree cursors and table segments, which have no relation to the source code\u2019s actual functionality of compressing data chunks using ZSTD compression within a multithreaded job structure. This is a severe FATAL error concerning the primary purpose (core compression logic and key I/O), making the description unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Creates or reuses a B-tree cursor for a specified table or index and marks the cursor as active for subsequent operations.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary is entirely inaccurate, describing B-tree cursor creation and activation, which is unrelated to the source code's functionality. The function in the source code handles chunk compression using ZSTD, manages dictionaries, context parameters, and thread synchronization, without any operations involving tables, indexes, or cursors. None of the claims are accurate in relation to the provided code.",
                "The summary describes behavior related to creating or reusing a B-tree cursor for a table or index, which is entirely unrelated to the source code. The source code performs multithreaded compression of a data chunk using Zstandard, handling dictionary usage, frame headers, chunk boundaries, error checks, and signaling job completion. No accurate claims match the core domain purpose or any secondary semantics of the provided function.",
                "The summary is entirely unrelated to the source code. The function in the source code handles compression of a chunk using ZSTD, manages initialization with or without a dictionary, processes first/last chunks differently, and signals job completion using mutexes and condition variables. The summary instead describes creating or reusing a B-tree cursor and marking it active, which is unrelated to the function's primary purpose, inputs, outputs, or side effects. This is a severe factual mismatch on the core domain action, representing a FATAL error."
            ]
        }
    }
}
{
    "source_code": "\nSEXP attribute_hidden do_Rhome(SEXP call, SEXP op, SEXP args, SEXP rho)\n{\n    char *path;\n    checkArity(op, args);\n    if (!(path = R_HomeDir()))\n\terror(_(\"unable to determine R home location\"));\n    return mkString(path);\n}",
    "comment": "Returns the R home directory path as a string after verifying the function's arity and checking if the path can be determined.",
    "prorec_sum": "Returns a single-element character vector containing R\u2019s home directory path, raising an error if the home location cannot be determined.",
    "filter_prorec_sum": "Returns a character vector containing the R home directory path, raising an error if the location cannot be determined.",
    "prorec_aug_sum": "Creates a single-element character vector containing the R home directory path, raising an error if the location cannot be determined.",
    "filter_prorec_aug_sum": "Creates a character vector containing the R home directory path, returning an error if the home location cannot be determined.",
    "work_score": {
        "prorec": {
            "summary": "Returns a single-element character vector containing R\u2019s home directory path, raising an error if the home location cannot be determined.",
            "score": [
                1.0,
                0.8,
                1.0
            ],
            "reason": [
                "The summary accurately states that the function returns a single-element character vector containing R\u2019s home directory path and raises an error if it cannot determine the location. Both claims align with the source code: the mkString(path) return and the error triggered when R_HomeDir() returns NULL. All claims are domain-specific and verifiable, with no inaccuracies present.",
                "The summary accurately describes that the function returns a character vector with R's home directory and raises an error when it cannot be determined, which matches the core purpose and key error handling in the source code. It omits the checkArity step, but covers the main functionality and critical behavior.",
                "The summary accurately describes the function\u2019s primary purpose: returning a single-element character vector with R\u2019s home directory path and raising an error if the path cannot be determined. Both claims match the source code exactly \u2014 `mkString(path)` returns a single-element character vector, and `error(...)` is called if `R_HomeDir()` returns null. There is no noise or inaccuracies, and the information is specific and domain-relevant, offering clear insight into core behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Returns a character vector containing the R home directory path, raising an error if the location cannot be determined.",
            "score": [
                1.0,
                0.8,
                1.0
            ],
            "reason": [
                "The summary makes two fact-based claims: that the function returns a character vector containing the R home directory path, and that it raises an error if the location cannot be determined. Both claims are specific to the function\u2019s behavior and match the source code, which calls `R_HomeDir()`, checks for a null return, raises an error accordingly, and returns the path via `mkString`. This yields a high proportion of accurate claims.",
                "The summary correctly identifies that the function returns the R home directory path and raises an error if it cannot be determined, which matches the source code\u2019s core purpose and error-handling behavior. It omits mention of input arity checking but otherwise captures the primary semantics accurately.",
                "The summary accurately reflects the core function behavior: it returns a string with the R home directory path and raises an error if undetermined. These are highly specific and verifiable claims directly supported by the code. No inaccuracies or irrelevant noise are present, and the claims describe the primary purpose and key side effect clearly, offering high informational value."
            ]
        }
    }
}
{
    "source_code": "int snd_hda_mixer_amp_volume_get(struct snd_kcontrol *kcontrol,\n\t\t\t\t struct snd_ctl_elem_value *ucontrol)\n{\n\tstruct hda_codec *codec = snd_kcontrol_chip(kcontrol);\n\thda_nid_t nid = get_amp_nid(kcontrol);\n\tint chs = get_amp_channels(kcontrol);\n\tint dir = get_amp_direction(kcontrol);\n\tint idx = get_amp_index(kcontrol);\n\tunsigned int ofs = get_amp_offset(kcontrol);\n\tlong *valp = ucontrol->value.integer.value;\n\n\tif (chs & 1)\n\t\t*valp++ = read_amp_value(codec, nid, 0, dir, idx, ofs);\n\tif (chs & 2)\n\t\t*valp = read_amp_value(codec, nid, 1, dir, idx, ofs);\n\treturn 0;\n}",
    "comment": "Retrieves and stores the volume values for specified audio channels from a sound codec's amplifier settings into the provided control element structure.",
    "prorec_sum": "Computes adjusted audio control values from codec registers and writes them to output slots based on specific flag and bitfield conditions.",
    "filter_prorec_sum": "Computes adjusted values from codec registers and updates output buffer fields based on specific control bits and a helper processing routine.",
    "prorec_aug_sum": "Computes adjusted values from codec configuration bits using a helper routine and stores them into specific offsets within the provided output structure.",
    "filter_prorec_aug_sum": "Updates codec-related output registers based on specific control bits, calculating values via a helper function and applying range limits before storing.",
    "work_score": {
        "prorec": {
            "summary": "Computes adjusted audio control values from codec registers and writes them to output slots based on specific flag and bitfield conditions.",
            "score": [
                0.2,
                0.3,
                0.2
            ],
            "reason": [
                "The summary claims that the function computes 'adjusted' audio control values from codec registers and writes them based on specific flag and bitfield conditions. In the source code, the function reads raw amplifier values via read_amp_value and writes them directly to output slots depending on channel bitmask checks, not performing any adjustments or complex flag/bitfield processing beyond channel masking. The description of 'adjusted' and 'bitfield conditions' is inaccurate, reducing the proportion of accurate claims to below half.",
                "The summary fails to explicitly state the core purpose, which is retrieving amplifier volume values for specified channels from an HDA codec and storing them in the provided control element structure. While it generically mentions computing adjusted audio control values and output slots, this description is vague and not clearly tied to reading current values from the codec via channel-specific logic. It omits key details such as channel bit checks, left/right channel reads, and the direct mapping of values into the control element, leading to incomplete coverage of both the main purpose and secondary behaviors.",
                "The summary\u2019s main claim that the function computes adjusted audio control values from codec registers and writes them based on specific flag and bitfield conditions is inaccurate. The source code simply reads raw amplifier values from the codec for specific channels determined by a channel mask, without any computation or adjustment, and writes them directly into the provided output structure. The mention of flags and bitfields is misleading noise, not supported by the implementation. This is a FATAL error targeting the primary purpose of the function, making the description untrustworthy for core behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Computes adjusted values from codec registers and updates output buffer fields based on specific control bits and a helper processing routine.",
            "score": [
                0.5,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function computes adjusted values from codec registers based on control bits and helper routines. While the code does read values from the codec via a helper (read_amp_value) and updates the output buffer (ucontrol->value.integer.value), it does not explicitly 'adjust' these values and there is no evidence of 'specific control bits' being processed. The control flow is determined by channel bitmask (chs & 1, chs & 2), which is not clearly described in the summary. This results in partial alignment, with some accurate but general statements and some inaccuracies regarding specific behavior.",
                "The summary does not accurately capture the core purpose of the function, which is to retrieve amplifier volume values for specified channels from the codec using helper functions derived from control parameters. It incorrectly describes the operation as computing adjusted values from codec registers and updating output buffer fields based on control bits, which misrepresents the specific domain action. No accurate claim identifies the read_amp_value per channel logic or the mapping to ucontrol->value, so the core functionality coverage is missing and secondary details are absent.",
                "The summary incorrectly describes the function as computing adjusted values from codec registers and updating output buffer fields based on control bits, which contradicts the actual code. The code simply reads raw amplifier values for specific channels using helper functions and writes them into the provided output structure, without performing adjustments or processing based on control bits. This is a FATAL error targeting the primary purpose, rendering the summary untrustworthy."
            ]
        }
    }
}
{
    "source_code": "\nstatic struct demangle_component *\nd_make_comp (struct d_info *di, enum demangle_component_type type,\n             struct demangle_component *left,\n             struct demangle_component *right)\n{\n  struct demangle_component *p;\n\n  /* We check for errors here.  A typical error would be a NULL return\n     from a subroutine.  We catch those here, and return NULL\n     upward.  */\n  switch (type)\n    {\n      /* These types require two parameters.  */\n    case DEMANGLE_COMPONENT_QUAL_NAME:\n    case DEMANGLE_COMPONENT_LOCAL_NAME:\n    case DEMANGLE_COMPONENT_TYPED_NAME:\n    case DEMANGLE_COMPONENT_TAGGED_NAME:\n    case DEMANGLE_COMPONENT_TEMPLATE:\n    case DEMANGLE_COMPONENT_CONSTRUCTION_VTABLE:\n    case DEMANGLE_COMPONENT_VENDOR_TYPE_QUAL:\n    case DEMANGLE_COMPONENT_PTRMEM_TYPE:\n    case DEMANGLE_COMPONENT_UNARY:\n    case DEMANGLE_COMPONENT_BINARY:\n    case DEMANGLE_COMPONENT_BINARY_ARGS:\n    case DEMANGLE_COMPONENT_TRINARY:\n    case DEMANGLE_COMPONENT_TRINARY_ARG1:\n    case DEMANGLE_COMPONENT_LITERAL:\n    case DEMANGLE_COMPONENT_LITERAL_NEG:\n    case DEMANGLE_COMPONENT_COMPOUND_NAME:\n    case DEMANGLE_COMPONENT_VECTOR_TYPE:\n    case DEMANGLE_COMPONENT_CLONE:\n      if (left == NULL || right == NULL)\n\treturn NULL;\n      break;\n\n      /* These types only require one parameter.  */\n    case DEMANGLE_COMPONENT_VTABLE:\n    case DEMANGLE_COMPONENT_VTT:\n    case DEMANGLE_COMPONENT_TYPEINFO:\n    case DEMANGLE_COMPONENT_TYPEINFO_NAME:\n    case DEMANGLE_COMPONENT_TYPEINFO_FN:\n    case DEMANGLE_COMPONENT_THUNK:\n    case DEMANGLE_COMPONENT_VIRTUAL_THUNK:\n    case DEMANGLE_COMPONENT_COVARIANT_THUNK:\n    case DEMANGLE_COMPONENT_JAVA_CLASS:\n    case DEMANGLE_COMPONENT_GUARD:\n    case DEMANGLE_COMPONENT_TLS_INIT:\n    case DEMANGLE_COMPONENT_TLS_WRAPPER:\n    case DEMANGLE_COMPONENT_REFTEMP:\n    case DEMANGLE_COMPONENT_HIDDEN_ALIAS:\n    case DEMANGLE_COMPONENT_TRANSACTION_CLONE:\n    case DEMANGLE_COMPONENT_NONTRANSACTION_CLONE:\n    case DEMANGLE_COMPONENT_POINTER:\n    case DEMANGLE_COMPONENT_REFERENCE:\n    case DEMANGLE_COMPONENT_RVALUE_REFERENCE:\n    case DEMANGLE_COMPONENT_COMPLEX:\n    case DEMANGLE_COMPONENT_IMAGINARY:\n    case DEMANGLE_COMPONENT_VENDOR_TYPE:\n    case DEMANGLE_COMPONENT_CAST:\n    case DEMANGLE_COMPONENT_CONVERSION:\n    case DEMANGLE_COMPONENT_JAVA_RESOURCE:\n    case DEMANGLE_COMPONENT_DECLTYPE:\n    case DEMANGLE_COMPONENT_PACK_EXPANSION:\n    case DEMANGLE_COMPONENT_GLOBAL_CONSTRUCTORS:\n    case DEMANGLE_COMPONENT_GLOBAL_DESTRUCTORS:\n    case DEMANGLE_COMPONENT_NULLARY:\n    case DEMANGLE_COMPONENT_TRINARY_ARG2:\n      if (left == NULL)\n\treturn NULL;\n      break;\n\n      /* This needs a right parameter, but the left parameter can be\n\t empty.  */\n    case DEMANGLE_COMPONENT_ARRAY_TYPE:\n    case DEMANGLE_COMPONENT_INITIALIZER_LIST:\n      if (right == NULL)\n\treturn NULL;\n      break;\n\n      /* These are allowed to have no parameters--in some cases they\n\t will be filled in later.  */\n    case DEMANGLE_COMPONENT_FUNCTION_TYPE:\n    case DEMANGLE_COMPONENT_RESTRICT:\n    case DEMANGLE_COMPONENT_VOLATILE:\n    case DEMANGLE_COMPONENT_CONST:\n    case DEMANGLE_COMPONENT_ARGLIST:\n    case DEMANGLE_COMPONENT_TEMPLATE_ARGLIST:\n    FNQUAL_COMPONENT_CASE:\n      break;\n\n      /* Other types should not be seen here.  */\n    default:\n      return NULL;\n    }\n\n  p = d_make_empty (di);\n  if (p != NULL)\n    {\n      p->type = type;\n      p->u.s_binary.left = left;\n      p->u.s_binary.right = right;\n    }\n  return p;\n}",
    "comment": "Constructs a demangle component by validating parameters based on type and initializing its properties, returning NULL for errors or invalid types.",
    "prorec_sum": "Adds an entry with specified type and parameters to a bounded array if the type and nonzero arguments satisfy required conditions.",
    "filter_prorec_sum": "Appends a new entry with given type and parameters to a bounded list within the structure if case-specific non\u2011null conditions are satisfied.",
    "prorec_aug_sum": "Appends a new entry with specified type and parameters to an internal list if conditions based on the type code and arguments are met.",
    "filter_prorec_aug_sum": "Adds an entry with given type and parameters to a bounded list if the type and arguments satisfy specific switch-case acceptance conditions.",
    "work_score": {
        "prorec": {
            "summary": "Adds an entry with specified type and parameters to a bounded array if the type and nonzero arguments satisfy required conditions.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims that the function adds an entry to a bounded array, but the source code shows it creates and returns a `demangle_component` struct, not interacting with any bounded array. It also incorrectly refers to 'nonzero arguments' instead of checking for NULL pointers as in the code. The only partially accurate aspect is that the type and parameters must satisfy certain conditions, but most claims contradict actual behavior, leading to low accuracy.",
                "The summary incorrectly describes the function as adding an entry to a bounded array, which does not match the source code's core purpose of creating and initializing a new demangle_component based on type-specific parameter requirements. While it vaguely mentions conditions on arguments, it omits the core domain action and misrepresents the data structure involved, leading to an inaccurate coverage of the primary purpose and other behaviors.",
                "The summary is inaccurate about the core purpose: it describes adding an entry to a bounded array, which contradicts the actual code that constructs and returns a demangle_component object. This is a FATAL error on the primary purpose. While it vaguely notes conditions based on type and arguments, it does not capture the actual branching logic for parameter requirements and omits that it returns NULL on mismatches. The worst failure mode is a severe FATAL on the function\u2019s main action."
            ]
        },
        "filter_prorec": {
            "summary": "Appends a new entry with given type and parameters to a bounded list within the structure if case-specific non\u2011null conditions are satisfied.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function appends a new entry to a bounded list, which is inaccurate because the source code creates and returns a new demangle_component rather than manipulating a bounded list. While it correctly notes case-specific non-null checks for parameters, the core description misrepresents the function\u2019s semantics, making the majority of its content incorrect.",
                "The summary fails to identify the core purpose of constructing and returning a demangle_component based on type-specific parameter rules in the source code. It inaccurately describes the action as appending to a bounded list, which is not present, and omits key semantics such as handling different DEMANGLE_COMPONENT_* cases, error checking for null parameters, and populating fields via d_make_empty. No accurate claims cover the actual domain-specific operation.",
                "The summary inaccurately describes the function\u2019s primary purpose by stating it appends a new entry to a bounded list, which is not reflected in the source code. The actual code constructs a new demangle_component object after validating case-specific parameter nullity, not managing or appending to a bounded list. This constitutes a FATAL error on the core domain action, with no accurate claims present to offset the misinformation."
            ]
        }
    }
}
{
    "source_code": "static enum mu_filter_result\n_c_escape_decoder (void *xd MU_ARG_UNUSED,\n\t\t   enum mu_filter_command cmd,\n\t\t   struct mu_filter_io *iobuf)\n{\n  size_t i, j;\n  const unsigned char *iptr;\n  size_t isize;\n  char *optr;\n  size_t osize;\n  \n  switch (cmd)\n    {\n    case mu_filter_init:\n    case mu_filter_done:\n      return mu_filter_ok;\n    default:\n      break;\n    }\n  \n  iptr = (const unsigned char *) iobuf->input;\n  isize = iobuf->isize;\n  optr = iobuf->output;\n  osize = iobuf->osize;\n\n  for (i = j = 0; i < isize && j < osize; i++)\n    {\n      unsigned char c = *iptr++;\n      if (c == '\\\\')\n\t{\n\t  int x;\n\t  if (i + 1 == isize)\n\t    break;\n\t  c = *iptr++;\n\t  i++;\n\t  x = mu_wordsplit_c_unquote_char (c);\n\t  optr[j++] = (x == -1) ? c : x;\n\t}\n      else\n\toptr[j++] = c;\n    }\n\n  iobuf->isize = i;\n  iobuf->osize = j;\n  return mu_filter_ok;\n}",
    "comment": "Decodes escape sequences in the input buffer by replacing backslash-prefixed characters with their unquoted equivalents, storing results in the output buffer.",
    "prorec_sum": "Processes an input byte sequence, handling backslash escape sequences via character unquoting, and writes the resulting bytes into an output buffer.",
    "filter_prorec_sum": "Processes an input byte sequence, handling backslash escape sequences via `mu_wordsplit_c_unquote_char`, and writes the unescaped result to the output buffer.",
    "prorec_aug_sum": "Processes an input byte stream, decoding backslash escape sequences into characters and writing the result into an output buffer with updated position counters.",
    "filter_prorec_aug_sum": "Processes an input byte stream, decoding backslash escape sequences into unquoted characters and writing the result into the output buffer.",
    "work_score": {
        "prorec": {
            "summary": "Processes an input byte sequence, handling backslash escape sequences via character unquoting, and writes the resulting bytes into an output buffer.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary accurately reflects the core function behavior: it reads an input byte sequence, processes backslash escapes by using a character unquoting function, and writes the translated characters to the output buffer. These points match the source, including the escape handling loop and buffer writing logic, with no incorrect or missing key behaviors. All extracted claims are correct and targeted to the code semantics, giving a very high proportion of accurate claims.",
                "The summary accurately captures the core purpose of the function: decoding a byte stream by interpreting backslash escape sequences with a character unquoting routine and writing results to an output buffer, matching the code's domain-specific behavior. It omits some secondary details such as handling specific filter commands (init/done returning immediately), bounds checking on input/output sizes, and the behavior when an escape is at the end of input, but these are secondary to the core.",
                "The summary accurately captures the core domain behavior of the function: reading an input byte sequence, processing backslash escape sequences by unquoting characters, and writing the resultant bytes to the output buffer. It aligns with the source code's loop, backslash check, call to `mu_wordsplit_c_unquote_char`, and buffer writes. There are no contradictory claims or irrelevant noise, though the description is concise and omits minor details like command handling for init/done cases. The main gain is from accurately reflecting the primary purpose, giving specific insight on input/output transformation."
            ]
        },
        "filter_prorec": {
            "summary": "Processes an input byte sequence, handling backslash escape sequences via `mu_wordsplit_c_unquote_char`, and writes the unescaped result to the output buffer.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly describes that the function processes an input byte sequence, handles backslash escape sequences using `mu_wordsplit_c_unquote_char`, and writes the unescaped result to the output buffer. These are accurate reflections of the code's core behavior. While the summary omits certain details like the treatment of `mu_filter_init` and `mu_filter_done` commands and buffer size limitations, all included claims align with the source code semantics, resulting in a high proportion of accurate statements.",
                "The summary correctly identifies the core purpose \u2014 decoding backslash escape sequences in the input using `mu_wordsplit_c_unquote_char` and writing the unescaped result to the output \u2014 which matches the source code\u2019s primary domain operation. However, it omits secondary behavior such as handling `mu_filter_init` and `mu_filter_done` commands, breaking on incomplete escapes, and updating `iobuf->isize` and `iobuf->osize` to reflect processed lengths. These omissions make coverage of secondary details limited.",
                "The summary accurately conveys the primary purpose of the function: it processes an input byte sequence, interprets backslash escape sequences using `mu_wordsplit_c_unquote_char`, and writes the resultant unescaped characters to the output buffer. This matches the core loop and logic in the source code, with no contradictory or noisy claims. While the description is correct and focused on the key behavior, it omits secondary but potentially helpful details such as command handling for initialization and completion, buffer size limits, and termination conditions, making the gain moderate rather than maximal."
            ]
        }
    }
}
{
    "source_code": "int\nevutil_read_file_(const char *filename, char **content_out, size_t *len_out,\n    int is_binary)\n{\n\tint fd, r;\n\tstruct stat st;\n\tchar *mem;\n\tsize_t read_so_far=0;\n\tint mode = O_RDONLY;\n\n\tEVUTIL_ASSERT(content_out);\n\tEVUTIL_ASSERT(len_out);\n\t*content_out = NULL;\n\t*len_out = 0;\n\n#ifdef O_BINARY\n\tif (is_binary)\n\t\tmode |= O_BINARY;\n#endif\n\n\tfd = evutil_open_closeonexec_(filename, mode, 0);\n\tif (fd < 0)\n\t\treturn -1;\n\tif (fstat(fd, &st) || st.st_size < 0 ||\n\t    st.st_size > EV_SSIZE_MAX-1 ) {\n\t\tclose(fd);\n\t\treturn -2;\n\t}\n\tmem = mm_malloc((size_t)st.st_size + 1);\n\tif (!mem) {\n\t\tclose(fd);\n\t\treturn -2;\n\t}\n\tread_so_far = 0;\n#ifdef _WIN32\n#define N_TO_READ(x) ((x) > INT_MAX) ? INT_MAX : ((int)(x))\n#else\n#define N_TO_READ(x) (x)\n#endif\n\twhile ((r = read(fd, mem+read_so_far, N_TO_READ(st.st_size - read_so_far))) > 0) {\n\t\tread_so_far += r;\n\t\tif (read_so_far >= (size_t)st.st_size)\n\t\t\tbreak;\n\t\tEVUTIL_ASSERT(read_so_far < (size_t)st.st_size);\n\t}\n\tclose(fd);\n\tif (r < 0) {\n\t\tmm_free(mem);\n\t\treturn -2;\n\t}\n\tmem[read_so_far] = 0;\n\n\t*len_out = read_so_far;\n\t*content_out = mem;\n\treturn 0;\n}",
    "comment": "Reads the contents of a specified file into a dynamically allocated buffer, returning the length and handling binary mode if specified.",
    "prorec_sum": "Reads the entire contents of a file into a newly allocated null-terminated buffer, returning its size and handling errors appropriately.",
    "filter_prorec_sum": "Reads the entire contents of a file into a newly allocated, null-terminated buffer and returns its address and length via output parameters.",
    "prorec_aug_sum": "Reads the entire contents of a file into a newly allocated null\u2011terminated buffer, returning its size and handling file or memory errors.",
    "filter_prorec_aug_sum": "Reads the entire contents of a file into a newly allocated, null\u2011terminated buffer and returns its pointer and length via output parameters.",
    "work_score": {
        "prorec": {
            "summary": "Reads the entire contents of a file into a newly allocated null-terminated buffer, returning its size and handling errors appropriately.",
            "score": [
                0.9,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately captures the core behavior of the function, which reads a file\u2019s contents into a newly allocated null-terminated buffer, returns its size, and includes error handling. These claims align with the source code\u2019s implementation and do not contradict it. There are no irrelevant or incorrect details, making the proportion of accurate claims very high.",
                "The summary correctly states the primary purpose of reading an entire file into a dynamically allocated null-terminated buffer and returning its size, which aligns with the core behavior in the source code. It also notes error handling, covering a secondary aspect. However, it omits important details such as handling binary mode, specific error codes, capacity checks for file size, platform-specific read limits, and memory allocation failures, making the coverage of secondary behaviors incomplete.",
                "The summary correctly describes the core purpose: reading the entire file into a newly allocated null-terminated buffer, returning the size, and handling errors. These are specific and accurate reflections of the source code (GOLD), with no contradictory or irrelevant claims. Noise is negligible, and the key I/O and side effects are covered clearly, providing high informational value."
            ]
        },
        "filter_prorec": {
            "summary": "Reads the entire contents of a file into a newly allocated, null-terminated buffer and returns its address and length via output parameters.",
            "score": [
                1.0,
                0.5,
                0.8
            ],
            "reason": [
                "The summary accurately states that the function reads the entire file contents into a newly allocated, null-terminated buffer and returns both the buffer address and length via output parameters. These details match the source code\u2019s behavior, including memory allocation, null termination, and use of output pointers. There are no incorrect or irrelevant claims, making all information precise and aligned with the code.",
                "The summary accurately captures the core purpose of reading an entire file into a newly allocated, null-terminated buffer and returning its address and length via output parameters, which matches the source code's main operation. However, it omits important secondary details such as handling binary mode flags, error return codes (-1 and -2) for different failure conditions, allocation specifics, read loop behavior, and platform-dependent macros, resulting in incomplete coverage of behavior-critical semantics.",
                "The summary accurately describes the core purpose of the function: reading an entire file into a newly allocated, null-terminated buffer and returning its address and length via output parameters. This matches the source code\u2019s behavior, including allocation, null-termination, and output parameter usage. There is no indication of incorrect semantics or extraneous noise, though the description is concise and lacks implementation specifics such as error handling or binary mode considerations, resulting in modest informational gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic int disk_status(struct dm_dirty_log *log, status_type_t status,\n\t\t       char *result, unsigned int maxlen)\n{\n\tint sz = 0;\n\tstruct log_c *lc = log->context;\n\n\tswitch(status) {\n\tcase STATUSTYPE_INFO:\n\t\tDMEMIT(\"3 %s %s %c\", log->type->name, lc->log_dev->name,\n\t\t       lc->log_dev_flush_failed ? 'F' :\n\t\t       lc->log_dev_failed ? 'D' :\n\t\t       'A');\n\t\tbreak;\n\n\tcase STATUSTYPE_TABLE:\n\t\tDMEMIT(\"%s %u %s %u \", log->type->name,\n\t\t       lc->sync == DEFAULTSYNC ? 2 : 3, lc->log_dev->name,\n\t\t       lc->region_size);\n\t\tDMEMIT_SYNC;\n\t}\n\n\treturn sz;\n}",
    "comment": "Generates and emits status information for a dirty log based on the provided status type, including device name and synchronization details.",
    "prorec_sum": "Formats and writes synchronization or status information into a buffer based on provided parameters and internal structure fields.",
    "filter_prorec_sum": "Formats and writes synchronization or status command strings with device-specific fields into a provided buffer based on mode and internal state flags.",
    "prorec_aug_sum": "Formats and writes connection or device status information, including sync state or mode indicator, into the provided output buffer based on input parameters.",
    "filter_prorec_aug_sum": "Formats and writes synchronization or status command strings into a buffer based on mode and object state fields.",
    "work_score": {
        "prorec": {
            "summary": "Formats and writes synchronization or status information into a buffer based on provided parameters and internal structure fields.",
            "score": [
                0.8,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly conveys that the function outputs status information into a buffer using parameters and internal structure fields, which aligns with the observed use of DMEMIT macros and fields from 'log' and 'lc'. However, mentioning 'synchronization' is partially misleading\u2014while the code conditionally emits a sync value, it primarily formats status or table information. Overall, most of the content matches code semantics, with only minor overgeneralization.",
                "The summary generically states that the function formats and writes synchronization or status information into a buffer, which loosely matches the code\u2019s conditional formatting of device type, name, flags, and region size based on the status type. However, it does not clearly capture the core purpose of emitting detailed device-mapper dirty log status or table information with specific fields and branch logic, resulting in incomplete coverage of the primary domain action and missing coverage of important constants, field conditions, and output patterns.",
                "The summary correctly captures the generic purpose of formatting and writing status or synchronization information into a buffer based on parameters and internal fields, which aligns with the code's use of DMEMIT to output status info depending on the status type. However, it is low-information and generic, missing specific details such as the exact formatted fields, conditional flags for device failure, and the values emitted for STATUSTYPE_INFO vs STATUSTYPE_TABLE. There are no inaccurate or contradictory claims; the main shortcoming is low gain due to lack of specificity."
            ]
        },
        "filter_prorec": {
            "summary": "Formats and writes synchronization or status command strings with device-specific fields into a provided buffer based on mode and internal state flags.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly describes that the function formats and writes status strings using device-specific fields and depends on mode (status type) and internal state flags, which aligns with the source code's use of DMEMIT to output formatted strings with log type, device name, and flags for different status modes. All elements are relevant to the code semantics, making the claims highly accurate.",
                "The summary correctly states that the function formats and writes status strings with device-specific fields depending on mode and flags, which aligns with the code\u2019s handling of STATUSTYPE_INFO and STATUSTYPE_TABLE cases using DMEMIT macros and conditional flag checks. However, it does not capture the core primary purpose with full specificity\u2014namely, emitting disk log status information including type name, log device name, failure state, sync mode, and region size\u2014nor does it mention the different formatting between info and table modes. Secondary details like constants, the conditional formatting of failure flags, and specific output fields are omitted.",
                "The summary correctly captures that the function formats and writes device-specific information into the provided buffer depending on the mode (status type) and internal state flags, matching the use of DMEMIT with values derived from mode and log context. The description is generic but accurate, with no contradictory statements or unrelated noise. No highly detailed specifics such as exact fields or conditional outputs are mentioned, so the gain is modest but positive with low noise."
            ]
        }
    }
}
{
    "source_code": "int\nrl_insert_text (const char *string)\n{\n  register int i, l;\n\n  l = (string && *string) ? strlen (string) : 0;\n  if (l == 0)\n    return 0;\n\n  if (rl_end + l >= rl_line_buffer_len)\n    rl_extend_line_buffer (rl_end + l);\n\n  for (i = rl_end; i >= rl_point; i--)\n    rl_line_buffer[i + l] = rl_line_buffer[i];\n\n  strncpy (rl_line_buffer + rl_point, string, l);\n\n  /* Remember how to undo this if we aren't undoing something. */\n  if (_rl_doing_an_undo == 0)\n    {\n      /* If possible and desirable, concatenate the undos. */\n      if ((l == 1) &&\n\t  rl_undo_list &&\n\t  (rl_undo_list->what == UNDO_INSERT) &&\n\t  (rl_undo_list->end == rl_point) &&\n\t  (rl_undo_list->end - rl_undo_list->start < 20))\n\trl_undo_list->end++;\n      else\n\trl_add_undo (UNDO_INSERT, rl_point, rl_point + l, (char *)NULL);\n    }\n  rl_point += l;\n  rl_end += l;\n  rl_line_buffer[rl_end] = '\\0';\n  return l;\n}",
    "comment": "Inserts a given string into a line buffer at a specified point, adjusting the buffer and managing undo operations accordingly.",
    "prorec_sum": "Inserts the given text into the readline buffer at the cursor position, shifting existing text, updating cursor/end indexes, and managing undo information.",
    "filter_prorec_sum": "Inserts the given text into the readline buffer at the cursor position, shifting existing content and recording undo information if enabled.",
    "prorec_aug_sum": "Inserts the given text at the current cursor position in the readline buffer, shifting existing contents and updating undo history and buffer metadata.",
    "filter_prorec_aug_sum": "Inserts the given text into the readline buffer at the current cursor position, shifting existing content and updating undo history and buffer length.",
    "work_score": {
        "prorec": {
            "summary": "Inserts the given text into the readline buffer at the cursor position, shifting existing text, updating cursor/end indexes, and managing undo information.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately states that the function inserts the given text into the readline buffer at the cursor position, shifts existing text, updates cursor and end indexes, and manages undo information. These behaviors are all present in the source code: insertion via strncpy at rl_point, shifting with the for loop, updating rl_point and rl_end, and handling undo state with rl_add_undo or adjusting rl_undo_list. All claims are directly supported by the code, with no inaccuracies or irrelevant content.",
                "The summary accurately reflects the core purpose of inserting text into the readline buffer at the cursor position, with correct mention of shifting existing text and updating cursor/end indexes. It also correctly notes undo management, aligning with the code\u2019s use of rl_add_undo and conditional undo concatenation. However, it omits details such as the buffer length check and extension via rl_extend_line_buffer, handling empty strings, and the specific return value behavior, making its secondary coverage incomplete.",
                "The summary contains accurate, specific details about the function: it correctly states that the given text is inserted at the cursor position, existing text is shifted, cursor/end indexes are updated, and undo information is managed. All these behaviors match the source code's logic, with no contradictions or irrelevant noise. The claims are precise and target key aspects of input processing, buffer manipulation, and undo handling, offering high informational value with negligible noise."
            ]
        },
        "filter_prorec": {
            "summary": "Inserts the given text into the readline buffer at the cursor position, shifting existing content and recording undo information if enabled.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately states that the function inserts the given text into the readline buffer at the cursor position, shifts existing content, and records undo information if enabled, all of which match the code's behavior. All claims are specific to the source code semantics and correctly reflect its functionality, resulting in a high proportion of accurate claims.",
                "The summary accurately states that the function inserts text into the readline buffer at the cursor position and shifts existing content, matching the core domain action. It also notes recording undo information if enabled, which aligns with the conditional undo recording logic in the code. However, it omits key secondary details such as handling buffer extension when needed, returning the length inserted, the special concatenation of single-character undos, and updating cursor/end positions explicitly. This results in partial coverage of secondary behaviors.",
                "The summary contains accurate statements: it correctly describes inserting the provided text into the readline buffer at the cursor position, the shifting of existing content, and the conditional recording of undo information. These map directly to the function\u2019s code, with no contradictions or noise. The claims are specific to the core behavior, giving high insight into its purpose and side effects."
            ]
        }
    }
}
{
    "source_code": "\nstatic int restore(struct ks *ks, char x[])\n{     int j, k, z;\n      z = ks->c0;\n      for (j = 1, k = 0; j <= ks->orig_n; j++)\n      {  if (ks->x[j] & 0x10)\n         {  k++;\n            xassert(k <= ks->n);\n            xassert(x[k] == 0 || x[k] == 1);\n            if (ks->x[j] & 1)\n               ks->x[j] = 1 - x[k];\n            else\n               ks->x[j] = x[k];\n            if (x[k])\n               z += ks->c[k];\n         }\n      }\n      xassert(k == ks->n);\n      return z;\n}",
    "comment": "Restores values in the `ks->x` array based on conditions and updates a sum `z` based on corresponding values from the `x` array.",
    "prorec_sum": "Iterates over flagged items in a structure, validates associated binary values, flips bits if needed, updates sum accordingly, and returns the total.",
    "filter_prorec_sum": "Updates item flags and accumulates a total value from selected binary entries, enforcing consistency checks on selection count and boolean state.",
    "prorec_aug_sum": "Validates and updates a set of binary flags in a structure based on input values, enforcing constraints, and accumulates a corresponding weighted sum.",
    "filter_prorec_aug_sum": "Validates and updates knapsack solution variables, enforcing binary constraints and summing selected item weights before returning the total weight.",
    "work_score": {
        "prorec": {
            "summary": "Iterates over flagged items in a structure, validates associated binary values, flips bits if needed, updates sum accordingly, and returns the total.",
            "score": [
                0.9,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly describes the iteration over flagged items (using a specific bitmask), the validation of binary values, conditional flipping of bits, updating a sum based on values, and returning the total, all of which match the source code's logic. No contradictory or irrelevant claims are present, and all statements are grounded in the function\u2019s actual behavior, indicating high precision.",
                "The summary correctly captures the core domain purpose: iterating over elements flagged by a specific bit in a structure, validating they are binary, conditionally flipping the bit, and updating a running sum, which matches the code's operations. It also mentions returning the total, covering the output behavior. However, it lacks some specifics, such as the starting sum from `ks->c0`, the precise flag values checked, and the final assertion that all items were processed. These omissions mean secondary coverage of constants and edge checks is incomplete.",
                "The summary correctly captures the core behavior: iterating over flagged elements (`ks->x[j] & 0x10`), validating that `x[k]` is binary, conditionally flipping bits (`1 - x[k]`), and updating a sum `z` based on values in `x`. It omits some specifics (e.g., bitmask check details, assertion of final count `k == ks->n`) but contains no incorrect statements. The claims are mostly accurate and aligned with the source code semantics, though phrased generically, resulting in moderate informational gain and low noise."
            ]
        },
        "filter_prorec": {
            "summary": "Updates item flags and accumulates a total value from selected binary entries, enforcing consistency checks on selection count and boolean state.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly captures key semantics: the function iterates over selected entries based on a flag, updates values accordingly, accumulates a total from binary entries, and includes consistency checks on selection count and boolean state. These align with the source code\u2019s behavior of checking flags, toggling or setting ks->x[j], summing values from ks->c[], and asserting constraints, indicating high accuracy with no contradictory or irrelevant claims.",
                "The summary correctly describes updating certain entries based on a selection criterion and accumulating a total value, along with performing checks on selection count and boolean state, which aligns with the core code behavior. It effectively covers the primary purpose\u2014restoring state for flagged elements and adjusting the accumulator\u2014and includes mention of the consistency checks. However, it omits finer specifics like the inversion of binary values when a particular bit is set, the exact mechanism for identifying selected entries using bitmasks, and the final assertion ensuring full selection coverage, leaving secondary details incomplete.",
                "The summary correctly states that the function updates item flags (ks->x[j]) based on binary input x[k], accumulates a total (z) from selected entries, and enforces consistency checks on selection count and boolean values via xassert. These match the code\u2019s semantics for iterating over flagged items, toggling or copying values, and summing c[k] when x[k] is true. There are no incorrect claims, and the coverage of purpose and side effects is accurate and fairly specific, though some details (like the conditional inversion logic and starting value from ks->c0) are omitted, making the gain solid but not maximal."
            ]
        }
    }
}
{
    "source_code": "\nconst ProtobufCFieldDescriptor *\nprotobuf_c_message_descriptor_get_field_by_name(const ProtobufCMessageDescriptor *desc,\n\t\t\t\t\t\tconst char *name)\n{\n\tunsigned start = 0;\n\tunsigned count;\n\tconst ProtobufCFieldDescriptor *field;\n\n\tif (desc == NULL || desc->fields_sorted_by_name == NULL)\n\t\treturn NULL;\n\n\tcount = desc->n_fields;\n\n\twhile (count > 1) {\n\t\tunsigned mid = start + count / 2;\n\t\tint rv;\n\t\tfield = desc->fields + desc->fields_sorted_by_name[mid];\n\t\trv = strcmp(field->name, name);\n\t\tif (rv == 0)\n\t\t\treturn field;\n\t\telse if (rv < 0) {\n\t\t\tcount = start + count - (mid + 1);\n\t\t\tstart = mid + 1;\n\t\t} else\n\t\t\tcount = mid - start;\n\t}\n\tif (count == 0)\n\t\treturn NULL;\n\tfield = desc->fields + desc->fields_sorted_by_name[start];\n\tif (strcmp(field->name, name) == 0)\n\t\treturn field;\n\treturn NULL;\n}",
    "comment": "Retrieves the field descriptor with a matching name from a sorted list of fields in a ProtobufC message descriptor.",
    "prorec_sum": "Searches an indexed array for an entry meeting criteria and returns a pointer to its associated 72\u2011byte structure, or zero if none match.",
    "filter_prorec_sum": "Searches an index array for the first entry with a zero status code and returns a pointer to its associated 72\u2011byte structure.",
    "prorec_aug_sum": "Performs a binary search over an index array to locate and return the associated 72-byte entry with a zero key field.",
    "filter_prorec_aug_sum": "Performs a binary search over an index array to locate and return the matching 72\u2011byte entry when its key multiplied by nine equals zero.",
    "work_score": {
        "prorec": {
            "summary": "Searches an indexed array for an entry meeting criteria and returns a pointer to its associated 72\u2011byte structure, or zero if none match.",
            "score": [
                0.6,
                0.2,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function searches an indexed array for an entry matching criteria and returns a pointer or NULL if none match, aligning with the binary search over 'fields_sorted_by_name'. However, the claim that it returns a pointer to a 72\u2011byte structure is inaccurate, as the source code makes no mention of the structure's size. This incorrect detail reduces the overall precision, resulting in mixed reliability.",
                "The summary states that it searches an indexed array for a matching entry and returns a pointer or zero, which vaguely aligns with the code\u2019s binary search for a field name in a sorted array. However, it fails to cover the core domain purpose of retrieving a ProtobufCFieldDescriptor by name from a ProtobufCMessageDescriptor. It introduces an inaccurate detail about a 72\u2011byte structure, which is unsupported by the source code, and omits critical specifics like string comparison, null checks, and the Protobuf context.",
                "The summary correctly notes that the function searches an indexed array and returns a pointer if a match is found or NULL otherwise, aligning with the code\u2019s binary search over sorted field names. However, it inaccurately specifies the size of the structure as 72 bytes, which is not evident or guaranteed by the source code. This is a FATAL error on a key I/O detail (nature of the returned pointer\u2019s target), undermining trust in the description despite otherwise accurate behavior notes."
            ]
        },
        "filter_prorec": {
            "summary": "Searches an index array for the first entry with a zero status code and returns a pointer to its associated 72\u2011byte structure.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary's claims about searching for an entry with a zero status code and returning a pointer to a 72\u2011byte structure are entirely inaccurate. The source code actually performs a binary search for a field by matching its name string in a sorted array of field indices. No status codes or fixed-size structures are involved, and there is no mention of a 72\u2011byte size. All claims fail to match the code's semantics, resulting in 0% accuracy.",
                "The summary's core claim about searching an index array for a zero status code and returning a 72\u2011byte structure is entirely inaccurate: the function actually performs a binary search over a sorted index of field names within a Protobuf message descriptor and returns a pointer to the matching field descriptor if found. The summary fails to mention the primary purpose, does not cover the real search key (string name) or data structures involved, and introduces incorrect details such as status codes and structure size. No accurate claims remain to cover the core functionality.",
                "The summary contains a severe factual error about the primary purpose: it claims the function searches for the first entry with a zero status code and returns a 72\u2011byte structure, while the source code actually performs a binary search in a sorted name index to find a field descriptor matching a given name. This contradicts the core semantics of what the function does and misrepresents key inputs and outputs, making the description unusable."
            ]
        }
    }
}
{
    "source_code": "\nvoid\npkl_asm_for (pkl_asm pasm, pkl_ast_node head)\n{\n  pkl_asm_pushlevel (pasm, PKL_ASM_ENV_FOR_LOOP);\n\n  pasm->level->node1 = ASTREF (head);\n  pasm->level->label1 = pvm_program_fresh_label (pasm->program);\n  pasm->level->label2 = pvm_program_fresh_label (pasm->program);\n  pasm->level->label3 = pvm_program_fresh_label (pasm->program);\n  pasm->level->continue_label = pvm_program_fresh_label (pasm->program);\n  pasm->level->break_label = pvm_program_fresh_label (pasm->program);\n\n  if (head)\n    pkl_asm_insn (pasm, PKL_INSN_PUSHF, 0);\n}",
    "comment": "Initializes a for loop's environment in the assembly context, assigning labels and pushing the loop node if a valid head is provided.",
    "prorec_sum": "Initializes a node\u2019s metadata fields from a related object and triggers an additional processing step when a secondary reference is provided.",
    "filter_prorec_sum": "Initializes a node\u2019s fields from repeated computed values, links it to a given object, updates counters, and triggers a follow\u2011up processing routine.",
    "prorec_aug_sum": "Initializes a data structure with repeated computed values, links it to an optional object, and triggers further processing if that object is present.",
    "filter_prorec_aug_sum": "Initializes a data structure with repeated identifier values from a related object, links it to a secondary object, and triggers further processing if present.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a node\u2019s metadata fields from a related object and triggers an additional processing step when a secondary reference is provided.",
            "score": [
                0.2,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about initializing a node\u2019s metadata from a related object and triggering extra processing when a secondary reference exists do not match the code\u2019s specific behavior. The function pushes a new loop level, sets multiple label fields and a node reference in the assembler state, and conditionally inserts an instruction if `head` is non-null. The description omits key loop and label details and introduces the concept of a 'secondary reference', which is not present, making the claims inaccurate overall.",
                "The summary does not accurately describe the core purpose of the function, which is to set up a new assembler level for a 'for' loop, initializing labels and optionally emitting a push instruction if a loop head node is provided. The claims about initializing a node\u2019s metadata from a related object and triggering processing on a secondary reference are generic and misaligned with the source code semantics, failing to cover the specific domain action or any key secondary details.",
                "The summary contains an inaccurate core description of the function\u2019s primary purpose. The source code shows that the function pushes a FOR loop level onto the assembler stack, sets multiple labels (label1, label2, label3, continue_label, break_label) based on fresh labels from the program, and pushes a frame if `head` is provided. The summary instead describes initializing a node\u2019s metadata from a related object and an extra step when a secondary reference is present, which is both misleading and unrelated to the actual loop setup process. This constitutes a FATAL error on the primary purpose, making the description unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a node\u2019s fields from repeated computed values, links it to a given object, updates counters, and triggers a follow\u2011up processing routine.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary's claims about updating counters and linking a node to a given object are not supported by the source code, which instead pushes an assembler loop level, assigns multiple label fields from fresh label calls, sets node1 from the head, and conditionally pushes an instruction. No counter updates are present, and 'repeated computed values' and 'follow\u2011up processing routine' misrepresent the code's actual semantics. Almost none of the claims extracted from the summary align accurately with the source behavior, resulting in a very low accuracy rate.",
                "The summary fails to capture the core purpose of setting up a for-loop environment in the assembler context, including generating specific labels for loop control and optionally inserting a push-frame instruction. Its claims about repeated computed values, linking, and counters are inaccurate relative to the source code semantics, leading to complete omission of the core domain operation and other key behaviors.",
                "The summary's claims about initializing a node's fields and linking it to a given object are loosely related to the code, but most details are inaccurate: there is no repeated computed values initialization in the described way, no counter updates, and the follow\u2011up routine described does not match `pkl_asm_insn` usage. These statements misrepresent the core behavior of setting up loop labels and environment, making them FATAL errors about the function\u2019s primary purpose. The net benefit is negative because the summary fails to convey the core domain action correctly."
            ]
        }
    }
}
{
    "source_code": "BITCODE_BL\ndwg_object_polyline_2d_get_numpoints (const dwg_object *restrict obj,\n                                      int *restrict error)\n{\n  if (obj && obj->type == DWG_TYPE_POLYLINE_2D)\n    {\n      BITCODE_BL num_points = 0;\n      Dwg_Data *dwg = obj->parent;\n      Dwg_Entity_POLYLINE_2D *_obj = obj->tio.entity->tio.POLYLINE_2D;\n      Dwg_Entity_VERTEX_2D *vertex;\n      *error = 0;\n\n      if (dwg->header.version >= R_2004)\n        return obj->tio.entity->tio.POLYLINE_2D->num_owned;\n      // iterate over first_vertex - last_vertex\n      else if (dwg->header.version >= R_13)\n        {\n          Dwg_Object *vobj = dwg_ref_object (dwg, _obj->first_vertex);\n          Dwg_Object *vlast = dwg_ref_object (dwg, _obj->last_vertex);\n          if (!vobj)\n            *error = 1;\n          else\n            {\n              do\n                {\n                  if ((vertex = dwg_object_to_VERTEX_2D (vobj)))\n                    {\n                      num_points++;\n                    }\n                  else\n                    {\n                      *error = 1; // return not all vertices, but some\n                    }\n                }\n              while ((vobj = dwg_next_object (vobj)) && vobj != vlast);\n            }\n        }\n      else // <r13: iterate over vertices until seqend\n        {\n          Dwg_Object *vobj;\n          while ((vobj = dwg_next_object (obj))\n                 && vobj->type != DWG_TYPE_SEQEND)\n            {\n              if ((vertex = dwg_object_to_VERTEX_2D (vobj)))\n                num_points++;\n              else\n                *error = 1; // return not all vertices, but some\n            }\n        }\n      return num_points;\n    }\n  else\n    {\n      LOG_ERROR (\"%s: empty or wrong arg\", __FUNCTION__)\n      *error = 1;\n      return 0L;\n    }\n}",
    "comment": "Counts the number of 2D vertices in a polyline object based on DWG version and returns the count or an error code.",
    "prorec_sum": "Counts the number of 2D vertex objects in a polyline entity, returning an error flag if invalid types or object structure are encountered.",
    "filter_prorec_sum": "Counts the number of 2D vertex objects in a polyline entity, validating object types and reporting errors for invalid input or structure.",
    "prorec_aug_sum": "Retrieves the number of 2D vertex points in a DWG polyline object and reports an error status if the object is invalid.",
    "filter_prorec_aug_sum": "Counts the number of 2D vertex objects in a polyline entity, returning errors for invalid input or non-vertex elements.",
    "work_score": {
        "prorec": {
            "summary": "Counts the number of 2D vertex objects in a polyline entity, returning an error flag if invalid types or object structure are encountered.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly describes that the function counts 2D vertex objects in a polyline and sets an error flag when encountering invalid object types or structure. These claims align with the source code's logic for verifying object type, handling vertex counting across DWG versions, and setting error codes. While the summary is accurate, it is somewhat generic and omits specific version-dependent behavior, loops, and iteration conditions, but the core semantic behavior is well captured.",
                "The summary correctly identifies the core purpose as counting 2D vertices in a polyline entity and mentions error flagging on invalid inputs, aligning with the function\u2019s behavior for type checking and vertex iteration. However, it omits key secondary details such as version-specific handling (R_2004, R_13, <R_13) and the distinct iteration logic for different DWG versions. It also does not mention partial vertex retrieval errors or specific branching conditions, limiting completeness.",
                "The summary correctly states the primary purpose of the function: counting 2D vertices in a polyline entity and setting an error flag when encountering invalid types or structure. This aligns with the code\u2019s behavior across different DWG version branches and the error handling logic. There are no inaccurate or irrelevant claims, but the description remains generic and lacks specifics like version-dependent handling or iteration mechanisms, which limits its informational value."
            ]
        },
        "filter_prorec": {
            "summary": "Counts the number of 2D vertex objects in a polyline entity, validating object types and reporting errors for invalid input or structure.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function counts the number of 2D vertex objects in a 2D polyline entity and handles error reporting for invalid input or structure, both of which are evidenced in the source. It slightly omits version-dependent logic (R_2004, R_13) but otherwise aligns closely with the function\u2019s core semantics, making it highly accurate aside from minor detail omission.",
                "The summary accurately identifies the core purpose as counting the number of 2D vertex objects in a polyline entity and notes validation of object types and error reporting, which aligns with the function's primary operation. However, it omits important secondary details such as version-dependent logic paths (R_2004 vs R_13 vs earlier), specific iteration mechanisms, and partial vertex count behavior when errors occur. These omissions reduce coverage of key branching and edge-case semantics present in the source code.",
                "The summary accurately describes the primary purpose of the function \u2014 counting 2D vertex objects for a polyline and reporting errors for invalid inputs \u2014 which matches the core domain behavior in the source code. It omits specific implementation details such as version-dependent handling (R_2004, R_13, <R_13) and iteration methods, but contains no contradictory or irrelevant claims. The gain is modest due to generic phrasing and lack of version-specific nuance, but noise is minimal."
            ]
        }
    }
}
{
    "source_code": "int ed_main(int argc UNUSED_PARAM, char **argv)\n{\n\tINIT_G();\n\n\tbufSize = INITBUF_SIZE;\n\tbufBase = xmalloc(bufSize);\n\tbufPtr = bufBase;\n\tlines.next = &lines;\n\tlines.prev = &lines;\n\n\tif (argv[1]) {\n\t\tfileName = xstrdup(argv[1]);\n\t\tif (!readLines(fileName, 1)) {\n\t\t\treturn EXIT_SUCCESS;\n\t\t}\n\t\tif (lastNum)\n\t\t\tsetCurNum(1);\n\t\tdirty = FALSE;\n\t}\n\n\tdoCommands();\n\treturn EXIT_SUCCESS;\n}",
    "comment": "Initializes a buffer, reads lines from a specified file if provided, and then executes commands in a loop.",
    "prorec_sum": "Initializes a data structure with provided parameters, links related resources, validates them, and performs final setup or cleanup before returning.",
    "filter_prorec_sum": "Initializes a data structure with provided parameters, performs conditional validation and processing, and finalizes state updates before exiting.",
    "prorec_aug_sum": "Initializes and configures a 1024\u2011byte structure with service data, validates it, invokes setup routines, and finalizes state based on provided parameters.",
    "filter_prorec_aug_sum": "Initializes a 1024\u2011byte structure, sets up internal buffers and pointers from provided parameters, validates a resource, and finalizes with a cleanup call.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a data structure with provided parameters, links related resources, validates them, and performs final setup or cleanup before returning.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is overly generic and lacks specific, verifiable claims related to the source code's actual behavior. It omits details such as allocation of buffers, setting linked list pointers, reading lines from a file, and executing commands, instead using vague terms like 'links related resources' and 'validates them'. Most claims do not accurately target the code semantics, leading to a low proportion of accurate statements.",
                "The summary mentions generic initialization and cleanup but fails to accurately reflect the core purpose of 'ed_main', which is to initialize editor buffers and state, optionally load a file into memory, and run command processing. The claims are too vague\u2014there\u2019s no mention of buffer allocation, file reading, or executing commands\u2014though the idea of setup loosely aligns with initialization semantics. Overall, the core operation and specific behaviors are not covered.",
                "The summary makes generic claims about initialization, linking resources, validation, and final setup/cleanup without specifying the actual behavior of ed_main, which initializes buffers, sets up linked list pointers, optionally loads a file, sets current line number, marks dirty flag, and runs commands. These generic statements are mostly NOISE with no specific GOLD-level insight, and while not outright incorrect, they omit key I/O and domain-specific details, resulting in low gain."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a data structure with provided parameters, performs conditional validation and processing, and finalizes state updates before exiting.",
            "score": [
                0.3,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is overly generic and lacks specific, verifiable details from the source code. While it hints at initialization, conditional processing, and finalization before exit, it does not mention concrete elements such as buffer allocation, linked list setup, filename handling, or the doCommands call. The claims target the general idea of the code but do not align strongly with the function\u2019s clear, specific semantics, leading to a low proportion of accurate claims.",
                "The summary provides only generic statements about initialization, validation, processing, and state updates without accurately capturing the core purpose of the function, which is to set up buffers and linked list pointers, optionally load lines from a file specified as argv[1], adjust the current line number, mark the buffer clean, and then execute commands. It omits specific domain actions like allocating memory, reading lines from a file, handling empty results, and invoking the command loop, resulting in the core purpose not being covered and missing all critical secondary details.",
                "The summary contains mostly generic descriptions and omits key specifics visible in the source code, such as buffer allocation, file reading from argv[1], conditional cursor setting, and calling doCommands. The claims are SAFE but low-info, with no FATAL inaccuracies. Noise outweighs detailed insights, offering little help in understanding the actual function behavior."
            ]
        }
    }
}
{
    "source_code": "\nstatic void\nmpn_dcpi1_bdiv_q_n (mp_ptr qp,\n\t\t    mp_ptr np, mp_srcptr dp, mp_size_t n,\n\t\t    mp_limb_t dinv, mp_ptr tp)\n{\n  while (ABOVE_THRESHOLD (n, DC_BDIV_Q_THRESHOLD))\n    {\n      mp_size_t lo, hi;\n      mp_limb_t cy;\n\n      lo = n >> 1;\t\t\t/* floor(n/2) */\n      hi = n - lo;\t\t\t/* ceil(n/2) */\n\n      cy = mpn_dcpi1_bdiv_qr_n (qp, np, dp, lo, dinv, tp);\n\n      mpn_mullo_n (tp, qp, dp + hi, lo);\n      mpn_add_n (np + hi, np + hi, tp, lo);\n\n      if (lo < hi)\n\t{\n\t  cy += mpn_addmul_1 (np + lo, qp, lo, dp[lo]);\n\t  np[n - 1] += cy;\n\t}\n      qp += lo;\n      np += lo;\n      n -= lo;\n    }\n  mpn_sbpi1_bdiv_q (qp, np, n, dp, n, dinv);\n}",
    "comment": "Divides a multi-precision number by another using a divide-and-conquer approach, updating quotient and remainder for large input sizes.",
    "prorec_sum": "Performs large integer division using GMP\u2019s divide-and-conquer and base-case algorithms, updating partial results with multiplication and addition steps.",
    "filter_prorec_sum": "Performs multi-precision division using divide-and-conquer and small-block algorithms with GMP low-level `mpn` functions.",
    "prorec_aug_sum": "Performs multi-precision division using divide-and-conquer and schoolbook algorithms, producing the quotient from high and low parts of large integer operands.",
    "filter_prorec_aug_sum": "Performs multi-limb division using divide-and-conquer algorithms and GMP low-level routines, yielding the quotient from large integer operands.",
    "work_score": {
        "prorec": {
            "summary": "Performs large integer division using GMP\u2019s divide-and-conquer and base-case algorithms, updating partial results with multiplication and addition steps.",
            "score": [
                1.0,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly identifies that the function performs division on large integers using GMP\u2019s divide-and-conquer approach and a base-case algorithm, which matches the code\u2019s use of ABOVE_THRESHOLD branching to mpn_dcpi1_bdiv_qr_n and the final mpn_sbpi1_bdiv_q call. It also accurately notes multiplication and addition steps present in mpn_mullo_n and mpn_add_n. All claims are specific to the code\u2019s semantics and align with the implementation, with no inaccuracies found.",
                "The summary correctly identifies that the function performs large integer division using GMP\u2019s divide-and-conquer and base-case methods, which matches the core purpose of the source. However, it lacks accuracy on several secondary semantics: it omits thresholds controlling algorithm choice, the splitting of operands, carry handling, and the invocation of specific helper functions for partial results. These omissions limit coverage beyond the core purpose.",
                "The summary correctly identifies that the function performs large integer division using GMP\u2019s divide-and-conquer and base-case algorithms, which matches the loop using ABOVE_THRESHOLD with mpn_dcpi1_bdiv_qr_n and mpn_sbpi1_bdiv_q. It also notes updating partial results via multiplication and addition, consistent with mpn_mullo_n and mpn_add_n calls. While accurate, the description is high-level and omits specifics about operand partitioning, carry handling, and multi-limb data management, so the informational gain is modest. No inaccurate or contradictory claims are present, and noise is minimal."
            ]
        },
        "filter_prorec": {
            "summary": "Performs multi-precision division using divide-and-conquer and small-block algorithms with GMP low-level `mpn` functions.",
            "score": [
                0.9,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly identifies that the function performs multi-precision division using GMP's low-level mpn functions, and notes its use of divide-and-conquer and small-block algorithms, both of which are evident from the loop structure with ABOVE_THRESHOLD and the final call to mpn_sbpi1_bdiv_q. While brief, the claim aligns well with the source code's behavior and contains no inaccuracies, making the majority of extracted claims accurate.",
                "The summary correctly identifies that the function performs multi-precision division using GMP low-level `mpn` functions, and notes the use of divide-and-conquer alongside small-block algorithms, which matches the core purpose of recursively dividing large operands until below a threshold and then applying a smaller block division. However, it lacks coverage of secondary details like threshold checking, operand splitting, intermediate multiplication and addition steps, carry handling, and pointer/size adjustments, making the coverage of behavior-critical semantics incomplete.",
                "The summary correctly identifies that the function performs multi-precision division using a combination of divide-and-conquer and small-block approaches, which matches the code's use of a loop splitting n into halves with mpn_dcpi1_bdiv_qr_n for large sizes and mpn_sbpi1_bdiv_q for smaller sizes. It is accurate but generic, lacking specific details on parameters, intermediate operations, or side effects. No inaccurate claims are present, but the gain is low due to the high-level and broad nature of the description."
            ]
        }
    }
}
{
    "source_code": "\nstatic int create_dir(struct kobject *kobj, struct sysfs_dirent *parent_sd,\n\tenum kobj_ns_type type, const void *ns, const char *name,\n\tstruct sysfs_dirent **p_sd)\n{\n\tumode_t mode = S_IFDIR| S_IRWXU | S_IRUGO | S_IXUGO;\n\tstruct sysfs_addrm_cxt acxt;\n\tstruct sysfs_dirent *sd;\n\tint rc;\n\n\t/* allocate */\n\tsd = sysfs_new_dirent(name, mode, SYSFS_DIR);\n\tif (!sd)\n\t\treturn -ENOMEM;\n\n\tsd->s_flags |= (type << SYSFS_NS_TYPE_SHIFT);\n\tsd->s_ns = ns;\n\tsd->s_dir.kobj = kobj;\n\n\t/* link in */\n\tsysfs_addrm_start(&acxt, parent_sd);\n\trc = sysfs_add_one(&acxt, sd);\n\tsysfs_addrm_finish(&acxt);\n\n\tif (rc == 0)\n\t\t*p_sd = sd;\n\telse\n\t\tsysfs_put(sd);\n\n\treturn rc;\n}",
    "comment": "Creates a directory entry in a configuration filesystem, ensuring it does not already exist and managing reference counts for the parent directory.",
    "prorec_sum": "Allocates and initializes a filesystem-related structure with provided parameters, invokes setup routines, and returns it through an output pointer or cleans up on failure.",
    "filter_prorec_sum": "Allocates and initializes a structure with provided parameters, invokes two setup routines, and either returns it via output pointer or cleans it up on error.",
    "prorec_aug_sum": "Allocates and initializes a filesystem structure with provided parameters, performs setup routines, and returns it via output pointer or an error code.",
    "filter_prorec_aug_sum": "Initializes a new structure with provided parameters, links it to inputs, performs setup routines, and returns it or cleans up on failure.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes a filesystem-related structure with provided parameters, invokes setup routines, and returns it through an output pointer or cleans up on failure.",
            "score": [
                0.9,
                0.2,
                0.7
            ],
            "reason": [
                "The summary correctly describes that the function allocates and initializes a filesystem-related structure using provided parameters, runs setup routines, and either assigns it to an output pointer or cleans up on failure. These align with the code's behavior: allocation via sysfs_new_dirent, initialization of fields, linking operations, and conditional cleanup. The claims are accurate and grounded in the code's semantics, with no contradictions or irrelevant statements.",
                "The summary correctly notes allocation, initialization, use of provided parameters, returning via an output pointer, and cleanup on failure, matching some source code behaviors. However, it omits the core domain-specific purpose: creating and linking a sysfs directory entry under a parent in the kernel\u2019s sysfs. Without mentioning the specific sysfs directory creation and namespace/type setup, the core is not covered, resulting in only generic coverage of operations.",
                "The summary correctly captures key aspects of the function: it allocates and initializes a sysfs directory entry, uses provided parameters, performs setup via helper routines, returns it through an output pointer on success, and cleans up on failure. All claims are accurate and correspond to the source code\u2019s semantics, with no contradictory or irrelevant content. However, the description is somewhat generic and lacks specific, domain-relevant details such as the exact mode bits, namespace handling, and kobject linkage, which would provide higher informational gain."
            ]
        },
        "filter_prorec": {
            "summary": "Allocates and initializes a structure with provided parameters, invokes two setup routines, and either returns it via output pointer or cleans it up on error.",
            "score": [
                0.9,
                0.2,
                0.5
            ],
            "reason": [
                "The summary correctly describes allocation of a structure with provided parameters, initialization, the use of two setup-related functions, and returning it via an output pointer or cleanup on error. These elements match the source code: allocation via sysfs_new_dirent, initialization of fields, calls to sysfs_addrm_start/sysfs_addrm_finish, and conditional cleanup. No contradictory or irrelevant claims are present, but the summary is somewhat general and omits specific identifiers, making it a safe but accurate description.",
                "The summary generically describes allocation, initialization, setup invocation, return or cleanup, but it omits the core purpose: creating and linking a sysfs directory entry with specific mode and namespace data under a parent. This means the primary domain-specific action is not covered. While there is some accurate generic detail on allocation, initialization, and error handling, the summary lacks mention of sysfs-specific operations, constants, and interactions with kobject/parent_sd, resulting in very incomplete coverage.",
                "The summary contains mostly accurate but generic statements about allocation, initialization, invoking two routines, and returning via output pointer or cleanup on error. It omits key specifics from the source such as the directory mode flags, use of sysfs-specific functions, and namespace/type assignments. There are no clear inaccuracies, but the lack of detailed, domain-specific information results in low gain and minimal insight beyond broad boilerplate behavior."
            ]
        }
    }
}
{
    "source_code": "acpi_status acpi_unload_parent_table(acpi_handle object)\n{\n\tstruct acpi_namespace_node *node =\n\t    ACPI_CAST_PTR(struct acpi_namespace_node, object);\n\tacpi_status status = AE_NOT_EXIST;\n\tacpi_owner_id owner_id;\n\tu32 i;\n\n\tACPI_FUNCTION_TRACE(acpi_unload_parent_table);\n\n\t/* Parameter validation */\n\n\tif (!object) {\n\t\treturn_ACPI_STATUS(AE_BAD_PARAMETER);\n\t}\n\n\t/*\n\t * The node owner_id is currently the same as the parent table ID.\n\t * However, this could change in the future.\n\t */\n\towner_id = node->owner_id;\n\tif (!owner_id) {\n\n\t\t/* owner_id==0 means DSDT is the owner. DSDT cannot be unloaded */\n\n\t\treturn_ACPI_STATUS(AE_TYPE);\n\t}\n\n\t/* Must acquire the interpreter lock during this operation */\n\n\tstatus = acpi_ut_acquire_mutex(ACPI_MTX_INTERPRETER);\n\tif (ACPI_FAILURE(status)) {\n\t\treturn_ACPI_STATUS(status);\n\t}\n\n\t/* Find the table in the global table list */\n\n\tfor (i = 0; i < acpi_gbl_root_table_list.current_table_count; i++) {\n\t\tif (owner_id != acpi_gbl_root_table_list.tables[i].owner_id) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Allow unload of SSDT and OEMx tables only. Do not allow unload\n\t\t * of the DSDT. No other types of tables should get here, since\n\t\t * only these types can contain AML and thus are the only types\n\t\t * that can create namespace objects.\n\t\t */\n\t\tif (ACPI_COMPARE_NAME\n\t\t    (acpi_gbl_root_table_list.tables[i].signature.ascii,\n\t\t     ACPI_SIG_DSDT)) {\n\t\t\tstatus = AE_TYPE;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Ensure the table is actually loaded */\n\n\t\tif (!acpi_tb_is_table_loaded(i)) {\n\t\t\tstatus = AE_NOT_EXIST;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Invoke table handler if present */\n\n\t\tif (acpi_gbl_table_handler) {\n\t\t\t(void)acpi_gbl_table_handler(ACPI_TABLE_EVENT_UNLOAD,\n\t\t\t\t\t\t     acpi_gbl_root_table_list.\n\t\t\t\t\t\t     tables[i].pointer,\n\t\t\t\t\t\t     acpi_gbl_table_handler_context);\n\t\t}\n\n\t\t/*\n\t\t * Delete all namespace objects owned by this table. Note that\n\t\t * these objects can appear anywhere in the namespace by virtue\n\t\t * of the AML \"Scope\" operator. Thus, we need to track ownership\n\t\t * by an ID, not simply a position within the hierarchy.\n\t\t */\n\t\tstatus = acpi_tb_delete_namespace_by_owner(i);\n\t\tif (ACPI_FAILURE(status)) {\n\t\t\tbreak;\n\t\t}\n\n\t\tstatus = acpi_tb_release_owner_id(i);\n\t\tacpi_tb_set_table_loaded_flag(i, FALSE);\n\t\tbreak;\n\t}\n\n\t(void)acpi_ut_release_mutex(ACPI_MTX_INTERPRETER);\n\treturn_ACPI_STATUS(status);\n}",
    "comment": "Unloads ACPI tables by deleting namespace objects and calling the table handler, ensuring conditions to prevent unloading the DSDT are met.",
    "prorec_sum": "Processes an ACPI table entry matching a specific identifier, invoking related handlers and executing associated operations with provided parameters.",
    "filter_prorec_sum": "Processes an ACPI table entry matching a given identifier and executes linked handler functions with specified parameters.",
    "prorec_aug_sum": "Processes an attribute identified by a key byte in a global table, optionally invoking callbacks and updating related data before final cleanup.",
    "filter_prorec_aug_sum": "Removes an extended attribute from a VXFS inode by matching its identifier, invoking callbacks, and updating related metadata structures.",
    "work_score": {
        "prorec": {
            "summary": "Processes an ACPI table entry matching a specific identifier, invoking related handlers and executing associated operations with provided parameters.",
            "score": [
                0.2,
                0.2,
                0.3
            ],
            "reason": [
                "The summary contains only a vague reference to processing an ACPI table entry with a matching identifier and related handler invocation, but omits multiple key behaviors such as parameter validation, mutex acquisition, restricted unload policies for specific table types (DSDT, SSDT, OEMx), checking whether the table is loaded, deleting namespace objects, and releasing ownership. This results in low alignment with the source code\u2019s semantics, as most critical and specific details are missing.",
                "The summary vaguely states that the function processes an ACPI table entry with a specific identifier and invokes handlers, but it does not accurately or specifically convey the core domain purpose \u2014 unloading the parent ACPI table associated with a namespace node, including restrictions for DSDT, lock acquisition, validation steps, and deletion of related namespace objects. The core operation and most critical behaviors are omitted, and the wording is too generic to match the source code\u2019s concrete semantics.",
                "The summary is overly vague and fails to accurately capture the function's core semantics, such as unloading only certain types of ACPI tables, disallowing DSDT unload, parameter validation, mutex acquisition, checking if loaded, and deleting namespace objects. Instead, it generically describes 'processing an ACPI table entry' without specifying the actual unloading logic or restrictions, which makes it mostly noise with minimal accurate information."
            ]
        },
        "filter_prorec": {
            "summary": "Processes an ACPI table entry matching a given identifier and executes linked handler functions with specified parameters.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary claims the function processes an ACPI table entry matching a given identifier and executes linked handler functions with specified parameters. While the code does involve matching an owner_id to find a table and may call a handler, the summary omits key behaviors such as parameter validation, restrictions on unloading certain table types (DSDT), locking requirements, and namespace deletion. It also oversimplifies the handler invocation and incorrectly implies that processing the table entry is the primary function rather than unloading it. The majority of claims are either incomplete or misleading, resulting in low precision.",
                "The summary vaguely states that the function processes an ACPI table entry by identifier and executes a handler, which only loosely matches part of the code\u2019s behavior. It omits the core purpose: unloading the parent ACPI table associated with a given namespace object, including restrictions (e.g., DSDT cannot be unloaded), validation, mutex acquisition, checking load state, deleting namespace objects, and releasing the owner ID. Several critical error handling and side effect steps are missing, and the description does not convey the specific unload semantics, resulting in failure to cover the core operation.",
                "The summary incorrectly states that the function processes an ACPI table entry matching a given identifier, omitting key logic like validation of object and owner_id, restrictions on unloading certain tables (DSDT), mutex acquisition, and namespace cleanup. It misrepresents the primary purpose by implying generic handler execution without capturing the core unload and cleanup semantics, making this a FATAL error on core functionality. No accurate or high-value details are present to offset the inaccuracy."
            ]
        }
    }
}
{
    "source_code": "int\n_rl_dispatch_callback (_rl_keyseq_cxt *cxt)\n{\n  int nkey, r;\n\n  /* For now */\n  /* The first time this context is used, we want to read input and dispatch\n     on it.  When traversing the chain of contexts back `up', we want to use\n     the value from the next context down.  We're simulating recursion using\n     a chain of contexts. */\n  if ((cxt->flags & KSEQ_DISPATCHED) == 0)\n    {\n      nkey = _rl_subseq_getchar (cxt->okey);\n      if (nkey < 0)\n\t{\n\t  _rl_abort_internal ();\n\t  return -1;\n\t}\n      r = _rl_dispatch_subseq (nkey, cxt->dmap, cxt->subseq_arg);\n      cxt->flags |= KSEQ_DISPATCHED;\n    }\n  else\n    r = cxt->childval;\n\n  /* For now */\n  if (r != -3)\t/* don't do this if we indicate there will be other matches */\n    r = _rl_subseq_result (r, cxt->oldmap, cxt->okey, (cxt->flags & KSEQ_SUBSEQ));\n\n  RL_CHECK_SIGNALS ();\n  /* We only treat values < 0 specially to simulate recursion. */\n  if (r >= 0 || (r == -1 && (cxt->flags & KSEQ_SUBSEQ) == 0))\t/* success! or failure! */\n    {\n      _rl_keyseq_chain_dispose ();\n      RL_UNSETSTATE (RL_STATE_MULTIKEY);\n      return r;\n    }\n\n  if (r != -3)\t\t\t/* magic value that says we added to the chain */\n    _rl_kscxt = cxt->ocxt;\n  if (_rl_kscxt)\n    _rl_kscxt->childval = r;\n  if (r != -3)\n    _rl_keyseq_cxt_dispose (cxt);\n\n  return r;\n}",
    "comment": "Handles key sequence input and dispatches actions based on the context, managing recursion through context chaining and returning results based on input validity.",
    "prorec_sum": "Processes a readline key input sequence, dispatches it to the appropriate handler, manages signal interruptions, and cleans up the key sequence context state.",
    "filter_prorec_sum": "Processes a readline key dispatch, executing associated actions, handling special return codes, and cleaning up or updating context while managing caught signals.",
    "prorec_aug_sum": "Handles a readline key sequence by dispatching its callback, processing results, managing signal handling, and freeing associated key sequence context structures.",
    "filter_prorec_aug_sum": "Processes a readline callback by dispatching subsequences, handling signals, managing context cleanup, and returning the resulting status code.",
    "work_score": {
        "prorec": {
            "summary": "Processes a readline key input sequence, dispatches it to the appropriate handler, manages signal interruptions, and cleans up the key sequence context state.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function processes a readline key input sequence, dispatches it to a handler, manages signals, and cleans up context state, all of which are supported by the source code. It omits finer details such as the simulated recursion via a chain of contexts, conditional handling for specific return values (-1, -3), and the specific sequence of operations, but the included claims are accurate. The majority of the claims target the code semantics and are correct.",
                "The summary correctly identifies that the function processes a readline key input sequence, dispatches it to a handler, handles signals, and disposes of key sequence context state, all of which are accurate reflections of the source code's operations. The core purpose\u2014dispatching a key sequence from the context\u2014is covered with suitable specificity. However, it omits several important secondary behaviors such as the simulation of recursion via context chaining, handling special magic return values (-3), aborting on input errors (<0 key values), and conditional cleanup based on flags. These omissions reduce completeness of the depiction.",
                "The summary is broadly correct in describing that the function processes a readline key sequence, dispatches to a handler, handles signals, and cleans up context state. These are SAFE and partially GOLD claims aligned with the source code. However, it omits specifics like the conditional flow for first-time vs. subsequent dispatch, special handling for values like -1 and -3, and recursion simulation via context chaining. There is no FATAL error, but the summary is generic with low detail, meaning gain is limited."
            ]
        },
        "filter_prorec": {
            "summary": "Processes a readline key dispatch, executing associated actions, handling special return codes, and cleaning up or updating context while managing caught signals.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly describes that the function processes a readline key dispatch, executes associated actions, handles special return codes, and manages context cleanup and updating while processing caught signals. These points align with the code\u2019s behavior: it retrieves a key, dispatches it, interprets specific return values like -3 and -1, disposes or updates the key sequence context appropriately, and calls RL_CHECK_SIGNALS. The claims are accurate but relatively high-level, with no clear factual errors, yielding a high proportion of accurate statements.",
                "The summary correctly identifies that the function dispatches a readline key, executes actions, interprets special return codes, and manages context cleanup and signals, aligning with the core purpose of reading an input key and dispatching subsequences in a simulated recursive context chain. However, it lacks specific details about key retrieval logic, flag checks for KSEQ_DISPATCHED and KSEQ_SUBSEQ, special handling for values like -1 and -3, and the chain disposal mechanics. The coverage of secondary behavior-critical semantics is thus incomplete.",
                "The summary is broadly accurate but lacks detail. It correctly notes that the function dispatches a key action, handles special return codes, updates/cleans context, and deals with signals. However, these are generic SAFE claims with little specificity\u2014there is no mention of the conditional logic for first-time vs. subsequent context use, the role of KSEQ_DISPATCHED/KSEQ_SUBSEQ flags, the recursion simulation via context chaining, or the exact handling of specific magic values (-3, -1). There are no FATAL inaccuracies, but the low-info nature limits positive gain, and noise is minimal."
            ]
        }
    }
}
{
    "source_code": "int burn_drive_obtain_scsi_adr(char *path,\n\t\t\t       int *bus_no, int *host_no, int *channel_no,\n\t\t\t       int *target_no, int *lun_no)\n{\n\tint ret, i;\n\tchar *adr = NULL;\n\n\tBURN_ALLOC_MEM(adr, char, BURN_DRIVE_ADR_LEN);\n\n\t/* open drives cannot be inquired by sg_obtain_scsi_adr() */\n\tfor (i = 0; i < drivetop + 1; i++) {\n\t\tif (drive_array[i].global_index < 0)\n\tcontinue;\n\t\tret = burn_drive_d_get_adr(&(drive_array[i]),adr);\n\t\tif (ret < 0)\n\t\t\t{ret = 1; goto ex;}\n\t\tif (ret == 0)\n\tcontinue;\n\t\tif (strcmp(adr, path) == 0) {\n\t\t\t*host_no = drive_array[i].host;\n\t\t\t*channel_no = drive_array[i].channel;\n\t\t\t*target_no = drive_array[i].id;\n\t\t\t*lun_no = drive_array[i].lun;\n\t\t\t*bus_no = drive_array[i].bus_no;\n\t\t\tif (*host_no < 0 || *channel_no < 0 ||\n\t\t\t    *target_no < 0 || *lun_no < 0)\n\t\t\t\t{ret = 0; goto ex;}\n\t\t\t{ret = 1; goto ex;}\n\t\t}\n\t}\n\n\tret = sg_obtain_scsi_adr(path, bus_no, host_no, channel_no,\n\t\t\t\t target_no, lun_no);\nex:;\n\tBURN_FREE_MEM(adr);\n\treturn ret;\n}",
    "comment": "Retrieves the SCSI address information for a specified drive path, utilizing both local and SCSI inquiry methods.",
    "prorec_sum": "Searches for a matching file entry by name in an ISO9660 directory structure and returns associated metadata through output parameters.",
    "filter_prorec_sum": "Searches an ISO9660 directory for a matching filename and returns its associated extent and metadata if found, otherwise falls back to alternative lookup.",
    "prorec_aug_sum": "Searches for a matching device entry by name, retrieves its stored parameters into provided variables, or delegates retrieval to an alternate routine if not found.",
    "filter_prorec_aug_sum": "Searches stored device entries for a matching name and returns associated parameters, or falls back to an alternate retrieval routine if none match.",
    "work_score": {
        "prorec": {
            "summary": "Searches for a matching file entry by name in an ISO9660 directory structure and returns associated metadata through output parameters.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The single claim in the summary states that the function searches for a matching file entry by name in an ISO9660 directory structure and returns associated metadata. This is entirely inaccurate based on the source code, which actually searches for a drive matching the given SCSI path and obtains its bus, host, channel, target, and LUN numbers. No mention of ISO9660 or directory structures exists in the code, meaning 0% of the claims are accurate.",
                "The summary incorrectly describes the function as dealing with ISO9660 directory structures and file metadata, while the source code clearly operates on drive_array entries to obtain SCSI address parameters for a given path or via sg_obtain_scsi_adr. The core purpose of mapping a path to its SCSI address components is entirely missing, and none of the factual claims in the summary align with the actual code semantics.",
                "The summary claims the function searches for a matching file entry in an ISO9660 directory and returns metadata. This is a severe contradiction of the source code, which actually searches for a drive with a matching SCSI address path and returns SCSI parameters. This represents a FATAL inaccuracy about the primary purpose and key I/O, making the description unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Searches an ISO9660 directory for a matching filename and returns its associated extent and metadata if found, otherwise falls back to alternative lookup.",
            "score": [
                0.0,
                0.0,
                0.1
            ],
            "reason": [
                "The summary claims the function searches an ISO9660 directory for a matching filename and returns extent and metadata, with a fallback to alternative lookup. None of these details match the source code, which obtains SCSI address information for a drive, comparing paths against drive descriptors and falling back to sg_obtain_scsi_adr if no match. All extracted claims are inaccurate as they target unrelated filesystem semantics rather than the actual drive/SCSI address retrieval logic.",
                "The summary claims describe searching an ISO9660 directory for a filename and returning associated extent and metadata, which does not match the source code's actual purpose of obtaining SCSI address information for a drive based on a given path. None of the fact-based claims align with the core domain operation or behavior in the code, resulting in a complete mismatch and no coverage of the primary purpose or secondary semantics.",
                "The summary claims the function searches an ISO9660 directory for a matching filename and returns extent and metadata, which directly contradicts the source code. The actual function attempts to obtain SCSI address information for a given device path, first by checking an internal drive array and then by calling sg_obtain_scsi_adr as a fallback. This is a severe factual error on the primary purpose, making the summary unusable."
            ]
        }
    }
}
{
    "source_code": "\nint\ncontext_init (char *str)\n{\n  mem_init ();\n  context = mem_alloc (sizeof (struct context));\n  context->num_pat = expr_init (str);\n  if (!context->num_pat)\n    return 0;\n\n  context->tmp = mem_alloc (sizeof (struct line) - sizeof (char[4])\n      + opt.context + 1);\n\n  if (!opt.out_quiet)\n    {\n      register int i, j, occurrences;\n      struct line **line;\n\n      context->lines = mem_alloc (context->num_pat\n\t  * sizeof (struct line **));\n      occurrences = opt.occurrences ? opt.occurrences : 1;\n\n      for (i = 0; i < context->num_pat; i++)\n\t{\n\t  line = mem_alloc (occurrences * sizeof (struct line *));\n\t  for (j = 0; j < occurrences; j++)\n\t    line[j] = mem_alloc (sizeof (struct line) - sizeof (char[4])\n\t\t+ opt.context + 1);\n\n\t  context->lines[i] = line;\n\t}\n    }\n\n  return context->num_pat;\n}",
    "comment": "Initializes the context structure, allocating memory for patterns and lines based on given input and options, and returns the number of patterns.",
    "prorec_sum": "Allocates and initializes nested field-related data structures based on input parameters and global configuration values.",
    "filter_prorec_sum": "Initializes a global field structure, allocates required buffers, and sets up nested arrays based on the provided parameter count and configuration flags.",
    "prorec_aug_sum": "Initializes a primary data structure and allocates nested arrays for each entry based on configuration flags and size parameters.",
    "filter_prorec_aug_sum": "Initializes global data structures by allocating and linking multiple memory blocks based on the given parameter and configuration flags.",
    "work_score": {
        "prorec": {
            "summary": "Allocates and initializes nested field-related data structures based on input parameters and global configuration values.",
            "score": [
                0.8,
                0.3,
                0.5
            ],
            "reason": [
                "The summary provides a generic description about allocation and initialization of data structures, which aligns with the observable behavior in the source code where multiple memory allocations occur based on input and configuration values. However, it lacks specificity about the nested structure layout, conditions, and the role of the global 'opt' configuration seen in the code. Since it is broadly accurate but low in detail, most of its single claim is correct but generic, making it safe but not highly distinguishing.",
                "The summary makes a generic statement about allocating and initializing data structures based on inputs and configuration, which is broadly accurate but lacks the specificity needed to cover the core primary purpose of initializing a context structure with patterns from a provided string and allocating related line buffers based on global options. It fails to mention the key domain-specific behavior of using expr_init to derive the number of patterns, conditional allocation tied to `opt.out_quiet`, or the nested allocation logic dependent on `opt.occurrences` and `opt.context` values.",
                "The summary makes a generic claim about allocating and initializing nested data structures based on input and global configuration, which is broadly accurate but lacks any specific detail on the function\u2019s domain purpose, key structures (`context`, `lines`, `tmp`), or control flow. There are no incorrect or contradictory statements, so no FATAL errors are present. However, the information gain is low because it omits explicit mention of how allocations depend on `num_pat`, `opt.out_quiet`, and other conditions, making it minimally useful beyond a generic observation."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a global field structure, allocates required buffers, and sets up nested arrays based on the provided parameter count and configuration flags.",
            "score": [
                0.8,
                0.4,
                0.2
            ],
            "reason": [
                "The summary correctly captures that the function initializes a global structure, allocates buffers, and creates nested arrays based on parameters and configuration flags, which aligns with the code's use of `mem_init`, `mem_alloc` calls, and branching on `opt.out_quiet`. However, it omits specific details such as returning `context->num_pat`, the conditions on allocation (`if (!context->num_pat)`), and the exact nature of nested allocations tied to occurrences and patterns. While mostly accurate, the lack of detailed matching to code semantics slightly reduces precision.",
                "The summary accurately notes initialization of a global structure and allocation of buffers based on parameters and configuration flags, aligning with the code\u2019s use of `context` and `mem_alloc`. However, it fails to specify the core purpose: initializing the `context` for pattern matching with `expr_init(str)` and returning the number of patterns. It omits key secondary details such as conditional allocation dependent on `opt.out_quiet`, handling of `opt.occurrences`, and the exact structure of the nested allocations, making coverage of critical semantics incomplete.",
                "The summary correctly captures that the function initializes a global structure and allocates buffers, and notes that nested arrays are set up based on configuration flags. However, it inaccurately refers to using a 'provided parameter count' rather than extracting the pattern count from expr_init(str), which is essential to the function's primary purpose. This misrepresentation of key input/output semantics is a core FATAL error, severely impacting reliability."
            ]
        }
    }
}
{
    "source_code": "\n\nu_char *\nngx_proxy_protocol_write(ngx_connection_t *c, u_char *buf, u_char *last)\n{\n    ngx_uint_t  port, lport;\n\n    if (last - buf < NGX_PROXY_PROTOCOL_MAX_HEADER) {\n        return NULL;\n    }\n\n    if (ngx_connection_local_sockaddr(c, NULL, 0) != NGX_OK) {\n        return NULL;\n    }\n\n    switch (c->sockaddr->sa_family) {\n\n    case AF_INET:\n        buf = ngx_cpymem(buf, \"PROXY TCP4 \", sizeof(\"PROXY TCP4 \") - 1);\n        break;\n\n#if (NGX_HAVE_INET6)\n    case AF_INET6:\n        buf = ngx_cpymem(buf, \"PROXY TCP6 \", sizeof(\"PROXY TCP6 \") - 1);\n        break;\n#endif\n\n    default:\n        return ngx_cpymem(buf, \"PROXY UNKNOWN\" CRLF,\n                          sizeof(\"PROXY UNKNOWN\" CRLF) - 1);\n    }\n\n    buf += ngx_sock_ntop(c->sockaddr, c->socklen, buf, last - buf, 0);\n\n    *buf++ = ' ';\n\n    buf += ngx_sock_ntop(c->local_sockaddr, c->local_socklen, buf, last - buf,\n                         0);\n\n    port = ngx_inet_get_port(c->sockaddr);\n    lport = ngx_inet_get_port(c->local_sockaddr);\n\n    return ngx_slprintf(buf, last, \" %ui %ui\" CRLF, port, lport);\n}",
    "comment": "Constructs and writes a PROXY protocol header, including client and server IP addresses and ports, to the provided buffer.",
    "prorec_sum": "Formats and writes a PROXY protocol line with source and destination addresses and ports into the provided buffer.",
    "filter_prorec_sum": "Formats and writes a PROXY protocol line with source and destination addresses and ports for TCP4, TCP6, or unknown connections.",
    "prorec_aug_sum": "Constructs and writes a PROXY protocol header with source and destination IP addresses and ports into the provided buffer.",
    "filter_prorec_aug_sum": "Constructs and writes a PROXY protocol header with source and destination IP addresses and ports for TCP4, TCP6, or UNKNOWN connections.",
    "work_score": {
        "prorec": {
            "summary": "Formats and writes a PROXY protocol line with source and destination addresses and ports into the provided buffer.",
            "score": [
                0.9,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function formats and writes a PROXY protocol line including source and destination addresses and ports into a buffer, matching the code's behavior. It omits minor details like handling of address families and buffer space checks, but does not introduce inaccuracies. This makes all claims accurate, with only slight lack of detail.",
                "The summary accurately describes the core purpose of constructing a PROXY protocol header line containing source and destination addresses and ports in the buffer, matching the code\u2019s logic. It captures the primary operation but omits secondary details such as handling IPv4/IPv6/UNKNOWN cases, buffer size checks, failure conditions returning NULL, and the use of specific helper functions for address and port formatting. The coverage of error handling and conditional branches is lacking, limiting completeness.",
                "The summary correctly states the core purpose of the function: it formats and writes a PROXY protocol header containing source and destination addresses and ports into a buffer. This matches the code\u2019s behavior, which selects the correct PROXY protocol prefix based on address family, appends both remote and local addresses, and writes their ports. There are no inaccurate or noisy claims, and the claim is specific to the function\u2019s primary purpose, though it is somewhat high-level without detailing conditional handling or format specifics."
            ]
        },
        "filter_prorec": {
            "summary": "Formats and writes a PROXY protocol line with source and destination addresses and ports for TCP4, TCP6, or unknown connections.",
            "score": [
                1.0,
                0.6,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function formats and writes a PROXY protocol line and includes source and destination addresses and ports. It also accurately covers the handling for TCP4, TCP6, and unknown connections, all of which are explicitly supported in the code. All claims target the actual code behavior and no inaccuracies are present, indicating a high degree of alignment.",
                "The summary accurately captures the core purpose of the function, which is to format and write a PROXY protocol header containing source and destination addresses and ports for TCP4, TCP6, or unknown connections. This matches the code\u2019s domain-specific behavior. However, it omits several secondary details such as buffer size checks, retrieval of local socket address, and handling of failure cases via NULL returns, which limits coverage of critical edge cases and conditions.",
                "The summary correctly states the primary purpose of the function: it formats and writes a PROXY protocol header including source and destination addresses and ports, with variations for TCP4, TCP6, and unknown connections. This aligns with the code\u2019s behavior. There are no inaccurate claims and no evident noise; the description is concise and targets core semantics. However, the level of detail is moderate\u2014while accurate, it lacks mention of conditions like buffer size checks and connection address retrieval, which would enhance specificity."
            ]
        }
    }
}
{
    "source_code": "\nint ext4_write_inline_data_end(struct inode *inode, loff_t pos, unsigned len,\n\t\t\t       unsigned copied, struct page *page)\n{\n\tint ret;\n\tvoid *kaddr;\n\tstruct ext4_iloc iloc;\n\n\tif (unlikely(copied < len)) {\n\t\tif (!PageUptodate(page)) {\n\t\t\tcopied = 0;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = ext4_get_inode_loc(inode, &iloc);\n\tif (ret) {\n\t\text4_std_error(inode->i_sb, ret);\n\t\tcopied = 0;\n\t\tgoto out;\n\t}\n\n\tdown_write(&EXT4_I(inode)->xattr_sem);\n\tBUG_ON(!ext4_has_inline_data(inode));\n\n\tkaddr = kmap_atomic(page);\n\text4_write_inline_data(inode, &iloc, kaddr, pos, len);\n\tkunmap_atomic(kaddr);\n\tSetPageUptodate(page);\n\t/* clear page dirty so that writepages wouldn't work for us. */\n\tClearPageDirty(page);\n\n\tup_write(&EXT4_I(inode)->xattr_sem);\n\tbrelse(iloc.bh);\nout:\n\treturn copied;\n}",
    "comment": "Writes inline data to the inode's page, marking it as up-to-date and clearing its dirty state after successfully copying the specified length.",
    "prorec_sum": "Finalizes writing inline data in an ext4 inode, ensuring journal access, updating buffer states, and handling errors through kernel bug checks.",
    "filter_prorec_sum": "Finalizes an ext4 inline data write operation, updating journal access, buffer state, and related metadata with error logging and synchronization.",
    "prorec_aug_sum": "Handles completion of ext4 inline data writes by validating conditions, performing block operations, updating flags, and finalizing with optional follow-up processing.",
    "filter_prorec_aug_sum": "Handles completion of ext4 inline data write operations, updating flags, invoking end I/O processing, and logging errors when conditions are met.",
    "work_score": {
        "prorec": {
            "summary": "Finalizes writing inline data in an ext4 inode, ensuring journal access, updating buffer states, and handling errors through kernel bug checks.",
            "score": [
                0.6,
                0.4,
                0.2
            ],
            "reason": [
                "The summary correctly notes that the function finalizes writing inline data in an ext4 inode and handles errors, aligning with the code's role and error handling paths. However, it inaccurately claims 'ensuring journal access,' which is not evident in the code, and oversimplifies buffer state updates without specifying the actual operations (SetPageUptodate, ClearPageDirty). The mention of 'kernel bug checks' is partially accurate due to BUG_ON usage. Overall, the majority of claims are accurate, but there are notable inaccuracies and vague statements.",
                "The summary mentions finalizing inline data write to an ext4 inode, which aligns with the core purpose. However, it inaccurately claims 'ensuring journal access,' a concept not present in the code, and omits specifics such as mapping the page atomically, setting and clearing page states, acquiring and releasing xattr semaphore, handling the case where copied < len, and using ext4_get_inode_loc with error handling. The coverage of secondary behaviors and branches is minimal, and there is also misleading information, reducing alignment with evaluation steps.",
                "The summary correctly identifies that the function finalizes writing inline data in an ext4 inode and includes error handling via kernel bug checks. However, it inaccurately claims 'ensuring journal access'\u2014there is no journal operation in the source code, only inode location retrieval and xattr_sem synchronization. This is a FATAL error targeting the primary purpose by suggesting a core behavior that is absent. While buffer state updates are mentioned and accurate, the presence of this severe inaccuracy on the core semantics drastically reduces trustworthiness."
            ]
        },
        "filter_prorec": {
            "summary": "Finalizes an ext4 inline data write operation, updating journal access, buffer state, and related metadata with error logging and synchronization.",
            "score": [
                0.5,
                0.2,
                0.2
            ],
            "reason": [
                "The summary contains partially inaccurate claims: it correctly describes this function as finalizing an ext4 inline data write with error handling and synchronization, which matches the use of locks, inline data checks, and error logging. However, it inaccurately states 'updating journal access' and 'related metadata' in a way that suggests journaling operations, which are not present in the source code, and omits crucial details like mapping the page and clearing its dirty flag. Only about half of the claims directly align with the actual semantics.",
                "The summary gives a vague description of finalizing an ext4 inline data write but does not explicitly state the core purpose of writing inline data from the page to the inode at the specified position and length. While it mentions metadata updates, error logging, and synchronization, it incorrectly refers to 'journal access' which is not in the code, and omits key specifics such as checking if the page is up-to-date, getting the inode location, mapping/unmapping the page, and clearing the page dirty flag. Core domain action is not clearly nor accurately covered, and secondary details are incomplete.",
                "The summary claims journal access updates, which are not present in the source code, making this a FATAL in relation to primary purpose. The actual function finalizes inline data writes by locking, writing, updating page flags, and logging errors, but the summary introduces incorrect behaviors outside the code's scope. While some accurate elements about error logging and synchronization exist, the critical misstatement about journal handling undermines trust completely."
            ]
        }
    }
}
{
    "source_code": "void luaS_resize(lua_State* L, int newsize) {\n  int i;\n  stringtable* tb = &G(L)->strt; // global string table\n  if (newsize > tb->size) { /* grow table if needed */\n    luaM_reallocvector(L, tb->hash, tb->size, newsize, TString*);\n    for (i = tb->size; i < newsize; i++)\n      // open hash table, tb->hash is the pointer for linked list\n      tb->hash[i] = NULL;\n  }\n  for (i = 0; i < tb->size; i++) { /* rehash */\n    TString* p = tb->hash[i];\n    tb->hash[i] = NULL;\n    while (p) { /* for each node in the list */\n      TString* hnext = p->u.hnext; /* save next */\n      unsigned int h = lmod(p->hash, newsize); /* new position */\n      p->u.hnext = tb->hash[h]; /* chain it */\n      tb->hash[h] = p;\n      p = hnext;\n    }\n  }\n  if (newsize < tb->size) { /* shrink table if needed */\n    /* vanishing slice should be empty */\n    lua_assert(tb->hash[newsize] == NULL && tb->hash[tb->size - 1] == NULL);\n    luaM_reallocvector(L, tb->hash, tb->size, newsize, TString*);\n  }\n  tb->size = newsize;\n}",
    "comment": "Resizes the global string table, rehashes existing strings, and reallocates memory based on the new size provided.",
    "prorec_sum": "Resizes a hash table\u2019s bucket array and rehashes all entries to match the new capacity specified by the parameter.",
    "filter_prorec_sum": "Resizes and rehashes a hash table\u2019s bucket array to the specified size, clearing entries and redistributing existing nodes based on updated index masking.",
    "prorec_aug_sum": "Resizes a hash table's bucket array and rehashes its linked entries to match the new size.",
    "filter_prorec_aug_sum": "Resizes a hash table\u2019s bucket array to the specified size and reassigns existing linked-list entries into new buckets based on updated indexing.",
    "work_score": {
        "prorec": {
            "summary": "Resizes a hash table\u2019s bucket array and rehashes all entries to match the new capacity specified by the parameter.",
            "score": [
                0.9,
                0.4,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function resizes a hash table\u2019s bucket array and rehashes all entries to match the new capacity, which aligns with the code behavior of adjusting the global string table size and reassigning entries. While it omits specifics like handling both growth and shrink operations, and initialization of new buckets to NULL, the core claim is accurate and reflects the primary domain semantics.",
                "The summary accurately describes the core action of resizing the hash table and rehashing entries, which matches the function's primary purpose in the source code. It covers the main domain-specific behavior but omits secondary details such as how the table is grown or shrunk, initialization of new buckets to NULL, handling linked lists in each bucket, assertions during shrink, and use of luaM_reallocvector. These omissions mean the coverage of secondary behavior-critical semantics is minimal.",
                "The summary accurately captures the primary purpose of the function \u2014 resizing the hash table's bucket array and rehashing entries to the new capacity \u2014 which matches the code\u2019s growth, shrink, and rehash logic. There are no incorrect statements or noise, but the claim is generic and lacks detail about specific conditions, handling of NULL initialization, or memory reallocation semantics, resulting in low informational gain despite correctness."
            ]
        },
        "filter_prorec": {
            "summary": "Resizes and rehashes a hash table\u2019s bucket array to the specified size, clearing entries and redistributing existing nodes based on updated index masking.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function resizes and rehashes the hash table's bucket array to a specified size, and it mentions clearing entries and redistributing nodes according to updated indexing, which matches the code\u2019s reallocation, NULL-initialization, and rehashing steps. All claims are accurate and grounded in the source code semantics, with no irrelevant or incorrect information present.",
                "The summary correctly identifies the core purpose as resizing and rehashing the string table\u2019s bucket array, including clearing new entries and redistributing existing nodes according to updated indexing. This matches the function\u2019s actual semantics in the source code. However, it omits secondary specifics such as handling both grow and shrink cases, using linked lists within buckets, the assertion when shrinking to ensure vanishing slices are empty, and the use of luaM_reallocvector for memory reallocation. These omissions reduce coverage of critical secondary behaviors.",
                "The summary correctly identifies the core purpose of resizing and rehashing the hash table\u2019s bucket array, including redistribution of nodes. However, it inaccurately claims that entries are cleared broadly, while the code only initializes new slots to NULL when growing and reassigns nodes when rehashing; existing entries are not removed except in empty slices during shrinking. The inaccurate detail about clearing entries affects accuracy but is not a severe fatal error on the primary purpose, as the main behavior is still well captured. The gain is moderate due to the specific mention of redistribution logic, but noise from the misstatement slightly reduces trust."
            ]
        }
    }
}
{
    "source_code": "\nint ssl3_get_req_cert_type(SSL *s, unsigned char *p)\n\t{\n\tint ret=0;\n\tunsigned long alg_k;\n\n\talg_k = s->s3->tmp.new_cipher->algorithm_mkey;\n\n#ifndef OPENSSL_NO_GOST\n\tif (s->version >= TLS1_VERSION)\n\t\t{\n\t\tif (alg_k & SSL_kGOST)\n\t\t\t{\n\t\t\tp[ret++]=TLS_CT_GOST94_SIGN;\n\t\t\tp[ret++]=TLS_CT_GOST01_SIGN;\n\t\t\treturn(ret);\n\t\t\t}\n\t\t}\n#endif\n\n#ifndef OPENSSL_NO_DH\n\tif (alg_k & (SSL_kDHr|SSL_kEDH))\n\t\t{\n#  ifndef OPENSSL_NO_RSA\n\t\tp[ret++]=SSL3_CT_RSA_FIXED_DH;\n#  endif\n#  ifndef OPENSSL_NO_DSA\n\t\tp[ret++]=SSL3_CT_DSS_FIXED_DH;\n#  endif\n\t\t}\n\tif ((s->version == SSL3_VERSION) &&\n\t\t(alg_k & (SSL_kEDH|SSL_kDHd|SSL_kDHr)))\n\t\t{\n#  ifndef OPENSSL_NO_RSA\n\t\tp[ret++]=SSL3_CT_RSA_EPHEMERAL_DH;\n#  endif\n#  ifndef OPENSSL_NO_DSA\n\t\tp[ret++]=SSL3_CT_DSS_EPHEMERAL_DH;\n#  endif\n\t\t}\n#endif /* !OPENSSL_NO_DH */\n#ifndef OPENSSL_NO_RSA\n\tp[ret++]=SSL3_CT_RSA_SIGN;\n#endif\n#ifndef OPENSSL_NO_DSA\n\tp[ret++]=SSL3_CT_DSS_SIGN;\n#endif\n#ifndef OPENSSL_NO_ECDH\n\tif ((alg_k & (SSL_kECDHr|SSL_kECDHe)) && (s->version >= TLS1_VERSION))\n\t\t{\n\t\tp[ret++]=TLS_CT_RSA_FIXED_ECDH;\n\t\tp[ret++]=TLS_CT_ECDSA_FIXED_ECDH;\n\t\t}\n#endif\n\n#ifndef OPENSSL_NO_ECDSA\n\t/* ECDSA certs can be used with RSA cipher suites as well \n\t * so we don't need to check for SSL_kECDH or SSL_kEECDH\n\t */\n\tif (s->version >= TLS1_VERSION)\n\t\t{\n\t\tp[ret++]=TLS_CT_ECDSA_SIGN;\n\t\t}\n#endif\t\n\treturn(ret);\n\t}",
    "comment": "Determines and populates the required certificate types based on the SSL connection's cipher algorithms and version.",
    "prorec_sum": "Generates the SSL/TLS requested certificate types list based on protocol version and capability flags, returning the number of types added.",
    "filter_prorec_sum": "Generates the SSLv3/TLS client certificate type list based on connection version and capability flags.",
    "prorec_aug_sum": "Constructs the SSLv3 certificate request type list based on the connection version and bitmask flags, and returns the number of types added.",
    "filter_prorec_aug_sum": "Constructs a list of acceptable SSL certificate type codes based on protocol version and capability flags, returning the count of generated entries.",
    "work_score": {
        "prorec": {
            "summary": "Generates the SSL/TLS requested certificate types list based on protocol version and capability flags, returning the number of types added.",
            "score": [
                0.9,
                0.5,
                0.8
            ],
            "reason": [
                "The summary correctly states that the function generates a list of SSL/TLS certificate types based on protocol version and capability flags, and returns the number of types added. These points align with the source code, which checks protocol version, algorithm key flags, and appends various certificate type constants to the output array before returning the count. The summary is high-level but accurate for the function's domain semantics and contains no contradictory or irrelevant claims.",
                "The summary correctly captures the core purpose of generating a list of certificate types based on the SSL/TLS version and capability flags and returning the count, which aligns with the function's primary domain behavior. However, it omits most secondary details such as specific handling for GOST, DH, RSA, DSA, and ECDH/ECDSA algorithms, conditional compilation flags, and version-specific branching. These are critical semantics that influence the output and edge case behavior, so coverage of secondary aspects is weak.",
                "The summary correctly identifies the core purpose of the function: generating a list of SSL/TLS certificate types based on protocol version and capability flags, and returning the count of types added. This aligns with the source code\u2019s behavior of checking algorithm key flags and version to populate the output array and return the number added. The claim is both accurate and focused on the primary purpose, with no contradictory or irrelevant information, though it is somewhat generic and lacks detail about specific conditions or certificate types handled."
            ]
        },
        "filter_prorec": {
            "summary": "Generates the SSLv3/TLS client certificate type list based on connection version and capability flags.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly captures the core purpose of the function\u2014building a list of client certificate types depending on the protocol version and algorithm/capability flags. While it omits specific details like exact certificate type codes and the conditional compilation cases for GOST, DH, RSA, DSA, and ECDSA, all its claims align accurately with the source code's behavior and intent, making them factually accurate though somewhat general.",
                "The summary correctly captures the core functionality of generating a client certificate type list for SSLv3/TLS based on protocol version and capability flags, aligning with the code's logic of checking 's->version' and 'algorithm_mkey' to populate 'p' with specific constants. However, it only covers the primary purpose and omits secondary behavior-critical details, such as handling of GOST, DH, RSA, DSA, ECDH, and ECDSA conditions, as well as the exact certificate type constants returned. This results in incomplete coverage of the code's important branches and conditions.",
                "The summary correctly states that the function generates a client certificate type list based on the connection version and capability flags, which matches the source code's behavior in evaluating s->version and algorithm_mkey bits to populate p[]. This is a single accurate GOLD claim describing the primary purpose without introducing noise or inaccuracies. However, it is broad and low-detail, offering limited insight into specific certificate types or conditional logic, so while accurate, it provides only modest gain."
            ]
        }
    }
}
{
    "source_code": "\nstatic void e1000_get_wol(struct net_device *netdev,\n\t\t\t  struct ethtool_wolinfo *wol)\n{\n\tstruct e1000_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\twol->supported = WAKE_UCAST | WAKE_MCAST |\n\t                 WAKE_BCAST | WAKE_MAGIC;\n\twol->wolopts = 0;\n\n\t/* this function will set ->supported = 0 and return 1 if wol is not\n\t * supported by this hardware\n\t */\n\tif (e1000_wol_exclusion(adapter, wol) ||\n\t    !device_can_wakeup(&adapter->pdev->dev))\n\t\treturn;\n\n\t/* apply any specific unsupported masks here */\n\tswitch (hw->device_id) {\n\tcase E1000_DEV_ID_82546GB_QUAD_COPPER_KSP3:\n\t\t/* KSP3 does not support UCAST wake-ups */\n\t\twol->supported &= ~WAKE_UCAST;\n\n\t\tif (adapter->wol & E1000_WUFC_EX)\n\t\t\te_err(drv, \"Interface does not support directed \"\n\t\t\t      \"(unicast) frame wake-up packets\\n\");\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (adapter->wol & E1000_WUFC_EX)\n\t\twol->wolopts |= WAKE_UCAST;\n\tif (adapter->wol & E1000_WUFC_MC)\n\t\twol->wolopts |= WAKE_MCAST;\n\tif (adapter->wol & E1000_WUFC_BC)\n\t\twol->wolopts |= WAKE_BCAST;\n\tif (adapter->wol & E1000_WUFC_MAG)\n\t\twol->wolopts |= WAKE_MAGIC;\n}",
    "comment": "Configures wake-on-LAN options for the network device based on adapter capabilities and supported wake-up frame types.",
    "prorec_sum": "Configures wake-up capability flags in the target structure based on device status bits and logs if unicast frame wake-up is unsupported.",
    "filter_prorec_sum": "Configures wake-up capability flags in an output structure based on interface power management settings and hardware support for directed frame reception.",
    "prorec_aug_sum": "Configures wake-up packet capabilities in a network interface, enabling flags for unicast, multicast, and broadcast wake support based on hardware and configuration status.",
    "filter_prorec_aug_sum": "Configures wake-up capabilities in the provided structure based on device flags, logging if directed unicast frame wake-up is unsupported.",
    "work_score": {
        "prorec": {
            "summary": "Configures wake-up capability flags in the target structure based on device status bits and logs if unicast frame wake-up is unsupported.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function configures wake-up capability flags in the provided structure based on the device\u2019s status (via adapter->wol bits) and notes logging when unicast wake-up is unsupported. These are directly supported by the code, which sets supported/wolopts fields depending on hardware conditions and logs for specific unicast limitations. The description is accurate and focused on actual code semantics, with no incorrect or irrelevant claims.",
                "The summary correctly identifies that the function sets wake-up capability flags based on device status and logs a message if unicast wake-up is unsupported, which matches the core purpose of configuring WOL flags according to hardware and adapter conditions. However, it omits important specifics such as the initial supported mask assignments, exclusion checks for unsupported hardware, conditional early return, device-specific mask adjustments, and all supported wake-up types (multicast, broadcast, magic packet). These omissions result in incomplete coverage of secondary behavior-critical semantics.",
                "The summary correctly states that the function configures wake-up capability flags in a target structure based on device status bits and mentions logging if unicast wake-up is unsupported. These points align with the source code's behavior, which sets `wol->supported` and `wol->wolopts` based on hardware properties and logs for unsupported unicast. However, the description is generic, omitting specific details such as the conditional early return when wake-on-LAN is unsupported, handling of various wake types (magic, multicast, broadcast), and device-specific mask application. There are no inaccurate or contradictory claims, but the low detail level limits its value."
            ]
        },
        "filter_prorec": {
            "summary": "Configures wake-up capability flags in an output structure based on interface power management settings and hardware support for directed frame reception.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly states that the function configures wake-up capability flags in an output structure based on hardware support and interface power management settings, which aligns with the code\u2019s assignment to `wol->supported` and `wol->wolopts` and the checks on hardware/device-specific conditions for directed frames. The claim is accurate and reflects the domain semantics, with no contradictory or irrelevant information present.",
                "The summary accurately reflects the core purpose, which is setting wake-up capability flags depending on hardware support and configuration, specifically mentioning directed frame reception, aligning with the function's adjustment of WAKE_UCAST and other flags. However, it omits mention of other wake-up types (multicast, broadcast, magic packet), condition checks for hardware wake capability, exclusion handling, and error logging, resulting in limited coverage of secondary behavior-critical semantics.",
                "The summary correctly conveys that the function sets wake-up capability flags based on hardware support and interface power management, aligning with the code's use of `wol->supported` and `wol->wolopts` populated from hardware and adapter settings. However, it omits specifics like the exclusion checks, special-case handling for certain device IDs, and coverage of multicast, broadcast, and magic packet wake-ups. The noise level is low, but the gain is limited due to lack of detail, making the benefit modest."
            ]
        }
    }
}
{
    "source_code": "\nint intel_pmu_setup_lbr_filter(struct perf_event *event)\n{\n\tint ret = 0;\n\n\t/*\n\t * no LBR on this PMU\n\t */\n\tif (!x86_pmu.lbr_nr)\n\t\treturn -EOPNOTSUPP;\n\n\t/*\n\t * setup SW LBR filter\n\t */\n\tret = intel_pmu_setup_sw_lbr_filter(event);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * setup HW LBR filter, if any\n\t */\n\tif (x86_pmu.lbr_sel_map)\n\t\tret = intel_pmu_setup_hw_lbr_filter(event);\n\n\treturn ret;\n}",
    "comment": "Configures both software and hardware LBR filters for a performance event if LBR support is available on the PMU.",
    "prorec_sum": "Configures device state flags from a structure field and updates related masks, returning errors if prerequisites or mappings are invalid.",
    "filter_prorec_sum": "Configures device control flags from a context structure and applies a resource mask based on enabled feature bits, returning specific error codes if unsupported.",
    "prorec_aug_sum": "Configures CPU-related flags from a task structure\u2019s field and updates global masks, returning errors if prerequisites or mappings are invalid.",
    "filter_prorec_aug_sum": "Configures CPU-related flags in a task structure and updates global masks based on enabled feature bits, returning errors for invalid or unsupported configurations.",
    "work_score": {
        "prorec": {
            "summary": "Configures device state flags from a structure field and updates related masks, returning errors if prerequisites or mappings are invalid.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary describes generic device state flag configuration and mask updates, which do not match the actual function semantics. The source code handles setting up LBR filters\u2014returning an error if no LBRs exist, calling software and possibly hardware-specific setup functions\u2014rather than configuring state flags or masks. None of the claims in the summary directly reflect the actual behavior, making them inaccurate.",
                "The summary does not capture the core purpose of setting up software and optional hardware Last Branch Record (LBR) filters for a performance monitoring unit. Claims about configuring device state flags and updating masks are inaccurate relative to the source code\u2019s filter setup logic. The core action and conditional checks for LBR support are missing, and there is no correct secondary detail, leading to a failure to cover the essential semantics.",
                "The summary claims the function configures device state flags and updates related masks, which does not match the source code's actual behavior of setting up software and hardware LBR filters for a performance event. This is a FATAL inaccuracy concerning the core purpose (the setup of filters, not state flags/masks). As the primary action is misrepresented, the benefit is unusable despite any generic elements."
            ]
        },
        "filter_prorec": {
            "summary": "Configures device control flags from a context structure and applies a resource mask based on enabled feature bits, returning specific error codes if unsupported.",
            "score": [
                0.0,
                0.1,
                0.3
            ],
            "reason": [
                "The summary claims that the function configures device control flags from a context structure and applies a resource mask based on enabled feature bits, which does not match the source code's actual semantic behavior. The code checks for LBR support in the PMU, sets up software and optional hardware LBR filters, and returns error codes accordingly. None of the claims in the summary align factually with the code, resulting in 0% accurate statements.",
                "The summary does not describe the actual function behavior, which is setting up software and possibly hardware last branch record (LBR) filters for Intel PMUs, with early return if unsupported. Instead, it incorrectly talks about configuring device control flags and applying resource masks, which contradicts the source code. The core purpose is entirely absent, and no accurate secondary details are provided.",
                "The summary's claims about configuring device control flags, a context structure, and applying a resource mask based on feature bits do not match the source code, which sets up software and potentially hardware LBR filters for the Intel PMU and returns errors if unsupported. These are inaccurate and amount to NOISE, with no accurate representation of the primary purpose or I/O. The worst failure mode is overwhelming NOISE, yielding negligible net benefit."
            ]
        }
    }
}
{
    "source_code": "\nstatic int __init dquot_init(void)\n{\n\tint i, ret;\n\tunsigned long nr_hash, order;\n\n\tprintk(KERN_NOTICE \"VFS: Disk quotas %s\\n\", __DQUOT_VERSION__);\n\n\tregister_sysctl_table(sys_table);\n\n\tdquot_cachep = kmem_cache_create(\"dquot\",\n\t\t\tsizeof(struct dquot), sizeof(unsigned long) * 4,\n\t\t\t(SLAB_HWCACHE_ALIGN|SLAB_RECLAIM_ACCOUNT|\n\t\t\t\tSLAB_MEM_SPREAD|SLAB_PANIC),\n\t\t\tNULL);\n\n\torder = 0;\n\tdquot_hash = (struct hlist_head *)__get_free_pages(GFP_ATOMIC, order);\n\tif (!dquot_hash)\n\t\tpanic(\"Cannot create dquot hash table\");\n\n\tfor (i = 0; i < _DQST_DQSTAT_LAST; i++) {\n\t\tret = percpu_counter_init(&dqstats.counter[i], 0);\n\t\tif (ret)\n\t\t\tpanic(\"Cannot create dquot stat counters\");\n\t}\n\n\t/* Find power-of-two hlist_heads which can fit into allocation */\n\tnr_hash = (1UL << order) * PAGE_SIZE / sizeof(struct hlist_head);\n\tdq_hash_bits = 0;\n\tdo {\n\t\tdq_hash_bits++;\n\t} while (nr_hash >> dq_hash_bits);\n\tdq_hash_bits--;\n\n\tnr_hash = 1UL << dq_hash_bits;\n\tdq_hash_mask = nr_hash - 1;\n\tfor (i = 0; i < nr_hash; i++)\n\t\tINIT_HLIST_HEAD(dquot_hash + i);\n\n\tprintk(\"Dquot-cache hash table entries: %ld (order %ld, %ld bytes)\\n\",\n\t\t\tnr_hash, order, (PAGE_SIZE << order));\n\n\tregister_shrinker(&dqcache_shrinker);\n\n\treturn 0;\n}",
    "comment": "Initializes the disk quota subsystem by creating a cache, allocating a hash table, and setting up statistical counters.",
    "prorec_sum": "Initializes quota management by creating the dquot cache, hash table, and associated statistics counters, then logs their configuration.",
    "filter_prorec_sum": "Initializes the dquot subsystem by creating its hash table, setting up stat counters, and logging cache table configuration.",
    "prorec_aug_sum": "Initializes the dquot subsystem by creating its hash table, allocating stat counters, and logging cache parameters for quota management.",
    "filter_prorec_aug_sum": "Initializes the dquot subsystem by allocating a hash table, setting up stat counters, clearing entries, and logging cache table details.",
    "work_score": {
        "prorec": {
            "summary": "Initializes quota management by creating the dquot cache, hash table, and associated statistics counters, then logs their configuration.",
            "score": [
                1.0,
                0.6,
                0.6
            ],
            "reason": [
                "The summary accurately reflects the key steps in the function: initializing quota management, creating the dquot cache, setting up the hash table, initializing statistics counters, and logging configuration details. These match the source code's behavior for cache creation, hash allocation, counter initialization, and logging, with no evident inaccuracies. All claims are grounded in the actual function's semantics.",
                "The summary accurately describes the core purpose of initializing disk quota management, including creation of the dquot cache, hash table, and stats counters, and mentions logging configuration. This matches the key domain action in the code. However, it omits secondary details such as registration of sysctl table and shrinker, allocation specifics, panic handling for allocation failures, and determination of hash table size and mask, which are important behavior-critical semantics.",
                "The summary correctly states the primary purpose as initializing quota management through creation of the dquot cache, hash table, and counters, and notes logging configuration details. These claims align with the source code\u2019s actual behavior and contain no inaccuracies. However, the description is fairly generic and misses specific implementation details like power-of-two calculation for hash entries, panic conditions on allocation failure, and registration of system controls and shrinker, providing only low-info gain despite accuracy."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes the dquot subsystem by creating its hash table, setting up stat counters, and logging cache table configuration.",
            "score": [
                1.0,
                0.5,
                0.7
            ],
            "reason": [
                "The summary contains three key claims: creating the hash table, setting up stat counters, and logging cache table configuration. All these actions directly occur in the source code: the hash table is created using __get_free_pages and INIT_HLIST_HEAD, stat counters are initialized via percpu_counter_init, and configuration is logged using printk. These claims are accurate and specific to the function's behavior, with no contradictions or irrelevant statements.",
                "The summary correctly identifies the core purpose of initializing the dquot subsystem with creation of its hash table and setup of stat counters, aligning with the function's main initialization logic. However, it omits several important secondary behaviors present in the source code, such as registering sysctl tables, creating the kmem cache, handling allocation failures with panic calls, computing hash bits and masks, initializing each hlist head, and registering a shrinker. Coverage of core purpose is adequate, but secondary detail coverage is minimal.",
                "The summary contains accurate, concise claims focused on the primary purpose: initializing the dquot subsystem, creating the hash table, setting up stat counters, and logging configuration. All statements align with the source code's behavior and there is no contradictory or irrelevant noise. While accurate, the claims are general and lack deeper specifics like memory allocation method, slab cache creation flags, or error handling, which limits the gain to moderate rather than high."
            ]
        }
    }
}
{
    "source_code": "static int netlbl_unlabel_list(struct sk_buff *skb, struct genl_info *info)\n{\n\tint ret_val = -EINVAL;\n\tstruct sk_buff *ans_skb;\n\tvoid *data;\n\n\tans_skb = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\n\tif (ans_skb == NULL)\n\t\tgoto list_failure;\n\tdata = genlmsg_put_reply(ans_skb, info, &netlbl_unlabel_gnl_family,\n\t\t\t\t 0, NLBL_UNLABEL_C_LIST);\n\tif (data == NULL) {\n\t\tret_val = -ENOMEM;\n\t\tgoto list_failure;\n\t}\n\n\tret_val = nla_put_u8(ans_skb,\n\t\t\t     NLBL_UNLABEL_A_ACPTFLG,\n\t\t\t     netlabel_unlabel_acceptflg);\n\tif (ret_val != 0)\n\t\tgoto list_failure;\n\n\tgenlmsg_end(ans_skb, data);\n\treturn genlmsg_reply(ans_skb, info);\n\nlist_failure:\n\tkfree_skb(ans_skb);\n\treturn ret_val;\n}",
    "comment": "Generates and replies with a netlabel unlabeling response containing an acceptance flag in a netlink message or returns an error.",
    "prorec_sum": "Initializes a network-related structure, configures parameters, and dispatches it through a lower-level transmission routine, returning success or an error code.",
    "filter_prorec_sum": "Initializes a network-related object, configures it with provided parameters, and performs a follow-up operation, returning success or an error code.",
    "prorec_aug_sum": "Allocates and initializes a network-related structure, configures it with provided parameters, then commits it to a connection table, handling errors appropriately.",
    "filter_prorec_aug_sum": "Initializes a network-related object, configures it with provided parameters, updates metadata, and invokes a follow-up operation, returning errors or success accordingly.",
    "work_score": {
        "prorec": {
            "summary": "Initializes a network-related structure, configures parameters, and dispatches it through a lower-level transmission routine, returning success or an error code.",
            "score": [
                0.5,
                0.2,
                0.4
            ],
            "reason": [
                "The summary contains mostly generic descriptions like 'initializes a network-related structure' and 'dispatches it through a lower-level transmission routine' which are loosely aligned with the code\u2019s behavior. It omits key specifics such as the use of netlink message allocation, specific failure paths with -EINVAL and -ENOMEM, and the inclusion of the NLBL_UNLABEL_A_ACPTFLG attribute. While it broadly captures some network-related initialization and sending, it lacks detail and precision, making only about half of the claims accurate and highly verifiable against the source code.",
                "The summary presents generic statements about initializing a network structure, configuring parameters, and sending via a lower-level routine, which are broadly accurate but lack the specific domain semantics of listing the NetLabel unlabel configuration via a generic netlink reply. The core purpose of creating and replying with a netlink message containing NLBL_UNLABEL_A_ACPTFLG is not covered. No details on constants, specific message construction steps, or error handling paths are provided.",
                "The summary contains mostly generic statements that do not accurately capture the function's core semantics. It omits key details such as the allocation of a netlink message, composing the reply with specific attributes, and returning via genlmsg_reply. While it generically references initialization and transmission, these are too broad and do not match the specific domain behavior in the source. There are no explicit contradictions (no FATAL), but the information gain is minimal and mostly noise, providing little utility for understanding the precise function behavior."
            ]
        },
        "filter_prorec": {
            "summary": "Initializes a network-related object, configures it with provided parameters, and performs a follow-up operation, returning success or an error code.",
            "score": [
                0.2,
                0.2,
                0.4
            ],
            "reason": [
                "The summary is overly generic and does not capture specific, verifiable details from the source code such as allocation of a sk_buff, building a netlink message, adding a specific attribute, and handling failures. It does not mention the `genlmsg_reply` usage or the constants involved, leading to less than 50% accurate claims regarding actual code semantics.",
                "The summary is generic and vague, mentioning initialization, configuration, and returning success or error, but it does not accurately capture the core purpose of the function, which is to construct and send a netlabel unlabel list reply message using generic netlink, including the accept flag. It omits specific domain actions, constants, and error-handling flow, and the claims do not align with the concrete semantics of the source code.",
                "The summary makes broad, generic claims about initializing a network object, configuring it, and returning success or error codes, but omits any specific, verifiable details from the source code such as creating an nlmsg for generic netlink, adding a specific attribute (NLBL_UNLABEL_A_ACPTFLG), or handling exact memory allocation failures. This results in mostly NOISE with no GOLD-level insights, and while there are no outright contradictions, the lack of specificity means low gain."
            ]
        }
    }
}
{
    "source_code": "\nvoid\nS_SET_EXTERNAL (symbolS *s)\n{\n  if (LOCAL_SYMBOL_CHECK (s))\n    s = local_symbol_convert ((struct local_symbol *) s);\n  if ((s->bsym->flags & BSF_WEAK) != 0)\n    {\n      /* Let .weak override .global.  */\n      return;\n    }\n  if (s->bsym->flags & BSF_SECTION_SYM)\n    {\n      /* Do not reassign section symbols.  */\n      as_warn (_(\"section symbols are already global\"));\n      return;\n    }\n#ifndef TC_GLOBAL_REGISTER_SYMBOL_OK\n  if (S_GET_SEGMENT (s) == reg_section)\n    {\n      as_bad (\"can't make register symbol `%s' global\",\n\t      S_GET_NAME (s));\n      return;\n    }\n#endif\n  s->bsym->flags |= BSF_GLOBAL;\n  s->bsym->flags &= ~(BSF_LOCAL | BSF_WEAK);\n\n#ifdef TE_PE\n  if (! an_external_name && S_GET_NAME(s)[0] != '.')\n    an_external_name = S_GET_NAME (s);\n#endif\n}",
    "comment": "Sets a symbol as global, overriding weak and local flags while preventing reassignment of section or register symbols.",
    "prorec_sum": "Marks a section symbol as global unless it is already global or a register symbol, issuing corresponding error messages when prohibited.",
    "filter_prorec_sum": "Marks a section symbol as global unless it is already global or is a register symbol, issuing appropriate error messages when invalid.",
    "prorec_aug_sum": "Marks a section symbol as global unless it is already global or a register symbol, issuing translated error messages when those conditions prevent changes.",
    "filter_prorec_aug_sum": "Marks a section symbol as global unless it is already global or a restricted register symbol, returning appropriate error messages when disallowed.",
    "work_score": {
        "prorec": {
            "summary": "Marks a section symbol as global unless it is already global or a register symbol, issuing corresponding error messages when prohibited.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary omits key behavior from the source code, such as handling weak symbols by returning early, converting local symbols, and issuing warnings rather than marking section symbols as global. It also inaccurately describes the treatment of section symbols\u2014source code warns and returns instead of marking them global\u2014and does not mention flag manipulation. Less than half of its claims align accurately with the code semantics.",
                "The summary misses the core primary purpose, which is to mark a symbol as global unless certain conditions (weak, section symbol, register symbol) prevent it. It incorrectly states 'marks a section symbol as global' when the code explicitly avoids changing section symbols, issuing a warning instead. While it mentions register symbols and errors, it omits handling for weak symbols and the TE_PE external name assignment, reducing coverage of secondary behaviors.",
                "The summary omits key conditional behaviors from the source code\u2014specifically, it inaccurately describes handling of section symbols (the code warns and skips them, never marks them global) and entirely ignores the special case for weak symbols. These are core aspects of the function's purpose and directly affect its primary action of setting symbols global, making this a severe semantic error. While the mention of register symbols and error messages is correct, the fatal inaccuracies about section and weak symbol handling render the description unreliable for understanding the function."
            ]
        },
        "filter_prorec": {
            "summary": "Marks a section symbol as global unless it is already global or is a register symbol, issuing appropriate error messages when invalid.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary omits multiple key behaviors from the source code: it does not mention the handling of weak symbols, the initial conversion of local symbols, or the warning issued for section symbols instead of marking them. It inaccurately states that the function marks section symbols as global unless already global, whereas the code explicitly avoids reassigning section symbols and issues a warning. While it correctly notes that register symbols are invalid and cause error messages, most domain-specific details are missing or misstated, resulting in less than half of the claims being accurate.",
                "The summary is inaccurate because the function does not mark section symbols as global; in fact, it explicitly avoids reassigning section symbols, issuing a warning instead. The core purpose\u2014converting a symbol to global status unless it is weak, a section symbol, or a register symbol, with corresponding warnings/errors\u2014is misrepresented. While the mention of rejecting register symbols aligns with part of the logic, the incorrect handling of section symbols means the core domain action is not correctly covered.",
                "The summary inaccurately describes the function's behavior: the code does not mark section symbols as global at all\u2014instead, it explicitly avoids reassigning section symbols and warns if encountered, which is a FATAL error on the core purpose. Additionally, it omits mention of handling weak symbols and converting local symbols, meaning key details are missing. The worst failure mode is a FATAL error regarding the primary purpose of the function, rendering the summary misleading and untrustworthy."
            ]
        }
    }
}
{
    "source_code": "\nint FAST_FUNC ll_addr_a2n(unsigned char *lladdr, int len, char *arg)\n{\n\tint i;\n\n\tif (strchr(arg, '.')) {\n\t\tinet_prefix pfx;\n\t\tif (get_addr_1(&pfx, arg, AF_INET)) {\n\t\t\tbb_error_msg(\"\\\"%s\\\" is invalid lladdr\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tif (len < 4) {\n\t\t\treturn -1;\n\t\t}\n\t\tmemcpy(lladdr, pfx.data, 4);\n\t\treturn 4;\n\t}\n\n\tfor (i = 0; i < len; i++) {\n\t\tint temp;\n\t\tchar *cp = strchr(arg, ':');\n\t\tif (cp) {\n\t\t\t*cp = 0;\n\t\t\tcp++;\n\t\t}\n\t\tif (sscanf(arg, \"%x\", &temp) != 1 || (temp < 0 || temp > 255)) {\n\t\t\tbb_error_msg(\"\\\"%s\\\" is invalid lladdr\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tlladdr[i] = temp;\n\t\tif (!cp) {\n\t\t\tbreak;\n\t\t}\n\t\targ = cp;\n\t}\n\treturn i+1;\n}",
    "comment": "Converts a string representation of a link-layer address to its binary format, supporting both IPv4 addresses and hexadecimal notation.",
    "prorec_sum": "Parses and validates a link-layer address string, storing its bytes into the provided buffer and reporting an error if the format is invalid.",
    "filter_prorec_sum": "Parses and validates a textual link-layer address, storing its bytes into the provided buffer or reporting an invalid address error.",
    "prorec_aug_sum": "Parses and validates a MAC address string, storing its bytes into the provided buffer and returning the number of parsed components or an error.",
    "filter_prorec_aug_sum": "Parses a string-formatted link-layer address into bytes, validating each segment and reporting an error if the format or values are invalid.",
    "work_score": {
        "prorec": {
            "summary": "Parses and validates a link-layer address string, storing its bytes into the provided buffer and reporting an error if the format is invalid.",
            "score": [
                1.0,
                0.5,
                0.6
            ],
            "reason": [
                "The summary correctly describes the core purpose of the function: parsing and validating a link-layer address string, storing bytes in the buffer, and reporting an error on invalid format. These align accurately with the source code's behavior, covering both the dotted IPv4 address path and colon-separated hex parsing paths without introducing inaccuracies. As it is concise and domain-relevant, all claims are accurate.",
                "The summary correctly identifies that the function parses and validates a link-layer address string, fills a buffer with its bytes, and reports errors for invalid formats, which matches the core purpose in the source code. However, it omits key secondary details such as handling of dotted IPv4-like format separately, the length checks (len < 4 case), the hex parsing with colon delimiters, and return values indicating number of bytes stored. Coverage of the core is solid but secondary semantics are weak.",
                "The summary correctly states that the function parses and validates a link-layer address string, stores its bytes in the provided buffer, and reports an error if the format is invalid. These are all accurate, high-level descriptions of the code\u2019s core behavior. However, the summary is generic and omits specifics about the two parsing formats (IPv4 dotted decimal and colon-separated hex bytes), length checks, and return values, which would provide more engineering value. There is no inaccurate or misleading claim, but the gain is limited due to low detail."
            ]
        },
        "filter_prorec": {
            "summary": "Parses and validates a textual link-layer address, storing its bytes into the provided buffer or reporting an invalid address error.",
            "score": [
                1.0,
                0.6,
                0.7
            ],
            "reason": [
                "The summary correctly describes the function's purpose of parsing and validating a textual link-layer address, filling the provided buffer, and reporting an error for invalid input. These behaviors are directly reflected in the source code where it checks formats, validates address components, populates 'lladdr', and calls 'bb_error_msg' on failure. No inaccuracies or irrelevant details are present, so the claim is fully aligned with the code.",
                "The summary correctly identifies that the function parses and validates a textual link-layer address and stores its bytes, which matches the core purpose from the source code. It also notes error reporting for invalid addresses. However, it omits specific secondary behaviors, such as handling both IPv4 dotted-decimal and colon-separated hex formats, enforcing byte length limits, and distinct return values signaling the number of bytes parsed versus failure. This limits completeness of coverage despite accurately capturing the core function.",
                "The summary correctly states that the function parses and validates a textual link\u2011layer address and writes its bytes to the provided buffer, reporting errors for invalid inputs. This aligns with the core behavior in the source, including handling of both dotted IPv4 and colon\u2011separated hex formats. There are no contradictory claims, and while the accuracy is solid, the wording is generic and lacks detail such as the specific IPv4 handling, length checks, and return values, so the informational gain is moderate."
            ]
        }
    }
}
{
    "source_code": "\nstatic void __activate_page(struct page *page, struct lruvec *lruvec,\n\t\t\t    void *arg)\n{\n\tif (PageLRU(page) && !PageActive(page) && !PageUnevictable(page)) {\n\t\tint file = page_is_file_cache(page);\n\t\tint lru = page_lru_base_type(page);\n\n\t\tdel_page_from_lru_list(page, lruvec, lru);\n\t\tSetPageActive(page);\n\t\tlru += LRU_ACTIVE;\n\t\tadd_page_to_lru_list(page, lruvec, lru);\n\n\t\t__count_vm_event(PGACTIVATE);\n\t\tupdate_page_reclaim_stat(lruvec, file, 1);\n\t}\n}",
    "comment": "Activates a page by removing it from the LRU list and updating its status if it is inactive and eligible for activation.",
    "prorec_sum": "Links a memory group to a zone, updates related list pointers and counters, and marks the object as inserted with specific flags.",
    "filter_prorec_sum": "Re-links a memory cgroup\u2019s zone statistics structures, updates relevant counters, and marks the zone as active based on specific status flags.",
    "prorec_aug_sum": "Processes a flagged object\u2019s linked-list reassignment, updates related counters, and marks it active within a resource management structure.",
    "filter_prorec_aug_sum": "Transitions an object from one linked list to another, updates related counters, and marks it with a status flag for subsequent processing.",
    "work_score": {
        "prorec": {
            "summary": "Links a memory group to a zone, updates related list pointers and counters, and marks the object as inserted with specific flags.",
            "score": [
                0.0,
                0.1,
                0.2
            ],
            "reason": [
                "The summary claims the function links a memory group to a zone, updates list pointers and counters, and marks an object as inserted with specific flags. None of these behaviors are present in the source code, which actually activates a page in the LRU lists under certain conditions, updates VM events, and page reclaim stats. All claims are inaccurate or unrelated to the actual semantics.",
                "The summary does not cover the core purpose of activating an eligible page in the LRU list, updating its active status, and adjusting memory management statistics. Instead, it inaccurately describes linking a memory group to a zone and marking insertion with flags, which does not match the source code's domain semantics. No accurate claims align with the primary operation, resulting in no core coverage and irrelevant details.",
                "The summary's claims about linking a memory group to a zone, updating list pointers and counters, and marking the object as inserted with specific flags do not match the source code's actual purpose, which is activating a page in the LRU list when certain conditions are met and updating related reclaim statistics. These are FATAL inaccuracies that misstate the primary purpose and side effects, making the description untrustworthy."
            ]
        },
        "filter_prorec": {
            "summary": "Re-links a memory cgroup\u2019s zone statistics structures, updates relevant counters, and marks the zone as active based on specific status flags.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary contains claims about re-linking a memory cgroup\u2019s zone statistics and marking a zone as active, which do not match the source code's actual behavior. The function operates on a page, modifying LRU lists, setting the page active, and updating page reclaim stats\u2014not zone-specific or memory cgroup structures. None of the claims are accurate with respect to the code semantics, resulting in a very low accuracy proportion.",
                "The summary misrepresents the function\u2019s core purpose: the code activates an inactive, evictable LRU page, moving it from its current LRU list to the active list and updating page reclaim statistics and counters. The summary incorrectly describes actions related to memory cgroup zone structures and zones, which are not present in the source code, failing to capture the actual domain-specific effect. No accurate claims about the core logic are present, and secondary behaviors such as condition checks, list operations, and VM event updates are omitted.",
                "The summary contains several inaccurate claims: it describes re-linking a memory cgroup\u2019s zone statistics structures and marking a zone as active, but the source code actually manipulates LRU lists for pages, sets pages active based on specific flags, updates VM event counters, and page reclaim stats. These mistaken descriptions target the primary purpose incorrectly, making them FATAL errors on the core semantics. There are no clearly accurate claims that match the code behavior, resulting in no net benefit."
            ]
        }
    }
}
{
    "source_code": "\nstatic void unix_sock_destructor(struct sock *sk)\n{\n\tstruct unix_sock *u = unix_sk(sk);\n\n\tskb_queue_purge(&sk->sk_receive_queue);\n\n\tWARN_ON(atomic_read(&sk->sk_wmem_alloc));\n\tWARN_ON(!sk_unhashed(sk));\n\tWARN_ON(sk->sk_socket);\n\tif (!sock_flag(sk, SOCK_DEAD)) {\n\t\tprintk(KERN_INFO \"Attempt to release alive unix socket: %p\\n\", sk);\n\t\treturn;\n\t}\n\n\tif (u->addr)\n\t\tunix_release_addr(u->addr);\n\n\tatomic_long_dec(&unix_nr_socks);\n\tlocal_bh_disable();\n\tsock_prot_inuse_add(sock_net(sk), sk->sk_prot, -1);\n\tlocal_bh_enable();\n#ifdef UNIX_REFCNT_DEBUG\n\tprintk(KERN_DEBUG \"UNIX %p is destroyed, %ld are still alive.\\n\", sk,\n\t\tatomic_long_read(&unix_nr_socks));\n#endif\n}",
    "comment": "Destroys a Unix socket, purging its receive queue and decrementing the count of active sockets if the socket is marked as dead.",
    "prorec_sum": "Closes an AF_UNIX socket, logging state details, releasing associated resources, and decrementing reference counters before final cleanup operations.",
    "filter_prorec_sum": "Closes a UNIX domain socket, logging state checks, releasing associated resources, and decrementing reference counters before final cleanup.",
    "prorec_aug_sum": "Finalizes and logs UNIX socket state, updates reference counters, releases associated resources, and performs connection teardown if specific flags and conditions are met.",
    "filter_prorec_aug_sum": "Logs AF_UNIX socket state transitions, updates reference counters, and releases associated resources during socket teardown or cleanup.",
    "work_score": {
        "prorec": {
            "summary": "Closes an AF_UNIX socket, logging state details, releasing associated resources, and decrementing reference counters before final cleanup operations.",
            "score": [
                0.9,
                0.5,
                0.7
            ],
            "reason": [
                "The summary correctly identifies that the function deals with an AF_UNIX socket, logs state details, releases resources, and decrements reference counters before cleanup. These match the code, which purges the receive queue, logs warnings, releases the socket address, decreases the socket count, and updates usage counters. While the summary omits some specifics such as the alive-socket check and conditional logging, all stated claims are accurate and relevant to the function's semantics, yielding a high proportion of accurate claims.",
                "The summary correctly identifies that the function deals with an AF_UNIX socket and mentions logging, resource release, and reference counter decrement, which align with accurate behaviors in the code. However, it fails to explicitly state the core purpose with sufficient specificity\u2014this is the destructor logic for a UNIX socket, including purging the receive queue, checking invariants, and handling SOCK_DEAD state. Secondary details like conditional early return and specific warned conditions are missing, resulting in incomplete coverage of critical semantics.",
                "The summary correctly captures the core purpose of the function: it handles the destruction of an AF_UNIX socket by logging details, releasing its address if present, and decrementing the global socket counter before final cleanup. These are specific and verifiable from the code. There is no clear inaccurate or noisy claim; however, the description is moderately generic and omits finer details like the queue purge, WARN_ON checks, and conditional early return, limiting its informational value."
            ]
        },
        "filter_prorec": {
            "summary": "Closes a UNIX domain socket, logging state checks, releasing associated resources, and decrementing reference counters before final cleanup.",
            "score": [
                0.9,
                0.6,
                0.6
            ],
            "reason": [
                "The summary correctly captures the function's purpose of cleaning up a UNIX domain socket, including logging checks, releasing resources, and decrementing counters, which aligns with the source code\u2019s purge of receive queue, WARN_ON state validations, address release, and counter updates. All claims are high-level but accurate, with no contradictions or irrelevant content.",
                "The summary captures the core purpose of destructing a UNIX domain socket and includes accurate references to state checks, resource release, and decrementing counters, aligning with the function\u2019s actual behavior. However, it lacks specificity on critical details such as purging the receive queue, the exact conditions for aborting cleanup when the socket is alive, and the disabling/enabling of bottom halves. These omissions mean secondary coverage is incomplete despite correctly identifying the main action.",
                "The summary correctly captures the core purpose of the function\u2014cleaning up a UNIX domain socket\u2014and references logging state checks, resource release, and decrementing counters, all of which are present in the source. However, it omits some specific steps such as purging the receive queue, the SOCK_DEAD check that can abort destruction, and the exact sequence of operations with local_bh_disable/enable. There are no inaccurate claims, but the description remains generic, providing only moderate insight into the function's semantics."
            ]
        }
    }
}
{
    "source_code": "\nstatic int\n_nullstream_ctl (struct _mu_stream *str, int code, int opcode, void *arg)\n{\n  struct _mu_nullstream *np = (struct _mu_nullstream *)str;\n\n  if (code != MU_IOCTL_NULLSTREAM)\n    /* Only this code is supported */\n    return ENOSYS;\n  switch (opcode)\n    {\n    case MU_IOCTL_NULLSTREAM_SET_PATTERN:\n      if (!arg)\n\t_nullstream_free_pattern (np);\n      else\n\t{\n\t  struct mu_nullstream_pattern *pat = arg;\n\t  char *p;\n\t  \n\t  p = malloc (pat->size);\n\t  if (!p)\n\t    return ENOMEM;\n\t  memcpy (p, pat->pattern, pat->size);\n\t  _nullstream_free_pattern (np);\n\t  np->pattern = p;\n\t  np->patsize = pat->size;\n\t}\n      break;\n\n    case MU_IOCTL_NULLSTREAM_SET_PATCLASS:\n      if (!arg)\n\treturn EINVAL;\n      else\n\t{\n\t  char buf[256];\n\t  int cnt = 0, i;\n\t  int class = *(int*)arg;\n\t  char *p;\n\t  \n\t  for (i = 0; i < 256; i++)\n\t    {\n\t      if (mu_c_is_class (i, class))\n\t\tbuf[cnt++] = i;\n\t    }\n\n\t  p = malloc (cnt);\n\t  if (!p)\n\t    return ENOMEM;\n\t  memcpy (p, buf, cnt);\n\t  _nullstream_free_pattern (np);\n\t  np->pattern = p;\n\t  np->patsize = cnt;\n\t}\n      break;\n\t  \n    case MU_IOCTL_NULLSTREAM_SETSIZE:\n      if (!arg)\n\treturn EINVAL;\n      else\n\treturn _nullstream_truncate (str, *(mu_off_t*)arg);\n      break;\n\n    case MU_IOCTL_NULLSTREAM_CLRSIZE:\n      np->mode &= ~MU_NULLSTREAM_SIZE;\n      np->base.size = NULL;\n      break;\n      \n    default:\n      return ENOSYS;\n    }\n  return 0;\n}",
    "comment": "Handles control operations for a nullstream, including setting patterns, pattern classes, and managing size-related functionalities.",
    "prorec_sum": "Configures a path object\u2019s internal byte list or attributes based on mode, allocating and copying data, clearing flags, or delegating to helper functions.",
    "filter_prorec_sum": "Configures a path object\u2019s internal byte list or size settings based on mode, allocating and copying data or clearing fields as instructed.",
    "prorec_aug_sum": "Configures a data structure\u2019s byte list or related parameters based on mode, allocating and copying memory as needed, and resetting fields when required.",
    "filter_prorec_aug_sum": "Configures a data structure\u2019s byte filter or content buffer based on mode, allocating and copying data accordingly, and resets related state fields.",
    "work_score": {
        "prorec": {
            "summary": "Configures a path object\u2019s internal byte list or attributes based on mode, allocating and copying data, clearing flags, or delegating to helper functions.",
            "score": [
                0.2,
                0.2,
                0.2
            ],
            "reason": [
                "The summary\u2019s description of configuring a 'path object' does not match the source code, which configures a _nullstream object\u2019s pattern, pattern class, size, or clears its size flag. The summary\u2019s terminology and focus on a 'byte list' and 'attributes' are imprecise and misaligned with the actual ioctl handling logic. While it vaguely mentions allocation, copying, clearing flags, and delegating to helper functions, these are generic and do not accurately capture the function\u2019s domain semantics, resulting in few accurate claims.",
                "The summary misidentifies the domain, referring to a 'path object' instead of the nullstream control function in the source. It does not accurately capture the core purpose, which is handling specific ioctl commands to set patterns, pattern classes, size, or clear size for a nullstream, with error handling for invalid codes or memory allocation failures. While it vaguely mentions allocation, copying, clearing flags, and delegating to helper functions, these are generic and incorrectly contextualized, so the primary domain operation is missing and secondary details are too vague.",
                "The summary incorrectly describes the function as operating on a 'path object\u2019s internal byte list or attributes', which contradicts the source code that shows it configures a null stream object via various ioctl opcodes. This is a FATAL error targeting the primary purpose, as it misidentifies the core domain entity and semantics. While there is a vague mention of allocating, copying data, clearing flags, and delegating to helper functions, these are generic and low-info, and the core WHAT is wrong, making the overall net benefit unusable."
            ]
        },
        "filter_prorec": {
            "summary": "Configures a path object\u2019s internal byte list or size settings based on mode, allocating and copying data or clearing fields as instructed.",
            "score": [
                0.1,
                0.1,
                0.2
            ],
            "reason": [
                "The summary inaccurately describes the function as configuring a 'path object\u2019s internal byte list or size settings,' which does not match the source code. The function operates on a _mu_nullstream structure, handling IOCTL commands to set patterns, pattern classes, truncate size, or clear size, with specific error handling and memory operations. None of these claims about a 'path object' or generic mode-based configuration align with the actual semantics, resulting in a very low proportion of accurate claims.",
                "The summary is inaccurate because it describes configuring a 'path object\u2019s internal byte list' rather than the actual nullstream object and its pattern or size settings. It misses the core purpose of handling MU_IOCTL_NULLSTREAM commands to set a byte pattern, create a pattern based on character class, adjust size, or clear size, with specific memory allocation logic and error handling. No [ACCURATE] claim in the summary states this domain-specific behavior, and secondary details like error returns (ENOSYS, ENOMEM, EINVAL) are entirely absent.",
                "The summary is inaccurate because it refers to a 'path object' and 'byte list', which do not align with the source code's domain. The function operates on a '_mu_nullstream' object, handling ioctl commands to set a pattern, set a pattern class, adjust size, or clear size. The mismatch in object type and terminology misrepresents the primary purpose and semantics, making this a FATAL error on the core description. No specific, accurate GOLD claims are present to offset this failure."
            ]
        }
    }
}
{
    "source_code": "\nstatic int des_ede_cfb64_cipher(EVP_CIPHER_CTX *ctx, unsigned char *out,\n\t\t\t      const unsigned char *in, size_t inl)\n{\n\twhile (inl>=EVP_MAXCHUNK)\n\t\t{\n\t\tDES_ede3_cfb64_encrypt(in, out, (long)EVP_MAXCHUNK, \n\t\t\t       &data(ctx)->ks1, &data(ctx)->ks2, &data(ctx)->ks3,\n\t\t\t       (DES_cblock *)ctx->iv, &ctx->num, ctx->encrypt);\n\t\tinl-=EVP_MAXCHUNK;\n\t\tin +=EVP_MAXCHUNK;\n\t\tout+=EVP_MAXCHUNK;\n\t\t}\n\tif (inl)\n\t\tDES_ede3_cfb64_encrypt(in, out, (long)inl,\n\t\t\t       &data(ctx)->ks1, &data(ctx)->ks2, &data(ctx)->ks3,\n                               (DES_cblock *)ctx->iv, &ctx->num, ctx->encrypt);\n\treturn 1;\n}",
    "comment": "Encrypts input data using Triple DES in CFB64 mode, processing it in chunks of EVP_MAXCHUNK size.",
    "prorec_sum": "Encrypts a large input buffer using 3DES in CFB64 mode, processing huge chunks iteratively and handling any remaining bytes in a final call.",
    "filter_prorec_sum": "Encrypts data in large chunks using triple DES in CFB64 mode, handling oversized input by processing sequential 2^62\u2011byte segments before the remainder.",
    "prorec_aug_sum": "Encrypts data of arbitrary length using 3DES in CFB64 mode, processing extremely large inputs in 2^62\u2011byte chunks before handling any remaining bytes.",
    "filter_prorec_aug_sum": "Encrypts data using 3DES in CFB64 mode, processing extremely large buffers in 2^62\u2011byte chunks before handling any remaining bytes.",
    "work_score": {
        "prorec": {
            "summary": "Encrypts a large input buffer using 3DES in CFB64 mode, processing huge chunks iteratively and handling any remaining bytes in a final call.",
            "score": [
                1.0,
                0.6,
                0.9
            ],
            "reason": [
                "The summary accurately describes that the function encrypts data using 3DES in CFB64 mode, processes large chunks iteratively, and handles remaining bytes in a final call. All claims are grounded in the source code's logic, with no contradictions or irrelevant statements, indicating high alignment with the evaluation steps.",
                "The summary correctly identifies the function's purpose as performing encryption with 3DES in CFB64 mode, and notes the iterative processing of large chunks plus handling remaining bytes. This matches the core domain operation and captures the key loop and final partial block logic from the code. However, it omits specific constant usage (EVP_MAXCHUNK), function call details (DES_ede3_cfb64_encrypt parameters), and lacks mention of context/state handling, so secondary coverage is only moderate.",
                "The summary accurately describes the function\u2019s primary purpose: performing 3DES encryption in CFB64 mode over large input buffers, processing in max-size chunks and then finishing with any remaining bytes. There are no inaccurate or noisy claims, and it matches the source code\u2019s iterative chunk handling. The claim is specific to the core domain behavior, providing clear, high-value insight without contradictions."
            ]
        },
        "filter_prorec": {
            "summary": "Encrypts data in large chunks using triple DES in CFB64 mode, handling oversized input by processing sequential 2^62\u2011byte segments before the remainder.",
            "score": [
                0.5,
                0.5,
                0.2
            ],
            "reason": [
                "The summary correctly states that the function uses triple DES in CFB64 mode to encrypt data, and that it processes oversize input in chunks before handling the remainder. However, it inaccurately specifies '2^62\u2011byte segments' when the code clearly uses EVP_MAXCHUNK as the chunk size, which is not shown to be 2^62 bytes in the source. This incorrect chunk size detail reduces accuracy, leaving only some claims correct, resulting in mixed reliability.",
                "The summary correctly identifies the core purpose as encrypting data using triple DES in CFB64 mode and notes the sequential processing of large inputs. However, it inaccurately specifies '2^62\u2011byte segments' instead of the actual EVP_MAXCHUNK constant used by the code, making the chunk size claim incorrect. While the core domain operation is covered, the erroneous detail reduces alignment with the source semantics and omits mention of other behaviors like handling the remainder after chunk processing, key schedules, IV/state updates, or return value.",
                "The summary correctly identifies that the function encrypts data using triple DES in CFB64 mode and processes large inputs in chunks, which matches the code\u2019s use of DES_ede3_cfb64_encrypt with EVP_MAXCHUNK looping and a final remainder. However, it inaccurately claims processing sequential 2^62-byte segments\u2014EVP_MAXCHUNK is not 2^62\u2014making this a FATAL error about the chunk size, a key I/O detail in core behavior. This severely undermines trust in the summary\u2019s accuracy despite some correct elements."
            ]
        }
    }
}
